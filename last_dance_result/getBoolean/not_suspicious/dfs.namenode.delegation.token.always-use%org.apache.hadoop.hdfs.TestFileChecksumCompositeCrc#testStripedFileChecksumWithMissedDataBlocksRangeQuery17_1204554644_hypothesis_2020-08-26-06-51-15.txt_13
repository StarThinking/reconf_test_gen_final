reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-281743988-172.17.0.4-1598424770456:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36925,DS-9f24a958-3311-434f-b374-fb1a4906e69e,DISK], DatanodeInfoWithStorage[127.0.0.1:41767,DS-736d9d14-4cac-43f4-8f52-68e6360db9b0,DISK], DatanodeInfoWithStorage[127.0.0.1:36578,DS-fcd097f9-fefb-454b-bd86-b494f18529e7,DISK], DatanodeInfoWithStorage[127.0.0.1:35271,DS-8013b7ec-46f3-46ec-bbb7-e66522e293e0,DISK], DatanodeInfoWithStorage[127.0.0.1:35147,DS-6aa68890-4792-486f-8a7e-7af54a2ce4f2,DISK], DatanodeInfoWithStorage[127.0.0.1:35746,DS-b51c59c7-581a-440f-bd8e-0700e101e7e5,DISK], DatanodeInfoWithStorage[127.0.0.1:46312,DS-a576750a-c0c2-4065-a30f-f415cbcb1c39,DISK], DatanodeInfoWithStorage[127.0.0.1:42401,DS-fe9fce98-f73f-4eb9-8726-f88ebc8b4704,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-281743988-172.17.0.4-1598424770456:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36925,DS-9f24a958-3311-434f-b374-fb1a4906e69e,DISK], DatanodeInfoWithStorage[127.0.0.1:41767,DS-736d9d14-4cac-43f4-8f52-68e6360db9b0,DISK], DatanodeInfoWithStorage[127.0.0.1:36578,DS-fcd097f9-fefb-454b-bd86-b494f18529e7,DISK], DatanodeInfoWithStorage[127.0.0.1:35271,DS-8013b7ec-46f3-46ec-bbb7-e66522e293e0,DISK], DatanodeInfoWithStorage[127.0.0.1:35147,DS-6aa68890-4792-486f-8a7e-7af54a2ce4f2,DISK], DatanodeInfoWithStorage[127.0.0.1:35746,DS-b51c59c7-581a-440f-bd8e-0700e101e7e5,DISK], DatanodeInfoWithStorage[127.0.0.1:46312,DS-a576750a-c0c2-4065-a30f-f415cbcb1c39,DISK], DatanodeInfoWithStorage[127.0.0.1:42401,DS-fe9fce98-f73f-4eb9-8726-f88ebc8b4704,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-528346663-172.17.0.4-1598424887377:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45075,DS-e63fa789-a50e-43f4-b328-e8f56b9d1059,DISK], DatanodeInfoWithStorage[127.0.0.1:33283,DS-31dd0b4c-5a9a-4b92-ac57-a46c3f1f7912,DISK], DatanodeInfoWithStorage[127.0.0.1:37364,DS-b1594ccd-0ad7-4a57-8cb2-5b74d6475276,DISK], DatanodeInfoWithStorage[127.0.0.1:35370,DS-2eff3b64-fcc7-4dc3-9d0f-06ac666db078,DISK], DatanodeInfoWithStorage[127.0.0.1:36614,DS-629932bf-db97-4b31-9373-0473270f3d4f,DISK], DatanodeInfoWithStorage[127.0.0.1:42023,DS-df5e3bcd-3ec5-469e-bf40-34768547f79c,DISK], DatanodeInfoWithStorage[127.0.0.1:39944,DS-784d2300-4c63-42bd-b407-0c949b5db996,DISK], DatanodeInfoWithStorage[127.0.0.1:33034,DS-4f9ced02-d1ab-40d4-b2b9-4779c75055d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-528346663-172.17.0.4-1598424887377:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45075,DS-e63fa789-a50e-43f4-b328-e8f56b9d1059,DISK], DatanodeInfoWithStorage[127.0.0.1:33283,DS-31dd0b4c-5a9a-4b92-ac57-a46c3f1f7912,DISK], DatanodeInfoWithStorage[127.0.0.1:37364,DS-b1594ccd-0ad7-4a57-8cb2-5b74d6475276,DISK], DatanodeInfoWithStorage[127.0.0.1:35370,DS-2eff3b64-fcc7-4dc3-9d0f-06ac666db078,DISK], DatanodeInfoWithStorage[127.0.0.1:36614,DS-629932bf-db97-4b31-9373-0473270f3d4f,DISK], DatanodeInfoWithStorage[127.0.0.1:42023,DS-df5e3bcd-3ec5-469e-bf40-34768547f79c,DISK], DatanodeInfoWithStorage[127.0.0.1:39944,DS-784d2300-4c63-42bd-b407-0c949b5db996,DISK], DatanodeInfoWithStorage[127.0.0.1:33034,DS-4f9ced02-d1ab-40d4-b2b9-4779c75055d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-118581015-172.17.0.4-1598425133024:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33237,DS-508d661f-ca13-455d-87ba-55a7bddfd218,DISK], DatanodeInfoWithStorage[127.0.0.1:45982,DS-c6e3d4fb-8e0c-4c87-adc8-59d36d4690d0,DISK], DatanodeInfoWithStorage[127.0.0.1:36089,DS-ba21ae40-f394-4d9c-ae73-e9de3b8977a6,DISK], DatanodeInfoWithStorage[127.0.0.1:40207,DS-ea1ff2d3-1772-48cb-bede-e519415ca35b,DISK], DatanodeInfoWithStorage[127.0.0.1:43667,DS-1a65c61b-eca6-4ddb-938b-a43f2add21a0,DISK], DatanodeInfoWithStorage[127.0.0.1:42235,DS-db62522e-65c5-4798-ab8c-d2954589c0a3,DISK], DatanodeInfoWithStorage[127.0.0.1:46435,DS-acfe3896-989a-4792-90c8-43c83c35b4f2,DISK], DatanodeInfoWithStorage[127.0.0.1:41186,DS-98dc4d77-1c99-4e4e-a073-593a14b0861d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-118581015-172.17.0.4-1598425133024:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33237,DS-508d661f-ca13-455d-87ba-55a7bddfd218,DISK], DatanodeInfoWithStorage[127.0.0.1:45982,DS-c6e3d4fb-8e0c-4c87-adc8-59d36d4690d0,DISK], DatanodeInfoWithStorage[127.0.0.1:36089,DS-ba21ae40-f394-4d9c-ae73-e9de3b8977a6,DISK], DatanodeInfoWithStorage[127.0.0.1:40207,DS-ea1ff2d3-1772-48cb-bede-e519415ca35b,DISK], DatanodeInfoWithStorage[127.0.0.1:43667,DS-1a65c61b-eca6-4ddb-938b-a43f2add21a0,DISK], DatanodeInfoWithStorage[127.0.0.1:42235,DS-db62522e-65c5-4798-ab8c-d2954589c0a3,DISK], DatanodeInfoWithStorage[127.0.0.1:46435,DS-acfe3896-989a-4792-90c8-43c83c35b4f2,DISK], DatanodeInfoWithStorage[127.0.0.1:41186,DS-98dc4d77-1c99-4e4e-a073-593a14b0861d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-528607097-172.17.0.4-1598425173112:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40162,DS-95b6a6ed-b6b2-4de0-940f-82c0e2b1dd9e,DISK], DatanodeInfoWithStorage[127.0.0.1:43453,DS-f80d7f9a-6895-4016-82dc-b423e00bccb1,DISK], DatanodeInfoWithStorage[127.0.0.1:33961,DS-56ef3f23-30bb-4336-b664-b34e82bdd94b,DISK], DatanodeInfoWithStorage[127.0.0.1:44402,DS-4e9edcfc-0d05-4469-967f-4cec29781345,DISK], DatanodeInfoWithStorage[127.0.0.1:46084,DS-ff979364-7214-4516-8a67-1b21da8364dd,DISK], DatanodeInfoWithStorage[127.0.0.1:38800,DS-eb374a90-593e-4549-bff0-8a483e960028,DISK], DatanodeInfoWithStorage[127.0.0.1:34920,DS-77ce511c-31c4-4fe6-8b3c-ddacf179b27c,DISK], DatanodeInfoWithStorage[127.0.0.1:43398,DS-0a1ed434-fe02-427b-97ea-26e4931fba2a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-528607097-172.17.0.4-1598425173112:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40162,DS-95b6a6ed-b6b2-4de0-940f-82c0e2b1dd9e,DISK], DatanodeInfoWithStorage[127.0.0.1:43453,DS-f80d7f9a-6895-4016-82dc-b423e00bccb1,DISK], DatanodeInfoWithStorage[127.0.0.1:33961,DS-56ef3f23-30bb-4336-b664-b34e82bdd94b,DISK], DatanodeInfoWithStorage[127.0.0.1:44402,DS-4e9edcfc-0d05-4469-967f-4cec29781345,DISK], DatanodeInfoWithStorage[127.0.0.1:46084,DS-ff979364-7214-4516-8a67-1b21da8364dd,DISK], DatanodeInfoWithStorage[127.0.0.1:38800,DS-eb374a90-593e-4549-bff0-8a483e960028,DISK], DatanodeInfoWithStorage[127.0.0.1:34920,DS-77ce511c-31c4-4fe6-8b3c-ddacf179b27c,DISK], DatanodeInfoWithStorage[127.0.0.1:43398,DS-0a1ed434-fe02-427b-97ea-26e4931fba2a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1500696020-172.17.0.4-1598425241436:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36175,DS-6d697da8-c7b1-4aaf-9056-d95b1e679a25,DISK], DatanodeInfoWithStorage[127.0.0.1:34466,DS-71d24346-39be-4854-a22e-72f10ac3a878,DISK], DatanodeInfoWithStorage[127.0.0.1:38203,DS-d03df50e-57e2-4729-b9b0-8825b7f6d365,DISK], DatanodeInfoWithStorage[127.0.0.1:44450,DS-44e180e1-6ed4-4fc5-9079-22227ebf266d,DISK], DatanodeInfoWithStorage[127.0.0.1:45269,DS-7b6b8f08-d09e-418f-8fed-0b253f5be5da,DISK], DatanodeInfoWithStorage[127.0.0.1:35720,DS-17187f61-abcf-4394-a136-d92e2256baaa,DISK], DatanodeInfoWithStorage[127.0.0.1:39922,DS-00756318-0af2-44da-81fe-bf0ed2d4993d,DISK], DatanodeInfoWithStorage[127.0.0.1:43121,DS-275ef599-5302-462d-94e5-34673be94e81,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1500696020-172.17.0.4-1598425241436:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36175,DS-6d697da8-c7b1-4aaf-9056-d95b1e679a25,DISK], DatanodeInfoWithStorage[127.0.0.1:34466,DS-71d24346-39be-4854-a22e-72f10ac3a878,DISK], DatanodeInfoWithStorage[127.0.0.1:38203,DS-d03df50e-57e2-4729-b9b0-8825b7f6d365,DISK], DatanodeInfoWithStorage[127.0.0.1:44450,DS-44e180e1-6ed4-4fc5-9079-22227ebf266d,DISK], DatanodeInfoWithStorage[127.0.0.1:45269,DS-7b6b8f08-d09e-418f-8fed-0b253f5be5da,DISK], DatanodeInfoWithStorage[127.0.0.1:35720,DS-17187f61-abcf-4394-a136-d92e2256baaa,DISK], DatanodeInfoWithStorage[127.0.0.1:39922,DS-00756318-0af2-44da-81fe-bf0ed2d4993d,DISK], DatanodeInfoWithStorage[127.0.0.1:43121,DS-275ef599-5302-462d-94e5-34673be94e81,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1815994342-172.17.0.4-1598425312869:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38756,DS-cee55223-c780-45e6-a766-ce143eda5971,DISK], DatanodeInfoWithStorage[127.0.0.1:40123,DS-33d56449-47ea-4e6a-972f-9e0ec7128a2f,DISK], DatanodeInfoWithStorage[127.0.0.1:44447,DS-3588247e-95e1-4076-ad47-b6d8150380f5,DISK], DatanodeInfoWithStorage[127.0.0.1:39009,DS-7bb0d7d6-9013-41a9-95c9-b3f185b4072a,DISK], DatanodeInfoWithStorage[127.0.0.1:39986,DS-9344402e-312b-41cc-a51b-aa2b6a64e9c8,DISK], DatanodeInfoWithStorage[127.0.0.1:33636,DS-7f121cfe-3769-436b-9f9a-3b5b08ff26c6,DISK], DatanodeInfoWithStorage[127.0.0.1:32932,DS-e54e35e7-304a-4623-be98-c58fd3032fc3,DISK], DatanodeInfoWithStorage[127.0.0.1:36637,DS-90325751-7fcf-4782-beee-1816fb0562a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1815994342-172.17.0.4-1598425312869:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38756,DS-cee55223-c780-45e6-a766-ce143eda5971,DISK], DatanodeInfoWithStorage[127.0.0.1:40123,DS-33d56449-47ea-4e6a-972f-9e0ec7128a2f,DISK], DatanodeInfoWithStorage[127.0.0.1:44447,DS-3588247e-95e1-4076-ad47-b6d8150380f5,DISK], DatanodeInfoWithStorage[127.0.0.1:39009,DS-7bb0d7d6-9013-41a9-95c9-b3f185b4072a,DISK], DatanodeInfoWithStorage[127.0.0.1:39986,DS-9344402e-312b-41cc-a51b-aa2b6a64e9c8,DISK], DatanodeInfoWithStorage[127.0.0.1:33636,DS-7f121cfe-3769-436b-9f9a-3b5b08ff26c6,DISK], DatanodeInfoWithStorage[127.0.0.1:32932,DS-e54e35e7-304a-4623-be98-c58fd3032fc3,DISK], DatanodeInfoWithStorage[127.0.0.1:36637,DS-90325751-7fcf-4782-beee-1816fb0562a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-477730718-172.17.0.4-1598425590979:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42200,DS-49828666-1596-430d-9fe5-327e14b884f3,DISK], DatanodeInfoWithStorage[127.0.0.1:40349,DS-c9473449-09db-4e69-a58b-d720bfa0d09c,DISK], DatanodeInfoWithStorage[127.0.0.1:40116,DS-e6f11e68-5b32-46d1-8a2a-706cfb0d97d2,DISK], DatanodeInfoWithStorage[127.0.0.1:38037,DS-9ca74572-47d8-428f-9fdf-a9410bcd7e12,DISK], DatanodeInfoWithStorage[127.0.0.1:40605,DS-bd903562-fe7f-4e69-b5d7-b40697f18be2,DISK], DatanodeInfoWithStorage[127.0.0.1:41226,DS-6c15743b-aa96-4b05-aba9-8beb437f5dfd,DISK], DatanodeInfoWithStorage[127.0.0.1:33381,DS-982c35c9-ebec-4660-97d0-0006283bc526,DISK], DatanodeInfoWithStorage[127.0.0.1:46449,DS-3b30a803-584a-4be7-a871-a31f67ac8b62,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-477730718-172.17.0.4-1598425590979:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42200,DS-49828666-1596-430d-9fe5-327e14b884f3,DISK], DatanodeInfoWithStorage[127.0.0.1:40349,DS-c9473449-09db-4e69-a58b-d720bfa0d09c,DISK], DatanodeInfoWithStorage[127.0.0.1:40116,DS-e6f11e68-5b32-46d1-8a2a-706cfb0d97d2,DISK], DatanodeInfoWithStorage[127.0.0.1:38037,DS-9ca74572-47d8-428f-9fdf-a9410bcd7e12,DISK], DatanodeInfoWithStorage[127.0.0.1:40605,DS-bd903562-fe7f-4e69-b5d7-b40697f18be2,DISK], DatanodeInfoWithStorage[127.0.0.1:41226,DS-6c15743b-aa96-4b05-aba9-8beb437f5dfd,DISK], DatanodeInfoWithStorage[127.0.0.1:33381,DS-982c35c9-ebec-4660-97d0-0006283bc526,DISK], DatanodeInfoWithStorage[127.0.0.1:46449,DS-3b30a803-584a-4be7-a871-a31f67ac8b62,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1963547548-172.17.0.4-1598426573196:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33216,DS-b00454f5-a156-4589-b644-fa7446c8385f,DISK], DatanodeInfoWithStorage[127.0.0.1:37368,DS-00efdbde-f1c7-4d7c-ba82-7601a762de63,DISK], DatanodeInfoWithStorage[127.0.0.1:38590,DS-9ec8d6e8-8845-4c66-8de0-0f79d4622e90,DISK], DatanodeInfoWithStorage[127.0.0.1:38773,DS-7f06148a-d44d-4f57-9246-2a3236ed0e03,DISK], DatanodeInfoWithStorage[127.0.0.1:34942,DS-ff1947e1-560e-46d6-b584-5b6ee07e8885,DISK], DatanodeInfoWithStorage[127.0.0.1:42078,DS-485ecba5-7242-4062-9066-c1e37b1c5115,DISK], DatanodeInfoWithStorage[127.0.0.1:33604,DS-033f1949-7587-488b-be32-0ee2f3e5bb7b,DISK], DatanodeInfoWithStorage[127.0.0.1:35434,DS-eca16a8b-6b7d-4660-8648-294c0e9d7af4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1963547548-172.17.0.4-1598426573196:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33216,DS-b00454f5-a156-4589-b644-fa7446c8385f,DISK], DatanodeInfoWithStorage[127.0.0.1:37368,DS-00efdbde-f1c7-4d7c-ba82-7601a762de63,DISK], DatanodeInfoWithStorage[127.0.0.1:38590,DS-9ec8d6e8-8845-4c66-8de0-0f79d4622e90,DISK], DatanodeInfoWithStorage[127.0.0.1:38773,DS-7f06148a-d44d-4f57-9246-2a3236ed0e03,DISK], DatanodeInfoWithStorage[127.0.0.1:34942,DS-ff1947e1-560e-46d6-b584-5b6ee07e8885,DISK], DatanodeInfoWithStorage[127.0.0.1:42078,DS-485ecba5-7242-4062-9066-c1e37b1c5115,DISK], DatanodeInfoWithStorage[127.0.0.1:33604,DS-033f1949-7587-488b-be32-0ee2f3e5bb7b,DISK], DatanodeInfoWithStorage[127.0.0.1:35434,DS-eca16a8b-6b7d-4660-8648-294c0e9d7af4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-333598148-172.17.0.4-1598426608480:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45801,DS-4e77f64c-a0ba-45ad-8c42-f6af551a4e96,DISK], DatanodeInfoWithStorage[127.0.0.1:45268,DS-ee03f58c-37f3-42b2-8a57-5beb7036e281,DISK], DatanodeInfoWithStorage[127.0.0.1:34990,DS-cd6bfc44-51d0-488c-8257-3adab921cebe,DISK], DatanodeInfoWithStorage[127.0.0.1:35781,DS-eaccd736-d8b8-4c09-b1eb-e100740797b0,DISK], DatanodeInfoWithStorage[127.0.0.1:46625,DS-8f4b28e2-7f38-40f4-b246-99a9e0021317,DISK], DatanodeInfoWithStorage[127.0.0.1:45339,DS-3315ed0d-e864-4561-83c3-e5204f5b788d,DISK], DatanodeInfoWithStorage[127.0.0.1:46110,DS-c4e2184e-1c2c-494f-967c-fe3360ec6119,DISK], DatanodeInfoWithStorage[127.0.0.1:35670,DS-9e2a4b1a-ef8c-43eb-bd54-c7920f3326a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-333598148-172.17.0.4-1598426608480:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45801,DS-4e77f64c-a0ba-45ad-8c42-f6af551a4e96,DISK], DatanodeInfoWithStorage[127.0.0.1:45268,DS-ee03f58c-37f3-42b2-8a57-5beb7036e281,DISK], DatanodeInfoWithStorage[127.0.0.1:34990,DS-cd6bfc44-51d0-488c-8257-3adab921cebe,DISK], DatanodeInfoWithStorage[127.0.0.1:35781,DS-eaccd736-d8b8-4c09-b1eb-e100740797b0,DISK], DatanodeInfoWithStorage[127.0.0.1:46625,DS-8f4b28e2-7f38-40f4-b246-99a9e0021317,DISK], DatanodeInfoWithStorage[127.0.0.1:45339,DS-3315ed0d-e864-4561-83c3-e5204f5b788d,DISK], DatanodeInfoWithStorage[127.0.0.1:46110,DS-c4e2184e-1c2c-494f-967c-fe3360ec6119,DISK], DatanodeInfoWithStorage[127.0.0.1:35670,DS-9e2a4b1a-ef8c-43eb-bd54-c7920f3326a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-775625486-172.17.0.4-1598426768689:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41960,DS-08129463-6d13-4ea0-9d60-8b5e2f434f02,DISK], DatanodeInfoWithStorage[127.0.0.1:45712,DS-a8cf0ee3-87a1-4f4e-9b29-02e3fbd0185b,DISK], DatanodeInfoWithStorage[127.0.0.1:32871,DS-3bde73dc-6f52-49a7-ac4a-84698a4ce3f2,DISK], DatanodeInfoWithStorage[127.0.0.1:41721,DS-c34daf6f-68fa-4ec3-9c7f-e640aaca54e6,DISK], DatanodeInfoWithStorage[127.0.0.1:45537,DS-0f1c16fc-00f2-4f31-8634-c0bc86f567bc,DISK], DatanodeInfoWithStorage[127.0.0.1:41382,DS-02b268c3-bad5-4c93-a939-dcd2b6280d9c,DISK], DatanodeInfoWithStorage[127.0.0.1:38357,DS-eaca05e4-aece-42eb-a6c4-16187e3b5347,DISK], DatanodeInfoWithStorage[127.0.0.1:42623,DS-cb7617f0-3f76-408e-981f-6fdd6f182dc1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-775625486-172.17.0.4-1598426768689:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41960,DS-08129463-6d13-4ea0-9d60-8b5e2f434f02,DISK], DatanodeInfoWithStorage[127.0.0.1:45712,DS-a8cf0ee3-87a1-4f4e-9b29-02e3fbd0185b,DISK], DatanodeInfoWithStorage[127.0.0.1:32871,DS-3bde73dc-6f52-49a7-ac4a-84698a4ce3f2,DISK], DatanodeInfoWithStorage[127.0.0.1:41721,DS-c34daf6f-68fa-4ec3-9c7f-e640aaca54e6,DISK], DatanodeInfoWithStorage[127.0.0.1:45537,DS-0f1c16fc-00f2-4f31-8634-c0bc86f567bc,DISK], DatanodeInfoWithStorage[127.0.0.1:41382,DS-02b268c3-bad5-4c93-a939-dcd2b6280d9c,DISK], DatanodeInfoWithStorage[127.0.0.1:38357,DS-eaca05e4-aece-42eb-a6c4-16187e3b5347,DISK], DatanodeInfoWithStorage[127.0.0.1:42623,DS-cb7617f0-3f76-408e-981f-6fdd6f182dc1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-179260369-172.17.0.4-1598427651677:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38359,DS-986480a2-2200-4fc7-bec5-82d95a15753a,DISK], DatanodeInfoWithStorage[127.0.0.1:40429,DS-0e8b4864-4056-4ff4-b59f-b8ca9296e12e,DISK], DatanodeInfoWithStorage[127.0.0.1:41849,DS-7f9c0b96-aff6-4e49-821b-b62a9687a331,DISK], DatanodeInfoWithStorage[127.0.0.1:41718,DS-ec013d0a-b1cd-4b9f-9049-5f1cc50828ac,DISK], DatanodeInfoWithStorage[127.0.0.1:46542,DS-05b4cc00-a547-4bfc-b003-b407ab931dcb,DISK], DatanodeInfoWithStorage[127.0.0.1:33143,DS-c31e4511-4672-4e21-a026-a7bd1a966f92,DISK], DatanodeInfoWithStorage[127.0.0.1:32979,DS-7389a409-efb9-460e-b4dd-79e965c7cd7f,DISK], DatanodeInfoWithStorage[127.0.0.1:44818,DS-a66efca6-0f97-4cee-983c-ae764fbcd75e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-179260369-172.17.0.4-1598427651677:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38359,DS-986480a2-2200-4fc7-bec5-82d95a15753a,DISK], DatanodeInfoWithStorage[127.0.0.1:40429,DS-0e8b4864-4056-4ff4-b59f-b8ca9296e12e,DISK], DatanodeInfoWithStorage[127.0.0.1:41849,DS-7f9c0b96-aff6-4e49-821b-b62a9687a331,DISK], DatanodeInfoWithStorage[127.0.0.1:41718,DS-ec013d0a-b1cd-4b9f-9049-5f1cc50828ac,DISK], DatanodeInfoWithStorage[127.0.0.1:46542,DS-05b4cc00-a547-4bfc-b003-b407ab931dcb,DISK], DatanodeInfoWithStorage[127.0.0.1:33143,DS-c31e4511-4672-4e21-a026-a7bd1a966f92,DISK], DatanodeInfoWithStorage[127.0.0.1:32979,DS-7389a409-efb9-460e-b4dd-79e965c7cd7f,DISK], DatanodeInfoWithStorage[127.0.0.1:44818,DS-a66efca6-0f97-4cee-983c-ae764fbcd75e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-171667295-172.17.0.4-1598427982569:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35693,DS-37f54001-a192-4a53-bd7e-5ee79c9acaf5,DISK], DatanodeInfoWithStorage[127.0.0.1:32923,DS-66d1bc3d-b37f-462e-92c5-ee1085d1040b,DISK], DatanodeInfoWithStorage[127.0.0.1:40700,DS-0bf29a75-bd54-4646-80f1-7169e4b73f32,DISK], DatanodeInfoWithStorage[127.0.0.1:37168,DS-c69e8072-f5a6-46b3-99c9-c693ced40e36,DISK], DatanodeInfoWithStorage[127.0.0.1:44207,DS-a1d9be26-5607-455d-8b02-485f4f866315,DISK], DatanodeInfoWithStorage[127.0.0.1:37303,DS-2f903b2f-c8bd-46d4-a5b3-dffe4ec079fb,DISK], DatanodeInfoWithStorage[127.0.0.1:33138,DS-e0f3a4f6-8f2e-4cdc-8314-3b2fdbd40081,DISK], DatanodeInfoWithStorage[127.0.0.1:46243,DS-a26e0e8a-ce8b-498e-9d3d-78973677b702,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-171667295-172.17.0.4-1598427982569:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35693,DS-37f54001-a192-4a53-bd7e-5ee79c9acaf5,DISK], DatanodeInfoWithStorage[127.0.0.1:32923,DS-66d1bc3d-b37f-462e-92c5-ee1085d1040b,DISK], DatanodeInfoWithStorage[127.0.0.1:40700,DS-0bf29a75-bd54-4646-80f1-7169e4b73f32,DISK], DatanodeInfoWithStorage[127.0.0.1:37168,DS-c69e8072-f5a6-46b3-99c9-c693ced40e36,DISK], DatanodeInfoWithStorage[127.0.0.1:44207,DS-a1d9be26-5607-455d-8b02-485f4f866315,DISK], DatanodeInfoWithStorage[127.0.0.1:37303,DS-2f903b2f-c8bd-46d4-a5b3-dffe4ec079fb,DISK], DatanodeInfoWithStorage[127.0.0.1:33138,DS-e0f3a4f6-8f2e-4cdc-8314-3b2fdbd40081,DISK], DatanodeInfoWithStorage[127.0.0.1:46243,DS-a26e0e8a-ce8b-498e-9d3d-78973677b702,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-567023268-172.17.0.4-1598428890576:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46079,DS-0f2e6612-23dc-4ecf-ac86-0d6f4ef4c036,DISK], DatanodeInfoWithStorage[127.0.0.1:35840,DS-ad44e450-79f6-463b-92ce-d204187e2b6d,DISK], DatanodeInfoWithStorage[127.0.0.1:42346,DS-0552ad27-6398-4584-8640-c7a3a828cf47,DISK], DatanodeInfoWithStorage[127.0.0.1:46105,DS-9dc34d19-aecc-4eb5-b646-a276a6ec95ad,DISK], DatanodeInfoWithStorage[127.0.0.1:44571,DS-753c2f2b-381e-4773-abe2-b7aaa444e2a5,DISK], DatanodeInfoWithStorage[127.0.0.1:34146,DS-de9eb92a-7c44-45bb-aa72-a540fb0b196b,DISK], DatanodeInfoWithStorage[127.0.0.1:41789,DS-4faef01a-b8a5-4bd5-ad96-2034e0d63890,DISK], DatanodeInfoWithStorage[127.0.0.1:38595,DS-2c8f3dab-0a94-4329-bfbd-193977f5cba5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-567023268-172.17.0.4-1598428890576:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46079,DS-0f2e6612-23dc-4ecf-ac86-0d6f4ef4c036,DISK], DatanodeInfoWithStorage[127.0.0.1:35840,DS-ad44e450-79f6-463b-92ce-d204187e2b6d,DISK], DatanodeInfoWithStorage[127.0.0.1:42346,DS-0552ad27-6398-4584-8640-c7a3a828cf47,DISK], DatanodeInfoWithStorage[127.0.0.1:46105,DS-9dc34d19-aecc-4eb5-b646-a276a6ec95ad,DISK], DatanodeInfoWithStorage[127.0.0.1:44571,DS-753c2f2b-381e-4773-abe2-b7aaa444e2a5,DISK], DatanodeInfoWithStorage[127.0.0.1:34146,DS-de9eb92a-7c44-45bb-aa72-a540fb0b196b,DISK], DatanodeInfoWithStorage[127.0.0.1:41789,DS-4faef01a-b8a5-4bd5-ad96-2034e0d63890,DISK], DatanodeInfoWithStorage[127.0.0.1:38595,DS-2c8f3dab-0a94-4329-bfbd-193977f5cba5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-110106619-172.17.0.4-1598429053403:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33120,DS-aa5676d5-2693-402d-8204-199c3070b942,DISK], DatanodeInfoWithStorage[127.0.0.1:39198,DS-779f0383-1869-4dcd-a920-2e03dc98aa2d,DISK], DatanodeInfoWithStorage[127.0.0.1:33136,DS-128d6a7d-0b9f-4a8c-bfaa-d9d35cc64c99,DISK], DatanodeInfoWithStorage[127.0.0.1:44465,DS-242f8ecb-f16f-4fce-a4ce-3f769e907ba3,DISK], DatanodeInfoWithStorage[127.0.0.1:42008,DS-cb1f3eab-8d53-4935-845b-6cb3867abbc3,DISK], DatanodeInfoWithStorage[127.0.0.1:33452,DS-2aeb85ea-51e4-46a2-a418-84222bbe0a12,DISK], DatanodeInfoWithStorage[127.0.0.1:42652,DS-792bffa8-d778-406c-a747-ce2f4b01a437,DISK], DatanodeInfoWithStorage[127.0.0.1:34428,DS-4abd96be-71b5-48dd-8a98-f0d1c6bc0679,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-110106619-172.17.0.4-1598429053403:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33120,DS-aa5676d5-2693-402d-8204-199c3070b942,DISK], DatanodeInfoWithStorage[127.0.0.1:39198,DS-779f0383-1869-4dcd-a920-2e03dc98aa2d,DISK], DatanodeInfoWithStorage[127.0.0.1:33136,DS-128d6a7d-0b9f-4a8c-bfaa-d9d35cc64c99,DISK], DatanodeInfoWithStorage[127.0.0.1:44465,DS-242f8ecb-f16f-4fce-a4ce-3f769e907ba3,DISK], DatanodeInfoWithStorage[127.0.0.1:42008,DS-cb1f3eab-8d53-4935-845b-6cb3867abbc3,DISK], DatanodeInfoWithStorage[127.0.0.1:33452,DS-2aeb85ea-51e4-46a2-a418-84222bbe0a12,DISK], DatanodeInfoWithStorage[127.0.0.1:42652,DS-792bffa8-d778-406c-a747-ce2f4b01a437,DISK], DatanodeInfoWithStorage[127.0.0.1:34428,DS-4abd96be-71b5-48dd-8a98-f0d1c6bc0679,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1264668377-172.17.0.4-1598429380511:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38895,DS-18a9ce99-3115-4335-8d86-9e535d9be09d,DISK], DatanodeInfoWithStorage[127.0.0.1:34473,DS-9c429037-78c5-4c0c-a8ef-8ae80fbbe39b,DISK], DatanodeInfoWithStorage[127.0.0.1:39466,DS-3fa392ba-16c4-4012-a97f-cbd7285f2049,DISK], DatanodeInfoWithStorage[127.0.0.1:42802,DS-f0a7a9f1-6aca-4edd-a2b2-60b8c32cd273,DISK], DatanodeInfoWithStorage[127.0.0.1:43083,DS-dbf7c144-ed9f-44b2-97af-85b9aa9ac7f7,DISK], DatanodeInfoWithStorage[127.0.0.1:34335,DS-a691f451-b267-49cc-a3f0-a96260a7c4ca,DISK], DatanodeInfoWithStorage[127.0.0.1:35782,DS-5a08bccf-29b3-4758-911f-7a39f1019887,DISK], DatanodeInfoWithStorage[127.0.0.1:36718,DS-aabe604f-74c7-436d-908e-05fe050aa61b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1264668377-172.17.0.4-1598429380511:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38895,DS-18a9ce99-3115-4335-8d86-9e535d9be09d,DISK], DatanodeInfoWithStorage[127.0.0.1:34473,DS-9c429037-78c5-4c0c-a8ef-8ae80fbbe39b,DISK], DatanodeInfoWithStorage[127.0.0.1:39466,DS-3fa392ba-16c4-4012-a97f-cbd7285f2049,DISK], DatanodeInfoWithStorage[127.0.0.1:42802,DS-f0a7a9f1-6aca-4edd-a2b2-60b8c32cd273,DISK], DatanodeInfoWithStorage[127.0.0.1:43083,DS-dbf7c144-ed9f-44b2-97af-85b9aa9ac7f7,DISK], DatanodeInfoWithStorage[127.0.0.1:34335,DS-a691f451-b267-49cc-a3f0-a96260a7c4ca,DISK], DatanodeInfoWithStorage[127.0.0.1:35782,DS-5a08bccf-29b3-4758-911f-7a39f1019887,DISK], DatanodeInfoWithStorage[127.0.0.1:36718,DS-aabe604f-74c7-436d-908e-05fe050aa61b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-385851004-172.17.0.4-1598429810407:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42758,DS-2e41aa56-5f8d-45e8-97b8-690961b4d4ef,DISK], DatanodeInfoWithStorage[127.0.0.1:34721,DS-74b49c80-c5dc-418e-8784-22cce3c5f872,DISK], DatanodeInfoWithStorage[127.0.0.1:34879,DS-12d64e98-3ad3-436c-90f1-1e3226f4a332,DISK], DatanodeInfoWithStorage[127.0.0.1:45890,DS-cfb6e819-a1aa-4051-8979-28b957c8282a,DISK], DatanodeInfoWithStorage[127.0.0.1:42660,DS-a7fe25e4-66eb-4a19-9cd5-776f7ec54755,DISK], DatanodeInfoWithStorage[127.0.0.1:43152,DS-0f1a3d37-1838-415d-b612-659e3c0e587e,DISK], DatanodeInfoWithStorage[127.0.0.1:46694,DS-d1489385-61e3-47a6-9b39-e97deecf7a80,DISK], DatanodeInfoWithStorage[127.0.0.1:37117,DS-aee0fe87-315c-4b4b-ad42-97932dfcb3a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-385851004-172.17.0.4-1598429810407:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42758,DS-2e41aa56-5f8d-45e8-97b8-690961b4d4ef,DISK], DatanodeInfoWithStorage[127.0.0.1:34721,DS-74b49c80-c5dc-418e-8784-22cce3c5f872,DISK], DatanodeInfoWithStorage[127.0.0.1:34879,DS-12d64e98-3ad3-436c-90f1-1e3226f4a332,DISK], DatanodeInfoWithStorage[127.0.0.1:45890,DS-cfb6e819-a1aa-4051-8979-28b957c8282a,DISK], DatanodeInfoWithStorage[127.0.0.1:42660,DS-a7fe25e4-66eb-4a19-9cd5-776f7ec54755,DISK], DatanodeInfoWithStorage[127.0.0.1:43152,DS-0f1a3d37-1838-415d-b612-659e3c0e587e,DISK], DatanodeInfoWithStorage[127.0.0.1:46694,DS-d1489385-61e3-47a6-9b39-e97deecf7a80,DISK], DatanodeInfoWithStorage[127.0.0.1:37117,DS-aee0fe87-315c-4b4b-ad42-97932dfcb3a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 2 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 5155
