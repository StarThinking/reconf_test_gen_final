reconf_parameter: dfs.datanode.block-pinning.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.block-pinning.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1567188101-172.17.0.9-1598171237078:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44406,DS-f1ecaf4a-574f-4bd5-b539-b9d10aa834af,DISK], DatanodeInfoWithStorage[127.0.0.1:45571,DS-e48af757-cb86-4f7c-b4a5-b612b06e599f,DISK], DatanodeInfoWithStorage[127.0.0.1:34424,DS-2036d459-98ec-4e19-bbfc-3d5d8a75c975,DISK], DatanodeInfoWithStorage[127.0.0.1:43940,DS-63640fdf-d3be-4ec4-8da7-05650b8f219f,DISK], DatanodeInfoWithStorage[127.0.0.1:40451,DS-d8440c53-842d-4924-bcee-622ce4a81d5a,DISK], DatanodeInfoWithStorage[127.0.0.1:42391,DS-3addecb8-7f28-45ed-bd86-f88455a8364c,DISK], DatanodeInfoWithStorage[127.0.0.1:39981,DS-1df39953-a6b1-40f4-9f0b-5da1167ea038,DISK], DatanodeInfoWithStorage[127.0.0.1:39179,DS-fb7d22ce-b833-4b12-ba45-8e1661b9c858,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1567188101-172.17.0.9-1598171237078:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44406,DS-f1ecaf4a-574f-4bd5-b539-b9d10aa834af,DISK], DatanodeInfoWithStorage[127.0.0.1:45571,DS-e48af757-cb86-4f7c-b4a5-b612b06e599f,DISK], DatanodeInfoWithStorage[127.0.0.1:34424,DS-2036d459-98ec-4e19-bbfc-3d5d8a75c975,DISK], DatanodeInfoWithStorage[127.0.0.1:43940,DS-63640fdf-d3be-4ec4-8da7-05650b8f219f,DISK], DatanodeInfoWithStorage[127.0.0.1:40451,DS-d8440c53-842d-4924-bcee-622ce4a81d5a,DISK], DatanodeInfoWithStorage[127.0.0.1:42391,DS-3addecb8-7f28-45ed-bd86-f88455a8364c,DISK], DatanodeInfoWithStorage[127.0.0.1:39981,DS-1df39953-a6b1-40f4-9f0b-5da1167ea038,DISK], DatanodeInfoWithStorage[127.0.0.1:39179,DS-fb7d22ce-b833-4b12-ba45-8e1661b9c858,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.block-pinning.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-797177483-172.17.0.9-1598171407355:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41149,DS-bf84d607-5965-4691-9970-677bf14a0f2d,DISK], DatanodeInfoWithStorage[127.0.0.1:33869,DS-39fa830c-96ef-48d3-9694-6f83c6a82039,DISK], DatanodeInfoWithStorage[127.0.0.1:38158,DS-5439e033-39af-4830-88ca-895973c8016d,DISK], DatanodeInfoWithStorage[127.0.0.1:33799,DS-396381e0-d457-44e7-b397-8e795e871bf2,DISK], DatanodeInfoWithStorage[127.0.0.1:37944,DS-14bc227b-7969-4b32-9d0e-5ed71a317c89,DISK], DatanodeInfoWithStorage[127.0.0.1:44113,DS-d38e9145-0b4a-487f-8fc3-b0ebfa42e08a,DISK], DatanodeInfoWithStorage[127.0.0.1:39854,DS-13e32846-bb31-416c-8c28-9f830da8f0ba,DISK], DatanodeInfoWithStorage[127.0.0.1:33140,DS-689b14f3-72b0-4eb3-8356-f86bec17a5cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-797177483-172.17.0.9-1598171407355:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41149,DS-bf84d607-5965-4691-9970-677bf14a0f2d,DISK], DatanodeInfoWithStorage[127.0.0.1:33869,DS-39fa830c-96ef-48d3-9694-6f83c6a82039,DISK], DatanodeInfoWithStorage[127.0.0.1:38158,DS-5439e033-39af-4830-88ca-895973c8016d,DISK], DatanodeInfoWithStorage[127.0.0.1:33799,DS-396381e0-d457-44e7-b397-8e795e871bf2,DISK], DatanodeInfoWithStorage[127.0.0.1:37944,DS-14bc227b-7969-4b32-9d0e-5ed71a317c89,DISK], DatanodeInfoWithStorage[127.0.0.1:44113,DS-d38e9145-0b4a-487f-8fc3-b0ebfa42e08a,DISK], DatanodeInfoWithStorage[127.0.0.1:39854,DS-13e32846-bb31-416c-8c28-9f830da8f0ba,DISK], DatanodeInfoWithStorage[127.0.0.1:33140,DS-689b14f3-72b0-4eb3-8356-f86bec17a5cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.block-pinning.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-16827139-172.17.0.9-1598171799215:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38466,DS-e0d06ab7-c1b3-4e1c-8a3d-521691643822,DISK], DatanodeInfoWithStorage[127.0.0.1:40441,DS-e7ff6b31-11fd-4ad4-8793-b23dfa3297b6,DISK], DatanodeInfoWithStorage[127.0.0.1:38645,DS-7e5004cc-7235-4838-8591-08656a12e536,DISK], DatanodeInfoWithStorage[127.0.0.1:45585,DS-71dad09c-6089-4aba-bf39-2639cc6847f8,DISK], DatanodeInfoWithStorage[127.0.0.1:35277,DS-d006473d-ce71-440c-8609-315ec9ff755d,DISK], DatanodeInfoWithStorage[127.0.0.1:42386,DS-fcec4691-918d-4073-8074-7d9a9153209d,DISK], DatanodeInfoWithStorage[127.0.0.1:35626,DS-87048888-37ed-4b1c-b65e-e51abd9cc020,DISK], DatanodeInfoWithStorage[127.0.0.1:36131,DS-6602abd1-cc4a-45f1-94cc-89f495b85733,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-16827139-172.17.0.9-1598171799215:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38466,DS-e0d06ab7-c1b3-4e1c-8a3d-521691643822,DISK], DatanodeInfoWithStorage[127.0.0.1:40441,DS-e7ff6b31-11fd-4ad4-8793-b23dfa3297b6,DISK], DatanodeInfoWithStorage[127.0.0.1:38645,DS-7e5004cc-7235-4838-8591-08656a12e536,DISK], DatanodeInfoWithStorage[127.0.0.1:45585,DS-71dad09c-6089-4aba-bf39-2639cc6847f8,DISK], DatanodeInfoWithStorage[127.0.0.1:35277,DS-d006473d-ce71-440c-8609-315ec9ff755d,DISK], DatanodeInfoWithStorage[127.0.0.1:42386,DS-fcec4691-918d-4073-8074-7d9a9153209d,DISK], DatanodeInfoWithStorage[127.0.0.1:35626,DS-87048888-37ed-4b1c-b65e-e51abd9cc020,DISK], DatanodeInfoWithStorage[127.0.0.1:36131,DS-6602abd1-cc4a-45f1-94cc-89f495b85733,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.block-pinning.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1923278604-172.17.0.9-1598171863672:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43895,DS-2358ee43-b04b-41cc-82f0-238f7040765a,DISK], DatanodeInfoWithStorage[127.0.0.1:32794,DS-3e04d395-b0e7-4bd1-8352-4e53085a70d5,DISK], DatanodeInfoWithStorage[127.0.0.1:41808,DS-c7e32b4a-3522-4445-9c12-30e583645c2d,DISK], DatanodeInfoWithStorage[127.0.0.1:35013,DS-79bfaff6-24b9-4bdb-b9dc-3edcb01cd487,DISK], DatanodeInfoWithStorage[127.0.0.1:35775,DS-9998ac68-bc91-4ab3-9568-5629ef6523bd,DISK], DatanodeInfoWithStorage[127.0.0.1:44354,DS-4cabcf78-b3c9-4c93-b240-46eebb9640de,DISK], DatanodeInfoWithStorage[127.0.0.1:37064,DS-4bb37120-f641-4513-9ac9-3be37b38f4b7,DISK], DatanodeInfoWithStorage[127.0.0.1:35500,DS-9f66d948-bf76-4f2f-8a69-9123e69bd475,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1923278604-172.17.0.9-1598171863672:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43895,DS-2358ee43-b04b-41cc-82f0-238f7040765a,DISK], DatanodeInfoWithStorage[127.0.0.1:32794,DS-3e04d395-b0e7-4bd1-8352-4e53085a70d5,DISK], DatanodeInfoWithStorage[127.0.0.1:41808,DS-c7e32b4a-3522-4445-9c12-30e583645c2d,DISK], DatanodeInfoWithStorage[127.0.0.1:35013,DS-79bfaff6-24b9-4bdb-b9dc-3edcb01cd487,DISK], DatanodeInfoWithStorage[127.0.0.1:35775,DS-9998ac68-bc91-4ab3-9568-5629ef6523bd,DISK], DatanodeInfoWithStorage[127.0.0.1:44354,DS-4cabcf78-b3c9-4c93-b240-46eebb9640de,DISK], DatanodeInfoWithStorage[127.0.0.1:37064,DS-4bb37120-f641-4513-9ac9-3be37b38f4b7,DISK], DatanodeInfoWithStorage[127.0.0.1:35500,DS-9f66d948-bf76-4f2f-8a69-9123e69bd475,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.block-pinning.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-627990412-172.17.0.9-1598172018197:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44000,DS-eb1a332a-470a-4a2c-8db7-b3d3a706028e,DISK], DatanodeInfoWithStorage[127.0.0.1:35746,DS-a0daa94e-c053-4d5b-87e9-0a7bb6133cd5,DISK], DatanodeInfoWithStorage[127.0.0.1:40474,DS-823188a4-5c3f-48de-81b7-ee9d25c83880,DISK], DatanodeInfoWithStorage[127.0.0.1:45162,DS-e49e4f26-13ae-4669-b77d-f11eadb3bc4b,DISK], DatanodeInfoWithStorage[127.0.0.1:37039,DS-4377266a-186f-41f6-b52a-1060fb2ffd5b,DISK], DatanodeInfoWithStorage[127.0.0.1:43365,DS-27bb4883-9cb9-47f1-bb3f-7b8d796c30f0,DISK], DatanodeInfoWithStorage[127.0.0.1:40183,DS-f7325810-adf9-4ebf-8da9-6730c6080661,DISK], DatanodeInfoWithStorage[127.0.0.1:38857,DS-00627ce4-ba29-4f2d-83a1-60beb8eba6db,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-627990412-172.17.0.9-1598172018197:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44000,DS-eb1a332a-470a-4a2c-8db7-b3d3a706028e,DISK], DatanodeInfoWithStorage[127.0.0.1:35746,DS-a0daa94e-c053-4d5b-87e9-0a7bb6133cd5,DISK], DatanodeInfoWithStorage[127.0.0.1:40474,DS-823188a4-5c3f-48de-81b7-ee9d25c83880,DISK], DatanodeInfoWithStorage[127.0.0.1:45162,DS-e49e4f26-13ae-4669-b77d-f11eadb3bc4b,DISK], DatanodeInfoWithStorage[127.0.0.1:37039,DS-4377266a-186f-41f6-b52a-1060fb2ffd5b,DISK], DatanodeInfoWithStorage[127.0.0.1:43365,DS-27bb4883-9cb9-47f1-bb3f-7b8d796c30f0,DISK], DatanodeInfoWithStorage[127.0.0.1:40183,DS-f7325810-adf9-4ebf-8da9-6730c6080661,DISK], DatanodeInfoWithStorage[127.0.0.1:38857,DS-00627ce4-ba29-4f2d-83a1-60beb8eba6db,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.block-pinning.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-959681642-172.17.0.9-1598172094146:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45028,DS-8e9a197c-3a01-472e-8a49-c8a8b00e298d,DISK], DatanodeInfoWithStorage[127.0.0.1:33000,DS-0e52c4c9-b307-4ba4-868c-18531453131d,DISK], DatanodeInfoWithStorage[127.0.0.1:46740,DS-8045826c-781d-47ac-89ec-7f1e2c0ac2c3,DISK], DatanodeInfoWithStorage[127.0.0.1:33114,DS-dde7e7d6-8caa-4cba-adad-db608cdc4ff7,DISK], DatanodeInfoWithStorage[127.0.0.1:32924,DS-b516e87c-4287-4a30-a17c-3616d8d31ef2,DISK], DatanodeInfoWithStorage[127.0.0.1:44377,DS-be57b8cb-8c32-41b2-9e3d-2c4a0782490a,DISK], DatanodeInfoWithStorage[127.0.0.1:46067,DS-a9bd1ac0-d4f4-4b42-923e-af88e34fc7a6,DISK], DatanodeInfoWithStorage[127.0.0.1:41622,DS-f6a8fcb2-99cf-476c-a93a-5e8f7ed84436,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-959681642-172.17.0.9-1598172094146:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45028,DS-8e9a197c-3a01-472e-8a49-c8a8b00e298d,DISK], DatanodeInfoWithStorage[127.0.0.1:33000,DS-0e52c4c9-b307-4ba4-868c-18531453131d,DISK], DatanodeInfoWithStorage[127.0.0.1:46740,DS-8045826c-781d-47ac-89ec-7f1e2c0ac2c3,DISK], DatanodeInfoWithStorage[127.0.0.1:33114,DS-dde7e7d6-8caa-4cba-adad-db608cdc4ff7,DISK], DatanodeInfoWithStorage[127.0.0.1:32924,DS-b516e87c-4287-4a30-a17c-3616d8d31ef2,DISK], DatanodeInfoWithStorage[127.0.0.1:44377,DS-be57b8cb-8c32-41b2-9e3d-2c4a0782490a,DISK], DatanodeInfoWithStorage[127.0.0.1:46067,DS-a9bd1ac0-d4f4-4b42-923e-af88e34fc7a6,DISK], DatanodeInfoWithStorage[127.0.0.1:41622,DS-f6a8fcb2-99cf-476c-a93a-5e8f7ed84436,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.block-pinning.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1329206038-172.17.0.9-1598172241584:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35356,DS-90cd637c-2c84-4aaa-b3da-038ab122efcc,DISK], DatanodeInfoWithStorage[127.0.0.1:38714,DS-e78d09b9-97e7-405a-a343-c831076921a9,DISK], DatanodeInfoWithStorage[127.0.0.1:43032,DS-7ea73d6b-1ba4-4ded-bcf5-3fc959bb5898,DISK], DatanodeInfoWithStorage[127.0.0.1:44139,DS-ef76c427-6370-4530-86a1-cad14886bdd4,DISK], DatanodeInfoWithStorage[127.0.0.1:36182,DS-376f4fdd-19b0-4f57-b6c9-643ff238e61b,DISK], DatanodeInfoWithStorage[127.0.0.1:34433,DS-143ed14e-809f-4385-bd95-f21febf518c4,DISK], DatanodeInfoWithStorage[127.0.0.1:45719,DS-6caf5084-b8f0-47f8-a46a-0e660d8c26b1,DISK], DatanodeInfoWithStorage[127.0.0.1:33815,DS-2c7eeac6-9ae6-464c-b1e5-2e5b77f4eddd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1329206038-172.17.0.9-1598172241584:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35356,DS-90cd637c-2c84-4aaa-b3da-038ab122efcc,DISK], DatanodeInfoWithStorage[127.0.0.1:38714,DS-e78d09b9-97e7-405a-a343-c831076921a9,DISK], DatanodeInfoWithStorage[127.0.0.1:43032,DS-7ea73d6b-1ba4-4ded-bcf5-3fc959bb5898,DISK], DatanodeInfoWithStorage[127.0.0.1:44139,DS-ef76c427-6370-4530-86a1-cad14886bdd4,DISK], DatanodeInfoWithStorage[127.0.0.1:36182,DS-376f4fdd-19b0-4f57-b6c9-643ff238e61b,DISK], DatanodeInfoWithStorage[127.0.0.1:34433,DS-143ed14e-809f-4385-bd95-f21febf518c4,DISK], DatanodeInfoWithStorage[127.0.0.1:45719,DS-6caf5084-b8f0-47f8-a46a-0e660d8c26b1,DISK], DatanodeInfoWithStorage[127.0.0.1:33815,DS-2c7eeac6-9ae6-464c-b1e5-2e5b77f4eddd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.block-pinning.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-841628708-172.17.0.9-1598172276695:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34385,DS-550030db-3268-4d40-b5b9-9ff62c211b68,DISK], DatanodeInfoWithStorage[127.0.0.1:44296,DS-04b663e4-c089-4808-b8a5-9fdeb87716ea,DISK], DatanodeInfoWithStorage[127.0.0.1:37492,DS-c487b9f8-3cde-4948-b05a-9c4c183585e0,DISK], DatanodeInfoWithStorage[127.0.0.1:40684,DS-a9f27b70-fabf-4bf3-8b31-eb9da4ea6c51,DISK], DatanodeInfoWithStorage[127.0.0.1:40490,DS-9bebfe2c-5e0d-499a-a9da-426a27e6b628,DISK], DatanodeInfoWithStorage[127.0.0.1:33739,DS-86a4f25e-7f45-4a4b-a22f-1a31ac621ecc,DISK], DatanodeInfoWithStorage[127.0.0.1:42442,DS-28a9b4a1-15d5-46f3-9c9c-b6d342ae67c5,DISK], DatanodeInfoWithStorage[127.0.0.1:44951,DS-cc5e635e-3875-4f54-9bc4-5ae505a8e94b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-841628708-172.17.0.9-1598172276695:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34385,DS-550030db-3268-4d40-b5b9-9ff62c211b68,DISK], DatanodeInfoWithStorage[127.0.0.1:44296,DS-04b663e4-c089-4808-b8a5-9fdeb87716ea,DISK], DatanodeInfoWithStorage[127.0.0.1:37492,DS-c487b9f8-3cde-4948-b05a-9c4c183585e0,DISK], DatanodeInfoWithStorage[127.0.0.1:40684,DS-a9f27b70-fabf-4bf3-8b31-eb9da4ea6c51,DISK], DatanodeInfoWithStorage[127.0.0.1:40490,DS-9bebfe2c-5e0d-499a-a9da-426a27e6b628,DISK], DatanodeInfoWithStorage[127.0.0.1:33739,DS-86a4f25e-7f45-4a4b-a22f-1a31ac621ecc,DISK], DatanodeInfoWithStorage[127.0.0.1:42442,DS-28a9b4a1-15d5-46f3-9c9c-b6d342ae67c5,DISK], DatanodeInfoWithStorage[127.0.0.1:44951,DS-cc5e635e-3875-4f54-9bc4-5ae505a8e94b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.block-pinning.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-589463886-172.17.0.9-1598172353701:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33283,DS-c0832b87-53c5-4e2a-9986-2dd9c847d7ea,DISK], DatanodeInfoWithStorage[127.0.0.1:33274,DS-c23af120-51bc-4ad9-a783-cfce8df844d5,DISK], DatanodeInfoWithStorage[127.0.0.1:35275,DS-50f0fdad-096e-4384-8d2a-3211aa545e6f,DISK], DatanodeInfoWithStorage[127.0.0.1:40999,DS-e649747b-4b91-496e-9a81-fa990f4b6153,DISK], DatanodeInfoWithStorage[127.0.0.1:38502,DS-3fefcd95-5b90-4b2f-90eb-0748e1ab5d88,DISK], DatanodeInfoWithStorage[127.0.0.1:44840,DS-47bca2f1-cfb5-4a97-9d38-c0359e11b559,DISK], DatanodeInfoWithStorage[127.0.0.1:46877,DS-f0236b13-e9b5-4680-9764-1fc258f737f4,DISK], DatanodeInfoWithStorage[127.0.0.1:42150,DS-c134354e-9196-4b24-a63d-d45ec809f097,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-589463886-172.17.0.9-1598172353701:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33283,DS-c0832b87-53c5-4e2a-9986-2dd9c847d7ea,DISK], DatanodeInfoWithStorage[127.0.0.1:33274,DS-c23af120-51bc-4ad9-a783-cfce8df844d5,DISK], DatanodeInfoWithStorage[127.0.0.1:35275,DS-50f0fdad-096e-4384-8d2a-3211aa545e6f,DISK], DatanodeInfoWithStorage[127.0.0.1:40999,DS-e649747b-4b91-496e-9a81-fa990f4b6153,DISK], DatanodeInfoWithStorage[127.0.0.1:38502,DS-3fefcd95-5b90-4b2f-90eb-0748e1ab5d88,DISK], DatanodeInfoWithStorage[127.0.0.1:44840,DS-47bca2f1-cfb5-4a97-9d38-c0359e11b559,DISK], DatanodeInfoWithStorage[127.0.0.1:46877,DS-f0236b13-e9b5-4680-9764-1fc258f737f4,DISK], DatanodeInfoWithStorage[127.0.0.1:42150,DS-c134354e-9196-4b24-a63d-d45ec809f097,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.block-pinning.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2055431206-172.17.0.9-1598172532256:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35169,DS-f3c9f421-d977-41ce-abed-caac0be46b8b,DISK], DatanodeInfoWithStorage[127.0.0.1:36474,DS-957ae9c4-8e55-41eb-803b-c04b6ce0cc9c,DISK], DatanodeInfoWithStorage[127.0.0.1:43908,DS-7849a8e5-a73f-4ff6-83f2-b995803a25ad,DISK], DatanodeInfoWithStorage[127.0.0.1:44071,DS-d8251c13-ce24-400a-805a-32398bef234e,DISK], DatanodeInfoWithStorage[127.0.0.1:37716,DS-2e246031-d568-45a2-b6f0-4fc673379597,DISK], DatanodeInfoWithStorage[127.0.0.1:36903,DS-6e0a1e7d-ba59-4efb-a960-fc5de64827c0,DISK], DatanodeInfoWithStorage[127.0.0.1:40275,DS-3413e2f2-4ca1-4012-86d3-053b990a5a2b,DISK], DatanodeInfoWithStorage[127.0.0.1:40706,DS-2c95ec02-8c3c-43df-91a7-3d6443cf3e55,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2055431206-172.17.0.9-1598172532256:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35169,DS-f3c9f421-d977-41ce-abed-caac0be46b8b,DISK], DatanodeInfoWithStorage[127.0.0.1:36474,DS-957ae9c4-8e55-41eb-803b-c04b6ce0cc9c,DISK], DatanodeInfoWithStorage[127.0.0.1:43908,DS-7849a8e5-a73f-4ff6-83f2-b995803a25ad,DISK], DatanodeInfoWithStorage[127.0.0.1:44071,DS-d8251c13-ce24-400a-805a-32398bef234e,DISK], DatanodeInfoWithStorage[127.0.0.1:37716,DS-2e246031-d568-45a2-b6f0-4fc673379597,DISK], DatanodeInfoWithStorage[127.0.0.1:36903,DS-6e0a1e7d-ba59-4efb-a960-fc5de64827c0,DISK], DatanodeInfoWithStorage[127.0.0.1:40275,DS-3413e2f2-4ca1-4012-86d3-053b990a5a2b,DISK], DatanodeInfoWithStorage[127.0.0.1:40706,DS-2c95ec02-8c3c-43df-91a7-3d6443cf3e55,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.block-pinning.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-918531134-172.17.0.9-1598172601012:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43390,DS-fc94172b-c7ea-498b-ba08-af012fc7b165,DISK], DatanodeInfoWithStorage[127.0.0.1:35416,DS-074f82df-aae7-45ce-8aa5-907139f9dafd,DISK], DatanodeInfoWithStorage[127.0.0.1:43615,DS-7374b93d-ba87-44d1-8e4b-65d693ccb015,DISK], DatanodeInfoWithStorage[127.0.0.1:45340,DS-b8b219be-8666-4846-955b-a9810a6fc8ed,DISK], DatanodeInfoWithStorage[127.0.0.1:43577,DS-5a958d46-d4be-4466-b9fe-b09ea56052d8,DISK], DatanodeInfoWithStorage[127.0.0.1:43094,DS-7b9c5617-a0be-458d-88b8-ec5d341b7765,DISK], DatanodeInfoWithStorage[127.0.0.1:33408,DS-67ae9fd0-12b1-480d-aa8b-082535888c4e,DISK], DatanodeInfoWithStorage[127.0.0.1:36598,DS-ee3cfe19-c4ad-4f8e-802f-a5af96ccd0c5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-918531134-172.17.0.9-1598172601012:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43390,DS-fc94172b-c7ea-498b-ba08-af012fc7b165,DISK], DatanodeInfoWithStorage[127.0.0.1:35416,DS-074f82df-aae7-45ce-8aa5-907139f9dafd,DISK], DatanodeInfoWithStorage[127.0.0.1:43615,DS-7374b93d-ba87-44d1-8e4b-65d693ccb015,DISK], DatanodeInfoWithStorage[127.0.0.1:45340,DS-b8b219be-8666-4846-955b-a9810a6fc8ed,DISK], DatanodeInfoWithStorage[127.0.0.1:43577,DS-5a958d46-d4be-4466-b9fe-b09ea56052d8,DISK], DatanodeInfoWithStorage[127.0.0.1:43094,DS-7b9c5617-a0be-458d-88b8-ec5d341b7765,DISK], DatanodeInfoWithStorage[127.0.0.1:33408,DS-67ae9fd0-12b1-480d-aa8b-082535888c4e,DISK], DatanodeInfoWithStorage[127.0.0.1:36598,DS-ee3cfe19-c4ad-4f8e-802f-a5af96ccd0c5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.block-pinning.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1410581309-172.17.0.9-1598172715871:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35325,DS-5136eee8-522d-45a0-9634-b664bbd59940,DISK], DatanodeInfoWithStorage[127.0.0.1:37692,DS-6dd92e47-a945-4c98-9876-e5f59123ccae,DISK], DatanodeInfoWithStorage[127.0.0.1:34369,DS-3c840318-1f52-401a-89c1-90751d548aa0,DISK], DatanodeInfoWithStorage[127.0.0.1:42122,DS-202a71d2-f587-45b1-bde4-0bfabf779578,DISK], DatanodeInfoWithStorage[127.0.0.1:39392,DS-872c0994-ac67-4eb8-9504-a5328a62a870,DISK], DatanodeInfoWithStorage[127.0.0.1:39561,DS-6adc36fa-b421-4de3-8ab2-39a44692abd7,DISK], DatanodeInfoWithStorage[127.0.0.1:41514,DS-9487d25a-f81f-484f-9822-fa824f5bbd40,DISK], DatanodeInfoWithStorage[127.0.0.1:40711,DS-929968ff-64e4-426d-9a63-9a07369954b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1410581309-172.17.0.9-1598172715871:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35325,DS-5136eee8-522d-45a0-9634-b664bbd59940,DISK], DatanodeInfoWithStorage[127.0.0.1:37692,DS-6dd92e47-a945-4c98-9876-e5f59123ccae,DISK], DatanodeInfoWithStorage[127.0.0.1:34369,DS-3c840318-1f52-401a-89c1-90751d548aa0,DISK], DatanodeInfoWithStorage[127.0.0.1:42122,DS-202a71d2-f587-45b1-bde4-0bfabf779578,DISK], DatanodeInfoWithStorage[127.0.0.1:39392,DS-872c0994-ac67-4eb8-9504-a5328a62a870,DISK], DatanodeInfoWithStorage[127.0.0.1:39561,DS-6adc36fa-b421-4de3-8ab2-39a44692abd7,DISK], DatanodeInfoWithStorage[127.0.0.1:41514,DS-9487d25a-f81f-484f-9822-fa824f5bbd40,DISK], DatanodeInfoWithStorage[127.0.0.1:40711,DS-929968ff-64e4-426d-9a63-9a07369954b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.block-pinning.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-359551823-172.17.0.9-1598172823316:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42180,DS-fe7f1832-dc21-44ea-9365-efc141fccfe3,DISK], DatanodeInfoWithStorage[127.0.0.1:38347,DS-36b5305c-8dad-4670-ae39-d5ef7a5d8265,DISK], DatanodeInfoWithStorage[127.0.0.1:39039,DS-f70ad3a4-1187-4659-b1c4-4c1c34d605c6,DISK], DatanodeInfoWithStorage[127.0.0.1:43700,DS-7cfe0ad9-6544-4304-acf0-10a4e738daf1,DISK], DatanodeInfoWithStorage[127.0.0.1:41932,DS-69f6a434-7fc6-4654-9c8b-0d48cb175596,DISK], DatanodeInfoWithStorage[127.0.0.1:32845,DS-85bc779a-f200-4683-8ad8-0ae8e1cbdf00,DISK], DatanodeInfoWithStorage[127.0.0.1:41460,DS-d1915d29-02ff-417b-b799-09daea5bb492,DISK], DatanodeInfoWithStorage[127.0.0.1:40173,DS-5cf7dc25-96c0-4f34-b068-f2f7dce7ec76,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-359551823-172.17.0.9-1598172823316:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42180,DS-fe7f1832-dc21-44ea-9365-efc141fccfe3,DISK], DatanodeInfoWithStorage[127.0.0.1:38347,DS-36b5305c-8dad-4670-ae39-d5ef7a5d8265,DISK], DatanodeInfoWithStorage[127.0.0.1:39039,DS-f70ad3a4-1187-4659-b1c4-4c1c34d605c6,DISK], DatanodeInfoWithStorage[127.0.0.1:43700,DS-7cfe0ad9-6544-4304-acf0-10a4e738daf1,DISK], DatanodeInfoWithStorage[127.0.0.1:41932,DS-69f6a434-7fc6-4654-9c8b-0d48cb175596,DISK], DatanodeInfoWithStorage[127.0.0.1:32845,DS-85bc779a-f200-4683-8ad8-0ae8e1cbdf00,DISK], DatanodeInfoWithStorage[127.0.0.1:41460,DS-d1915d29-02ff-417b-b799-09daea5bb492,DISK], DatanodeInfoWithStorage[127.0.0.1:40173,DS-5cf7dc25-96c0-4f34-b068-f2f7dce7ec76,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.block-pinning.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1320587336-172.17.0.9-1598173025504:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38626,DS-1e720077-9d9d-4417-813c-7e96a7f0a8f4,DISK], DatanodeInfoWithStorage[127.0.0.1:41399,DS-d76d475f-2126-43ac-96b5-8a8ec65b6545,DISK], DatanodeInfoWithStorage[127.0.0.1:33099,DS-e3bf78e4-5701-429f-be14-14ff48df5790,DISK], DatanodeInfoWithStorage[127.0.0.1:36637,DS-6714cc08-7559-45af-80a9-71fb5fbfa70f,DISK], DatanodeInfoWithStorage[127.0.0.1:40626,DS-db4e81fb-0687-4e01-b2a2-1b0c7cdab3e3,DISK], DatanodeInfoWithStorage[127.0.0.1:41089,DS-97296b42-ba38-4888-b8a6-41f7ff760da1,DISK], DatanodeInfoWithStorage[127.0.0.1:45858,DS-ab3c6851-64da-47b8-a6c7-c52b082fed68,DISK], DatanodeInfoWithStorage[127.0.0.1:34284,DS-541ca42f-d77b-4878-90a0-73d0a1986f91,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1320587336-172.17.0.9-1598173025504:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38626,DS-1e720077-9d9d-4417-813c-7e96a7f0a8f4,DISK], DatanodeInfoWithStorage[127.0.0.1:41399,DS-d76d475f-2126-43ac-96b5-8a8ec65b6545,DISK], DatanodeInfoWithStorage[127.0.0.1:33099,DS-e3bf78e4-5701-429f-be14-14ff48df5790,DISK], DatanodeInfoWithStorage[127.0.0.1:36637,DS-6714cc08-7559-45af-80a9-71fb5fbfa70f,DISK], DatanodeInfoWithStorage[127.0.0.1:40626,DS-db4e81fb-0687-4e01-b2a2-1b0c7cdab3e3,DISK], DatanodeInfoWithStorage[127.0.0.1:41089,DS-97296b42-ba38-4888-b8a6-41f7ff760da1,DISK], DatanodeInfoWithStorage[127.0.0.1:45858,DS-ab3c6851-64da-47b8-a6c7-c52b082fed68,DISK], DatanodeInfoWithStorage[127.0.0.1:34284,DS-541ca42f-d77b-4878-90a0-73d0a1986f91,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.block-pinning.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1824846494-172.17.0.9-1598173358328:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41692,DS-81bbe279-9cdf-463c-a7ef-b5c96cf84514,DISK], DatanodeInfoWithStorage[127.0.0.1:46729,DS-5bd9a21f-9425-4dd2-8c22-807da11d897f,DISK], DatanodeInfoWithStorage[127.0.0.1:38538,DS-9939398e-338d-49ab-9c10-ebbf67943060,DISK], DatanodeInfoWithStorage[127.0.0.1:38988,DS-8246e29a-28a9-43cf-81e3-87409733d1ec,DISK], DatanodeInfoWithStorage[127.0.0.1:33763,DS-83c95496-d283-48bc-a1c2-7b3741e3b1da,DISK], DatanodeInfoWithStorage[127.0.0.1:41985,DS-f772b616-6786-46a2-885c-cc58b1f58730,DISK], DatanodeInfoWithStorage[127.0.0.1:36138,DS-6bc8c513-9909-42a3-ad67-1abddd683368,DISK], DatanodeInfoWithStorage[127.0.0.1:34889,DS-4e812571-ec63-4516-b9a5-2843f13e629b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1824846494-172.17.0.9-1598173358328:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41692,DS-81bbe279-9cdf-463c-a7ef-b5c96cf84514,DISK], DatanodeInfoWithStorage[127.0.0.1:46729,DS-5bd9a21f-9425-4dd2-8c22-807da11d897f,DISK], DatanodeInfoWithStorage[127.0.0.1:38538,DS-9939398e-338d-49ab-9c10-ebbf67943060,DISK], DatanodeInfoWithStorage[127.0.0.1:38988,DS-8246e29a-28a9-43cf-81e3-87409733d1ec,DISK], DatanodeInfoWithStorage[127.0.0.1:33763,DS-83c95496-d283-48bc-a1c2-7b3741e3b1da,DISK], DatanodeInfoWithStorage[127.0.0.1:41985,DS-f772b616-6786-46a2-885c-cc58b1f58730,DISK], DatanodeInfoWithStorage[127.0.0.1:36138,DS-6bc8c513-9909-42a3-ad67-1abddd683368,DISK], DatanodeInfoWithStorage[127.0.0.1:34889,DS-4e812571-ec63-4516-b9a5-2843f13e629b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.block-pinning.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-619044307-172.17.0.9-1598173394154:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41048,DS-75cace18-1131-4462-88dd-9cba773c564e,DISK], DatanodeInfoWithStorage[127.0.0.1:45666,DS-d81277c1-13d0-4c14-8825-9e62d6ce2ae9,DISK], DatanodeInfoWithStorage[127.0.0.1:40354,DS-3a98cc57-463a-41d1-96f1-782a9cec05c6,DISK], DatanodeInfoWithStorage[127.0.0.1:46248,DS-7eb7d5e5-3dbc-47c6-8207-bade89b3cb39,DISK], DatanodeInfoWithStorage[127.0.0.1:36780,DS-fdac0d72-01f9-4838-885e-a98c8f40df49,DISK], DatanodeInfoWithStorage[127.0.0.1:44943,DS-41b7d883-c73b-4e97-ae79-5adea2a9cf04,DISK], DatanodeInfoWithStorage[127.0.0.1:39968,DS-629f37ea-df6a-4834-a0da-33c319f70346,DISK], DatanodeInfoWithStorage[127.0.0.1:37213,DS-7e896eb1-285f-43d6-bc8e-247abcf9193e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-619044307-172.17.0.9-1598173394154:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41048,DS-75cace18-1131-4462-88dd-9cba773c564e,DISK], DatanodeInfoWithStorage[127.0.0.1:45666,DS-d81277c1-13d0-4c14-8825-9e62d6ce2ae9,DISK], DatanodeInfoWithStorage[127.0.0.1:40354,DS-3a98cc57-463a-41d1-96f1-782a9cec05c6,DISK], DatanodeInfoWithStorage[127.0.0.1:46248,DS-7eb7d5e5-3dbc-47c6-8207-bade89b3cb39,DISK], DatanodeInfoWithStorage[127.0.0.1:36780,DS-fdac0d72-01f9-4838-885e-a98c8f40df49,DISK], DatanodeInfoWithStorage[127.0.0.1:44943,DS-41b7d883-c73b-4e97-ae79-5adea2a9cf04,DISK], DatanodeInfoWithStorage[127.0.0.1:39968,DS-629f37ea-df6a-4834-a0da-33c319f70346,DISK], DatanodeInfoWithStorage[127.0.0.1:37213,DS-7e896eb1-285f-43d6-bc8e-247abcf9193e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.block-pinning.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-811219561-172.17.0.9-1598173596205:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43950,DS-f24410a8-9fb6-45dd-8501-87dc9bfe2e74,DISK], DatanodeInfoWithStorage[127.0.0.1:33358,DS-e39aa9dd-3710-463f-81a9-d816802257dc,DISK], DatanodeInfoWithStorage[127.0.0.1:42384,DS-da250705-c031-4f8e-9c64-f2e8d5808024,DISK], DatanodeInfoWithStorage[127.0.0.1:41793,DS-f116d297-2bf7-41d7-bf66-4bf773714f9e,DISK], DatanodeInfoWithStorage[127.0.0.1:46281,DS-fcae1e7b-3888-4a27-b343-1f01c84e3cf4,DISK], DatanodeInfoWithStorage[127.0.0.1:43539,DS-f11b01fd-753d-4471-a9e7-ef8bb1f102ae,DISK], DatanodeInfoWithStorage[127.0.0.1:34761,DS-38491721-b33e-4b17-a048-758a9cc305d1,DISK], DatanodeInfoWithStorage[127.0.0.1:46645,DS-89df8b6f-acfd-4483-8a56-39273eee4419,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-811219561-172.17.0.9-1598173596205:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43950,DS-f24410a8-9fb6-45dd-8501-87dc9bfe2e74,DISK], DatanodeInfoWithStorage[127.0.0.1:33358,DS-e39aa9dd-3710-463f-81a9-d816802257dc,DISK], DatanodeInfoWithStorage[127.0.0.1:42384,DS-da250705-c031-4f8e-9c64-f2e8d5808024,DISK], DatanodeInfoWithStorage[127.0.0.1:41793,DS-f116d297-2bf7-41d7-bf66-4bf773714f9e,DISK], DatanodeInfoWithStorage[127.0.0.1:46281,DS-fcae1e7b-3888-4a27-b343-1f01c84e3cf4,DISK], DatanodeInfoWithStorage[127.0.0.1:43539,DS-f11b01fd-753d-4471-a9e7-ef8bb1f102ae,DISK], DatanodeInfoWithStorage[127.0.0.1:34761,DS-38491721-b33e-4b17-a048-758a9cc305d1,DISK], DatanodeInfoWithStorage[127.0.0.1:46645,DS-89df8b6f-acfd-4483-8a56-39273eee4419,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.block-pinning.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2123365915-172.17.0.9-1598173999599:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42722,DS-f79363ee-0e11-437e-991b-ccb4d29cc12f,DISK], DatanodeInfoWithStorage[127.0.0.1:43274,DS-b22491a0-2d6e-4442-bc83-bf179b154e96,DISK], DatanodeInfoWithStorage[127.0.0.1:42335,DS-e2578ad2-f1ef-45e4-ba4f-d62dad42cb6d,DISK], DatanodeInfoWithStorage[127.0.0.1:33826,DS-6097ea97-46be-44e1-a685-5052b37a90a7,DISK], DatanodeInfoWithStorage[127.0.0.1:41564,DS-50d98f01-7c31-470e-8888-c875693d4bfc,DISK], DatanodeInfoWithStorage[127.0.0.1:45897,DS-5b6d4bb7-c210-4e4c-a70b-0ac3c6b6a8e9,DISK], DatanodeInfoWithStorage[127.0.0.1:33183,DS-10ff257c-7622-47b2-b598-6a539a34a042,DISK], DatanodeInfoWithStorage[127.0.0.1:35623,DS-7728f090-cf32-49c1-9851-ea48b8223d15,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2123365915-172.17.0.9-1598173999599:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42722,DS-f79363ee-0e11-437e-991b-ccb4d29cc12f,DISK], DatanodeInfoWithStorage[127.0.0.1:43274,DS-b22491a0-2d6e-4442-bc83-bf179b154e96,DISK], DatanodeInfoWithStorage[127.0.0.1:42335,DS-e2578ad2-f1ef-45e4-ba4f-d62dad42cb6d,DISK], DatanodeInfoWithStorage[127.0.0.1:33826,DS-6097ea97-46be-44e1-a685-5052b37a90a7,DISK], DatanodeInfoWithStorage[127.0.0.1:41564,DS-50d98f01-7c31-470e-8888-c875693d4bfc,DISK], DatanodeInfoWithStorage[127.0.0.1:45897,DS-5b6d4bb7-c210-4e4c-a70b-0ac3c6b6a8e9,DISK], DatanodeInfoWithStorage[127.0.0.1:33183,DS-10ff257c-7622-47b2-b598-6a539a34a042,DISK], DatanodeInfoWithStorage[127.0.0.1:35623,DS-7728f090-cf32-49c1-9851-ea48b8223d15,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.block-pinning.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-148825596-172.17.0.9-1598174215696:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43531,DS-27bf6fe8-7c77-470d-b24c-5d176380e319,DISK], DatanodeInfoWithStorage[127.0.0.1:38323,DS-0cf91a2c-e1fd-44b7-8aac-524d9affd16e,DISK], DatanodeInfoWithStorage[127.0.0.1:41973,DS-d56e6945-f9cc-48c6-a6cb-06b6ed8b9cdd,DISK], DatanodeInfoWithStorage[127.0.0.1:43143,DS-9e34615a-551e-4ae6-9282-ca380b2dda42,DISK], DatanodeInfoWithStorage[127.0.0.1:37581,DS-4ec50175-d456-45ed-9977-c996be14a3d7,DISK], DatanodeInfoWithStorage[127.0.0.1:34997,DS-e32efc9d-0010-491f-93ab-dafc367a0bc3,DISK], DatanodeInfoWithStorage[127.0.0.1:37792,DS-9816d0cd-acc4-4ccd-bcce-e750c7bf8e9c,DISK], DatanodeInfoWithStorage[127.0.0.1:36830,DS-0a71a1c5-1c98-4435-a8cd-dffe4f4f6b55,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-148825596-172.17.0.9-1598174215696:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43531,DS-27bf6fe8-7c77-470d-b24c-5d176380e319,DISK], DatanodeInfoWithStorage[127.0.0.1:38323,DS-0cf91a2c-e1fd-44b7-8aac-524d9affd16e,DISK], DatanodeInfoWithStorage[127.0.0.1:41973,DS-d56e6945-f9cc-48c6-a6cb-06b6ed8b9cdd,DISK], DatanodeInfoWithStorage[127.0.0.1:43143,DS-9e34615a-551e-4ae6-9282-ca380b2dda42,DISK], DatanodeInfoWithStorage[127.0.0.1:37581,DS-4ec50175-d456-45ed-9977-c996be14a3d7,DISK], DatanodeInfoWithStorage[127.0.0.1:34997,DS-e32efc9d-0010-491f-93ab-dafc367a0bc3,DISK], DatanodeInfoWithStorage[127.0.0.1:37792,DS-9816d0cd-acc4-4ccd-bcce-e750c7bf8e9c,DISK], DatanodeInfoWithStorage[127.0.0.1:36830,DS-0a71a1c5-1c98-4435-a8cd-dffe4f4f6b55,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.block-pinning.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1050442748-172.17.0.9-1598174986206:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37744,DS-219edeb9-7d77-40a2-89b1-20442319ca95,DISK], DatanodeInfoWithStorage[127.0.0.1:35815,DS-0e012bd3-5ab4-401d-a638-8f218c043c5c,DISK], DatanodeInfoWithStorage[127.0.0.1:46069,DS-0eb59271-153b-4afe-8381-ca67d9295f80,DISK], DatanodeInfoWithStorage[127.0.0.1:35516,DS-7f5f76ad-21ad-4f4b-b8ee-ba74b37381fa,DISK], DatanodeInfoWithStorage[127.0.0.1:33067,DS-13fbf6da-f691-4c1d-ab02-d1af102fd67b,DISK], DatanodeInfoWithStorage[127.0.0.1:38965,DS-5f04b10f-cb7f-45e1-9a56-ccd63e0430cc,DISK], DatanodeInfoWithStorage[127.0.0.1:33256,DS-bb79ff41-246e-4369-a0b9-6ec4c3b6c16d,DISK], DatanodeInfoWithStorage[127.0.0.1:35953,DS-6885642c-7705-4fc4-8e7f-095424dd7ef2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1050442748-172.17.0.9-1598174986206:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37744,DS-219edeb9-7d77-40a2-89b1-20442319ca95,DISK], DatanodeInfoWithStorage[127.0.0.1:35815,DS-0e012bd3-5ab4-401d-a638-8f218c043c5c,DISK], DatanodeInfoWithStorage[127.0.0.1:46069,DS-0eb59271-153b-4afe-8381-ca67d9295f80,DISK], DatanodeInfoWithStorage[127.0.0.1:35516,DS-7f5f76ad-21ad-4f4b-b8ee-ba74b37381fa,DISK], DatanodeInfoWithStorage[127.0.0.1:33067,DS-13fbf6da-f691-4c1d-ab02-d1af102fd67b,DISK], DatanodeInfoWithStorage[127.0.0.1:38965,DS-5f04b10f-cb7f-45e1-9a56-ccd63e0430cc,DISK], DatanodeInfoWithStorage[127.0.0.1:33256,DS-bb79ff41-246e-4369-a0b9-6ec4c3b6c16d,DISK], DatanodeInfoWithStorage[127.0.0.1:35953,DS-6885642c-7705-4fc4-8e7f-095424dd7ef2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.block-pinning.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2057319747-172.17.0.9-1598175021920:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44250,DS-65a72f77-7fd5-42af-b24d-13b83cea100b,DISK], DatanodeInfoWithStorage[127.0.0.1:34298,DS-bc96562c-fbd3-481f-890e-75563d11ebbc,DISK], DatanodeInfoWithStorage[127.0.0.1:40103,DS-62b18672-2413-450b-b5a1-1d3c71e10dce,DISK], DatanodeInfoWithStorage[127.0.0.1:42040,DS-4a683382-3857-46d5-a4a4-66be1b0caefa,DISK], DatanodeInfoWithStorage[127.0.0.1:43113,DS-2998f34d-a591-429e-8372-e8fd23ce8e9d,DISK], DatanodeInfoWithStorage[127.0.0.1:33017,DS-2463239c-b837-422c-b194-24ff0680ce00,DISK], DatanodeInfoWithStorage[127.0.0.1:37746,DS-4d6d5131-ad1d-4a1a-9d61-fbe372c7262c,DISK], DatanodeInfoWithStorage[127.0.0.1:43977,DS-48057695-bf5c-4a26-9f04-1d00ce52dbeb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2057319747-172.17.0.9-1598175021920:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44250,DS-65a72f77-7fd5-42af-b24d-13b83cea100b,DISK], DatanodeInfoWithStorage[127.0.0.1:34298,DS-bc96562c-fbd3-481f-890e-75563d11ebbc,DISK], DatanodeInfoWithStorage[127.0.0.1:40103,DS-62b18672-2413-450b-b5a1-1d3c71e10dce,DISK], DatanodeInfoWithStorage[127.0.0.1:42040,DS-4a683382-3857-46d5-a4a4-66be1b0caefa,DISK], DatanodeInfoWithStorage[127.0.0.1:43113,DS-2998f34d-a591-429e-8372-e8fd23ce8e9d,DISK], DatanodeInfoWithStorage[127.0.0.1:33017,DS-2463239c-b837-422c-b194-24ff0680ce00,DISK], DatanodeInfoWithStorage[127.0.0.1:37746,DS-4d6d5131-ad1d-4a1a-9d61-fbe372c7262c,DISK], DatanodeInfoWithStorage[127.0.0.1:43977,DS-48057695-bf5c-4a26-9f04-1d00ce52dbeb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.block-pinning.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-334461000-172.17.0.9-1598175168136:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46149,DS-b126afd4-1872-4b61-9b7e-b98f66be4198,DISK], DatanodeInfoWithStorage[127.0.0.1:43093,DS-a8049161-e1e4-4551-a7ae-1b701e29fea9,DISK], DatanodeInfoWithStorage[127.0.0.1:39706,DS-78372464-6ab3-4c52-8e0b-6af49c9055c7,DISK], DatanodeInfoWithStorage[127.0.0.1:40889,DS-89e22ffa-553b-44e5-b31a-3073575eed5c,DISK], DatanodeInfoWithStorage[127.0.0.1:42938,DS-bb77047d-f6c9-4257-8dcb-4fe58282eec2,DISK], DatanodeInfoWithStorage[127.0.0.1:42797,DS-826793df-8918-41fb-9784-30e35fab5951,DISK], DatanodeInfoWithStorage[127.0.0.1:34792,DS-19764414-c5c8-42a0-9acd-d612aa48066b,DISK], DatanodeInfoWithStorage[127.0.0.1:36866,DS-d360e5e9-a72f-4118-9cc2-2af8c53fe1d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-334461000-172.17.0.9-1598175168136:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46149,DS-b126afd4-1872-4b61-9b7e-b98f66be4198,DISK], DatanodeInfoWithStorage[127.0.0.1:43093,DS-a8049161-e1e4-4551-a7ae-1b701e29fea9,DISK], DatanodeInfoWithStorage[127.0.0.1:39706,DS-78372464-6ab3-4c52-8e0b-6af49c9055c7,DISK], DatanodeInfoWithStorage[127.0.0.1:40889,DS-89e22ffa-553b-44e5-b31a-3073575eed5c,DISK], DatanodeInfoWithStorage[127.0.0.1:42938,DS-bb77047d-f6c9-4257-8dcb-4fe58282eec2,DISK], DatanodeInfoWithStorage[127.0.0.1:42797,DS-826793df-8918-41fb-9784-30e35fab5951,DISK], DatanodeInfoWithStorage[127.0.0.1:34792,DS-19764414-c5c8-42a0-9acd-d612aa48066b,DISK], DatanodeInfoWithStorage[127.0.0.1:36866,DS-d360e5e9-a72f-4118-9cc2-2af8c53fe1d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.block-pinning.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-915085795-172.17.0.9-1598175208639:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43326,DS-5ca2cb71-3251-414c-93e4-5c6764664877,DISK], DatanodeInfoWithStorage[127.0.0.1:42660,DS-b8aceba1-73b8-482e-a01c-c50f49af97de,DISK], DatanodeInfoWithStorage[127.0.0.1:45200,DS-4d6243a2-9866-4762-beb6-e23e705dd7da,DISK], DatanodeInfoWithStorage[127.0.0.1:33085,DS-b46ac588-8533-4b4c-aaea-93ea864c8ac3,DISK], DatanodeInfoWithStorage[127.0.0.1:45904,DS-9153ea1c-1a72-4086-8a5d-fed4ae9e91a6,DISK], DatanodeInfoWithStorage[127.0.0.1:33843,DS-6e85eead-2ca9-4360-a314-f2d10d775110,DISK], DatanodeInfoWithStorage[127.0.0.1:34780,DS-1c072fce-729c-45d7-b336-c7dd57e59b7d,DISK], DatanodeInfoWithStorage[127.0.0.1:45240,DS-43d99638-ef5e-49a3-ae50-16bb58459519,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-915085795-172.17.0.9-1598175208639:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43326,DS-5ca2cb71-3251-414c-93e4-5c6764664877,DISK], DatanodeInfoWithStorage[127.0.0.1:42660,DS-b8aceba1-73b8-482e-a01c-c50f49af97de,DISK], DatanodeInfoWithStorage[127.0.0.1:45200,DS-4d6243a2-9866-4762-beb6-e23e705dd7da,DISK], DatanodeInfoWithStorage[127.0.0.1:33085,DS-b46ac588-8533-4b4c-aaea-93ea864c8ac3,DISK], DatanodeInfoWithStorage[127.0.0.1:45904,DS-9153ea1c-1a72-4086-8a5d-fed4ae9e91a6,DISK], DatanodeInfoWithStorage[127.0.0.1:33843,DS-6e85eead-2ca9-4360-a314-f2d10d775110,DISK], DatanodeInfoWithStorage[127.0.0.1:34780,DS-1c072fce-729c-45d7-b336-c7dd57e59b7d,DISK], DatanodeInfoWithStorage[127.0.0.1:45240,DS-43d99638-ef5e-49a3-ae50-16bb58459519,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.block-pinning.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1114142644-172.17.0.9-1598175250313:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32811,DS-3101f0d8-5afc-4e1f-8d79-45249e5f28ff,DISK], DatanodeInfoWithStorage[127.0.0.1:40928,DS-072a6db9-4795-4d04-b591-fb1280be0975,DISK], DatanodeInfoWithStorage[127.0.0.1:37336,DS-27c6e32d-2822-4bca-a753-024490bfd047,DISK], DatanodeInfoWithStorage[127.0.0.1:39461,DS-b51748ae-555c-462a-a0a7-b5feed79e5f1,DISK], DatanodeInfoWithStorage[127.0.0.1:43497,DS-e0ba1de5-19b4-4b30-a052-caf6cbb0712a,DISK], DatanodeInfoWithStorage[127.0.0.1:43668,DS-423e9652-f51a-42a0-ab0c-22eba87e63bf,DISK], DatanodeInfoWithStorage[127.0.0.1:46460,DS-30dfc66a-87a3-4e6a-94ad-7b011ff36c3a,DISK], DatanodeInfoWithStorage[127.0.0.1:35443,DS-93c09808-4817-4037-b623-140a29f6d985,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1114142644-172.17.0.9-1598175250313:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32811,DS-3101f0d8-5afc-4e1f-8d79-45249e5f28ff,DISK], DatanodeInfoWithStorage[127.0.0.1:40928,DS-072a6db9-4795-4d04-b591-fb1280be0975,DISK], DatanodeInfoWithStorage[127.0.0.1:37336,DS-27c6e32d-2822-4bca-a753-024490bfd047,DISK], DatanodeInfoWithStorage[127.0.0.1:39461,DS-b51748ae-555c-462a-a0a7-b5feed79e5f1,DISK], DatanodeInfoWithStorage[127.0.0.1:43497,DS-e0ba1de5-19b4-4b30-a052-caf6cbb0712a,DISK], DatanodeInfoWithStorage[127.0.0.1:43668,DS-423e9652-f51a-42a0-ab0c-22eba87e63bf,DISK], DatanodeInfoWithStorage[127.0.0.1:46460,DS-30dfc66a-87a3-4e6a-94ad-7b011ff36c3a,DISK], DatanodeInfoWithStorage[127.0.0.1:35443,DS-93c09808-4817-4037-b623-140a29f6d985,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.block-pinning.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-205653840-172.17.0.9-1598175748251:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39724,DS-9e673b66-fb88-4c9c-abc5-2ac8df0fb4ef,DISK], DatanodeInfoWithStorage[127.0.0.1:42155,DS-558249c7-90fc-4f86-a094-82a4f325cea7,DISK], DatanodeInfoWithStorage[127.0.0.1:34173,DS-b4c5493e-75a4-48da-b6b7-4dd5600d1d5f,DISK], DatanodeInfoWithStorage[127.0.0.1:38539,DS-ac5d84a5-25c2-43c1-af66-241cb14bebce,DISK], DatanodeInfoWithStorage[127.0.0.1:46676,DS-41e693b2-c345-4574-bf6b-a953cecb0bd8,DISK], DatanodeInfoWithStorage[127.0.0.1:34651,DS-08f2922a-6c4e-426c-9697-69a0ad226860,DISK], DatanodeInfoWithStorage[127.0.0.1:46657,DS-19d4c4b4-616b-4baa-ad21-bc9e70eb06f2,DISK], DatanodeInfoWithStorage[127.0.0.1:43113,DS-2ecb0c68-34c9-41e3-b85e-b7302326961a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-205653840-172.17.0.9-1598175748251:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39724,DS-9e673b66-fb88-4c9c-abc5-2ac8df0fb4ef,DISK], DatanodeInfoWithStorage[127.0.0.1:42155,DS-558249c7-90fc-4f86-a094-82a4f325cea7,DISK], DatanodeInfoWithStorage[127.0.0.1:34173,DS-b4c5493e-75a4-48da-b6b7-4dd5600d1d5f,DISK], DatanodeInfoWithStorage[127.0.0.1:38539,DS-ac5d84a5-25c2-43c1-af66-241cb14bebce,DISK], DatanodeInfoWithStorage[127.0.0.1:46676,DS-41e693b2-c345-4574-bf6b-a953cecb0bd8,DISK], DatanodeInfoWithStorage[127.0.0.1:34651,DS-08f2922a-6c4e-426c-9697-69a0ad226860,DISK], DatanodeInfoWithStorage[127.0.0.1:46657,DS-19d4c4b4-616b-4baa-ad21-bc9e70eb06f2,DISK], DatanodeInfoWithStorage[127.0.0.1:43113,DS-2ecb0c68-34c9-41e3-b85e-b7302326961a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.block-pinning.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1862301654-172.17.0.9-1598175974495:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38840,DS-b2ea9d53-7ba9-4400-aa32-81e7e4584826,DISK], DatanodeInfoWithStorage[127.0.0.1:35499,DS-2d998e30-fc96-48dd-8e44-cb092b851565,DISK], DatanodeInfoWithStorage[127.0.0.1:42378,DS-49976e74-69cf-4d10-b58a-11811d12a2dd,DISK], DatanodeInfoWithStorage[127.0.0.1:40181,DS-38da42cc-bcef-4028-9798-36d1238e94c7,DISK], DatanodeInfoWithStorage[127.0.0.1:36293,DS-74a90890-8254-4561-be74-69b94bf743b2,DISK], DatanodeInfoWithStorage[127.0.0.1:36263,DS-655b9ab2-d218-45c1-a56d-b8d6ac767512,DISK], DatanodeInfoWithStorage[127.0.0.1:42318,DS-ff25105d-e9d6-4921-b4ab-2b582eb13875,DISK], DatanodeInfoWithStorage[127.0.0.1:42844,DS-b0c8fbb3-cea1-4a3d-85c8-29ee1b9312a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1862301654-172.17.0.9-1598175974495:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38840,DS-b2ea9d53-7ba9-4400-aa32-81e7e4584826,DISK], DatanodeInfoWithStorage[127.0.0.1:35499,DS-2d998e30-fc96-48dd-8e44-cb092b851565,DISK], DatanodeInfoWithStorage[127.0.0.1:42378,DS-49976e74-69cf-4d10-b58a-11811d12a2dd,DISK], DatanodeInfoWithStorage[127.0.0.1:40181,DS-38da42cc-bcef-4028-9798-36d1238e94c7,DISK], DatanodeInfoWithStorage[127.0.0.1:36293,DS-74a90890-8254-4561-be74-69b94bf743b2,DISK], DatanodeInfoWithStorage[127.0.0.1:36263,DS-655b9ab2-d218-45c1-a56d-b8d6ac767512,DISK], DatanodeInfoWithStorage[127.0.0.1:42318,DS-ff25105d-e9d6-4921-b4ab-2b582eb13875,DISK], DatanodeInfoWithStorage[127.0.0.1:42844,DS-b0c8fbb3-cea1-4a3d-85c8-29ee1b9312a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 9 out of 50
v1v1v2v2 failed with probability 16 out of 50
result: false positive !!!
Total execution time in seconds : 5510
