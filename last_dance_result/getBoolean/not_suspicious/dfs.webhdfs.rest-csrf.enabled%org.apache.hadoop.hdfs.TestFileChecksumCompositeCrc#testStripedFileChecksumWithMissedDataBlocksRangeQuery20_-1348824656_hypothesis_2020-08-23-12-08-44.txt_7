reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1140690108-172.17.0.17-1598184802238:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42212,DS-6645986d-f91f-4371-ac89-b3ba4c4dd6ec,DISK], DatanodeInfoWithStorage[127.0.0.1:43721,DS-475a2f1d-f2ea-4e36-a52a-189e353d5c43,DISK], DatanodeInfoWithStorage[127.0.0.1:44794,DS-22055502-df98-4e78-8f19-7b58b7bb300a,DISK], DatanodeInfoWithStorage[127.0.0.1:45724,DS-0e9a1a9d-7247-483b-8341-cadfe0a213ff,DISK], DatanodeInfoWithStorage[127.0.0.1:44976,DS-e2f96563-93ff-4a0e-8698-c408ce6acedf,DISK], DatanodeInfoWithStorage[127.0.0.1:34119,DS-8b413f2a-7f47-483f-bfce-d212ba378347,DISK], DatanodeInfoWithStorage[127.0.0.1:40548,DS-f5650275-1bcd-4511-999d-d4747874e2ad,DISK], DatanodeInfoWithStorage[127.0.0.1:38220,DS-e0c357b6-323c-4aa3-8f08-fcbde147662e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1140690108-172.17.0.17-1598184802238:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42212,DS-6645986d-f91f-4371-ac89-b3ba4c4dd6ec,DISK], DatanodeInfoWithStorage[127.0.0.1:43721,DS-475a2f1d-f2ea-4e36-a52a-189e353d5c43,DISK], DatanodeInfoWithStorage[127.0.0.1:44794,DS-22055502-df98-4e78-8f19-7b58b7bb300a,DISK], DatanodeInfoWithStorage[127.0.0.1:45724,DS-0e9a1a9d-7247-483b-8341-cadfe0a213ff,DISK], DatanodeInfoWithStorage[127.0.0.1:44976,DS-e2f96563-93ff-4a0e-8698-c408ce6acedf,DISK], DatanodeInfoWithStorage[127.0.0.1:34119,DS-8b413f2a-7f47-483f-bfce-d212ba378347,DISK], DatanodeInfoWithStorage[127.0.0.1:40548,DS-f5650275-1bcd-4511-999d-d4747874e2ad,DISK], DatanodeInfoWithStorage[127.0.0.1:38220,DS-e0c357b6-323c-4aa3-8f08-fcbde147662e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-882062385-172.17.0.17-1598185144577:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44192,DS-12190f28-f8f7-4227-9481-b0150b7c5d04,DISK], DatanodeInfoWithStorage[127.0.0.1:33659,DS-dade5af8-e20a-402a-bcc7-2938070975a9,DISK], DatanodeInfoWithStorage[127.0.0.1:40605,DS-cc6508a4-a1b8-48ba-82e1-ef8375beb435,DISK], DatanodeInfoWithStorage[127.0.0.1:41060,DS-03ba5b06-b4ab-457f-b676-c798f6c0f5e4,DISK], DatanodeInfoWithStorage[127.0.0.1:35836,DS-8ba2813c-2edd-49ff-bc86-fbe0e936cad0,DISK], DatanodeInfoWithStorage[127.0.0.1:38163,DS-c51f5087-7a28-448c-a134-3be8b28e1e13,DISK], DatanodeInfoWithStorage[127.0.0.1:36654,DS-658aeaf7-acf2-42ee-8902-70b26a04f5dd,DISK], DatanodeInfoWithStorage[127.0.0.1:41984,DS-d5b7e2f6-b77e-4719-9c45-a8ed93dec4e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-882062385-172.17.0.17-1598185144577:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44192,DS-12190f28-f8f7-4227-9481-b0150b7c5d04,DISK], DatanodeInfoWithStorage[127.0.0.1:33659,DS-dade5af8-e20a-402a-bcc7-2938070975a9,DISK], DatanodeInfoWithStorage[127.0.0.1:40605,DS-cc6508a4-a1b8-48ba-82e1-ef8375beb435,DISK], DatanodeInfoWithStorage[127.0.0.1:41060,DS-03ba5b06-b4ab-457f-b676-c798f6c0f5e4,DISK], DatanodeInfoWithStorage[127.0.0.1:35836,DS-8ba2813c-2edd-49ff-bc86-fbe0e936cad0,DISK], DatanodeInfoWithStorage[127.0.0.1:38163,DS-c51f5087-7a28-448c-a134-3be8b28e1e13,DISK], DatanodeInfoWithStorage[127.0.0.1:36654,DS-658aeaf7-acf2-42ee-8902-70b26a04f5dd,DISK], DatanodeInfoWithStorage[127.0.0.1:41984,DS-d5b7e2f6-b77e-4719-9c45-a8ed93dec4e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1707346075-172.17.0.17-1598185184144:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33878,DS-493c00f8-1732-4f16-8f44-88e06b6c85d3,DISK], DatanodeInfoWithStorage[127.0.0.1:38227,DS-2a2afaed-0dd7-45ec-b722-6bd6d1beb55b,DISK], DatanodeInfoWithStorage[127.0.0.1:42006,DS-d5cb46df-7225-4b5c-9d4d-5e9d65f269a3,DISK], DatanodeInfoWithStorage[127.0.0.1:41055,DS-f7e853d0-df8d-462e-b662-bfe1627f78fb,DISK], DatanodeInfoWithStorage[127.0.0.1:44738,DS-c004d712-765f-49ad-b901-2ab419b11a43,DISK], DatanodeInfoWithStorage[127.0.0.1:44098,DS-0a185714-5c7a-4fe7-be29-e8024919b594,DISK], DatanodeInfoWithStorage[127.0.0.1:41655,DS-29a1a9e2-ada8-4b2d-9eeb-f1affa98974e,DISK], DatanodeInfoWithStorage[127.0.0.1:38763,DS-640f20ef-8e1e-420d-8e39-2bc8fb6ba291,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1707346075-172.17.0.17-1598185184144:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33878,DS-493c00f8-1732-4f16-8f44-88e06b6c85d3,DISK], DatanodeInfoWithStorage[127.0.0.1:38227,DS-2a2afaed-0dd7-45ec-b722-6bd6d1beb55b,DISK], DatanodeInfoWithStorage[127.0.0.1:42006,DS-d5cb46df-7225-4b5c-9d4d-5e9d65f269a3,DISK], DatanodeInfoWithStorage[127.0.0.1:41055,DS-f7e853d0-df8d-462e-b662-bfe1627f78fb,DISK], DatanodeInfoWithStorage[127.0.0.1:44738,DS-c004d712-765f-49ad-b901-2ab419b11a43,DISK], DatanodeInfoWithStorage[127.0.0.1:44098,DS-0a185714-5c7a-4fe7-be29-e8024919b594,DISK], DatanodeInfoWithStorage[127.0.0.1:41655,DS-29a1a9e2-ada8-4b2d-9eeb-f1affa98974e,DISK], DatanodeInfoWithStorage[127.0.0.1:38763,DS-640f20ef-8e1e-420d-8e39-2bc8fb6ba291,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1476431342-172.17.0.17-1598186329363:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33862,DS-56094100-e121-4552-8b52-af111787138e,DISK], DatanodeInfoWithStorage[127.0.0.1:42475,DS-453b5797-e504-4e7a-b1ae-2b6788309921,DISK], DatanodeInfoWithStorage[127.0.0.1:42592,DS-81a37ddb-5aba-47a5-8872-6e404f4bf806,DISK], DatanodeInfoWithStorage[127.0.0.1:40515,DS-13e2b835-c294-4d03-a36a-871ccfb0c022,DISK], DatanodeInfoWithStorage[127.0.0.1:41146,DS-2d4ef99a-36a7-438b-ad18-bc0480f2394d,DISK], DatanodeInfoWithStorage[127.0.0.1:37139,DS-916292b3-4c31-4e96-95fc-9508fb385165,DISK], DatanodeInfoWithStorage[127.0.0.1:40470,DS-a012c96f-32fb-4ab7-9cd5-825dd86a3194,DISK], DatanodeInfoWithStorage[127.0.0.1:44448,DS-5854b1f2-a8bd-4646-a6d4-a36596acbfaf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1476431342-172.17.0.17-1598186329363:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33862,DS-56094100-e121-4552-8b52-af111787138e,DISK], DatanodeInfoWithStorage[127.0.0.1:42475,DS-453b5797-e504-4e7a-b1ae-2b6788309921,DISK], DatanodeInfoWithStorage[127.0.0.1:42592,DS-81a37ddb-5aba-47a5-8872-6e404f4bf806,DISK], DatanodeInfoWithStorage[127.0.0.1:40515,DS-13e2b835-c294-4d03-a36a-871ccfb0c022,DISK], DatanodeInfoWithStorage[127.0.0.1:41146,DS-2d4ef99a-36a7-438b-ad18-bc0480f2394d,DISK], DatanodeInfoWithStorage[127.0.0.1:37139,DS-916292b3-4c31-4e96-95fc-9508fb385165,DISK], DatanodeInfoWithStorage[127.0.0.1:40470,DS-a012c96f-32fb-4ab7-9cd5-825dd86a3194,DISK], DatanodeInfoWithStorage[127.0.0.1:44448,DS-5854b1f2-a8bd-4646-a6d4-a36596acbfaf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1511388165-172.17.0.17-1598186399603:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35336,DS-67a27689-4f53-4a64-be23-152e17653bda,DISK], DatanodeInfoWithStorage[127.0.0.1:46489,DS-9e6b0776-2568-4abd-9a49-3330efe9b7cd,DISK], DatanodeInfoWithStorage[127.0.0.1:44223,DS-725b3e6f-6733-4105-b649-d07fa3c4190b,DISK], DatanodeInfoWithStorage[127.0.0.1:37202,DS-12de5167-14a7-42be-bf74-eaa2c0fdb831,DISK], DatanodeInfoWithStorage[127.0.0.1:39847,DS-8775ebe8-698c-438e-aa9b-6a325eb6204d,DISK], DatanodeInfoWithStorage[127.0.0.1:39678,DS-ef40d017-74fd-4537-981c-af3ce99c3f1d,DISK], DatanodeInfoWithStorage[127.0.0.1:40033,DS-2f5bd013-bc80-4faf-9d44-7a9b9b76acba,DISK], DatanodeInfoWithStorage[127.0.0.1:42373,DS-0fa92ecc-5c54-4a49-8e6f-29f6c7e5e7a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1511388165-172.17.0.17-1598186399603:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35336,DS-67a27689-4f53-4a64-be23-152e17653bda,DISK], DatanodeInfoWithStorage[127.0.0.1:46489,DS-9e6b0776-2568-4abd-9a49-3330efe9b7cd,DISK], DatanodeInfoWithStorage[127.0.0.1:44223,DS-725b3e6f-6733-4105-b649-d07fa3c4190b,DISK], DatanodeInfoWithStorage[127.0.0.1:37202,DS-12de5167-14a7-42be-bf74-eaa2c0fdb831,DISK], DatanodeInfoWithStorage[127.0.0.1:39847,DS-8775ebe8-698c-438e-aa9b-6a325eb6204d,DISK], DatanodeInfoWithStorage[127.0.0.1:39678,DS-ef40d017-74fd-4537-981c-af3ce99c3f1d,DISK], DatanodeInfoWithStorage[127.0.0.1:40033,DS-2f5bd013-bc80-4faf-9d44-7a9b9b76acba,DISK], DatanodeInfoWithStorage[127.0.0.1:42373,DS-0fa92ecc-5c54-4a49-8e6f-29f6c7e5e7a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-537046293-172.17.0.17-1598186686024:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45634,DS-e25ad9db-fd62-42f5-8574-55fcf26485f7,DISK], DatanodeInfoWithStorage[127.0.0.1:44442,DS-75a49b81-30e0-431e-925e-d738e3bb26b4,DISK], DatanodeInfoWithStorage[127.0.0.1:44832,DS-a4542ee9-82bf-49c8-baa3-32e327f70bc9,DISK], DatanodeInfoWithStorage[127.0.0.1:40565,DS-6d200522-e7ec-439e-82a6-15644ba4e83d,DISK], DatanodeInfoWithStorage[127.0.0.1:39409,DS-4c37b47f-08b7-4405-b8a8-0a7e80f5b950,DISK], DatanodeInfoWithStorage[127.0.0.1:42352,DS-c28de04e-a2ce-4672-bc97-9e535ee74c9d,DISK], DatanodeInfoWithStorage[127.0.0.1:34462,DS-c5154cfd-2571-43a8-a757-907a940e8f73,DISK], DatanodeInfoWithStorage[127.0.0.1:46048,DS-4aa64f03-24cc-49a4-97d6-e4c24f12171b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-537046293-172.17.0.17-1598186686024:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45634,DS-e25ad9db-fd62-42f5-8574-55fcf26485f7,DISK], DatanodeInfoWithStorage[127.0.0.1:44442,DS-75a49b81-30e0-431e-925e-d738e3bb26b4,DISK], DatanodeInfoWithStorage[127.0.0.1:44832,DS-a4542ee9-82bf-49c8-baa3-32e327f70bc9,DISK], DatanodeInfoWithStorage[127.0.0.1:40565,DS-6d200522-e7ec-439e-82a6-15644ba4e83d,DISK], DatanodeInfoWithStorage[127.0.0.1:39409,DS-4c37b47f-08b7-4405-b8a8-0a7e80f5b950,DISK], DatanodeInfoWithStorage[127.0.0.1:42352,DS-c28de04e-a2ce-4672-bc97-9e535ee74c9d,DISK], DatanodeInfoWithStorage[127.0.0.1:34462,DS-c5154cfd-2571-43a8-a757-907a940e8f73,DISK], DatanodeInfoWithStorage[127.0.0.1:46048,DS-4aa64f03-24cc-49a4-97d6-e4c24f12171b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1534436705-172.17.0.17-1598186720067:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45287,DS-17ecf93d-125f-4802-ade1-9d01333a0c87,DISK], DatanodeInfoWithStorage[127.0.0.1:41357,DS-46232939-cd1a-4a3e-8c72-5ab40841f018,DISK], DatanodeInfoWithStorage[127.0.0.1:43555,DS-123b0918-eee8-491d-9e6b-fbead2ccc1cd,DISK], DatanodeInfoWithStorage[127.0.0.1:38820,DS-54888e2c-7114-4147-b09c-4162e503f76f,DISK], DatanodeInfoWithStorage[127.0.0.1:45355,DS-307d99af-ffe9-4342-ad5f-d3c127f8bfbf,DISK], DatanodeInfoWithStorage[127.0.0.1:33535,DS-5f33fc0c-b9e6-45a8-8ac8-f6cd45bf7f3f,DISK], DatanodeInfoWithStorage[127.0.0.1:37672,DS-e873cabd-199d-4920-92ae-c62b9b44749d,DISK], DatanodeInfoWithStorage[127.0.0.1:40102,DS-5d4da5cc-a2f1-4b54-bbc9-6a851a11a463,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1534436705-172.17.0.17-1598186720067:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45287,DS-17ecf93d-125f-4802-ade1-9d01333a0c87,DISK], DatanodeInfoWithStorage[127.0.0.1:41357,DS-46232939-cd1a-4a3e-8c72-5ab40841f018,DISK], DatanodeInfoWithStorage[127.0.0.1:43555,DS-123b0918-eee8-491d-9e6b-fbead2ccc1cd,DISK], DatanodeInfoWithStorage[127.0.0.1:38820,DS-54888e2c-7114-4147-b09c-4162e503f76f,DISK], DatanodeInfoWithStorage[127.0.0.1:45355,DS-307d99af-ffe9-4342-ad5f-d3c127f8bfbf,DISK], DatanodeInfoWithStorage[127.0.0.1:33535,DS-5f33fc0c-b9e6-45a8-8ac8-f6cd45bf7f3f,DISK], DatanodeInfoWithStorage[127.0.0.1:37672,DS-e873cabd-199d-4920-92ae-c62b9b44749d,DISK], DatanodeInfoWithStorage[127.0.0.1:40102,DS-5d4da5cc-a2f1-4b54-bbc9-6a851a11a463,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-96105369-172.17.0.17-1598187093689:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43842,DS-37a54800-41d8-4730-8b9d-7f59ea4129bb,DISK], DatanodeInfoWithStorage[127.0.0.1:33252,DS-6a943eee-7d37-4be5-b50a-d66d74328a3c,DISK], DatanodeInfoWithStorage[127.0.0.1:34497,DS-b32714b6-81fc-4ffe-b185-26b503ac0a83,DISK], DatanodeInfoWithStorage[127.0.0.1:40256,DS-c6ba3c4c-c5fb-4e66-8947-fd3dd3e1a180,DISK], DatanodeInfoWithStorage[127.0.0.1:38010,DS-d0049c7e-c511-4a84-aaf4-44268dc44f5d,DISK], DatanodeInfoWithStorage[127.0.0.1:44958,DS-38d4a0e6-ef6f-4090-957b-d50cd1a8ecdf,DISK], DatanodeInfoWithStorage[127.0.0.1:39434,DS-4dbed903-8ece-4a55-9d73-7f3c03f79c96,DISK], DatanodeInfoWithStorage[127.0.0.1:44402,DS-18608508-2069-4f4f-b510-7480298d8af4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-96105369-172.17.0.17-1598187093689:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43842,DS-37a54800-41d8-4730-8b9d-7f59ea4129bb,DISK], DatanodeInfoWithStorage[127.0.0.1:33252,DS-6a943eee-7d37-4be5-b50a-d66d74328a3c,DISK], DatanodeInfoWithStorage[127.0.0.1:34497,DS-b32714b6-81fc-4ffe-b185-26b503ac0a83,DISK], DatanodeInfoWithStorage[127.0.0.1:40256,DS-c6ba3c4c-c5fb-4e66-8947-fd3dd3e1a180,DISK], DatanodeInfoWithStorage[127.0.0.1:38010,DS-d0049c7e-c511-4a84-aaf4-44268dc44f5d,DISK], DatanodeInfoWithStorage[127.0.0.1:44958,DS-38d4a0e6-ef6f-4090-957b-d50cd1a8ecdf,DISK], DatanodeInfoWithStorage[127.0.0.1:39434,DS-4dbed903-8ece-4a55-9d73-7f3c03f79c96,DISK], DatanodeInfoWithStorage[127.0.0.1:44402,DS-18608508-2069-4f4f-b510-7480298d8af4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-729652072-172.17.0.17-1598187483026:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34955,DS-da280406-6568-4f6c-a6af-b8bed765bd20,DISK], DatanodeInfoWithStorage[127.0.0.1:46285,DS-7e518a27-be90-4f38-98eb-23daa228d883,DISK], DatanodeInfoWithStorage[127.0.0.1:45739,DS-1fd8628f-c761-4379-a3b6-f93b0ccbf636,DISK], DatanodeInfoWithStorage[127.0.0.1:44502,DS-be88ea24-d88d-4b9f-86b0-7f7da06e3cf2,DISK], DatanodeInfoWithStorage[127.0.0.1:45981,DS-7359d05f-4594-4347-9d19-6461bc82679f,DISK], DatanodeInfoWithStorage[127.0.0.1:44025,DS-bea84832-ffb0-4482-b52d-c2930eebf951,DISK], DatanodeInfoWithStorage[127.0.0.1:37808,DS-268b8e98-78fc-4c7f-9694-176bea43955c,DISK], DatanodeInfoWithStorage[127.0.0.1:45854,DS-2c018b0b-3b1f-4b15-b819-0ba828c76fd7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-729652072-172.17.0.17-1598187483026:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34955,DS-da280406-6568-4f6c-a6af-b8bed765bd20,DISK], DatanodeInfoWithStorage[127.0.0.1:46285,DS-7e518a27-be90-4f38-98eb-23daa228d883,DISK], DatanodeInfoWithStorage[127.0.0.1:45739,DS-1fd8628f-c761-4379-a3b6-f93b0ccbf636,DISK], DatanodeInfoWithStorage[127.0.0.1:44502,DS-be88ea24-d88d-4b9f-86b0-7f7da06e3cf2,DISK], DatanodeInfoWithStorage[127.0.0.1:45981,DS-7359d05f-4594-4347-9d19-6461bc82679f,DISK], DatanodeInfoWithStorage[127.0.0.1:44025,DS-bea84832-ffb0-4482-b52d-c2930eebf951,DISK], DatanodeInfoWithStorage[127.0.0.1:37808,DS-268b8e98-78fc-4c7f-9694-176bea43955c,DISK], DatanodeInfoWithStorage[127.0.0.1:45854,DS-2c018b0b-3b1f-4b15-b819-0ba828c76fd7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1406863898-172.17.0.17-1598187840328:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38677,DS-41ab242c-2723-49d0-ada5-f369d8a4148a,DISK], DatanodeInfoWithStorage[127.0.0.1:40794,DS-2c447a39-cf4e-4088-b862-1c1d7c87e8f4,DISK], DatanodeInfoWithStorage[127.0.0.1:33535,DS-0ef1dd03-d411-4ecf-86db-ee24882d5114,DISK], DatanodeInfoWithStorage[127.0.0.1:33548,DS-4cda0a41-f156-45da-aa6d-1bc39603ba4f,DISK], DatanodeInfoWithStorage[127.0.0.1:33827,DS-41b308dd-fe37-4db2-bae1-33a1d8271b11,DISK], DatanodeInfoWithStorage[127.0.0.1:33292,DS-a19ce489-23de-41f2-bdce-e8b39b9d7eaf,DISK], DatanodeInfoWithStorage[127.0.0.1:36855,DS-cf48e011-9c6e-477d-adee-bf03af626257,DISK], DatanodeInfoWithStorage[127.0.0.1:38229,DS-2cc0b1e8-868a-4ae2-919c-64d7cff7e156,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1406863898-172.17.0.17-1598187840328:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38677,DS-41ab242c-2723-49d0-ada5-f369d8a4148a,DISK], DatanodeInfoWithStorage[127.0.0.1:40794,DS-2c447a39-cf4e-4088-b862-1c1d7c87e8f4,DISK], DatanodeInfoWithStorage[127.0.0.1:33535,DS-0ef1dd03-d411-4ecf-86db-ee24882d5114,DISK], DatanodeInfoWithStorage[127.0.0.1:33548,DS-4cda0a41-f156-45da-aa6d-1bc39603ba4f,DISK], DatanodeInfoWithStorage[127.0.0.1:33827,DS-41b308dd-fe37-4db2-bae1-33a1d8271b11,DISK], DatanodeInfoWithStorage[127.0.0.1:33292,DS-a19ce489-23de-41f2-bdce-e8b39b9d7eaf,DISK], DatanodeInfoWithStorage[127.0.0.1:36855,DS-cf48e011-9c6e-477d-adee-bf03af626257,DISK], DatanodeInfoWithStorage[127.0.0.1:38229,DS-2cc0b1e8-868a-4ae2-919c-64d7cff7e156,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1572369368-172.17.0.17-1598188144848:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42019,DS-b066f7bf-86e3-435e-bddb-0a1079fbc311,DISK], DatanodeInfoWithStorage[127.0.0.1:39764,DS-50513f7e-f9e9-4aa0-ade8-ae5af2c89e14,DISK], DatanodeInfoWithStorage[127.0.0.1:46668,DS-d9de630d-3eb8-45cf-9cf3-e1b0f1a4b634,DISK], DatanodeInfoWithStorage[127.0.0.1:37577,DS-b9375e28-9a72-4d3a-b1a3-97d50b71cb03,DISK], DatanodeInfoWithStorage[127.0.0.1:37420,DS-1dbeb8bb-d588-4764-9ab1-553c031a74ea,DISK], DatanodeInfoWithStorage[127.0.0.1:37408,DS-d4f711d7-60a1-4977-86d3-7548fa57f7f0,DISK], DatanodeInfoWithStorage[127.0.0.1:43509,DS-4458d5f9-74e0-4e1d-a63c-55e97450ace4,DISK], DatanodeInfoWithStorage[127.0.0.1:45767,DS-8da18c8d-3c16-43cb-9d51-d2569342dff7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1572369368-172.17.0.17-1598188144848:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42019,DS-b066f7bf-86e3-435e-bddb-0a1079fbc311,DISK], DatanodeInfoWithStorage[127.0.0.1:39764,DS-50513f7e-f9e9-4aa0-ade8-ae5af2c89e14,DISK], DatanodeInfoWithStorage[127.0.0.1:46668,DS-d9de630d-3eb8-45cf-9cf3-e1b0f1a4b634,DISK], DatanodeInfoWithStorage[127.0.0.1:37577,DS-b9375e28-9a72-4d3a-b1a3-97d50b71cb03,DISK], DatanodeInfoWithStorage[127.0.0.1:37420,DS-1dbeb8bb-d588-4764-9ab1-553c031a74ea,DISK], DatanodeInfoWithStorage[127.0.0.1:37408,DS-d4f711d7-60a1-4977-86d3-7548fa57f7f0,DISK], DatanodeInfoWithStorage[127.0.0.1:43509,DS-4458d5f9-74e0-4e1d-a63c-55e97450ace4,DISK], DatanodeInfoWithStorage[127.0.0.1:45767,DS-8da18c8d-3c16-43cb-9d51-d2569342dff7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-29714908-172.17.0.17-1598188213211:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42793,DS-6b6f11f8-c106-4443-905c-92f06e2aca44,DISK], DatanodeInfoWithStorage[127.0.0.1:42476,DS-a36d155a-33fc-4222-b0de-e8dab1e9254e,DISK], DatanodeInfoWithStorage[127.0.0.1:44017,DS-c7d45b92-768f-44f0-8f87-5256b01e4ed6,DISK], DatanodeInfoWithStorage[127.0.0.1:46435,DS-cbf11a95-e8f4-4cd0-bb2f-5b41af0e7f45,DISK], DatanodeInfoWithStorage[127.0.0.1:32799,DS-08064755-08b8-46dd-af71-073aaad1eec6,DISK], DatanodeInfoWithStorage[127.0.0.1:33087,DS-2c9b94a1-eb75-45e5-8a84-5377fab43095,DISK], DatanodeInfoWithStorage[127.0.0.1:46819,DS-75f25ce5-c80c-47dc-929b-5ac6565becfa,DISK], DatanodeInfoWithStorage[127.0.0.1:36126,DS-c89b9b57-6b8c-440a-81c9-25aad9a89958,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-29714908-172.17.0.17-1598188213211:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42793,DS-6b6f11f8-c106-4443-905c-92f06e2aca44,DISK], DatanodeInfoWithStorage[127.0.0.1:42476,DS-a36d155a-33fc-4222-b0de-e8dab1e9254e,DISK], DatanodeInfoWithStorage[127.0.0.1:44017,DS-c7d45b92-768f-44f0-8f87-5256b01e4ed6,DISK], DatanodeInfoWithStorage[127.0.0.1:46435,DS-cbf11a95-e8f4-4cd0-bb2f-5b41af0e7f45,DISK], DatanodeInfoWithStorage[127.0.0.1:32799,DS-08064755-08b8-46dd-af71-073aaad1eec6,DISK], DatanodeInfoWithStorage[127.0.0.1:33087,DS-2c9b94a1-eb75-45e5-8a84-5377fab43095,DISK], DatanodeInfoWithStorage[127.0.0.1:46819,DS-75f25ce5-c80c-47dc-929b-5ac6565becfa,DISK], DatanodeInfoWithStorage[127.0.0.1:36126,DS-c89b9b57-6b8c-440a-81c9-25aad9a89958,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-150847939-172.17.0.17-1598188284084:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45831,DS-6930ca67-ff75-4bb8-8c50-8b332bbefc90,DISK], DatanodeInfoWithStorage[127.0.0.1:46856,DS-6ad557d0-0afe-45c7-ada7-a9ca2e8280df,DISK], DatanodeInfoWithStorage[127.0.0.1:32850,DS-e150c62c-7a08-4f1a-a7b2-505d986607a1,DISK], DatanodeInfoWithStorage[127.0.0.1:35239,DS-d4afc8e1-559b-42f0-ad40-bad583c083b4,DISK], DatanodeInfoWithStorage[127.0.0.1:44775,DS-d6a8ed82-ab1d-4d02-a98a-acf6ca876eac,DISK], DatanodeInfoWithStorage[127.0.0.1:35284,DS-e0812584-cce1-4dba-8efc-c8c0831c14bc,DISK], DatanodeInfoWithStorage[127.0.0.1:35078,DS-312b4f16-e4dd-4fb3-842e-324e1746d378,DISK], DatanodeInfoWithStorage[127.0.0.1:37092,DS-51cebe9a-5487-4c80-b6cf-61380c2cf3ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-150847939-172.17.0.17-1598188284084:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45831,DS-6930ca67-ff75-4bb8-8c50-8b332bbefc90,DISK], DatanodeInfoWithStorage[127.0.0.1:46856,DS-6ad557d0-0afe-45c7-ada7-a9ca2e8280df,DISK], DatanodeInfoWithStorage[127.0.0.1:32850,DS-e150c62c-7a08-4f1a-a7b2-505d986607a1,DISK], DatanodeInfoWithStorage[127.0.0.1:35239,DS-d4afc8e1-559b-42f0-ad40-bad583c083b4,DISK], DatanodeInfoWithStorage[127.0.0.1:44775,DS-d6a8ed82-ab1d-4d02-a98a-acf6ca876eac,DISK], DatanodeInfoWithStorage[127.0.0.1:35284,DS-e0812584-cce1-4dba-8efc-c8c0831c14bc,DISK], DatanodeInfoWithStorage[127.0.0.1:35078,DS-312b4f16-e4dd-4fb3-842e-324e1746d378,DISK], DatanodeInfoWithStorage[127.0.0.1:37092,DS-51cebe9a-5487-4c80-b6cf-61380c2cf3ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1441761377-172.17.0.17-1598188353540:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44841,DS-a1533d22-132f-4389-b06e-026fd19fffcf,DISK], DatanodeInfoWithStorage[127.0.0.1:42391,DS-c2769027-35b2-4444-b0fd-daad90ed4923,DISK], DatanodeInfoWithStorage[127.0.0.1:39172,DS-0546f943-6860-49c7-9faf-b166fdee9a72,DISK], DatanodeInfoWithStorage[127.0.0.1:44720,DS-72c09615-7832-4576-8029-72b068e28eee,DISK], DatanodeInfoWithStorage[127.0.0.1:37663,DS-c6177f8c-a2d7-48bd-940a-d4d81816be0b,DISK], DatanodeInfoWithStorage[127.0.0.1:45520,DS-d42ccffb-7968-4a90-99f6-188954569bef,DISK], DatanodeInfoWithStorage[127.0.0.1:41151,DS-2e2b2496-bd84-466d-9651-2cc41e202935,DISK], DatanodeInfoWithStorage[127.0.0.1:44486,DS-10b8790b-045d-4cab-a9fc-135aba176ed3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1441761377-172.17.0.17-1598188353540:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44841,DS-a1533d22-132f-4389-b06e-026fd19fffcf,DISK], DatanodeInfoWithStorage[127.0.0.1:42391,DS-c2769027-35b2-4444-b0fd-daad90ed4923,DISK], DatanodeInfoWithStorage[127.0.0.1:39172,DS-0546f943-6860-49c7-9faf-b166fdee9a72,DISK], DatanodeInfoWithStorage[127.0.0.1:44720,DS-72c09615-7832-4576-8029-72b068e28eee,DISK], DatanodeInfoWithStorage[127.0.0.1:37663,DS-c6177f8c-a2d7-48bd-940a-d4d81816be0b,DISK], DatanodeInfoWithStorage[127.0.0.1:45520,DS-d42ccffb-7968-4a90-99f6-188954569bef,DISK], DatanodeInfoWithStorage[127.0.0.1:41151,DS-2e2b2496-bd84-466d-9651-2cc41e202935,DISK], DatanodeInfoWithStorage[127.0.0.1:44486,DS-10b8790b-045d-4cab-a9fc-135aba176ed3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1786535400-172.17.0.17-1598188775322:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41289,DS-1cbb6517-823f-46f5-9130-14da1091f337,DISK], DatanodeInfoWithStorage[127.0.0.1:43380,DS-bdb3a457-cd59-441b-9646-c97efccb1925,DISK], DatanodeInfoWithStorage[127.0.0.1:45670,DS-18ba56d1-a906-4905-936b-83c770e3c8f7,DISK], DatanodeInfoWithStorage[127.0.0.1:36074,DS-7a253964-de39-4d3c-9583-7768804bad4a,DISK], DatanodeInfoWithStorage[127.0.0.1:35828,DS-613a10b1-38e2-4507-817c-cd8f1f0ac92e,DISK], DatanodeInfoWithStorage[127.0.0.1:43206,DS-5d78582e-73c8-4bff-93a5-966bd389fad9,DISK], DatanodeInfoWithStorage[127.0.0.1:39688,DS-acf7665f-8296-4175-adc7-30027ecd8cae,DISK], DatanodeInfoWithStorage[127.0.0.1:44726,DS-443f7401-35d9-497f-b0dc-c0a8d183f3f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1786535400-172.17.0.17-1598188775322:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41289,DS-1cbb6517-823f-46f5-9130-14da1091f337,DISK], DatanodeInfoWithStorage[127.0.0.1:43380,DS-bdb3a457-cd59-441b-9646-c97efccb1925,DISK], DatanodeInfoWithStorage[127.0.0.1:45670,DS-18ba56d1-a906-4905-936b-83c770e3c8f7,DISK], DatanodeInfoWithStorage[127.0.0.1:36074,DS-7a253964-de39-4d3c-9583-7768804bad4a,DISK], DatanodeInfoWithStorage[127.0.0.1:35828,DS-613a10b1-38e2-4507-817c-cd8f1f0ac92e,DISK], DatanodeInfoWithStorage[127.0.0.1:43206,DS-5d78582e-73c8-4bff-93a5-966bd389fad9,DISK], DatanodeInfoWithStorage[127.0.0.1:39688,DS-acf7665f-8296-4175-adc7-30027ecd8cae,DISK], DatanodeInfoWithStorage[127.0.0.1:44726,DS-443f7401-35d9-497f-b0dc-c0a8d183f3f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1655263598-172.17.0.17-1598188960381:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36983,DS-62a8b6e1-6efc-4a6b-ae2e-3b7dc2df894c,DISK], DatanodeInfoWithStorage[127.0.0.1:36456,DS-ca338020-9b31-4557-ada3-17591bf02b9f,DISK], DatanodeInfoWithStorage[127.0.0.1:36426,DS-86101dd0-e052-42d1-82a9-e425492642d7,DISK], DatanodeInfoWithStorage[127.0.0.1:42918,DS-cc96b36a-849c-4947-a023-2c63dc7e28c3,DISK], DatanodeInfoWithStorage[127.0.0.1:37242,DS-c0daa686-9a21-49ee-b04f-69cc2728603b,DISK], DatanodeInfoWithStorage[127.0.0.1:37369,DS-424d0182-492e-4d73-968b-7b094d6052a1,DISK], DatanodeInfoWithStorage[127.0.0.1:34670,DS-c8ddc8cf-211e-43df-a619-24e4cdbcdec6,DISK], DatanodeInfoWithStorage[127.0.0.1:43058,DS-8c0a495e-d7c9-4319-b231-42f18cf339a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1655263598-172.17.0.17-1598188960381:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36983,DS-62a8b6e1-6efc-4a6b-ae2e-3b7dc2df894c,DISK], DatanodeInfoWithStorage[127.0.0.1:36456,DS-ca338020-9b31-4557-ada3-17591bf02b9f,DISK], DatanodeInfoWithStorage[127.0.0.1:36426,DS-86101dd0-e052-42d1-82a9-e425492642d7,DISK], DatanodeInfoWithStorage[127.0.0.1:42918,DS-cc96b36a-849c-4947-a023-2c63dc7e28c3,DISK], DatanodeInfoWithStorage[127.0.0.1:37242,DS-c0daa686-9a21-49ee-b04f-69cc2728603b,DISK], DatanodeInfoWithStorage[127.0.0.1:37369,DS-424d0182-492e-4d73-968b-7b094d6052a1,DISK], DatanodeInfoWithStorage[127.0.0.1:34670,DS-c8ddc8cf-211e-43df-a619-24e4cdbcdec6,DISK], DatanodeInfoWithStorage[127.0.0.1:43058,DS-8c0a495e-d7c9-4319-b231-42f18cf339a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5263
