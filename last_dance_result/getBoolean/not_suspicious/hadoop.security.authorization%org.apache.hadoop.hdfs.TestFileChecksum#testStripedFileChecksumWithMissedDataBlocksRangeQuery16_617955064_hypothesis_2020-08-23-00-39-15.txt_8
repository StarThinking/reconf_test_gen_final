reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1159912060-172.17.0.20-1598143172538:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32951,DS-8b1f0f4f-df93-483a-8003-486ec7ef72b9,DISK], DatanodeInfoWithStorage[127.0.0.1:39850,DS-594ed849-f18f-44d2-86b5-1828a41c041d,DISK], DatanodeInfoWithStorage[127.0.0.1:43138,DS-a90c93f2-2d79-4cc9-aef5-178d1b208b25,DISK], DatanodeInfoWithStorage[127.0.0.1:39830,DS-2542dc26-122d-4b30-8230-d5572b8fe92f,DISK], DatanodeInfoWithStorage[127.0.0.1:42698,DS-2cdcd685-cc3d-4046-b765-aff1c0fb6140,DISK], DatanodeInfoWithStorage[127.0.0.1:38116,DS-6509d1cc-93cf-4288-b109-0552db78b07e,DISK], DatanodeInfoWithStorage[127.0.0.1:38304,DS-1c2c6a47-2948-4b60-a45c-9fb61bf3cc4b,DISK], DatanodeInfoWithStorage[127.0.0.1:36033,DS-f27c666a-8469-40fa-9211-e0e630b1e733,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1159912060-172.17.0.20-1598143172538:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32951,DS-8b1f0f4f-df93-483a-8003-486ec7ef72b9,DISK], DatanodeInfoWithStorage[127.0.0.1:39850,DS-594ed849-f18f-44d2-86b5-1828a41c041d,DISK], DatanodeInfoWithStorage[127.0.0.1:43138,DS-a90c93f2-2d79-4cc9-aef5-178d1b208b25,DISK], DatanodeInfoWithStorage[127.0.0.1:39830,DS-2542dc26-122d-4b30-8230-d5572b8fe92f,DISK], DatanodeInfoWithStorage[127.0.0.1:42698,DS-2cdcd685-cc3d-4046-b765-aff1c0fb6140,DISK], DatanodeInfoWithStorage[127.0.0.1:38116,DS-6509d1cc-93cf-4288-b109-0552db78b07e,DISK], DatanodeInfoWithStorage[127.0.0.1:38304,DS-1c2c6a47-2948-4b60-a45c-9fb61bf3cc4b,DISK], DatanodeInfoWithStorage[127.0.0.1:36033,DS-f27c666a-8469-40fa-9211-e0e630b1e733,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1198111607-172.17.0.20-1598143312584:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40936,DS-3109eda8-a773-4f47-9fe1-bc8fa4a99661,DISK], DatanodeInfoWithStorage[127.0.0.1:37866,DS-0c2145ca-da3a-461f-b138-6412d764c6ed,DISK], DatanodeInfoWithStorage[127.0.0.1:34970,DS-a454a6c2-8c1c-45e4-8680-7722e85b85eb,DISK], DatanodeInfoWithStorage[127.0.0.1:42384,DS-889dfeed-dc28-4d5a-bc69-75da4ac1a876,DISK], DatanodeInfoWithStorage[127.0.0.1:33331,DS-bec91e76-1f96-4cad-944f-f8fbebad02e7,DISK], DatanodeInfoWithStorage[127.0.0.1:37019,DS-51affb0d-9aea-4193-adb5-b07cd90a0a01,DISK], DatanodeInfoWithStorage[127.0.0.1:35395,DS-953f0421-32f5-46a8-a74d-7b37322765dd,DISK], DatanodeInfoWithStorage[127.0.0.1:41497,DS-f83132c5-9094-47f1-9206-1b087b8dffa5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1198111607-172.17.0.20-1598143312584:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40936,DS-3109eda8-a773-4f47-9fe1-bc8fa4a99661,DISK], DatanodeInfoWithStorage[127.0.0.1:37866,DS-0c2145ca-da3a-461f-b138-6412d764c6ed,DISK], DatanodeInfoWithStorage[127.0.0.1:34970,DS-a454a6c2-8c1c-45e4-8680-7722e85b85eb,DISK], DatanodeInfoWithStorage[127.0.0.1:42384,DS-889dfeed-dc28-4d5a-bc69-75da4ac1a876,DISK], DatanodeInfoWithStorage[127.0.0.1:33331,DS-bec91e76-1f96-4cad-944f-f8fbebad02e7,DISK], DatanodeInfoWithStorage[127.0.0.1:37019,DS-51affb0d-9aea-4193-adb5-b07cd90a0a01,DISK], DatanodeInfoWithStorage[127.0.0.1:35395,DS-953f0421-32f5-46a8-a74d-7b37322765dd,DISK], DatanodeInfoWithStorage[127.0.0.1:41497,DS-f83132c5-9094-47f1-9206-1b087b8dffa5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-510742886-172.17.0.20-1598143849502:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40878,DS-c1681b38-ef78-4378-b615-6326cb30a5c0,DISK], DatanodeInfoWithStorage[127.0.0.1:45639,DS-82b3d4e4-f4e3-4d51-bb43-56b90845b7d8,DISK], DatanodeInfoWithStorage[127.0.0.1:39841,DS-4d7d8fac-2dec-4ab9-8dcf-60265ea0d06e,DISK], DatanodeInfoWithStorage[127.0.0.1:42584,DS-2a491bca-b6e9-4ce2-ba72-5c709403792e,DISK], DatanodeInfoWithStorage[127.0.0.1:39018,DS-d562c07a-75b6-44e8-a409-ff7c9dae3eaa,DISK], DatanodeInfoWithStorage[127.0.0.1:42099,DS-12a1219e-86fd-472f-a412-237a9af905e0,DISK], DatanodeInfoWithStorage[127.0.0.1:43391,DS-cfa8cb0f-6df2-4b45-8b5e-c1576e1387cb,DISK], DatanodeInfoWithStorage[127.0.0.1:38297,DS-4fd9304d-41c1-48e7-aaba-44017288234a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-510742886-172.17.0.20-1598143849502:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40878,DS-c1681b38-ef78-4378-b615-6326cb30a5c0,DISK], DatanodeInfoWithStorage[127.0.0.1:45639,DS-82b3d4e4-f4e3-4d51-bb43-56b90845b7d8,DISK], DatanodeInfoWithStorage[127.0.0.1:39841,DS-4d7d8fac-2dec-4ab9-8dcf-60265ea0d06e,DISK], DatanodeInfoWithStorage[127.0.0.1:42584,DS-2a491bca-b6e9-4ce2-ba72-5c709403792e,DISK], DatanodeInfoWithStorage[127.0.0.1:39018,DS-d562c07a-75b6-44e8-a409-ff7c9dae3eaa,DISK], DatanodeInfoWithStorage[127.0.0.1:42099,DS-12a1219e-86fd-472f-a412-237a9af905e0,DISK], DatanodeInfoWithStorage[127.0.0.1:43391,DS-cfa8cb0f-6df2-4b45-8b5e-c1576e1387cb,DISK], DatanodeInfoWithStorage[127.0.0.1:38297,DS-4fd9304d-41c1-48e7-aaba-44017288234a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-703752582-172.17.0.20-1598143912432:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41116,DS-e29a4eed-5356-4ad0-a28a-7d2ca60b4477,DISK], DatanodeInfoWithStorage[127.0.0.1:33862,DS-ca5ba1c1-a04a-4a10-92ce-8c1c7c37c2e1,DISK], DatanodeInfoWithStorage[127.0.0.1:39143,DS-0ce83494-ff7a-4ffe-9615-ccb7fafbcc86,DISK], DatanodeInfoWithStorage[127.0.0.1:45671,DS-2154f2cb-7c30-49db-8b33-ea392ed17c53,DISK], DatanodeInfoWithStorage[127.0.0.1:40479,DS-8ee78857-cb0f-4714-9f85-ce04ed37de6a,DISK], DatanodeInfoWithStorage[127.0.0.1:38309,DS-799fa9c1-ae7f-4525-ba64-f391cdbe459c,DISK], DatanodeInfoWithStorage[127.0.0.1:33987,DS-0950b585-365e-4994-aaa3-7696641b60c1,DISK], DatanodeInfoWithStorage[127.0.0.1:33773,DS-369a551b-b242-4898-ab40-27e0ec8ba3f8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-703752582-172.17.0.20-1598143912432:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41116,DS-e29a4eed-5356-4ad0-a28a-7d2ca60b4477,DISK], DatanodeInfoWithStorage[127.0.0.1:33862,DS-ca5ba1c1-a04a-4a10-92ce-8c1c7c37c2e1,DISK], DatanodeInfoWithStorage[127.0.0.1:39143,DS-0ce83494-ff7a-4ffe-9615-ccb7fafbcc86,DISK], DatanodeInfoWithStorage[127.0.0.1:45671,DS-2154f2cb-7c30-49db-8b33-ea392ed17c53,DISK], DatanodeInfoWithStorage[127.0.0.1:40479,DS-8ee78857-cb0f-4714-9f85-ce04ed37de6a,DISK], DatanodeInfoWithStorage[127.0.0.1:38309,DS-799fa9c1-ae7f-4525-ba64-f391cdbe459c,DISK], DatanodeInfoWithStorage[127.0.0.1:33987,DS-0950b585-365e-4994-aaa3-7696641b60c1,DISK], DatanodeInfoWithStorage[127.0.0.1:33773,DS-369a551b-b242-4898-ab40-27e0ec8ba3f8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1449626971-172.17.0.20-1598144607043:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41029,DS-80121334-24f1-4187-afff-4a3fd2d2afcd,DISK], DatanodeInfoWithStorage[127.0.0.1:38423,DS-e4aecc1a-8a86-404d-a711-c91870ff0528,DISK], DatanodeInfoWithStorage[127.0.0.1:33315,DS-b2fec89c-243d-4d22-9d79-525658910992,DISK], DatanodeInfoWithStorage[127.0.0.1:46557,DS-7cc24596-d9b7-4121-824f-99d407076fa5,DISK], DatanodeInfoWithStorage[127.0.0.1:45427,DS-babf1767-7a25-4635-8b01-25c544347a43,DISK], DatanodeInfoWithStorage[127.0.0.1:41296,DS-7154b2e3-647c-49d4-bc04-7026e253fd6b,DISK], DatanodeInfoWithStorage[127.0.0.1:35433,DS-8ceecce2-767f-49e0-a252-7b524a2fd92f,DISK], DatanodeInfoWithStorage[127.0.0.1:34820,DS-ad49064f-36f4-44dd-b5d9-47eda771d77b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1449626971-172.17.0.20-1598144607043:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41029,DS-80121334-24f1-4187-afff-4a3fd2d2afcd,DISK], DatanodeInfoWithStorage[127.0.0.1:38423,DS-e4aecc1a-8a86-404d-a711-c91870ff0528,DISK], DatanodeInfoWithStorage[127.0.0.1:33315,DS-b2fec89c-243d-4d22-9d79-525658910992,DISK], DatanodeInfoWithStorage[127.0.0.1:46557,DS-7cc24596-d9b7-4121-824f-99d407076fa5,DISK], DatanodeInfoWithStorage[127.0.0.1:45427,DS-babf1767-7a25-4635-8b01-25c544347a43,DISK], DatanodeInfoWithStorage[127.0.0.1:41296,DS-7154b2e3-647c-49d4-bc04-7026e253fd6b,DISK], DatanodeInfoWithStorage[127.0.0.1:35433,DS-8ceecce2-767f-49e0-a252-7b524a2fd92f,DISK], DatanodeInfoWithStorage[127.0.0.1:34820,DS-ad49064f-36f4-44dd-b5d9-47eda771d77b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-453431106-172.17.0.20-1598145211328:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40914,DS-e4e2d1dd-ae94-466f-9c27-a6491525cfc2,DISK], DatanodeInfoWithStorage[127.0.0.1:34692,DS-59c82333-895d-49bf-a4bf-b5f1f1a612d4,DISK], DatanodeInfoWithStorage[127.0.0.1:37479,DS-92353fd0-9633-452a-b610-1628405bcc6a,DISK], DatanodeInfoWithStorage[127.0.0.1:44666,DS-a05750c3-8c10-4c01-9b51-aae149a4d206,DISK], DatanodeInfoWithStorage[127.0.0.1:41671,DS-1f256805-62c0-495c-a6b1-75f3c5220fa0,DISK], DatanodeInfoWithStorage[127.0.0.1:43308,DS-71a62ecd-f487-4ade-81aa-fb451100f033,DISK], DatanodeInfoWithStorage[127.0.0.1:34691,DS-cbbb1f5f-d3f3-4c73-b715-4023806ec4f0,DISK], DatanodeInfoWithStorage[127.0.0.1:34850,DS-e1489f8d-b7b1-4fbe-a0a7-664af25478b4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-453431106-172.17.0.20-1598145211328:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40914,DS-e4e2d1dd-ae94-466f-9c27-a6491525cfc2,DISK], DatanodeInfoWithStorage[127.0.0.1:34692,DS-59c82333-895d-49bf-a4bf-b5f1f1a612d4,DISK], DatanodeInfoWithStorage[127.0.0.1:37479,DS-92353fd0-9633-452a-b610-1628405bcc6a,DISK], DatanodeInfoWithStorage[127.0.0.1:44666,DS-a05750c3-8c10-4c01-9b51-aae149a4d206,DISK], DatanodeInfoWithStorage[127.0.0.1:41671,DS-1f256805-62c0-495c-a6b1-75f3c5220fa0,DISK], DatanodeInfoWithStorage[127.0.0.1:43308,DS-71a62ecd-f487-4ade-81aa-fb451100f033,DISK], DatanodeInfoWithStorage[127.0.0.1:34691,DS-cbbb1f5f-d3f3-4c73-b715-4023806ec4f0,DISK], DatanodeInfoWithStorage[127.0.0.1:34850,DS-e1489f8d-b7b1-4fbe-a0a7-664af25478b4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-341949182-172.17.0.20-1598145243132:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39617,DS-f4f695e2-3d9e-4594-8d34-b42ab7156acf,DISK], DatanodeInfoWithStorage[127.0.0.1:33739,DS-9650d77c-1c4f-4e54-9290-7e7cc9959e24,DISK], DatanodeInfoWithStorage[127.0.0.1:33645,DS-a61362d0-61d2-42bd-8fe6-5f90fd2a9b15,DISK], DatanodeInfoWithStorage[127.0.0.1:42388,DS-7dd0edbf-bc10-4dbf-9f58-8a0141214be5,DISK], DatanodeInfoWithStorage[127.0.0.1:44822,DS-67b4d665-1a71-49c1-b1ca-447d06009017,DISK], DatanodeInfoWithStorage[127.0.0.1:40431,DS-4fd44925-1eca-4001-b72d-7e343f11e4a5,DISK], DatanodeInfoWithStorage[127.0.0.1:45706,DS-78a0ecf1-1cf8-4256-9cd4-9e8b70f839de,DISK], DatanodeInfoWithStorage[127.0.0.1:39815,DS-f3a040b3-2fb2-448b-af73-6701ad36a024,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-341949182-172.17.0.20-1598145243132:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39617,DS-f4f695e2-3d9e-4594-8d34-b42ab7156acf,DISK], DatanodeInfoWithStorage[127.0.0.1:33739,DS-9650d77c-1c4f-4e54-9290-7e7cc9959e24,DISK], DatanodeInfoWithStorage[127.0.0.1:33645,DS-a61362d0-61d2-42bd-8fe6-5f90fd2a9b15,DISK], DatanodeInfoWithStorage[127.0.0.1:42388,DS-7dd0edbf-bc10-4dbf-9f58-8a0141214be5,DISK], DatanodeInfoWithStorage[127.0.0.1:44822,DS-67b4d665-1a71-49c1-b1ca-447d06009017,DISK], DatanodeInfoWithStorage[127.0.0.1:40431,DS-4fd44925-1eca-4001-b72d-7e343f11e4a5,DISK], DatanodeInfoWithStorage[127.0.0.1:45706,DS-78a0ecf1-1cf8-4256-9cd4-9e8b70f839de,DISK], DatanodeInfoWithStorage[127.0.0.1:39815,DS-f3a040b3-2fb2-448b-af73-6701ad36a024,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1422398007-172.17.0.20-1598145328500:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39600,DS-32c82610-b42e-40b1-9cb3-9125336dc8dc,DISK], DatanodeInfoWithStorage[127.0.0.1:41916,DS-87a7274f-ba00-45a6-a82d-b5ab8aa30342,DISK], DatanodeInfoWithStorage[127.0.0.1:37248,DS-f96aa6c8-1ab2-40cb-a188-e31bbc4ce053,DISK], DatanodeInfoWithStorage[127.0.0.1:34150,DS-f25da36c-b7f4-45d1-9e3f-6506b9b0af35,DISK], DatanodeInfoWithStorage[127.0.0.1:36020,DS-bc428d92-5ed0-4889-8cde-5bce2af0882f,DISK], DatanodeInfoWithStorage[127.0.0.1:45166,DS-3147e6f2-3e97-4533-a791-7bc9da692cff,DISK], DatanodeInfoWithStorage[127.0.0.1:40758,DS-e909b6ca-4d26-4c05-a433-32f0dc13a691,DISK], DatanodeInfoWithStorage[127.0.0.1:45059,DS-0fe12619-02f9-478f-a56e-2d499b4da4a9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1422398007-172.17.0.20-1598145328500:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39600,DS-32c82610-b42e-40b1-9cb3-9125336dc8dc,DISK], DatanodeInfoWithStorage[127.0.0.1:41916,DS-87a7274f-ba00-45a6-a82d-b5ab8aa30342,DISK], DatanodeInfoWithStorage[127.0.0.1:37248,DS-f96aa6c8-1ab2-40cb-a188-e31bbc4ce053,DISK], DatanodeInfoWithStorage[127.0.0.1:34150,DS-f25da36c-b7f4-45d1-9e3f-6506b9b0af35,DISK], DatanodeInfoWithStorage[127.0.0.1:36020,DS-bc428d92-5ed0-4889-8cde-5bce2af0882f,DISK], DatanodeInfoWithStorage[127.0.0.1:45166,DS-3147e6f2-3e97-4533-a791-7bc9da692cff,DISK], DatanodeInfoWithStorage[127.0.0.1:40758,DS-e909b6ca-4d26-4c05-a433-32f0dc13a691,DISK], DatanodeInfoWithStorage[127.0.0.1:45059,DS-0fe12619-02f9-478f-a56e-2d499b4da4a9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-855777126-172.17.0.20-1598145447996:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45209,DS-f2ecc8cb-2b73-433d-bcb4-e2819061b228,DISK], DatanodeInfoWithStorage[127.0.0.1:38710,DS-d0ce8e49-8ce3-4523-a6f5-9ce75bcf91ce,DISK], DatanodeInfoWithStorage[127.0.0.1:44677,DS-6d2df569-6f96-43f0-88b1-fe92b2c6cd3c,DISK], DatanodeInfoWithStorage[127.0.0.1:40392,DS-408ff312-bfa4-4f1d-8b13-dc17c44368e0,DISK], DatanodeInfoWithStorage[127.0.0.1:36227,DS-19e169d4-68b8-44e1-a69a-3455415d6f62,DISK], DatanodeInfoWithStorage[127.0.0.1:39042,DS-13fcf0cf-20d5-4853-9c21-1e80705bfab5,DISK], DatanodeInfoWithStorage[127.0.0.1:36719,DS-6336a4ce-2e52-4b4f-89cb-6b3ea5fc7314,DISK], DatanodeInfoWithStorage[127.0.0.1:40742,DS-6f55f1cf-477c-4429-b6f7-57600940ff1b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-855777126-172.17.0.20-1598145447996:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45209,DS-f2ecc8cb-2b73-433d-bcb4-e2819061b228,DISK], DatanodeInfoWithStorage[127.0.0.1:38710,DS-d0ce8e49-8ce3-4523-a6f5-9ce75bcf91ce,DISK], DatanodeInfoWithStorage[127.0.0.1:44677,DS-6d2df569-6f96-43f0-88b1-fe92b2c6cd3c,DISK], DatanodeInfoWithStorage[127.0.0.1:40392,DS-408ff312-bfa4-4f1d-8b13-dc17c44368e0,DISK], DatanodeInfoWithStorage[127.0.0.1:36227,DS-19e169d4-68b8-44e1-a69a-3455415d6f62,DISK], DatanodeInfoWithStorage[127.0.0.1:39042,DS-13fcf0cf-20d5-4853-9c21-1e80705bfab5,DISK], DatanodeInfoWithStorage[127.0.0.1:36719,DS-6336a4ce-2e52-4b4f-89cb-6b3ea5fc7314,DISK], DatanodeInfoWithStorage[127.0.0.1:40742,DS-6f55f1cf-477c-4429-b6f7-57600940ff1b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1312901448-172.17.0.20-1598145711067:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43002,DS-1038b291-7ec3-4c88-90f1-a17a2b509a35,DISK], DatanodeInfoWithStorage[127.0.0.1:45958,DS-a5a326ef-49a5-4b4a-922d-ee9d4cb0fb7c,DISK], DatanodeInfoWithStorage[127.0.0.1:45700,DS-1266a569-5cca-4a38-a2b1-4d18099ec89d,DISK], DatanodeInfoWithStorage[127.0.0.1:34211,DS-aedeb2ce-edff-47d6-8f48-5764c165c8aa,DISK], DatanodeInfoWithStorage[127.0.0.1:39611,DS-8d2622b6-114e-4638-8725-65ff6fc8e518,DISK], DatanodeInfoWithStorage[127.0.0.1:46383,DS-69933583-21ea-4246-b389-9e210aefb93e,DISK], DatanodeInfoWithStorage[127.0.0.1:38891,DS-1800562d-2fd4-4ca9-a77d-e39bcdc3cf45,DISK], DatanodeInfoWithStorage[127.0.0.1:45916,DS-9c13f34f-6d81-4bd4-9034-950472f08837,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1312901448-172.17.0.20-1598145711067:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43002,DS-1038b291-7ec3-4c88-90f1-a17a2b509a35,DISK], DatanodeInfoWithStorage[127.0.0.1:45958,DS-a5a326ef-49a5-4b4a-922d-ee9d4cb0fb7c,DISK], DatanodeInfoWithStorage[127.0.0.1:45700,DS-1266a569-5cca-4a38-a2b1-4d18099ec89d,DISK], DatanodeInfoWithStorage[127.0.0.1:34211,DS-aedeb2ce-edff-47d6-8f48-5764c165c8aa,DISK], DatanodeInfoWithStorage[127.0.0.1:39611,DS-8d2622b6-114e-4638-8725-65ff6fc8e518,DISK], DatanodeInfoWithStorage[127.0.0.1:46383,DS-69933583-21ea-4246-b389-9e210aefb93e,DISK], DatanodeInfoWithStorage[127.0.0.1:38891,DS-1800562d-2fd4-4ca9-a77d-e39bcdc3cf45,DISK], DatanodeInfoWithStorage[127.0.0.1:45916,DS-9c13f34f-6d81-4bd4-9034-950472f08837,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-88127862-172.17.0.20-1598145782093:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34122,DS-2601476d-1c5b-4c90-b9dc-cec84cfff483,DISK], DatanodeInfoWithStorage[127.0.0.1:46764,DS-898cc7d8-3e30-4530-9ab8-218eaed7ecb2,DISK], DatanodeInfoWithStorage[127.0.0.1:35522,DS-fb3ad257-fed7-413c-99eb-c452f146cdd9,DISK], DatanodeInfoWithStorage[127.0.0.1:45312,DS-8fa06788-8e08-4a10-a773-768d2816ac27,DISK], DatanodeInfoWithStorage[127.0.0.1:38053,DS-4a98fb85-39b4-4062-b3a2-be70ae2fa8e3,DISK], DatanodeInfoWithStorage[127.0.0.1:44449,DS-55153b04-1e4a-44cf-91f7-f886ecfc6152,DISK], DatanodeInfoWithStorage[127.0.0.1:46095,DS-af502238-1d3b-42ee-9ef0-1faa117cdd24,DISK], DatanodeInfoWithStorage[127.0.0.1:41807,DS-f2ede2ae-5e8c-45d3-bb1b-92770d4748db,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-88127862-172.17.0.20-1598145782093:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34122,DS-2601476d-1c5b-4c90-b9dc-cec84cfff483,DISK], DatanodeInfoWithStorage[127.0.0.1:46764,DS-898cc7d8-3e30-4530-9ab8-218eaed7ecb2,DISK], DatanodeInfoWithStorage[127.0.0.1:35522,DS-fb3ad257-fed7-413c-99eb-c452f146cdd9,DISK], DatanodeInfoWithStorage[127.0.0.1:45312,DS-8fa06788-8e08-4a10-a773-768d2816ac27,DISK], DatanodeInfoWithStorage[127.0.0.1:38053,DS-4a98fb85-39b4-4062-b3a2-be70ae2fa8e3,DISK], DatanodeInfoWithStorage[127.0.0.1:44449,DS-55153b04-1e4a-44cf-91f7-f886ecfc6152,DISK], DatanodeInfoWithStorage[127.0.0.1:46095,DS-af502238-1d3b-42ee-9ef0-1faa117cdd24,DISK], DatanodeInfoWithStorage[127.0.0.1:41807,DS-f2ede2ae-5e8c-45d3-bb1b-92770d4748db,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-256296030-172.17.0.20-1598145867430:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34280,DS-76d4a0c7-1c22-432d-a91d-144e60fbb60a,DISK], DatanodeInfoWithStorage[127.0.0.1:33096,DS-91221b58-4b62-4a1e-afab-fd9937866ba3,DISK], DatanodeInfoWithStorage[127.0.0.1:35082,DS-d670f9d8-2f27-4ca2-be3e-ec07a8796db4,DISK], DatanodeInfoWithStorage[127.0.0.1:41377,DS-d9002dd9-641b-4701-978f-a421f42a9a79,DISK], DatanodeInfoWithStorage[127.0.0.1:41660,DS-de9300c6-fe60-4a42-b030-ac32f6a769e5,DISK], DatanodeInfoWithStorage[127.0.0.1:45544,DS-10897204-287d-4b9d-b183-d2e5bd39ee2c,DISK], DatanodeInfoWithStorage[127.0.0.1:36965,DS-542553f4-ae9b-4ac2-8371-950281fc2948,DISK], DatanodeInfoWithStorage[127.0.0.1:45783,DS-c59afc41-e2f2-447a-850a-d657cec2126e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-256296030-172.17.0.20-1598145867430:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34280,DS-76d4a0c7-1c22-432d-a91d-144e60fbb60a,DISK], DatanodeInfoWithStorage[127.0.0.1:33096,DS-91221b58-4b62-4a1e-afab-fd9937866ba3,DISK], DatanodeInfoWithStorage[127.0.0.1:35082,DS-d670f9d8-2f27-4ca2-be3e-ec07a8796db4,DISK], DatanodeInfoWithStorage[127.0.0.1:41377,DS-d9002dd9-641b-4701-978f-a421f42a9a79,DISK], DatanodeInfoWithStorage[127.0.0.1:41660,DS-de9300c6-fe60-4a42-b030-ac32f6a769e5,DISK], DatanodeInfoWithStorage[127.0.0.1:45544,DS-10897204-287d-4b9d-b183-d2e5bd39ee2c,DISK], DatanodeInfoWithStorage[127.0.0.1:36965,DS-542553f4-ae9b-4ac2-8371-950281fc2948,DISK], DatanodeInfoWithStorage[127.0.0.1:45783,DS-c59afc41-e2f2-447a-850a-d657cec2126e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-845134660-172.17.0.20-1598145901975:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39000,DS-82f2bb99-d91d-4b6d-a6b8-e896b9907683,DISK], DatanodeInfoWithStorage[127.0.0.1:38991,DS-3fc523d7-8ace-47b5-ab92-0db30584eb71,DISK], DatanodeInfoWithStorage[127.0.0.1:46237,DS-fb06b5ff-8c25-4eb2-ade0-6a4721eebb04,DISK], DatanodeInfoWithStorage[127.0.0.1:36808,DS-2259d09d-4f54-4ce2-8e10-572cbdbddc8e,DISK], DatanodeInfoWithStorage[127.0.0.1:44647,DS-92df6c96-e136-4c13-9303-0f8e04f60d73,DISK], DatanodeInfoWithStorage[127.0.0.1:35746,DS-533a89db-01d4-4dc1-9843-9cf09e1a05dc,DISK], DatanodeInfoWithStorage[127.0.0.1:42323,DS-bc2df4c8-44d5-46b4-ae72-ccf10354c58e,DISK], DatanodeInfoWithStorage[127.0.0.1:43561,DS-8b530047-b89d-41d0-ae2a-4ff9a9976be9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-845134660-172.17.0.20-1598145901975:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39000,DS-82f2bb99-d91d-4b6d-a6b8-e896b9907683,DISK], DatanodeInfoWithStorage[127.0.0.1:38991,DS-3fc523d7-8ace-47b5-ab92-0db30584eb71,DISK], DatanodeInfoWithStorage[127.0.0.1:46237,DS-fb06b5ff-8c25-4eb2-ade0-6a4721eebb04,DISK], DatanodeInfoWithStorage[127.0.0.1:36808,DS-2259d09d-4f54-4ce2-8e10-572cbdbddc8e,DISK], DatanodeInfoWithStorage[127.0.0.1:44647,DS-92df6c96-e136-4c13-9303-0f8e04f60d73,DISK], DatanodeInfoWithStorage[127.0.0.1:35746,DS-533a89db-01d4-4dc1-9843-9cf09e1a05dc,DISK], DatanodeInfoWithStorage[127.0.0.1:42323,DS-bc2df4c8-44d5-46b4-ae72-ccf10354c58e,DISK], DatanodeInfoWithStorage[127.0.0.1:43561,DS-8b530047-b89d-41d0-ae2a-4ff9a9976be9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1268307985-172.17.0.20-1598146065779:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45283,DS-b71017cc-0d86-4af0-8734-561721d82469,DISK], DatanodeInfoWithStorage[127.0.0.1:40338,DS-3e76c888-6092-490a-a8eb-9caf2068139a,DISK], DatanodeInfoWithStorage[127.0.0.1:40053,DS-ad5a56ef-1723-4fe7-b6ee-a4ed9b9c9d2f,DISK], DatanodeInfoWithStorage[127.0.0.1:46713,DS-0c621035-6fc1-4127-a739-913d87189fdc,DISK], DatanodeInfoWithStorage[127.0.0.1:40630,DS-bcfac2d8-450b-4f7d-b4c8-7f0ce05090db,DISK], DatanodeInfoWithStorage[127.0.0.1:45795,DS-018466e4-b237-416b-ad61-afcee39eb261,DISK], DatanodeInfoWithStorage[127.0.0.1:42446,DS-f04f6765-cd3c-47f9-83f7-276e800a0878,DISK], DatanodeInfoWithStorage[127.0.0.1:41791,DS-0651b9ea-4111-46ea-bbc9-75795d8e227a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1268307985-172.17.0.20-1598146065779:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45283,DS-b71017cc-0d86-4af0-8734-561721d82469,DISK], DatanodeInfoWithStorage[127.0.0.1:40338,DS-3e76c888-6092-490a-a8eb-9caf2068139a,DISK], DatanodeInfoWithStorage[127.0.0.1:40053,DS-ad5a56ef-1723-4fe7-b6ee-a4ed9b9c9d2f,DISK], DatanodeInfoWithStorage[127.0.0.1:46713,DS-0c621035-6fc1-4127-a739-913d87189fdc,DISK], DatanodeInfoWithStorage[127.0.0.1:40630,DS-bcfac2d8-450b-4f7d-b4c8-7f0ce05090db,DISK], DatanodeInfoWithStorage[127.0.0.1:45795,DS-018466e4-b237-416b-ad61-afcee39eb261,DISK], DatanodeInfoWithStorage[127.0.0.1:42446,DS-f04f6765-cd3c-47f9-83f7-276e800a0878,DISK], DatanodeInfoWithStorage[127.0.0.1:41791,DS-0651b9ea-4111-46ea-bbc9-75795d8e227a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1340385183-172.17.0.20-1598147254265:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46277,DS-8d9bd571-6dbf-4ae5-a14c-cf0e5c54bf04,DISK], DatanodeInfoWithStorage[127.0.0.1:37032,DS-ebd22a58-5530-46c8-8b80-2b3f11c5a82f,DISK], DatanodeInfoWithStorage[127.0.0.1:45664,DS-957b7bec-4780-424a-81ce-c7f63fb40001,DISK], DatanodeInfoWithStorage[127.0.0.1:44225,DS-c233cbca-0ed5-4678-9a36-ae79256c64de,DISK], DatanodeInfoWithStorage[127.0.0.1:44003,DS-f28020bd-ed99-4a4c-848a-9adc78e01029,DISK], DatanodeInfoWithStorage[127.0.0.1:33683,DS-ca41ba73-9867-4f23-8089-a669395cf11b,DISK], DatanodeInfoWithStorage[127.0.0.1:37883,DS-64c6ec03-0c5a-4834-aff9-69e121bc3d97,DISK], DatanodeInfoWithStorage[127.0.0.1:38262,DS-85817707-acd9-4165-96da-df281c682489,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1340385183-172.17.0.20-1598147254265:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46277,DS-8d9bd571-6dbf-4ae5-a14c-cf0e5c54bf04,DISK], DatanodeInfoWithStorage[127.0.0.1:37032,DS-ebd22a58-5530-46c8-8b80-2b3f11c5a82f,DISK], DatanodeInfoWithStorage[127.0.0.1:45664,DS-957b7bec-4780-424a-81ce-c7f63fb40001,DISK], DatanodeInfoWithStorage[127.0.0.1:44225,DS-c233cbca-0ed5-4678-9a36-ae79256c64de,DISK], DatanodeInfoWithStorage[127.0.0.1:44003,DS-f28020bd-ed99-4a4c-848a-9adc78e01029,DISK], DatanodeInfoWithStorage[127.0.0.1:33683,DS-ca41ba73-9867-4f23-8089-a669395cf11b,DISK], DatanodeInfoWithStorage[127.0.0.1:37883,DS-64c6ec03-0c5a-4834-aff9-69e121bc3d97,DISK], DatanodeInfoWithStorage[127.0.0.1:38262,DS-85817707-acd9-4165-96da-df281c682489,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1381947661-172.17.0.20-1598147915594:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46176,DS-faafb2b4-5371-4ffe-b53a-fda5cd2d1068,DISK], DatanodeInfoWithStorage[127.0.0.1:43715,DS-a34e3a00-c6a3-4e7d-9c1d-4cdbbb4847c2,DISK], DatanodeInfoWithStorage[127.0.0.1:42896,DS-f6047b78-11d0-42f1-bff8-3793e026f1dc,DISK], DatanodeInfoWithStorage[127.0.0.1:38139,DS-ac384977-82bb-4c21-b1e0-8981e84cc511,DISK], DatanodeInfoWithStorage[127.0.0.1:34796,DS-9969450c-04f1-4beb-84f3-3e27d5061246,DISK], DatanodeInfoWithStorage[127.0.0.1:38270,DS-cf3df56e-a339-4ff6-89a0-2bf70796ad59,DISK], DatanodeInfoWithStorage[127.0.0.1:41783,DS-caccc1e6-b68a-4b14-a05e-15de5fd8b073,DISK], DatanodeInfoWithStorage[127.0.0.1:36812,DS-6fca77aa-e84c-4abe-9113-d161f9994159,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1381947661-172.17.0.20-1598147915594:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46176,DS-faafb2b4-5371-4ffe-b53a-fda5cd2d1068,DISK], DatanodeInfoWithStorage[127.0.0.1:43715,DS-a34e3a00-c6a3-4e7d-9c1d-4cdbbb4847c2,DISK], DatanodeInfoWithStorage[127.0.0.1:42896,DS-f6047b78-11d0-42f1-bff8-3793e026f1dc,DISK], DatanodeInfoWithStorage[127.0.0.1:38139,DS-ac384977-82bb-4c21-b1e0-8981e84cc511,DISK], DatanodeInfoWithStorage[127.0.0.1:34796,DS-9969450c-04f1-4beb-84f3-3e27d5061246,DISK], DatanodeInfoWithStorage[127.0.0.1:38270,DS-cf3df56e-a339-4ff6-89a0-2bf70796ad59,DISK], DatanodeInfoWithStorage[127.0.0.1:41783,DS-caccc1e6-b68a-4b14-a05e-15de5fd8b073,DISK], DatanodeInfoWithStorage[127.0.0.1:36812,DS-6fca77aa-e84c-4abe-9113-d161f9994159,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1450941529-172.17.0.20-1598148253179:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37275,DS-03a8e655-42b5-4356-ad36-4680a5fc3b13,DISK], DatanodeInfoWithStorage[127.0.0.1:39164,DS-3f8c90e5-817c-41c6-86e6-e0d1a676842e,DISK], DatanodeInfoWithStorage[127.0.0.1:40871,DS-69d0445f-d4cd-403f-a901-c48042360564,DISK], DatanodeInfoWithStorage[127.0.0.1:33859,DS-ffc6e8b9-0750-4899-9402-5c4b96c4627e,DISK], DatanodeInfoWithStorage[127.0.0.1:44102,DS-831f54cf-b6da-44cb-a61f-c904a4edf66e,DISK], DatanodeInfoWithStorage[127.0.0.1:43075,DS-7ac3576e-b34f-459d-bb22-3d99d3967958,DISK], DatanodeInfoWithStorage[127.0.0.1:44096,DS-d6de5d31-9c30-440e-94ca-2156c277f4fd,DISK], DatanodeInfoWithStorage[127.0.0.1:37565,DS-7482cc35-eba9-4405-add7-dc47ffe73d9a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1450941529-172.17.0.20-1598148253179:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37275,DS-03a8e655-42b5-4356-ad36-4680a5fc3b13,DISK], DatanodeInfoWithStorage[127.0.0.1:39164,DS-3f8c90e5-817c-41c6-86e6-e0d1a676842e,DISK], DatanodeInfoWithStorage[127.0.0.1:40871,DS-69d0445f-d4cd-403f-a901-c48042360564,DISK], DatanodeInfoWithStorage[127.0.0.1:33859,DS-ffc6e8b9-0750-4899-9402-5c4b96c4627e,DISK], DatanodeInfoWithStorage[127.0.0.1:44102,DS-831f54cf-b6da-44cb-a61f-c904a4edf66e,DISK], DatanodeInfoWithStorage[127.0.0.1:43075,DS-7ac3576e-b34f-459d-bb22-3d99d3967958,DISK], DatanodeInfoWithStorage[127.0.0.1:44096,DS-d6de5d31-9c30-440e-94ca-2156c277f4fd,DISK], DatanodeInfoWithStorage[127.0.0.1:37565,DS-7482cc35-eba9-4405-add7-dc47ffe73d9a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-594906879-172.17.0.20-1598148605606:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37425,DS-f148febc-c99c-4d34-9d81-6fbd94307542,DISK], DatanodeInfoWithStorage[127.0.0.1:41469,DS-ceac4420-624e-44a1-ad0c-d7864e0ff411,DISK], DatanodeInfoWithStorage[127.0.0.1:33113,DS-290df4bd-6057-4dde-ad7d-e4c304923638,DISK], DatanodeInfoWithStorage[127.0.0.1:35910,DS-e1c7b915-6599-4c1f-bbae-853e6d09feed,DISK], DatanodeInfoWithStorage[127.0.0.1:44171,DS-69db021d-9c20-4c69-b9a4-e5fdfe3ebcf8,DISK], DatanodeInfoWithStorage[127.0.0.1:38284,DS-7abf06ac-f71c-493a-9eea-8276a94c813a,DISK], DatanodeInfoWithStorage[127.0.0.1:36180,DS-6199d744-7fad-4517-9245-00e858f1f0e8,DISK], DatanodeInfoWithStorage[127.0.0.1:34187,DS-d1c4f86a-c9e8-4895-83e3-e38548c6ae8e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-594906879-172.17.0.20-1598148605606:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37425,DS-f148febc-c99c-4d34-9d81-6fbd94307542,DISK], DatanodeInfoWithStorage[127.0.0.1:41469,DS-ceac4420-624e-44a1-ad0c-d7864e0ff411,DISK], DatanodeInfoWithStorage[127.0.0.1:33113,DS-290df4bd-6057-4dde-ad7d-e4c304923638,DISK], DatanodeInfoWithStorage[127.0.0.1:35910,DS-e1c7b915-6599-4c1f-bbae-853e6d09feed,DISK], DatanodeInfoWithStorage[127.0.0.1:44171,DS-69db021d-9c20-4c69-b9a4-e5fdfe3ebcf8,DISK], DatanodeInfoWithStorage[127.0.0.1:38284,DS-7abf06ac-f71c-493a-9eea-8276a94c813a,DISK], DatanodeInfoWithStorage[127.0.0.1:36180,DS-6199d744-7fad-4517-9245-00e858f1f0e8,DISK], DatanodeInfoWithStorage[127.0.0.1:34187,DS-d1c4f86a-c9e8-4895-83e3-e38548c6ae8e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-549285773-172.17.0.20-1598148985743:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35617,DS-47d695ae-4f89-4487-bd4e-e552e6c931e5,DISK], DatanodeInfoWithStorage[127.0.0.1:45666,DS-711503f4-57f6-4b3d-9420-1a1a788594cc,DISK], DatanodeInfoWithStorage[127.0.0.1:45915,DS-df03181d-cf7d-4159-90e7-a1ef6c4f41a4,DISK], DatanodeInfoWithStorage[127.0.0.1:36777,DS-bda11c84-72b3-4545-a37f-02710a74ac64,DISK], DatanodeInfoWithStorage[127.0.0.1:38940,DS-98cc1eba-34ae-4b75-9df5-a448ec629fca,DISK], DatanodeInfoWithStorage[127.0.0.1:41087,DS-b98c9a8b-a355-499e-a691-5a89a2ba9c2e,DISK], DatanodeInfoWithStorage[127.0.0.1:43636,DS-b398eb68-fcfd-4b70-9c09-be1b7e8ae0dd,DISK], DatanodeInfoWithStorage[127.0.0.1:35364,DS-31fdd81c-f435-4d6b-8c09-9a24b642a16c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-549285773-172.17.0.20-1598148985743:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35617,DS-47d695ae-4f89-4487-bd4e-e552e6c931e5,DISK], DatanodeInfoWithStorage[127.0.0.1:45666,DS-711503f4-57f6-4b3d-9420-1a1a788594cc,DISK], DatanodeInfoWithStorage[127.0.0.1:45915,DS-df03181d-cf7d-4159-90e7-a1ef6c4f41a4,DISK], DatanodeInfoWithStorage[127.0.0.1:36777,DS-bda11c84-72b3-4545-a37f-02710a74ac64,DISK], DatanodeInfoWithStorage[127.0.0.1:38940,DS-98cc1eba-34ae-4b75-9df5-a448ec629fca,DISK], DatanodeInfoWithStorage[127.0.0.1:41087,DS-b98c9a8b-a355-499e-a691-5a89a2ba9c2e,DISK], DatanodeInfoWithStorage[127.0.0.1:43636,DS-b398eb68-fcfd-4b70-9c09-be1b7e8ae0dd,DISK], DatanodeInfoWithStorage[127.0.0.1:35364,DS-31fdd81c-f435-4d6b-8c09-9a24b642a16c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5854
