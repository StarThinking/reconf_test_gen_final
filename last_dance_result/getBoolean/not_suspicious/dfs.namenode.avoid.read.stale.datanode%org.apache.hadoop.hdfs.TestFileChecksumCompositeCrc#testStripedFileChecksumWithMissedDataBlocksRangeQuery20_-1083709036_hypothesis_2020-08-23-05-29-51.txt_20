reconf_parameter: dfs.namenode.avoid.read.stale.datanode
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.avoid.read.stale.datanode
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1347850878-172.17.0.6-1598161985167:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35732,DS-1da344e6-c7f9-472a-af13-ac0619e91e7d,DISK], DatanodeInfoWithStorage[127.0.0.1:42483,DS-fb490b41-43c5-496a-a87c-54a25ea010be,DISK], DatanodeInfoWithStorage[127.0.0.1:39656,DS-5ff5e26b-ca6e-45df-b8e1-03d280433c4c,DISK], DatanodeInfoWithStorage[127.0.0.1:40672,DS-7fbc1ca1-ea4d-4bbd-a620-441e70f5c589,DISK], DatanodeInfoWithStorage[127.0.0.1:41984,DS-2280a70d-41c6-4ff5-803b-1b498209d4ac,DISK], DatanodeInfoWithStorage[127.0.0.1:38667,DS-4ea543ab-b089-425f-98ee-f45e57bca918,DISK], DatanodeInfoWithStorage[127.0.0.1:33004,DS-38c660d9-c721-4e7d-8017-b08c03768243,DISK], DatanodeInfoWithStorage[127.0.0.1:40893,DS-3f5fafeb-f0d9-4fa7-b176-f443cdde6448,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1347850878-172.17.0.6-1598161985167:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35732,DS-1da344e6-c7f9-472a-af13-ac0619e91e7d,DISK], DatanodeInfoWithStorage[127.0.0.1:42483,DS-fb490b41-43c5-496a-a87c-54a25ea010be,DISK], DatanodeInfoWithStorage[127.0.0.1:39656,DS-5ff5e26b-ca6e-45df-b8e1-03d280433c4c,DISK], DatanodeInfoWithStorage[127.0.0.1:40672,DS-7fbc1ca1-ea4d-4bbd-a620-441e70f5c589,DISK], DatanodeInfoWithStorage[127.0.0.1:41984,DS-2280a70d-41c6-4ff5-803b-1b498209d4ac,DISK], DatanodeInfoWithStorage[127.0.0.1:38667,DS-4ea543ab-b089-425f-98ee-f45e57bca918,DISK], DatanodeInfoWithStorage[127.0.0.1:33004,DS-38c660d9-c721-4e7d-8017-b08c03768243,DISK], DatanodeInfoWithStorage[127.0.0.1:40893,DS-3f5fafeb-f0d9-4fa7-b176-f443cdde6448,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.avoid.read.stale.datanode
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-27998793-172.17.0.6-1598162499777:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38548,DS-5ed8063e-4907-4645-83b1-c08577948942,DISK], DatanodeInfoWithStorage[127.0.0.1:42926,DS-15eb3d08-8ac7-4999-af45-10c5efe2a024,DISK], DatanodeInfoWithStorage[127.0.0.1:44329,DS-165b6e72-0f2b-47f0-bf4d-ad19151cb1ff,DISK], DatanodeInfoWithStorage[127.0.0.1:43246,DS-74f5c45d-0704-49b5-92bb-8fb19021d583,DISK], DatanodeInfoWithStorage[127.0.0.1:38435,DS-da265930-5374-4a9b-94cf-ef674aa601d7,DISK], DatanodeInfoWithStorage[127.0.0.1:34472,DS-2723daf4-0290-4b08-a201-0159d0747774,DISK], DatanodeInfoWithStorage[127.0.0.1:45079,DS-06ffe018-124c-4366-8507-a76014850f02,DISK], DatanodeInfoWithStorage[127.0.0.1:41631,DS-78126923-271e-4803-ab57-3cfd5fae469a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-27998793-172.17.0.6-1598162499777:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38548,DS-5ed8063e-4907-4645-83b1-c08577948942,DISK], DatanodeInfoWithStorage[127.0.0.1:42926,DS-15eb3d08-8ac7-4999-af45-10c5efe2a024,DISK], DatanodeInfoWithStorage[127.0.0.1:44329,DS-165b6e72-0f2b-47f0-bf4d-ad19151cb1ff,DISK], DatanodeInfoWithStorage[127.0.0.1:43246,DS-74f5c45d-0704-49b5-92bb-8fb19021d583,DISK], DatanodeInfoWithStorage[127.0.0.1:38435,DS-da265930-5374-4a9b-94cf-ef674aa601d7,DISK], DatanodeInfoWithStorage[127.0.0.1:34472,DS-2723daf4-0290-4b08-a201-0159d0747774,DISK], DatanodeInfoWithStorage[127.0.0.1:45079,DS-06ffe018-124c-4366-8507-a76014850f02,DISK], DatanodeInfoWithStorage[127.0.0.1:41631,DS-78126923-271e-4803-ab57-3cfd5fae469a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.avoid.read.stale.datanode
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1430663685-172.17.0.6-1598163018571:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37593,DS-de81de5d-373c-4c80-aa91-2d0d45137e35,DISK], DatanodeInfoWithStorage[127.0.0.1:41201,DS-f854cfab-65ca-45c2-9157-6b8bf25f0a37,DISK], DatanodeInfoWithStorage[127.0.0.1:44463,DS-1f5ca803-a774-4ac5-937e-221cefc8feee,DISK], DatanodeInfoWithStorage[127.0.0.1:35749,DS-1439159f-78fe-4814-a132-b99d087abd6d,DISK], DatanodeInfoWithStorage[127.0.0.1:41085,DS-ad84d573-6197-4e6a-8fee-53302c830ef1,DISK], DatanodeInfoWithStorage[127.0.0.1:41126,DS-bd8715fa-1123-4b5f-8766-2c62210f8cde,DISK], DatanodeInfoWithStorage[127.0.0.1:35599,DS-49f81548-49e5-441d-99c5-1948399f2d44,DISK], DatanodeInfoWithStorage[127.0.0.1:33089,DS-a0da453c-dd37-49f3-a507-58d33c38be4c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1430663685-172.17.0.6-1598163018571:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37593,DS-de81de5d-373c-4c80-aa91-2d0d45137e35,DISK], DatanodeInfoWithStorage[127.0.0.1:41201,DS-f854cfab-65ca-45c2-9157-6b8bf25f0a37,DISK], DatanodeInfoWithStorage[127.0.0.1:44463,DS-1f5ca803-a774-4ac5-937e-221cefc8feee,DISK], DatanodeInfoWithStorage[127.0.0.1:35749,DS-1439159f-78fe-4814-a132-b99d087abd6d,DISK], DatanodeInfoWithStorage[127.0.0.1:41085,DS-ad84d573-6197-4e6a-8fee-53302c830ef1,DISK], DatanodeInfoWithStorage[127.0.0.1:41126,DS-bd8715fa-1123-4b5f-8766-2c62210f8cde,DISK], DatanodeInfoWithStorage[127.0.0.1:35599,DS-49f81548-49e5-441d-99c5-1948399f2d44,DISK], DatanodeInfoWithStorage[127.0.0.1:33089,DS-a0da453c-dd37-49f3-a507-58d33c38be4c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.avoid.read.stale.datanode
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-789778531-172.17.0.6-1598163646472:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33785,DS-db560a21-6b50-4a54-967b-e8152a433ea9,DISK], DatanodeInfoWithStorage[127.0.0.1:46265,DS-69b66816-d6c7-4061-ba7e-744b6f31f2fb,DISK], DatanodeInfoWithStorage[127.0.0.1:35314,DS-48c46abe-9e8d-4c75-8181-1af251bea12a,DISK], DatanodeInfoWithStorage[127.0.0.1:40357,DS-24764754-e4a7-4d0a-b05a-9d9d6191c684,DISK], DatanodeInfoWithStorage[127.0.0.1:41212,DS-a5d17919-bdd4-44e9-974a-c83df44e87a7,DISK], DatanodeInfoWithStorage[127.0.0.1:36372,DS-48f61bcd-2dc4-479e-b017-56faadd5ec54,DISK], DatanodeInfoWithStorage[127.0.0.1:42287,DS-fa24bb3e-f245-4f8c-ac92-88c6dc219ca9,DISK], DatanodeInfoWithStorage[127.0.0.1:42153,DS-16b9152f-616a-46a7-85e4-ee2112c52dc4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-789778531-172.17.0.6-1598163646472:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33785,DS-db560a21-6b50-4a54-967b-e8152a433ea9,DISK], DatanodeInfoWithStorage[127.0.0.1:46265,DS-69b66816-d6c7-4061-ba7e-744b6f31f2fb,DISK], DatanodeInfoWithStorage[127.0.0.1:35314,DS-48c46abe-9e8d-4c75-8181-1af251bea12a,DISK], DatanodeInfoWithStorage[127.0.0.1:40357,DS-24764754-e4a7-4d0a-b05a-9d9d6191c684,DISK], DatanodeInfoWithStorage[127.0.0.1:41212,DS-a5d17919-bdd4-44e9-974a-c83df44e87a7,DISK], DatanodeInfoWithStorage[127.0.0.1:36372,DS-48f61bcd-2dc4-479e-b017-56faadd5ec54,DISK], DatanodeInfoWithStorage[127.0.0.1:42287,DS-fa24bb3e-f245-4f8c-ac92-88c6dc219ca9,DISK], DatanodeInfoWithStorage[127.0.0.1:42153,DS-16b9152f-616a-46a7-85e4-ee2112c52dc4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.avoid.read.stale.datanode
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-168470714-172.17.0.6-1598163881098:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34284,DS-5143e92b-dcec-4101-8eed-ba2f29238db5,DISK], DatanodeInfoWithStorage[127.0.0.1:39633,DS-c60bd54b-a2d3-41df-8633-a2b541e12cf1,DISK], DatanodeInfoWithStorage[127.0.0.1:34180,DS-993d66f4-d1a4-4056-948a-293d54617061,DISK], DatanodeInfoWithStorage[127.0.0.1:36291,DS-96aee339-3293-49ad-b85c-34ced28eb5cd,DISK], DatanodeInfoWithStorage[127.0.0.1:35076,DS-c8d12cd2-4139-4236-b717-55aeb89fbf32,DISK], DatanodeInfoWithStorage[127.0.0.1:39794,DS-da8c78b6-59e2-46c6-9ecb-1d627395fd55,DISK], DatanodeInfoWithStorage[127.0.0.1:42602,DS-df9d351b-48c3-40fb-82c6-4fb0e5825268,DISK], DatanodeInfoWithStorage[127.0.0.1:34668,DS-3625c35a-4055-4023-803c-3c5d4bdb20df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-168470714-172.17.0.6-1598163881098:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34284,DS-5143e92b-dcec-4101-8eed-ba2f29238db5,DISK], DatanodeInfoWithStorage[127.0.0.1:39633,DS-c60bd54b-a2d3-41df-8633-a2b541e12cf1,DISK], DatanodeInfoWithStorage[127.0.0.1:34180,DS-993d66f4-d1a4-4056-948a-293d54617061,DISK], DatanodeInfoWithStorage[127.0.0.1:36291,DS-96aee339-3293-49ad-b85c-34ced28eb5cd,DISK], DatanodeInfoWithStorage[127.0.0.1:35076,DS-c8d12cd2-4139-4236-b717-55aeb89fbf32,DISK], DatanodeInfoWithStorage[127.0.0.1:39794,DS-da8c78b6-59e2-46c6-9ecb-1d627395fd55,DISK], DatanodeInfoWithStorage[127.0.0.1:42602,DS-df9d351b-48c3-40fb-82c6-4fb0e5825268,DISK], DatanodeInfoWithStorage[127.0.0.1:34668,DS-3625c35a-4055-4023-803c-3c5d4bdb20df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.avoid.read.stale.datanode
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2088517295-172.17.0.6-1598163924101:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43860,DS-1bee7261-0a57-44f8-9251-88afe12377ad,DISK], DatanodeInfoWithStorage[127.0.0.1:40174,DS-e46ee907-180a-414c-80c7-27174f163da3,DISK], DatanodeInfoWithStorage[127.0.0.1:42687,DS-3945c0ac-bac0-470d-8a4e-b4a5a3a77e22,DISK], DatanodeInfoWithStorage[127.0.0.1:37108,DS-92f6c92e-c361-4cd6-828b-106ebafe7b6e,DISK], DatanodeInfoWithStorage[127.0.0.1:41382,DS-4f25a6c8-30cc-441d-825e-0fed7c64bbb9,DISK], DatanodeInfoWithStorage[127.0.0.1:40210,DS-173f6c58-d594-4322-9e5c-660c6e3dd8ae,DISK], DatanodeInfoWithStorage[127.0.0.1:42060,DS-44fd4736-2c6e-47f5-9e9c-eca8b9546524,DISK], DatanodeInfoWithStorage[127.0.0.1:38791,DS-91ca638c-0dfe-4532-acd2-05c3838a9c08,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2088517295-172.17.0.6-1598163924101:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43860,DS-1bee7261-0a57-44f8-9251-88afe12377ad,DISK], DatanodeInfoWithStorage[127.0.0.1:40174,DS-e46ee907-180a-414c-80c7-27174f163da3,DISK], DatanodeInfoWithStorage[127.0.0.1:42687,DS-3945c0ac-bac0-470d-8a4e-b4a5a3a77e22,DISK], DatanodeInfoWithStorage[127.0.0.1:37108,DS-92f6c92e-c361-4cd6-828b-106ebafe7b6e,DISK], DatanodeInfoWithStorage[127.0.0.1:41382,DS-4f25a6c8-30cc-441d-825e-0fed7c64bbb9,DISK], DatanodeInfoWithStorage[127.0.0.1:40210,DS-173f6c58-d594-4322-9e5c-660c6e3dd8ae,DISK], DatanodeInfoWithStorage[127.0.0.1:42060,DS-44fd4736-2c6e-47f5-9e9c-eca8b9546524,DISK], DatanodeInfoWithStorage[127.0.0.1:38791,DS-91ca638c-0dfe-4532-acd2-05c3838a9c08,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.avoid.read.stale.datanode
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-596915760-172.17.0.6-1598164007219:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36991,DS-8c727d79-9932-4603-a61b-083878037bbd,DISK], DatanodeInfoWithStorage[127.0.0.1:42405,DS-7624dcc3-7742-4156-a580-84184ac316fe,DISK], DatanodeInfoWithStorage[127.0.0.1:39257,DS-732630b1-f209-489f-ab50-38b4742e9c0a,DISK], DatanodeInfoWithStorage[127.0.0.1:37963,DS-88c15407-cf55-455c-8db1-87e34e9c9f1a,DISK], DatanodeInfoWithStorage[127.0.0.1:43781,DS-571a9578-8580-4c0b-b1c5-43a77c230de4,DISK], DatanodeInfoWithStorage[127.0.0.1:46167,DS-8c50f2d3-fdb0-43c5-9898-962863ece089,DISK], DatanodeInfoWithStorage[127.0.0.1:35271,DS-e74ee89b-077e-4891-9a66-5381ee2bf289,DISK], DatanodeInfoWithStorage[127.0.0.1:37521,DS-9e4c1996-3fb7-4642-acf0-24fbad8d6692,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-596915760-172.17.0.6-1598164007219:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36991,DS-8c727d79-9932-4603-a61b-083878037bbd,DISK], DatanodeInfoWithStorage[127.0.0.1:42405,DS-7624dcc3-7742-4156-a580-84184ac316fe,DISK], DatanodeInfoWithStorage[127.0.0.1:39257,DS-732630b1-f209-489f-ab50-38b4742e9c0a,DISK], DatanodeInfoWithStorage[127.0.0.1:37963,DS-88c15407-cf55-455c-8db1-87e34e9c9f1a,DISK], DatanodeInfoWithStorage[127.0.0.1:43781,DS-571a9578-8580-4c0b-b1c5-43a77c230de4,DISK], DatanodeInfoWithStorage[127.0.0.1:46167,DS-8c50f2d3-fdb0-43c5-9898-962863ece089,DISK], DatanodeInfoWithStorage[127.0.0.1:35271,DS-e74ee89b-077e-4891-9a66-5381ee2bf289,DISK], DatanodeInfoWithStorage[127.0.0.1:37521,DS-9e4c1996-3fb7-4642-acf0-24fbad8d6692,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.avoid.read.stale.datanode
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1963753151-172.17.0.6-1598164287112:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38099,DS-fe02e6a6-bbc5-4ede-9e8a-801ef6405c46,DISK], DatanodeInfoWithStorage[127.0.0.1:40482,DS-3f51820e-bfa7-4367-a757-6f4bcadddf53,DISK], DatanodeInfoWithStorage[127.0.0.1:39698,DS-8be6aeb8-d8f8-432e-bfc7-c8d52b291829,DISK], DatanodeInfoWithStorage[127.0.0.1:42697,DS-6650fcd5-dc7a-4619-a4d9-8bf4c1bd2ea2,DISK], DatanodeInfoWithStorage[127.0.0.1:39486,DS-dcbe0de0-5900-4150-a5db-f4cc523fe2d3,DISK], DatanodeInfoWithStorage[127.0.0.1:35438,DS-0b667737-c3da-45c1-a001-26007a5aa390,DISK], DatanodeInfoWithStorage[127.0.0.1:35495,DS-1a2f72a8-c91d-444a-86f8-8c1014351d98,DISK], DatanodeInfoWithStorage[127.0.0.1:38311,DS-064cf302-0033-47ba-b38e-1288a90bc52a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1963753151-172.17.0.6-1598164287112:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38099,DS-fe02e6a6-bbc5-4ede-9e8a-801ef6405c46,DISK], DatanodeInfoWithStorage[127.0.0.1:40482,DS-3f51820e-bfa7-4367-a757-6f4bcadddf53,DISK], DatanodeInfoWithStorage[127.0.0.1:39698,DS-8be6aeb8-d8f8-432e-bfc7-c8d52b291829,DISK], DatanodeInfoWithStorage[127.0.0.1:42697,DS-6650fcd5-dc7a-4619-a4d9-8bf4c1bd2ea2,DISK], DatanodeInfoWithStorage[127.0.0.1:39486,DS-dcbe0de0-5900-4150-a5db-f4cc523fe2d3,DISK], DatanodeInfoWithStorage[127.0.0.1:35438,DS-0b667737-c3da-45c1-a001-26007a5aa390,DISK], DatanodeInfoWithStorage[127.0.0.1:35495,DS-1a2f72a8-c91d-444a-86f8-8c1014351d98,DISK], DatanodeInfoWithStorage[127.0.0.1:38311,DS-064cf302-0033-47ba-b38e-1288a90bc52a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.avoid.read.stale.datanode
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1745517845-172.17.0.6-1598164425878:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36760,DS-d71d8d7c-e8c6-4112-aac9-f8ed958e1870,DISK], DatanodeInfoWithStorage[127.0.0.1:44179,DS-d1c022fb-b1b7-4d71-a8b3-d9d186906cf9,DISK], DatanodeInfoWithStorage[127.0.0.1:32910,DS-e127aaeb-fc7b-4288-9126-a181b4af0ba0,DISK], DatanodeInfoWithStorage[127.0.0.1:37968,DS-a44240eb-871b-47f1-af16-0c983eb8864e,DISK], DatanodeInfoWithStorage[127.0.0.1:40899,DS-770daaf3-bb37-4c7b-8734-1d60b56f0710,DISK], DatanodeInfoWithStorage[127.0.0.1:41499,DS-06d9f9de-126c-4b2f-a134-0c9e8c7a9515,DISK], DatanodeInfoWithStorage[127.0.0.1:34561,DS-5cd3193d-e876-4581-a0a7-632a5702b975,DISK], DatanodeInfoWithStorage[127.0.0.1:41684,DS-d53cdd20-b071-4bbc-af0d-da0a1d3df84e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1745517845-172.17.0.6-1598164425878:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36760,DS-d71d8d7c-e8c6-4112-aac9-f8ed958e1870,DISK], DatanodeInfoWithStorage[127.0.0.1:44179,DS-d1c022fb-b1b7-4d71-a8b3-d9d186906cf9,DISK], DatanodeInfoWithStorage[127.0.0.1:32910,DS-e127aaeb-fc7b-4288-9126-a181b4af0ba0,DISK], DatanodeInfoWithStorage[127.0.0.1:37968,DS-a44240eb-871b-47f1-af16-0c983eb8864e,DISK], DatanodeInfoWithStorage[127.0.0.1:40899,DS-770daaf3-bb37-4c7b-8734-1d60b56f0710,DISK], DatanodeInfoWithStorage[127.0.0.1:41499,DS-06d9f9de-126c-4b2f-a134-0c9e8c7a9515,DISK], DatanodeInfoWithStorage[127.0.0.1:34561,DS-5cd3193d-e876-4581-a0a7-632a5702b975,DISK], DatanodeInfoWithStorage[127.0.0.1:41684,DS-d53cdd20-b071-4bbc-af0d-da0a1d3df84e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.avoid.read.stale.datanode
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-110905291-172.17.0.6-1598164646599:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41808,DS-c09432c0-3148-4e08-b21c-f9a9d716993c,DISK], DatanodeInfoWithStorage[127.0.0.1:35791,DS-6e92723c-023e-4606-ba01-0a9101350e4f,DISK], DatanodeInfoWithStorage[127.0.0.1:44277,DS-2e170e9a-7992-444c-87bb-aa1fb40775a2,DISK], DatanodeInfoWithStorage[127.0.0.1:32812,DS-b381123e-97c7-410c-a2d3-e585bd259374,DISK], DatanodeInfoWithStorage[127.0.0.1:43822,DS-1049e888-57f7-4223-a818-e66c939a8140,DISK], DatanodeInfoWithStorage[127.0.0.1:43257,DS-46147960-a1b8-4652-b8f5-8272cc52f6cf,DISK], DatanodeInfoWithStorage[127.0.0.1:37479,DS-f5fe91bc-d3b0-402c-aeb7-77944eac9e9e,DISK], DatanodeInfoWithStorage[127.0.0.1:38828,DS-c45589ec-02f8-4c57-8dc7-204adfa0a833,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-110905291-172.17.0.6-1598164646599:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41808,DS-c09432c0-3148-4e08-b21c-f9a9d716993c,DISK], DatanodeInfoWithStorage[127.0.0.1:35791,DS-6e92723c-023e-4606-ba01-0a9101350e4f,DISK], DatanodeInfoWithStorage[127.0.0.1:44277,DS-2e170e9a-7992-444c-87bb-aa1fb40775a2,DISK], DatanodeInfoWithStorage[127.0.0.1:32812,DS-b381123e-97c7-410c-a2d3-e585bd259374,DISK], DatanodeInfoWithStorage[127.0.0.1:43822,DS-1049e888-57f7-4223-a818-e66c939a8140,DISK], DatanodeInfoWithStorage[127.0.0.1:43257,DS-46147960-a1b8-4652-b8f5-8272cc52f6cf,DISK], DatanodeInfoWithStorage[127.0.0.1:37479,DS-f5fe91bc-d3b0-402c-aeb7-77944eac9e9e,DISK], DatanodeInfoWithStorage[127.0.0.1:38828,DS-c45589ec-02f8-4c57-8dc7-204adfa0a833,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.avoid.read.stale.datanode
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1815908716-172.17.0.6-1598164781297:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46253,DS-17f224f1-acad-4af2-badf-637f97f61eb7,DISK], DatanodeInfoWithStorage[127.0.0.1:35100,DS-10b8f46a-da2a-48bf-b1b7-58d62344b9dc,DISK], DatanodeInfoWithStorage[127.0.0.1:44609,DS-a2477c76-53f5-47b8-b0c4-504a64aeed43,DISK], DatanodeInfoWithStorage[127.0.0.1:45932,DS-9e7b1c83-d9a3-4c99-93db-44a83615c4a7,DISK], DatanodeInfoWithStorage[127.0.0.1:39664,DS-c1beb2b6-4b93-49d7-b13c-cc7f56a8d0b6,DISK], DatanodeInfoWithStorage[127.0.0.1:44327,DS-77565ff2-92e2-4565-a15a-708cecf04fe9,DISK], DatanodeInfoWithStorage[127.0.0.1:35166,DS-e8a6057e-dbe2-4747-bc4c-1b629d20fe81,DISK], DatanodeInfoWithStorage[127.0.0.1:38262,DS-86f6e20b-6009-4b50-b57e-e13ccf6ac69c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1815908716-172.17.0.6-1598164781297:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46253,DS-17f224f1-acad-4af2-badf-637f97f61eb7,DISK], DatanodeInfoWithStorage[127.0.0.1:35100,DS-10b8f46a-da2a-48bf-b1b7-58d62344b9dc,DISK], DatanodeInfoWithStorage[127.0.0.1:44609,DS-a2477c76-53f5-47b8-b0c4-504a64aeed43,DISK], DatanodeInfoWithStorage[127.0.0.1:45932,DS-9e7b1c83-d9a3-4c99-93db-44a83615c4a7,DISK], DatanodeInfoWithStorage[127.0.0.1:39664,DS-c1beb2b6-4b93-49d7-b13c-cc7f56a8d0b6,DISK], DatanodeInfoWithStorage[127.0.0.1:44327,DS-77565ff2-92e2-4565-a15a-708cecf04fe9,DISK], DatanodeInfoWithStorage[127.0.0.1:35166,DS-e8a6057e-dbe2-4747-bc4c-1b629d20fe81,DISK], DatanodeInfoWithStorage[127.0.0.1:38262,DS-86f6e20b-6009-4b50-b57e-e13ccf6ac69c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.avoid.read.stale.datanode
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1293765305-172.17.0.6-1598165709207:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38774,DS-14dc8fdf-99bc-47b8-8f1e-6563cd36e220,DISK], DatanodeInfoWithStorage[127.0.0.1:45113,DS-9f5966e6-8c2e-47f1-8058-8894bedcd305,DISK], DatanodeInfoWithStorage[127.0.0.1:39971,DS-3001649c-53a1-4e00-8436-19e10dd97019,DISK], DatanodeInfoWithStorage[127.0.0.1:44190,DS-f0ee226c-217c-4d81-90c5-6aee9d23c13b,DISK], DatanodeInfoWithStorage[127.0.0.1:38615,DS-6082bc58-f494-41a5-8e27-27367d56b0f9,DISK], DatanodeInfoWithStorage[127.0.0.1:36278,DS-688d0e27-1333-4812-bb37-ac9d06eb005e,DISK], DatanodeInfoWithStorage[127.0.0.1:40501,DS-a3ac07d4-8cdc-4290-8568-bc5805b519c5,DISK], DatanodeInfoWithStorage[127.0.0.1:41018,DS-22dbcf09-7dab-4f4a-b29c-7e06c08a40e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1293765305-172.17.0.6-1598165709207:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38774,DS-14dc8fdf-99bc-47b8-8f1e-6563cd36e220,DISK], DatanodeInfoWithStorage[127.0.0.1:45113,DS-9f5966e6-8c2e-47f1-8058-8894bedcd305,DISK], DatanodeInfoWithStorage[127.0.0.1:39971,DS-3001649c-53a1-4e00-8436-19e10dd97019,DISK], DatanodeInfoWithStorage[127.0.0.1:44190,DS-f0ee226c-217c-4d81-90c5-6aee9d23c13b,DISK], DatanodeInfoWithStorage[127.0.0.1:38615,DS-6082bc58-f494-41a5-8e27-27367d56b0f9,DISK], DatanodeInfoWithStorage[127.0.0.1:36278,DS-688d0e27-1333-4812-bb37-ac9d06eb005e,DISK], DatanodeInfoWithStorage[127.0.0.1:40501,DS-a3ac07d4-8cdc-4290-8568-bc5805b519c5,DISK], DatanodeInfoWithStorage[127.0.0.1:41018,DS-22dbcf09-7dab-4f4a-b29c-7e06c08a40e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.avoid.read.stale.datanode
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-49107466-172.17.0.6-1598165787513:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37592,DS-28b788fd-0a7e-435b-9c87-98d3a2747e6a,DISK], DatanodeInfoWithStorage[127.0.0.1:45305,DS-a9c91447-2fa5-4763-bb43-336321269477,DISK], DatanodeInfoWithStorage[127.0.0.1:32796,DS-af2f5c30-9a8e-461d-b55b-b10783dfd2f9,DISK], DatanodeInfoWithStorage[127.0.0.1:44559,DS-680772db-e0fa-46a9-8f3a-f947d1e4cc28,DISK], DatanodeInfoWithStorage[127.0.0.1:37130,DS-60a00f23-1ce6-4cf6-a5bf-c5b66ca843e1,DISK], DatanodeInfoWithStorage[127.0.0.1:34793,DS-817edf8a-c104-4c0a-97c3-74c6cb892bb3,DISK], DatanodeInfoWithStorage[127.0.0.1:40375,DS-061b810b-c073-4a52-9773-742324956927,DISK], DatanodeInfoWithStorage[127.0.0.1:35936,DS-0b52f4c0-a45f-4c52-bf53-67c5908dfd37,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-49107466-172.17.0.6-1598165787513:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37592,DS-28b788fd-0a7e-435b-9c87-98d3a2747e6a,DISK], DatanodeInfoWithStorage[127.0.0.1:45305,DS-a9c91447-2fa5-4763-bb43-336321269477,DISK], DatanodeInfoWithStorage[127.0.0.1:32796,DS-af2f5c30-9a8e-461d-b55b-b10783dfd2f9,DISK], DatanodeInfoWithStorage[127.0.0.1:44559,DS-680772db-e0fa-46a9-8f3a-f947d1e4cc28,DISK], DatanodeInfoWithStorage[127.0.0.1:37130,DS-60a00f23-1ce6-4cf6-a5bf-c5b66ca843e1,DISK], DatanodeInfoWithStorage[127.0.0.1:34793,DS-817edf8a-c104-4c0a-97c3-74c6cb892bb3,DISK], DatanodeInfoWithStorage[127.0.0.1:40375,DS-061b810b-c073-4a52-9773-742324956927,DISK], DatanodeInfoWithStorage[127.0.0.1:35936,DS-0b52f4c0-a45f-4c52-bf53-67c5908dfd37,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.avoid.read.stale.datanode
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1478663085-172.17.0.6-1598165825047:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46141,DS-0b945fe3-5cb2-4c7b-87e7-a89c5e57e56b,DISK], DatanodeInfoWithStorage[127.0.0.1:39551,DS-05233088-7d67-41c7-9990-cdb7986fd6b0,DISK], DatanodeInfoWithStorage[127.0.0.1:42593,DS-62ad92f9-f5a8-4aeb-b8f3-1ce0f3a8418a,DISK], DatanodeInfoWithStorage[127.0.0.1:44800,DS-5336b78e-efba-46c9-96d0-4959468702ba,DISK], DatanodeInfoWithStorage[127.0.0.1:39973,DS-13a4f03d-5da6-467b-a9e7-5a1c6cecf189,DISK], DatanodeInfoWithStorage[127.0.0.1:45489,DS-d790f2c0-75c3-4ba8-942c-4d24985654a3,DISK], DatanodeInfoWithStorage[127.0.0.1:35800,DS-49b27cf1-08f1-4fdd-94ea-2219df1d1c61,DISK], DatanodeInfoWithStorage[127.0.0.1:46221,DS-cd3d3ed1-28f8-43c6-9dcc-d6e1f54e750f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1478663085-172.17.0.6-1598165825047:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46141,DS-0b945fe3-5cb2-4c7b-87e7-a89c5e57e56b,DISK], DatanodeInfoWithStorage[127.0.0.1:39551,DS-05233088-7d67-41c7-9990-cdb7986fd6b0,DISK], DatanodeInfoWithStorage[127.0.0.1:42593,DS-62ad92f9-f5a8-4aeb-b8f3-1ce0f3a8418a,DISK], DatanodeInfoWithStorage[127.0.0.1:44800,DS-5336b78e-efba-46c9-96d0-4959468702ba,DISK], DatanodeInfoWithStorage[127.0.0.1:39973,DS-13a4f03d-5da6-467b-a9e7-5a1c6cecf189,DISK], DatanodeInfoWithStorage[127.0.0.1:45489,DS-d790f2c0-75c3-4ba8-942c-4d24985654a3,DISK], DatanodeInfoWithStorage[127.0.0.1:35800,DS-49b27cf1-08f1-4fdd-94ea-2219df1d1c61,DISK], DatanodeInfoWithStorage[127.0.0.1:46221,DS-cd3d3ed1-28f8-43c6-9dcc-d6e1f54e750f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.avoid.read.stale.datanode
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1218815004-172.17.0.6-1598165915438:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37297,DS-787c370c-126d-44cd-b9c1-7cedbaffd0cd,DISK], DatanodeInfoWithStorage[127.0.0.1:37966,DS-29ba87a9-0690-429b-95e4-e8a748b9b666,DISK], DatanodeInfoWithStorage[127.0.0.1:37187,DS-054ddf4f-2e2c-49d6-9cba-e79d5bc5fa04,DISK], DatanodeInfoWithStorage[127.0.0.1:45458,DS-f4660280-3014-4316-8f66-ec50a3554f7c,DISK], DatanodeInfoWithStorage[127.0.0.1:41939,DS-5fb9e231-309d-48de-92f4-e07af768cb64,DISK], DatanodeInfoWithStorage[127.0.0.1:44484,DS-2686b75e-6f99-4af9-aab3-8937fcae8fcb,DISK], DatanodeInfoWithStorage[127.0.0.1:38069,DS-4be9718e-c539-428c-93e7-f8a9fc412669,DISK], DatanodeInfoWithStorage[127.0.0.1:41815,DS-d410ffcc-8526-4773-b154-56df1e0d550b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1218815004-172.17.0.6-1598165915438:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37297,DS-787c370c-126d-44cd-b9c1-7cedbaffd0cd,DISK], DatanodeInfoWithStorage[127.0.0.1:37966,DS-29ba87a9-0690-429b-95e4-e8a748b9b666,DISK], DatanodeInfoWithStorage[127.0.0.1:37187,DS-054ddf4f-2e2c-49d6-9cba-e79d5bc5fa04,DISK], DatanodeInfoWithStorage[127.0.0.1:45458,DS-f4660280-3014-4316-8f66-ec50a3554f7c,DISK], DatanodeInfoWithStorage[127.0.0.1:41939,DS-5fb9e231-309d-48de-92f4-e07af768cb64,DISK], DatanodeInfoWithStorage[127.0.0.1:44484,DS-2686b75e-6f99-4af9-aab3-8937fcae8fcb,DISK], DatanodeInfoWithStorage[127.0.0.1:38069,DS-4be9718e-c539-428c-93e7-f8a9fc412669,DISK], DatanodeInfoWithStorage[127.0.0.1:41815,DS-d410ffcc-8526-4773-b154-56df1e0d550b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.avoid.read.stale.datanode
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-373146258-172.17.0.6-1598166659492:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36572,DS-e8f8d40e-2ed9-414c-81c9-e874905b62ae,DISK], DatanodeInfoWithStorage[127.0.0.1:38615,DS-9d74444a-6d77-4398-812d-3b03b65e89e2,DISK], DatanodeInfoWithStorage[127.0.0.1:36326,DS-7327e660-30ba-4c9c-b5fe-64b887028946,DISK], DatanodeInfoWithStorage[127.0.0.1:42421,DS-25ceb7aa-0b26-4095-810a-24b43480658a,DISK], DatanodeInfoWithStorage[127.0.0.1:44254,DS-f9db4f5b-365a-4a33-a3c2-01bbfa4252fa,DISK], DatanodeInfoWithStorage[127.0.0.1:37201,DS-7ca6c53e-61ba-47cf-9b9a-5251004e1c5e,DISK], DatanodeInfoWithStorage[127.0.0.1:42966,DS-bec5bfe4-0f55-45f0-99d4-d9ee84861c3d,DISK], DatanodeInfoWithStorage[127.0.0.1:35627,DS-3f75eb7e-3529-49d3-b106-dd839dcf20c5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-373146258-172.17.0.6-1598166659492:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36572,DS-e8f8d40e-2ed9-414c-81c9-e874905b62ae,DISK], DatanodeInfoWithStorage[127.0.0.1:38615,DS-9d74444a-6d77-4398-812d-3b03b65e89e2,DISK], DatanodeInfoWithStorage[127.0.0.1:36326,DS-7327e660-30ba-4c9c-b5fe-64b887028946,DISK], DatanodeInfoWithStorage[127.0.0.1:42421,DS-25ceb7aa-0b26-4095-810a-24b43480658a,DISK], DatanodeInfoWithStorage[127.0.0.1:44254,DS-f9db4f5b-365a-4a33-a3c2-01bbfa4252fa,DISK], DatanodeInfoWithStorage[127.0.0.1:37201,DS-7ca6c53e-61ba-47cf-9b9a-5251004e1c5e,DISK], DatanodeInfoWithStorage[127.0.0.1:42966,DS-bec5bfe4-0f55-45f0-99d4-d9ee84861c3d,DISK], DatanodeInfoWithStorage[127.0.0.1:35627,DS-3f75eb7e-3529-49d3-b106-dd839dcf20c5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.avoid.read.stale.datanode
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1808396762-172.17.0.6-1598166956572:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35936,DS-4ca042e6-fca4-4fab-907d-dff74ac7a16e,DISK], DatanodeInfoWithStorage[127.0.0.1:44584,DS-9794c12f-bd07-429b-b472-21e67aaaccf0,DISK], DatanodeInfoWithStorage[127.0.0.1:37056,DS-eb39e67c-702a-4c7f-abb4-99c9b6ca607f,DISK], DatanodeInfoWithStorage[127.0.0.1:36476,DS-1fc37ee9-a386-4fa1-834a-5ecd387ca5ee,DISK], DatanodeInfoWithStorage[127.0.0.1:39765,DS-8a025414-4186-4fd5-9ee0-9657e511005f,DISK], DatanodeInfoWithStorage[127.0.0.1:44207,DS-6a6c3054-7f2c-4ea3-ada9-10fbd5550fb8,DISK], DatanodeInfoWithStorage[127.0.0.1:37688,DS-a8be906e-b408-4229-b6a5-7fe5f212f96b,DISK], DatanodeInfoWithStorage[127.0.0.1:35046,DS-1643564e-6b55-43a9-9ea7-b858f7e7e6ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1808396762-172.17.0.6-1598166956572:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35936,DS-4ca042e6-fca4-4fab-907d-dff74ac7a16e,DISK], DatanodeInfoWithStorage[127.0.0.1:44584,DS-9794c12f-bd07-429b-b472-21e67aaaccf0,DISK], DatanodeInfoWithStorage[127.0.0.1:37056,DS-eb39e67c-702a-4c7f-abb4-99c9b6ca607f,DISK], DatanodeInfoWithStorage[127.0.0.1:36476,DS-1fc37ee9-a386-4fa1-834a-5ecd387ca5ee,DISK], DatanodeInfoWithStorage[127.0.0.1:39765,DS-8a025414-4186-4fd5-9ee0-9657e511005f,DISK], DatanodeInfoWithStorage[127.0.0.1:44207,DS-6a6c3054-7f2c-4ea3-ada9-10fbd5550fb8,DISK], DatanodeInfoWithStorage[127.0.0.1:37688,DS-a8be906e-b408-4229-b6a5-7fe5f212f96b,DISK], DatanodeInfoWithStorage[127.0.0.1:35046,DS-1643564e-6b55-43a9-9ea7-b858f7e7e6ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 6597
