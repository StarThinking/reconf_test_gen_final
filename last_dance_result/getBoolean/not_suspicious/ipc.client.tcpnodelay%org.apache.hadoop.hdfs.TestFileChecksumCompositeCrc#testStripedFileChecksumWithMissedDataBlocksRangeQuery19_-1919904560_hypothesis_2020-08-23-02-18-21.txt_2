reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1039931991-172.17.0.13-1598149117454:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38150,DS-60d44c43-f4fa-4053-8659-958822ea22f8,DISK], DatanodeInfoWithStorage[127.0.0.1:44212,DS-6faa2672-6170-48be-864c-dfa72d833703,DISK], DatanodeInfoWithStorage[127.0.0.1:41487,DS-8a6fa50c-179f-4870-a1ee-c872a789bc9c,DISK], DatanodeInfoWithStorage[127.0.0.1:43141,DS-f848575e-76ba-47b8-ba50-2fa5d19e3717,DISK], DatanodeInfoWithStorage[127.0.0.1:37189,DS-cb9d12e7-99cb-4812-8746-460852bcc4ef,DISK], DatanodeInfoWithStorage[127.0.0.1:42787,DS-e9245bb2-ead5-4494-b9b7-7ef6e68b6cc3,DISK], DatanodeInfoWithStorage[127.0.0.1:36356,DS-d663b506-5b9a-4d59-a031-0328839bdc11,DISK], DatanodeInfoWithStorage[127.0.0.1:36647,DS-fdc54676-8c8a-4fab-ab20-e97c55b79133,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1039931991-172.17.0.13-1598149117454:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38150,DS-60d44c43-f4fa-4053-8659-958822ea22f8,DISK], DatanodeInfoWithStorage[127.0.0.1:44212,DS-6faa2672-6170-48be-864c-dfa72d833703,DISK], DatanodeInfoWithStorage[127.0.0.1:41487,DS-8a6fa50c-179f-4870-a1ee-c872a789bc9c,DISK], DatanodeInfoWithStorage[127.0.0.1:43141,DS-f848575e-76ba-47b8-ba50-2fa5d19e3717,DISK], DatanodeInfoWithStorage[127.0.0.1:37189,DS-cb9d12e7-99cb-4812-8746-460852bcc4ef,DISK], DatanodeInfoWithStorage[127.0.0.1:42787,DS-e9245bb2-ead5-4494-b9b7-7ef6e68b6cc3,DISK], DatanodeInfoWithStorage[127.0.0.1:36356,DS-d663b506-5b9a-4d59-a031-0328839bdc11,DISK], DatanodeInfoWithStorage[127.0.0.1:36647,DS-fdc54676-8c8a-4fab-ab20-e97c55b79133,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-857842508-172.17.0.13-1598149150123:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36858,DS-8c231555-bb58-4acf-9dc0-a719c4bdedb7,DISK], DatanodeInfoWithStorage[127.0.0.1:35490,DS-6b598a1d-5075-47a4-a95e-2c0d9ab6c143,DISK], DatanodeInfoWithStorage[127.0.0.1:39662,DS-43eed61d-80cc-491a-b5be-e26744a8b883,DISK], DatanodeInfoWithStorage[127.0.0.1:36110,DS-dbd626a8-45ee-4e31-8cff-3ebe01b82cbf,DISK], DatanodeInfoWithStorage[127.0.0.1:41502,DS-7eab446d-d661-410d-b88b-939c71113f11,DISK], DatanodeInfoWithStorage[127.0.0.1:40831,DS-bf37d6d2-d79b-40e7-8d96-be55f46e6348,DISK], DatanodeInfoWithStorage[127.0.0.1:35615,DS-d56b8d63-2013-4a91-8e40-d467c4009a7d,DISK], DatanodeInfoWithStorage[127.0.0.1:35649,DS-646bc06d-1328-4402-b375-d8b9e6c39baf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-857842508-172.17.0.13-1598149150123:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36858,DS-8c231555-bb58-4acf-9dc0-a719c4bdedb7,DISK], DatanodeInfoWithStorage[127.0.0.1:35490,DS-6b598a1d-5075-47a4-a95e-2c0d9ab6c143,DISK], DatanodeInfoWithStorage[127.0.0.1:39662,DS-43eed61d-80cc-491a-b5be-e26744a8b883,DISK], DatanodeInfoWithStorage[127.0.0.1:36110,DS-dbd626a8-45ee-4e31-8cff-3ebe01b82cbf,DISK], DatanodeInfoWithStorage[127.0.0.1:41502,DS-7eab446d-d661-410d-b88b-939c71113f11,DISK], DatanodeInfoWithStorage[127.0.0.1:40831,DS-bf37d6d2-d79b-40e7-8d96-be55f46e6348,DISK], DatanodeInfoWithStorage[127.0.0.1:35615,DS-d56b8d63-2013-4a91-8e40-d467c4009a7d,DISK], DatanodeInfoWithStorage[127.0.0.1:35649,DS-646bc06d-1328-4402-b375-d8b9e6c39baf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-199890214-172.17.0.13-1598149370137:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42325,DS-3941ec5f-75c9-449d-8fd1-6efcfbc38c5f,DISK], DatanodeInfoWithStorage[127.0.0.1:46840,DS-74168db6-f790-49aa-a1be-076f9ccb875e,DISK], DatanodeInfoWithStorage[127.0.0.1:43136,DS-969cf00a-fbec-46b5-8ce3-8f7ef2c09af1,DISK], DatanodeInfoWithStorage[127.0.0.1:35769,DS-1e81d62e-f242-4a22-9658-38f85cca4fba,DISK], DatanodeInfoWithStorage[127.0.0.1:40454,DS-940c1b02-9978-4ca8-8b70-35d586172140,DISK], DatanodeInfoWithStorage[127.0.0.1:44847,DS-515d1b5c-827f-4f9a-87aa-36ba9a7b36cf,DISK], DatanodeInfoWithStorage[127.0.0.1:33305,DS-9f8aacf7-0cbf-4c43-8f28-b64030fac4d0,DISK], DatanodeInfoWithStorage[127.0.0.1:45480,DS-4a313fbc-5915-4b2f-b761-41268e83540e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-199890214-172.17.0.13-1598149370137:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42325,DS-3941ec5f-75c9-449d-8fd1-6efcfbc38c5f,DISK], DatanodeInfoWithStorage[127.0.0.1:46840,DS-74168db6-f790-49aa-a1be-076f9ccb875e,DISK], DatanodeInfoWithStorage[127.0.0.1:43136,DS-969cf00a-fbec-46b5-8ce3-8f7ef2c09af1,DISK], DatanodeInfoWithStorage[127.0.0.1:35769,DS-1e81d62e-f242-4a22-9658-38f85cca4fba,DISK], DatanodeInfoWithStorage[127.0.0.1:40454,DS-940c1b02-9978-4ca8-8b70-35d586172140,DISK], DatanodeInfoWithStorage[127.0.0.1:44847,DS-515d1b5c-827f-4f9a-87aa-36ba9a7b36cf,DISK], DatanodeInfoWithStorage[127.0.0.1:33305,DS-9f8aacf7-0cbf-4c43-8f28-b64030fac4d0,DISK], DatanodeInfoWithStorage[127.0.0.1:45480,DS-4a313fbc-5915-4b2f-b761-41268e83540e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-199927274-172.17.0.13-1598149411047:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45904,DS-df54dc4c-d661-478f-98cf-187c2f154480,DISK], DatanodeInfoWithStorage[127.0.0.1:36563,DS-06724f40-2b81-4215-80c8-ef15a26685ea,DISK], DatanodeInfoWithStorage[127.0.0.1:34950,DS-2cfc5473-df58-4304-8963-7cee0dbae427,DISK], DatanodeInfoWithStorage[127.0.0.1:37708,DS-5a794617-f87c-49c9-ba90-4138d1bbde64,DISK], DatanodeInfoWithStorage[127.0.0.1:42435,DS-c9ab8e61-772f-4ce2-8be7-8ed4666f2e62,DISK], DatanodeInfoWithStorage[127.0.0.1:34269,DS-5eb4e2ff-572b-4efb-a7a7-d1604c095a95,DISK], DatanodeInfoWithStorage[127.0.0.1:45953,DS-1b834a73-c27a-446c-9690-9a9f40413cbe,DISK], DatanodeInfoWithStorage[127.0.0.1:45028,DS-42fda836-3fd1-4ef3-9f73-5ee669271190,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-199927274-172.17.0.13-1598149411047:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45904,DS-df54dc4c-d661-478f-98cf-187c2f154480,DISK], DatanodeInfoWithStorage[127.0.0.1:36563,DS-06724f40-2b81-4215-80c8-ef15a26685ea,DISK], DatanodeInfoWithStorage[127.0.0.1:34950,DS-2cfc5473-df58-4304-8963-7cee0dbae427,DISK], DatanodeInfoWithStorage[127.0.0.1:37708,DS-5a794617-f87c-49c9-ba90-4138d1bbde64,DISK], DatanodeInfoWithStorage[127.0.0.1:42435,DS-c9ab8e61-772f-4ce2-8be7-8ed4666f2e62,DISK], DatanodeInfoWithStorage[127.0.0.1:34269,DS-5eb4e2ff-572b-4efb-a7a7-d1604c095a95,DISK], DatanodeInfoWithStorage[127.0.0.1:45953,DS-1b834a73-c27a-446c-9690-9a9f40413cbe,DISK], DatanodeInfoWithStorage[127.0.0.1:45028,DS-42fda836-3fd1-4ef3-9f73-5ee669271190,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1371384908-172.17.0.13-1598149446770:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38164,DS-34a03534-82c3-4c23-b7a1-efee6928ed5d,DISK], DatanodeInfoWithStorage[127.0.0.1:40929,DS-0fa82327-9900-4101-ae46-97f61920fa61,DISK], DatanodeInfoWithStorage[127.0.0.1:40588,DS-a49ab86d-b58b-4a64-a114-286ea61aebcb,DISK], DatanodeInfoWithStorage[127.0.0.1:33574,DS-fc55675d-3c27-4a2a-976b-16d94c5fd5d9,DISK], DatanodeInfoWithStorage[127.0.0.1:42843,DS-a4ee3d87-b191-4142-b04f-23f82774a4e4,DISK], DatanodeInfoWithStorage[127.0.0.1:35108,DS-9426c71b-50f7-43ae-a9cc-bb3d5519f139,DISK], DatanodeInfoWithStorage[127.0.0.1:40999,DS-248044a1-44bd-4f4e-bef0-4c3d18e7f614,DISK], DatanodeInfoWithStorage[127.0.0.1:40074,DS-2da398e7-c289-486d-89f5-062a3f1075d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1371384908-172.17.0.13-1598149446770:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38164,DS-34a03534-82c3-4c23-b7a1-efee6928ed5d,DISK], DatanodeInfoWithStorage[127.0.0.1:40929,DS-0fa82327-9900-4101-ae46-97f61920fa61,DISK], DatanodeInfoWithStorage[127.0.0.1:40588,DS-a49ab86d-b58b-4a64-a114-286ea61aebcb,DISK], DatanodeInfoWithStorage[127.0.0.1:33574,DS-fc55675d-3c27-4a2a-976b-16d94c5fd5d9,DISK], DatanodeInfoWithStorage[127.0.0.1:42843,DS-a4ee3d87-b191-4142-b04f-23f82774a4e4,DISK], DatanodeInfoWithStorage[127.0.0.1:35108,DS-9426c71b-50f7-43ae-a9cc-bb3d5519f139,DISK], DatanodeInfoWithStorage[127.0.0.1:40999,DS-248044a1-44bd-4f4e-bef0-4c3d18e7f614,DISK], DatanodeInfoWithStorage[127.0.0.1:40074,DS-2da398e7-c289-486d-89f5-062a3f1075d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-836044612-172.17.0.13-1598149786959:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43086,DS-e3b4e18c-2de0-49cd-8a7e-a421ee7e642c,DISK], DatanodeInfoWithStorage[127.0.0.1:46863,DS-1bc7bc2e-947b-471e-a6af-9790d848463f,DISK], DatanodeInfoWithStorage[127.0.0.1:35800,DS-0a22b922-8b7b-4aad-bcde-195aa21833a1,DISK], DatanodeInfoWithStorage[127.0.0.1:41078,DS-66f4a084-e590-4d7a-92b5-76e3b870af6c,DISK], DatanodeInfoWithStorage[127.0.0.1:41835,DS-dd9227d9-121d-46ce-942e-13e4781c7dfc,DISK], DatanodeInfoWithStorage[127.0.0.1:45368,DS-7bb864a3-f6da-46fb-98ec-15b3599b6c87,DISK], DatanodeInfoWithStorage[127.0.0.1:46790,DS-61d17afc-2972-4958-86f0-f75c68db06f2,DISK], DatanodeInfoWithStorage[127.0.0.1:34910,DS-ee265503-7750-4111-9bc3-4f23066cd8da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-836044612-172.17.0.13-1598149786959:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43086,DS-e3b4e18c-2de0-49cd-8a7e-a421ee7e642c,DISK], DatanodeInfoWithStorage[127.0.0.1:46863,DS-1bc7bc2e-947b-471e-a6af-9790d848463f,DISK], DatanodeInfoWithStorage[127.0.0.1:35800,DS-0a22b922-8b7b-4aad-bcde-195aa21833a1,DISK], DatanodeInfoWithStorage[127.0.0.1:41078,DS-66f4a084-e590-4d7a-92b5-76e3b870af6c,DISK], DatanodeInfoWithStorage[127.0.0.1:41835,DS-dd9227d9-121d-46ce-942e-13e4781c7dfc,DISK], DatanodeInfoWithStorage[127.0.0.1:45368,DS-7bb864a3-f6da-46fb-98ec-15b3599b6c87,DISK], DatanodeInfoWithStorage[127.0.0.1:46790,DS-61d17afc-2972-4958-86f0-f75c68db06f2,DISK], DatanodeInfoWithStorage[127.0.0.1:34910,DS-ee265503-7750-4111-9bc3-4f23066cd8da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1441995624-172.17.0.13-1598150666530:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38654,DS-33895cf9-b042-4df4-83dd-15819949dba6,DISK], DatanodeInfoWithStorage[127.0.0.1:36535,DS-e69a2692-d706-4ae2-be9a-baa58426eb02,DISK], DatanodeInfoWithStorage[127.0.0.1:44960,DS-81ac8e7d-3d85-41d5-8b81-7568ba3b4ae2,DISK], DatanodeInfoWithStorage[127.0.0.1:45488,DS-b9e2685c-a76a-4d0d-9f7b-173393bdd99c,DISK], DatanodeInfoWithStorage[127.0.0.1:43310,DS-9aed38a5-5165-4260-bf04-f87970c706ac,DISK], DatanodeInfoWithStorage[127.0.0.1:36878,DS-cf5481bb-e130-4736-9a81-be186d67b266,DISK], DatanodeInfoWithStorage[127.0.0.1:38832,DS-5a3caae7-a3f6-428e-91df-d0e98115345c,DISK], DatanodeInfoWithStorage[127.0.0.1:35150,DS-98030dbd-5ea1-4acc-9099-674cbd8f8efd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1441995624-172.17.0.13-1598150666530:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38654,DS-33895cf9-b042-4df4-83dd-15819949dba6,DISK], DatanodeInfoWithStorage[127.0.0.1:36535,DS-e69a2692-d706-4ae2-be9a-baa58426eb02,DISK], DatanodeInfoWithStorage[127.0.0.1:44960,DS-81ac8e7d-3d85-41d5-8b81-7568ba3b4ae2,DISK], DatanodeInfoWithStorage[127.0.0.1:45488,DS-b9e2685c-a76a-4d0d-9f7b-173393bdd99c,DISK], DatanodeInfoWithStorage[127.0.0.1:43310,DS-9aed38a5-5165-4260-bf04-f87970c706ac,DISK], DatanodeInfoWithStorage[127.0.0.1:36878,DS-cf5481bb-e130-4736-9a81-be186d67b266,DISK], DatanodeInfoWithStorage[127.0.0.1:38832,DS-5a3caae7-a3f6-428e-91df-d0e98115345c,DISK], DatanodeInfoWithStorage[127.0.0.1:35150,DS-98030dbd-5ea1-4acc-9099-674cbd8f8efd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1840097970-172.17.0.13-1598150704679:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39478,DS-8b1f6fe5-e1ae-46d5-bbba-f86fced892e9,DISK], DatanodeInfoWithStorage[127.0.0.1:39890,DS-bb3f1361-efa0-4b59-a238-0ccf5f1f9fbe,DISK], DatanodeInfoWithStorage[127.0.0.1:36082,DS-6d2a6056-f3f6-4f74-bffa-d837aaedab17,DISK], DatanodeInfoWithStorage[127.0.0.1:39508,DS-e0d9352a-a46b-43ea-aed2-cba08f813e37,DISK], DatanodeInfoWithStorage[127.0.0.1:42016,DS-f1df9b89-0be0-496d-af61-13bb8d540c0c,DISK], DatanodeInfoWithStorage[127.0.0.1:46674,DS-237490fd-13af-4093-bd62-abbb526c6b3b,DISK], DatanodeInfoWithStorage[127.0.0.1:41802,DS-8779e53b-85bb-4153-a436-3eaee3676e90,DISK], DatanodeInfoWithStorage[127.0.0.1:41378,DS-a9744895-4ef1-4bd3-b95f-e1b7b9d9029b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1840097970-172.17.0.13-1598150704679:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39478,DS-8b1f6fe5-e1ae-46d5-bbba-f86fced892e9,DISK], DatanodeInfoWithStorage[127.0.0.1:39890,DS-bb3f1361-efa0-4b59-a238-0ccf5f1f9fbe,DISK], DatanodeInfoWithStorage[127.0.0.1:36082,DS-6d2a6056-f3f6-4f74-bffa-d837aaedab17,DISK], DatanodeInfoWithStorage[127.0.0.1:39508,DS-e0d9352a-a46b-43ea-aed2-cba08f813e37,DISK], DatanodeInfoWithStorage[127.0.0.1:42016,DS-f1df9b89-0be0-496d-af61-13bb8d540c0c,DISK], DatanodeInfoWithStorage[127.0.0.1:46674,DS-237490fd-13af-4093-bd62-abbb526c6b3b,DISK], DatanodeInfoWithStorage[127.0.0.1:41802,DS-8779e53b-85bb-4153-a436-3eaee3676e90,DISK], DatanodeInfoWithStorage[127.0.0.1:41378,DS-a9744895-4ef1-4bd3-b95f-e1b7b9d9029b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1114006340-172.17.0.13-1598150745544:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33566,DS-5a24be82-9ff9-400c-922c-637be6424085,DISK], DatanodeInfoWithStorage[127.0.0.1:41011,DS-95a3c6df-0dc6-4c65-9a67-37313d9cfd46,DISK], DatanodeInfoWithStorage[127.0.0.1:42533,DS-544d547a-fe01-4743-bfe7-c5fcf09c3432,DISK], DatanodeInfoWithStorage[127.0.0.1:37130,DS-e14ef089-ea16-401c-a33e-a7f8e0f4e381,DISK], DatanodeInfoWithStorage[127.0.0.1:44923,DS-e698d1f5-db7e-4109-8cd1-fbfaa6ce9087,DISK], DatanodeInfoWithStorage[127.0.0.1:36585,DS-41f66ebc-aac8-48cb-9c16-88d1140fb550,DISK], DatanodeInfoWithStorage[127.0.0.1:43326,DS-736e5a8a-1010-4f98-acbb-01ae4383e50e,DISK], DatanodeInfoWithStorage[127.0.0.1:41442,DS-1bc5c73e-139a-4ebe-b93c-e3badf69f879,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1114006340-172.17.0.13-1598150745544:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33566,DS-5a24be82-9ff9-400c-922c-637be6424085,DISK], DatanodeInfoWithStorage[127.0.0.1:41011,DS-95a3c6df-0dc6-4c65-9a67-37313d9cfd46,DISK], DatanodeInfoWithStorage[127.0.0.1:42533,DS-544d547a-fe01-4743-bfe7-c5fcf09c3432,DISK], DatanodeInfoWithStorage[127.0.0.1:37130,DS-e14ef089-ea16-401c-a33e-a7f8e0f4e381,DISK], DatanodeInfoWithStorage[127.0.0.1:44923,DS-e698d1f5-db7e-4109-8cd1-fbfaa6ce9087,DISK], DatanodeInfoWithStorage[127.0.0.1:36585,DS-41f66ebc-aac8-48cb-9c16-88d1140fb550,DISK], DatanodeInfoWithStorage[127.0.0.1:43326,DS-736e5a8a-1010-4f98-acbb-01ae4383e50e,DISK], DatanodeInfoWithStorage[127.0.0.1:41442,DS-1bc5c73e-139a-4ebe-b93c-e3badf69f879,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-455344290-172.17.0.13-1598150779217:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33102,DS-71d65eed-e8c4-418e-b868-4d6f53cef846,DISK], DatanodeInfoWithStorage[127.0.0.1:45393,DS-824e9444-da42-4110-870f-169de2c13649,DISK], DatanodeInfoWithStorage[127.0.0.1:37595,DS-0cc19a16-f066-4669-a2db-8393e170a9e9,DISK], DatanodeInfoWithStorage[127.0.0.1:36769,DS-d92a58fe-c4b8-49ea-b563-1c6f484707b6,DISK], DatanodeInfoWithStorage[127.0.0.1:36668,DS-cb3809e9-3d2f-4c61-8082-08a13e39f355,DISK], DatanodeInfoWithStorage[127.0.0.1:34286,DS-aba86ec1-5462-4f7b-8683-81e7c8e008aa,DISK], DatanodeInfoWithStorage[127.0.0.1:37787,DS-081727ab-dd67-4116-bd50-8d4fdcba3d44,DISK], DatanodeInfoWithStorage[127.0.0.1:38559,DS-f02a6eca-a0d7-4432-bf80-e60afd770e51,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-455344290-172.17.0.13-1598150779217:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33102,DS-71d65eed-e8c4-418e-b868-4d6f53cef846,DISK], DatanodeInfoWithStorage[127.0.0.1:45393,DS-824e9444-da42-4110-870f-169de2c13649,DISK], DatanodeInfoWithStorage[127.0.0.1:37595,DS-0cc19a16-f066-4669-a2db-8393e170a9e9,DISK], DatanodeInfoWithStorage[127.0.0.1:36769,DS-d92a58fe-c4b8-49ea-b563-1c6f484707b6,DISK], DatanodeInfoWithStorage[127.0.0.1:36668,DS-cb3809e9-3d2f-4c61-8082-08a13e39f355,DISK], DatanodeInfoWithStorage[127.0.0.1:34286,DS-aba86ec1-5462-4f7b-8683-81e7c8e008aa,DISK], DatanodeInfoWithStorage[127.0.0.1:37787,DS-081727ab-dd67-4116-bd50-8d4fdcba3d44,DISK], DatanodeInfoWithStorage[127.0.0.1:38559,DS-f02a6eca-a0d7-4432-bf80-e60afd770e51,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1669419679-172.17.0.13-1598150988047:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34041,DS-970d6cf9-e434-4ef6-b0ec-c6ae8ffa0117,DISK], DatanodeInfoWithStorage[127.0.0.1:40990,DS-73b4125e-9c02-41b9-b61b-07d095e809ca,DISK], DatanodeInfoWithStorage[127.0.0.1:34255,DS-2151f2ff-b1be-4eb1-8adb-f4fe3c01339a,DISK], DatanodeInfoWithStorage[127.0.0.1:39498,DS-9d47acc5-bcf7-496e-a138-d71cad7817dc,DISK], DatanodeInfoWithStorage[127.0.0.1:44278,DS-ddd48dc6-0c63-49af-81fc-11f4c2fea937,DISK], DatanodeInfoWithStorage[127.0.0.1:35376,DS-cd51caca-17df-4a67-abd4-c53298b169f3,DISK], DatanodeInfoWithStorage[127.0.0.1:38513,DS-7e0bc912-e895-4230-be7d-2a1b7340aebe,DISK], DatanodeInfoWithStorage[127.0.0.1:34076,DS-be9ea37e-2288-4819-b3b7-c902b20e6671,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1669419679-172.17.0.13-1598150988047:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34041,DS-970d6cf9-e434-4ef6-b0ec-c6ae8ffa0117,DISK], DatanodeInfoWithStorage[127.0.0.1:40990,DS-73b4125e-9c02-41b9-b61b-07d095e809ca,DISK], DatanodeInfoWithStorage[127.0.0.1:34255,DS-2151f2ff-b1be-4eb1-8adb-f4fe3c01339a,DISK], DatanodeInfoWithStorage[127.0.0.1:39498,DS-9d47acc5-bcf7-496e-a138-d71cad7817dc,DISK], DatanodeInfoWithStorage[127.0.0.1:44278,DS-ddd48dc6-0c63-49af-81fc-11f4c2fea937,DISK], DatanodeInfoWithStorage[127.0.0.1:35376,DS-cd51caca-17df-4a67-abd4-c53298b169f3,DISK], DatanodeInfoWithStorage[127.0.0.1:38513,DS-7e0bc912-e895-4230-be7d-2a1b7340aebe,DISK], DatanodeInfoWithStorage[127.0.0.1:34076,DS-be9ea37e-2288-4819-b3b7-c902b20e6671,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1935822964-172.17.0.13-1598152286300:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45630,DS-f027fe30-e244-4360-a18f-232ad3554db6,DISK], DatanodeInfoWithStorage[127.0.0.1:42772,DS-1cb7243a-711e-4e68-b04b-2a035b579ff8,DISK], DatanodeInfoWithStorage[127.0.0.1:44580,DS-cf22691c-56c9-457b-be5f-3f015154691b,DISK], DatanodeInfoWithStorage[127.0.0.1:34242,DS-85662191-0997-4196-a2b6-fec7854e8513,DISK], DatanodeInfoWithStorage[127.0.0.1:41611,DS-9ec8deac-dce1-42fa-bd63-a6ae6b9da201,DISK], DatanodeInfoWithStorage[127.0.0.1:43525,DS-87e0e178-e32f-4600-8657-5d6ff49f6654,DISK], DatanodeInfoWithStorage[127.0.0.1:40136,DS-c7c47032-94e6-47f9-919a-f068063a9417,DISK], DatanodeInfoWithStorage[127.0.0.1:42015,DS-9212d1e6-b0dd-4bd3-a38a-4095f5281fe7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1935822964-172.17.0.13-1598152286300:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45630,DS-f027fe30-e244-4360-a18f-232ad3554db6,DISK], DatanodeInfoWithStorage[127.0.0.1:42772,DS-1cb7243a-711e-4e68-b04b-2a035b579ff8,DISK], DatanodeInfoWithStorage[127.0.0.1:44580,DS-cf22691c-56c9-457b-be5f-3f015154691b,DISK], DatanodeInfoWithStorage[127.0.0.1:34242,DS-85662191-0997-4196-a2b6-fec7854e8513,DISK], DatanodeInfoWithStorage[127.0.0.1:41611,DS-9ec8deac-dce1-42fa-bd63-a6ae6b9da201,DISK], DatanodeInfoWithStorage[127.0.0.1:43525,DS-87e0e178-e32f-4600-8657-5d6ff49f6654,DISK], DatanodeInfoWithStorage[127.0.0.1:40136,DS-c7c47032-94e6-47f9-919a-f068063a9417,DISK], DatanodeInfoWithStorage[127.0.0.1:42015,DS-9212d1e6-b0dd-4bd3-a38a-4095f5281fe7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1885070924-172.17.0.13-1598152360853:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33393,DS-8c74d3b5-2c4a-4be5-8123-090510717cb9,DISK], DatanodeInfoWithStorage[127.0.0.1:35785,DS-9d5fb30b-a556-477c-864b-881baea193a2,DISK], DatanodeInfoWithStorage[127.0.0.1:34978,DS-eacc7cd0-4f30-4e8b-86a9-bae44b9d3eee,DISK], DatanodeInfoWithStorage[127.0.0.1:35722,DS-a01c62e1-07db-464c-aca4-5f6c3c9619f8,DISK], DatanodeInfoWithStorage[127.0.0.1:41189,DS-3724dd12-4912-4d73-be09-39d522358578,DISK], DatanodeInfoWithStorage[127.0.0.1:33529,DS-d41b9c06-4174-4ddd-b042-6a161334b009,DISK], DatanodeInfoWithStorage[127.0.0.1:44645,DS-11f74494-1996-43bf-a86e-9d72cb2a9cac,DISK], DatanodeInfoWithStorage[127.0.0.1:42495,DS-1e97bb54-7bb2-4134-b531-1bc816cee01f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1885070924-172.17.0.13-1598152360853:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33393,DS-8c74d3b5-2c4a-4be5-8123-090510717cb9,DISK], DatanodeInfoWithStorage[127.0.0.1:35785,DS-9d5fb30b-a556-477c-864b-881baea193a2,DISK], DatanodeInfoWithStorage[127.0.0.1:34978,DS-eacc7cd0-4f30-4e8b-86a9-bae44b9d3eee,DISK], DatanodeInfoWithStorage[127.0.0.1:35722,DS-a01c62e1-07db-464c-aca4-5f6c3c9619f8,DISK], DatanodeInfoWithStorage[127.0.0.1:41189,DS-3724dd12-4912-4d73-be09-39d522358578,DISK], DatanodeInfoWithStorage[127.0.0.1:33529,DS-d41b9c06-4174-4ddd-b042-6a161334b009,DISK], DatanodeInfoWithStorage[127.0.0.1:44645,DS-11f74494-1996-43bf-a86e-9d72cb2a9cac,DISK], DatanodeInfoWithStorage[127.0.0.1:42495,DS-1e97bb54-7bb2-4134-b531-1bc816cee01f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-611769923-172.17.0.13-1598152549170:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40961,DS-9706d5b0-c967-464d-947c-97bca366700f,DISK], DatanodeInfoWithStorage[127.0.0.1:44031,DS-ea4563c2-c79c-4819-808b-6f9cd914a2ba,DISK], DatanodeInfoWithStorage[127.0.0.1:42522,DS-1995f186-c38e-41d5-88bd-67ed6fe3b20c,DISK], DatanodeInfoWithStorage[127.0.0.1:37748,DS-09b06de4-220a-465a-8ab6-62bf9a063e2b,DISK], DatanodeInfoWithStorage[127.0.0.1:34214,DS-cb4c7caa-63c7-4eec-a123-fb422312e1c9,DISK], DatanodeInfoWithStorage[127.0.0.1:44975,DS-c1d1908b-75cd-42d8-9cd1-338b0fc700e4,DISK], DatanodeInfoWithStorage[127.0.0.1:40953,DS-ee6ddded-3409-425f-810b-7432142f3aa1,DISK], DatanodeInfoWithStorage[127.0.0.1:46452,DS-d604b01b-18c3-4106-abb0-3a3628d48e40,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-611769923-172.17.0.13-1598152549170:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40961,DS-9706d5b0-c967-464d-947c-97bca366700f,DISK], DatanodeInfoWithStorage[127.0.0.1:44031,DS-ea4563c2-c79c-4819-808b-6f9cd914a2ba,DISK], DatanodeInfoWithStorage[127.0.0.1:42522,DS-1995f186-c38e-41d5-88bd-67ed6fe3b20c,DISK], DatanodeInfoWithStorage[127.0.0.1:37748,DS-09b06de4-220a-465a-8ab6-62bf9a063e2b,DISK], DatanodeInfoWithStorage[127.0.0.1:34214,DS-cb4c7caa-63c7-4eec-a123-fb422312e1c9,DISK], DatanodeInfoWithStorage[127.0.0.1:44975,DS-c1d1908b-75cd-42d8-9cd1-338b0fc700e4,DISK], DatanodeInfoWithStorage[127.0.0.1:40953,DS-ee6ddded-3409-425f-810b-7432142f3aa1,DISK], DatanodeInfoWithStorage[127.0.0.1:46452,DS-d604b01b-18c3-4106-abb0-3a3628d48e40,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-177126435-172.17.0.13-1598152589754:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46050,DS-0de83e22-b1db-430e-86cf-addc8c85be44,DISK], DatanodeInfoWithStorage[127.0.0.1:41926,DS-06b08b48-1d33-4b9e-a095-9ed43976c9a0,DISK], DatanodeInfoWithStorage[127.0.0.1:33174,DS-26783b02-b4f5-44fc-bc5a-44d7675a6cfb,DISK], DatanodeInfoWithStorage[127.0.0.1:44160,DS-ae0cf641-a12d-4bcf-b244-a94cc77b4dda,DISK], DatanodeInfoWithStorage[127.0.0.1:45910,DS-9635c74e-6956-4b19-bcc0-1b6945c61d3b,DISK], DatanodeInfoWithStorage[127.0.0.1:46830,DS-8faf819c-5659-488d-87b3-59eef0feb162,DISK], DatanodeInfoWithStorage[127.0.0.1:44693,DS-5ae493d3-0fc1-48b1-b1f6-9129e8ed388d,DISK], DatanodeInfoWithStorage[127.0.0.1:34903,DS-3c394b6b-37bf-4e27-a85b-c8e1ffc421e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-177126435-172.17.0.13-1598152589754:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46050,DS-0de83e22-b1db-430e-86cf-addc8c85be44,DISK], DatanodeInfoWithStorage[127.0.0.1:41926,DS-06b08b48-1d33-4b9e-a095-9ed43976c9a0,DISK], DatanodeInfoWithStorage[127.0.0.1:33174,DS-26783b02-b4f5-44fc-bc5a-44d7675a6cfb,DISK], DatanodeInfoWithStorage[127.0.0.1:44160,DS-ae0cf641-a12d-4bcf-b244-a94cc77b4dda,DISK], DatanodeInfoWithStorage[127.0.0.1:45910,DS-9635c74e-6956-4b19-bcc0-1b6945c61d3b,DISK], DatanodeInfoWithStorage[127.0.0.1:46830,DS-8faf819c-5659-488d-87b3-59eef0feb162,DISK], DatanodeInfoWithStorage[127.0.0.1:44693,DS-5ae493d3-0fc1-48b1-b1f6-9129e8ed388d,DISK], DatanodeInfoWithStorage[127.0.0.1:34903,DS-3c394b6b-37bf-4e27-a85b-c8e1ffc421e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-31398030-172.17.0.13-1598152656845:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44610,DS-bbe9c8b7-7f9c-4dc8-ad3d-de0175da5109,DISK], DatanodeInfoWithStorage[127.0.0.1:37695,DS-7c183b66-6c7d-44f7-80cf-49da7dd10c95,DISK], DatanodeInfoWithStorage[127.0.0.1:34929,DS-f6652da0-24d7-4798-b4e0-e82a58264550,DISK], DatanodeInfoWithStorage[127.0.0.1:35631,DS-f257ad9f-0c33-40aa-a924-280c555e6ebc,DISK], DatanodeInfoWithStorage[127.0.0.1:37727,DS-aab5c260-3e8f-4854-8f33-26c7714b9428,DISK], DatanodeInfoWithStorage[127.0.0.1:45960,DS-40c4b674-da8f-4c45-890f-2e21ca6e09e6,DISK], DatanodeInfoWithStorage[127.0.0.1:40230,DS-88cd261d-8fa6-4931-a894-23b0f06e02a4,DISK], DatanodeInfoWithStorage[127.0.0.1:39476,DS-4450943b-8656-4bd2-b892-01ae126aa578,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-31398030-172.17.0.13-1598152656845:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44610,DS-bbe9c8b7-7f9c-4dc8-ad3d-de0175da5109,DISK], DatanodeInfoWithStorage[127.0.0.1:37695,DS-7c183b66-6c7d-44f7-80cf-49da7dd10c95,DISK], DatanodeInfoWithStorage[127.0.0.1:34929,DS-f6652da0-24d7-4798-b4e0-e82a58264550,DISK], DatanodeInfoWithStorage[127.0.0.1:35631,DS-f257ad9f-0c33-40aa-a924-280c555e6ebc,DISK], DatanodeInfoWithStorage[127.0.0.1:37727,DS-aab5c260-3e8f-4854-8f33-26c7714b9428,DISK], DatanodeInfoWithStorage[127.0.0.1:45960,DS-40c4b674-da8f-4c45-890f-2e21ca6e09e6,DISK], DatanodeInfoWithStorage[127.0.0.1:40230,DS-88cd261d-8fa6-4931-a894-23b0f06e02a4,DISK], DatanodeInfoWithStorage[127.0.0.1:39476,DS-4450943b-8656-4bd2-b892-01ae126aa578,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1253360747-172.17.0.13-1598152865773:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37535,DS-8786af79-8d61-45c4-8536-74197ce44042,DISK], DatanodeInfoWithStorage[127.0.0.1:45432,DS-da240390-dd7c-47d5-bb56-70410f1673c3,DISK], DatanodeInfoWithStorage[127.0.0.1:38158,DS-3c732a12-93d8-4520-a435-7d8e4010da96,DISK], DatanodeInfoWithStorage[127.0.0.1:36884,DS-b79eb0af-1d2d-4c41-9920-37bbbbeb68a8,DISK], DatanodeInfoWithStorage[127.0.0.1:45030,DS-15e797f1-9c69-4247-aca7-f0e807ad4927,DISK], DatanodeInfoWithStorage[127.0.0.1:39697,DS-db8e8c7d-5a3d-48e8-9723-126ca6c3c38f,DISK], DatanodeInfoWithStorage[127.0.0.1:43264,DS-5fda9d68-c755-4f7b-8563-6f76a6df238e,DISK], DatanodeInfoWithStorage[127.0.0.1:41047,DS-7637329e-a594-4eea-b42d-1ab4877eff1e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1253360747-172.17.0.13-1598152865773:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37535,DS-8786af79-8d61-45c4-8536-74197ce44042,DISK], DatanodeInfoWithStorage[127.0.0.1:45432,DS-da240390-dd7c-47d5-bb56-70410f1673c3,DISK], DatanodeInfoWithStorage[127.0.0.1:38158,DS-3c732a12-93d8-4520-a435-7d8e4010da96,DISK], DatanodeInfoWithStorage[127.0.0.1:36884,DS-b79eb0af-1d2d-4c41-9920-37bbbbeb68a8,DISK], DatanodeInfoWithStorage[127.0.0.1:45030,DS-15e797f1-9c69-4247-aca7-f0e807ad4927,DISK], DatanodeInfoWithStorage[127.0.0.1:39697,DS-db8e8c7d-5a3d-48e8-9723-126ca6c3c38f,DISK], DatanodeInfoWithStorage[127.0.0.1:43264,DS-5fda9d68-c755-4f7b-8563-6f76a6df238e,DISK], DatanodeInfoWithStorage[127.0.0.1:41047,DS-7637329e-a594-4eea-b42d-1ab4877eff1e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1030663058-172.17.0.13-1598153241384:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33376,DS-883930bd-2ad6-4d2f-9b98-3a31c0f8c9bc,DISK], DatanodeInfoWithStorage[127.0.0.1:40392,DS-d5140b4b-6909-42a1-baca-a310e07c3020,DISK], DatanodeInfoWithStorage[127.0.0.1:37717,DS-624c2912-b309-43bf-bfd7-0aba714e1b72,DISK], DatanodeInfoWithStorage[127.0.0.1:36968,DS-c4aedfaa-4c97-4507-9043-673a4e5eba81,DISK], DatanodeInfoWithStorage[127.0.0.1:37957,DS-8661938f-b80f-4fe7-9cba-dfd0d6f60842,DISK], DatanodeInfoWithStorage[127.0.0.1:36024,DS-17b3fcc8-ede2-4cff-a1fd-face01ed6c69,DISK], DatanodeInfoWithStorage[127.0.0.1:39731,DS-efcf7d0d-e948-4406-9a7f-b03d151bf30c,DISK], DatanodeInfoWithStorage[127.0.0.1:44172,DS-5d1d4351-d29b-4b9b-9a93-6a9576b08957,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1030663058-172.17.0.13-1598153241384:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33376,DS-883930bd-2ad6-4d2f-9b98-3a31c0f8c9bc,DISK], DatanodeInfoWithStorage[127.0.0.1:40392,DS-d5140b4b-6909-42a1-baca-a310e07c3020,DISK], DatanodeInfoWithStorage[127.0.0.1:37717,DS-624c2912-b309-43bf-bfd7-0aba714e1b72,DISK], DatanodeInfoWithStorage[127.0.0.1:36968,DS-c4aedfaa-4c97-4507-9043-673a4e5eba81,DISK], DatanodeInfoWithStorage[127.0.0.1:37957,DS-8661938f-b80f-4fe7-9cba-dfd0d6f60842,DISK], DatanodeInfoWithStorage[127.0.0.1:36024,DS-17b3fcc8-ede2-4cff-a1fd-face01ed6c69,DISK], DatanodeInfoWithStorage[127.0.0.1:39731,DS-efcf7d0d-e948-4406-9a7f-b03d151bf30c,DISK], DatanodeInfoWithStorage[127.0.0.1:44172,DS-5d1d4351-d29b-4b9b-9a93-6a9576b08957,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1965025301-172.17.0.13-1598153276200:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38213,DS-2ed2db0a-cf1d-405f-84f0-88ef29b05d0d,DISK], DatanodeInfoWithStorage[127.0.0.1:46717,DS-a0fc1705-afb7-4068-9bd1-09e136fa2d3e,DISK], DatanodeInfoWithStorage[127.0.0.1:39298,DS-5459537e-9e5c-4851-94ed-4dc0b7e3562e,DISK], DatanodeInfoWithStorage[127.0.0.1:33309,DS-041eea87-69af-40e7-a6df-03147e087346,DISK], DatanodeInfoWithStorage[127.0.0.1:38382,DS-7850fae3-e359-4f6c-b881-d5aae21c002b,DISK], DatanodeInfoWithStorage[127.0.0.1:35533,DS-9aa7bcc8-92e7-434f-88f2-77eda5ea6416,DISK], DatanodeInfoWithStorage[127.0.0.1:36933,DS-653449f1-d572-4396-bab5-83aed6fdf128,DISK], DatanodeInfoWithStorage[127.0.0.1:35732,DS-197d0207-9503-4832-913f-0bb0ee69adfa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1965025301-172.17.0.13-1598153276200:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38213,DS-2ed2db0a-cf1d-405f-84f0-88ef29b05d0d,DISK], DatanodeInfoWithStorage[127.0.0.1:46717,DS-a0fc1705-afb7-4068-9bd1-09e136fa2d3e,DISK], DatanodeInfoWithStorage[127.0.0.1:39298,DS-5459537e-9e5c-4851-94ed-4dc0b7e3562e,DISK], DatanodeInfoWithStorage[127.0.0.1:33309,DS-041eea87-69af-40e7-a6df-03147e087346,DISK], DatanodeInfoWithStorage[127.0.0.1:38382,DS-7850fae3-e359-4f6c-b881-d5aae21c002b,DISK], DatanodeInfoWithStorage[127.0.0.1:35533,DS-9aa7bcc8-92e7-434f-88f2-77eda5ea6416,DISK], DatanodeInfoWithStorage[127.0.0.1:36933,DS-653449f1-d572-4396-bab5-83aed6fdf128,DISK], DatanodeInfoWithStorage[127.0.0.1:35732,DS-197d0207-9503-4832-913f-0bb0ee69adfa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-665770119-172.17.0.13-1598153377524:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38772,DS-7a39042c-5442-4fb7-87ee-756c14a43332,DISK], DatanodeInfoWithStorage[127.0.0.1:34897,DS-ac1a4e92-cf9c-4994-b12c-122b0d3e6589,DISK], DatanodeInfoWithStorage[127.0.0.1:35783,DS-c737e94c-cd08-4c9d-a8a4-65b1ed6145e1,DISK], DatanodeInfoWithStorage[127.0.0.1:37425,DS-75a64612-4ebf-4d01-a14b-e9e6da421283,DISK], DatanodeInfoWithStorage[127.0.0.1:34090,DS-a0985658-1701-481a-bf42-e761ec150ed0,DISK], DatanodeInfoWithStorage[127.0.0.1:46510,DS-3e192924-21c8-4fb4-b831-b88601e34f92,DISK], DatanodeInfoWithStorage[127.0.0.1:37193,DS-853a84e0-a32c-4101-81e2-7206c4fc59d0,DISK], DatanodeInfoWithStorage[127.0.0.1:45410,DS-d6eb96fc-b558-4b0f-9b42-4c4aefbe0411,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-665770119-172.17.0.13-1598153377524:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38772,DS-7a39042c-5442-4fb7-87ee-756c14a43332,DISK], DatanodeInfoWithStorage[127.0.0.1:34897,DS-ac1a4e92-cf9c-4994-b12c-122b0d3e6589,DISK], DatanodeInfoWithStorage[127.0.0.1:35783,DS-c737e94c-cd08-4c9d-a8a4-65b1ed6145e1,DISK], DatanodeInfoWithStorage[127.0.0.1:37425,DS-75a64612-4ebf-4d01-a14b-e9e6da421283,DISK], DatanodeInfoWithStorage[127.0.0.1:34090,DS-a0985658-1701-481a-bf42-e761ec150ed0,DISK], DatanodeInfoWithStorage[127.0.0.1:46510,DS-3e192924-21c8-4fb4-b831-b88601e34f92,DISK], DatanodeInfoWithStorage[127.0.0.1:37193,DS-853a84e0-a32c-4101-81e2-7206c4fc59d0,DISK], DatanodeInfoWithStorage[127.0.0.1:45410,DS-d6eb96fc-b558-4b0f-9b42-4c4aefbe0411,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1460560444-172.17.0.13-1598154051768:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35490,DS-7378b5ac-02b9-4105-80a8-f1ae7b35f3c4,DISK], DatanodeInfoWithStorage[127.0.0.1:44022,DS-9350496b-1412-4dfb-a902-d3695e6178f7,DISK], DatanodeInfoWithStorage[127.0.0.1:33947,DS-2cf0fa59-044a-4ee0-a32f-9ae5371476d8,DISK], DatanodeInfoWithStorage[127.0.0.1:38691,DS-c33c55d2-77c0-42a3-aa0e-d1df97ccf1a3,DISK], DatanodeInfoWithStorage[127.0.0.1:43839,DS-b299fa62-1f70-43b1-9f9b-1fae9c940a73,DISK], DatanodeInfoWithStorage[127.0.0.1:46663,DS-0b4f1d3f-934f-4cd9-9fd3-614588014a85,DISK], DatanodeInfoWithStorage[127.0.0.1:38501,DS-0c1ed725-4e2d-41ae-8529-b56970e2472f,DISK], DatanodeInfoWithStorage[127.0.0.1:38500,DS-f09d694d-a753-413b-924c-c4448f32cb92,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1460560444-172.17.0.13-1598154051768:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35490,DS-7378b5ac-02b9-4105-80a8-f1ae7b35f3c4,DISK], DatanodeInfoWithStorage[127.0.0.1:44022,DS-9350496b-1412-4dfb-a902-d3695e6178f7,DISK], DatanodeInfoWithStorage[127.0.0.1:33947,DS-2cf0fa59-044a-4ee0-a32f-9ae5371476d8,DISK], DatanodeInfoWithStorage[127.0.0.1:38691,DS-c33c55d2-77c0-42a3-aa0e-d1df97ccf1a3,DISK], DatanodeInfoWithStorage[127.0.0.1:43839,DS-b299fa62-1f70-43b1-9f9b-1fae9c940a73,DISK], DatanodeInfoWithStorage[127.0.0.1:46663,DS-0b4f1d3f-934f-4cd9-9fd3-614588014a85,DISK], DatanodeInfoWithStorage[127.0.0.1:38501,DS-0c1ed725-4e2d-41ae-8529-b56970e2472f,DISK], DatanodeInfoWithStorage[127.0.0.1:38500,DS-f09d694d-a753-413b-924c-c4448f32cb92,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 10 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: might be true error
Total execution time in seconds : 5171
