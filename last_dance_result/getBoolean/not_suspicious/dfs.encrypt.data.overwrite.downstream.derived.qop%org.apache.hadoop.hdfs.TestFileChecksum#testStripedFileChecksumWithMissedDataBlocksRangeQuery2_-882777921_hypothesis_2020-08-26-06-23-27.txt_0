reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-83958658-172.17.0.16-1598423555625:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41143,DS-52cfc35f-f7f3-442e-a36f-b201e7b2eb33,DISK], DatanodeInfoWithStorage[127.0.0.1:34017,DS-a87a8434-4d3b-4027-94a8-b7b75c5c79e1,DISK], DatanodeInfoWithStorage[127.0.0.1:39403,DS-f31a7dbb-0edc-4e15-bdb2-27980fc1b6df,DISK], DatanodeInfoWithStorage[127.0.0.1:44094,DS-abf21a26-6402-42ad-971e-d828dae17595,DISK], DatanodeInfoWithStorage[127.0.0.1:43272,DS-0a184a50-ddd8-4633-b936-ab6db73f686d,DISK], DatanodeInfoWithStorage[127.0.0.1:44209,DS-426c4dee-13f7-4580-b4df-a66e7bea8122,DISK], DatanodeInfoWithStorage[127.0.0.1:38205,DS-cdf57955-93cd-4e15-8f41-35f6c0483377,DISK], DatanodeInfoWithStorage[127.0.0.1:46714,DS-be8ed6e2-25a2-4d70-ba26-b9374228aac7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-83958658-172.17.0.16-1598423555625:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41143,DS-52cfc35f-f7f3-442e-a36f-b201e7b2eb33,DISK], DatanodeInfoWithStorage[127.0.0.1:34017,DS-a87a8434-4d3b-4027-94a8-b7b75c5c79e1,DISK], DatanodeInfoWithStorage[127.0.0.1:39403,DS-f31a7dbb-0edc-4e15-bdb2-27980fc1b6df,DISK], DatanodeInfoWithStorage[127.0.0.1:44094,DS-abf21a26-6402-42ad-971e-d828dae17595,DISK], DatanodeInfoWithStorage[127.0.0.1:43272,DS-0a184a50-ddd8-4633-b936-ab6db73f686d,DISK], DatanodeInfoWithStorage[127.0.0.1:44209,DS-426c4dee-13f7-4580-b4df-a66e7bea8122,DISK], DatanodeInfoWithStorage[127.0.0.1:38205,DS-cdf57955-93cd-4e15-8f41-35f6c0483377,DISK], DatanodeInfoWithStorage[127.0.0.1:46714,DS-be8ed6e2-25a2-4d70-ba26-b9374228aac7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-567200606-172.17.0.16-1598423756676:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37528,DS-8ee46a13-e80a-4a7c-9e0f-20647386b420,DISK], DatanodeInfoWithStorage[127.0.0.1:44928,DS-0ba5d6c5-95f0-4b3c-ac81-d63bf30b465b,DISK], DatanodeInfoWithStorage[127.0.0.1:38773,DS-c013d6ba-b176-477a-aeee-18f029ef4a9c,DISK], DatanodeInfoWithStorage[127.0.0.1:46833,DS-72f04c41-2188-4420-90df-46962783f11b,DISK], DatanodeInfoWithStorage[127.0.0.1:41506,DS-20cdfc2a-ac97-466a-9b29-7de0ca8a63f6,DISK], DatanodeInfoWithStorage[127.0.0.1:35154,DS-ed49e3d7-8baa-4115-bb12-5b127c951c16,DISK], DatanodeInfoWithStorage[127.0.0.1:46304,DS-984b1231-ab07-44e3-8153-df3fdcd1e088,DISK], DatanodeInfoWithStorage[127.0.0.1:44484,DS-41e8c80c-13fc-43f1-b544-59edb622339a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-567200606-172.17.0.16-1598423756676:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37528,DS-8ee46a13-e80a-4a7c-9e0f-20647386b420,DISK], DatanodeInfoWithStorage[127.0.0.1:44928,DS-0ba5d6c5-95f0-4b3c-ac81-d63bf30b465b,DISK], DatanodeInfoWithStorage[127.0.0.1:38773,DS-c013d6ba-b176-477a-aeee-18f029ef4a9c,DISK], DatanodeInfoWithStorage[127.0.0.1:46833,DS-72f04c41-2188-4420-90df-46962783f11b,DISK], DatanodeInfoWithStorage[127.0.0.1:41506,DS-20cdfc2a-ac97-466a-9b29-7de0ca8a63f6,DISK], DatanodeInfoWithStorage[127.0.0.1:35154,DS-ed49e3d7-8baa-4115-bb12-5b127c951c16,DISK], DatanodeInfoWithStorage[127.0.0.1:46304,DS-984b1231-ab07-44e3-8153-df3fdcd1e088,DISK], DatanodeInfoWithStorage[127.0.0.1:44484,DS-41e8c80c-13fc-43f1-b544-59edb622339a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-411103766-172.17.0.16-1598423874563:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44214,DS-132d0dcb-b7cb-4043-9f89-c2196db0c188,DISK], DatanodeInfoWithStorage[127.0.0.1:39443,DS-7d147b91-dfcf-4077-bf91-aa68eea516f6,DISK], DatanodeInfoWithStorage[127.0.0.1:33543,DS-7aa4b31e-b872-4d81-b98c-fc2b3661ab68,DISK], DatanodeInfoWithStorage[127.0.0.1:36139,DS-fb45bf41-7942-4461-ae9b-868f5b58f417,DISK], DatanodeInfoWithStorage[127.0.0.1:39563,DS-b57617e3-aebe-44c7-ae9e-e6b0c35a6263,DISK], DatanodeInfoWithStorage[127.0.0.1:37657,DS-fbe657c7-b67f-458d-9176-956c1e06614f,DISK], DatanodeInfoWithStorage[127.0.0.1:37270,DS-9f88ed16-8c95-4e14-8f7a-327b24125b12,DISK], DatanodeInfoWithStorage[127.0.0.1:43330,DS-91c4fb62-8c88-4723-a3d2-c0c2710eadee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-411103766-172.17.0.16-1598423874563:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44214,DS-132d0dcb-b7cb-4043-9f89-c2196db0c188,DISK], DatanodeInfoWithStorage[127.0.0.1:39443,DS-7d147b91-dfcf-4077-bf91-aa68eea516f6,DISK], DatanodeInfoWithStorage[127.0.0.1:33543,DS-7aa4b31e-b872-4d81-b98c-fc2b3661ab68,DISK], DatanodeInfoWithStorage[127.0.0.1:36139,DS-fb45bf41-7942-4461-ae9b-868f5b58f417,DISK], DatanodeInfoWithStorage[127.0.0.1:39563,DS-b57617e3-aebe-44c7-ae9e-e6b0c35a6263,DISK], DatanodeInfoWithStorage[127.0.0.1:37657,DS-fbe657c7-b67f-458d-9176-956c1e06614f,DISK], DatanodeInfoWithStorage[127.0.0.1:37270,DS-9f88ed16-8c95-4e14-8f7a-327b24125b12,DISK], DatanodeInfoWithStorage[127.0.0.1:43330,DS-91c4fb62-8c88-4723-a3d2-c0c2710eadee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-272788890-172.17.0.16-1598424245858:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39169,DS-ea9da40e-5558-41bc-98a3-f5b87f75b896,DISK], DatanodeInfoWithStorage[127.0.0.1:41091,DS-da5fec28-c9fd-4740-b47a-6db252e3a7e0,DISK], DatanodeInfoWithStorage[127.0.0.1:40071,DS-8e511363-a57c-4b73-8cfb-535d9e086d2f,DISK], DatanodeInfoWithStorage[127.0.0.1:39267,DS-05382c55-2e3e-4b9c-a80f-e44b9a05bc66,DISK], DatanodeInfoWithStorage[127.0.0.1:44638,DS-f254d0d4-9774-4276-8923-821d32813985,DISK], DatanodeInfoWithStorage[127.0.0.1:46005,DS-d7db966c-3715-4c9c-bf79-5701f3fd6124,DISK], DatanodeInfoWithStorage[127.0.0.1:46841,DS-bb06fe58-a93e-49f5-bc7d-abde37c1203a,DISK], DatanodeInfoWithStorage[127.0.0.1:37885,DS-fb16c218-5a26-4651-9920-a88d55f20266,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-272788890-172.17.0.16-1598424245858:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39169,DS-ea9da40e-5558-41bc-98a3-f5b87f75b896,DISK], DatanodeInfoWithStorage[127.0.0.1:41091,DS-da5fec28-c9fd-4740-b47a-6db252e3a7e0,DISK], DatanodeInfoWithStorage[127.0.0.1:40071,DS-8e511363-a57c-4b73-8cfb-535d9e086d2f,DISK], DatanodeInfoWithStorage[127.0.0.1:39267,DS-05382c55-2e3e-4b9c-a80f-e44b9a05bc66,DISK], DatanodeInfoWithStorage[127.0.0.1:44638,DS-f254d0d4-9774-4276-8923-821d32813985,DISK], DatanodeInfoWithStorage[127.0.0.1:46005,DS-d7db966c-3715-4c9c-bf79-5701f3fd6124,DISK], DatanodeInfoWithStorage[127.0.0.1:46841,DS-bb06fe58-a93e-49f5-bc7d-abde37c1203a,DISK], DatanodeInfoWithStorage[127.0.0.1:37885,DS-fb16c218-5a26-4651-9920-a88d55f20266,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2024155822-172.17.0.16-1598424741427:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40207,DS-04cdd297-8659-4be0-8fed-7cfec396103e,DISK], DatanodeInfoWithStorage[127.0.0.1:32831,DS-9b0819e5-8336-4c85-b74d-ea55fd015b96,DISK], DatanodeInfoWithStorage[127.0.0.1:43843,DS-42f10b25-884a-43c0-8fef-49892547723d,DISK], DatanodeInfoWithStorage[127.0.0.1:34809,DS-9cd02121-6de3-44df-bc1b-c1935900a95d,DISK], DatanodeInfoWithStorage[127.0.0.1:38597,DS-87eb6467-3cdc-4dcc-bf97-f5ccb3050498,DISK], DatanodeInfoWithStorage[127.0.0.1:41576,DS-5e66b28b-df1e-4cde-ae24-789d83b02cf8,DISK], DatanodeInfoWithStorage[127.0.0.1:34080,DS-99ab5935-3b95-4f8b-a7b6-6fb324590c83,DISK], DatanodeInfoWithStorage[127.0.0.1:39202,DS-d2ed99ff-25aa-4be5-aa52-412f63cfa99e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2024155822-172.17.0.16-1598424741427:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40207,DS-04cdd297-8659-4be0-8fed-7cfec396103e,DISK], DatanodeInfoWithStorage[127.0.0.1:32831,DS-9b0819e5-8336-4c85-b74d-ea55fd015b96,DISK], DatanodeInfoWithStorage[127.0.0.1:43843,DS-42f10b25-884a-43c0-8fef-49892547723d,DISK], DatanodeInfoWithStorage[127.0.0.1:34809,DS-9cd02121-6de3-44df-bc1b-c1935900a95d,DISK], DatanodeInfoWithStorage[127.0.0.1:38597,DS-87eb6467-3cdc-4dcc-bf97-f5ccb3050498,DISK], DatanodeInfoWithStorage[127.0.0.1:41576,DS-5e66b28b-df1e-4cde-ae24-789d83b02cf8,DISK], DatanodeInfoWithStorage[127.0.0.1:34080,DS-99ab5935-3b95-4f8b-a7b6-6fb324590c83,DISK], DatanodeInfoWithStorage[127.0.0.1:39202,DS-d2ed99ff-25aa-4be5-aa52-412f63cfa99e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-581423876-172.17.0.16-1598424800456:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43548,DS-dfb85b9c-f7ae-41f5-bbb2-f87a71ca6b9d,DISK], DatanodeInfoWithStorage[127.0.0.1:45639,DS-d029e4d4-5776-41b8-a7bf-b934a73fd591,DISK], DatanodeInfoWithStorage[127.0.0.1:40195,DS-bcd96c11-469a-4270-ae00-a04079bb6d84,DISK], DatanodeInfoWithStorage[127.0.0.1:37719,DS-4dd1fa9b-6091-412e-87a0-a5dcde4495ad,DISK], DatanodeInfoWithStorage[127.0.0.1:46109,DS-ad3f551f-0505-4299-aa26-2987a62e3ea7,DISK], DatanodeInfoWithStorage[127.0.0.1:32912,DS-85453748-3be8-4c86-92b0-d0498d0d7c2b,DISK], DatanodeInfoWithStorage[127.0.0.1:39640,DS-ccbcc11b-c8e7-4b29-8dcf-457977efa4b2,DISK], DatanodeInfoWithStorage[127.0.0.1:45879,DS-e4c014bf-44ea-41b0-938a-094b20db672f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-581423876-172.17.0.16-1598424800456:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43548,DS-dfb85b9c-f7ae-41f5-bbb2-f87a71ca6b9d,DISK], DatanodeInfoWithStorage[127.0.0.1:45639,DS-d029e4d4-5776-41b8-a7bf-b934a73fd591,DISK], DatanodeInfoWithStorage[127.0.0.1:40195,DS-bcd96c11-469a-4270-ae00-a04079bb6d84,DISK], DatanodeInfoWithStorage[127.0.0.1:37719,DS-4dd1fa9b-6091-412e-87a0-a5dcde4495ad,DISK], DatanodeInfoWithStorage[127.0.0.1:46109,DS-ad3f551f-0505-4299-aa26-2987a62e3ea7,DISK], DatanodeInfoWithStorage[127.0.0.1:32912,DS-85453748-3be8-4c86-92b0-d0498d0d7c2b,DISK], DatanodeInfoWithStorage[127.0.0.1:39640,DS-ccbcc11b-c8e7-4b29-8dcf-457977efa4b2,DISK], DatanodeInfoWithStorage[127.0.0.1:45879,DS-e4c014bf-44ea-41b0-938a-094b20db672f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1550799218-172.17.0.16-1598425730435:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39447,DS-ab064c99-1bd0-4551-bf22-99629649cd01,DISK], DatanodeInfoWithStorage[127.0.0.1:46077,DS-5664fc96-c5ad-412e-b5e0-e6b07b2bf018,DISK], DatanodeInfoWithStorage[127.0.0.1:36097,DS-ea0d3644-fbc5-48c0-aec9-2a7a6a342372,DISK], DatanodeInfoWithStorage[127.0.0.1:40238,DS-7593559b-07a7-420f-bd8b-31662f7f67b1,DISK], DatanodeInfoWithStorage[127.0.0.1:35033,DS-dc082870-a79f-4c90-ae78-318217e4d43e,DISK], DatanodeInfoWithStorage[127.0.0.1:33559,DS-b69a0701-1e18-411a-95c9-e73d478f7252,DISK], DatanodeInfoWithStorage[127.0.0.1:43498,DS-8894cdf2-0326-47dc-9c03-47dcec5d3fb5,DISK], DatanodeInfoWithStorage[127.0.0.1:42971,DS-a8dd05cf-57ca-441f-a162-c93bb7cbb028,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1550799218-172.17.0.16-1598425730435:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39447,DS-ab064c99-1bd0-4551-bf22-99629649cd01,DISK], DatanodeInfoWithStorage[127.0.0.1:46077,DS-5664fc96-c5ad-412e-b5e0-e6b07b2bf018,DISK], DatanodeInfoWithStorage[127.0.0.1:36097,DS-ea0d3644-fbc5-48c0-aec9-2a7a6a342372,DISK], DatanodeInfoWithStorage[127.0.0.1:40238,DS-7593559b-07a7-420f-bd8b-31662f7f67b1,DISK], DatanodeInfoWithStorage[127.0.0.1:35033,DS-dc082870-a79f-4c90-ae78-318217e4d43e,DISK], DatanodeInfoWithStorage[127.0.0.1:33559,DS-b69a0701-1e18-411a-95c9-e73d478f7252,DISK], DatanodeInfoWithStorage[127.0.0.1:43498,DS-8894cdf2-0326-47dc-9c03-47dcec5d3fb5,DISK], DatanodeInfoWithStorage[127.0.0.1:42971,DS-a8dd05cf-57ca-441f-a162-c93bb7cbb028,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-229822798-172.17.0.16-1598425769386:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34724,DS-ce310512-9a50-4d33-83d4-61473bdcaa1a,DISK], DatanodeInfoWithStorage[127.0.0.1:44865,DS-8780f53a-66ab-4de5-8593-382bf2282691,DISK], DatanodeInfoWithStorage[127.0.0.1:34281,DS-c44b722a-1505-4b01-911c-b8ead794d4f1,DISK], DatanodeInfoWithStorage[127.0.0.1:44798,DS-dd9ec14a-72f4-4cab-bc60-1a4966f94f11,DISK], DatanodeInfoWithStorage[127.0.0.1:33626,DS-0424bfe8-5f55-41bc-94f2-7f1691526a84,DISK], DatanodeInfoWithStorage[127.0.0.1:37711,DS-2b65875b-c6cf-4e7c-853f-0de97697787a,DISK], DatanodeInfoWithStorage[127.0.0.1:39451,DS-0f505111-bb3f-45f4-90e4-c2e6d22eb0ee,DISK], DatanodeInfoWithStorage[127.0.0.1:44458,DS-c0b362c1-1351-4cd8-965a-f4eb7648ff95,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-229822798-172.17.0.16-1598425769386:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34724,DS-ce310512-9a50-4d33-83d4-61473bdcaa1a,DISK], DatanodeInfoWithStorage[127.0.0.1:44865,DS-8780f53a-66ab-4de5-8593-382bf2282691,DISK], DatanodeInfoWithStorage[127.0.0.1:34281,DS-c44b722a-1505-4b01-911c-b8ead794d4f1,DISK], DatanodeInfoWithStorage[127.0.0.1:44798,DS-dd9ec14a-72f4-4cab-bc60-1a4966f94f11,DISK], DatanodeInfoWithStorage[127.0.0.1:33626,DS-0424bfe8-5f55-41bc-94f2-7f1691526a84,DISK], DatanodeInfoWithStorage[127.0.0.1:37711,DS-2b65875b-c6cf-4e7c-853f-0de97697787a,DISK], DatanodeInfoWithStorage[127.0.0.1:39451,DS-0f505111-bb3f-45f4-90e4-c2e6d22eb0ee,DISK], DatanodeInfoWithStorage[127.0.0.1:44458,DS-c0b362c1-1351-4cd8-965a-f4eb7648ff95,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2038541035-172.17.0.16-1598425809435:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35583,DS-d634e567-e9a9-46de-9c76-9ef34d1d5426,DISK], DatanodeInfoWithStorage[127.0.0.1:44162,DS-2adf2302-5d51-40cf-93f8-c4e3383c8ea2,DISK], DatanodeInfoWithStorage[127.0.0.1:38829,DS-ec100517-8be0-464d-ade7-bdd38ae81bcd,DISK], DatanodeInfoWithStorage[127.0.0.1:37854,DS-50f90841-44ea-4182-987e-dfdfb0b4f6b6,DISK], DatanodeInfoWithStorage[127.0.0.1:40371,DS-990281e3-fb1f-4dee-822a-a7933ddd614a,DISK], DatanodeInfoWithStorage[127.0.0.1:39710,DS-23689dd8-a2df-4244-ae40-8d9feab41af0,DISK], DatanodeInfoWithStorage[127.0.0.1:36388,DS-ada28861-71ec-49b3-879d-93b2d48f91ce,DISK], DatanodeInfoWithStorage[127.0.0.1:46347,DS-45cb1a68-59fc-4d3b-b6c8-09c91e436635,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2038541035-172.17.0.16-1598425809435:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35583,DS-d634e567-e9a9-46de-9c76-9ef34d1d5426,DISK], DatanodeInfoWithStorage[127.0.0.1:44162,DS-2adf2302-5d51-40cf-93f8-c4e3383c8ea2,DISK], DatanodeInfoWithStorage[127.0.0.1:38829,DS-ec100517-8be0-464d-ade7-bdd38ae81bcd,DISK], DatanodeInfoWithStorage[127.0.0.1:37854,DS-50f90841-44ea-4182-987e-dfdfb0b4f6b6,DISK], DatanodeInfoWithStorage[127.0.0.1:40371,DS-990281e3-fb1f-4dee-822a-a7933ddd614a,DISK], DatanodeInfoWithStorage[127.0.0.1:39710,DS-23689dd8-a2df-4244-ae40-8d9feab41af0,DISK], DatanodeInfoWithStorage[127.0.0.1:36388,DS-ada28861-71ec-49b3-879d-93b2d48f91ce,DISK], DatanodeInfoWithStorage[127.0.0.1:46347,DS-45cb1a68-59fc-4d3b-b6c8-09c91e436635,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-572214230-172.17.0.16-1598426029560:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40762,DS-81b0dbad-376e-43b6-ac67-5d547c3fc352,DISK], DatanodeInfoWithStorage[127.0.0.1:37341,DS-49456a91-cc36-47de-b562-d162cd774e14,DISK], DatanodeInfoWithStorage[127.0.0.1:35070,DS-79d73ec9-8231-4df2-b0bb-48b3ac63c1da,DISK], DatanodeInfoWithStorage[127.0.0.1:36106,DS-4c8f7b00-939e-43a0-97d7-451dda45a387,DISK], DatanodeInfoWithStorage[127.0.0.1:33076,DS-327ee92d-0775-49fa-8ae3-763190a69001,DISK], DatanodeInfoWithStorage[127.0.0.1:46449,DS-8e26d39d-7f67-4d67-8b6d-74454471fe2c,DISK], DatanodeInfoWithStorage[127.0.0.1:42712,DS-d37cd917-dd6e-46b1-8417-46bf33c44f7f,DISK], DatanodeInfoWithStorage[127.0.0.1:37635,DS-22f0ac1e-e4bf-4643-a8de-7acbfe6b6be5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-572214230-172.17.0.16-1598426029560:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40762,DS-81b0dbad-376e-43b6-ac67-5d547c3fc352,DISK], DatanodeInfoWithStorage[127.0.0.1:37341,DS-49456a91-cc36-47de-b562-d162cd774e14,DISK], DatanodeInfoWithStorage[127.0.0.1:35070,DS-79d73ec9-8231-4df2-b0bb-48b3ac63c1da,DISK], DatanodeInfoWithStorage[127.0.0.1:36106,DS-4c8f7b00-939e-43a0-97d7-451dda45a387,DISK], DatanodeInfoWithStorage[127.0.0.1:33076,DS-327ee92d-0775-49fa-8ae3-763190a69001,DISK], DatanodeInfoWithStorage[127.0.0.1:46449,DS-8e26d39d-7f67-4d67-8b6d-74454471fe2c,DISK], DatanodeInfoWithStorage[127.0.0.1:42712,DS-d37cd917-dd6e-46b1-8417-46bf33c44f7f,DISK], DatanodeInfoWithStorage[127.0.0.1:37635,DS-22f0ac1e-e4bf-4643-a8de-7acbfe6b6be5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-264073058-172.17.0.16-1598426924228:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40758,DS-4e174642-6d47-4d4f-8f6f-e8675b43131f,DISK], DatanodeInfoWithStorage[127.0.0.1:36011,DS-1b691985-2d5c-4ed6-a6b5-57f189ff59c3,DISK], DatanodeInfoWithStorage[127.0.0.1:36791,DS-a1c26941-2a47-4ab0-a31b-d298b830ab1c,DISK], DatanodeInfoWithStorage[127.0.0.1:36061,DS-f7f71a33-307b-4701-83fb-7b03a2c6bd44,DISK], DatanodeInfoWithStorage[127.0.0.1:35341,DS-72387bdf-86cc-4282-b770-e370de39aa16,DISK], DatanodeInfoWithStorage[127.0.0.1:38416,DS-7e88fbfc-46b5-4225-973a-090b10e38200,DISK], DatanodeInfoWithStorage[127.0.0.1:44607,DS-a47aca8b-f49b-4ebf-9e96-06164116a703,DISK], DatanodeInfoWithStorage[127.0.0.1:37980,DS-d414dda7-15fa-434a-aa9e-3cd375b30a77,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-264073058-172.17.0.16-1598426924228:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40758,DS-4e174642-6d47-4d4f-8f6f-e8675b43131f,DISK], DatanodeInfoWithStorage[127.0.0.1:36011,DS-1b691985-2d5c-4ed6-a6b5-57f189ff59c3,DISK], DatanodeInfoWithStorage[127.0.0.1:36791,DS-a1c26941-2a47-4ab0-a31b-d298b830ab1c,DISK], DatanodeInfoWithStorage[127.0.0.1:36061,DS-f7f71a33-307b-4701-83fb-7b03a2c6bd44,DISK], DatanodeInfoWithStorage[127.0.0.1:35341,DS-72387bdf-86cc-4282-b770-e370de39aa16,DISK], DatanodeInfoWithStorage[127.0.0.1:38416,DS-7e88fbfc-46b5-4225-973a-090b10e38200,DISK], DatanodeInfoWithStorage[127.0.0.1:44607,DS-a47aca8b-f49b-4ebf-9e96-06164116a703,DISK], DatanodeInfoWithStorage[127.0.0.1:37980,DS-d414dda7-15fa-434a-aa9e-3cd375b30a77,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1249120482-172.17.0.16-1598426992884:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42327,DS-f6eee13f-903f-4e9d-95b3-57e34555d74f,DISK], DatanodeInfoWithStorage[127.0.0.1:41937,DS-448a0165-5b42-4195-9ed2-0ac8790cbdf4,DISK], DatanodeInfoWithStorage[127.0.0.1:39107,DS-5f8b8ec1-2bc7-4e9b-aec8-2b4fd8a20f1e,DISK], DatanodeInfoWithStorage[127.0.0.1:43689,DS-751b634d-fd95-4714-89de-431aaf97a884,DISK], DatanodeInfoWithStorage[127.0.0.1:33713,DS-1cdb5f67-13f8-44dc-aac7-ee9468f4595c,DISK], DatanodeInfoWithStorage[127.0.0.1:35301,DS-5340ee48-128a-4cbf-9dc8-9aaf5315f62b,DISK], DatanodeInfoWithStorage[127.0.0.1:39193,DS-1a187bc3-6f09-4e58-a16f-02ee3f8cacc2,DISK], DatanodeInfoWithStorage[127.0.0.1:34103,DS-d928690f-01c7-4797-899a-3245f05f0528,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1249120482-172.17.0.16-1598426992884:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42327,DS-f6eee13f-903f-4e9d-95b3-57e34555d74f,DISK], DatanodeInfoWithStorage[127.0.0.1:41937,DS-448a0165-5b42-4195-9ed2-0ac8790cbdf4,DISK], DatanodeInfoWithStorage[127.0.0.1:39107,DS-5f8b8ec1-2bc7-4e9b-aec8-2b4fd8a20f1e,DISK], DatanodeInfoWithStorage[127.0.0.1:43689,DS-751b634d-fd95-4714-89de-431aaf97a884,DISK], DatanodeInfoWithStorage[127.0.0.1:33713,DS-1cdb5f67-13f8-44dc-aac7-ee9468f4595c,DISK], DatanodeInfoWithStorage[127.0.0.1:35301,DS-5340ee48-128a-4cbf-9dc8-9aaf5315f62b,DISK], DatanodeInfoWithStorage[127.0.0.1:39193,DS-1a187bc3-6f09-4e58-a16f-02ee3f8cacc2,DISK], DatanodeInfoWithStorage[127.0.0.1:34103,DS-d928690f-01c7-4797-899a-3245f05f0528,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1126270930-172.17.0.16-1598427164755:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40995,DS-931378a6-84d6-4753-895d-797fff9e60f5,DISK], DatanodeInfoWithStorage[127.0.0.1:40679,DS-4a295ae5-c4ed-4418-91a0-3c8275ca0468,DISK], DatanodeInfoWithStorage[127.0.0.1:42307,DS-5e359e3a-0e18-4af7-8047-f90f75c60a74,DISK], DatanodeInfoWithStorage[127.0.0.1:36526,DS-1626a9bb-cc39-4c74-83f2-0d8c63efa587,DISK], DatanodeInfoWithStorage[127.0.0.1:45282,DS-3ff52edd-29b6-408d-b753-88f729692985,DISK], DatanodeInfoWithStorage[127.0.0.1:40111,DS-855e5220-76ff-439e-ba11-2cb185c5cf91,DISK], DatanodeInfoWithStorage[127.0.0.1:41358,DS-40c32862-588b-4ab8-8792-8d27d37208fd,DISK], DatanodeInfoWithStorage[127.0.0.1:36343,DS-826fd4bc-d66a-48cb-8b26-c691c2252ba1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1126270930-172.17.0.16-1598427164755:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40995,DS-931378a6-84d6-4753-895d-797fff9e60f5,DISK], DatanodeInfoWithStorage[127.0.0.1:40679,DS-4a295ae5-c4ed-4418-91a0-3c8275ca0468,DISK], DatanodeInfoWithStorage[127.0.0.1:42307,DS-5e359e3a-0e18-4af7-8047-f90f75c60a74,DISK], DatanodeInfoWithStorage[127.0.0.1:36526,DS-1626a9bb-cc39-4c74-83f2-0d8c63efa587,DISK], DatanodeInfoWithStorage[127.0.0.1:45282,DS-3ff52edd-29b6-408d-b753-88f729692985,DISK], DatanodeInfoWithStorage[127.0.0.1:40111,DS-855e5220-76ff-439e-ba11-2cb185c5cf91,DISK], DatanodeInfoWithStorage[127.0.0.1:41358,DS-40c32862-588b-4ab8-8792-8d27d37208fd,DISK], DatanodeInfoWithStorage[127.0.0.1:36343,DS-826fd4bc-d66a-48cb-8b26-c691c2252ba1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-174480547-172.17.0.16-1598428058788:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36511,DS-c4aa532c-8a2f-4a13-aada-294c233b0a5c,DISK], DatanodeInfoWithStorage[127.0.0.1:43321,DS-181fba56-3e93-43c8-836d-191f1f19299c,DISK], DatanodeInfoWithStorage[127.0.0.1:40257,DS-f28ce072-7825-482d-8222-8c08c4724a1f,DISK], DatanodeInfoWithStorage[127.0.0.1:38517,DS-ff87fa32-1d62-4b4f-8a58-8e670f0fe8ed,DISK], DatanodeInfoWithStorage[127.0.0.1:40190,DS-c2aa95b8-6da4-40ca-b17e-93363cc8d094,DISK], DatanodeInfoWithStorage[127.0.0.1:40954,DS-1bb92a84-8d29-4427-ade1-240b705173b0,DISK], DatanodeInfoWithStorage[127.0.0.1:39947,DS-c9b9b58f-67c7-43ab-8ba2-dbeab941468d,DISK], DatanodeInfoWithStorage[127.0.0.1:46045,DS-cad74788-31a8-40f3-9f64-086a7953beca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-174480547-172.17.0.16-1598428058788:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36511,DS-c4aa532c-8a2f-4a13-aada-294c233b0a5c,DISK], DatanodeInfoWithStorage[127.0.0.1:43321,DS-181fba56-3e93-43c8-836d-191f1f19299c,DISK], DatanodeInfoWithStorage[127.0.0.1:40257,DS-f28ce072-7825-482d-8222-8c08c4724a1f,DISK], DatanodeInfoWithStorage[127.0.0.1:38517,DS-ff87fa32-1d62-4b4f-8a58-8e670f0fe8ed,DISK], DatanodeInfoWithStorage[127.0.0.1:40190,DS-c2aa95b8-6da4-40ca-b17e-93363cc8d094,DISK], DatanodeInfoWithStorage[127.0.0.1:40954,DS-1bb92a84-8d29-4427-ade1-240b705173b0,DISK], DatanodeInfoWithStorage[127.0.0.1:39947,DS-c9b9b58f-67c7-43ab-8ba2-dbeab941468d,DISK], DatanodeInfoWithStorage[127.0.0.1:46045,DS-cad74788-31a8-40f3-9f64-086a7953beca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5206
