reconf_parameter: dfs.permissions.ContentSummary.subAccess
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.ContentSummary.subAccess
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1139994650-172.17.0.18-1598418157327:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39653,DS-525b7f52-002e-47d1-b015-fa9057739e3e,DISK], DatanodeInfoWithStorage[127.0.0.1:32992,DS-687e7edb-bee9-4de0-bd6d-489b9c098a94,DISK], DatanodeInfoWithStorage[127.0.0.1:38768,DS-e8c781db-64b7-4ca3-bca4-3089e3ef199a,DISK], DatanodeInfoWithStorage[127.0.0.1:46595,DS-6f10421f-79b5-43dd-be9a-3844a82beef9,DISK], DatanodeInfoWithStorage[127.0.0.1:46666,DS-13e1244e-8e6a-42bc-87f6-e08a08fa8534,DISK], DatanodeInfoWithStorage[127.0.0.1:32777,DS-d1276916-8403-461c-a462-7f22b37f5105,DISK], DatanodeInfoWithStorage[127.0.0.1:46236,DS-38a85cf4-1f68-44a0-a1de-8dd3028e4797,DISK], DatanodeInfoWithStorage[127.0.0.1:42828,DS-a2605bba-0ef6-42e7-ba57-0f04ab2e51c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1139994650-172.17.0.18-1598418157327:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39653,DS-525b7f52-002e-47d1-b015-fa9057739e3e,DISK], DatanodeInfoWithStorage[127.0.0.1:32992,DS-687e7edb-bee9-4de0-bd6d-489b9c098a94,DISK], DatanodeInfoWithStorage[127.0.0.1:38768,DS-e8c781db-64b7-4ca3-bca4-3089e3ef199a,DISK], DatanodeInfoWithStorage[127.0.0.1:46595,DS-6f10421f-79b5-43dd-be9a-3844a82beef9,DISK], DatanodeInfoWithStorage[127.0.0.1:46666,DS-13e1244e-8e6a-42bc-87f6-e08a08fa8534,DISK], DatanodeInfoWithStorage[127.0.0.1:32777,DS-d1276916-8403-461c-a462-7f22b37f5105,DISK], DatanodeInfoWithStorage[127.0.0.1:46236,DS-38a85cf4-1f68-44a0-a1de-8dd3028e4797,DISK], DatanodeInfoWithStorage[127.0.0.1:42828,DS-a2605bba-0ef6-42e7-ba57-0f04ab2e51c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.ContentSummary.subAccess
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1196466866-172.17.0.18-1598418222559:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40040,DS-995ec744-8815-4043-a6b3-5be0f43005c4,DISK], DatanodeInfoWithStorage[127.0.0.1:46560,DS-d4837e70-ea98-4ce2-8d49-1d65cba51fc4,DISK], DatanodeInfoWithStorage[127.0.0.1:45729,DS-aa2d7649-b2ed-47ab-9e52-7b15f3082dbe,DISK], DatanodeInfoWithStorage[127.0.0.1:45157,DS-ef6c38aa-d555-404e-9c13-89fcb05d2e55,DISK], DatanodeInfoWithStorage[127.0.0.1:38638,DS-149f4e2b-8d43-40fe-86d3-89c36bef1ff6,DISK], DatanodeInfoWithStorage[127.0.0.1:45433,DS-aa6f4394-58e7-45af-878f-415940b8131b,DISK], DatanodeInfoWithStorage[127.0.0.1:37665,DS-bbd11fc9-ee10-4eb7-8791-9181c54ad5e3,DISK], DatanodeInfoWithStorage[127.0.0.1:44421,DS-167c46c0-4f93-4c29-9b59-f66bb9c3a62b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1196466866-172.17.0.18-1598418222559:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40040,DS-995ec744-8815-4043-a6b3-5be0f43005c4,DISK], DatanodeInfoWithStorage[127.0.0.1:46560,DS-d4837e70-ea98-4ce2-8d49-1d65cba51fc4,DISK], DatanodeInfoWithStorage[127.0.0.1:45729,DS-aa2d7649-b2ed-47ab-9e52-7b15f3082dbe,DISK], DatanodeInfoWithStorage[127.0.0.1:45157,DS-ef6c38aa-d555-404e-9c13-89fcb05d2e55,DISK], DatanodeInfoWithStorage[127.0.0.1:38638,DS-149f4e2b-8d43-40fe-86d3-89c36bef1ff6,DISK], DatanodeInfoWithStorage[127.0.0.1:45433,DS-aa6f4394-58e7-45af-878f-415940b8131b,DISK], DatanodeInfoWithStorage[127.0.0.1:37665,DS-bbd11fc9-ee10-4eb7-8791-9181c54ad5e3,DISK], DatanodeInfoWithStorage[127.0.0.1:44421,DS-167c46c0-4f93-4c29-9b59-f66bb9c3a62b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.ContentSummary.subAccess
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-614416869-172.17.0.18-1598418500988:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46535,DS-912c9f6f-b332-4fd6-90b7-f9ef98b66499,DISK], DatanodeInfoWithStorage[127.0.0.1:39458,DS-919d5516-86da-4867-b1cb-791123589c63,DISK], DatanodeInfoWithStorage[127.0.0.1:42304,DS-05dfb068-fac7-439c-85ba-a4035e06b66c,DISK], DatanodeInfoWithStorage[127.0.0.1:37106,DS-845dede8-6179-41e9-83bd-1af07bfeabbb,DISK], DatanodeInfoWithStorage[127.0.0.1:44864,DS-9ad7e032-3d91-4f16-9bbb-16069876e5b1,DISK], DatanodeInfoWithStorage[127.0.0.1:44959,DS-48f95d57-66a5-48fd-86c0-c4c665e2b5e4,DISK], DatanodeInfoWithStorage[127.0.0.1:38499,DS-071a37e2-75eb-45f3-8f29-8d7f7823c5ca,DISK], DatanodeInfoWithStorage[127.0.0.1:45373,DS-15c92700-f6e9-4961-9fd5-6223dbbccba5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-614416869-172.17.0.18-1598418500988:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46535,DS-912c9f6f-b332-4fd6-90b7-f9ef98b66499,DISK], DatanodeInfoWithStorage[127.0.0.1:39458,DS-919d5516-86da-4867-b1cb-791123589c63,DISK], DatanodeInfoWithStorage[127.0.0.1:42304,DS-05dfb068-fac7-439c-85ba-a4035e06b66c,DISK], DatanodeInfoWithStorage[127.0.0.1:37106,DS-845dede8-6179-41e9-83bd-1af07bfeabbb,DISK], DatanodeInfoWithStorage[127.0.0.1:44864,DS-9ad7e032-3d91-4f16-9bbb-16069876e5b1,DISK], DatanodeInfoWithStorage[127.0.0.1:44959,DS-48f95d57-66a5-48fd-86c0-c4c665e2b5e4,DISK], DatanodeInfoWithStorage[127.0.0.1:38499,DS-071a37e2-75eb-45f3-8f29-8d7f7823c5ca,DISK], DatanodeInfoWithStorage[127.0.0.1:45373,DS-15c92700-f6e9-4961-9fd5-6223dbbccba5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.ContentSummary.subAccess
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-800959986-172.17.0.18-1598419386213:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45832,DS-9a271e8c-9aac-4c3b-be88-b38b54d05881,DISK], DatanodeInfoWithStorage[127.0.0.1:44533,DS-0db17c17-24e3-463c-903c-4f523a65ff3a,DISK], DatanodeInfoWithStorage[127.0.0.1:43355,DS-8919ce7a-5176-4bed-9647-ecc73a2e1ee7,DISK], DatanodeInfoWithStorage[127.0.0.1:39886,DS-fd69f85f-69ba-4d08-8194-ae9f7842b936,DISK], DatanodeInfoWithStorage[127.0.0.1:33616,DS-8da1dd1d-679d-4f66-a63e-311f29dbab36,DISK], DatanodeInfoWithStorage[127.0.0.1:44086,DS-db8baecb-5eea-4f3a-b90d-361811f72623,DISK], DatanodeInfoWithStorage[127.0.0.1:41381,DS-abfcebb7-9147-4315-b1cf-38f6a099cb6a,DISK], DatanodeInfoWithStorage[127.0.0.1:42845,DS-6c322228-2e04-48e2-8297-f6c20695cbb5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-800959986-172.17.0.18-1598419386213:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45832,DS-9a271e8c-9aac-4c3b-be88-b38b54d05881,DISK], DatanodeInfoWithStorage[127.0.0.1:44533,DS-0db17c17-24e3-463c-903c-4f523a65ff3a,DISK], DatanodeInfoWithStorage[127.0.0.1:43355,DS-8919ce7a-5176-4bed-9647-ecc73a2e1ee7,DISK], DatanodeInfoWithStorage[127.0.0.1:39886,DS-fd69f85f-69ba-4d08-8194-ae9f7842b936,DISK], DatanodeInfoWithStorage[127.0.0.1:33616,DS-8da1dd1d-679d-4f66-a63e-311f29dbab36,DISK], DatanodeInfoWithStorage[127.0.0.1:44086,DS-db8baecb-5eea-4f3a-b90d-361811f72623,DISK], DatanodeInfoWithStorage[127.0.0.1:41381,DS-abfcebb7-9147-4315-b1cf-38f6a099cb6a,DISK], DatanodeInfoWithStorage[127.0.0.1:42845,DS-6c322228-2e04-48e2-8297-f6c20695cbb5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.ContentSummary.subAccess
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-282647783-172.17.0.18-1598419699767:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34666,DS-82b61ab4-54f4-43e2-8153-3102656c8379,DISK], DatanodeInfoWithStorage[127.0.0.1:32848,DS-fbb8f776-9802-4bc3-a411-e34c666bcb99,DISK], DatanodeInfoWithStorage[127.0.0.1:39605,DS-6648435a-8750-4d91-a3f3-e4175ba964ce,DISK], DatanodeInfoWithStorage[127.0.0.1:45345,DS-023bbac4-ad68-413d-a4ce-f3b62e6e365b,DISK], DatanodeInfoWithStorage[127.0.0.1:40287,DS-2d9a6189-a331-4c1a-8b5e-cc5260ddf5d3,DISK], DatanodeInfoWithStorage[127.0.0.1:34121,DS-8272bf6e-269e-4de2-9f38-567308dbdd45,DISK], DatanodeInfoWithStorage[127.0.0.1:46474,DS-b5a574fa-1c8d-463d-a763-a35ab1c5e6ae,DISK], DatanodeInfoWithStorage[127.0.0.1:46820,DS-f19f46cc-d855-4a92-8f4a-5afb0f619dc4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-282647783-172.17.0.18-1598419699767:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34666,DS-82b61ab4-54f4-43e2-8153-3102656c8379,DISK], DatanodeInfoWithStorage[127.0.0.1:32848,DS-fbb8f776-9802-4bc3-a411-e34c666bcb99,DISK], DatanodeInfoWithStorage[127.0.0.1:39605,DS-6648435a-8750-4d91-a3f3-e4175ba964ce,DISK], DatanodeInfoWithStorage[127.0.0.1:45345,DS-023bbac4-ad68-413d-a4ce-f3b62e6e365b,DISK], DatanodeInfoWithStorage[127.0.0.1:40287,DS-2d9a6189-a331-4c1a-8b5e-cc5260ddf5d3,DISK], DatanodeInfoWithStorage[127.0.0.1:34121,DS-8272bf6e-269e-4de2-9f38-567308dbdd45,DISK], DatanodeInfoWithStorage[127.0.0.1:46474,DS-b5a574fa-1c8d-463d-a763-a35ab1c5e6ae,DISK], DatanodeInfoWithStorage[127.0.0.1:46820,DS-f19f46cc-d855-4a92-8f4a-5afb0f619dc4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.ContentSummary.subAccess
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-9743822-172.17.0.18-1598420081463:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42711,DS-207ce062-0e71-4e87-ade2-82a1129da787,DISK], DatanodeInfoWithStorage[127.0.0.1:46521,DS-528be83f-bb5c-40f6-8172-6eb7e4ebd132,DISK], DatanodeInfoWithStorage[127.0.0.1:41414,DS-acaa7597-e242-492b-999b-0510a4992949,DISK], DatanodeInfoWithStorage[127.0.0.1:45755,DS-d6aba72c-b47e-42e7-ae4b-e69bb424901d,DISK], DatanodeInfoWithStorage[127.0.0.1:44458,DS-fcb2c9ae-5f10-4a88-bb60-c429ef3d9e88,DISK], DatanodeInfoWithStorage[127.0.0.1:46422,DS-e721292e-0715-4948-8f97-4530ad417314,DISK], DatanodeInfoWithStorage[127.0.0.1:34406,DS-737cfc35-4304-4f16-81bf-93798e449350,DISK], DatanodeInfoWithStorage[127.0.0.1:36481,DS-f02a5803-3dd9-4aa0-a943-be72bb972fda,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-9743822-172.17.0.18-1598420081463:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42711,DS-207ce062-0e71-4e87-ade2-82a1129da787,DISK], DatanodeInfoWithStorage[127.0.0.1:46521,DS-528be83f-bb5c-40f6-8172-6eb7e4ebd132,DISK], DatanodeInfoWithStorage[127.0.0.1:41414,DS-acaa7597-e242-492b-999b-0510a4992949,DISK], DatanodeInfoWithStorage[127.0.0.1:45755,DS-d6aba72c-b47e-42e7-ae4b-e69bb424901d,DISK], DatanodeInfoWithStorage[127.0.0.1:44458,DS-fcb2c9ae-5f10-4a88-bb60-c429ef3d9e88,DISK], DatanodeInfoWithStorage[127.0.0.1:46422,DS-e721292e-0715-4948-8f97-4530ad417314,DISK], DatanodeInfoWithStorage[127.0.0.1:34406,DS-737cfc35-4304-4f16-81bf-93798e449350,DISK], DatanodeInfoWithStorage[127.0.0.1:36481,DS-f02a5803-3dd9-4aa0-a943-be72bb972fda,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.ContentSummary.subAccess
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-667577821-172.17.0.18-1598420328714:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45526,DS-3e76479a-35dc-4e67-90e3-39cb748f41ce,DISK], DatanodeInfoWithStorage[127.0.0.1:39723,DS-27011169-1ec3-4532-8b0d-e887091ea754,DISK], DatanodeInfoWithStorage[127.0.0.1:35625,DS-64d6b8d2-c3b3-43c4-bb76-9c420859de0a,DISK], DatanodeInfoWithStorage[127.0.0.1:37484,DS-861aec4e-1784-47d3-bf34-90e6ef6df3d7,DISK], DatanodeInfoWithStorage[127.0.0.1:40293,DS-f4674e6c-2bad-40cc-b8a0-6b4064b70636,DISK], DatanodeInfoWithStorage[127.0.0.1:42109,DS-97ecf08c-ec46-44ff-aeba-113eae662ed5,DISK], DatanodeInfoWithStorage[127.0.0.1:37068,DS-e79e3735-03b9-4acf-a044-3bf8b5bc07e8,DISK], DatanodeInfoWithStorage[127.0.0.1:42871,DS-48c363ea-60f7-438d-a07c-eb736eb8ce6c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-667577821-172.17.0.18-1598420328714:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45526,DS-3e76479a-35dc-4e67-90e3-39cb748f41ce,DISK], DatanodeInfoWithStorage[127.0.0.1:39723,DS-27011169-1ec3-4532-8b0d-e887091ea754,DISK], DatanodeInfoWithStorage[127.0.0.1:35625,DS-64d6b8d2-c3b3-43c4-bb76-9c420859de0a,DISK], DatanodeInfoWithStorage[127.0.0.1:37484,DS-861aec4e-1784-47d3-bf34-90e6ef6df3d7,DISK], DatanodeInfoWithStorage[127.0.0.1:40293,DS-f4674e6c-2bad-40cc-b8a0-6b4064b70636,DISK], DatanodeInfoWithStorage[127.0.0.1:42109,DS-97ecf08c-ec46-44ff-aeba-113eae662ed5,DISK], DatanodeInfoWithStorage[127.0.0.1:37068,DS-e79e3735-03b9-4acf-a044-3bf8b5bc07e8,DISK], DatanodeInfoWithStorage[127.0.0.1:42871,DS-48c363ea-60f7-438d-a07c-eb736eb8ce6c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.ContentSummary.subAccess
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-287245573-172.17.0.18-1598420614153:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39165,DS-b0c86e4b-adef-4d49-a395-1a2e2a575134,DISK], DatanodeInfoWithStorage[127.0.0.1:44287,DS-5ab25962-d196-44ac-9674-894e89b16b16,DISK], DatanodeInfoWithStorage[127.0.0.1:40673,DS-7cafc896-e1c4-44b4-a841-ace4f8116f03,DISK], DatanodeInfoWithStorage[127.0.0.1:36788,DS-3696e1f7-fdad-4d39-89ee-47c430185f84,DISK], DatanodeInfoWithStorage[127.0.0.1:43436,DS-2ceb4c01-e48c-4390-999c-fdf9d044dcec,DISK], DatanodeInfoWithStorage[127.0.0.1:45123,DS-893b4275-9cd1-4c1e-95bc-88d8d0b83d77,DISK], DatanodeInfoWithStorage[127.0.0.1:37041,DS-d9b2d1ff-f773-4db8-a3c8-ba21dbc88fa4,DISK], DatanodeInfoWithStorage[127.0.0.1:35628,DS-104bf1bd-6163-4753-9784-d4f1fada01b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-287245573-172.17.0.18-1598420614153:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39165,DS-b0c86e4b-adef-4d49-a395-1a2e2a575134,DISK], DatanodeInfoWithStorage[127.0.0.1:44287,DS-5ab25962-d196-44ac-9674-894e89b16b16,DISK], DatanodeInfoWithStorage[127.0.0.1:40673,DS-7cafc896-e1c4-44b4-a841-ace4f8116f03,DISK], DatanodeInfoWithStorage[127.0.0.1:36788,DS-3696e1f7-fdad-4d39-89ee-47c430185f84,DISK], DatanodeInfoWithStorage[127.0.0.1:43436,DS-2ceb4c01-e48c-4390-999c-fdf9d044dcec,DISK], DatanodeInfoWithStorage[127.0.0.1:45123,DS-893b4275-9cd1-4c1e-95bc-88d8d0b83d77,DISK], DatanodeInfoWithStorage[127.0.0.1:37041,DS-d9b2d1ff-f773-4db8-a3c8-ba21dbc88fa4,DISK], DatanodeInfoWithStorage[127.0.0.1:35628,DS-104bf1bd-6163-4753-9784-d4f1fada01b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.ContentSummary.subAccess
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1118803181-172.17.0.18-1598420842313:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33522,DS-2d8b96f0-891e-462e-a7f2-2e98945d7bd0,DISK], DatanodeInfoWithStorage[127.0.0.1:38255,DS-3f99090b-5021-4158-ab1c-3617f0bea4fc,DISK], DatanodeInfoWithStorage[127.0.0.1:39207,DS-10dcb1fc-6dea-469a-aa56-c01718a5d65c,DISK], DatanodeInfoWithStorage[127.0.0.1:35957,DS-8326286f-f11d-47e0-800e-4625d560bd96,DISK], DatanodeInfoWithStorage[127.0.0.1:34827,DS-b399fa7f-42df-4d45-85d2-3efb61cf4d5c,DISK], DatanodeInfoWithStorage[127.0.0.1:44759,DS-4460a0e3-c86e-47c0-9454-942d06792a10,DISK], DatanodeInfoWithStorage[127.0.0.1:38282,DS-4ef69d74-3fad-4898-aa0b-bc75dc14fcad,DISK], DatanodeInfoWithStorage[127.0.0.1:46303,DS-806b333f-316a-489d-830f-128c0ae4173c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1118803181-172.17.0.18-1598420842313:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33522,DS-2d8b96f0-891e-462e-a7f2-2e98945d7bd0,DISK], DatanodeInfoWithStorage[127.0.0.1:38255,DS-3f99090b-5021-4158-ab1c-3617f0bea4fc,DISK], DatanodeInfoWithStorage[127.0.0.1:39207,DS-10dcb1fc-6dea-469a-aa56-c01718a5d65c,DISK], DatanodeInfoWithStorage[127.0.0.1:35957,DS-8326286f-f11d-47e0-800e-4625d560bd96,DISK], DatanodeInfoWithStorage[127.0.0.1:34827,DS-b399fa7f-42df-4d45-85d2-3efb61cf4d5c,DISK], DatanodeInfoWithStorage[127.0.0.1:44759,DS-4460a0e3-c86e-47c0-9454-942d06792a10,DISK], DatanodeInfoWithStorage[127.0.0.1:38282,DS-4ef69d74-3fad-4898-aa0b-bc75dc14fcad,DISK], DatanodeInfoWithStorage[127.0.0.1:46303,DS-806b333f-316a-489d-830f-128c0ae4173c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.ContentSummary.subAccess
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-306483248-172.17.0.18-1598421523933:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35577,DS-e3376cee-0508-4f75-a52a-e8d97cf877c1,DISK], DatanodeInfoWithStorage[127.0.0.1:40259,DS-d39413d3-d1b6-46a7-8b5b-c3f9cdd6e3f9,DISK], DatanodeInfoWithStorage[127.0.0.1:39728,DS-989caeba-efe4-4d1e-a8d0-9e11df405c5d,DISK], DatanodeInfoWithStorage[127.0.0.1:37494,DS-3b0cbe00-cd08-49ff-b7c5-18ad4a5fa9fe,DISK], DatanodeInfoWithStorage[127.0.0.1:33280,DS-1318f1f0-c41f-4aa7-88cc-27e231214931,DISK], DatanodeInfoWithStorage[127.0.0.1:36023,DS-670448b0-aa8a-4e06-88be-3693aa46b154,DISK], DatanodeInfoWithStorage[127.0.0.1:45759,DS-22052dfb-742b-402c-9cd2-860c72e51e64,DISK], DatanodeInfoWithStorage[127.0.0.1:45717,DS-6a27c60c-cd24-40e5-a8d7-493d0982d02c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-306483248-172.17.0.18-1598421523933:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35577,DS-e3376cee-0508-4f75-a52a-e8d97cf877c1,DISK], DatanodeInfoWithStorage[127.0.0.1:40259,DS-d39413d3-d1b6-46a7-8b5b-c3f9cdd6e3f9,DISK], DatanodeInfoWithStorage[127.0.0.1:39728,DS-989caeba-efe4-4d1e-a8d0-9e11df405c5d,DISK], DatanodeInfoWithStorage[127.0.0.1:37494,DS-3b0cbe00-cd08-49ff-b7c5-18ad4a5fa9fe,DISK], DatanodeInfoWithStorage[127.0.0.1:33280,DS-1318f1f0-c41f-4aa7-88cc-27e231214931,DISK], DatanodeInfoWithStorage[127.0.0.1:36023,DS-670448b0-aa8a-4e06-88be-3693aa46b154,DISK], DatanodeInfoWithStorage[127.0.0.1:45759,DS-22052dfb-742b-402c-9cd2-860c72e51e64,DISK], DatanodeInfoWithStorage[127.0.0.1:45717,DS-6a27c60c-cd24-40e5-a8d7-493d0982d02c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.ContentSummary.subAccess
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-746889255-172.17.0.18-1598421631216:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35754,DS-4657b22f-d3ff-43bc-a54c-fecf23479c41,DISK], DatanodeInfoWithStorage[127.0.0.1:46723,DS-db41b818-0686-4993-a79e-e7310e5e0239,DISK], DatanodeInfoWithStorage[127.0.0.1:33363,DS-7c6f7fe6-6931-4689-aaed-42d1268e2161,DISK], DatanodeInfoWithStorage[127.0.0.1:40075,DS-c2c9fc3e-80e5-437e-afff-02970722937f,DISK], DatanodeInfoWithStorage[127.0.0.1:34063,DS-afbabe9f-949f-4525-a552-b4988f1e7a1c,DISK], DatanodeInfoWithStorage[127.0.0.1:40015,DS-1b79d4f5-9722-4cb1-946b-46e2fda6ce8f,DISK], DatanodeInfoWithStorage[127.0.0.1:38787,DS-a5e3ea2b-fedc-40b6-87d1-ae2b8798bb32,DISK], DatanodeInfoWithStorage[127.0.0.1:43167,DS-2306675c-66cc-4069-a5f0-6bfd0dbbee3b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-746889255-172.17.0.18-1598421631216:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35754,DS-4657b22f-d3ff-43bc-a54c-fecf23479c41,DISK], DatanodeInfoWithStorage[127.0.0.1:46723,DS-db41b818-0686-4993-a79e-e7310e5e0239,DISK], DatanodeInfoWithStorage[127.0.0.1:33363,DS-7c6f7fe6-6931-4689-aaed-42d1268e2161,DISK], DatanodeInfoWithStorage[127.0.0.1:40075,DS-c2c9fc3e-80e5-437e-afff-02970722937f,DISK], DatanodeInfoWithStorage[127.0.0.1:34063,DS-afbabe9f-949f-4525-a552-b4988f1e7a1c,DISK], DatanodeInfoWithStorage[127.0.0.1:40015,DS-1b79d4f5-9722-4cb1-946b-46e2fda6ce8f,DISK], DatanodeInfoWithStorage[127.0.0.1:38787,DS-a5e3ea2b-fedc-40b6-87d1-ae2b8798bb32,DISK], DatanodeInfoWithStorage[127.0.0.1:43167,DS-2306675c-66cc-4069-a5f0-6bfd0dbbee3b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.ContentSummary.subAccess
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-932921163-172.17.0.18-1598422064258:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45535,DS-fac139af-8ffc-43a6-a703-4362ba91391a,DISK], DatanodeInfoWithStorage[127.0.0.1:35807,DS-959d589f-ce8d-4e01-8b27-670068328d5d,DISK], DatanodeInfoWithStorage[127.0.0.1:36877,DS-c690b9d8-c43c-4b5f-9cfe-a9777c3a2d68,DISK], DatanodeInfoWithStorage[127.0.0.1:45358,DS-c1ae71a7-19c0-40c3-8ad1-f30250310e14,DISK], DatanodeInfoWithStorage[127.0.0.1:41581,DS-fd485ddf-10a1-4cae-b03e-5b329367c049,DISK], DatanodeInfoWithStorage[127.0.0.1:38961,DS-36c12556-5356-4c13-be6d-085df34bb5cf,DISK], DatanodeInfoWithStorage[127.0.0.1:41417,DS-54fff72a-b3f1-4722-9e06-e415fc3f4cae,DISK], DatanodeInfoWithStorage[127.0.0.1:38058,DS-0f4b42e9-fd2f-493a-a4b6-36fa5e6a7459,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-932921163-172.17.0.18-1598422064258:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45535,DS-fac139af-8ffc-43a6-a703-4362ba91391a,DISK], DatanodeInfoWithStorage[127.0.0.1:35807,DS-959d589f-ce8d-4e01-8b27-670068328d5d,DISK], DatanodeInfoWithStorage[127.0.0.1:36877,DS-c690b9d8-c43c-4b5f-9cfe-a9777c3a2d68,DISK], DatanodeInfoWithStorage[127.0.0.1:45358,DS-c1ae71a7-19c0-40c3-8ad1-f30250310e14,DISK], DatanodeInfoWithStorage[127.0.0.1:41581,DS-fd485ddf-10a1-4cae-b03e-5b329367c049,DISK], DatanodeInfoWithStorage[127.0.0.1:38961,DS-36c12556-5356-4c13-be6d-085df34bb5cf,DISK], DatanodeInfoWithStorage[127.0.0.1:41417,DS-54fff72a-b3f1-4722-9e06-e415fc3f4cae,DISK], DatanodeInfoWithStorage[127.0.0.1:38058,DS-0f4b42e9-fd2f-493a-a4b6-36fa5e6a7459,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.ContentSummary.subAccess
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1402381227-172.17.0.18-1598422133528:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46743,DS-b68b290b-3584-42ba-b2c9-c8d35ebed781,DISK], DatanodeInfoWithStorage[127.0.0.1:44113,DS-64c6940f-4ce4-446c-a1c3-bbd16ab5f2a7,DISK], DatanodeInfoWithStorage[127.0.0.1:45250,DS-b77b8888-4238-4ef8-b8df-41fdf9762161,DISK], DatanodeInfoWithStorage[127.0.0.1:44549,DS-2d0cfe0f-57a3-4e8d-9445-3007092018db,DISK], DatanodeInfoWithStorage[127.0.0.1:34416,DS-fcec6612-2340-4797-a103-5a6bc0fa2154,DISK], DatanodeInfoWithStorage[127.0.0.1:35516,DS-ead090ff-1f6e-4b5b-a8af-c0775e756b11,DISK], DatanodeInfoWithStorage[127.0.0.1:46854,DS-dc205253-6e0d-42bf-abdd-a69e11ae658f,DISK], DatanodeInfoWithStorage[127.0.0.1:42465,DS-9a718b6b-f718-45d6-ab7f-6ddb571a1069,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1402381227-172.17.0.18-1598422133528:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46743,DS-b68b290b-3584-42ba-b2c9-c8d35ebed781,DISK], DatanodeInfoWithStorage[127.0.0.1:44113,DS-64c6940f-4ce4-446c-a1c3-bbd16ab5f2a7,DISK], DatanodeInfoWithStorage[127.0.0.1:45250,DS-b77b8888-4238-4ef8-b8df-41fdf9762161,DISK], DatanodeInfoWithStorage[127.0.0.1:44549,DS-2d0cfe0f-57a3-4e8d-9445-3007092018db,DISK], DatanodeInfoWithStorage[127.0.0.1:34416,DS-fcec6612-2340-4797-a103-5a6bc0fa2154,DISK], DatanodeInfoWithStorage[127.0.0.1:35516,DS-ead090ff-1f6e-4b5b-a8af-c0775e756b11,DISK], DatanodeInfoWithStorage[127.0.0.1:46854,DS-dc205253-6e0d-42bf-abdd-a69e11ae658f,DISK], DatanodeInfoWithStorage[127.0.0.1:42465,DS-9a718b6b-f718-45d6-ab7f-6ddb571a1069,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.ContentSummary.subAccess
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-990378831-172.17.0.18-1598422200397:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42668,DS-842ba36e-9138-4c37-9bcb-600e0bdc45e1,DISK], DatanodeInfoWithStorage[127.0.0.1:41751,DS-a982669f-7cd5-4b66-8fdf-184a1811bca6,DISK], DatanodeInfoWithStorage[127.0.0.1:35068,DS-a6fa96bb-5456-45a7-bb80-f12df95b500c,DISK], DatanodeInfoWithStorage[127.0.0.1:40385,DS-b898e935-8e48-4c5a-870c-5b15d28c0936,DISK], DatanodeInfoWithStorage[127.0.0.1:38077,DS-263e9311-c879-4596-ac20-897e50fc364d,DISK], DatanodeInfoWithStorage[127.0.0.1:39578,DS-f5d296dc-87f9-45f7-8f5c-e92cca5003da,DISK], DatanodeInfoWithStorage[127.0.0.1:37012,DS-821e5873-48cc-46ab-8ace-cffd222f47f6,DISK], DatanodeInfoWithStorage[127.0.0.1:39718,DS-a50b76f2-9273-472e-82b5-03776b67945d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-990378831-172.17.0.18-1598422200397:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42668,DS-842ba36e-9138-4c37-9bcb-600e0bdc45e1,DISK], DatanodeInfoWithStorage[127.0.0.1:41751,DS-a982669f-7cd5-4b66-8fdf-184a1811bca6,DISK], DatanodeInfoWithStorage[127.0.0.1:35068,DS-a6fa96bb-5456-45a7-bb80-f12df95b500c,DISK], DatanodeInfoWithStorage[127.0.0.1:40385,DS-b898e935-8e48-4c5a-870c-5b15d28c0936,DISK], DatanodeInfoWithStorage[127.0.0.1:38077,DS-263e9311-c879-4596-ac20-897e50fc364d,DISK], DatanodeInfoWithStorage[127.0.0.1:39578,DS-f5d296dc-87f9-45f7-8f5c-e92cca5003da,DISK], DatanodeInfoWithStorage[127.0.0.1:37012,DS-821e5873-48cc-46ab-8ace-cffd222f47f6,DISK], DatanodeInfoWithStorage[127.0.0.1:39718,DS-a50b76f2-9273-472e-82b5-03776b67945d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.permissions.ContentSummary.subAccess
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-697258210-172.17.0.18-1598422241512:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41000,DS-a8e2e2d6-ae88-4163-a0c4-7a52d5045344,DISK], DatanodeInfoWithStorage[127.0.0.1:33223,DS-51c854a9-1de7-481b-a80b-a285df0f399a,DISK], DatanodeInfoWithStorage[127.0.0.1:39233,DS-da89283b-fa54-4f14-8568-4e2385adad5a,DISK], DatanodeInfoWithStorage[127.0.0.1:46301,DS-0fab65d5-ef39-4744-84c8-a9d8fb2056e1,DISK], DatanodeInfoWithStorage[127.0.0.1:46289,DS-3b3d2ee8-2ef4-48e8-892c-be55c7680588,DISK], DatanodeInfoWithStorage[127.0.0.1:43490,DS-2d9464fc-63ba-4895-a0ff-02a343b1dc47,DISK], DatanodeInfoWithStorage[127.0.0.1:37850,DS-5caf0b0d-5dfe-4062-8ab4-c12d633363d1,DISK], DatanodeInfoWithStorage[127.0.0.1:37089,DS-c5d8e7d1-96d6-4ce2-9cca-e1671c8cc0b7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-697258210-172.17.0.18-1598422241512:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41000,DS-a8e2e2d6-ae88-4163-a0c4-7a52d5045344,DISK], DatanodeInfoWithStorage[127.0.0.1:33223,DS-51c854a9-1de7-481b-a80b-a285df0f399a,DISK], DatanodeInfoWithStorage[127.0.0.1:39233,DS-da89283b-fa54-4f14-8568-4e2385adad5a,DISK], DatanodeInfoWithStorage[127.0.0.1:46301,DS-0fab65d5-ef39-4744-84c8-a9d8fb2056e1,DISK], DatanodeInfoWithStorage[127.0.0.1:46289,DS-3b3d2ee8-2ef4-48e8-892c-be55c7680588,DISK], DatanodeInfoWithStorage[127.0.0.1:43490,DS-2d9464fc-63ba-4895-a0ff-02a343b1dc47,DISK], DatanodeInfoWithStorage[127.0.0.1:37850,DS-5caf0b0d-5dfe-4062-8ab4-c12d633363d1,DISK], DatanodeInfoWithStorage[127.0.0.1:37089,DS-c5d8e7d1-96d6-4ce2-9cca-e1671c8cc0b7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.ContentSummary.subAccess
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-893751188-172.17.0.18-1598422303093:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42899,DS-aa9950ac-b443-4204-bfd4-06cbba341ba5,DISK], DatanodeInfoWithStorage[127.0.0.1:40264,DS-af01484d-4b8d-40de-9c3e-380f077336ce,DISK], DatanodeInfoWithStorage[127.0.0.1:38477,DS-6f18cf4f-1994-496e-8fa5-fad9e4464ea2,DISK], DatanodeInfoWithStorage[127.0.0.1:34904,DS-b85ade10-f834-446f-9be0-706a734d1025,DISK], DatanodeInfoWithStorage[127.0.0.1:46182,DS-32cd5220-913e-4de4-87b8-bc42e19e75ce,DISK], DatanodeInfoWithStorage[127.0.0.1:43711,DS-61fbd141-eb16-47ce-aa3a-2d8d2a7d6e8e,DISK], DatanodeInfoWithStorage[127.0.0.1:45600,DS-affc7d24-b642-4109-937a-df10c85335ed,DISK], DatanodeInfoWithStorage[127.0.0.1:40012,DS-24a981a5-6311-4f46-98aa-34b110a2ad1d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-893751188-172.17.0.18-1598422303093:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42899,DS-aa9950ac-b443-4204-bfd4-06cbba341ba5,DISK], DatanodeInfoWithStorage[127.0.0.1:40264,DS-af01484d-4b8d-40de-9c3e-380f077336ce,DISK], DatanodeInfoWithStorage[127.0.0.1:38477,DS-6f18cf4f-1994-496e-8fa5-fad9e4464ea2,DISK], DatanodeInfoWithStorage[127.0.0.1:34904,DS-b85ade10-f834-446f-9be0-706a734d1025,DISK], DatanodeInfoWithStorage[127.0.0.1:46182,DS-32cd5220-913e-4de4-87b8-bc42e19e75ce,DISK], DatanodeInfoWithStorage[127.0.0.1:43711,DS-61fbd141-eb16-47ce-aa3a-2d8d2a7d6e8e,DISK], DatanodeInfoWithStorage[127.0.0.1:45600,DS-affc7d24-b642-4109-937a-df10c85335ed,DISK], DatanodeInfoWithStorage[127.0.0.1:40012,DS-24a981a5-6311-4f46-98aa-34b110a2ad1d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.ContentSummary.subAccess
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2143263529-172.17.0.18-1598422632828:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34777,DS-ebed0d80-a2df-491e-9831-82a6ab08b239,DISK], DatanodeInfoWithStorage[127.0.0.1:34737,DS-f8ebc3ef-9e62-48a1-80c5-6a843716efd7,DISK], DatanodeInfoWithStorage[127.0.0.1:45103,DS-a7f1cef5-b46d-4e7e-9c06-25f59249f3fe,DISK], DatanodeInfoWithStorage[127.0.0.1:35940,DS-f791c491-c223-4053-9e3c-00d85157898f,DISK], DatanodeInfoWithStorage[127.0.0.1:33332,DS-bdcc98d1-c0a4-4d11-831d-c0f49218e938,DISK], DatanodeInfoWithStorage[127.0.0.1:43971,DS-cb87f242-272f-485b-8764-884689c2648a,DISK], DatanodeInfoWithStorage[127.0.0.1:39016,DS-29c67bde-9e35-430f-8d5f-d38baf683564,DISK], DatanodeInfoWithStorage[127.0.0.1:38340,DS-17d25456-3af3-49cc-9793-4c9b99d4734e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2143263529-172.17.0.18-1598422632828:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34777,DS-ebed0d80-a2df-491e-9831-82a6ab08b239,DISK], DatanodeInfoWithStorage[127.0.0.1:34737,DS-f8ebc3ef-9e62-48a1-80c5-6a843716efd7,DISK], DatanodeInfoWithStorage[127.0.0.1:45103,DS-a7f1cef5-b46d-4e7e-9c06-25f59249f3fe,DISK], DatanodeInfoWithStorage[127.0.0.1:35940,DS-f791c491-c223-4053-9e3c-00d85157898f,DISK], DatanodeInfoWithStorage[127.0.0.1:33332,DS-bdcc98d1-c0a4-4d11-831d-c0f49218e938,DISK], DatanodeInfoWithStorage[127.0.0.1:43971,DS-cb87f242-272f-485b-8764-884689c2648a,DISK], DatanodeInfoWithStorage[127.0.0.1:39016,DS-29c67bde-9e35-430f-8d5f-d38baf683564,DISK], DatanodeInfoWithStorage[127.0.0.1:38340,DS-17d25456-3af3-49cc-9793-4c9b99d4734e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.ContentSummary.subAccess
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-963071518-172.17.0.18-1598422698146:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35550,DS-9fa7bd13-6c69-467e-ad33-b565338a01c7,DISK], DatanodeInfoWithStorage[127.0.0.1:39733,DS-857965f4-b1d9-4535-808c-f035a5ce3437,DISK], DatanodeInfoWithStorage[127.0.0.1:44257,DS-22a2d83f-424a-4691-8e52-20cabef90bb9,DISK], DatanodeInfoWithStorage[127.0.0.1:37899,DS-e57c5f00-0f96-45a7-aabb-d3e498b3caed,DISK], DatanodeInfoWithStorage[127.0.0.1:42479,DS-f691e792-4999-4589-b018-0f6e5c21e71c,DISK], DatanodeInfoWithStorage[127.0.0.1:46388,DS-dbc5ed25-0c69-426b-8a56-e3d772d7dfe8,DISK], DatanodeInfoWithStorage[127.0.0.1:44269,DS-f63781b2-983b-4685-ae31-56066bdf6315,DISK], DatanodeInfoWithStorage[127.0.0.1:44073,DS-bf6e78a3-c664-4497-8d51-8b3d93a2e8c5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-963071518-172.17.0.18-1598422698146:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35550,DS-9fa7bd13-6c69-467e-ad33-b565338a01c7,DISK], DatanodeInfoWithStorage[127.0.0.1:39733,DS-857965f4-b1d9-4535-808c-f035a5ce3437,DISK], DatanodeInfoWithStorage[127.0.0.1:44257,DS-22a2d83f-424a-4691-8e52-20cabef90bb9,DISK], DatanodeInfoWithStorage[127.0.0.1:37899,DS-e57c5f00-0f96-45a7-aabb-d3e498b3caed,DISK], DatanodeInfoWithStorage[127.0.0.1:42479,DS-f691e792-4999-4589-b018-0f6e5c21e71c,DISK], DatanodeInfoWithStorage[127.0.0.1:46388,DS-dbc5ed25-0c69-426b-8a56-e3d772d7dfe8,DISK], DatanodeInfoWithStorage[127.0.0.1:44269,DS-f63781b2-983b-4685-ae31-56066bdf6315,DISK], DatanodeInfoWithStorage[127.0.0.1:44073,DS-bf6e78a3-c664-4497-8d51-8b3d93a2e8c5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.ContentSummary.subAccess
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-834361573-172.17.0.18-1598422906498:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32908,DS-cbf2d444-00a0-49d1-9e82-8bf0f5491c7f,DISK], DatanodeInfoWithStorage[127.0.0.1:44088,DS-33aec82c-9222-4ac9-8cb4-47c879be684d,DISK], DatanodeInfoWithStorage[127.0.0.1:45604,DS-1175653f-27f1-48d3-8871-f2c2b6bff684,DISK], DatanodeInfoWithStorage[127.0.0.1:42731,DS-2a68aacc-0526-438c-b98f-59d09d6d2584,DISK], DatanodeInfoWithStorage[127.0.0.1:36331,DS-38f3d71b-ba5b-4d75-ab6a-efcb4f7da2f1,DISK], DatanodeInfoWithStorage[127.0.0.1:33859,DS-b713a6d5-ef6d-44e4-b9bd-e474fd1056e6,DISK], DatanodeInfoWithStorage[127.0.0.1:37457,DS-baee86f7-13e7-401d-a05f-5957981861df,DISK], DatanodeInfoWithStorage[127.0.0.1:33327,DS-c20b5ccd-455a-4e84-999a-38dd7fb59427,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-834361573-172.17.0.18-1598422906498:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32908,DS-cbf2d444-00a0-49d1-9e82-8bf0f5491c7f,DISK], DatanodeInfoWithStorage[127.0.0.1:44088,DS-33aec82c-9222-4ac9-8cb4-47c879be684d,DISK], DatanodeInfoWithStorage[127.0.0.1:45604,DS-1175653f-27f1-48d3-8871-f2c2b6bff684,DISK], DatanodeInfoWithStorage[127.0.0.1:42731,DS-2a68aacc-0526-438c-b98f-59d09d6d2584,DISK], DatanodeInfoWithStorage[127.0.0.1:36331,DS-38f3d71b-ba5b-4d75-ab6a-efcb4f7da2f1,DISK], DatanodeInfoWithStorage[127.0.0.1:33859,DS-b713a6d5-ef6d-44e4-b9bd-e474fd1056e6,DISK], DatanodeInfoWithStorage[127.0.0.1:37457,DS-baee86f7-13e7-401d-a05f-5957981861df,DISK], DatanodeInfoWithStorage[127.0.0.1:33327,DS-c20b5ccd-455a-4e84-999a-38dd7fb59427,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5123
