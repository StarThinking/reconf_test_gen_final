reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-227570931-172.17.0.20-1598441833918:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46824,DS-72c7e46f-0317-4cae-a808-1979720052ba,DISK], DatanodeInfoWithStorage[127.0.0.1:46851,DS-3e6f8188-0e8d-4134-8232-c32917a907d7,DISK], DatanodeInfoWithStorage[127.0.0.1:40541,DS-2e3636d6-4e61-4c17-9d9c-87ef5cf68e2d,DISK], DatanodeInfoWithStorage[127.0.0.1:33107,DS-06264ce2-7f34-4fb5-8f72-259475920af0,DISK], DatanodeInfoWithStorage[127.0.0.1:43177,DS-c9a4afd7-32bd-43de-9c9e-3677d5a49a31,DISK], DatanodeInfoWithStorage[127.0.0.1:39773,DS-6df6e0e4-e777-4f9e-869e-dda50eb3199a,DISK], DatanodeInfoWithStorage[127.0.0.1:40958,DS-1190f5d4-7880-4e24-b646-a2caced108da,DISK], DatanodeInfoWithStorage[127.0.0.1:44052,DS-a358d90d-2e33-40d2-9d36-8bb2cbe1dfa2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-227570931-172.17.0.20-1598441833918:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46824,DS-72c7e46f-0317-4cae-a808-1979720052ba,DISK], DatanodeInfoWithStorage[127.0.0.1:46851,DS-3e6f8188-0e8d-4134-8232-c32917a907d7,DISK], DatanodeInfoWithStorage[127.0.0.1:40541,DS-2e3636d6-4e61-4c17-9d9c-87ef5cf68e2d,DISK], DatanodeInfoWithStorage[127.0.0.1:33107,DS-06264ce2-7f34-4fb5-8f72-259475920af0,DISK], DatanodeInfoWithStorage[127.0.0.1:43177,DS-c9a4afd7-32bd-43de-9c9e-3677d5a49a31,DISK], DatanodeInfoWithStorage[127.0.0.1:39773,DS-6df6e0e4-e777-4f9e-869e-dda50eb3199a,DISK], DatanodeInfoWithStorage[127.0.0.1:40958,DS-1190f5d4-7880-4e24-b646-a2caced108da,DISK], DatanodeInfoWithStorage[127.0.0.1:44052,DS-a358d90d-2e33-40d2-9d36-8bb2cbe1dfa2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1864323381-172.17.0.20-1598441945566:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39417,DS-e30183b4-0ea7-4c32-b18d-d07689f63318,DISK], DatanodeInfoWithStorage[127.0.0.1:36182,DS-9007cea0-ef51-447d-878b-bf7533c7b0fe,DISK], DatanodeInfoWithStorage[127.0.0.1:43801,DS-d35f86ba-b37d-4d36-b2b8-8a440a80ebf1,DISK], DatanodeInfoWithStorage[127.0.0.1:34758,DS-a513bd38-a5ea-438c-a3a3-87a65fa2805f,DISK], DatanodeInfoWithStorage[127.0.0.1:43985,DS-dd77a62c-8b92-40f5-8c30-28bdc080f37c,DISK], DatanodeInfoWithStorage[127.0.0.1:38493,DS-0de664d2-b770-48f4-9b07-6f0a53dee030,DISK], DatanodeInfoWithStorage[127.0.0.1:39290,DS-6f93f7e3-e4ac-47c4-81d1-9f3e90b01048,DISK], DatanodeInfoWithStorage[127.0.0.1:44504,DS-85974dfd-c3c4-40fe-a70e-4ed97e72de5b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1864323381-172.17.0.20-1598441945566:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39417,DS-e30183b4-0ea7-4c32-b18d-d07689f63318,DISK], DatanodeInfoWithStorage[127.0.0.1:36182,DS-9007cea0-ef51-447d-878b-bf7533c7b0fe,DISK], DatanodeInfoWithStorage[127.0.0.1:43801,DS-d35f86ba-b37d-4d36-b2b8-8a440a80ebf1,DISK], DatanodeInfoWithStorage[127.0.0.1:34758,DS-a513bd38-a5ea-438c-a3a3-87a65fa2805f,DISK], DatanodeInfoWithStorage[127.0.0.1:43985,DS-dd77a62c-8b92-40f5-8c30-28bdc080f37c,DISK], DatanodeInfoWithStorage[127.0.0.1:38493,DS-0de664d2-b770-48f4-9b07-6f0a53dee030,DISK], DatanodeInfoWithStorage[127.0.0.1:39290,DS-6f93f7e3-e4ac-47c4-81d1-9f3e90b01048,DISK], DatanodeInfoWithStorage[127.0.0.1:44504,DS-85974dfd-c3c4-40fe-a70e-4ed97e72de5b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1502874129-172.17.0.20-1598442115171:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34214,DS-de4dc9e0-4208-490a-b317-5b8a42a10fe1,DISK], DatanodeInfoWithStorage[127.0.0.1:35586,DS-23c5747c-1574-4d9c-ad4d-5b175865d68b,DISK], DatanodeInfoWithStorage[127.0.0.1:38760,DS-75ea7ec0-c258-4293-8402-c6b499301dd2,DISK], DatanodeInfoWithStorage[127.0.0.1:32941,DS-0dc56d88-2f9e-42c4-ae32-ca68c01eb3f0,DISK], DatanodeInfoWithStorage[127.0.0.1:35028,DS-f3587919-ff81-429b-8fb7-5b6220907a9a,DISK], DatanodeInfoWithStorage[127.0.0.1:36282,DS-3c1bac15-9d93-4c3a-8343-a81e6bfb1c8e,DISK], DatanodeInfoWithStorage[127.0.0.1:45933,DS-2cfa8d30-2e7b-4418-9f5c-cb7e1f33fbc8,DISK], DatanodeInfoWithStorage[127.0.0.1:45952,DS-bd015fad-925e-48cf-ac40-4d9bf747bf26,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1502874129-172.17.0.20-1598442115171:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34214,DS-de4dc9e0-4208-490a-b317-5b8a42a10fe1,DISK], DatanodeInfoWithStorage[127.0.0.1:35586,DS-23c5747c-1574-4d9c-ad4d-5b175865d68b,DISK], DatanodeInfoWithStorage[127.0.0.1:38760,DS-75ea7ec0-c258-4293-8402-c6b499301dd2,DISK], DatanodeInfoWithStorage[127.0.0.1:32941,DS-0dc56d88-2f9e-42c4-ae32-ca68c01eb3f0,DISK], DatanodeInfoWithStorage[127.0.0.1:35028,DS-f3587919-ff81-429b-8fb7-5b6220907a9a,DISK], DatanodeInfoWithStorage[127.0.0.1:36282,DS-3c1bac15-9d93-4c3a-8343-a81e6bfb1c8e,DISK], DatanodeInfoWithStorage[127.0.0.1:45933,DS-2cfa8d30-2e7b-4418-9f5c-cb7e1f33fbc8,DISK], DatanodeInfoWithStorage[127.0.0.1:45952,DS-bd015fad-925e-48cf-ac40-4d9bf747bf26,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1767502595-172.17.0.20-1598442252361:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35202,DS-00fc8321-1edb-413b-b596-38e0eebd3a3e,DISK], DatanodeInfoWithStorage[127.0.0.1:45301,DS-7892de9a-e622-453b-a759-521df7773fb5,DISK], DatanodeInfoWithStorage[127.0.0.1:33194,DS-ac19ac61-e4ec-42c1-a4c9-cf74e58efca3,DISK], DatanodeInfoWithStorage[127.0.0.1:46605,DS-957bd09a-ad81-4cc4-92cc-a5e838c9d541,DISK], DatanodeInfoWithStorage[127.0.0.1:43952,DS-3d9c15f1-ae87-40be-96bc-2a088b5c1dac,DISK], DatanodeInfoWithStorage[127.0.0.1:43203,DS-78ff6363-373c-46cf-a006-54046086f383,DISK], DatanodeInfoWithStorage[127.0.0.1:44072,DS-6dcb09e5-b49a-4e26-9706-227b58caf719,DISK], DatanodeInfoWithStorage[127.0.0.1:43306,DS-c6475a3d-7ac7-4ae8-ba50-87cb97df0a7c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1767502595-172.17.0.20-1598442252361:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35202,DS-00fc8321-1edb-413b-b596-38e0eebd3a3e,DISK], DatanodeInfoWithStorage[127.0.0.1:45301,DS-7892de9a-e622-453b-a759-521df7773fb5,DISK], DatanodeInfoWithStorage[127.0.0.1:33194,DS-ac19ac61-e4ec-42c1-a4c9-cf74e58efca3,DISK], DatanodeInfoWithStorage[127.0.0.1:46605,DS-957bd09a-ad81-4cc4-92cc-a5e838c9d541,DISK], DatanodeInfoWithStorage[127.0.0.1:43952,DS-3d9c15f1-ae87-40be-96bc-2a088b5c1dac,DISK], DatanodeInfoWithStorage[127.0.0.1:43203,DS-78ff6363-373c-46cf-a006-54046086f383,DISK], DatanodeInfoWithStorage[127.0.0.1:44072,DS-6dcb09e5-b49a-4e26-9706-227b58caf719,DISK], DatanodeInfoWithStorage[127.0.0.1:43306,DS-c6475a3d-7ac7-4ae8-ba50-87cb97df0a7c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-999853485-172.17.0.20-1598442626826:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44791,DS-9ea74fc8-bc03-4c84-b92c-5ff6211c9711,DISK], DatanodeInfoWithStorage[127.0.0.1:36880,DS-76bfa8bb-1b7e-4b48-a9f9-b03619c5ca1e,DISK], DatanodeInfoWithStorage[127.0.0.1:34511,DS-056abc8d-a053-48fe-98ca-45a517362a02,DISK], DatanodeInfoWithStorage[127.0.0.1:36677,DS-3c50e22a-637b-4947-b80b-e21080909d31,DISK], DatanodeInfoWithStorage[127.0.0.1:34381,DS-634cbcfb-460a-421f-8b25-307ef824b8a1,DISK], DatanodeInfoWithStorage[127.0.0.1:41198,DS-e56760a7-0d7b-456f-a2b5-3d504f00b2d1,DISK], DatanodeInfoWithStorage[127.0.0.1:34508,DS-4b68d9b8-f2f2-47ea-8b0c-ea2ce4d42803,DISK], DatanodeInfoWithStorage[127.0.0.1:34603,DS-7402b39c-33e4-44d5-aece-1ba5becaa18e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-999853485-172.17.0.20-1598442626826:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44791,DS-9ea74fc8-bc03-4c84-b92c-5ff6211c9711,DISK], DatanodeInfoWithStorage[127.0.0.1:36880,DS-76bfa8bb-1b7e-4b48-a9f9-b03619c5ca1e,DISK], DatanodeInfoWithStorage[127.0.0.1:34511,DS-056abc8d-a053-48fe-98ca-45a517362a02,DISK], DatanodeInfoWithStorage[127.0.0.1:36677,DS-3c50e22a-637b-4947-b80b-e21080909d31,DISK], DatanodeInfoWithStorage[127.0.0.1:34381,DS-634cbcfb-460a-421f-8b25-307ef824b8a1,DISK], DatanodeInfoWithStorage[127.0.0.1:41198,DS-e56760a7-0d7b-456f-a2b5-3d504f00b2d1,DISK], DatanodeInfoWithStorage[127.0.0.1:34508,DS-4b68d9b8-f2f2-47ea-8b0c-ea2ce4d42803,DISK], DatanodeInfoWithStorage[127.0.0.1:34603,DS-7402b39c-33e4-44d5-aece-1ba5becaa18e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1314536958-172.17.0.20-1598442659525:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43626,DS-ff31f206-9372-413d-9182-cf864da8a8e4,DISK], DatanodeInfoWithStorage[127.0.0.1:34896,DS-8101ef58-9613-485e-88cc-622c2afb8c8a,DISK], DatanodeInfoWithStorage[127.0.0.1:43808,DS-64cde421-ee0d-47cc-8dc9-e9008c537cda,DISK], DatanodeInfoWithStorage[127.0.0.1:42719,DS-b9d7c0a5-5870-4422-8f61-425651b3667e,DISK], DatanodeInfoWithStorage[127.0.0.1:39354,DS-a75cbd0e-4c98-468c-bbeb-84b854c3c8d8,DISK], DatanodeInfoWithStorage[127.0.0.1:33819,DS-2d19704b-5fef-42db-a40c-a28a20ae19f7,DISK], DatanodeInfoWithStorage[127.0.0.1:40015,DS-574a3f78-a574-44f2-baa9-69577ff5c608,DISK], DatanodeInfoWithStorage[127.0.0.1:45989,DS-561af470-0455-4e00-aebe-5b853db42f46,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1314536958-172.17.0.20-1598442659525:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43626,DS-ff31f206-9372-413d-9182-cf864da8a8e4,DISK], DatanodeInfoWithStorage[127.0.0.1:34896,DS-8101ef58-9613-485e-88cc-622c2afb8c8a,DISK], DatanodeInfoWithStorage[127.0.0.1:43808,DS-64cde421-ee0d-47cc-8dc9-e9008c537cda,DISK], DatanodeInfoWithStorage[127.0.0.1:42719,DS-b9d7c0a5-5870-4422-8f61-425651b3667e,DISK], DatanodeInfoWithStorage[127.0.0.1:39354,DS-a75cbd0e-4c98-468c-bbeb-84b854c3c8d8,DISK], DatanodeInfoWithStorage[127.0.0.1:33819,DS-2d19704b-5fef-42db-a40c-a28a20ae19f7,DISK], DatanodeInfoWithStorage[127.0.0.1:40015,DS-574a3f78-a574-44f2-baa9-69577ff5c608,DISK], DatanodeInfoWithStorage[127.0.0.1:45989,DS-561af470-0455-4e00-aebe-5b853db42f46,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2071978104-172.17.0.20-1598442759172:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36015,DS-be945325-55fd-4d20-9576-04edefcac2d0,DISK], DatanodeInfoWithStorage[127.0.0.1:43264,DS-a7c2cbef-9df9-45a7-8b39-b765cb73d13e,DISK], DatanodeInfoWithStorage[127.0.0.1:34844,DS-65cd9d35-94ef-40ce-80a8-59c2f3b88463,DISK], DatanodeInfoWithStorage[127.0.0.1:46859,DS-950c66b8-0df6-4dd2-ab40-6ab05aa4978d,DISK], DatanodeInfoWithStorage[127.0.0.1:33414,DS-9d5cb335-c4a2-4c47-b52e-2d857f1d99c5,DISK], DatanodeInfoWithStorage[127.0.0.1:40118,DS-fe10f036-2533-4399-978d-05ec8400301f,DISK], DatanodeInfoWithStorage[127.0.0.1:33434,DS-a6a3ce6c-cc84-4ee8-93e0-303ba9bdac08,DISK], DatanodeInfoWithStorage[127.0.0.1:39069,DS-786d361e-41b5-423f-81f8-79eaa127aa62,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2071978104-172.17.0.20-1598442759172:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36015,DS-be945325-55fd-4d20-9576-04edefcac2d0,DISK], DatanodeInfoWithStorage[127.0.0.1:43264,DS-a7c2cbef-9df9-45a7-8b39-b765cb73d13e,DISK], DatanodeInfoWithStorage[127.0.0.1:34844,DS-65cd9d35-94ef-40ce-80a8-59c2f3b88463,DISK], DatanodeInfoWithStorage[127.0.0.1:46859,DS-950c66b8-0df6-4dd2-ab40-6ab05aa4978d,DISK], DatanodeInfoWithStorage[127.0.0.1:33414,DS-9d5cb335-c4a2-4c47-b52e-2d857f1d99c5,DISK], DatanodeInfoWithStorage[127.0.0.1:40118,DS-fe10f036-2533-4399-978d-05ec8400301f,DISK], DatanodeInfoWithStorage[127.0.0.1:33434,DS-a6a3ce6c-cc84-4ee8-93e0-303ba9bdac08,DISK], DatanodeInfoWithStorage[127.0.0.1:39069,DS-786d361e-41b5-423f-81f8-79eaa127aa62,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1406802530-172.17.0.20-1598442856850:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40660,DS-6d28caf6-a5fa-461e-8936-68129ad63097,DISK], DatanodeInfoWithStorage[127.0.0.1:38506,DS-d1607a14-7744-45f7-86a3-978fc844602c,DISK], DatanodeInfoWithStorage[127.0.0.1:34241,DS-dd0696f9-1516-46c3-af5a-a6130bc77ef9,DISK], DatanodeInfoWithStorage[127.0.0.1:35686,DS-82f77762-1e1e-455c-8980-2173838b2eca,DISK], DatanodeInfoWithStorage[127.0.0.1:41024,DS-c2fdac87-1d89-427c-a708-ce6d1b8b6c99,DISK], DatanodeInfoWithStorage[127.0.0.1:37052,DS-f7c986fe-4f8d-4d86-9b9f-b9ac0b6e7dd5,DISK], DatanodeInfoWithStorage[127.0.0.1:37010,DS-e2a62fdf-d89a-4d28-82e9-cace71d93fe7,DISK], DatanodeInfoWithStorage[127.0.0.1:34199,DS-40d06c73-48e4-4ee9-be3b-22ab4cc9bb9b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1406802530-172.17.0.20-1598442856850:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40660,DS-6d28caf6-a5fa-461e-8936-68129ad63097,DISK], DatanodeInfoWithStorage[127.0.0.1:38506,DS-d1607a14-7744-45f7-86a3-978fc844602c,DISK], DatanodeInfoWithStorage[127.0.0.1:34241,DS-dd0696f9-1516-46c3-af5a-a6130bc77ef9,DISK], DatanodeInfoWithStorage[127.0.0.1:35686,DS-82f77762-1e1e-455c-8980-2173838b2eca,DISK], DatanodeInfoWithStorage[127.0.0.1:41024,DS-c2fdac87-1d89-427c-a708-ce6d1b8b6c99,DISK], DatanodeInfoWithStorage[127.0.0.1:37052,DS-f7c986fe-4f8d-4d86-9b9f-b9ac0b6e7dd5,DISK], DatanodeInfoWithStorage[127.0.0.1:37010,DS-e2a62fdf-d89a-4d28-82e9-cace71d93fe7,DISK], DatanodeInfoWithStorage[127.0.0.1:34199,DS-40d06c73-48e4-4ee9-be3b-22ab4cc9bb9b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1822130433-172.17.0.20-1598443049833:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37889,DS-9e108f77-886f-4553-bcc5-d2e6e4640496,DISK], DatanodeInfoWithStorage[127.0.0.1:38936,DS-b1001019-a3e0-45ef-8309-ea1e19d4024a,DISK], DatanodeInfoWithStorage[127.0.0.1:42881,DS-74caf2f1-fcc2-4ad1-96ce-20be21e38468,DISK], DatanodeInfoWithStorage[127.0.0.1:41217,DS-3cea27f0-174c-40a4-81cf-40b0e766d055,DISK], DatanodeInfoWithStorage[127.0.0.1:40527,DS-bf97a135-16bc-4bcd-8e77-193adbb17f69,DISK], DatanodeInfoWithStorage[127.0.0.1:39601,DS-1ade7159-4cfc-46ff-a6c5-fb40f1bc06c8,DISK], DatanodeInfoWithStorage[127.0.0.1:43617,DS-0a2659dd-d0d7-4756-b275-410efb559dc8,DISK], DatanodeInfoWithStorage[127.0.0.1:40807,DS-30de2ede-04bf-4e41-9378-befdc71def34,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1822130433-172.17.0.20-1598443049833:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37889,DS-9e108f77-886f-4553-bcc5-d2e6e4640496,DISK], DatanodeInfoWithStorage[127.0.0.1:38936,DS-b1001019-a3e0-45ef-8309-ea1e19d4024a,DISK], DatanodeInfoWithStorage[127.0.0.1:42881,DS-74caf2f1-fcc2-4ad1-96ce-20be21e38468,DISK], DatanodeInfoWithStorage[127.0.0.1:41217,DS-3cea27f0-174c-40a4-81cf-40b0e766d055,DISK], DatanodeInfoWithStorage[127.0.0.1:40527,DS-bf97a135-16bc-4bcd-8e77-193adbb17f69,DISK], DatanodeInfoWithStorage[127.0.0.1:39601,DS-1ade7159-4cfc-46ff-a6c5-fb40f1bc06c8,DISK], DatanodeInfoWithStorage[127.0.0.1:43617,DS-0a2659dd-d0d7-4756-b275-410efb559dc8,DISK], DatanodeInfoWithStorage[127.0.0.1:40807,DS-30de2ede-04bf-4e41-9378-befdc71def34,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1762567105-172.17.0.20-1598443208092:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41784,DS-bf5f8944-0e41-49b8-8bf1-ec122e647b33,DISK], DatanodeInfoWithStorage[127.0.0.1:43141,DS-2116ee57-8597-42f5-96ea-4e8ffe9434d4,DISK], DatanodeInfoWithStorage[127.0.0.1:45078,DS-507d89b2-7db5-426e-b685-7511ab508653,DISK], DatanodeInfoWithStorage[127.0.0.1:39712,DS-b5c14f72-5020-4304-9ebd-d736527d4dd5,DISK], DatanodeInfoWithStorage[127.0.0.1:37516,DS-6f592db1-f878-4985-93ab-99bbb471edbe,DISK], DatanodeInfoWithStorage[127.0.0.1:32801,DS-d9320471-468d-4268-8b61-d944be9d643a,DISK], DatanodeInfoWithStorage[127.0.0.1:36790,DS-b6c368be-e686-424d-b76d-ac5e0489e3ef,DISK], DatanodeInfoWithStorage[127.0.0.1:41551,DS-391fa45a-11a8-496d-8020-ae320ea5ce7c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1762567105-172.17.0.20-1598443208092:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41784,DS-bf5f8944-0e41-49b8-8bf1-ec122e647b33,DISK], DatanodeInfoWithStorage[127.0.0.1:43141,DS-2116ee57-8597-42f5-96ea-4e8ffe9434d4,DISK], DatanodeInfoWithStorage[127.0.0.1:45078,DS-507d89b2-7db5-426e-b685-7511ab508653,DISK], DatanodeInfoWithStorage[127.0.0.1:39712,DS-b5c14f72-5020-4304-9ebd-d736527d4dd5,DISK], DatanodeInfoWithStorage[127.0.0.1:37516,DS-6f592db1-f878-4985-93ab-99bbb471edbe,DISK], DatanodeInfoWithStorage[127.0.0.1:32801,DS-d9320471-468d-4268-8b61-d944be9d643a,DISK], DatanodeInfoWithStorage[127.0.0.1:36790,DS-b6c368be-e686-424d-b76d-ac5e0489e3ef,DISK], DatanodeInfoWithStorage[127.0.0.1:41551,DS-391fa45a-11a8-496d-8020-ae320ea5ce7c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-739688616-172.17.0.20-1598443277547:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39019,DS-191dc1ed-5d9b-4ebc-9d2c-a54c56f0dfcb,DISK], DatanodeInfoWithStorage[127.0.0.1:44785,DS-bc2e98e7-17d0-4834-b73e-c3afca60f64f,DISK], DatanodeInfoWithStorage[127.0.0.1:41358,DS-2c2591d2-8313-4225-bc45-464a8b0960f0,DISK], DatanodeInfoWithStorage[127.0.0.1:41652,DS-733b21c6-6cba-4ebe-bb05-0db9c70d5420,DISK], DatanodeInfoWithStorage[127.0.0.1:32951,DS-16be165d-888a-49be-bac1-d19a0a739d08,DISK], DatanodeInfoWithStorage[127.0.0.1:40728,DS-ec37fb54-eae6-4645-943b-74a6355d2657,DISK], DatanodeInfoWithStorage[127.0.0.1:37714,DS-81d8dfa2-ef7d-40aa-be77-d8a2d67055a0,DISK], DatanodeInfoWithStorage[127.0.0.1:45515,DS-a50e3ced-1667-4383-8ff2-c48399323077,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-739688616-172.17.0.20-1598443277547:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39019,DS-191dc1ed-5d9b-4ebc-9d2c-a54c56f0dfcb,DISK], DatanodeInfoWithStorage[127.0.0.1:44785,DS-bc2e98e7-17d0-4834-b73e-c3afca60f64f,DISK], DatanodeInfoWithStorage[127.0.0.1:41358,DS-2c2591d2-8313-4225-bc45-464a8b0960f0,DISK], DatanodeInfoWithStorage[127.0.0.1:41652,DS-733b21c6-6cba-4ebe-bb05-0db9c70d5420,DISK], DatanodeInfoWithStorage[127.0.0.1:32951,DS-16be165d-888a-49be-bac1-d19a0a739d08,DISK], DatanodeInfoWithStorage[127.0.0.1:40728,DS-ec37fb54-eae6-4645-943b-74a6355d2657,DISK], DatanodeInfoWithStorage[127.0.0.1:37714,DS-81d8dfa2-ef7d-40aa-be77-d8a2d67055a0,DISK], DatanodeInfoWithStorage[127.0.0.1:45515,DS-a50e3ced-1667-4383-8ff2-c48399323077,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1051952290-172.17.0.20-1598443742878:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36268,DS-5638e9ae-633a-4e41-bc4e-2e853597b34e,DISK], DatanodeInfoWithStorage[127.0.0.1:35330,DS-604e1c34-031e-41fb-8164-6c1ae23ecd6d,DISK], DatanodeInfoWithStorage[127.0.0.1:43854,DS-563b9ff9-c96b-4fb7-a6a1-ecf7d0b82858,DISK], DatanodeInfoWithStorage[127.0.0.1:33097,DS-06b81dac-b05d-4a3f-9f4f-f609b236dbe0,DISK], DatanodeInfoWithStorage[127.0.0.1:46345,DS-e4769a43-45ac-4e0f-9f88-eed1c4d70b87,DISK], DatanodeInfoWithStorage[127.0.0.1:38872,DS-d552b290-affe-4258-9a1c-1d1934928117,DISK], DatanodeInfoWithStorage[127.0.0.1:42428,DS-d233012d-b525-4668-9ba6-ff1874a1dc04,DISK], DatanodeInfoWithStorage[127.0.0.1:34985,DS-b1491b0a-f973-48ea-b86a-9f8389bd5436,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1051952290-172.17.0.20-1598443742878:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36268,DS-5638e9ae-633a-4e41-bc4e-2e853597b34e,DISK], DatanodeInfoWithStorage[127.0.0.1:35330,DS-604e1c34-031e-41fb-8164-6c1ae23ecd6d,DISK], DatanodeInfoWithStorage[127.0.0.1:43854,DS-563b9ff9-c96b-4fb7-a6a1-ecf7d0b82858,DISK], DatanodeInfoWithStorage[127.0.0.1:33097,DS-06b81dac-b05d-4a3f-9f4f-f609b236dbe0,DISK], DatanodeInfoWithStorage[127.0.0.1:46345,DS-e4769a43-45ac-4e0f-9f88-eed1c4d70b87,DISK], DatanodeInfoWithStorage[127.0.0.1:38872,DS-d552b290-affe-4258-9a1c-1d1934928117,DISK], DatanodeInfoWithStorage[127.0.0.1:42428,DS-d233012d-b525-4668-9ba6-ff1874a1dc04,DISK], DatanodeInfoWithStorage[127.0.0.1:34985,DS-b1491b0a-f973-48ea-b86a-9f8389bd5436,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1685509998-172.17.0.20-1598443871392:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45220,DS-a35b94aa-231e-4362-adef-5b7114729afd,DISK], DatanodeInfoWithStorage[127.0.0.1:34349,DS-f2f1b916-6970-42b8-88ed-2722ef26d135,DISK], DatanodeInfoWithStorage[127.0.0.1:38802,DS-da416464-86c3-4c26-ad4f-2634305d4bb3,DISK], DatanodeInfoWithStorage[127.0.0.1:38245,DS-20d6db7a-bb1f-4a9e-88cd-4b122716977b,DISK], DatanodeInfoWithStorage[127.0.0.1:39797,DS-a30ec1a4-783e-484f-88d5-c92a7c6250c0,DISK], DatanodeInfoWithStorage[127.0.0.1:42754,DS-2333b2d5-fa7c-4770-94fa-88499278b27b,DISK], DatanodeInfoWithStorage[127.0.0.1:44790,DS-5f7317a2-003f-4c5c-a852-702e723e6354,DISK], DatanodeInfoWithStorage[127.0.0.1:38723,DS-9e1897e1-5901-460b-bfce-0a396ea1371a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1685509998-172.17.0.20-1598443871392:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45220,DS-a35b94aa-231e-4362-adef-5b7114729afd,DISK], DatanodeInfoWithStorage[127.0.0.1:34349,DS-f2f1b916-6970-42b8-88ed-2722ef26d135,DISK], DatanodeInfoWithStorage[127.0.0.1:38802,DS-da416464-86c3-4c26-ad4f-2634305d4bb3,DISK], DatanodeInfoWithStorage[127.0.0.1:38245,DS-20d6db7a-bb1f-4a9e-88cd-4b122716977b,DISK], DatanodeInfoWithStorage[127.0.0.1:39797,DS-a30ec1a4-783e-484f-88d5-c92a7c6250c0,DISK], DatanodeInfoWithStorage[127.0.0.1:42754,DS-2333b2d5-fa7c-4770-94fa-88499278b27b,DISK], DatanodeInfoWithStorage[127.0.0.1:44790,DS-5f7317a2-003f-4c5c-a852-702e723e6354,DISK], DatanodeInfoWithStorage[127.0.0.1:38723,DS-9e1897e1-5901-460b-bfce-0a396ea1371a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-955976040-172.17.0.20-1598444024228:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42935,DS-ff72ff4c-4cfd-4427-b1b0-2388403c8225,DISK], DatanodeInfoWithStorage[127.0.0.1:33340,DS-c5cc51ec-4615-4f7f-afe2-e743eac4bbe8,DISK], DatanodeInfoWithStorage[127.0.0.1:43029,DS-24ae1e94-6e3f-4bb5-933d-7caa865d1077,DISK], DatanodeInfoWithStorage[127.0.0.1:35868,DS-728c9c2a-e21e-47ba-8f4b-e8017dfae703,DISK], DatanodeInfoWithStorage[127.0.0.1:39985,DS-dd10f32b-bd91-4ff2-becf-1a8778350daa,DISK], DatanodeInfoWithStorage[127.0.0.1:40156,DS-b0137f21-ec3d-4036-9638-51bf2c444614,DISK], DatanodeInfoWithStorage[127.0.0.1:36281,DS-e0fa4ee3-7960-4172-8183-d584a746b889,DISK], DatanodeInfoWithStorage[127.0.0.1:43999,DS-ce3904a9-f4b0-4171-9d3d-62bb669e1c8d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-955976040-172.17.0.20-1598444024228:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42935,DS-ff72ff4c-4cfd-4427-b1b0-2388403c8225,DISK], DatanodeInfoWithStorage[127.0.0.1:33340,DS-c5cc51ec-4615-4f7f-afe2-e743eac4bbe8,DISK], DatanodeInfoWithStorage[127.0.0.1:43029,DS-24ae1e94-6e3f-4bb5-933d-7caa865d1077,DISK], DatanodeInfoWithStorage[127.0.0.1:35868,DS-728c9c2a-e21e-47ba-8f4b-e8017dfae703,DISK], DatanodeInfoWithStorage[127.0.0.1:39985,DS-dd10f32b-bd91-4ff2-becf-1a8778350daa,DISK], DatanodeInfoWithStorage[127.0.0.1:40156,DS-b0137f21-ec3d-4036-9638-51bf2c444614,DISK], DatanodeInfoWithStorage[127.0.0.1:36281,DS-e0fa4ee3-7960-4172-8183-d584a746b889,DISK], DatanodeInfoWithStorage[127.0.0.1:43999,DS-ce3904a9-f4b0-4171-9d3d-62bb669e1c8d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1214410833-172.17.0.20-1598444060445:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41177,DS-48ef6e8a-4b97-4d2f-83d1-b8d28a3439d5,DISK], DatanodeInfoWithStorage[127.0.0.1:33359,DS-2d163288-8328-4948-bd4c-4e86a6dd6f2d,DISK], DatanodeInfoWithStorage[127.0.0.1:43517,DS-30cee42d-3157-412e-9166-c9138bfd65b2,DISK], DatanodeInfoWithStorage[127.0.0.1:34505,DS-dfd757e7-3549-470d-9736-db886b4b82ad,DISK], DatanodeInfoWithStorage[127.0.0.1:43477,DS-e80523ef-bcd9-4e17-a77a-d28bbcdcbcce,DISK], DatanodeInfoWithStorage[127.0.0.1:40185,DS-fdb64c44-484d-4cef-8827-b4f753c3df56,DISK], DatanodeInfoWithStorage[127.0.0.1:38946,DS-db4ca293-2b7d-449d-9aef-ab9ab8e636ef,DISK], DatanodeInfoWithStorage[127.0.0.1:40824,DS-9312825a-47c3-4111-a531-30587401be13,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1214410833-172.17.0.20-1598444060445:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41177,DS-48ef6e8a-4b97-4d2f-83d1-b8d28a3439d5,DISK], DatanodeInfoWithStorage[127.0.0.1:33359,DS-2d163288-8328-4948-bd4c-4e86a6dd6f2d,DISK], DatanodeInfoWithStorage[127.0.0.1:43517,DS-30cee42d-3157-412e-9166-c9138bfd65b2,DISK], DatanodeInfoWithStorage[127.0.0.1:34505,DS-dfd757e7-3549-470d-9736-db886b4b82ad,DISK], DatanodeInfoWithStorage[127.0.0.1:43477,DS-e80523ef-bcd9-4e17-a77a-d28bbcdcbcce,DISK], DatanodeInfoWithStorage[127.0.0.1:40185,DS-fdb64c44-484d-4cef-8827-b4f753c3df56,DISK], DatanodeInfoWithStorage[127.0.0.1:38946,DS-db4ca293-2b7d-449d-9aef-ab9ab8e636ef,DISK], DatanodeInfoWithStorage[127.0.0.1:40824,DS-9312825a-47c3-4111-a531-30587401be13,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-200432331-172.17.0.20-1598444278961:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32997,DS-b8e6a35c-5c0d-4575-9d5d-912100fe8da8,DISK], DatanodeInfoWithStorage[127.0.0.1:33940,DS-158a8f8b-a5e8-4a4f-9497-153b80e39ba6,DISK], DatanodeInfoWithStorage[127.0.0.1:33816,DS-db685b4b-4005-4b6b-834e-972850b5716a,DISK], DatanodeInfoWithStorage[127.0.0.1:39806,DS-42364589-fe11-49db-89cc-44a7dfd4595b,DISK], DatanodeInfoWithStorage[127.0.0.1:34146,DS-5cab8a8c-3fb4-4a85-a669-211b8acdb3e1,DISK], DatanodeInfoWithStorage[127.0.0.1:37778,DS-e9bb099d-270f-48cb-80e0-c1d8ae0538e1,DISK], DatanodeInfoWithStorage[127.0.0.1:42318,DS-34904160-4eef-442d-bf7c-116c21a6663e,DISK], DatanodeInfoWithStorage[127.0.0.1:39516,DS-8c904c6c-88f2-4cd4-9ee0-c9233c31b329,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-200432331-172.17.0.20-1598444278961:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32997,DS-b8e6a35c-5c0d-4575-9d5d-912100fe8da8,DISK], DatanodeInfoWithStorage[127.0.0.1:33940,DS-158a8f8b-a5e8-4a4f-9497-153b80e39ba6,DISK], DatanodeInfoWithStorage[127.0.0.1:33816,DS-db685b4b-4005-4b6b-834e-972850b5716a,DISK], DatanodeInfoWithStorage[127.0.0.1:39806,DS-42364589-fe11-49db-89cc-44a7dfd4595b,DISK], DatanodeInfoWithStorage[127.0.0.1:34146,DS-5cab8a8c-3fb4-4a85-a669-211b8acdb3e1,DISK], DatanodeInfoWithStorage[127.0.0.1:37778,DS-e9bb099d-270f-48cb-80e0-c1d8ae0538e1,DISK], DatanodeInfoWithStorage[127.0.0.1:42318,DS-34904160-4eef-442d-bf7c-116c21a6663e,DISK], DatanodeInfoWithStorage[127.0.0.1:39516,DS-8c904c6c-88f2-4cd4-9ee0-c9233c31b329,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-662228306-172.17.0.20-1598444349798:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44279,DS-9fc301fe-fb22-44e6-9904-36e2adb5386e,DISK], DatanodeInfoWithStorage[127.0.0.1:40295,DS-d1ffe4fa-18be-413e-a4ef-b063d21de32b,DISK], DatanodeInfoWithStorage[127.0.0.1:33400,DS-48ef3100-71c7-48d9-9557-1f31ee0ac183,DISK], DatanodeInfoWithStorage[127.0.0.1:33783,DS-71e98952-1120-486b-ba61-2238ed6fc835,DISK], DatanodeInfoWithStorage[127.0.0.1:37744,DS-664c44a7-ffe4-44fc-9e51-56be400a6b43,DISK], DatanodeInfoWithStorage[127.0.0.1:42475,DS-4ee8d6b9-d57a-4b37-90aa-9b0e69dc7396,DISK], DatanodeInfoWithStorage[127.0.0.1:43763,DS-164163c0-9a23-4a81-9fa4-a823d2a1a49d,DISK], DatanodeInfoWithStorage[127.0.0.1:33271,DS-2e08688e-3b4e-4364-ab6d-735da56dfeb4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-662228306-172.17.0.20-1598444349798:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44279,DS-9fc301fe-fb22-44e6-9904-36e2adb5386e,DISK], DatanodeInfoWithStorage[127.0.0.1:40295,DS-d1ffe4fa-18be-413e-a4ef-b063d21de32b,DISK], DatanodeInfoWithStorage[127.0.0.1:33400,DS-48ef3100-71c7-48d9-9557-1f31ee0ac183,DISK], DatanodeInfoWithStorage[127.0.0.1:33783,DS-71e98952-1120-486b-ba61-2238ed6fc835,DISK], DatanodeInfoWithStorage[127.0.0.1:37744,DS-664c44a7-ffe4-44fc-9e51-56be400a6b43,DISK], DatanodeInfoWithStorage[127.0.0.1:42475,DS-4ee8d6b9-d57a-4b37-90aa-9b0e69dc7396,DISK], DatanodeInfoWithStorage[127.0.0.1:43763,DS-164163c0-9a23-4a81-9fa4-a823d2a1a49d,DISK], DatanodeInfoWithStorage[127.0.0.1:33271,DS-2e08688e-3b4e-4364-ab6d-735da56dfeb4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-173317327-172.17.0.20-1598444616665:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35143,DS-630315e3-7b3d-4618-bc9d-4234b74a4574,DISK], DatanodeInfoWithStorage[127.0.0.1:42763,DS-4753621b-d920-4b50-9eef-1a1bf09062c7,DISK], DatanodeInfoWithStorage[127.0.0.1:43484,DS-a7555288-a870-4c3d-b0b8-7293fe7806be,DISK], DatanodeInfoWithStorage[127.0.0.1:44330,DS-218feb1d-7d5f-4f62-8fba-29d53103b27b,DISK], DatanodeInfoWithStorage[127.0.0.1:37522,DS-6fe39d99-ceee-4fb7-b9f3-61b6d6f61780,DISK], DatanodeInfoWithStorage[127.0.0.1:42640,DS-352c0291-a130-4a34-8908-2dd26219f962,DISK], DatanodeInfoWithStorage[127.0.0.1:42779,DS-7f57b96f-6ac7-4160-8ef8-6574d94a8cca,DISK], DatanodeInfoWithStorage[127.0.0.1:44995,DS-82af5739-77dd-435a-876b-3cc96eee46f0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-173317327-172.17.0.20-1598444616665:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35143,DS-630315e3-7b3d-4618-bc9d-4234b74a4574,DISK], DatanodeInfoWithStorage[127.0.0.1:42763,DS-4753621b-d920-4b50-9eef-1a1bf09062c7,DISK], DatanodeInfoWithStorage[127.0.0.1:43484,DS-a7555288-a870-4c3d-b0b8-7293fe7806be,DISK], DatanodeInfoWithStorage[127.0.0.1:44330,DS-218feb1d-7d5f-4f62-8fba-29d53103b27b,DISK], DatanodeInfoWithStorage[127.0.0.1:37522,DS-6fe39d99-ceee-4fb7-b9f3-61b6d6f61780,DISK], DatanodeInfoWithStorage[127.0.0.1:42640,DS-352c0291-a130-4a34-8908-2dd26219f962,DISK], DatanodeInfoWithStorage[127.0.0.1:42779,DS-7f57b96f-6ac7-4160-8ef8-6574d94a8cca,DISK], DatanodeInfoWithStorage[127.0.0.1:44995,DS-82af5739-77dd-435a-876b-3cc96eee46f0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1515623156-172.17.0.20-1598444889233:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40777,DS-a17765ab-c449-4538-97df-1f87e6536dd4,DISK], DatanodeInfoWithStorage[127.0.0.1:38215,DS-c3ae6075-da18-4205-a5fc-73c91e06897b,DISK], DatanodeInfoWithStorage[127.0.0.1:35316,DS-1a18b63f-527b-4e69-a857-a5fc40cd1a00,DISK], DatanodeInfoWithStorage[127.0.0.1:43586,DS-4c46bc7e-2d62-44af-8bf4-0b0bda408311,DISK], DatanodeInfoWithStorage[127.0.0.1:38282,DS-f0e463f8-f82f-4032-9ef0-ddff345121e2,DISK], DatanodeInfoWithStorage[127.0.0.1:40275,DS-896ccc33-19b6-4347-bc0b-daacff644924,DISK], DatanodeInfoWithStorage[127.0.0.1:37620,DS-73714957-2ed2-4e48-a32b-0f275254855e,DISK], DatanodeInfoWithStorage[127.0.0.1:46659,DS-54329bbd-b4fe-4def-9e74-71352d185694,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1515623156-172.17.0.20-1598444889233:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40777,DS-a17765ab-c449-4538-97df-1f87e6536dd4,DISK], DatanodeInfoWithStorage[127.0.0.1:38215,DS-c3ae6075-da18-4205-a5fc-73c91e06897b,DISK], DatanodeInfoWithStorage[127.0.0.1:35316,DS-1a18b63f-527b-4e69-a857-a5fc40cd1a00,DISK], DatanodeInfoWithStorage[127.0.0.1:43586,DS-4c46bc7e-2d62-44af-8bf4-0b0bda408311,DISK], DatanodeInfoWithStorage[127.0.0.1:38282,DS-f0e463f8-f82f-4032-9ef0-ddff345121e2,DISK], DatanodeInfoWithStorage[127.0.0.1:40275,DS-896ccc33-19b6-4347-bc0b-daacff644924,DISK], DatanodeInfoWithStorage[127.0.0.1:37620,DS-73714957-2ed2-4e48-a32b-0f275254855e,DISK], DatanodeInfoWithStorage[127.0.0.1:46659,DS-54329bbd-b4fe-4def-9e74-71352d185694,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1319863059-172.17.0.20-1598445001934:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34504,DS-43feb852-328e-4439-b59d-5f5a6c9f3ec1,DISK], DatanodeInfoWithStorage[127.0.0.1:40492,DS-153d1240-eeff-4fc1-9e32-957b79ad2327,DISK], DatanodeInfoWithStorage[127.0.0.1:36778,DS-d934d35f-9f27-4852-9899-52ea2cb4efa8,DISK], DatanodeInfoWithStorage[127.0.0.1:44398,DS-594498e8-d618-4754-84b8-e4b66e09d05a,DISK], DatanodeInfoWithStorage[127.0.0.1:38039,DS-0cf26a0d-e1c8-44b1-96b6-e642f61a198a,DISK], DatanodeInfoWithStorage[127.0.0.1:42157,DS-0026fa86-6f84-45b3-9f93-ecad2f803a7e,DISK], DatanodeInfoWithStorage[127.0.0.1:42756,DS-3b604dd2-aba6-4a07-b96f-e665e21ee3ea,DISK], DatanodeInfoWithStorage[127.0.0.1:33923,DS-bd9b43b9-f44b-4031-9203-bc0ffaf8bb89,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1319863059-172.17.0.20-1598445001934:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34504,DS-43feb852-328e-4439-b59d-5f5a6c9f3ec1,DISK], DatanodeInfoWithStorage[127.0.0.1:40492,DS-153d1240-eeff-4fc1-9e32-957b79ad2327,DISK], DatanodeInfoWithStorage[127.0.0.1:36778,DS-d934d35f-9f27-4852-9899-52ea2cb4efa8,DISK], DatanodeInfoWithStorage[127.0.0.1:44398,DS-594498e8-d618-4754-84b8-e4b66e09d05a,DISK], DatanodeInfoWithStorage[127.0.0.1:38039,DS-0cf26a0d-e1c8-44b1-96b6-e642f61a198a,DISK], DatanodeInfoWithStorage[127.0.0.1:42157,DS-0026fa86-6f84-45b3-9f93-ecad2f803a7e,DISK], DatanodeInfoWithStorage[127.0.0.1:42756,DS-3b604dd2-aba6-4a07-b96f-e665e21ee3ea,DISK], DatanodeInfoWithStorage[127.0.0.1:33923,DS-bd9b43b9-f44b-4031-9203-bc0ffaf8bb89,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1942117056-172.17.0.20-1598445042176:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37903,DS-5405ad9c-a7ea-4378-a0be-daeb52801bd1,DISK], DatanodeInfoWithStorage[127.0.0.1:41419,DS-74c4d5ae-6da0-4b84-9bd1-05953fa47a6a,DISK], DatanodeInfoWithStorage[127.0.0.1:34526,DS-41904603-3bbb-4728-89c5-d7c32e17ede3,DISK], DatanodeInfoWithStorage[127.0.0.1:37042,DS-45d30f11-9234-4d50-9f08-5b9556ed5ce2,DISK], DatanodeInfoWithStorage[127.0.0.1:41838,DS-ea8be0f4-b1ad-446b-8e48-2ac9c37130c6,DISK], DatanodeInfoWithStorage[127.0.0.1:34328,DS-53f296ca-01ba-4e72-aa38-47a9e24d5850,DISK], DatanodeInfoWithStorage[127.0.0.1:41479,DS-c94ab5e9-008b-4aa0-8723-65bdf0431c60,DISK], DatanodeInfoWithStorage[127.0.0.1:37616,DS-b011d302-9a0e-4047-8913-df5444a2f579,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1942117056-172.17.0.20-1598445042176:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37903,DS-5405ad9c-a7ea-4378-a0be-daeb52801bd1,DISK], DatanodeInfoWithStorage[127.0.0.1:41419,DS-74c4d5ae-6da0-4b84-9bd1-05953fa47a6a,DISK], DatanodeInfoWithStorage[127.0.0.1:34526,DS-41904603-3bbb-4728-89c5-d7c32e17ede3,DISK], DatanodeInfoWithStorage[127.0.0.1:37042,DS-45d30f11-9234-4d50-9f08-5b9556ed5ce2,DISK], DatanodeInfoWithStorage[127.0.0.1:41838,DS-ea8be0f4-b1ad-446b-8e48-2ac9c37130c6,DISK], DatanodeInfoWithStorage[127.0.0.1:34328,DS-53f296ca-01ba-4e72-aa38-47a9e24d5850,DISK], DatanodeInfoWithStorage[127.0.0.1:41479,DS-c94ab5e9-008b-4aa0-8723-65bdf0431c60,DISK], DatanodeInfoWithStorage[127.0.0.1:37616,DS-b011d302-9a0e-4047-8913-df5444a2f579,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1215240734-172.17.0.20-1598445121137:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43842,DS-973a6f19-a374-48a5-8efc-197a4c68a703,DISK], DatanodeInfoWithStorage[127.0.0.1:43752,DS-785d549b-97bb-42e4-87c6-cc511bc41c87,DISK], DatanodeInfoWithStorage[127.0.0.1:42655,DS-abd4f642-3b66-4df3-84fd-90fd5e29bd0b,DISK], DatanodeInfoWithStorage[127.0.0.1:33869,DS-96516435-83ea-4a85-a805-719163294419,DISK], DatanodeInfoWithStorage[127.0.0.1:39004,DS-ef4c90bf-8d9e-43a3-8638-8a876520c98a,DISK], DatanodeInfoWithStorage[127.0.0.1:32914,DS-46f6b63c-99b8-4076-babc-14a9d281d662,DISK], DatanodeInfoWithStorage[127.0.0.1:34422,DS-21c12e7f-3f59-418b-91a2-6d0d47b4d803,DISK], DatanodeInfoWithStorage[127.0.0.1:38670,DS-6dcaecec-0cc4-472b-bf41-815d90aed05e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1215240734-172.17.0.20-1598445121137:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43842,DS-973a6f19-a374-48a5-8efc-197a4c68a703,DISK], DatanodeInfoWithStorage[127.0.0.1:43752,DS-785d549b-97bb-42e4-87c6-cc511bc41c87,DISK], DatanodeInfoWithStorage[127.0.0.1:42655,DS-abd4f642-3b66-4df3-84fd-90fd5e29bd0b,DISK], DatanodeInfoWithStorage[127.0.0.1:33869,DS-96516435-83ea-4a85-a805-719163294419,DISK], DatanodeInfoWithStorage[127.0.0.1:39004,DS-ef4c90bf-8d9e-43a3-8638-8a876520c98a,DISK], DatanodeInfoWithStorage[127.0.0.1:32914,DS-46f6b63c-99b8-4076-babc-14a9d281d662,DISK], DatanodeInfoWithStorage[127.0.0.1:34422,DS-21c12e7f-3f59-418b-91a2-6d0d47b4d803,DISK], DatanodeInfoWithStorage[127.0.0.1:38670,DS-6dcaecec-0cc4-472b-bf41-815d90aed05e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1582155113-172.17.0.20-1598445267550:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46175,DS-3ae9e93e-0e0f-42bf-be5a-04c2e2e2d8af,DISK], DatanodeInfoWithStorage[127.0.0.1:39740,DS-7a57fc1d-a54b-4649-8b2c-fa06cfb16d1b,DISK], DatanodeInfoWithStorage[127.0.0.1:41225,DS-80d6dab0-3800-44b5-a619-1e97f215d883,DISK], DatanodeInfoWithStorage[127.0.0.1:37211,DS-6e3475a5-e3e8-41a8-b219-d879ce8f9c5e,DISK], DatanodeInfoWithStorage[127.0.0.1:35834,DS-0436cf2f-25a3-4c7e-8bc7-56fe9a514d59,DISK], DatanodeInfoWithStorage[127.0.0.1:36020,DS-a1ad8a00-91ff-4271-9759-b4542b4da3ec,DISK], DatanodeInfoWithStorage[127.0.0.1:41820,DS-f512a7d5-720e-424a-8923-082b35995e7d,DISK], DatanodeInfoWithStorage[127.0.0.1:37386,DS-88332b2a-e36d-421f-aa39-eeade22231a6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1582155113-172.17.0.20-1598445267550:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46175,DS-3ae9e93e-0e0f-42bf-be5a-04c2e2e2d8af,DISK], DatanodeInfoWithStorage[127.0.0.1:39740,DS-7a57fc1d-a54b-4649-8b2c-fa06cfb16d1b,DISK], DatanodeInfoWithStorage[127.0.0.1:41225,DS-80d6dab0-3800-44b5-a619-1e97f215d883,DISK], DatanodeInfoWithStorage[127.0.0.1:37211,DS-6e3475a5-e3e8-41a8-b219-d879ce8f9c5e,DISK], DatanodeInfoWithStorage[127.0.0.1:35834,DS-0436cf2f-25a3-4c7e-8bc7-56fe9a514d59,DISK], DatanodeInfoWithStorage[127.0.0.1:36020,DS-a1ad8a00-91ff-4271-9759-b4542b4da3ec,DISK], DatanodeInfoWithStorage[127.0.0.1:41820,DS-f512a7d5-720e-424a-8923-082b35995e7d,DISK], DatanodeInfoWithStorage[127.0.0.1:37386,DS-88332b2a-e36d-421f-aa39-eeade22231a6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1566208522-172.17.0.20-1598445342190:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40293,DS-72ed57ee-b47b-4afa-8e75-8e04e204f865,DISK], DatanodeInfoWithStorage[127.0.0.1:37073,DS-c6bf3ae3-75f3-4af1-9e83-6a7a84a9c2d5,DISK], DatanodeInfoWithStorage[127.0.0.1:42292,DS-02adb0d8-844f-4120-b4f6-d3e6d858528d,DISK], DatanodeInfoWithStorage[127.0.0.1:38409,DS-41bced39-1bae-4f72-9c15-6660b91b4b5b,DISK], DatanodeInfoWithStorage[127.0.0.1:34733,DS-85c99439-c98d-4723-a815-847ed6838d64,DISK], DatanodeInfoWithStorage[127.0.0.1:33815,DS-1c753a51-f953-4d89-8133-5e366a9b840a,DISK], DatanodeInfoWithStorage[127.0.0.1:44727,DS-82324668-7068-41e4-bc45-1491eb7ab58d,DISK], DatanodeInfoWithStorage[127.0.0.1:43765,DS-87a00b2d-3e50-4eb2-8f8a-e58c4ba321f2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1566208522-172.17.0.20-1598445342190:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40293,DS-72ed57ee-b47b-4afa-8e75-8e04e204f865,DISK], DatanodeInfoWithStorage[127.0.0.1:37073,DS-c6bf3ae3-75f3-4af1-9e83-6a7a84a9c2d5,DISK], DatanodeInfoWithStorage[127.0.0.1:42292,DS-02adb0d8-844f-4120-b4f6-d3e6d858528d,DISK], DatanodeInfoWithStorage[127.0.0.1:38409,DS-41bced39-1bae-4f72-9c15-6660b91b4b5b,DISK], DatanodeInfoWithStorage[127.0.0.1:34733,DS-85c99439-c98d-4723-a815-847ed6838d64,DISK], DatanodeInfoWithStorage[127.0.0.1:33815,DS-1c753a51-f953-4d89-8133-5e366a9b840a,DISK], DatanodeInfoWithStorage[127.0.0.1:44727,DS-82324668-7068-41e4-bc45-1491eb7ab58d,DISK], DatanodeInfoWithStorage[127.0.0.1:43765,DS-87a00b2d-3e50-4eb2-8f8a-e58c4ba321f2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1125138882-172.17.0.20-1598445379274:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40660,DS-41260a69-d4e9-4a15-9a00-35b860e11739,DISK], DatanodeInfoWithStorage[127.0.0.1:38471,DS-c05104c7-bae7-441a-b15f-b4226aea984a,DISK], DatanodeInfoWithStorage[127.0.0.1:42430,DS-be6311ba-1523-4403-af7f-a663fa7a1ee6,DISK], DatanodeInfoWithStorage[127.0.0.1:39875,DS-8366f056-ae23-4c96-b168-bbddf1ea6cf1,DISK], DatanodeInfoWithStorage[127.0.0.1:42080,DS-e30bd4a1-8f1f-41c3-aff5-ff392514193c,DISK], DatanodeInfoWithStorage[127.0.0.1:36521,DS-d328033a-f36f-464f-967e-caed632557e6,DISK], DatanodeInfoWithStorage[127.0.0.1:43108,DS-4562edb7-c298-43b6-98c7-59942fe0e1cd,DISK], DatanodeInfoWithStorage[127.0.0.1:45957,DS-e3ea8d1d-3988-4097-89c8-08a058b56aaa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1125138882-172.17.0.20-1598445379274:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40660,DS-41260a69-d4e9-4a15-9a00-35b860e11739,DISK], DatanodeInfoWithStorage[127.0.0.1:38471,DS-c05104c7-bae7-441a-b15f-b4226aea984a,DISK], DatanodeInfoWithStorage[127.0.0.1:42430,DS-be6311ba-1523-4403-af7f-a663fa7a1ee6,DISK], DatanodeInfoWithStorage[127.0.0.1:39875,DS-8366f056-ae23-4c96-b168-bbddf1ea6cf1,DISK], DatanodeInfoWithStorage[127.0.0.1:42080,DS-e30bd4a1-8f1f-41c3-aff5-ff392514193c,DISK], DatanodeInfoWithStorage[127.0.0.1:36521,DS-d328033a-f36f-464f-967e-caed632557e6,DISK], DatanodeInfoWithStorage[127.0.0.1:43108,DS-4562edb7-c298-43b6-98c7-59942fe0e1cd,DISK], DatanodeInfoWithStorage[127.0.0.1:45957,DS-e3ea8d1d-3988-4097-89c8-08a058b56aaa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-962243150-172.17.0.20-1598445488070:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41299,DS-b29d4e97-5b36-4429-9396-e40437d96162,DISK], DatanodeInfoWithStorage[127.0.0.1:35260,DS-8d713111-4b4b-4a8d-a4be-957a4b806dc5,DISK], DatanodeInfoWithStorage[127.0.0.1:40030,DS-22285816-b408-4e54-9899-751da2da2eb5,DISK], DatanodeInfoWithStorage[127.0.0.1:36137,DS-3ffb6830-ed95-4ca1-83ad-04ce3cc9bf91,DISK], DatanodeInfoWithStorage[127.0.0.1:41972,DS-be9fe821-0ee1-4142-a2eb-b13dd0a7abe1,DISK], DatanodeInfoWithStorage[127.0.0.1:43653,DS-e6395448-6414-4b7b-a757-d1fe0586eb40,DISK], DatanodeInfoWithStorage[127.0.0.1:37576,DS-45ab0e57-7b38-4ab7-abc5-c4fe83932941,DISK], DatanodeInfoWithStorage[127.0.0.1:39576,DS-ad25c9a2-12fa-4d79-aea3-5155dcd4f103,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-962243150-172.17.0.20-1598445488070:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41299,DS-b29d4e97-5b36-4429-9396-e40437d96162,DISK], DatanodeInfoWithStorage[127.0.0.1:35260,DS-8d713111-4b4b-4a8d-a4be-957a4b806dc5,DISK], DatanodeInfoWithStorage[127.0.0.1:40030,DS-22285816-b408-4e54-9899-751da2da2eb5,DISK], DatanodeInfoWithStorage[127.0.0.1:36137,DS-3ffb6830-ed95-4ca1-83ad-04ce3cc9bf91,DISK], DatanodeInfoWithStorage[127.0.0.1:41972,DS-be9fe821-0ee1-4142-a2eb-b13dd0a7abe1,DISK], DatanodeInfoWithStorage[127.0.0.1:43653,DS-e6395448-6414-4b7b-a757-d1fe0586eb40,DISK], DatanodeInfoWithStorage[127.0.0.1:37576,DS-45ab0e57-7b38-4ab7-abc5-c4fe83932941,DISK], DatanodeInfoWithStorage[127.0.0.1:39576,DS-ad25c9a2-12fa-4d79-aea3-5155dcd4f103,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-130727756-172.17.0.20-1598445523932:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33805,DS-565965b9-268c-45ed-a3ab-9ab3a07ca004,DISK], DatanodeInfoWithStorage[127.0.0.1:45632,DS-887f2c46-b3da-482d-8059-92f7025a04b9,DISK], DatanodeInfoWithStorage[127.0.0.1:33074,DS-c10185cc-b8df-4b36-88bb-5b495181407d,DISK], DatanodeInfoWithStorage[127.0.0.1:46315,DS-95bd27f4-12f3-4f26-ae57-a6c917446ac4,DISK], DatanodeInfoWithStorage[127.0.0.1:43866,DS-d549d5f2-fb68-4984-acff-d3029f73398e,DISK], DatanodeInfoWithStorage[127.0.0.1:46365,DS-57143de9-eb96-462b-ba1d-183c298f0ae4,DISK], DatanodeInfoWithStorage[127.0.0.1:42345,DS-ccf41160-745b-4775-8ca7-7a8f92dc5ee6,DISK], DatanodeInfoWithStorage[127.0.0.1:40944,DS-dd5660bd-09cf-4353-ba4b-d952be9ef42e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-130727756-172.17.0.20-1598445523932:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33805,DS-565965b9-268c-45ed-a3ab-9ab3a07ca004,DISK], DatanodeInfoWithStorage[127.0.0.1:45632,DS-887f2c46-b3da-482d-8059-92f7025a04b9,DISK], DatanodeInfoWithStorage[127.0.0.1:33074,DS-c10185cc-b8df-4b36-88bb-5b495181407d,DISK], DatanodeInfoWithStorage[127.0.0.1:46315,DS-95bd27f4-12f3-4f26-ae57-a6c917446ac4,DISK], DatanodeInfoWithStorage[127.0.0.1:43866,DS-d549d5f2-fb68-4984-acff-d3029f73398e,DISK], DatanodeInfoWithStorage[127.0.0.1:46365,DS-57143de9-eb96-462b-ba1d-183c298f0ae4,DISK], DatanodeInfoWithStorage[127.0.0.1:42345,DS-ccf41160-745b-4775-8ca7-7a8f92dc5ee6,DISK], DatanodeInfoWithStorage[127.0.0.1:40944,DS-dd5660bd-09cf-4353-ba4b-d952be9ef42e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1095163660-172.17.0.20-1598445680254:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42236,DS-7aff707f-1537-4d9f-979f-5e7e9caeb5b2,DISK], DatanodeInfoWithStorage[127.0.0.1:33637,DS-307df5e1-1331-47f1-ae5a-71162a70daa7,DISK], DatanodeInfoWithStorage[127.0.0.1:41350,DS-49e2e7a1-cd32-41fe-b902-d2cee7fa3202,DISK], DatanodeInfoWithStorage[127.0.0.1:40199,DS-1a8ea088-7d5e-4799-9699-55f4f2c60fd9,DISK], DatanodeInfoWithStorage[127.0.0.1:41043,DS-e8f0139d-6440-4073-94ad-c6f5c230b0f9,DISK], DatanodeInfoWithStorage[127.0.0.1:40234,DS-ce2d93a3-93af-4d47-ac23-3f70efc8cba7,DISK], DatanodeInfoWithStorage[127.0.0.1:35625,DS-d8b790c5-2a5a-4af3-af46-9c0b918c579b,DISK], DatanodeInfoWithStorage[127.0.0.1:35978,DS-4c7256db-2818-4249-9862-a092d2c303d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1095163660-172.17.0.20-1598445680254:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42236,DS-7aff707f-1537-4d9f-979f-5e7e9caeb5b2,DISK], DatanodeInfoWithStorage[127.0.0.1:33637,DS-307df5e1-1331-47f1-ae5a-71162a70daa7,DISK], DatanodeInfoWithStorage[127.0.0.1:41350,DS-49e2e7a1-cd32-41fe-b902-d2cee7fa3202,DISK], DatanodeInfoWithStorage[127.0.0.1:40199,DS-1a8ea088-7d5e-4799-9699-55f4f2c60fd9,DISK], DatanodeInfoWithStorage[127.0.0.1:41043,DS-e8f0139d-6440-4073-94ad-c6f5c230b0f9,DISK], DatanodeInfoWithStorage[127.0.0.1:40234,DS-ce2d93a3-93af-4d47-ac23-3f70efc8cba7,DISK], DatanodeInfoWithStorage[127.0.0.1:35625,DS-d8b790c5-2a5a-4af3-af46-9c0b918c579b,DISK], DatanodeInfoWithStorage[127.0.0.1:35978,DS-4c7256db-2818-4249-9862-a092d2c303d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-672125286-172.17.0.20-1598445761192:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45550,DS-d35a890f-72a1-483c-8393-1e16a6a76d9b,DISK], DatanodeInfoWithStorage[127.0.0.1:32859,DS-767c2951-6678-401a-8c01-0bbb7e3fa04f,DISK], DatanodeInfoWithStorage[127.0.0.1:45134,DS-a2b179bf-e136-4cc3-973a-497c1a7d1120,DISK], DatanodeInfoWithStorage[127.0.0.1:32769,DS-d186f60b-0a65-42f1-ab9e-1d0c4814d2a3,DISK], DatanodeInfoWithStorage[127.0.0.1:42608,DS-059073c3-3438-462d-8a47-70cda66a20ce,DISK], DatanodeInfoWithStorage[127.0.0.1:44748,DS-64b39fc5-ab1a-453d-a014-9b6db09681dd,DISK], DatanodeInfoWithStorage[127.0.0.1:42662,DS-6451e0f9-2008-447f-bdd7-cd4a2b93a679,DISK], DatanodeInfoWithStorage[127.0.0.1:39259,DS-40208a08-233e-47ef-817a-fed6a83de61e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-672125286-172.17.0.20-1598445761192:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45550,DS-d35a890f-72a1-483c-8393-1e16a6a76d9b,DISK], DatanodeInfoWithStorage[127.0.0.1:32859,DS-767c2951-6678-401a-8c01-0bbb7e3fa04f,DISK], DatanodeInfoWithStorage[127.0.0.1:45134,DS-a2b179bf-e136-4cc3-973a-497c1a7d1120,DISK], DatanodeInfoWithStorage[127.0.0.1:32769,DS-d186f60b-0a65-42f1-ab9e-1d0c4814d2a3,DISK], DatanodeInfoWithStorage[127.0.0.1:42608,DS-059073c3-3438-462d-8a47-70cda66a20ce,DISK], DatanodeInfoWithStorage[127.0.0.1:44748,DS-64b39fc5-ab1a-453d-a014-9b6db09681dd,DISK], DatanodeInfoWithStorage[127.0.0.1:42662,DS-6451e0f9-2008-447f-bdd7-cd4a2b93a679,DISK], DatanodeInfoWithStorage[127.0.0.1:39259,DS-40208a08-233e-47ef-817a-fed6a83de61e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-378458852-172.17.0.20-1598445831476:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42572,DS-55599c60-ce54-4d8c-ae97-f79c43f48442,DISK], DatanodeInfoWithStorage[127.0.0.1:44666,DS-8d9af163-f0f0-4191-9666-b6bc48a68bc1,DISK], DatanodeInfoWithStorage[127.0.0.1:45418,DS-27824840-73b6-4be6-9872-5e55b1489e88,DISK], DatanodeInfoWithStorage[127.0.0.1:37396,DS-7852d391-67c6-4c69-a871-1dae140ae042,DISK], DatanodeInfoWithStorage[127.0.0.1:46637,DS-8d1a9cab-b8c2-419a-9b61-f85c47f7cccc,DISK], DatanodeInfoWithStorage[127.0.0.1:44974,DS-28115213-e3c1-4d69-99e7-bcc970e6a1bc,DISK], DatanodeInfoWithStorage[127.0.0.1:42400,DS-381b174e-7b60-482c-a28d-161abd6a7ec2,DISK], DatanodeInfoWithStorage[127.0.0.1:32901,DS-27c0def9-b575-4af6-a1cd-5c50780fd96b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-378458852-172.17.0.20-1598445831476:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42572,DS-55599c60-ce54-4d8c-ae97-f79c43f48442,DISK], DatanodeInfoWithStorage[127.0.0.1:44666,DS-8d9af163-f0f0-4191-9666-b6bc48a68bc1,DISK], DatanodeInfoWithStorage[127.0.0.1:45418,DS-27824840-73b6-4be6-9872-5e55b1489e88,DISK], DatanodeInfoWithStorage[127.0.0.1:37396,DS-7852d391-67c6-4c69-a871-1dae140ae042,DISK], DatanodeInfoWithStorage[127.0.0.1:46637,DS-8d1a9cab-b8c2-419a-9b61-f85c47f7cccc,DISK], DatanodeInfoWithStorage[127.0.0.1:44974,DS-28115213-e3c1-4d69-99e7-bcc970e6a1bc,DISK], DatanodeInfoWithStorage[127.0.0.1:42400,DS-381b174e-7b60-482c-a28d-161abd6a7ec2,DISK], DatanodeInfoWithStorage[127.0.0.1:32901,DS-27c0def9-b575-4af6-a1cd-5c50780fd96b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-980762083-172.17.0.20-1598445972874:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42692,DS-d56db580-ff21-4cfa-801c-b0fa5950431a,DISK], DatanodeInfoWithStorage[127.0.0.1:37524,DS-9b423742-0c38-4e23-8d82-c0e465af8947,DISK], DatanodeInfoWithStorage[127.0.0.1:36658,DS-25e78016-ddcc-4a3f-886b-c7b15cd10281,DISK], DatanodeInfoWithStorage[127.0.0.1:41475,DS-15f0e706-e509-49e0-9a24-6c36bda1348d,DISK], DatanodeInfoWithStorage[127.0.0.1:43944,DS-ca4aa3d3-0dc1-4d1b-86d5-b7d11ca70da1,DISK], DatanodeInfoWithStorage[127.0.0.1:40327,DS-bf328141-59da-4d28-8dff-8dbd5a01011c,DISK], DatanodeInfoWithStorage[127.0.0.1:44730,DS-9ca9491e-1571-40f8-9248-46db70fbba00,DISK], DatanodeInfoWithStorage[127.0.0.1:43714,DS-6100014e-30f9-4dd1-b993-1e118999b571,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-980762083-172.17.0.20-1598445972874:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42692,DS-d56db580-ff21-4cfa-801c-b0fa5950431a,DISK], DatanodeInfoWithStorage[127.0.0.1:37524,DS-9b423742-0c38-4e23-8d82-c0e465af8947,DISK], DatanodeInfoWithStorage[127.0.0.1:36658,DS-25e78016-ddcc-4a3f-886b-c7b15cd10281,DISK], DatanodeInfoWithStorage[127.0.0.1:41475,DS-15f0e706-e509-49e0-9a24-6c36bda1348d,DISK], DatanodeInfoWithStorage[127.0.0.1:43944,DS-ca4aa3d3-0dc1-4d1b-86d5-b7d11ca70da1,DISK], DatanodeInfoWithStorage[127.0.0.1:40327,DS-bf328141-59da-4d28-8dff-8dbd5a01011c,DISK], DatanodeInfoWithStorage[127.0.0.1:44730,DS-9ca9491e-1571-40f8-9248-46db70fbba00,DISK], DatanodeInfoWithStorage[127.0.0.1:43714,DS-6100014e-30f9-4dd1-b993-1e118999b571,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-225498917-172.17.0.20-1598446054282:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34230,DS-d7a3c328-32b9-4483-8b75-beae864f8541,DISK], DatanodeInfoWithStorage[127.0.0.1:44378,DS-6c13f122-a45e-4ae3-b6a5-37e13f4d747a,DISK], DatanodeInfoWithStorage[127.0.0.1:40114,DS-92884841-c3c5-4e1a-baa6-1d0bd57b9a5f,DISK], DatanodeInfoWithStorage[127.0.0.1:37727,DS-e4161bc7-e624-44c5-abe1-a63ef2674c7c,DISK], DatanodeInfoWithStorage[127.0.0.1:42695,DS-ace92710-65df-437d-8608-53d146c19e9b,DISK], DatanodeInfoWithStorage[127.0.0.1:40263,DS-3da42e37-621a-4c32-98ec-1f6e667cb2a5,DISK], DatanodeInfoWithStorage[127.0.0.1:41690,DS-16aceb7b-4a14-4f2a-8aaf-ce44994becba,DISK], DatanodeInfoWithStorage[127.0.0.1:33711,DS-f55d22f9-b278-4e07-88f9-732f7e24f536,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-225498917-172.17.0.20-1598446054282:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34230,DS-d7a3c328-32b9-4483-8b75-beae864f8541,DISK], DatanodeInfoWithStorage[127.0.0.1:44378,DS-6c13f122-a45e-4ae3-b6a5-37e13f4d747a,DISK], DatanodeInfoWithStorage[127.0.0.1:40114,DS-92884841-c3c5-4e1a-baa6-1d0bd57b9a5f,DISK], DatanodeInfoWithStorage[127.0.0.1:37727,DS-e4161bc7-e624-44c5-abe1-a63ef2674c7c,DISK], DatanodeInfoWithStorage[127.0.0.1:42695,DS-ace92710-65df-437d-8608-53d146c19e9b,DISK], DatanodeInfoWithStorage[127.0.0.1:40263,DS-3da42e37-621a-4c32-98ec-1f6e667cb2a5,DISK], DatanodeInfoWithStorage[127.0.0.1:41690,DS-16aceb7b-4a14-4f2a-8aaf-ce44994becba,DISK], DatanodeInfoWithStorage[127.0.0.1:33711,DS-f55d22f9-b278-4e07-88f9-732f7e24f536,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1185946036-172.17.0.20-1598446094920:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39926,DS-ffa0103f-9922-4fea-9f79-5f67b7b8ea1b,DISK], DatanodeInfoWithStorage[127.0.0.1:42742,DS-8d4864a9-311c-4b98-905d-cdb181a222d5,DISK], DatanodeInfoWithStorage[127.0.0.1:40886,DS-ac0b9f81-d5de-44d1-9976-fc631aac6605,DISK], DatanodeInfoWithStorage[127.0.0.1:36474,DS-aa8d7bb1-b168-409c-b732-31bd645c203f,DISK], DatanodeInfoWithStorage[127.0.0.1:33582,DS-25ac7f9a-8a75-4787-9a90-213f71e591ca,DISK], DatanodeInfoWithStorage[127.0.0.1:34034,DS-77a5105a-9294-4536-9c87-f20564b307ea,DISK], DatanodeInfoWithStorage[127.0.0.1:45017,DS-6a4f1db0-0acf-4234-81f8-47319f977852,DISK], DatanodeInfoWithStorage[127.0.0.1:36642,DS-cf6f62e8-8825-4f77-8709-3d81abd027a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1185946036-172.17.0.20-1598446094920:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39926,DS-ffa0103f-9922-4fea-9f79-5f67b7b8ea1b,DISK], DatanodeInfoWithStorage[127.0.0.1:42742,DS-8d4864a9-311c-4b98-905d-cdb181a222d5,DISK], DatanodeInfoWithStorage[127.0.0.1:40886,DS-ac0b9f81-d5de-44d1-9976-fc631aac6605,DISK], DatanodeInfoWithStorage[127.0.0.1:36474,DS-aa8d7bb1-b168-409c-b732-31bd645c203f,DISK], DatanodeInfoWithStorage[127.0.0.1:33582,DS-25ac7f9a-8a75-4787-9a90-213f71e591ca,DISK], DatanodeInfoWithStorage[127.0.0.1:34034,DS-77a5105a-9294-4536-9c87-f20564b307ea,DISK], DatanodeInfoWithStorage[127.0.0.1:45017,DS-6a4f1db0-0acf-4234-81f8-47319f977852,DISK], DatanodeInfoWithStorage[127.0.0.1:36642,DS-cf6f62e8-8825-4f77-8709-3d81abd027a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-90928984-172.17.0.20-1598446334198:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44319,DS-5b131f9f-c597-4f19-a1bc-f1002cea553e,DISK], DatanodeInfoWithStorage[127.0.0.1:32781,DS-7e4597ce-5218-48c7-b9ef-caedcefb0c59,DISK], DatanodeInfoWithStorage[127.0.0.1:36415,DS-ddbe29fc-2fe4-49ec-8092-edba1828a230,DISK], DatanodeInfoWithStorage[127.0.0.1:46143,DS-efb8a192-6970-4e5c-97f5-b6a23ec02835,DISK], DatanodeInfoWithStorage[127.0.0.1:38949,DS-5c56af78-4783-400e-ad64-bf7ddf76372f,DISK], DatanodeInfoWithStorage[127.0.0.1:42774,DS-de2bb30a-fdf1-4e52-88ee-d2d2fb71faba,DISK], DatanodeInfoWithStorage[127.0.0.1:44384,DS-8544ed3c-a201-4a4a-830f-c00536ba197c,DISK], DatanodeInfoWithStorage[127.0.0.1:44884,DS-26a8df4b-adbb-4b5d-91ed-4507701c0be1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-90928984-172.17.0.20-1598446334198:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44319,DS-5b131f9f-c597-4f19-a1bc-f1002cea553e,DISK], DatanodeInfoWithStorage[127.0.0.1:32781,DS-7e4597ce-5218-48c7-b9ef-caedcefb0c59,DISK], DatanodeInfoWithStorage[127.0.0.1:36415,DS-ddbe29fc-2fe4-49ec-8092-edba1828a230,DISK], DatanodeInfoWithStorage[127.0.0.1:46143,DS-efb8a192-6970-4e5c-97f5-b6a23ec02835,DISK], DatanodeInfoWithStorage[127.0.0.1:38949,DS-5c56af78-4783-400e-ad64-bf7ddf76372f,DISK], DatanodeInfoWithStorage[127.0.0.1:42774,DS-de2bb30a-fdf1-4e52-88ee-d2d2fb71faba,DISK], DatanodeInfoWithStorage[127.0.0.1:44384,DS-8544ed3c-a201-4a4a-830f-c00536ba197c,DISK], DatanodeInfoWithStorage[127.0.0.1:44884,DS-26a8df4b-adbb-4b5d-91ed-4507701c0be1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1921368939-172.17.0.20-1598446379148:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42548,DS-55a7ee02-e325-4ab2-9286-050bcdcad1e6,DISK], DatanodeInfoWithStorage[127.0.0.1:43469,DS-5b637649-79c6-403d-80ed-fc0b2b31d928,DISK], DatanodeInfoWithStorage[127.0.0.1:34618,DS-0ba56ee4-152c-4ba2-a716-e724c388a260,DISK], DatanodeInfoWithStorage[127.0.0.1:36657,DS-d122e76a-9aee-4335-883e-35b929bcf379,DISK], DatanodeInfoWithStorage[127.0.0.1:45159,DS-83c64b62-9151-4564-a943-386a0a68c339,DISK], DatanodeInfoWithStorage[127.0.0.1:41097,DS-073cab3a-0f32-46be-8175-70b4ec4ddcb1,DISK], DatanodeInfoWithStorage[127.0.0.1:41125,DS-d590ed7d-524c-44da-af03-26d24a9ab203,DISK], DatanodeInfoWithStorage[127.0.0.1:41622,DS-20441592-a740-46b0-9630-a98865044594,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1921368939-172.17.0.20-1598446379148:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42548,DS-55a7ee02-e325-4ab2-9286-050bcdcad1e6,DISK], DatanodeInfoWithStorage[127.0.0.1:43469,DS-5b637649-79c6-403d-80ed-fc0b2b31d928,DISK], DatanodeInfoWithStorage[127.0.0.1:34618,DS-0ba56ee4-152c-4ba2-a716-e724c388a260,DISK], DatanodeInfoWithStorage[127.0.0.1:36657,DS-d122e76a-9aee-4335-883e-35b929bcf379,DISK], DatanodeInfoWithStorage[127.0.0.1:45159,DS-83c64b62-9151-4564-a943-386a0a68c339,DISK], DatanodeInfoWithStorage[127.0.0.1:41097,DS-073cab3a-0f32-46be-8175-70b4ec4ddcb1,DISK], DatanodeInfoWithStorage[127.0.0.1:41125,DS-d590ed7d-524c-44da-af03-26d24a9ab203,DISK], DatanodeInfoWithStorage[127.0.0.1:41622,DS-20441592-a740-46b0-9630-a98865044594,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1806091080-172.17.0.20-1598446493446:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38497,DS-d0b85f86-0337-4937-9268-6706bf2b5290,DISK], DatanodeInfoWithStorage[127.0.0.1:44496,DS-383509fe-4f5e-43a1-a2e8-7f9f7028c1d3,DISK], DatanodeInfoWithStorage[127.0.0.1:40651,DS-1095fec4-1ed9-4b93-9e50-7588a2b25fb1,DISK], DatanodeInfoWithStorage[127.0.0.1:38169,DS-cee749fb-0347-4fb8-9510-76fefc26d55d,DISK], DatanodeInfoWithStorage[127.0.0.1:42043,DS-9b5f076f-1a46-4064-b04d-293bfbeb2a9d,DISK], DatanodeInfoWithStorage[127.0.0.1:34885,DS-d2535c02-c937-49db-b048-4890db7e1fb6,DISK], DatanodeInfoWithStorage[127.0.0.1:34404,DS-98f2c056-e59b-46a4-b9db-08341e691618,DISK], DatanodeInfoWithStorage[127.0.0.1:39149,DS-d74cb23b-5e0e-446d-b0bb-a77ad360e9fe,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1806091080-172.17.0.20-1598446493446:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38497,DS-d0b85f86-0337-4937-9268-6706bf2b5290,DISK], DatanodeInfoWithStorage[127.0.0.1:44496,DS-383509fe-4f5e-43a1-a2e8-7f9f7028c1d3,DISK], DatanodeInfoWithStorage[127.0.0.1:40651,DS-1095fec4-1ed9-4b93-9e50-7588a2b25fb1,DISK], DatanodeInfoWithStorage[127.0.0.1:38169,DS-cee749fb-0347-4fb8-9510-76fefc26d55d,DISK], DatanodeInfoWithStorage[127.0.0.1:42043,DS-9b5f076f-1a46-4064-b04d-293bfbeb2a9d,DISK], DatanodeInfoWithStorage[127.0.0.1:34885,DS-d2535c02-c937-49db-b048-4890db7e1fb6,DISK], DatanodeInfoWithStorage[127.0.0.1:34404,DS-98f2c056-e59b-46a4-b9db-08341e691618,DISK], DatanodeInfoWithStorage[127.0.0.1:39149,DS-d74cb23b-5e0e-446d-b0bb-a77ad360e9fe,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2108140495-172.17.0.20-1598446674901:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42000,DS-dadb54cb-83dd-433a-b5b8-6a1ccf7ec767,DISK], DatanodeInfoWithStorage[127.0.0.1:33578,DS-a120f796-d741-41ed-b81b-2c1ab7fac0b8,DISK], DatanodeInfoWithStorage[127.0.0.1:44998,DS-64640d6d-0ff1-4b73-b0d5-359fc7e5aaa5,DISK], DatanodeInfoWithStorage[127.0.0.1:37147,DS-0a5d7d8f-63cb-4fd0-8355-5d254caa6baf,DISK], DatanodeInfoWithStorage[127.0.0.1:39852,DS-c7721042-876a-499e-9107-8df1e657cbd3,DISK], DatanodeInfoWithStorage[127.0.0.1:38650,DS-2d2d2637-4d32-431a-b894-5fc1b73bc02f,DISK], DatanodeInfoWithStorage[127.0.0.1:44259,DS-9b575b7d-2813-4292-bcf4-a10f5778a9d7,DISK], DatanodeInfoWithStorage[127.0.0.1:38795,DS-ea48677d-08bf-4831-aef8-deb867b6c0fc,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2108140495-172.17.0.20-1598446674901:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42000,DS-dadb54cb-83dd-433a-b5b8-6a1ccf7ec767,DISK], DatanodeInfoWithStorage[127.0.0.1:33578,DS-a120f796-d741-41ed-b81b-2c1ab7fac0b8,DISK], DatanodeInfoWithStorage[127.0.0.1:44998,DS-64640d6d-0ff1-4b73-b0d5-359fc7e5aaa5,DISK], DatanodeInfoWithStorage[127.0.0.1:37147,DS-0a5d7d8f-63cb-4fd0-8355-5d254caa6baf,DISK], DatanodeInfoWithStorage[127.0.0.1:39852,DS-c7721042-876a-499e-9107-8df1e657cbd3,DISK], DatanodeInfoWithStorage[127.0.0.1:38650,DS-2d2d2637-4d32-431a-b894-5fc1b73bc02f,DISK], DatanodeInfoWithStorage[127.0.0.1:44259,DS-9b575b7d-2813-4292-bcf4-a10f5778a9d7,DISK], DatanodeInfoWithStorage[127.0.0.1:38795,DS-ea48677d-08bf-4831-aef8-deb867b6c0fc,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1729526154-172.17.0.20-1598446715278:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35475,DS-da33c44f-6a3e-415c-b3ad-bcc7eaa434f3,DISK], DatanodeInfoWithStorage[127.0.0.1:36673,DS-736cafd1-b443-43b6-a2c5-c3caa044a02e,DISK], DatanodeInfoWithStorage[127.0.0.1:39905,DS-ec8f6f08-809f-41a7-b7b0-e135f51839ef,DISK], DatanodeInfoWithStorage[127.0.0.1:46209,DS-60646480-3529-4006-9aab-9ab66f15fa69,DISK], DatanodeInfoWithStorage[127.0.0.1:35967,DS-0f3d0e02-7810-4849-8d8d-239ae3da959c,DISK], DatanodeInfoWithStorage[127.0.0.1:44564,DS-db3a130e-ba35-49ea-b9fa-318c9df85948,DISK], DatanodeInfoWithStorage[127.0.0.1:39926,DS-9cb54897-8e25-45ef-8b0c-ebd2ed885071,DISK], DatanodeInfoWithStorage[127.0.0.1:33659,DS-558cdf2e-2c28-4c6f-b79a-586de837e2c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1729526154-172.17.0.20-1598446715278:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35475,DS-da33c44f-6a3e-415c-b3ad-bcc7eaa434f3,DISK], DatanodeInfoWithStorage[127.0.0.1:36673,DS-736cafd1-b443-43b6-a2c5-c3caa044a02e,DISK], DatanodeInfoWithStorage[127.0.0.1:39905,DS-ec8f6f08-809f-41a7-b7b0-e135f51839ef,DISK], DatanodeInfoWithStorage[127.0.0.1:46209,DS-60646480-3529-4006-9aab-9ab66f15fa69,DISK], DatanodeInfoWithStorage[127.0.0.1:35967,DS-0f3d0e02-7810-4849-8d8d-239ae3da959c,DISK], DatanodeInfoWithStorage[127.0.0.1:44564,DS-db3a130e-ba35-49ea-b9fa-318c9df85948,DISK], DatanodeInfoWithStorage[127.0.0.1:39926,DS-9cb54897-8e25-45ef-8b0c-ebd2ed885071,DISK], DatanodeInfoWithStorage[127.0.0.1:33659,DS-558cdf2e-2c28-4c6f-b79a-586de837e2c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1733368081-172.17.0.20-1598446750229:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43288,DS-a43f94db-260a-4aaa-a460-5aebeb20475c,DISK], DatanodeInfoWithStorage[127.0.0.1:44262,DS-9f522b3f-e116-4c98-a302-43d988159d3c,DISK], DatanodeInfoWithStorage[127.0.0.1:34358,DS-78872528-b17a-4f71-95b9-af68586b1ada,DISK], DatanodeInfoWithStorage[127.0.0.1:34643,DS-4f090cf6-f7af-415a-b3ee-dacbec29bd69,DISK], DatanodeInfoWithStorage[127.0.0.1:41921,DS-d6da8f21-b240-4d8d-b0df-f60a23425c15,DISK], DatanodeInfoWithStorage[127.0.0.1:42161,DS-d44aa370-0af1-4d7e-a8c7-b252fd4d75f5,DISK], DatanodeInfoWithStorage[127.0.0.1:38944,DS-e41fa9a4-5e93-40d0-9f6f-9061444a6725,DISK], DatanodeInfoWithStorage[127.0.0.1:40214,DS-cd75ac5f-209b-4cf8-bb2a-b070edd0b87d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1733368081-172.17.0.20-1598446750229:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43288,DS-a43f94db-260a-4aaa-a460-5aebeb20475c,DISK], DatanodeInfoWithStorage[127.0.0.1:44262,DS-9f522b3f-e116-4c98-a302-43d988159d3c,DISK], DatanodeInfoWithStorage[127.0.0.1:34358,DS-78872528-b17a-4f71-95b9-af68586b1ada,DISK], DatanodeInfoWithStorage[127.0.0.1:34643,DS-4f090cf6-f7af-415a-b3ee-dacbec29bd69,DISK], DatanodeInfoWithStorage[127.0.0.1:41921,DS-d6da8f21-b240-4d8d-b0df-f60a23425c15,DISK], DatanodeInfoWithStorage[127.0.0.1:42161,DS-d44aa370-0af1-4d7e-a8c7-b252fd4d75f5,DISK], DatanodeInfoWithStorage[127.0.0.1:38944,DS-e41fa9a4-5e93-40d0-9f6f-9061444a6725,DISK], DatanodeInfoWithStorage[127.0.0.1:40214,DS-cd75ac5f-209b-4cf8-bb2a-b070edd0b87d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1118590987-172.17.0.20-1598446829682:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42201,DS-ea63f296-1c64-48c2-b07d-35f9288d9f07,DISK], DatanodeInfoWithStorage[127.0.0.1:44466,DS-53acfb23-9e61-4624-8127-8ce6548db284,DISK], DatanodeInfoWithStorage[127.0.0.1:39184,DS-9b27e84b-5446-4ff4-bffa-e2cf6cf71681,DISK], DatanodeInfoWithStorage[127.0.0.1:41311,DS-d48af348-5aa3-436b-9d0f-c1d7de5ac475,DISK], DatanodeInfoWithStorage[127.0.0.1:38863,DS-5fe02063-f562-45de-9e3d-77da276af943,DISK], DatanodeInfoWithStorage[127.0.0.1:39303,DS-f3ba3ade-1243-409c-a61e-1725dc17823b,DISK], DatanodeInfoWithStorage[127.0.0.1:37130,DS-8ae14ed7-6049-4005-a707-a2c5565222b3,DISK], DatanodeInfoWithStorage[127.0.0.1:33391,DS-cce0b734-2dc2-4667-b381-5ca89691ebdd,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1118590987-172.17.0.20-1598446829682:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42201,DS-ea63f296-1c64-48c2-b07d-35f9288d9f07,DISK], DatanodeInfoWithStorage[127.0.0.1:44466,DS-53acfb23-9e61-4624-8127-8ce6548db284,DISK], DatanodeInfoWithStorage[127.0.0.1:39184,DS-9b27e84b-5446-4ff4-bffa-e2cf6cf71681,DISK], DatanodeInfoWithStorage[127.0.0.1:41311,DS-d48af348-5aa3-436b-9d0f-c1d7de5ac475,DISK], DatanodeInfoWithStorage[127.0.0.1:38863,DS-5fe02063-f562-45de-9e3d-77da276af943,DISK], DatanodeInfoWithStorage[127.0.0.1:39303,DS-f3ba3ade-1243-409c-a61e-1725dc17823b,DISK], DatanodeInfoWithStorage[127.0.0.1:37130,DS-8ae14ed7-6049-4005-a707-a2c5565222b3,DISK], DatanodeInfoWithStorage[127.0.0.1:33391,DS-cce0b734-2dc2-4667-b381-5ca89691ebdd,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-488843507-172.17.0.20-1598446865648:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40673,DS-22ed9249-5290-4a52-9d18-cf6630d459ac,DISK], DatanodeInfoWithStorage[127.0.0.1:40217,DS-04b97259-8fca-4f4f-abb8-108a7469f8e4,DISK], DatanodeInfoWithStorage[127.0.0.1:40515,DS-34d80d19-2999-456a-a7ae-784a9af0c660,DISK], DatanodeInfoWithStorage[127.0.0.1:33990,DS-78b2a6fd-8715-40da-bd3a-22f744ae6fdb,DISK], DatanodeInfoWithStorage[127.0.0.1:45905,DS-8c1d527e-4871-4f21-bf10-8975ebaaef9d,DISK], DatanodeInfoWithStorage[127.0.0.1:37118,DS-f3f9fa7a-df9f-44b2-a8b5-215d20da40df,DISK], DatanodeInfoWithStorage[127.0.0.1:34654,DS-1d3ef6ef-4007-4ead-8b09-845ac4b9f3e6,DISK], DatanodeInfoWithStorage[127.0.0.1:32832,DS-c05b88e2-4151-481d-90e4-f266390a7638,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-488843507-172.17.0.20-1598446865648:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40673,DS-22ed9249-5290-4a52-9d18-cf6630d459ac,DISK], DatanodeInfoWithStorage[127.0.0.1:40217,DS-04b97259-8fca-4f4f-abb8-108a7469f8e4,DISK], DatanodeInfoWithStorage[127.0.0.1:40515,DS-34d80d19-2999-456a-a7ae-784a9af0c660,DISK], DatanodeInfoWithStorage[127.0.0.1:33990,DS-78b2a6fd-8715-40da-bd3a-22f744ae6fdb,DISK], DatanodeInfoWithStorage[127.0.0.1:45905,DS-8c1d527e-4871-4f21-bf10-8975ebaaef9d,DISK], DatanodeInfoWithStorage[127.0.0.1:37118,DS-f3f9fa7a-df9f-44b2-a8b5-215d20da40df,DISK], DatanodeInfoWithStorage[127.0.0.1:34654,DS-1d3ef6ef-4007-4ead-8b09-845ac4b9f3e6,DISK], DatanodeInfoWithStorage[127.0.0.1:32832,DS-c05b88e2-4151-481d-90e4-f266390a7638,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1141626182-172.17.0.20-1598446903543:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35412,DS-3754c938-8d11-4fbe-9e13-cd77fbebd542,DISK], DatanodeInfoWithStorage[127.0.0.1:44715,DS-23320c2e-d908-4ee3-8004-ba52c378a0e0,DISK], DatanodeInfoWithStorage[127.0.0.1:41657,DS-d3cf5ff1-4647-4518-a777-d52e29fab2f6,DISK], DatanodeInfoWithStorage[127.0.0.1:41069,DS-ce338de4-3b48-4507-91eb-a19fe4af194a,DISK], DatanodeInfoWithStorage[127.0.0.1:39331,DS-57cdc695-2f8f-4170-b3fc-e848fc6b16ff,DISK], DatanodeInfoWithStorage[127.0.0.1:43897,DS-bb474a3a-d98d-4466-a4e8-ddc7f1b19987,DISK], DatanodeInfoWithStorage[127.0.0.1:43526,DS-d436b7ae-edee-4a6b-aff4-eaa6b38f79a5,DISK], DatanodeInfoWithStorage[127.0.0.1:38732,DS-8dc9389d-543f-46cd-8ea0-d0fb9c6cb85f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1141626182-172.17.0.20-1598446903543:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35412,DS-3754c938-8d11-4fbe-9e13-cd77fbebd542,DISK], DatanodeInfoWithStorage[127.0.0.1:44715,DS-23320c2e-d908-4ee3-8004-ba52c378a0e0,DISK], DatanodeInfoWithStorage[127.0.0.1:41657,DS-d3cf5ff1-4647-4518-a777-d52e29fab2f6,DISK], DatanodeInfoWithStorage[127.0.0.1:41069,DS-ce338de4-3b48-4507-91eb-a19fe4af194a,DISK], DatanodeInfoWithStorage[127.0.0.1:39331,DS-57cdc695-2f8f-4170-b3fc-e848fc6b16ff,DISK], DatanodeInfoWithStorage[127.0.0.1:43897,DS-bb474a3a-d98d-4466-a4e8-ddc7f1b19987,DISK], DatanodeInfoWithStorage[127.0.0.1:43526,DS-d436b7ae-edee-4a6b-aff4-eaa6b38f79a5,DISK], DatanodeInfoWithStorage[127.0.0.1:38732,DS-8dc9389d-543f-46cd-8ea0-d0fb9c6cb85f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 15 out of 50
v1v1v2v2 failed with probability 25 out of 50
result: false positive !!!
Total execution time in seconds : 5356
