reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-248230696-172.17.0.8-1598326019983:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36346,DS-107a0d67-692e-4491-87d2-74ad71d84cef,DISK], DatanodeInfoWithStorage[127.0.0.1:38680,DS-2da277f7-b058-40ec-a2e8-bae48d97c234,DISK], DatanodeInfoWithStorage[127.0.0.1:46306,DS-f011c246-d275-4c9a-94b2-4e62425f46f1,DISK], DatanodeInfoWithStorage[127.0.0.1:35899,DS-248099e3-769f-4f68-a214-d894bc8cd06d,DISK], DatanodeInfoWithStorage[127.0.0.1:33146,DS-a41a39f7-16fa-471c-b436-feb4af1e27d9,DISK], DatanodeInfoWithStorage[127.0.0.1:44875,DS-f5a5bf95-2e5d-49a4-b6c4-93a067423898,DISK], DatanodeInfoWithStorage[127.0.0.1:37647,DS-c48f7315-96fe-48f8-b1e8-f6f797ad3e5f,DISK], DatanodeInfoWithStorage[127.0.0.1:45853,DS-7c468ed0-c8cf-47ef-930b-8e41cd92a7b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-248230696-172.17.0.8-1598326019983:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36346,DS-107a0d67-692e-4491-87d2-74ad71d84cef,DISK], DatanodeInfoWithStorage[127.0.0.1:38680,DS-2da277f7-b058-40ec-a2e8-bae48d97c234,DISK], DatanodeInfoWithStorage[127.0.0.1:46306,DS-f011c246-d275-4c9a-94b2-4e62425f46f1,DISK], DatanodeInfoWithStorage[127.0.0.1:35899,DS-248099e3-769f-4f68-a214-d894bc8cd06d,DISK], DatanodeInfoWithStorage[127.0.0.1:33146,DS-a41a39f7-16fa-471c-b436-feb4af1e27d9,DISK], DatanodeInfoWithStorage[127.0.0.1:44875,DS-f5a5bf95-2e5d-49a4-b6c4-93a067423898,DISK], DatanodeInfoWithStorage[127.0.0.1:37647,DS-c48f7315-96fe-48f8-b1e8-f6f797ad3e5f,DISK], DatanodeInfoWithStorage[127.0.0.1:45853,DS-7c468ed0-c8cf-47ef-930b-8e41cd92a7b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1610180964-172.17.0.8-1598326085906:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38823,DS-28f690a9-bb27-4114-8380-646b1cf45ae5,DISK], DatanodeInfoWithStorage[127.0.0.1:34180,DS-7a3ff6a5-e0c7-43a7-9461-73701e03c1b9,DISK], DatanodeInfoWithStorage[127.0.0.1:37198,DS-d1dc8159-cfaa-4bb8-a123-ee90f9943125,DISK], DatanodeInfoWithStorage[127.0.0.1:42587,DS-52a0f9c5-67c3-4955-9eb2-13691f2e9bcc,DISK], DatanodeInfoWithStorage[127.0.0.1:39105,DS-b9dd4257-fb9a-4d2c-a977-e924b94c60e6,DISK], DatanodeInfoWithStorage[127.0.0.1:45464,DS-747fff0d-c08e-4aa8-a259-a0f32000ea09,DISK], DatanodeInfoWithStorage[127.0.0.1:43215,DS-b9b8b86e-8604-4216-b209-5708c0ad6add,DISK], DatanodeInfoWithStorage[127.0.0.1:33654,DS-618d337a-567a-40d3-8de2-c6491edcc11e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1610180964-172.17.0.8-1598326085906:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38823,DS-28f690a9-bb27-4114-8380-646b1cf45ae5,DISK], DatanodeInfoWithStorage[127.0.0.1:34180,DS-7a3ff6a5-e0c7-43a7-9461-73701e03c1b9,DISK], DatanodeInfoWithStorage[127.0.0.1:37198,DS-d1dc8159-cfaa-4bb8-a123-ee90f9943125,DISK], DatanodeInfoWithStorage[127.0.0.1:42587,DS-52a0f9c5-67c3-4955-9eb2-13691f2e9bcc,DISK], DatanodeInfoWithStorage[127.0.0.1:39105,DS-b9dd4257-fb9a-4d2c-a977-e924b94c60e6,DISK], DatanodeInfoWithStorage[127.0.0.1:45464,DS-747fff0d-c08e-4aa8-a259-a0f32000ea09,DISK], DatanodeInfoWithStorage[127.0.0.1:43215,DS-b9b8b86e-8604-4216-b209-5708c0ad6add,DISK], DatanodeInfoWithStorage[127.0.0.1:33654,DS-618d337a-567a-40d3-8de2-c6491edcc11e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-444275522-172.17.0.8-1598326118700:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40228,DS-f91ca093-2817-43e1-9a99-901b42e06497,DISK], DatanodeInfoWithStorage[127.0.0.1:34936,DS-0c923139-4e7f-4e84-9fff-cb2fa64e6e51,DISK], DatanodeInfoWithStorage[127.0.0.1:43663,DS-e4e2f84d-c8bf-4513-8279-1c2642d8f7ff,DISK], DatanodeInfoWithStorage[127.0.0.1:34181,DS-7065bf03-e5bc-48fa-8b79-9d5b74ef5caa,DISK], DatanodeInfoWithStorage[127.0.0.1:41442,DS-8b74a966-8747-424f-a184-089cd2586dca,DISK], DatanodeInfoWithStorage[127.0.0.1:40700,DS-7800ec63-44b9-42a3-9f96-6b68afe183f8,DISK], DatanodeInfoWithStorage[127.0.0.1:45148,DS-242f5313-d22e-4242-b387-77264e2411ed,DISK], DatanodeInfoWithStorage[127.0.0.1:39421,DS-c6f9e416-50be-4f2e-83f3-2a147c16414e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-444275522-172.17.0.8-1598326118700:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40228,DS-f91ca093-2817-43e1-9a99-901b42e06497,DISK], DatanodeInfoWithStorage[127.0.0.1:34936,DS-0c923139-4e7f-4e84-9fff-cb2fa64e6e51,DISK], DatanodeInfoWithStorage[127.0.0.1:43663,DS-e4e2f84d-c8bf-4513-8279-1c2642d8f7ff,DISK], DatanodeInfoWithStorage[127.0.0.1:34181,DS-7065bf03-e5bc-48fa-8b79-9d5b74ef5caa,DISK], DatanodeInfoWithStorage[127.0.0.1:41442,DS-8b74a966-8747-424f-a184-089cd2586dca,DISK], DatanodeInfoWithStorage[127.0.0.1:40700,DS-7800ec63-44b9-42a3-9f96-6b68afe183f8,DISK], DatanodeInfoWithStorage[127.0.0.1:45148,DS-242f5313-d22e-4242-b387-77264e2411ed,DISK], DatanodeInfoWithStorage[127.0.0.1:39421,DS-c6f9e416-50be-4f2e-83f3-2a147c16414e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1511982066-172.17.0.8-1598326215615:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33830,DS-5df87834-8afd-4898-a97f-e054beb50040,DISK], DatanodeInfoWithStorage[127.0.0.1:39295,DS-06335a48-af76-4300-bfad-d0f00226521a,DISK], DatanodeInfoWithStorage[127.0.0.1:38108,DS-3f86c044-37cb-47d9-a608-5feaa4944e6f,DISK], DatanodeInfoWithStorage[127.0.0.1:33655,DS-e30ed84c-b683-4320-864e-5e69dafc8471,DISK], DatanodeInfoWithStorage[127.0.0.1:40167,DS-6aab50ee-e15b-4d21-9053-f804987836f4,DISK], DatanodeInfoWithStorage[127.0.0.1:40201,DS-639ba672-7cde-432c-9f0d-2971b9ba1186,DISK], DatanodeInfoWithStorage[127.0.0.1:46670,DS-0b573f23-3ad2-4b24-8906-faf9705ea6d6,DISK], DatanodeInfoWithStorage[127.0.0.1:46502,DS-10fa27e9-7876-49a5-b568-0606cf51c8b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1511982066-172.17.0.8-1598326215615:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33830,DS-5df87834-8afd-4898-a97f-e054beb50040,DISK], DatanodeInfoWithStorage[127.0.0.1:39295,DS-06335a48-af76-4300-bfad-d0f00226521a,DISK], DatanodeInfoWithStorage[127.0.0.1:38108,DS-3f86c044-37cb-47d9-a608-5feaa4944e6f,DISK], DatanodeInfoWithStorage[127.0.0.1:33655,DS-e30ed84c-b683-4320-864e-5e69dafc8471,DISK], DatanodeInfoWithStorage[127.0.0.1:40167,DS-6aab50ee-e15b-4d21-9053-f804987836f4,DISK], DatanodeInfoWithStorage[127.0.0.1:40201,DS-639ba672-7cde-432c-9f0d-2971b9ba1186,DISK], DatanodeInfoWithStorage[127.0.0.1:46670,DS-0b573f23-3ad2-4b24-8906-faf9705ea6d6,DISK], DatanodeInfoWithStorage[127.0.0.1:46502,DS-10fa27e9-7876-49a5-b568-0606cf51c8b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2022916774-172.17.0.8-1598326798493:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35846,DS-3650b78f-14b7-4437-b204-0abfada48dce,DISK], DatanodeInfoWithStorage[127.0.0.1:43977,DS-8f142ccf-4025-45f3-844b-a7116169a977,DISK], DatanodeInfoWithStorage[127.0.0.1:37704,DS-15e2cf63-35dd-4835-86a5-44445b63496e,DISK], DatanodeInfoWithStorage[127.0.0.1:36115,DS-108bf30e-87b2-4116-833d-c0ca3fbf534e,DISK], DatanodeInfoWithStorage[127.0.0.1:44208,DS-e44ba52e-3de1-4a0d-87d0-c982492f3347,DISK], DatanodeInfoWithStorage[127.0.0.1:33459,DS-61b053bc-4712-49f1-971f-3340bcd23069,DISK], DatanodeInfoWithStorage[127.0.0.1:37245,DS-adc57401-a707-4a9a-ac07-60e1abf01dba,DISK], DatanodeInfoWithStorage[127.0.0.1:34680,DS-48dba65b-f88f-47a9-8ff0-7b6579f17301,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2022916774-172.17.0.8-1598326798493:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35846,DS-3650b78f-14b7-4437-b204-0abfada48dce,DISK], DatanodeInfoWithStorage[127.0.0.1:43977,DS-8f142ccf-4025-45f3-844b-a7116169a977,DISK], DatanodeInfoWithStorage[127.0.0.1:37704,DS-15e2cf63-35dd-4835-86a5-44445b63496e,DISK], DatanodeInfoWithStorage[127.0.0.1:36115,DS-108bf30e-87b2-4116-833d-c0ca3fbf534e,DISK], DatanodeInfoWithStorage[127.0.0.1:44208,DS-e44ba52e-3de1-4a0d-87d0-c982492f3347,DISK], DatanodeInfoWithStorage[127.0.0.1:33459,DS-61b053bc-4712-49f1-971f-3340bcd23069,DISK], DatanodeInfoWithStorage[127.0.0.1:37245,DS-adc57401-a707-4a9a-ac07-60e1abf01dba,DISK], DatanodeInfoWithStorage[127.0.0.1:34680,DS-48dba65b-f88f-47a9-8ff0-7b6579f17301,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1160223219-172.17.0.8-1598326869157:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36499,DS-1e0c37a8-7dab-4685-b306-e42a57cacaa2,DISK], DatanodeInfoWithStorage[127.0.0.1:41820,DS-9ec07b2f-8701-4980-b077-4dce44c83873,DISK], DatanodeInfoWithStorage[127.0.0.1:40289,DS-cc0c1770-0808-4ebd-b106-3df5050a630e,DISK], DatanodeInfoWithStorage[127.0.0.1:37928,DS-4de7bc00-1fb8-4831-bb82-ef33650346e1,DISK], DatanodeInfoWithStorage[127.0.0.1:45672,DS-5c879d57-e9cb-45f1-95aa-e1d65a965989,DISK], DatanodeInfoWithStorage[127.0.0.1:41307,DS-d27b211d-5e05-4241-8553-420830a74a29,DISK], DatanodeInfoWithStorage[127.0.0.1:35602,DS-aa6939d1-8d12-4521-a7f8-b4efb70c913c,DISK], DatanodeInfoWithStorage[127.0.0.1:41275,DS-03d3e654-6d68-4bb2-9806-5ddd61e9ca80,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1160223219-172.17.0.8-1598326869157:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36499,DS-1e0c37a8-7dab-4685-b306-e42a57cacaa2,DISK], DatanodeInfoWithStorage[127.0.0.1:41820,DS-9ec07b2f-8701-4980-b077-4dce44c83873,DISK], DatanodeInfoWithStorage[127.0.0.1:40289,DS-cc0c1770-0808-4ebd-b106-3df5050a630e,DISK], DatanodeInfoWithStorage[127.0.0.1:37928,DS-4de7bc00-1fb8-4831-bb82-ef33650346e1,DISK], DatanodeInfoWithStorage[127.0.0.1:45672,DS-5c879d57-e9cb-45f1-95aa-e1d65a965989,DISK], DatanodeInfoWithStorage[127.0.0.1:41307,DS-d27b211d-5e05-4241-8553-420830a74a29,DISK], DatanodeInfoWithStorage[127.0.0.1:35602,DS-aa6939d1-8d12-4521-a7f8-b4efb70c913c,DISK], DatanodeInfoWithStorage[127.0.0.1:41275,DS-03d3e654-6d68-4bb2-9806-5ddd61e9ca80,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2042822150-172.17.0.8-1598327565389:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45759,DS-672cbf3e-96e3-490d-a682-d659cb28ff0e,DISK], DatanodeInfoWithStorage[127.0.0.1:43478,DS-4af60639-ecbc-4c9b-a6bc-379c26d68e19,DISK], DatanodeInfoWithStorage[127.0.0.1:41103,DS-829057d1-9843-4b3f-9b0b-b599770f74a5,DISK], DatanodeInfoWithStorage[127.0.0.1:41608,DS-60aff9fe-5942-4f4a-9036-6e5fca5e9ae6,DISK], DatanodeInfoWithStorage[127.0.0.1:37421,DS-183a7280-ff89-4eda-8ce0-189a23f6833d,DISK], DatanodeInfoWithStorage[127.0.0.1:35832,DS-dba5a697-8720-4e5c-b696-21173135922b,DISK], DatanodeInfoWithStorage[127.0.0.1:43365,DS-757f8970-873c-44e2-85a9-6eb69c671415,DISK], DatanodeInfoWithStorage[127.0.0.1:36679,DS-7fe5bfef-eeda-4f45-8c17-4bb38338474b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2042822150-172.17.0.8-1598327565389:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45759,DS-672cbf3e-96e3-490d-a682-d659cb28ff0e,DISK], DatanodeInfoWithStorage[127.0.0.1:43478,DS-4af60639-ecbc-4c9b-a6bc-379c26d68e19,DISK], DatanodeInfoWithStorage[127.0.0.1:41103,DS-829057d1-9843-4b3f-9b0b-b599770f74a5,DISK], DatanodeInfoWithStorage[127.0.0.1:41608,DS-60aff9fe-5942-4f4a-9036-6e5fca5e9ae6,DISK], DatanodeInfoWithStorage[127.0.0.1:37421,DS-183a7280-ff89-4eda-8ce0-189a23f6833d,DISK], DatanodeInfoWithStorage[127.0.0.1:35832,DS-dba5a697-8720-4e5c-b696-21173135922b,DISK], DatanodeInfoWithStorage[127.0.0.1:43365,DS-757f8970-873c-44e2-85a9-6eb69c671415,DISK], DatanodeInfoWithStorage[127.0.0.1:36679,DS-7fe5bfef-eeda-4f45-8c17-4bb38338474b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1937861727-172.17.0.8-1598328147235:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34545,DS-f2f11d27-aaed-4e6d-a1c9-e80138b63f2d,DISK], DatanodeInfoWithStorage[127.0.0.1:39705,DS-b9ebdd4b-a074-43a3-9a87-f4f65494c5ec,DISK], DatanodeInfoWithStorage[127.0.0.1:40760,DS-bfe9b5e9-ab41-4b51-a486-3f71f0639b14,DISK], DatanodeInfoWithStorage[127.0.0.1:42050,DS-b281f0b7-bb5f-4cda-868c-6647ea7d4ae4,DISK], DatanodeInfoWithStorage[127.0.0.1:36509,DS-2b1ccba5-9f0c-4417-bb09-f4603fd9d5bc,DISK], DatanodeInfoWithStorage[127.0.0.1:46081,DS-7c4a5ea9-8728-4f89-9f87-1a6d39934695,DISK], DatanodeInfoWithStorage[127.0.0.1:35828,DS-3643062e-c957-4a58-bc79-099e73b43069,DISK], DatanodeInfoWithStorage[127.0.0.1:43774,DS-91bde917-4cd3-4cc9-b00e-17ccecbbe1dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1937861727-172.17.0.8-1598328147235:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34545,DS-f2f11d27-aaed-4e6d-a1c9-e80138b63f2d,DISK], DatanodeInfoWithStorage[127.0.0.1:39705,DS-b9ebdd4b-a074-43a3-9a87-f4f65494c5ec,DISK], DatanodeInfoWithStorage[127.0.0.1:40760,DS-bfe9b5e9-ab41-4b51-a486-3f71f0639b14,DISK], DatanodeInfoWithStorage[127.0.0.1:42050,DS-b281f0b7-bb5f-4cda-868c-6647ea7d4ae4,DISK], DatanodeInfoWithStorage[127.0.0.1:36509,DS-2b1ccba5-9f0c-4417-bb09-f4603fd9d5bc,DISK], DatanodeInfoWithStorage[127.0.0.1:46081,DS-7c4a5ea9-8728-4f89-9f87-1a6d39934695,DISK], DatanodeInfoWithStorage[127.0.0.1:35828,DS-3643062e-c957-4a58-bc79-099e73b43069,DISK], DatanodeInfoWithStorage[127.0.0.1:43774,DS-91bde917-4cd3-4cc9-b00e-17ccecbbe1dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2031009103-172.17.0.8-1598328221284:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42162,DS-af3d6c71-6dfb-415c-a076-6c5f409e8561,DISK], DatanodeInfoWithStorage[127.0.0.1:36491,DS-0d901c7a-1c09-404e-96c4-76f97aac3a6d,DISK], DatanodeInfoWithStorage[127.0.0.1:39081,DS-4db25c3e-1240-40d0-97c8-cd2ea3ac2777,DISK], DatanodeInfoWithStorage[127.0.0.1:40893,DS-135b1f6e-f2fc-4b2d-8fc2-c75de1b20b29,DISK], DatanodeInfoWithStorage[127.0.0.1:41204,DS-c897586a-2274-45ac-ba54-7992791ab5fa,DISK], DatanodeInfoWithStorage[127.0.0.1:39157,DS-e16c41f1-fb40-408a-a52c-a11ad246f355,DISK], DatanodeInfoWithStorage[127.0.0.1:43242,DS-f64b2296-0a18-4593-b455-3072f7ec9ee5,DISK], DatanodeInfoWithStorage[127.0.0.1:44167,DS-6daa6e70-d2f8-4dec-b0ce-9d0eba5e7d7b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2031009103-172.17.0.8-1598328221284:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42162,DS-af3d6c71-6dfb-415c-a076-6c5f409e8561,DISK], DatanodeInfoWithStorage[127.0.0.1:36491,DS-0d901c7a-1c09-404e-96c4-76f97aac3a6d,DISK], DatanodeInfoWithStorage[127.0.0.1:39081,DS-4db25c3e-1240-40d0-97c8-cd2ea3ac2777,DISK], DatanodeInfoWithStorage[127.0.0.1:40893,DS-135b1f6e-f2fc-4b2d-8fc2-c75de1b20b29,DISK], DatanodeInfoWithStorage[127.0.0.1:41204,DS-c897586a-2274-45ac-ba54-7992791ab5fa,DISK], DatanodeInfoWithStorage[127.0.0.1:39157,DS-e16c41f1-fb40-408a-a52c-a11ad246f355,DISK], DatanodeInfoWithStorage[127.0.0.1:43242,DS-f64b2296-0a18-4593-b455-3072f7ec9ee5,DISK], DatanodeInfoWithStorage[127.0.0.1:44167,DS-6daa6e70-d2f8-4dec-b0ce-9d0eba5e7d7b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-375593521-172.17.0.8-1598328287493:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42441,DS-8a0f4cff-581a-41ce-bbdf-e6e1d6c8a311,DISK], DatanodeInfoWithStorage[127.0.0.1:35623,DS-0ebc967f-9ca7-4156-9f59-d896f560e11e,DISK], DatanodeInfoWithStorage[127.0.0.1:44408,DS-33e82231-d812-48e2-b000-f1b3dd826120,DISK], DatanodeInfoWithStorage[127.0.0.1:34252,DS-f3aaae23-eba7-4480-a8bd-10aacb4f745c,DISK], DatanodeInfoWithStorage[127.0.0.1:44863,DS-7929d0cc-2159-47be-9630-0aae3773ca10,DISK], DatanodeInfoWithStorage[127.0.0.1:33760,DS-f32d2bc7-0458-4524-85ed-ff4491b90dde,DISK], DatanodeInfoWithStorage[127.0.0.1:37858,DS-fbf47b82-ef02-4218-9882-a2346dc1bb9f,DISK], DatanodeInfoWithStorage[127.0.0.1:46084,DS-31f8f72a-bcfa-43c4-b0f5-bdd2ba0b8ed5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-375593521-172.17.0.8-1598328287493:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42441,DS-8a0f4cff-581a-41ce-bbdf-e6e1d6c8a311,DISK], DatanodeInfoWithStorage[127.0.0.1:35623,DS-0ebc967f-9ca7-4156-9f59-d896f560e11e,DISK], DatanodeInfoWithStorage[127.0.0.1:44408,DS-33e82231-d812-48e2-b000-f1b3dd826120,DISK], DatanodeInfoWithStorage[127.0.0.1:34252,DS-f3aaae23-eba7-4480-a8bd-10aacb4f745c,DISK], DatanodeInfoWithStorage[127.0.0.1:44863,DS-7929d0cc-2159-47be-9630-0aae3773ca10,DISK], DatanodeInfoWithStorage[127.0.0.1:33760,DS-f32d2bc7-0458-4524-85ed-ff4491b90dde,DISK], DatanodeInfoWithStorage[127.0.0.1:37858,DS-fbf47b82-ef02-4218-9882-a2346dc1bb9f,DISK], DatanodeInfoWithStorage[127.0.0.1:46084,DS-31f8f72a-bcfa-43c4-b0f5-bdd2ba0b8ed5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-776478741-172.17.0.8-1598329284140:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39023,DS-7accab37-757c-4b45-bd59-bd0cb02dd411,DISK], DatanodeInfoWithStorage[127.0.0.1:45873,DS-d03d25cb-6d2e-46f3-a7e1-8402397ded8d,DISK], DatanodeInfoWithStorage[127.0.0.1:44465,DS-932ab100-4a3e-4e58-abc9-ce6035124dfc,DISK], DatanodeInfoWithStorage[127.0.0.1:36676,DS-50493a96-b982-4f03-8354-d5dedc2dddce,DISK], DatanodeInfoWithStorage[127.0.0.1:35303,DS-ce1ad5fc-9964-4153-a3dc-23fbc1117f9d,DISK], DatanodeInfoWithStorage[127.0.0.1:39768,DS-5612bdf7-06ed-4dd5-b9ce-0bb1593cedd7,DISK], DatanodeInfoWithStorage[127.0.0.1:44055,DS-8c8d2ed6-0274-44e5-9846-290ca6a71adc,DISK], DatanodeInfoWithStorage[127.0.0.1:41126,DS-669b8636-8640-436a-8b2b-0f185a81e8f2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-776478741-172.17.0.8-1598329284140:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39023,DS-7accab37-757c-4b45-bd59-bd0cb02dd411,DISK], DatanodeInfoWithStorage[127.0.0.1:45873,DS-d03d25cb-6d2e-46f3-a7e1-8402397ded8d,DISK], DatanodeInfoWithStorage[127.0.0.1:44465,DS-932ab100-4a3e-4e58-abc9-ce6035124dfc,DISK], DatanodeInfoWithStorage[127.0.0.1:36676,DS-50493a96-b982-4f03-8354-d5dedc2dddce,DISK], DatanodeInfoWithStorage[127.0.0.1:35303,DS-ce1ad5fc-9964-4153-a3dc-23fbc1117f9d,DISK], DatanodeInfoWithStorage[127.0.0.1:39768,DS-5612bdf7-06ed-4dd5-b9ce-0bb1593cedd7,DISK], DatanodeInfoWithStorage[127.0.0.1:44055,DS-8c8d2ed6-0274-44e5-9846-290ca6a71adc,DISK], DatanodeInfoWithStorage[127.0.0.1:41126,DS-669b8636-8640-436a-8b2b-0f185a81e8f2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1179626432-172.17.0.8-1598329490063:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39390,DS-896366d7-3c8b-413b-bcf9-5d2780197319,DISK], DatanodeInfoWithStorage[127.0.0.1:37942,DS-c4f7f70d-52d3-48a3-8b42-67bda73cbeaa,DISK], DatanodeInfoWithStorage[127.0.0.1:40922,DS-b6ec5824-61e3-452d-8e92-82f44a3f14e9,DISK], DatanodeInfoWithStorage[127.0.0.1:45815,DS-d1d6032f-3994-4591-92cc-289ed40b920f,DISK], DatanodeInfoWithStorage[127.0.0.1:37295,DS-39d5afa3-28da-4e89-848f-0e47517264ce,DISK], DatanodeInfoWithStorage[127.0.0.1:35676,DS-bac3e3e1-8717-4d28-9d6e-e40cddc3a2c8,DISK], DatanodeInfoWithStorage[127.0.0.1:44565,DS-8f433905-cf7b-42de-b8e9-003111f7027c,DISK], DatanodeInfoWithStorage[127.0.0.1:39935,DS-1f9f205e-e685-4378-ac03-e8c9167344ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1179626432-172.17.0.8-1598329490063:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39390,DS-896366d7-3c8b-413b-bcf9-5d2780197319,DISK], DatanodeInfoWithStorage[127.0.0.1:37942,DS-c4f7f70d-52d3-48a3-8b42-67bda73cbeaa,DISK], DatanodeInfoWithStorage[127.0.0.1:40922,DS-b6ec5824-61e3-452d-8e92-82f44a3f14e9,DISK], DatanodeInfoWithStorage[127.0.0.1:45815,DS-d1d6032f-3994-4591-92cc-289ed40b920f,DISK], DatanodeInfoWithStorage[127.0.0.1:37295,DS-39d5afa3-28da-4e89-848f-0e47517264ce,DISK], DatanodeInfoWithStorage[127.0.0.1:35676,DS-bac3e3e1-8717-4d28-9d6e-e40cddc3a2c8,DISK], DatanodeInfoWithStorage[127.0.0.1:44565,DS-8f433905-cf7b-42de-b8e9-003111f7027c,DISK], DatanodeInfoWithStorage[127.0.0.1:39935,DS-1f9f205e-e685-4378-ac03-e8c9167344ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1572240880-172.17.0.8-1598330392373:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40081,DS-9d6655e1-c990-4ae9-8ef9-2d0f4576fd95,DISK], DatanodeInfoWithStorage[127.0.0.1:41646,DS-491f3093-5d93-4551-8c3d-874aa269991a,DISK], DatanodeInfoWithStorage[127.0.0.1:38721,DS-22882b59-bbb0-438e-b6b4-7b2dcd6840dc,DISK], DatanodeInfoWithStorage[127.0.0.1:35597,DS-3f25479d-10b7-43ba-bcb0-98fa9216cc86,DISK], DatanodeInfoWithStorage[127.0.0.1:33189,DS-edd11f3d-a065-47f6-8c1a-b932deab30a1,DISK], DatanodeInfoWithStorage[127.0.0.1:37566,DS-d4d4485e-1eea-4353-bd99-383dd086dbc4,DISK], DatanodeInfoWithStorage[127.0.0.1:34806,DS-1caf81af-0952-4e28-90f6-ba617718af2b,DISK], DatanodeInfoWithStorage[127.0.0.1:43410,DS-88d4de2f-c0e7-4889-9a51-1c1736cfed97,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1572240880-172.17.0.8-1598330392373:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40081,DS-9d6655e1-c990-4ae9-8ef9-2d0f4576fd95,DISK], DatanodeInfoWithStorage[127.0.0.1:41646,DS-491f3093-5d93-4551-8c3d-874aa269991a,DISK], DatanodeInfoWithStorage[127.0.0.1:38721,DS-22882b59-bbb0-438e-b6b4-7b2dcd6840dc,DISK], DatanodeInfoWithStorage[127.0.0.1:35597,DS-3f25479d-10b7-43ba-bcb0-98fa9216cc86,DISK], DatanodeInfoWithStorage[127.0.0.1:33189,DS-edd11f3d-a065-47f6-8c1a-b932deab30a1,DISK], DatanodeInfoWithStorage[127.0.0.1:37566,DS-d4d4485e-1eea-4353-bd99-383dd086dbc4,DISK], DatanodeInfoWithStorage[127.0.0.1:34806,DS-1caf81af-0952-4e28-90f6-ba617718af2b,DISK], DatanodeInfoWithStorage[127.0.0.1:43410,DS-88d4de2f-c0e7-4889-9a51-1c1736cfed97,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-217125897-172.17.0.8-1598330529987:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38210,DS-8b407724-5b06-403c-a476-d4c0890a6af3,DISK], DatanodeInfoWithStorage[127.0.0.1:33231,DS-20fcbdd9-d27a-4963-907d-660ef3aae0d5,DISK], DatanodeInfoWithStorage[127.0.0.1:40163,DS-4dccf145-ff63-40ce-8c1f-63796ff0aa13,DISK], DatanodeInfoWithStorage[127.0.0.1:35698,DS-7f84f954-7e3b-4f74-98cc-d5444334fd16,DISK], DatanodeInfoWithStorage[127.0.0.1:38937,DS-171dfcef-9423-43b1-9666-9c0e083db60a,DISK], DatanodeInfoWithStorage[127.0.0.1:37203,DS-2810d517-438e-4d3b-a1e7-fd2e649bd56b,DISK], DatanodeInfoWithStorage[127.0.0.1:39545,DS-fcd98074-ae7f-4aa6-9a7a-f35acf16a642,DISK], DatanodeInfoWithStorage[127.0.0.1:37895,DS-e86dbac5-5bb7-4a23-9a66-5643d9fa2799,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-217125897-172.17.0.8-1598330529987:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38210,DS-8b407724-5b06-403c-a476-d4c0890a6af3,DISK], DatanodeInfoWithStorage[127.0.0.1:33231,DS-20fcbdd9-d27a-4963-907d-660ef3aae0d5,DISK], DatanodeInfoWithStorage[127.0.0.1:40163,DS-4dccf145-ff63-40ce-8c1f-63796ff0aa13,DISK], DatanodeInfoWithStorage[127.0.0.1:35698,DS-7f84f954-7e3b-4f74-98cc-d5444334fd16,DISK], DatanodeInfoWithStorage[127.0.0.1:38937,DS-171dfcef-9423-43b1-9666-9c0e083db60a,DISK], DatanodeInfoWithStorage[127.0.0.1:37203,DS-2810d517-438e-4d3b-a1e7-fd2e649bd56b,DISK], DatanodeInfoWithStorage[127.0.0.1:39545,DS-fcd98074-ae7f-4aa6-9a7a-f35acf16a642,DISK], DatanodeInfoWithStorage[127.0.0.1:37895,DS-e86dbac5-5bb7-4a23-9a66-5643d9fa2799,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-659168702-172.17.0.8-1598330795074:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41654,DS-cb738366-8109-4843-93c8-1bfc6dba5793,DISK], DatanodeInfoWithStorage[127.0.0.1:37495,DS-03715309-69ca-4c30-9774-1c1e4f3ff6d2,DISK], DatanodeInfoWithStorage[127.0.0.1:40812,DS-c965b304-4d76-424f-b70b-fe5330801bd2,DISK], DatanodeInfoWithStorage[127.0.0.1:43681,DS-083567de-3375-472b-a77f-64b3e6579794,DISK], DatanodeInfoWithStorage[127.0.0.1:34208,DS-497f7ea2-ef39-4ec6-8d7e-f5d63631ac15,DISK], DatanodeInfoWithStorage[127.0.0.1:36626,DS-48746d5c-66e2-42b8-8902-8a1387d95d11,DISK], DatanodeInfoWithStorage[127.0.0.1:44046,DS-20de9eac-05d3-41b5-ade6-f2d3f935be10,DISK], DatanodeInfoWithStorage[127.0.0.1:34117,DS-8fa3e99b-8cec-4032-bd7e-1fbf3731e03b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-659168702-172.17.0.8-1598330795074:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41654,DS-cb738366-8109-4843-93c8-1bfc6dba5793,DISK], DatanodeInfoWithStorage[127.0.0.1:37495,DS-03715309-69ca-4c30-9774-1c1e4f3ff6d2,DISK], DatanodeInfoWithStorage[127.0.0.1:40812,DS-c965b304-4d76-424f-b70b-fe5330801bd2,DISK], DatanodeInfoWithStorage[127.0.0.1:43681,DS-083567de-3375-472b-a77f-64b3e6579794,DISK], DatanodeInfoWithStorage[127.0.0.1:34208,DS-497f7ea2-ef39-4ec6-8d7e-f5d63631ac15,DISK], DatanodeInfoWithStorage[127.0.0.1:36626,DS-48746d5c-66e2-42b8-8902-8a1387d95d11,DISK], DatanodeInfoWithStorage[127.0.0.1:44046,DS-20de9eac-05d3-41b5-ade6-f2d3f935be10,DISK], DatanodeInfoWithStorage[127.0.0.1:34117,DS-8fa3e99b-8cec-4032-bd7e-1fbf3731e03b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5192
