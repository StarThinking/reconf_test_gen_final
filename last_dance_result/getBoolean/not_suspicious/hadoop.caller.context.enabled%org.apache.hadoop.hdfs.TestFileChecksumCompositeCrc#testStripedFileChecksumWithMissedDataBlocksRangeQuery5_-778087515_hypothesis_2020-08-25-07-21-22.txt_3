reconf_parameter: hadoop.caller.context.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1177152042-172.17.0.4-1598340805338:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37648,DS-14a660e2-1347-44f2-96eb-272b47b76696,DISK], DatanodeInfoWithStorage[127.0.0.1:44988,DS-1192cfc7-a2c1-4097-b7c7-8be35709de0b,DISK], DatanodeInfoWithStorage[127.0.0.1:38729,DS-0906751b-78b9-4eff-a186-47e46fdee0c1,DISK], DatanodeInfoWithStorage[127.0.0.1:41918,DS-1d8f6c99-ea05-499c-af1c-77b413565cb3,DISK], DatanodeInfoWithStorage[127.0.0.1:46658,DS-cff82f33-b90b-40a1-9e73-de144b7d884c,DISK], DatanodeInfoWithStorage[127.0.0.1:34987,DS-ca68c287-2259-4276-b699-30366e1655ce,DISK], DatanodeInfoWithStorage[127.0.0.1:34902,DS-e0a3b261-50a0-496e-8d07-d02d42ec3688,DISK], DatanodeInfoWithStorage[127.0.0.1:45581,DS-eff0f53a-16b7-4abb-be65-3558e6f75881,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1177152042-172.17.0.4-1598340805338:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37648,DS-14a660e2-1347-44f2-96eb-272b47b76696,DISK], DatanodeInfoWithStorage[127.0.0.1:44988,DS-1192cfc7-a2c1-4097-b7c7-8be35709de0b,DISK], DatanodeInfoWithStorage[127.0.0.1:38729,DS-0906751b-78b9-4eff-a186-47e46fdee0c1,DISK], DatanodeInfoWithStorage[127.0.0.1:41918,DS-1d8f6c99-ea05-499c-af1c-77b413565cb3,DISK], DatanodeInfoWithStorage[127.0.0.1:46658,DS-cff82f33-b90b-40a1-9e73-de144b7d884c,DISK], DatanodeInfoWithStorage[127.0.0.1:34987,DS-ca68c287-2259-4276-b699-30366e1655ce,DISK], DatanodeInfoWithStorage[127.0.0.1:34902,DS-e0a3b261-50a0-496e-8d07-d02d42ec3688,DISK], DatanodeInfoWithStorage[127.0.0.1:45581,DS-eff0f53a-16b7-4abb-be65-3558e6f75881,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-584756016-172.17.0.4-1598341279162:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45332,DS-34a86f87-befb-4d39-baab-d51e1444755a,DISK], DatanodeInfoWithStorage[127.0.0.1:44748,DS-d162aaf0-c188-45e2-b0ef-22c6012c62fe,DISK], DatanodeInfoWithStorage[127.0.0.1:45400,DS-77679dab-5309-47da-86a6-399b108b763e,DISK], DatanodeInfoWithStorage[127.0.0.1:43275,DS-c11fce16-bab3-41ad-b362-cc1e5747cd38,DISK], DatanodeInfoWithStorage[127.0.0.1:35720,DS-18bc956d-e474-44e9-bb5b-71c1c610f172,DISK], DatanodeInfoWithStorage[127.0.0.1:35108,DS-776744c3-5590-44c9-8d65-a4143fb34e52,DISK], DatanodeInfoWithStorage[127.0.0.1:44778,DS-81fdd449-2040-4d8e-aaf5-778f9dc6a395,DISK], DatanodeInfoWithStorage[127.0.0.1:43292,DS-fec5ca05-d020-4b70-8705-97663a2f57c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-584756016-172.17.0.4-1598341279162:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45332,DS-34a86f87-befb-4d39-baab-d51e1444755a,DISK], DatanodeInfoWithStorage[127.0.0.1:44748,DS-d162aaf0-c188-45e2-b0ef-22c6012c62fe,DISK], DatanodeInfoWithStorage[127.0.0.1:45400,DS-77679dab-5309-47da-86a6-399b108b763e,DISK], DatanodeInfoWithStorage[127.0.0.1:43275,DS-c11fce16-bab3-41ad-b362-cc1e5747cd38,DISK], DatanodeInfoWithStorage[127.0.0.1:35720,DS-18bc956d-e474-44e9-bb5b-71c1c610f172,DISK], DatanodeInfoWithStorage[127.0.0.1:35108,DS-776744c3-5590-44c9-8d65-a4143fb34e52,DISK], DatanodeInfoWithStorage[127.0.0.1:44778,DS-81fdd449-2040-4d8e-aaf5-778f9dc6a395,DISK], DatanodeInfoWithStorage[127.0.0.1:43292,DS-fec5ca05-d020-4b70-8705-97663a2f57c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1003948534-172.17.0.4-1598341909394:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41673,DS-cfa60a74-a1e0-4bf4-998b-ebe99f35ef6c,DISK], DatanodeInfoWithStorage[127.0.0.1:33036,DS-45e0f718-3928-49dc-a2b3-93f728994f21,DISK], DatanodeInfoWithStorage[127.0.0.1:33063,DS-1cf25c12-93e1-4467-9514-04fe348e6986,DISK], DatanodeInfoWithStorage[127.0.0.1:44932,DS-e7255d7a-828e-42e2-bef7-db98feabcac8,DISK], DatanodeInfoWithStorage[127.0.0.1:44778,DS-c5409a0d-07de-445d-867b-47ce65be24fd,DISK], DatanodeInfoWithStorage[127.0.0.1:38664,DS-673d9739-4de2-429a-bc72-e0e4bed28cbf,DISK], DatanodeInfoWithStorage[127.0.0.1:34603,DS-420f519b-b163-44bc-9c5c-8c6ac807b248,DISK], DatanodeInfoWithStorage[127.0.0.1:38300,DS-ec05a253-737a-4c84-b5f1-4c2ddb0f8cda,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1003948534-172.17.0.4-1598341909394:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41673,DS-cfa60a74-a1e0-4bf4-998b-ebe99f35ef6c,DISK], DatanodeInfoWithStorage[127.0.0.1:33036,DS-45e0f718-3928-49dc-a2b3-93f728994f21,DISK], DatanodeInfoWithStorage[127.0.0.1:33063,DS-1cf25c12-93e1-4467-9514-04fe348e6986,DISK], DatanodeInfoWithStorage[127.0.0.1:44932,DS-e7255d7a-828e-42e2-bef7-db98feabcac8,DISK], DatanodeInfoWithStorage[127.0.0.1:44778,DS-c5409a0d-07de-445d-867b-47ce65be24fd,DISK], DatanodeInfoWithStorage[127.0.0.1:38664,DS-673d9739-4de2-429a-bc72-e0e4bed28cbf,DISK], DatanodeInfoWithStorage[127.0.0.1:34603,DS-420f519b-b163-44bc-9c5c-8c6ac807b248,DISK], DatanodeInfoWithStorage[127.0.0.1:38300,DS-ec05a253-737a-4c84-b5f1-4c2ddb0f8cda,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: hadoop.caller.context.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1009747029-172.17.0.4-1598341945378:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34545,DS-c7a917c7-13ef-433d-8dfb-74179585584d,DISK], DatanodeInfoWithStorage[127.0.0.1:36028,DS-b84f0258-1ed6-4b0e-a0cd-9107dcfa059c,DISK], DatanodeInfoWithStorage[127.0.0.1:42374,DS-447f7576-18e5-4d76-a7ce-808e6e04822b,DISK], DatanodeInfoWithStorage[127.0.0.1:44486,DS-309aae7b-b155-415b-8c70-b1addb87071f,DISK], DatanodeInfoWithStorage[127.0.0.1:39816,DS-156947c2-fc9d-491c-9ccc-cb8e22e2bf32,DISK], DatanodeInfoWithStorage[127.0.0.1:34533,DS-e6fe5480-6f50-4cd3-87ef-97a2309e9df7,DISK], DatanodeInfoWithStorage[127.0.0.1:39363,DS-25ffedde-8615-4f28-aeef-b194202480f0,DISK], DatanodeInfoWithStorage[127.0.0.1:42208,DS-fce172c9-ae80-4ea9-8b27-6149ac5ab473,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1009747029-172.17.0.4-1598341945378:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34545,DS-c7a917c7-13ef-433d-8dfb-74179585584d,DISK], DatanodeInfoWithStorage[127.0.0.1:36028,DS-b84f0258-1ed6-4b0e-a0cd-9107dcfa059c,DISK], DatanodeInfoWithStorage[127.0.0.1:42374,DS-447f7576-18e5-4d76-a7ce-808e6e04822b,DISK], DatanodeInfoWithStorage[127.0.0.1:44486,DS-309aae7b-b155-415b-8c70-b1addb87071f,DISK], DatanodeInfoWithStorage[127.0.0.1:39816,DS-156947c2-fc9d-491c-9ccc-cb8e22e2bf32,DISK], DatanodeInfoWithStorage[127.0.0.1:34533,DS-e6fe5480-6f50-4cd3-87ef-97a2309e9df7,DISK], DatanodeInfoWithStorage[127.0.0.1:39363,DS-25ffedde-8615-4f28-aeef-b194202480f0,DISK], DatanodeInfoWithStorage[127.0.0.1:42208,DS-fce172c9-ae80-4ea9-8b27-6149ac5ab473,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.caller.context.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1054582217-172.17.0.4-1598342081214:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34781,DS-c9f22dd0-fcb1-4105-98af-40cdb6511d0e,DISK], DatanodeInfoWithStorage[127.0.0.1:33854,DS-9a7a28d1-4109-4a04-818f-64222b565921,DISK], DatanodeInfoWithStorage[127.0.0.1:43974,DS-7d79f9e1-4808-4624-91a6-a459c8c510da,DISK], DatanodeInfoWithStorage[127.0.0.1:39972,DS-8bd7181b-908e-45d2-a554-b355852f5c0f,DISK], DatanodeInfoWithStorage[127.0.0.1:34792,DS-8dba9c22-e6bb-418a-8780-6c7bacfbd45e,DISK], DatanodeInfoWithStorage[127.0.0.1:37698,DS-1017d5d1-e5a8-43d5-9e80-16910a83b6b3,DISK], DatanodeInfoWithStorage[127.0.0.1:45941,DS-a2d4baa0-619f-458c-81fc-a223a9e4edd9,DISK], DatanodeInfoWithStorage[127.0.0.1:33228,DS-82324f45-ecb1-4d52-b9c0-a75954261b7d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1054582217-172.17.0.4-1598342081214:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34781,DS-c9f22dd0-fcb1-4105-98af-40cdb6511d0e,DISK], DatanodeInfoWithStorage[127.0.0.1:33854,DS-9a7a28d1-4109-4a04-818f-64222b565921,DISK], DatanodeInfoWithStorage[127.0.0.1:43974,DS-7d79f9e1-4808-4624-91a6-a459c8c510da,DISK], DatanodeInfoWithStorage[127.0.0.1:39972,DS-8bd7181b-908e-45d2-a554-b355852f5c0f,DISK], DatanodeInfoWithStorage[127.0.0.1:34792,DS-8dba9c22-e6bb-418a-8780-6c7bacfbd45e,DISK], DatanodeInfoWithStorage[127.0.0.1:37698,DS-1017d5d1-e5a8-43d5-9e80-16910a83b6b3,DISK], DatanodeInfoWithStorage[127.0.0.1:45941,DS-a2d4baa0-619f-458c-81fc-a223a9e4edd9,DISK], DatanodeInfoWithStorage[127.0.0.1:33228,DS-82324f45-ecb1-4d52-b9c0-a75954261b7d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.caller.context.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2103900711-172.17.0.4-1598342388342:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36845,DS-7d63b0ca-4a09-4310-9a1a-742d03884b73,DISK], DatanodeInfoWithStorage[127.0.0.1:33780,DS-4a5623c2-9fa7-4a5a-adb4-2fbfbcbf2be5,DISK], DatanodeInfoWithStorage[127.0.0.1:38317,DS-8ca48330-dd83-402e-a95f-b31af07ddbe9,DISK], DatanodeInfoWithStorage[127.0.0.1:34465,DS-f35a016d-0d7e-40bc-9ed0-949fa203047d,DISK], DatanodeInfoWithStorage[127.0.0.1:37735,DS-247148ae-f62b-496b-93ca-3e1be3ffde0b,DISK], DatanodeInfoWithStorage[127.0.0.1:41283,DS-15e1b31f-df9c-4772-a4a8-196dd0745118,DISK], DatanodeInfoWithStorage[127.0.0.1:33321,DS-4a578950-3cd9-4d4c-99b1-5897ad294080,DISK], DatanodeInfoWithStorage[127.0.0.1:36855,DS-cbd81b49-43a9-4538-9206-f3759b768107,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2103900711-172.17.0.4-1598342388342:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36845,DS-7d63b0ca-4a09-4310-9a1a-742d03884b73,DISK], DatanodeInfoWithStorage[127.0.0.1:33780,DS-4a5623c2-9fa7-4a5a-adb4-2fbfbcbf2be5,DISK], DatanodeInfoWithStorage[127.0.0.1:38317,DS-8ca48330-dd83-402e-a95f-b31af07ddbe9,DISK], DatanodeInfoWithStorage[127.0.0.1:34465,DS-f35a016d-0d7e-40bc-9ed0-949fa203047d,DISK], DatanodeInfoWithStorage[127.0.0.1:37735,DS-247148ae-f62b-496b-93ca-3e1be3ffde0b,DISK], DatanodeInfoWithStorage[127.0.0.1:41283,DS-15e1b31f-df9c-4772-a4a8-196dd0745118,DISK], DatanodeInfoWithStorage[127.0.0.1:33321,DS-4a578950-3cd9-4d4c-99b1-5897ad294080,DISK], DatanodeInfoWithStorage[127.0.0.1:36855,DS-cbd81b49-43a9-4538-9206-f3759b768107,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1737906519-172.17.0.4-1598342676987:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38871,DS-15d6671d-5a92-49d7-999d-b774a537b5e2,DISK], DatanodeInfoWithStorage[127.0.0.1:39275,DS-d8dcc195-7206-42cf-92a9-51e9dc1eddee,DISK], DatanodeInfoWithStorage[127.0.0.1:40989,DS-a170fcd6-bbf8-4ab8-9b7f-d1f7b5e1d24f,DISK], DatanodeInfoWithStorage[127.0.0.1:36432,DS-dd702d9f-dbb2-4045-a907-6769f2975dd6,DISK], DatanodeInfoWithStorage[127.0.0.1:38415,DS-7ec003b7-cde5-4460-a056-678a53f22f29,DISK], DatanodeInfoWithStorage[127.0.0.1:45491,DS-ad78b7bc-a8ab-419f-9599-5ca9f3714352,DISK], DatanodeInfoWithStorage[127.0.0.1:41309,DS-0e73c1bd-0812-42c2-8437-667300502408,DISK], DatanodeInfoWithStorage[127.0.0.1:45805,DS-ddff8b4d-d0db-41d2-ba65-00d00ca15b0c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1737906519-172.17.0.4-1598342676987:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38871,DS-15d6671d-5a92-49d7-999d-b774a537b5e2,DISK], DatanodeInfoWithStorage[127.0.0.1:39275,DS-d8dcc195-7206-42cf-92a9-51e9dc1eddee,DISK], DatanodeInfoWithStorage[127.0.0.1:40989,DS-a170fcd6-bbf8-4ab8-9b7f-d1f7b5e1d24f,DISK], DatanodeInfoWithStorage[127.0.0.1:36432,DS-dd702d9f-dbb2-4045-a907-6769f2975dd6,DISK], DatanodeInfoWithStorage[127.0.0.1:38415,DS-7ec003b7-cde5-4460-a056-678a53f22f29,DISK], DatanodeInfoWithStorage[127.0.0.1:45491,DS-ad78b7bc-a8ab-419f-9599-5ca9f3714352,DISK], DatanodeInfoWithStorage[127.0.0.1:41309,DS-0e73c1bd-0812-42c2-8437-667300502408,DISK], DatanodeInfoWithStorage[127.0.0.1:45805,DS-ddff8b4d-d0db-41d2-ba65-00d00ca15b0c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.caller.context.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-718435951-172.17.0.4-1598342834197:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40935,DS-50d021a5-ff71-4972-b266-0833cd40ced6,DISK], DatanodeInfoWithStorage[127.0.0.1:33682,DS-6e94e908-30b5-4760-8104-25ce8d833c67,DISK], DatanodeInfoWithStorage[127.0.0.1:37741,DS-14fe0b1c-4155-43fd-94fd-b2ec0ec68a57,DISK], DatanodeInfoWithStorage[127.0.0.1:43820,DS-27e061d4-271f-4923-a917-55854490e30a,DISK], DatanodeInfoWithStorage[127.0.0.1:44431,DS-082ef6b6-36a9-4f1a-b976-7890a3e804cb,DISK], DatanodeInfoWithStorage[127.0.0.1:38138,DS-c7a136a5-54cb-47da-86d3-e74140149d3e,DISK], DatanodeInfoWithStorage[127.0.0.1:40757,DS-622b21cb-404b-48ae-939a-e4cdcdd7c556,DISK], DatanodeInfoWithStorage[127.0.0.1:43849,DS-dc84deee-93bd-4d54-aa7b-c833dbae8f00,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-718435951-172.17.0.4-1598342834197:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40935,DS-50d021a5-ff71-4972-b266-0833cd40ced6,DISK], DatanodeInfoWithStorage[127.0.0.1:33682,DS-6e94e908-30b5-4760-8104-25ce8d833c67,DISK], DatanodeInfoWithStorage[127.0.0.1:37741,DS-14fe0b1c-4155-43fd-94fd-b2ec0ec68a57,DISK], DatanodeInfoWithStorage[127.0.0.1:43820,DS-27e061d4-271f-4923-a917-55854490e30a,DISK], DatanodeInfoWithStorage[127.0.0.1:44431,DS-082ef6b6-36a9-4f1a-b976-7890a3e804cb,DISK], DatanodeInfoWithStorage[127.0.0.1:38138,DS-c7a136a5-54cb-47da-86d3-e74140149d3e,DISK], DatanodeInfoWithStorage[127.0.0.1:40757,DS-622b21cb-404b-48ae-939a-e4cdcdd7c556,DISK], DatanodeInfoWithStorage[127.0.0.1:43849,DS-dc84deee-93bd-4d54-aa7b-c833dbae8f00,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1351360283-172.17.0.4-1598342909480:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34398,DS-6e158782-e001-46ed-918b-f39d2870aed8,DISK], DatanodeInfoWithStorage[127.0.0.1:38881,DS-104b5693-70f9-45a9-ad5a-30c1edd393fd,DISK], DatanodeInfoWithStorage[127.0.0.1:44425,DS-9db7e8f2-ecc6-43ba-84f1-8f948982a43c,DISK], DatanodeInfoWithStorage[127.0.0.1:40598,DS-cc4b6d05-7460-45c4-89f7-f82cfbc34fb5,DISK], DatanodeInfoWithStorage[127.0.0.1:35281,DS-46c42d47-61cc-4324-b2f2-0ac25a5c177d,DISK], DatanodeInfoWithStorage[127.0.0.1:46040,DS-22437b48-7600-493e-a1a1-afa64a115014,DISK], DatanodeInfoWithStorage[127.0.0.1:36215,DS-9f0cc5b0-cc97-4893-ae5f-1bcc37523c81,DISK], DatanodeInfoWithStorage[127.0.0.1:44346,DS-d63e805d-1f86-4b74-bcd2-c1349477ac9f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1351360283-172.17.0.4-1598342909480:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34398,DS-6e158782-e001-46ed-918b-f39d2870aed8,DISK], DatanodeInfoWithStorage[127.0.0.1:38881,DS-104b5693-70f9-45a9-ad5a-30c1edd393fd,DISK], DatanodeInfoWithStorage[127.0.0.1:44425,DS-9db7e8f2-ecc6-43ba-84f1-8f948982a43c,DISK], DatanodeInfoWithStorage[127.0.0.1:40598,DS-cc4b6d05-7460-45c4-89f7-f82cfbc34fb5,DISK], DatanodeInfoWithStorage[127.0.0.1:35281,DS-46c42d47-61cc-4324-b2f2-0ac25a5c177d,DISK], DatanodeInfoWithStorage[127.0.0.1:46040,DS-22437b48-7600-493e-a1a1-afa64a115014,DISK], DatanodeInfoWithStorage[127.0.0.1:36215,DS-9f0cc5b0-cc97-4893-ae5f-1bcc37523c81,DISK], DatanodeInfoWithStorage[127.0.0.1:44346,DS-d63e805d-1f86-4b74-bcd2-c1349477ac9f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-283905940-172.17.0.4-1598343199276:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35582,DS-efb2768c-751a-4190-9b4f-baf33e80c5dd,DISK], DatanodeInfoWithStorage[127.0.0.1:44551,DS-0a6023fe-55a6-4d5c-bbba-f86bc8f2c198,DISK], DatanodeInfoWithStorage[127.0.0.1:41295,DS-374c8cf9-0c08-4719-a293-41c93e4f6332,DISK], DatanodeInfoWithStorage[127.0.0.1:37813,DS-d1e12c96-d2cd-4ec6-9313-f09084beb586,DISK], DatanodeInfoWithStorage[127.0.0.1:42617,DS-502ec54e-1e1d-45ef-b0e5-367de50b83eb,DISK], DatanodeInfoWithStorage[127.0.0.1:33735,DS-2b8f6a8a-9cc5-4b23-a51e-0678b3fa04e5,DISK], DatanodeInfoWithStorage[127.0.0.1:42307,DS-ec95a970-d624-4133-932e-6fd1cee51b0f,DISK], DatanodeInfoWithStorage[127.0.0.1:37255,DS-c744e640-a6b6-47ea-ac68-f51f3c570ee1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-283905940-172.17.0.4-1598343199276:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35582,DS-efb2768c-751a-4190-9b4f-baf33e80c5dd,DISK], DatanodeInfoWithStorage[127.0.0.1:44551,DS-0a6023fe-55a6-4d5c-bbba-f86bc8f2c198,DISK], DatanodeInfoWithStorage[127.0.0.1:41295,DS-374c8cf9-0c08-4719-a293-41c93e4f6332,DISK], DatanodeInfoWithStorage[127.0.0.1:37813,DS-d1e12c96-d2cd-4ec6-9313-f09084beb586,DISK], DatanodeInfoWithStorage[127.0.0.1:42617,DS-502ec54e-1e1d-45ef-b0e5-367de50b83eb,DISK], DatanodeInfoWithStorage[127.0.0.1:33735,DS-2b8f6a8a-9cc5-4b23-a51e-0678b3fa04e5,DISK], DatanodeInfoWithStorage[127.0.0.1:42307,DS-ec95a970-d624-4133-932e-6fd1cee51b0f,DISK], DatanodeInfoWithStorage[127.0.0.1:37255,DS-c744e640-a6b6-47ea-ac68-f51f3c570ee1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1064429250-172.17.0.4-1598343395055:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42285,DS-8799d650-a15e-40a7-b106-a06c1ea07b22,DISK], DatanodeInfoWithStorage[127.0.0.1:42330,DS-c1682eb3-ef5f-46d1-baa9-d6745a99ec80,DISK], DatanodeInfoWithStorage[127.0.0.1:32804,DS-b4101f9c-2f06-47e7-890c-2dc82e1d1520,DISK], DatanodeInfoWithStorage[127.0.0.1:39782,DS-160f69fb-6e09-4824-a172-fc3521ae944e,DISK], DatanodeInfoWithStorage[127.0.0.1:42603,DS-5598436b-fedd-4114-bcd2-d3fab8513922,DISK], DatanodeInfoWithStorage[127.0.0.1:34241,DS-1436c3ee-df77-43e1-828a-acc8ab244e00,DISK], DatanodeInfoWithStorage[127.0.0.1:35134,DS-082c5e9a-1b10-42d7-a4a5-3709173d5cc4,DISK], DatanodeInfoWithStorage[127.0.0.1:34249,DS-f7d4abc5-92ee-4ba8-91d1-bf843890e554,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1064429250-172.17.0.4-1598343395055:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42285,DS-8799d650-a15e-40a7-b106-a06c1ea07b22,DISK], DatanodeInfoWithStorage[127.0.0.1:42330,DS-c1682eb3-ef5f-46d1-baa9-d6745a99ec80,DISK], DatanodeInfoWithStorage[127.0.0.1:32804,DS-b4101f9c-2f06-47e7-890c-2dc82e1d1520,DISK], DatanodeInfoWithStorage[127.0.0.1:39782,DS-160f69fb-6e09-4824-a172-fc3521ae944e,DISK], DatanodeInfoWithStorage[127.0.0.1:42603,DS-5598436b-fedd-4114-bcd2-d3fab8513922,DISK], DatanodeInfoWithStorage[127.0.0.1:34241,DS-1436c3ee-df77-43e1-828a-acc8ab244e00,DISK], DatanodeInfoWithStorage[127.0.0.1:35134,DS-082c5e9a-1b10-42d7-a4a5-3709173d5cc4,DISK], DatanodeInfoWithStorage[127.0.0.1:34249,DS-f7d4abc5-92ee-4ba8-91d1-bf843890e554,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.caller.context.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-277121214-172.17.0.4-1598343451094:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37250,DS-0f0a7014-bead-417d-ac35-c91a24b77064,DISK], DatanodeInfoWithStorage[127.0.0.1:35587,DS-47803b7c-4d67-4735-b38d-ed3237c8ba63,DISK], DatanodeInfoWithStorage[127.0.0.1:45346,DS-5658153c-63ee-4862-a238-4a9e3d5f9548,DISK], DatanodeInfoWithStorage[127.0.0.1:42216,DS-f345533d-ee23-448d-bc8b-6c6336881ffd,DISK], DatanodeInfoWithStorage[127.0.0.1:43119,DS-008dd702-d3ad-470e-97dd-bb735aecc971,DISK], DatanodeInfoWithStorage[127.0.0.1:46045,DS-499fcf0c-a8cd-461d-9da9-64580690c0e6,DISK], DatanodeInfoWithStorage[127.0.0.1:35929,DS-f2c56fdc-8d2a-4ade-ba47-89cfd7ac829c,DISK], DatanodeInfoWithStorage[127.0.0.1:45344,DS-f66b000f-1ea3-4a43-94ec-225e69fb940e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-277121214-172.17.0.4-1598343451094:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37250,DS-0f0a7014-bead-417d-ac35-c91a24b77064,DISK], DatanodeInfoWithStorage[127.0.0.1:35587,DS-47803b7c-4d67-4735-b38d-ed3237c8ba63,DISK], DatanodeInfoWithStorage[127.0.0.1:45346,DS-5658153c-63ee-4862-a238-4a9e3d5f9548,DISK], DatanodeInfoWithStorage[127.0.0.1:42216,DS-f345533d-ee23-448d-bc8b-6c6336881ffd,DISK], DatanodeInfoWithStorage[127.0.0.1:43119,DS-008dd702-d3ad-470e-97dd-bb735aecc971,DISK], DatanodeInfoWithStorage[127.0.0.1:46045,DS-499fcf0c-a8cd-461d-9da9-64580690c0e6,DISK], DatanodeInfoWithStorage[127.0.0.1:35929,DS-f2c56fdc-8d2a-4ade-ba47-89cfd7ac829c,DISK], DatanodeInfoWithStorage[127.0.0.1:45344,DS-f66b000f-1ea3-4a43-94ec-225e69fb940e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-628105447-172.17.0.4-1598343628098:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33332,DS-18de6bb9-53e0-493f-aeda-e644f37343df,DISK], DatanodeInfoWithStorage[127.0.0.1:34223,DS-2d338ac1-9f4c-4a16-aa11-7e8c5ae9acd5,DISK], DatanodeInfoWithStorage[127.0.0.1:33289,DS-94a7552a-a990-4ccd-afef-42a84e96624d,DISK], DatanodeInfoWithStorage[127.0.0.1:36164,DS-4cdbfdc0-b145-4d23-9a79-272ce36bffdd,DISK], DatanodeInfoWithStorage[127.0.0.1:35440,DS-b0e8d91c-b3e7-4feb-8874-70ee3237eede,DISK], DatanodeInfoWithStorage[127.0.0.1:36399,DS-96eff394-34aa-42a8-a386-d68b7ae4769d,DISK], DatanodeInfoWithStorage[127.0.0.1:35264,DS-7089edf7-dfea-4123-be8c-7658059c2f01,DISK], DatanodeInfoWithStorage[127.0.0.1:38870,DS-0885e30c-1488-414e-b62a-364a67b27efd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-628105447-172.17.0.4-1598343628098:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33332,DS-18de6bb9-53e0-493f-aeda-e644f37343df,DISK], DatanodeInfoWithStorage[127.0.0.1:34223,DS-2d338ac1-9f4c-4a16-aa11-7e8c5ae9acd5,DISK], DatanodeInfoWithStorage[127.0.0.1:33289,DS-94a7552a-a990-4ccd-afef-42a84e96624d,DISK], DatanodeInfoWithStorage[127.0.0.1:36164,DS-4cdbfdc0-b145-4d23-9a79-272ce36bffdd,DISK], DatanodeInfoWithStorage[127.0.0.1:35440,DS-b0e8d91c-b3e7-4feb-8874-70ee3237eede,DISK], DatanodeInfoWithStorage[127.0.0.1:36399,DS-96eff394-34aa-42a8-a386-d68b7ae4769d,DISK], DatanodeInfoWithStorage[127.0.0.1:35264,DS-7089edf7-dfea-4123-be8c-7658059c2f01,DISK], DatanodeInfoWithStorage[127.0.0.1:38870,DS-0885e30c-1488-414e-b62a-364a67b27efd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.caller.context.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1104154960-172.17.0.4-1598344081968:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45785,DS-c74850a5-382f-4fa5-a7c7-b028162f87b5,DISK], DatanodeInfoWithStorage[127.0.0.1:46011,DS-caec9a9e-4597-47ab-8f41-6f8f4f03ac08,DISK], DatanodeInfoWithStorage[127.0.0.1:38073,DS-d5942a32-5672-407b-9c7e-22f6a95465da,DISK], DatanodeInfoWithStorage[127.0.0.1:44026,DS-409caaae-5c8b-40b0-9878-5817421564e7,DISK], DatanodeInfoWithStorage[127.0.0.1:36498,DS-903a0cbe-e5b5-447b-9323-87877f3b7f3c,DISK], DatanodeInfoWithStorage[127.0.0.1:44617,DS-b93ac299-3224-4961-a439-f89b4ff78d3e,DISK], DatanodeInfoWithStorage[127.0.0.1:36664,DS-d4eca5f3-6ebb-43ce-9cde-768ddf822df5,DISK], DatanodeInfoWithStorage[127.0.0.1:38799,DS-452cf2a5-5a63-4d62-8437-f9f70651aac9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1104154960-172.17.0.4-1598344081968:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45785,DS-c74850a5-382f-4fa5-a7c7-b028162f87b5,DISK], DatanodeInfoWithStorage[127.0.0.1:46011,DS-caec9a9e-4597-47ab-8f41-6f8f4f03ac08,DISK], DatanodeInfoWithStorage[127.0.0.1:38073,DS-d5942a32-5672-407b-9c7e-22f6a95465da,DISK], DatanodeInfoWithStorage[127.0.0.1:44026,DS-409caaae-5c8b-40b0-9878-5817421564e7,DISK], DatanodeInfoWithStorage[127.0.0.1:36498,DS-903a0cbe-e5b5-447b-9323-87877f3b7f3c,DISK], DatanodeInfoWithStorage[127.0.0.1:44617,DS-b93ac299-3224-4961-a439-f89b4ff78d3e,DISK], DatanodeInfoWithStorage[127.0.0.1:36664,DS-d4eca5f3-6ebb-43ce-9cde-768ddf822df5,DISK], DatanodeInfoWithStorage[127.0.0.1:38799,DS-452cf2a5-5a63-4d62-8437-f9f70651aac9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-475775335-172.17.0.4-1598344461888:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38030,DS-2b2b5dbd-8040-4504-9d1a-ddf737f34f36,DISK], DatanodeInfoWithStorage[127.0.0.1:42947,DS-67b10931-635f-4305-8f20-f6ef2ae70e15,DISK], DatanodeInfoWithStorage[127.0.0.1:42721,DS-b072c9cf-2a00-411d-885b-eb30ad74e633,DISK], DatanodeInfoWithStorage[127.0.0.1:44678,DS-4321af46-c4b2-48d3-be21-8574f6a0ee75,DISK], DatanodeInfoWithStorage[127.0.0.1:45918,DS-b9e2aec5-dace-4a5b-82ec-d48584f6682c,DISK], DatanodeInfoWithStorage[127.0.0.1:42476,DS-f5b118bc-23cd-49d5-9b6d-1beef99c22e3,DISK], DatanodeInfoWithStorage[127.0.0.1:45249,DS-ffc912e2-e4da-4483-b021-763231ba9073,DISK], DatanodeInfoWithStorage[127.0.0.1:43448,DS-6e15d1d9-a35f-40ef-9115-0d910e43ae29,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-475775335-172.17.0.4-1598344461888:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38030,DS-2b2b5dbd-8040-4504-9d1a-ddf737f34f36,DISK], DatanodeInfoWithStorage[127.0.0.1:42947,DS-67b10931-635f-4305-8f20-f6ef2ae70e15,DISK], DatanodeInfoWithStorage[127.0.0.1:42721,DS-b072c9cf-2a00-411d-885b-eb30ad74e633,DISK], DatanodeInfoWithStorage[127.0.0.1:44678,DS-4321af46-c4b2-48d3-be21-8574f6a0ee75,DISK], DatanodeInfoWithStorage[127.0.0.1:45918,DS-b9e2aec5-dace-4a5b-82ec-d48584f6682c,DISK], DatanodeInfoWithStorage[127.0.0.1:42476,DS-f5b118bc-23cd-49d5-9b6d-1beef99c22e3,DISK], DatanodeInfoWithStorage[127.0.0.1:45249,DS-ffc912e2-e4da-4483-b021-763231ba9073,DISK], DatanodeInfoWithStorage[127.0.0.1:43448,DS-6e15d1d9-a35f-40ef-9115-0d910e43ae29,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.caller.context.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-472803717-172.17.0.4-1598344899743:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40454,DS-365ff69a-274c-4d71-bacf-f1f8838b063e,DISK], DatanodeInfoWithStorage[127.0.0.1:41383,DS-31a9f160-3c21-4d59-bcc6-e68fad869e64,DISK], DatanodeInfoWithStorage[127.0.0.1:45369,DS-502bccf4-6d38-4177-bcd0-c0a7bdda7567,DISK], DatanodeInfoWithStorage[127.0.0.1:38047,DS-28e941b2-1042-4d16-a44a-ff85c57fbf51,DISK], DatanodeInfoWithStorage[127.0.0.1:46108,DS-67daec1d-2bf3-41b0-8dfd-0b891f52b600,DISK], DatanodeInfoWithStorage[127.0.0.1:42490,DS-b3062fdf-c4b1-4489-b43d-55935a55e950,DISK], DatanodeInfoWithStorage[127.0.0.1:40669,DS-d5774795-5072-4fa7-b9e7-a674e5c32297,DISK], DatanodeInfoWithStorage[127.0.0.1:35189,DS-b57ada18-266e-40a2-b991-44c7eee2b0ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-472803717-172.17.0.4-1598344899743:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40454,DS-365ff69a-274c-4d71-bacf-f1f8838b063e,DISK], DatanodeInfoWithStorage[127.0.0.1:41383,DS-31a9f160-3c21-4d59-bcc6-e68fad869e64,DISK], DatanodeInfoWithStorage[127.0.0.1:45369,DS-502bccf4-6d38-4177-bcd0-c0a7bdda7567,DISK], DatanodeInfoWithStorage[127.0.0.1:38047,DS-28e941b2-1042-4d16-a44a-ff85c57fbf51,DISK], DatanodeInfoWithStorage[127.0.0.1:46108,DS-67daec1d-2bf3-41b0-8dfd-0b891f52b600,DISK], DatanodeInfoWithStorage[127.0.0.1:42490,DS-b3062fdf-c4b1-4489-b43d-55935a55e950,DISK], DatanodeInfoWithStorage[127.0.0.1:40669,DS-d5774795-5072-4fa7-b9e7-a674e5c32297,DISK], DatanodeInfoWithStorage[127.0.0.1:35189,DS-b57ada18-266e-40a2-b991-44c7eee2b0ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-709233010-172.17.0.4-1598344957766:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32936,DS-1947fcc0-4023-458b-b36e-72a918895487,DISK], DatanodeInfoWithStorage[127.0.0.1:37365,DS-ee04bed6-d36f-4f2e-b4ce-89971f7d00fb,DISK], DatanodeInfoWithStorage[127.0.0.1:33629,DS-ccb26ad3-1ec1-496d-a120-cc43bb81d42b,DISK], DatanodeInfoWithStorage[127.0.0.1:46091,DS-331de8c3-b5b7-4421-876c-6f4b18df40bc,DISK], DatanodeInfoWithStorage[127.0.0.1:38724,DS-a7f16742-611e-4dbe-a939-616d0b1a8867,DISK], DatanodeInfoWithStorage[127.0.0.1:37058,DS-b6a3c14c-233b-4415-a91f-b337d32be447,DISK], DatanodeInfoWithStorage[127.0.0.1:45828,DS-8a5553ea-f274-4da9-87c5-1394d0b2a8a7,DISK], DatanodeInfoWithStorage[127.0.0.1:34100,DS-e3575f57-bdb6-4849-b6ec-fd772b0e6061,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-709233010-172.17.0.4-1598344957766:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32936,DS-1947fcc0-4023-458b-b36e-72a918895487,DISK], DatanodeInfoWithStorage[127.0.0.1:37365,DS-ee04bed6-d36f-4f2e-b4ce-89971f7d00fb,DISK], DatanodeInfoWithStorage[127.0.0.1:33629,DS-ccb26ad3-1ec1-496d-a120-cc43bb81d42b,DISK], DatanodeInfoWithStorage[127.0.0.1:46091,DS-331de8c3-b5b7-4421-876c-6f4b18df40bc,DISK], DatanodeInfoWithStorage[127.0.0.1:38724,DS-a7f16742-611e-4dbe-a939-616d0b1a8867,DISK], DatanodeInfoWithStorage[127.0.0.1:37058,DS-b6a3c14c-233b-4415-a91f-b337d32be447,DISK], DatanodeInfoWithStorage[127.0.0.1:45828,DS-8a5553ea-f274-4da9-87c5-1394d0b2a8a7,DISK], DatanodeInfoWithStorage[127.0.0.1:34100,DS-e3575f57-bdb6-4849-b6ec-fd772b0e6061,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-66893106-172.17.0.4-1598345129411:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36132,DS-c33a491a-a729-4e52-b3bd-8e9375b710e0,DISK], DatanodeInfoWithStorage[127.0.0.1:36798,DS-c54ebeac-1def-4cea-b73f-89edd7c51b52,DISK], DatanodeInfoWithStorage[127.0.0.1:35585,DS-697615c0-109e-4230-9db9-9509fa4ea8b1,DISK], DatanodeInfoWithStorage[127.0.0.1:39567,DS-a0a64d71-a72e-413c-8f4d-e59be93f3403,DISK], DatanodeInfoWithStorage[127.0.0.1:36107,DS-5d456a4e-f4a7-43e4-8823-ae9e5744ea59,DISK], DatanodeInfoWithStorage[127.0.0.1:39315,DS-c47b843a-f757-45e2-8cc8-8cac8e69daa5,DISK], DatanodeInfoWithStorage[127.0.0.1:44983,DS-6133b0d4-652a-4337-8656-d3e88042bb1a,DISK], DatanodeInfoWithStorage[127.0.0.1:41691,DS-cbc4f3ab-09e9-48ba-ab3a-b8f58ed1551d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-66893106-172.17.0.4-1598345129411:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36132,DS-c33a491a-a729-4e52-b3bd-8e9375b710e0,DISK], DatanodeInfoWithStorage[127.0.0.1:36798,DS-c54ebeac-1def-4cea-b73f-89edd7c51b52,DISK], DatanodeInfoWithStorage[127.0.0.1:35585,DS-697615c0-109e-4230-9db9-9509fa4ea8b1,DISK], DatanodeInfoWithStorage[127.0.0.1:39567,DS-a0a64d71-a72e-413c-8f4d-e59be93f3403,DISK], DatanodeInfoWithStorage[127.0.0.1:36107,DS-5d456a4e-f4a7-43e4-8823-ae9e5744ea59,DISK], DatanodeInfoWithStorage[127.0.0.1:39315,DS-c47b843a-f757-45e2-8cc8-8cac8e69daa5,DISK], DatanodeInfoWithStorage[127.0.0.1:44983,DS-6133b0d4-652a-4337-8656-d3e88042bb1a,DISK], DatanodeInfoWithStorage[127.0.0.1:41691,DS-cbc4f3ab-09e9-48ba-ab3a-b8f58ed1551d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5293
