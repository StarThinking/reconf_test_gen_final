reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-930830784-172.17.0.20-1598192546826:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40354,DS-69f1d968-d06d-4240-9576-dbc9170f0085,DISK], DatanodeInfoWithStorage[127.0.0.1:43561,DS-3ea6515e-b17e-4fb4-9781-1367d206711d,DISK], DatanodeInfoWithStorage[127.0.0.1:40818,DS-e9b98dcf-d699-4b35-b315-ae51c81f0eb7,DISK], DatanodeInfoWithStorage[127.0.0.1:41684,DS-8da29f8b-7061-4eec-bc71-2d1230def9ed,DISK], DatanodeInfoWithStorage[127.0.0.1:38105,DS-2e2ead00-e474-4507-a56e-3d1cf634743b,DISK], DatanodeInfoWithStorage[127.0.0.1:44666,DS-42dd10b5-1b37-4238-b6b9-7bbba5e0cf56,DISK], DatanodeInfoWithStorage[127.0.0.1:39303,DS-72ae82c2-2c44-42a3-9620-194b061f259b,DISK], DatanodeInfoWithStorage[127.0.0.1:36242,DS-6f63e634-062b-457c-b937-8f5acbf2b483,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-930830784-172.17.0.20-1598192546826:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40354,DS-69f1d968-d06d-4240-9576-dbc9170f0085,DISK], DatanodeInfoWithStorage[127.0.0.1:43561,DS-3ea6515e-b17e-4fb4-9781-1367d206711d,DISK], DatanodeInfoWithStorage[127.0.0.1:40818,DS-e9b98dcf-d699-4b35-b315-ae51c81f0eb7,DISK], DatanodeInfoWithStorage[127.0.0.1:41684,DS-8da29f8b-7061-4eec-bc71-2d1230def9ed,DISK], DatanodeInfoWithStorage[127.0.0.1:38105,DS-2e2ead00-e474-4507-a56e-3d1cf634743b,DISK], DatanodeInfoWithStorage[127.0.0.1:44666,DS-42dd10b5-1b37-4238-b6b9-7bbba5e0cf56,DISK], DatanodeInfoWithStorage[127.0.0.1:39303,DS-72ae82c2-2c44-42a3-9620-194b061f259b,DISK], DatanodeInfoWithStorage[127.0.0.1:36242,DS-6f63e634-062b-457c-b937-8f5acbf2b483,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1936354597-172.17.0.20-1598192754597:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35418,DS-e441007c-3647-4447-b22d-0350d0cea233,DISK], DatanodeInfoWithStorage[127.0.0.1:41641,DS-e6335130-fc64-41eb-99e7-7faf8b38ff36,DISK], DatanodeInfoWithStorage[127.0.0.1:40478,DS-e3bb248b-c1b7-4be7-a675-acda325f1dc5,DISK], DatanodeInfoWithStorage[127.0.0.1:46607,DS-fdb7eeb3-6667-4940-8a2f-4c2bbba59d12,DISK], DatanodeInfoWithStorage[127.0.0.1:43949,DS-e1a2a81d-de6b-41f5-b062-286716d516c4,DISK], DatanodeInfoWithStorage[127.0.0.1:33024,DS-ea749e55-d7c2-401f-826b-340b804611c1,DISK], DatanodeInfoWithStorage[127.0.0.1:34571,DS-457c55ea-4090-40d6-bc50-ee28fb5d4158,DISK], DatanodeInfoWithStorage[127.0.0.1:46013,DS-c110ddc6-f02a-4f52-9cf4-46ab7bfdd49f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1936354597-172.17.0.20-1598192754597:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35418,DS-e441007c-3647-4447-b22d-0350d0cea233,DISK], DatanodeInfoWithStorage[127.0.0.1:41641,DS-e6335130-fc64-41eb-99e7-7faf8b38ff36,DISK], DatanodeInfoWithStorage[127.0.0.1:40478,DS-e3bb248b-c1b7-4be7-a675-acda325f1dc5,DISK], DatanodeInfoWithStorage[127.0.0.1:46607,DS-fdb7eeb3-6667-4940-8a2f-4c2bbba59d12,DISK], DatanodeInfoWithStorage[127.0.0.1:43949,DS-e1a2a81d-de6b-41f5-b062-286716d516c4,DISK], DatanodeInfoWithStorage[127.0.0.1:33024,DS-ea749e55-d7c2-401f-826b-340b804611c1,DISK], DatanodeInfoWithStorage[127.0.0.1:34571,DS-457c55ea-4090-40d6-bc50-ee28fb5d4158,DISK], DatanodeInfoWithStorage[127.0.0.1:46013,DS-c110ddc6-f02a-4f52-9cf4-46ab7bfdd49f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-169829427-172.17.0.20-1598193445451:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35089,DS-3bc60c64-9511-4865-b401-9b8b48031bb5,DISK], DatanodeInfoWithStorage[127.0.0.1:34945,DS-e4cb7cf9-1147-427b-b65b-aca86eb3177e,DISK], DatanodeInfoWithStorage[127.0.0.1:44693,DS-c4e5ab66-1431-44e2-b705-0b7060bbf720,DISK], DatanodeInfoWithStorage[127.0.0.1:40869,DS-9fd897c2-c87f-46e6-8517-b25bca073d61,DISK], DatanodeInfoWithStorage[127.0.0.1:37295,DS-5fd29eea-22b4-4517-8479-7dba8410f394,DISK], DatanodeInfoWithStorage[127.0.0.1:33755,DS-eaf494c7-7741-4165-b324-f47443494761,DISK], DatanodeInfoWithStorage[127.0.0.1:36889,DS-ba19018e-6f87-4b5d-8e3b-1f7735a7ff8f,DISK], DatanodeInfoWithStorage[127.0.0.1:40046,DS-4dd63815-3c90-473c-9146-07d5be71a302,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-169829427-172.17.0.20-1598193445451:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35089,DS-3bc60c64-9511-4865-b401-9b8b48031bb5,DISK], DatanodeInfoWithStorage[127.0.0.1:34945,DS-e4cb7cf9-1147-427b-b65b-aca86eb3177e,DISK], DatanodeInfoWithStorage[127.0.0.1:44693,DS-c4e5ab66-1431-44e2-b705-0b7060bbf720,DISK], DatanodeInfoWithStorage[127.0.0.1:40869,DS-9fd897c2-c87f-46e6-8517-b25bca073d61,DISK], DatanodeInfoWithStorage[127.0.0.1:37295,DS-5fd29eea-22b4-4517-8479-7dba8410f394,DISK], DatanodeInfoWithStorage[127.0.0.1:33755,DS-eaf494c7-7741-4165-b324-f47443494761,DISK], DatanodeInfoWithStorage[127.0.0.1:36889,DS-ba19018e-6f87-4b5d-8e3b-1f7735a7ff8f,DISK], DatanodeInfoWithStorage[127.0.0.1:40046,DS-4dd63815-3c90-473c-9146-07d5be71a302,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2021334850-172.17.0.20-1598194149005:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39522,DS-2bbccb79-912b-4869-9a2a-bd0c1d2dc862,DISK], DatanodeInfoWithStorage[127.0.0.1:44509,DS-7273bcfb-9854-457a-a324-3a5ce7993bce,DISK], DatanodeInfoWithStorage[127.0.0.1:33068,DS-4b5513d7-ae07-4da6-ad85-9ea817f01b04,DISK], DatanodeInfoWithStorage[127.0.0.1:37963,DS-47f3af4b-6b21-40ce-a190-dc4110c2852d,DISK], DatanodeInfoWithStorage[127.0.0.1:42299,DS-8f242aad-01c9-4bc1-8ef5-b73b74b4fe75,DISK], DatanodeInfoWithStorage[127.0.0.1:40039,DS-96128888-eb8c-4329-b91e-399177f1dcfd,DISK], DatanodeInfoWithStorage[127.0.0.1:42409,DS-53a10388-909c-44e7-bf54-a59b6fd47c32,DISK], DatanodeInfoWithStorage[127.0.0.1:37932,DS-81c8dac1-60ad-4e75-b780-8ef5422b1fab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2021334850-172.17.0.20-1598194149005:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39522,DS-2bbccb79-912b-4869-9a2a-bd0c1d2dc862,DISK], DatanodeInfoWithStorage[127.0.0.1:44509,DS-7273bcfb-9854-457a-a324-3a5ce7993bce,DISK], DatanodeInfoWithStorage[127.0.0.1:33068,DS-4b5513d7-ae07-4da6-ad85-9ea817f01b04,DISK], DatanodeInfoWithStorage[127.0.0.1:37963,DS-47f3af4b-6b21-40ce-a190-dc4110c2852d,DISK], DatanodeInfoWithStorage[127.0.0.1:42299,DS-8f242aad-01c9-4bc1-8ef5-b73b74b4fe75,DISK], DatanodeInfoWithStorage[127.0.0.1:40039,DS-96128888-eb8c-4329-b91e-399177f1dcfd,DISK], DatanodeInfoWithStorage[127.0.0.1:42409,DS-53a10388-909c-44e7-bf54-a59b6fd47c32,DISK], DatanodeInfoWithStorage[127.0.0.1:37932,DS-81c8dac1-60ad-4e75-b780-8ef5422b1fab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-880199419-172.17.0.20-1598194856605:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38785,DS-d47e73c3-48c8-4b79-8523-62efc3e2e553,DISK], DatanodeInfoWithStorage[127.0.0.1:34821,DS-5f75c6b8-10e8-4dfc-b2f6-9d7716d52ff9,DISK], DatanodeInfoWithStorage[127.0.0.1:37684,DS-154eb65d-7714-45b6-8a51-2deeeb2d22c4,DISK], DatanodeInfoWithStorage[127.0.0.1:39176,DS-075fda74-e806-45e7-8868-3872ec636fc6,DISK], DatanodeInfoWithStorage[127.0.0.1:34304,DS-53e6684d-7abb-4f2a-939a-b8c0aa23fd3a,DISK], DatanodeInfoWithStorage[127.0.0.1:43386,DS-45c06636-d054-43df-aced-7d31f332d808,DISK], DatanodeInfoWithStorage[127.0.0.1:45289,DS-96f667ee-9d7c-46e3-85a7-f2fe73ce94da,DISK], DatanodeInfoWithStorage[127.0.0.1:40959,DS-eb03600f-e293-47ce-8ef2-7eb080b87ca9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-880199419-172.17.0.20-1598194856605:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38785,DS-d47e73c3-48c8-4b79-8523-62efc3e2e553,DISK], DatanodeInfoWithStorage[127.0.0.1:34821,DS-5f75c6b8-10e8-4dfc-b2f6-9d7716d52ff9,DISK], DatanodeInfoWithStorage[127.0.0.1:37684,DS-154eb65d-7714-45b6-8a51-2deeeb2d22c4,DISK], DatanodeInfoWithStorage[127.0.0.1:39176,DS-075fda74-e806-45e7-8868-3872ec636fc6,DISK], DatanodeInfoWithStorage[127.0.0.1:34304,DS-53e6684d-7abb-4f2a-939a-b8c0aa23fd3a,DISK], DatanodeInfoWithStorage[127.0.0.1:43386,DS-45c06636-d054-43df-aced-7d31f332d808,DISK], DatanodeInfoWithStorage[127.0.0.1:45289,DS-96f667ee-9d7c-46e3-85a7-f2fe73ce94da,DISK], DatanodeInfoWithStorage[127.0.0.1:40959,DS-eb03600f-e293-47ce-8ef2-7eb080b87ca9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-332017112-172.17.0.20-1598194961519:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41283,DS-f6d64d4a-2ad5-4144-8d8c-abac8a733d0a,DISK], DatanodeInfoWithStorage[127.0.0.1:46727,DS-161b1947-a100-47ac-82a6-dfafbe646cc6,DISK], DatanodeInfoWithStorage[127.0.0.1:33385,DS-cccb5f20-8fbf-4e4e-9914-5e726f56403c,DISK], DatanodeInfoWithStorage[127.0.0.1:37901,DS-abf7d08a-c8db-4749-98d7-f15396f91471,DISK], DatanodeInfoWithStorage[127.0.0.1:44198,DS-71e06b17-d867-43bd-b834-5ba064642a7f,DISK], DatanodeInfoWithStorage[127.0.0.1:35192,DS-71bd792d-1195-4205-aaf2-88aea4c569d3,DISK], DatanodeInfoWithStorage[127.0.0.1:43222,DS-f5149d8e-4092-40bc-8de9-eab20846b99c,DISK], DatanodeInfoWithStorage[127.0.0.1:44136,DS-e74b7466-c526-469d-bc7c-21b534092dd4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-332017112-172.17.0.20-1598194961519:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41283,DS-f6d64d4a-2ad5-4144-8d8c-abac8a733d0a,DISK], DatanodeInfoWithStorage[127.0.0.1:46727,DS-161b1947-a100-47ac-82a6-dfafbe646cc6,DISK], DatanodeInfoWithStorage[127.0.0.1:33385,DS-cccb5f20-8fbf-4e4e-9914-5e726f56403c,DISK], DatanodeInfoWithStorage[127.0.0.1:37901,DS-abf7d08a-c8db-4749-98d7-f15396f91471,DISK], DatanodeInfoWithStorage[127.0.0.1:44198,DS-71e06b17-d867-43bd-b834-5ba064642a7f,DISK], DatanodeInfoWithStorage[127.0.0.1:35192,DS-71bd792d-1195-4205-aaf2-88aea4c569d3,DISK], DatanodeInfoWithStorage[127.0.0.1:43222,DS-f5149d8e-4092-40bc-8de9-eab20846b99c,DISK], DatanodeInfoWithStorage[127.0.0.1:44136,DS-e74b7466-c526-469d-bc7c-21b534092dd4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1655909210-172.17.0.20-1598194998924:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39741,DS-21937bd4-5c88-4c64-960e-b950f4b0ff92,DISK], DatanodeInfoWithStorage[127.0.0.1:32817,DS-f94b9f5f-e488-4df7-9610-1f52732e1316,DISK], DatanodeInfoWithStorage[127.0.0.1:46581,DS-df252443-0d0b-4b4f-a7c7-18671113f905,DISK], DatanodeInfoWithStorage[127.0.0.1:38548,DS-de77c0b1-b459-45b4-bb4c-564c32b79bdb,DISK], DatanodeInfoWithStorage[127.0.0.1:33934,DS-60b90c69-fe1e-43ee-af6b-199b6dc27ad8,DISK], DatanodeInfoWithStorage[127.0.0.1:41841,DS-0fe404ca-4a8b-4130-b077-80e69d3d1e69,DISK], DatanodeInfoWithStorage[127.0.0.1:33479,DS-72a11956-9c49-4ccc-bf5c-ba138ed3c473,DISK], DatanodeInfoWithStorage[127.0.0.1:34618,DS-32b9b5dc-b88e-4635-b086-1157a75d25e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1655909210-172.17.0.20-1598194998924:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39741,DS-21937bd4-5c88-4c64-960e-b950f4b0ff92,DISK], DatanodeInfoWithStorage[127.0.0.1:32817,DS-f94b9f5f-e488-4df7-9610-1f52732e1316,DISK], DatanodeInfoWithStorage[127.0.0.1:46581,DS-df252443-0d0b-4b4f-a7c7-18671113f905,DISK], DatanodeInfoWithStorage[127.0.0.1:38548,DS-de77c0b1-b459-45b4-bb4c-564c32b79bdb,DISK], DatanodeInfoWithStorage[127.0.0.1:33934,DS-60b90c69-fe1e-43ee-af6b-199b6dc27ad8,DISK], DatanodeInfoWithStorage[127.0.0.1:41841,DS-0fe404ca-4a8b-4130-b077-80e69d3d1e69,DISK], DatanodeInfoWithStorage[127.0.0.1:33479,DS-72a11956-9c49-4ccc-bf5c-ba138ed3c473,DISK], DatanodeInfoWithStorage[127.0.0.1:34618,DS-32b9b5dc-b88e-4635-b086-1157a75d25e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2142925864-172.17.0.20-1598195714160:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35072,DS-90ab0eba-86b8-4f72-bde2-d126b09ea94c,DISK], DatanodeInfoWithStorage[127.0.0.1:41300,DS-d86573da-c82b-48b5-8763-8357a74b2b03,DISK], DatanodeInfoWithStorage[127.0.0.1:41445,DS-c60edb60-b823-4606-9a2d-b2c6525aa0ad,DISK], DatanodeInfoWithStorage[127.0.0.1:35550,DS-3def7690-1233-4534-8bed-9dc4ecd4e0ee,DISK], DatanodeInfoWithStorage[127.0.0.1:35007,DS-05ccc935-b0d3-4345-8308-300f1810b06b,DISK], DatanodeInfoWithStorage[127.0.0.1:36046,DS-2af0d7ee-5659-44e5-8d0e-fde07ebf3ead,DISK], DatanodeInfoWithStorage[127.0.0.1:41230,DS-e57fffd5-9561-42cf-ba02-fa2337cd2aa0,DISK], DatanodeInfoWithStorage[127.0.0.1:37680,DS-584d9b23-17a8-4141-9bdd-e8b7d9b845a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2142925864-172.17.0.20-1598195714160:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35072,DS-90ab0eba-86b8-4f72-bde2-d126b09ea94c,DISK], DatanodeInfoWithStorage[127.0.0.1:41300,DS-d86573da-c82b-48b5-8763-8357a74b2b03,DISK], DatanodeInfoWithStorage[127.0.0.1:41445,DS-c60edb60-b823-4606-9a2d-b2c6525aa0ad,DISK], DatanodeInfoWithStorage[127.0.0.1:35550,DS-3def7690-1233-4534-8bed-9dc4ecd4e0ee,DISK], DatanodeInfoWithStorage[127.0.0.1:35007,DS-05ccc935-b0d3-4345-8308-300f1810b06b,DISK], DatanodeInfoWithStorage[127.0.0.1:36046,DS-2af0d7ee-5659-44e5-8d0e-fde07ebf3ead,DISK], DatanodeInfoWithStorage[127.0.0.1:41230,DS-e57fffd5-9561-42cf-ba02-fa2337cd2aa0,DISK], DatanodeInfoWithStorage[127.0.0.1:37680,DS-584d9b23-17a8-4141-9bdd-e8b7d9b845a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-747363229-172.17.0.20-1598196126431:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35571,DS-985eee79-7e63-4579-a4b0-d3a5d7d08283,DISK], DatanodeInfoWithStorage[127.0.0.1:35503,DS-0d91a258-a4a9-4323-be58-7eb7e6fdf4d4,DISK], DatanodeInfoWithStorage[127.0.0.1:36530,DS-916ce8e6-23ba-4834-86cb-df96fc063d83,DISK], DatanodeInfoWithStorage[127.0.0.1:34128,DS-09583f09-d88c-4fab-b974-f8fa2c653f74,DISK], DatanodeInfoWithStorage[127.0.0.1:46291,DS-5fe2b8ab-3041-4d6c-9f60-2d03efb473d1,DISK], DatanodeInfoWithStorage[127.0.0.1:43092,DS-a7827f29-ec32-4731-b588-807fdcf6ba9e,DISK], DatanodeInfoWithStorage[127.0.0.1:42591,DS-6cfe6762-c7d6-4e8b-8451-55497696ef76,DISK], DatanodeInfoWithStorage[127.0.0.1:42753,DS-6eefcbc8-06b5-4375-9cb8-563c070c893b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-747363229-172.17.0.20-1598196126431:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35571,DS-985eee79-7e63-4579-a4b0-d3a5d7d08283,DISK], DatanodeInfoWithStorage[127.0.0.1:35503,DS-0d91a258-a4a9-4323-be58-7eb7e6fdf4d4,DISK], DatanodeInfoWithStorage[127.0.0.1:36530,DS-916ce8e6-23ba-4834-86cb-df96fc063d83,DISK], DatanodeInfoWithStorage[127.0.0.1:34128,DS-09583f09-d88c-4fab-b974-f8fa2c653f74,DISK], DatanodeInfoWithStorage[127.0.0.1:46291,DS-5fe2b8ab-3041-4d6c-9f60-2d03efb473d1,DISK], DatanodeInfoWithStorage[127.0.0.1:43092,DS-a7827f29-ec32-4731-b588-807fdcf6ba9e,DISK], DatanodeInfoWithStorage[127.0.0.1:42591,DS-6cfe6762-c7d6-4e8b-8451-55497696ef76,DISK], DatanodeInfoWithStorage[127.0.0.1:42753,DS-6eefcbc8-06b5-4375-9cb8-563c070c893b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-596636198-172.17.0.20-1598197278693:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38827,DS-f6d6ef20-5f17-45de-8ad6-af06035b6476,DISK], DatanodeInfoWithStorage[127.0.0.1:34744,DS-70e0fb1a-19b3-4236-909b-47964068587e,DISK], DatanodeInfoWithStorage[127.0.0.1:43308,DS-58bda664-c36f-4974-8ef2-0cad6d320404,DISK], DatanodeInfoWithStorage[127.0.0.1:40590,DS-bb490335-773b-41a5-ad6f-9c1a100381eb,DISK], DatanodeInfoWithStorage[127.0.0.1:35981,DS-2e0ffbe3-8f54-4d09-a38f-3544fe572bae,DISK], DatanodeInfoWithStorage[127.0.0.1:46583,DS-578c7bff-7491-4675-93b8-9a3e4cab281f,DISK], DatanodeInfoWithStorage[127.0.0.1:41643,DS-a3944f83-8ff5-4955-8e8a-c6ddc4f784a7,DISK], DatanodeInfoWithStorage[127.0.0.1:35418,DS-ee799398-5d28-4c9e-8de4-a7d23ab40111,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-596636198-172.17.0.20-1598197278693:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38827,DS-f6d6ef20-5f17-45de-8ad6-af06035b6476,DISK], DatanodeInfoWithStorage[127.0.0.1:34744,DS-70e0fb1a-19b3-4236-909b-47964068587e,DISK], DatanodeInfoWithStorage[127.0.0.1:43308,DS-58bda664-c36f-4974-8ef2-0cad6d320404,DISK], DatanodeInfoWithStorage[127.0.0.1:40590,DS-bb490335-773b-41a5-ad6f-9c1a100381eb,DISK], DatanodeInfoWithStorage[127.0.0.1:35981,DS-2e0ffbe3-8f54-4d09-a38f-3544fe572bae,DISK], DatanodeInfoWithStorage[127.0.0.1:46583,DS-578c7bff-7491-4675-93b8-9a3e4cab281f,DISK], DatanodeInfoWithStorage[127.0.0.1:41643,DS-a3944f83-8ff5-4955-8e8a-c6ddc4f784a7,DISK], DatanodeInfoWithStorage[127.0.0.1:35418,DS-ee799398-5d28-4c9e-8de4-a7d23ab40111,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1282117284-172.17.0.20-1598197382829:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46018,DS-c8e9b13a-35bf-4515-a846-0e7cde147674,DISK], DatanodeInfoWithStorage[127.0.0.1:39679,DS-5d6c4d9c-767c-4ad0-88f5-d74e9573cab9,DISK], DatanodeInfoWithStorage[127.0.0.1:42471,DS-cc03a4d5-7918-4514-9303-9bb124769f63,DISK], DatanodeInfoWithStorage[127.0.0.1:34276,DS-16f69c16-5bb7-4fec-96f7-c0749e6f961f,DISK], DatanodeInfoWithStorage[127.0.0.1:38033,DS-a0d0a07b-6ff8-4fc3-b250-c0542d6bad6d,DISK], DatanodeInfoWithStorage[127.0.0.1:40957,DS-bf093ea2-dca7-42b1-a2e5-0503ce6f83e3,DISK], DatanodeInfoWithStorage[127.0.0.1:36755,DS-84bc9a2e-fc1c-4a70-9e92-fb4c261d0f8c,DISK], DatanodeInfoWithStorage[127.0.0.1:36527,DS-0cddf7fb-d588-4e30-8e65-c228ac2c7c96,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1282117284-172.17.0.20-1598197382829:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46018,DS-c8e9b13a-35bf-4515-a846-0e7cde147674,DISK], DatanodeInfoWithStorage[127.0.0.1:39679,DS-5d6c4d9c-767c-4ad0-88f5-d74e9573cab9,DISK], DatanodeInfoWithStorage[127.0.0.1:42471,DS-cc03a4d5-7918-4514-9303-9bb124769f63,DISK], DatanodeInfoWithStorage[127.0.0.1:34276,DS-16f69c16-5bb7-4fec-96f7-c0749e6f961f,DISK], DatanodeInfoWithStorage[127.0.0.1:38033,DS-a0d0a07b-6ff8-4fc3-b250-c0542d6bad6d,DISK], DatanodeInfoWithStorage[127.0.0.1:40957,DS-bf093ea2-dca7-42b1-a2e5-0503ce6f83e3,DISK], DatanodeInfoWithStorage[127.0.0.1:36755,DS-84bc9a2e-fc1c-4a70-9e92-fb4c261d0f8c,DISK], DatanodeInfoWithStorage[127.0.0.1:36527,DS-0cddf7fb-d588-4e30-8e65-c228ac2c7c96,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1879330119-172.17.0.20-1598197453402:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42359,DS-5eca58f3-a4f4-4dbc-baec-32e3e0e19120,DISK], DatanodeInfoWithStorage[127.0.0.1:42603,DS-e8a3fde1-3885-4efd-a5d3-3248e5b34522,DISK], DatanodeInfoWithStorage[127.0.0.1:38279,DS-2610cde4-804a-46e1-9aad-f174ae77ff06,DISK], DatanodeInfoWithStorage[127.0.0.1:42097,DS-4ad61b7d-8a94-47ba-a1da-2e7f7e3c8ae8,DISK], DatanodeInfoWithStorage[127.0.0.1:34703,DS-3e212275-a50a-443a-a40e-91e2347fda55,DISK], DatanodeInfoWithStorage[127.0.0.1:41976,DS-229c9bdf-c46b-433e-a599-a70d1b77a180,DISK], DatanodeInfoWithStorage[127.0.0.1:42640,DS-f3a82768-e617-4eea-807b-bebcc789fd25,DISK], DatanodeInfoWithStorage[127.0.0.1:41297,DS-f4af43e5-49c3-465f-b512-3668ad528fae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1879330119-172.17.0.20-1598197453402:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42359,DS-5eca58f3-a4f4-4dbc-baec-32e3e0e19120,DISK], DatanodeInfoWithStorage[127.0.0.1:42603,DS-e8a3fde1-3885-4efd-a5d3-3248e5b34522,DISK], DatanodeInfoWithStorage[127.0.0.1:38279,DS-2610cde4-804a-46e1-9aad-f174ae77ff06,DISK], DatanodeInfoWithStorage[127.0.0.1:42097,DS-4ad61b7d-8a94-47ba-a1da-2e7f7e3c8ae8,DISK], DatanodeInfoWithStorage[127.0.0.1:34703,DS-3e212275-a50a-443a-a40e-91e2347fda55,DISK], DatanodeInfoWithStorage[127.0.0.1:41976,DS-229c9bdf-c46b-433e-a599-a70d1b77a180,DISK], DatanodeInfoWithStorage[127.0.0.1:42640,DS-f3a82768-e617-4eea-807b-bebcc789fd25,DISK], DatanodeInfoWithStorage[127.0.0.1:41297,DS-f4af43e5-49c3-465f-b512-3668ad528fae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 2 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5257
