reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1643583711-172.17.0.11-1598093261420:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43575,DS-9212d732-9b31-4740-bb93-78126dc4cedc,DISK], DatanodeInfoWithStorage[127.0.0.1:46306,DS-16d93e62-d572-49bf-885b-28e8d3e2fb17,DISK], DatanodeInfoWithStorage[127.0.0.1:43691,DS-7d3bc96e-a5f4-4659-b084-f280aceb84db,DISK], DatanodeInfoWithStorage[127.0.0.1:41482,DS-ca68f087-1de0-423c-b9ba-4282afe35890,DISK], DatanodeInfoWithStorage[127.0.0.1:43027,DS-0ac908e0-6cec-43ed-8d7a-9a578603802a,DISK], DatanodeInfoWithStorage[127.0.0.1:46294,DS-c3ee0be9-464f-41d2-b6ef-bcdb7618b9d8,DISK], DatanodeInfoWithStorage[127.0.0.1:39948,DS-cd4c336f-8201-42ec-9ab3-84f08c920eb0,DISK], DatanodeInfoWithStorage[127.0.0.1:38841,DS-81b2bce6-2438-49b8-b669-8025c1a0491d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1643583711-172.17.0.11-1598093261420:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43575,DS-9212d732-9b31-4740-bb93-78126dc4cedc,DISK], DatanodeInfoWithStorage[127.0.0.1:46306,DS-16d93e62-d572-49bf-885b-28e8d3e2fb17,DISK], DatanodeInfoWithStorage[127.0.0.1:43691,DS-7d3bc96e-a5f4-4659-b084-f280aceb84db,DISK], DatanodeInfoWithStorage[127.0.0.1:41482,DS-ca68f087-1de0-423c-b9ba-4282afe35890,DISK], DatanodeInfoWithStorage[127.0.0.1:43027,DS-0ac908e0-6cec-43ed-8d7a-9a578603802a,DISK], DatanodeInfoWithStorage[127.0.0.1:46294,DS-c3ee0be9-464f-41d2-b6ef-bcdb7618b9d8,DISK], DatanodeInfoWithStorage[127.0.0.1:39948,DS-cd4c336f-8201-42ec-9ab3-84f08c920eb0,DISK], DatanodeInfoWithStorage[127.0.0.1:38841,DS-81b2bce6-2438-49b8-b669-8025c1a0491d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1656921343-172.17.0.11-1598093449867:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33829,DS-15fbfb35-4b73-42f6-a4c3-717c0f4b1aae,DISK], DatanodeInfoWithStorage[127.0.0.1:41861,DS-d457ba4a-903a-4f6b-a302-99c547ace2cb,DISK], DatanodeInfoWithStorage[127.0.0.1:41712,DS-39e90df2-4127-4bec-a561-2f669e028550,DISK], DatanodeInfoWithStorage[127.0.0.1:40724,DS-f4891416-61ef-4733-bc47-49205d137d90,DISK], DatanodeInfoWithStorage[127.0.0.1:40426,DS-ab0f1f74-7cc7-4652-9df2-90fb01aa1acc,DISK], DatanodeInfoWithStorage[127.0.0.1:34728,DS-8f9cdc3e-cd17-43ca-99ee-9273864dceb8,DISK], DatanodeInfoWithStorage[127.0.0.1:33058,DS-a5db4a6f-ef4d-4131-823f-234fad6b334a,DISK], DatanodeInfoWithStorage[127.0.0.1:38466,DS-464f110a-da8c-4f31-b011-3583c7a8946d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1656921343-172.17.0.11-1598093449867:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33829,DS-15fbfb35-4b73-42f6-a4c3-717c0f4b1aae,DISK], DatanodeInfoWithStorage[127.0.0.1:41861,DS-d457ba4a-903a-4f6b-a302-99c547ace2cb,DISK], DatanodeInfoWithStorage[127.0.0.1:41712,DS-39e90df2-4127-4bec-a561-2f669e028550,DISK], DatanodeInfoWithStorage[127.0.0.1:40724,DS-f4891416-61ef-4733-bc47-49205d137d90,DISK], DatanodeInfoWithStorage[127.0.0.1:40426,DS-ab0f1f74-7cc7-4652-9df2-90fb01aa1acc,DISK], DatanodeInfoWithStorage[127.0.0.1:34728,DS-8f9cdc3e-cd17-43ca-99ee-9273864dceb8,DISK], DatanodeInfoWithStorage[127.0.0.1:33058,DS-a5db4a6f-ef4d-4131-823f-234fad6b334a,DISK], DatanodeInfoWithStorage[127.0.0.1:38466,DS-464f110a-da8c-4f31-b011-3583c7a8946d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-871357353-172.17.0.11-1598093792451:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46656,DS-7dad6f0c-472e-4280-9b9a-0122d3e85839,DISK], DatanodeInfoWithStorage[127.0.0.1:41925,DS-3e9c069a-0d1a-4804-ad2e-6601add7eebf,DISK], DatanodeInfoWithStorage[127.0.0.1:38709,DS-e75f62bc-b403-4d52-8144-d5d56202340b,DISK], DatanodeInfoWithStorage[127.0.0.1:39474,DS-77a0ef27-08c9-4581-a3d7-2ef74c68176e,DISK], DatanodeInfoWithStorage[127.0.0.1:41026,DS-dd58469d-c204-4946-ae22-2670cccb7ae2,DISK], DatanodeInfoWithStorage[127.0.0.1:35547,DS-47242bdc-9182-4908-b63d-e70f74d3518a,DISK], DatanodeInfoWithStorage[127.0.0.1:35606,DS-cf02cbd7-c8f1-472f-8b93-b6aa4ca32189,DISK], DatanodeInfoWithStorage[127.0.0.1:38375,DS-72f31909-20d3-4561-a5af-84ad15eeebca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-871357353-172.17.0.11-1598093792451:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46656,DS-7dad6f0c-472e-4280-9b9a-0122d3e85839,DISK], DatanodeInfoWithStorage[127.0.0.1:41925,DS-3e9c069a-0d1a-4804-ad2e-6601add7eebf,DISK], DatanodeInfoWithStorage[127.0.0.1:38709,DS-e75f62bc-b403-4d52-8144-d5d56202340b,DISK], DatanodeInfoWithStorage[127.0.0.1:39474,DS-77a0ef27-08c9-4581-a3d7-2ef74c68176e,DISK], DatanodeInfoWithStorage[127.0.0.1:41026,DS-dd58469d-c204-4946-ae22-2670cccb7ae2,DISK], DatanodeInfoWithStorage[127.0.0.1:35547,DS-47242bdc-9182-4908-b63d-e70f74d3518a,DISK], DatanodeInfoWithStorage[127.0.0.1:35606,DS-cf02cbd7-c8f1-472f-8b93-b6aa4ca32189,DISK], DatanodeInfoWithStorage[127.0.0.1:38375,DS-72f31909-20d3-4561-a5af-84ad15eeebca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-226967289-172.17.0.11-1598094001182:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40314,DS-8c0f896c-a20c-4ebe-9082-87d0985d6a02,DISK], DatanodeInfoWithStorage[127.0.0.1:43644,DS-cd6d4796-886f-4b44-ad2a-8863c089ae3d,DISK], DatanodeInfoWithStorage[127.0.0.1:34104,DS-652550ec-dec8-414f-950f-28b77ee4ce56,DISK], DatanodeInfoWithStorage[127.0.0.1:42253,DS-43988ede-0e47-4ac8-a94b-9bb2bf37d4a9,DISK], DatanodeInfoWithStorage[127.0.0.1:33732,DS-50fbf309-b341-4c65-a4f5-e09f32f1388d,DISK], DatanodeInfoWithStorage[127.0.0.1:41593,DS-19c8ed27-d440-4ccb-a5d8-e4e052b3836e,DISK], DatanodeInfoWithStorage[127.0.0.1:38585,DS-2cf72b1d-8357-4002-89ca-021accbfc566,DISK], DatanodeInfoWithStorage[127.0.0.1:37413,DS-ecba1f6e-14c1-4936-b0d8-45c56e834930,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-226967289-172.17.0.11-1598094001182:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40314,DS-8c0f896c-a20c-4ebe-9082-87d0985d6a02,DISK], DatanodeInfoWithStorage[127.0.0.1:43644,DS-cd6d4796-886f-4b44-ad2a-8863c089ae3d,DISK], DatanodeInfoWithStorage[127.0.0.1:34104,DS-652550ec-dec8-414f-950f-28b77ee4ce56,DISK], DatanodeInfoWithStorage[127.0.0.1:42253,DS-43988ede-0e47-4ac8-a94b-9bb2bf37d4a9,DISK], DatanodeInfoWithStorage[127.0.0.1:33732,DS-50fbf309-b341-4c65-a4f5-e09f32f1388d,DISK], DatanodeInfoWithStorage[127.0.0.1:41593,DS-19c8ed27-d440-4ccb-a5d8-e4e052b3836e,DISK], DatanodeInfoWithStorage[127.0.0.1:38585,DS-2cf72b1d-8357-4002-89ca-021accbfc566,DISK], DatanodeInfoWithStorage[127.0.0.1:37413,DS-ecba1f6e-14c1-4936-b0d8-45c56e834930,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-83534889-172.17.0.11-1598094107587:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36205,DS-f92aa675-3058-4a91-b94c-346bc95be3b1,DISK], DatanodeInfoWithStorage[127.0.0.1:46575,DS-e1a4b4df-0d24-4602-ae6e-10d53ffe4b81,DISK], DatanodeInfoWithStorage[127.0.0.1:42314,DS-0e692110-3fa3-4764-a93c-9da809f77c89,DISK], DatanodeInfoWithStorage[127.0.0.1:39400,DS-61a0bb8e-043b-4efd-980e-401e1110a36b,DISK], DatanodeInfoWithStorage[127.0.0.1:45806,DS-88fe5342-2d73-4473-9c65-10d09f70ee30,DISK], DatanodeInfoWithStorage[127.0.0.1:40597,DS-906d8895-44c9-478d-ae67-145bc423c068,DISK], DatanodeInfoWithStorage[127.0.0.1:43373,DS-56d2ed36-415a-49e1-8bee-fb136af45df1,DISK], DatanodeInfoWithStorage[127.0.0.1:39000,DS-0deac9e7-6dce-485b-9556-57c22a5f97a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-83534889-172.17.0.11-1598094107587:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36205,DS-f92aa675-3058-4a91-b94c-346bc95be3b1,DISK], DatanodeInfoWithStorage[127.0.0.1:46575,DS-e1a4b4df-0d24-4602-ae6e-10d53ffe4b81,DISK], DatanodeInfoWithStorage[127.0.0.1:42314,DS-0e692110-3fa3-4764-a93c-9da809f77c89,DISK], DatanodeInfoWithStorage[127.0.0.1:39400,DS-61a0bb8e-043b-4efd-980e-401e1110a36b,DISK], DatanodeInfoWithStorage[127.0.0.1:45806,DS-88fe5342-2d73-4473-9c65-10d09f70ee30,DISK], DatanodeInfoWithStorage[127.0.0.1:40597,DS-906d8895-44c9-478d-ae67-145bc423c068,DISK], DatanodeInfoWithStorage[127.0.0.1:43373,DS-56d2ed36-415a-49e1-8bee-fb136af45df1,DISK], DatanodeInfoWithStorage[127.0.0.1:39000,DS-0deac9e7-6dce-485b-9556-57c22a5f97a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1747335279-172.17.0.11-1598094227660:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43510,DS-9ea3f6d8-3c1e-40d1-9aa2-30e8e7bef1a3,DISK], DatanodeInfoWithStorage[127.0.0.1:45266,DS-e918c7f6-fddb-4ace-870b-36905814a314,DISK], DatanodeInfoWithStorage[127.0.0.1:33959,DS-90667a24-d1e0-45f4-9595-31336cdcf799,DISK], DatanodeInfoWithStorage[127.0.0.1:36474,DS-fe57c59e-bb53-4112-8d5e-a90351cc3088,DISK], DatanodeInfoWithStorage[127.0.0.1:38846,DS-d3d6cddf-6da5-4dd4-b55e-04e5a8d7cf27,DISK], DatanodeInfoWithStorage[127.0.0.1:33113,DS-edf6230b-8c8e-4694-a462-5c267963fa0d,DISK], DatanodeInfoWithStorage[127.0.0.1:42370,DS-88a51cd5-38d8-4117-bb8a-80261767fd76,DISK], DatanodeInfoWithStorage[127.0.0.1:46798,DS-8e4ce738-70c4-49f2-958a-40a59b45b831,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1747335279-172.17.0.11-1598094227660:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43510,DS-9ea3f6d8-3c1e-40d1-9aa2-30e8e7bef1a3,DISK], DatanodeInfoWithStorage[127.0.0.1:45266,DS-e918c7f6-fddb-4ace-870b-36905814a314,DISK], DatanodeInfoWithStorage[127.0.0.1:33959,DS-90667a24-d1e0-45f4-9595-31336cdcf799,DISK], DatanodeInfoWithStorage[127.0.0.1:36474,DS-fe57c59e-bb53-4112-8d5e-a90351cc3088,DISK], DatanodeInfoWithStorage[127.0.0.1:38846,DS-d3d6cddf-6da5-4dd4-b55e-04e5a8d7cf27,DISK], DatanodeInfoWithStorage[127.0.0.1:33113,DS-edf6230b-8c8e-4694-a462-5c267963fa0d,DISK], DatanodeInfoWithStorage[127.0.0.1:42370,DS-88a51cd5-38d8-4117-bb8a-80261767fd76,DISK], DatanodeInfoWithStorage[127.0.0.1:46798,DS-8e4ce738-70c4-49f2-958a-40a59b45b831,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1010057998-172.17.0.11-1598094371453:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45621,DS-dce05442-b168-40fd-b613-a707996202dc,DISK], DatanodeInfoWithStorage[127.0.0.1:35491,DS-8cfecac2-64f4-4b5a-81be-dc234b20d172,DISK], DatanodeInfoWithStorage[127.0.0.1:37434,DS-ea614c24-b6b3-4788-a433-7e0ca7500010,DISK], DatanodeInfoWithStorage[127.0.0.1:40284,DS-a28291fb-407f-4eeb-a268-1b39cf69d66f,DISK], DatanodeInfoWithStorage[127.0.0.1:43777,DS-c5a9cb72-b846-41d9-a104-03230666f4de,DISK], DatanodeInfoWithStorage[127.0.0.1:46365,DS-37b4a68e-cc9f-4e88-a821-fd3505603c8b,DISK], DatanodeInfoWithStorage[127.0.0.1:37687,DS-1a540ac3-1fb1-496b-ba48-5d25dbe4e6cb,DISK], DatanodeInfoWithStorage[127.0.0.1:35046,DS-8e122a99-8e3a-4c71-adf0-3d46e1479b9f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1010057998-172.17.0.11-1598094371453:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45621,DS-dce05442-b168-40fd-b613-a707996202dc,DISK], DatanodeInfoWithStorage[127.0.0.1:35491,DS-8cfecac2-64f4-4b5a-81be-dc234b20d172,DISK], DatanodeInfoWithStorage[127.0.0.1:37434,DS-ea614c24-b6b3-4788-a433-7e0ca7500010,DISK], DatanodeInfoWithStorage[127.0.0.1:40284,DS-a28291fb-407f-4eeb-a268-1b39cf69d66f,DISK], DatanodeInfoWithStorage[127.0.0.1:43777,DS-c5a9cb72-b846-41d9-a104-03230666f4de,DISK], DatanodeInfoWithStorage[127.0.0.1:46365,DS-37b4a68e-cc9f-4e88-a821-fd3505603c8b,DISK], DatanodeInfoWithStorage[127.0.0.1:37687,DS-1a540ac3-1fb1-496b-ba48-5d25dbe4e6cb,DISK], DatanodeInfoWithStorage[127.0.0.1:35046,DS-8e122a99-8e3a-4c71-adf0-3d46e1479b9f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1900255647-172.17.0.11-1598094444384:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35390,DS-3a104e8d-b2ea-479d-a510-b68a9d1741dc,DISK], DatanodeInfoWithStorage[127.0.0.1:39874,DS-bf57786e-f7d7-4e7b-ad6b-23a8916daa40,DISK], DatanodeInfoWithStorage[127.0.0.1:44586,DS-2da3ede3-f20a-481d-abbe-096b743f2d23,DISK], DatanodeInfoWithStorage[127.0.0.1:45616,DS-97afc410-1819-4094-9305-a096e64d8bf4,DISK], DatanodeInfoWithStorage[127.0.0.1:41258,DS-4cb75f73-375f-4b3c-8082-90a87bb602bb,DISK], DatanodeInfoWithStorage[127.0.0.1:39746,DS-91187cc0-5818-43ed-ba53-0a74f4aa0cb1,DISK], DatanodeInfoWithStorage[127.0.0.1:34965,DS-6c81ee12-4d38-45f9-9810-b6b3bbdea6df,DISK], DatanodeInfoWithStorage[127.0.0.1:38868,DS-422e346f-029b-4e2f-b983-3efa3a49b0fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1900255647-172.17.0.11-1598094444384:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35390,DS-3a104e8d-b2ea-479d-a510-b68a9d1741dc,DISK], DatanodeInfoWithStorage[127.0.0.1:39874,DS-bf57786e-f7d7-4e7b-ad6b-23a8916daa40,DISK], DatanodeInfoWithStorage[127.0.0.1:44586,DS-2da3ede3-f20a-481d-abbe-096b743f2d23,DISK], DatanodeInfoWithStorage[127.0.0.1:45616,DS-97afc410-1819-4094-9305-a096e64d8bf4,DISK], DatanodeInfoWithStorage[127.0.0.1:41258,DS-4cb75f73-375f-4b3c-8082-90a87bb602bb,DISK], DatanodeInfoWithStorage[127.0.0.1:39746,DS-91187cc0-5818-43ed-ba53-0a74f4aa0cb1,DISK], DatanodeInfoWithStorage[127.0.0.1:34965,DS-6c81ee12-4d38-45f9-9810-b6b3bbdea6df,DISK], DatanodeInfoWithStorage[127.0.0.1:38868,DS-422e346f-029b-4e2f-b983-3efa3a49b0fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-735815827-172.17.0.11-1598094596057:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35147,DS-b58e3c1a-c954-44e0-8969-17792fc7182e,DISK], DatanodeInfoWithStorage[127.0.0.1:39402,DS-423d2a99-637c-411e-bd9d-5ff9fdf83eef,DISK], DatanodeInfoWithStorage[127.0.0.1:37499,DS-50bcce2e-e69e-41a0-a648-dea695aca6dd,DISK], DatanodeInfoWithStorage[127.0.0.1:34108,DS-f4f3eefc-f2db-45ac-9644-c13b583bdf27,DISK], DatanodeInfoWithStorage[127.0.0.1:39506,DS-47754e07-f237-42db-9448-129a2a1b33f6,DISK], DatanodeInfoWithStorage[127.0.0.1:41207,DS-d20e5370-c091-4312-9800-455bcbc7c653,DISK], DatanodeInfoWithStorage[127.0.0.1:33046,DS-f0a38551-cade-4b76-a2c5-b8176b6178cc,DISK], DatanodeInfoWithStorage[127.0.0.1:33328,DS-1978e2ef-14f0-4335-943c-9111addbdf44,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-735815827-172.17.0.11-1598094596057:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35147,DS-b58e3c1a-c954-44e0-8969-17792fc7182e,DISK], DatanodeInfoWithStorage[127.0.0.1:39402,DS-423d2a99-637c-411e-bd9d-5ff9fdf83eef,DISK], DatanodeInfoWithStorage[127.0.0.1:37499,DS-50bcce2e-e69e-41a0-a648-dea695aca6dd,DISK], DatanodeInfoWithStorage[127.0.0.1:34108,DS-f4f3eefc-f2db-45ac-9644-c13b583bdf27,DISK], DatanodeInfoWithStorage[127.0.0.1:39506,DS-47754e07-f237-42db-9448-129a2a1b33f6,DISK], DatanodeInfoWithStorage[127.0.0.1:41207,DS-d20e5370-c091-4312-9800-455bcbc7c653,DISK], DatanodeInfoWithStorage[127.0.0.1:33046,DS-f0a38551-cade-4b76-a2c5-b8176b6178cc,DISK], DatanodeInfoWithStorage[127.0.0.1:33328,DS-1978e2ef-14f0-4335-943c-9111addbdf44,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1040696000-172.17.0.11-1598094971632:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35895,DS-5acd3b2a-97ea-43ac-897e-ac6a2adb542e,DISK], DatanodeInfoWithStorage[127.0.0.1:33808,DS-2b428e93-1290-4cb1-bef3-8387959ee7e5,DISK], DatanodeInfoWithStorage[127.0.0.1:37113,DS-355ddb6a-be7f-4fe2-bb38-a68732b5986f,DISK], DatanodeInfoWithStorage[127.0.0.1:42289,DS-d3fc8849-0b74-45ae-8d1b-9e3658578d56,DISK], DatanodeInfoWithStorage[127.0.0.1:35935,DS-765b4fd2-75a0-4a59-bbec-d08b4b9593fa,DISK], DatanodeInfoWithStorage[127.0.0.1:40038,DS-8802ba54-ff36-464a-8bbd-a3481d9dba4d,DISK], DatanodeInfoWithStorage[127.0.0.1:38536,DS-685e1faf-ab81-4cfb-b642-b101d6b5255a,DISK], DatanodeInfoWithStorage[127.0.0.1:39116,DS-d2f2b4aa-1123-4cdb-a6cd-e258393a8149,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1040696000-172.17.0.11-1598094971632:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35895,DS-5acd3b2a-97ea-43ac-897e-ac6a2adb542e,DISK], DatanodeInfoWithStorage[127.0.0.1:33808,DS-2b428e93-1290-4cb1-bef3-8387959ee7e5,DISK], DatanodeInfoWithStorage[127.0.0.1:37113,DS-355ddb6a-be7f-4fe2-bb38-a68732b5986f,DISK], DatanodeInfoWithStorage[127.0.0.1:42289,DS-d3fc8849-0b74-45ae-8d1b-9e3658578d56,DISK], DatanodeInfoWithStorage[127.0.0.1:35935,DS-765b4fd2-75a0-4a59-bbec-d08b4b9593fa,DISK], DatanodeInfoWithStorage[127.0.0.1:40038,DS-8802ba54-ff36-464a-8bbd-a3481d9dba4d,DISK], DatanodeInfoWithStorage[127.0.0.1:38536,DS-685e1faf-ab81-4cfb-b642-b101d6b5255a,DISK], DatanodeInfoWithStorage[127.0.0.1:39116,DS-d2f2b4aa-1123-4cdb-a6cd-e258393a8149,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1115724555-172.17.0.11-1598095124953:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46750,DS-2a3b3100-1697-42a0-9b24-aa7b2beaa483,DISK], DatanodeInfoWithStorage[127.0.0.1:33413,DS-ac485a85-d4c0-424a-ae3d-5f660143acb3,DISK], DatanodeInfoWithStorage[127.0.0.1:43223,DS-f7259f7d-88c3-420e-abf3-520965a61ebf,DISK], DatanodeInfoWithStorage[127.0.0.1:45680,DS-bb50fb31-a88d-4305-9761-dac6037ce79a,DISK], DatanodeInfoWithStorage[127.0.0.1:45055,DS-2ae03d24-355e-4377-9948-b9f860ae1fa2,DISK], DatanodeInfoWithStorage[127.0.0.1:45530,DS-cd44f7cf-9d4e-4028-8780-7371d0391ff5,DISK], DatanodeInfoWithStorage[127.0.0.1:32857,DS-96551d5b-295e-4205-9332-d45056e4ef7f,DISK], DatanodeInfoWithStorage[127.0.0.1:35644,DS-9dd49e50-8281-466a-a06a-2506652a4742,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1115724555-172.17.0.11-1598095124953:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46750,DS-2a3b3100-1697-42a0-9b24-aa7b2beaa483,DISK], DatanodeInfoWithStorage[127.0.0.1:33413,DS-ac485a85-d4c0-424a-ae3d-5f660143acb3,DISK], DatanodeInfoWithStorage[127.0.0.1:43223,DS-f7259f7d-88c3-420e-abf3-520965a61ebf,DISK], DatanodeInfoWithStorage[127.0.0.1:45680,DS-bb50fb31-a88d-4305-9761-dac6037ce79a,DISK], DatanodeInfoWithStorage[127.0.0.1:45055,DS-2ae03d24-355e-4377-9948-b9f860ae1fa2,DISK], DatanodeInfoWithStorage[127.0.0.1:45530,DS-cd44f7cf-9d4e-4028-8780-7371d0391ff5,DISK], DatanodeInfoWithStorage[127.0.0.1:32857,DS-96551d5b-295e-4205-9332-d45056e4ef7f,DISK], DatanodeInfoWithStorage[127.0.0.1:35644,DS-9dd49e50-8281-466a-a06a-2506652a4742,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1768920362-172.17.0.11-1598095194125:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39892,DS-610478c6-434a-43e6-9327-a0b365b5872f,DISK], DatanodeInfoWithStorage[127.0.0.1:46571,DS-a992df39-af86-46fa-8eed-608140cae026,DISK], DatanodeInfoWithStorage[127.0.0.1:33646,DS-e384b1d5-e2f9-41d6-b4e6-cac73ed311b5,DISK], DatanodeInfoWithStorage[127.0.0.1:38280,DS-125d3afc-6817-4c66-b961-61706c4a3a5d,DISK], DatanodeInfoWithStorage[127.0.0.1:38827,DS-785b8604-e47f-4cc6-b654-776aff03df98,DISK], DatanodeInfoWithStorage[127.0.0.1:46196,DS-5f2aaff9-095c-41d2-8734-30eae64c15bb,DISK], DatanodeInfoWithStorage[127.0.0.1:40357,DS-e5ba5a80-486c-491a-a387-f92dceff9b5c,DISK], DatanodeInfoWithStorage[127.0.0.1:46486,DS-425031a1-5b88-4fe8-9d57-d66382290679,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1768920362-172.17.0.11-1598095194125:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39892,DS-610478c6-434a-43e6-9327-a0b365b5872f,DISK], DatanodeInfoWithStorage[127.0.0.1:46571,DS-a992df39-af86-46fa-8eed-608140cae026,DISK], DatanodeInfoWithStorage[127.0.0.1:33646,DS-e384b1d5-e2f9-41d6-b4e6-cac73ed311b5,DISK], DatanodeInfoWithStorage[127.0.0.1:38280,DS-125d3afc-6817-4c66-b961-61706c4a3a5d,DISK], DatanodeInfoWithStorage[127.0.0.1:38827,DS-785b8604-e47f-4cc6-b654-776aff03df98,DISK], DatanodeInfoWithStorage[127.0.0.1:46196,DS-5f2aaff9-095c-41d2-8734-30eae64c15bb,DISK], DatanodeInfoWithStorage[127.0.0.1:40357,DS-e5ba5a80-486c-491a-a387-f92dceff9b5c,DISK], DatanodeInfoWithStorage[127.0.0.1:46486,DS-425031a1-5b88-4fe8-9d57-d66382290679,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-627860499-172.17.0.11-1598095770760:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40853,DS-8285bc3c-76ee-4092-8f17-2512bcdf0cdb,DISK], DatanodeInfoWithStorage[127.0.0.1:39947,DS-90025e58-13f2-4520-bdd7-7254f7e7ed97,DISK], DatanodeInfoWithStorage[127.0.0.1:35149,DS-893b1f48-55f8-459a-b0e1-5ee370b8e52e,DISK], DatanodeInfoWithStorage[127.0.0.1:35562,DS-e6282bb3-8618-4363-aaa9-d11039e78606,DISK], DatanodeInfoWithStorage[127.0.0.1:40610,DS-bb56d25e-61c3-4717-a25e-2d160cdf83ad,DISK], DatanodeInfoWithStorage[127.0.0.1:42565,DS-fb5a8624-0a04-44d3-98c5-e9ea798029c6,DISK], DatanodeInfoWithStorage[127.0.0.1:37971,DS-9e99c55a-e6e9-4bc3-9ba2-e7e84963655a,DISK], DatanodeInfoWithStorage[127.0.0.1:40021,DS-506cab9b-bdee-4976-9061-87aea08bf63e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-627860499-172.17.0.11-1598095770760:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40853,DS-8285bc3c-76ee-4092-8f17-2512bcdf0cdb,DISK], DatanodeInfoWithStorage[127.0.0.1:39947,DS-90025e58-13f2-4520-bdd7-7254f7e7ed97,DISK], DatanodeInfoWithStorage[127.0.0.1:35149,DS-893b1f48-55f8-459a-b0e1-5ee370b8e52e,DISK], DatanodeInfoWithStorage[127.0.0.1:35562,DS-e6282bb3-8618-4363-aaa9-d11039e78606,DISK], DatanodeInfoWithStorage[127.0.0.1:40610,DS-bb56d25e-61c3-4717-a25e-2d160cdf83ad,DISK], DatanodeInfoWithStorage[127.0.0.1:42565,DS-fb5a8624-0a04-44d3-98c5-e9ea798029c6,DISK], DatanodeInfoWithStorage[127.0.0.1:37971,DS-9e99c55a-e6e9-4bc3-9ba2-e7e84963655a,DISK], DatanodeInfoWithStorage[127.0.0.1:40021,DS-506cab9b-bdee-4976-9061-87aea08bf63e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-886376075-172.17.0.11-1598095993794:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42824,DS-719d3236-3b4b-4f52-be20-a9f5b2f3a7b0,DISK], DatanodeInfoWithStorage[127.0.0.1:35035,DS-c0ed3389-d658-44bf-9021-6aa44b056932,DISK], DatanodeInfoWithStorage[127.0.0.1:40672,DS-f1d2d3e1-c903-492c-b41f-3905a88b86a0,DISK], DatanodeInfoWithStorage[127.0.0.1:34422,DS-433ba53f-db46-4440-ab93-a2109c3f94ef,DISK], DatanodeInfoWithStorage[127.0.0.1:45627,DS-7f246d6a-fad9-40b8-9a52-5c14a505f883,DISK], DatanodeInfoWithStorage[127.0.0.1:32945,DS-de063b64-7fbe-4ea3-b3f0-0c4780135145,DISK], DatanodeInfoWithStorage[127.0.0.1:43869,DS-d11d6c87-0071-4eb9-9e74-a241e4c0696a,DISK], DatanodeInfoWithStorage[127.0.0.1:44126,DS-1cfd7eaa-81d9-4947-9f5b-02e94891b34e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-886376075-172.17.0.11-1598095993794:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42824,DS-719d3236-3b4b-4f52-be20-a9f5b2f3a7b0,DISK], DatanodeInfoWithStorage[127.0.0.1:35035,DS-c0ed3389-d658-44bf-9021-6aa44b056932,DISK], DatanodeInfoWithStorage[127.0.0.1:40672,DS-f1d2d3e1-c903-492c-b41f-3905a88b86a0,DISK], DatanodeInfoWithStorage[127.0.0.1:34422,DS-433ba53f-db46-4440-ab93-a2109c3f94ef,DISK], DatanodeInfoWithStorage[127.0.0.1:45627,DS-7f246d6a-fad9-40b8-9a52-5c14a505f883,DISK], DatanodeInfoWithStorage[127.0.0.1:32945,DS-de063b64-7fbe-4ea3-b3f0-0c4780135145,DISK], DatanodeInfoWithStorage[127.0.0.1:43869,DS-d11d6c87-0071-4eb9-9e74-a241e4c0696a,DISK], DatanodeInfoWithStorage[127.0.0.1:44126,DS-1cfd7eaa-81d9-4947-9f5b-02e94891b34e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-444675400-172.17.0.11-1598096117843:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32810,DS-1b9cf2e7-0c69-4413-9cd0-6dc278f9f77c,DISK], DatanodeInfoWithStorage[127.0.0.1:37316,DS-aa90f104-26e2-44be-ac01-9b969b45606a,DISK], DatanodeInfoWithStorage[127.0.0.1:38858,DS-dcdec36f-7ddc-4534-9c4c-c5a20988d81e,DISK], DatanodeInfoWithStorage[127.0.0.1:34707,DS-66c045cc-dc3a-4cae-a502-44c0277fc50d,DISK], DatanodeInfoWithStorage[127.0.0.1:43108,DS-fbf902cc-2326-426e-b4e5-83753f32ead0,DISK], DatanodeInfoWithStorage[127.0.0.1:44320,DS-0c13116d-0c45-4c78-b9bf-8be643e8b1e4,DISK], DatanodeInfoWithStorage[127.0.0.1:33829,DS-71cbaf0e-b2aa-40f7-84ce-f34bd197e00d,DISK], DatanodeInfoWithStorage[127.0.0.1:45458,DS-82e138ec-fef9-4fb2-9696-d57843512689,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-444675400-172.17.0.11-1598096117843:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32810,DS-1b9cf2e7-0c69-4413-9cd0-6dc278f9f77c,DISK], DatanodeInfoWithStorage[127.0.0.1:37316,DS-aa90f104-26e2-44be-ac01-9b969b45606a,DISK], DatanodeInfoWithStorage[127.0.0.1:38858,DS-dcdec36f-7ddc-4534-9c4c-c5a20988d81e,DISK], DatanodeInfoWithStorage[127.0.0.1:34707,DS-66c045cc-dc3a-4cae-a502-44c0277fc50d,DISK], DatanodeInfoWithStorage[127.0.0.1:43108,DS-fbf902cc-2326-426e-b4e5-83753f32ead0,DISK], DatanodeInfoWithStorage[127.0.0.1:44320,DS-0c13116d-0c45-4c78-b9bf-8be643e8b1e4,DISK], DatanodeInfoWithStorage[127.0.0.1:33829,DS-71cbaf0e-b2aa-40f7-84ce-f34bd197e00d,DISK], DatanodeInfoWithStorage[127.0.0.1:45458,DS-82e138ec-fef9-4fb2-9696-d57843512689,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-908223905-172.17.0.11-1598096273453:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38598,DS-b35063fe-7af9-483f-bbda-6a27941a0706,DISK], DatanodeInfoWithStorage[127.0.0.1:45147,DS-ed5423bb-ee45-4315-914b-013b6bb11341,DISK], DatanodeInfoWithStorage[127.0.0.1:43968,DS-2036787e-187e-4086-bfdc-0fafe400d315,DISK], DatanodeInfoWithStorage[127.0.0.1:37284,DS-82205699-7581-4935-9bd8-35567732f431,DISK], DatanodeInfoWithStorage[127.0.0.1:46126,DS-60769f0b-0d69-45f0-84f5-bb09d7400d8b,DISK], DatanodeInfoWithStorage[127.0.0.1:42700,DS-1ffae640-4a75-4474-8c1b-bcdd3d0c94dc,DISK], DatanodeInfoWithStorage[127.0.0.1:45349,DS-09d3feb7-cf5f-4d8f-a983-da216c3ae7d9,DISK], DatanodeInfoWithStorage[127.0.0.1:39974,DS-84c10be6-9311-4d7c-baae-9c0398b5cb35,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-908223905-172.17.0.11-1598096273453:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38598,DS-b35063fe-7af9-483f-bbda-6a27941a0706,DISK], DatanodeInfoWithStorage[127.0.0.1:45147,DS-ed5423bb-ee45-4315-914b-013b6bb11341,DISK], DatanodeInfoWithStorage[127.0.0.1:43968,DS-2036787e-187e-4086-bfdc-0fafe400d315,DISK], DatanodeInfoWithStorage[127.0.0.1:37284,DS-82205699-7581-4935-9bd8-35567732f431,DISK], DatanodeInfoWithStorage[127.0.0.1:46126,DS-60769f0b-0d69-45f0-84f5-bb09d7400d8b,DISK], DatanodeInfoWithStorage[127.0.0.1:42700,DS-1ffae640-4a75-4474-8c1b-bcdd3d0c94dc,DISK], DatanodeInfoWithStorage[127.0.0.1:45349,DS-09d3feb7-cf5f-4d8f-a983-da216c3ae7d9,DISK], DatanodeInfoWithStorage[127.0.0.1:39974,DS-84c10be6-9311-4d7c-baae-9c0398b5cb35,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-846602873-172.17.0.11-1598096393568:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42710,DS-05776daf-c73b-4bd4-90b1-9ae71eec0ed2,DISK], DatanodeInfoWithStorage[127.0.0.1:44102,DS-23af98a7-32de-4407-bed8-c7b15b792bab,DISK], DatanodeInfoWithStorage[127.0.0.1:33809,DS-a9caa93e-1658-4686-8784-761067c6d292,DISK], DatanodeInfoWithStorage[127.0.0.1:41845,DS-32a3bdb3-2ff5-428a-96c0-12f261ecb940,DISK], DatanodeInfoWithStorage[127.0.0.1:45746,DS-5e38dcf7-a11c-4f8c-8312-3bb6231127bc,DISK], DatanodeInfoWithStorage[127.0.0.1:39314,DS-b01da378-607e-4cfe-9de2-cdec63351f0e,DISK], DatanodeInfoWithStorage[127.0.0.1:33254,DS-0c6fd0a9-f034-4b0f-9cb3-fc229b3a32b7,DISK], DatanodeInfoWithStorage[127.0.0.1:41672,DS-9b233d47-5692-44e5-bb1a-7cc0b9764c50,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-846602873-172.17.0.11-1598096393568:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42710,DS-05776daf-c73b-4bd4-90b1-9ae71eec0ed2,DISK], DatanodeInfoWithStorage[127.0.0.1:44102,DS-23af98a7-32de-4407-bed8-c7b15b792bab,DISK], DatanodeInfoWithStorage[127.0.0.1:33809,DS-a9caa93e-1658-4686-8784-761067c6d292,DISK], DatanodeInfoWithStorage[127.0.0.1:41845,DS-32a3bdb3-2ff5-428a-96c0-12f261ecb940,DISK], DatanodeInfoWithStorage[127.0.0.1:45746,DS-5e38dcf7-a11c-4f8c-8312-3bb6231127bc,DISK], DatanodeInfoWithStorage[127.0.0.1:39314,DS-b01da378-607e-4cfe-9de2-cdec63351f0e,DISK], DatanodeInfoWithStorage[127.0.0.1:33254,DS-0c6fd0a9-f034-4b0f-9cb3-fc229b3a32b7,DISK], DatanodeInfoWithStorage[127.0.0.1:41672,DS-9b233d47-5692-44e5-bb1a-7cc0b9764c50,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-909024307-172.17.0.11-1598096636896:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39060,DS-fc23598f-5608-4e70-adbb-fc86ada5e9e1,DISK], DatanodeInfoWithStorage[127.0.0.1:42257,DS-394efd93-12bd-484e-87f4-42c8236cc8f2,DISK], DatanodeInfoWithStorage[127.0.0.1:36671,DS-8967a9a3-1d11-46da-8fbb-edabe6ce28a0,DISK], DatanodeInfoWithStorage[127.0.0.1:33040,DS-7f55be9e-729f-45d0-b354-07396e133f6e,DISK], DatanodeInfoWithStorage[127.0.0.1:37657,DS-ad336da4-7e45-4e9f-b3be-073322ef3931,DISK], DatanodeInfoWithStorage[127.0.0.1:33111,DS-3a2dd743-4e05-4534-b72f-534e13479eab,DISK], DatanodeInfoWithStorage[127.0.0.1:33137,DS-30b62afd-e5b0-4409-b23c-b6bfea4d6a92,DISK], DatanodeInfoWithStorage[127.0.0.1:44549,DS-5d526222-ecbe-4535-9c44-5e7d6fa9e618,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-909024307-172.17.0.11-1598096636896:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39060,DS-fc23598f-5608-4e70-adbb-fc86ada5e9e1,DISK], DatanodeInfoWithStorage[127.0.0.1:42257,DS-394efd93-12bd-484e-87f4-42c8236cc8f2,DISK], DatanodeInfoWithStorage[127.0.0.1:36671,DS-8967a9a3-1d11-46da-8fbb-edabe6ce28a0,DISK], DatanodeInfoWithStorage[127.0.0.1:33040,DS-7f55be9e-729f-45d0-b354-07396e133f6e,DISK], DatanodeInfoWithStorage[127.0.0.1:37657,DS-ad336da4-7e45-4e9f-b3be-073322ef3931,DISK], DatanodeInfoWithStorage[127.0.0.1:33111,DS-3a2dd743-4e05-4534-b72f-534e13479eab,DISK], DatanodeInfoWithStorage[127.0.0.1:33137,DS-30b62afd-e5b0-4409-b23c-b6bfea4d6a92,DISK], DatanodeInfoWithStorage[127.0.0.1:44549,DS-5d526222-ecbe-4535-9c44-5e7d6fa9e618,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-214418188-172.17.0.11-1598096973567:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42006,DS-6d0ca6f8-2636-4006-bb20-dd3f68d4eb70,DISK], DatanodeInfoWithStorage[127.0.0.1:38197,DS-01ed7c87-dbfb-4f5e-a27d-22dba98b9910,DISK], DatanodeInfoWithStorage[127.0.0.1:44738,DS-bfa84c49-4e1c-4648-9461-c81053272c5b,DISK], DatanodeInfoWithStorage[127.0.0.1:45335,DS-ce03e940-9207-4b83-bfb5-1cdf34059199,DISK], DatanodeInfoWithStorage[127.0.0.1:43953,DS-a807caf1-98a2-4357-939f-80b41cdf54e8,DISK], DatanodeInfoWithStorage[127.0.0.1:39907,DS-37b8e390-4305-448a-b4f7-2cae420309ed,DISK], DatanodeInfoWithStorage[127.0.0.1:37385,DS-1014213a-ddab-4936-8cb1-82d2ae41552f,DISK], DatanodeInfoWithStorage[127.0.0.1:38156,DS-e6b944a4-05f8-4a98-bbb5-8c12811a96dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-214418188-172.17.0.11-1598096973567:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42006,DS-6d0ca6f8-2636-4006-bb20-dd3f68d4eb70,DISK], DatanodeInfoWithStorage[127.0.0.1:38197,DS-01ed7c87-dbfb-4f5e-a27d-22dba98b9910,DISK], DatanodeInfoWithStorage[127.0.0.1:44738,DS-bfa84c49-4e1c-4648-9461-c81053272c5b,DISK], DatanodeInfoWithStorage[127.0.0.1:45335,DS-ce03e940-9207-4b83-bfb5-1cdf34059199,DISK], DatanodeInfoWithStorage[127.0.0.1:43953,DS-a807caf1-98a2-4357-939f-80b41cdf54e8,DISK], DatanodeInfoWithStorage[127.0.0.1:39907,DS-37b8e390-4305-448a-b4f7-2cae420309ed,DISK], DatanodeInfoWithStorage[127.0.0.1:37385,DS-1014213a-ddab-4936-8cb1-82d2ae41552f,DISK], DatanodeInfoWithStorage[127.0.0.1:38156,DS-e6b944a4-05f8-4a98-bbb5-8c12811a96dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-70704253-172.17.0.11-1598097157838:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43840,DS-554af2cc-6fe2-43af-8166-e4ba2ed4f42c,DISK], DatanodeInfoWithStorage[127.0.0.1:34956,DS-b5e02381-65a4-4425-a0de-81d6d2ae03eb,DISK], DatanodeInfoWithStorage[127.0.0.1:43615,DS-7be7040e-199e-424a-991a-7a0bce5551b2,DISK], DatanodeInfoWithStorage[127.0.0.1:40328,DS-57c4c4ee-00a0-4d59-bd42-501dddcebbf6,DISK], DatanodeInfoWithStorage[127.0.0.1:33830,DS-fb87848f-37e1-46d7-8cd5-635fed97bfe7,DISK], DatanodeInfoWithStorage[127.0.0.1:42772,DS-c22b9888-1fce-4e96-b8fd-c14833d4cb69,DISK], DatanodeInfoWithStorage[127.0.0.1:45015,DS-4eed66d2-839b-4de0-abb4-5467fce63c61,DISK], DatanodeInfoWithStorage[127.0.0.1:42839,DS-125bf056-e0ff-4d5e-98aa-e8f1281650a9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-70704253-172.17.0.11-1598097157838:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43840,DS-554af2cc-6fe2-43af-8166-e4ba2ed4f42c,DISK], DatanodeInfoWithStorage[127.0.0.1:34956,DS-b5e02381-65a4-4425-a0de-81d6d2ae03eb,DISK], DatanodeInfoWithStorage[127.0.0.1:43615,DS-7be7040e-199e-424a-991a-7a0bce5551b2,DISK], DatanodeInfoWithStorage[127.0.0.1:40328,DS-57c4c4ee-00a0-4d59-bd42-501dddcebbf6,DISK], DatanodeInfoWithStorage[127.0.0.1:33830,DS-fb87848f-37e1-46d7-8cd5-635fed97bfe7,DISK], DatanodeInfoWithStorage[127.0.0.1:42772,DS-c22b9888-1fce-4e96-b8fd-c14833d4cb69,DISK], DatanodeInfoWithStorage[127.0.0.1:45015,DS-4eed66d2-839b-4de0-abb4-5467fce63c61,DISK], DatanodeInfoWithStorage[127.0.0.1:42839,DS-125bf056-e0ff-4d5e-98aa-e8f1281650a9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-994552480-172.17.0.11-1598097357053:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33798,DS-836c2d21-1506-4525-86cd-c02129527f72,DISK], DatanodeInfoWithStorage[127.0.0.1:35023,DS-bc363be9-eafe-434f-9708-c2d675e1e321,DISK], DatanodeInfoWithStorage[127.0.0.1:41223,DS-454c6e3f-d6b7-4d45-8f34-9665da289627,DISK], DatanodeInfoWithStorage[127.0.0.1:37567,DS-9f7648b4-3f01-497a-a9c0-e2f3ad4cac8f,DISK], DatanodeInfoWithStorage[127.0.0.1:37668,DS-86035c8b-5f35-456e-aeee-2e295acfea4e,DISK], DatanodeInfoWithStorage[127.0.0.1:38681,DS-13c3ede0-6158-466f-9015-ba4d249197a1,DISK], DatanodeInfoWithStorage[127.0.0.1:38848,DS-e04d8dc6-a308-4455-ab60-4ad807912530,DISK], DatanodeInfoWithStorage[127.0.0.1:33970,DS-6c024001-9771-4808-95f8-dc37cce5d411,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-994552480-172.17.0.11-1598097357053:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33798,DS-836c2d21-1506-4525-86cd-c02129527f72,DISK], DatanodeInfoWithStorage[127.0.0.1:35023,DS-bc363be9-eafe-434f-9708-c2d675e1e321,DISK], DatanodeInfoWithStorage[127.0.0.1:41223,DS-454c6e3f-d6b7-4d45-8f34-9665da289627,DISK], DatanodeInfoWithStorage[127.0.0.1:37567,DS-9f7648b4-3f01-497a-a9c0-e2f3ad4cac8f,DISK], DatanodeInfoWithStorage[127.0.0.1:37668,DS-86035c8b-5f35-456e-aeee-2e295acfea4e,DISK], DatanodeInfoWithStorage[127.0.0.1:38681,DS-13c3ede0-6158-466f-9015-ba4d249197a1,DISK], DatanodeInfoWithStorage[127.0.0.1:38848,DS-e04d8dc6-a308-4455-ab60-4ad807912530,DISK], DatanodeInfoWithStorage[127.0.0.1:33970,DS-6c024001-9771-4808-95f8-dc37cce5d411,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2028815620-172.17.0.11-1598097821129:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43876,DS-35e1ef3d-fd92-45ad-8cca-e0c567b2469b,DISK], DatanodeInfoWithStorage[127.0.0.1:45899,DS-9bc53bcd-a891-4955-8c0c-d0f7ca1fcaf3,DISK], DatanodeInfoWithStorage[127.0.0.1:35515,DS-b9d7286e-0df5-4a0d-ac88-c5574c440e19,DISK], DatanodeInfoWithStorage[127.0.0.1:46128,DS-85fd1d3e-049a-4a66-beff-064d22d8ff6f,DISK], DatanodeInfoWithStorage[127.0.0.1:42532,DS-32205f92-ec99-4f23-89dc-85bfb994c57d,DISK], DatanodeInfoWithStorage[127.0.0.1:33494,DS-49c8aeec-5ca9-48e8-9923-1c6e8a35ec96,DISK], DatanodeInfoWithStorage[127.0.0.1:39062,DS-75184842-990c-4399-8619-b46b484d26a5,DISK], DatanodeInfoWithStorage[127.0.0.1:37027,DS-b5929671-a0ce-40d6-a235-d092e4b1be6c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2028815620-172.17.0.11-1598097821129:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43876,DS-35e1ef3d-fd92-45ad-8cca-e0c567b2469b,DISK], DatanodeInfoWithStorage[127.0.0.1:45899,DS-9bc53bcd-a891-4955-8c0c-d0f7ca1fcaf3,DISK], DatanodeInfoWithStorage[127.0.0.1:35515,DS-b9d7286e-0df5-4a0d-ac88-c5574c440e19,DISK], DatanodeInfoWithStorage[127.0.0.1:46128,DS-85fd1d3e-049a-4a66-beff-064d22d8ff6f,DISK], DatanodeInfoWithStorage[127.0.0.1:42532,DS-32205f92-ec99-4f23-89dc-85bfb994c57d,DISK], DatanodeInfoWithStorage[127.0.0.1:33494,DS-49c8aeec-5ca9-48e8-9923-1c6e8a35ec96,DISK], DatanodeInfoWithStorage[127.0.0.1:39062,DS-75184842-990c-4399-8619-b46b484d26a5,DISK], DatanodeInfoWithStorage[127.0.0.1:37027,DS-b5929671-a0ce-40d6-a235-d092e4b1be6c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 18 out of 50
result: false positive !!!
Total execution time in seconds : 5626
