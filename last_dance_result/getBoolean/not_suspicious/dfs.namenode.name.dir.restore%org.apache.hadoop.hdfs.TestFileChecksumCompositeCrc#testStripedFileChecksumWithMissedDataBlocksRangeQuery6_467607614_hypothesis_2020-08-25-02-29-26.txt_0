reconf_parameter: dfs.namenode.name.dir.restore
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.name.dir.restore
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-219647131-172.17.0.9-1598322582130:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34642,DS-a136c53b-66f2-4fba-a7c4-a61e5a6cc195,DISK], DatanodeInfoWithStorage[127.0.0.1:42540,DS-5af59015-e68f-4380-84bb-347aae17ff38,DISK], DatanodeInfoWithStorage[127.0.0.1:45945,DS-dbc9eaa3-5f70-4588-937f-00a3bba32ad7,DISK], DatanodeInfoWithStorage[127.0.0.1:45991,DS-c1c1383f-3e8e-466c-82ae-0b35fffce607,DISK], DatanodeInfoWithStorage[127.0.0.1:37712,DS-34329892-b0c3-4d30-8ae8-709a947feabe,DISK], DatanodeInfoWithStorage[127.0.0.1:46883,DS-fc4c1757-039c-4631-8abb-beab26f92c1a,DISK], DatanodeInfoWithStorage[127.0.0.1:45616,DS-42bc108f-d8d7-418e-b1f5-72c03145d503,DISK], DatanodeInfoWithStorage[127.0.0.1:33188,DS-f885aad9-e42e-431e-a501-71368690e4ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-219647131-172.17.0.9-1598322582130:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34642,DS-a136c53b-66f2-4fba-a7c4-a61e5a6cc195,DISK], DatanodeInfoWithStorage[127.0.0.1:42540,DS-5af59015-e68f-4380-84bb-347aae17ff38,DISK], DatanodeInfoWithStorage[127.0.0.1:45945,DS-dbc9eaa3-5f70-4588-937f-00a3bba32ad7,DISK], DatanodeInfoWithStorage[127.0.0.1:45991,DS-c1c1383f-3e8e-466c-82ae-0b35fffce607,DISK], DatanodeInfoWithStorage[127.0.0.1:37712,DS-34329892-b0c3-4d30-8ae8-709a947feabe,DISK], DatanodeInfoWithStorage[127.0.0.1:46883,DS-fc4c1757-039c-4631-8abb-beab26f92c1a,DISK], DatanodeInfoWithStorage[127.0.0.1:45616,DS-42bc108f-d8d7-418e-b1f5-72c03145d503,DISK], DatanodeInfoWithStorage[127.0.0.1:33188,DS-f885aad9-e42e-431e-a501-71368690e4ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.name.dir.restore
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1028878733-172.17.0.9-1598322619897:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33489,DS-be50f6a3-0915-417a-89f3-d0a8310dba46,DISK], DatanodeInfoWithStorage[127.0.0.1:35927,DS-f922e636-aafa-4f7f-bd99-0ed2eb4ee5f7,DISK], DatanodeInfoWithStorage[127.0.0.1:37040,DS-f31e4d8c-e6e4-4c80-83e5-a4ff97b942fc,DISK], DatanodeInfoWithStorage[127.0.0.1:36587,DS-487993ef-b8a5-4dfc-af6a-af14159cc4a9,DISK], DatanodeInfoWithStorage[127.0.0.1:36350,DS-66ae7981-9eb2-41a4-8f45-4ace2f91d5e3,DISK], DatanodeInfoWithStorage[127.0.0.1:33108,DS-eafdb4b5-860c-40fb-90b4-f9f51af2232f,DISK], DatanodeInfoWithStorage[127.0.0.1:41784,DS-1994dc7b-6245-45da-a8c6-3e49a076a547,DISK], DatanodeInfoWithStorage[127.0.0.1:33349,DS-9c848a99-f5e1-4648-8c61-bcbfa7173e14,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1028878733-172.17.0.9-1598322619897:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33489,DS-be50f6a3-0915-417a-89f3-d0a8310dba46,DISK], DatanodeInfoWithStorage[127.0.0.1:35927,DS-f922e636-aafa-4f7f-bd99-0ed2eb4ee5f7,DISK], DatanodeInfoWithStorage[127.0.0.1:37040,DS-f31e4d8c-e6e4-4c80-83e5-a4ff97b942fc,DISK], DatanodeInfoWithStorage[127.0.0.1:36587,DS-487993ef-b8a5-4dfc-af6a-af14159cc4a9,DISK], DatanodeInfoWithStorage[127.0.0.1:36350,DS-66ae7981-9eb2-41a4-8f45-4ace2f91d5e3,DISK], DatanodeInfoWithStorage[127.0.0.1:33108,DS-eafdb4b5-860c-40fb-90b4-f9f51af2232f,DISK], DatanodeInfoWithStorage[127.0.0.1:41784,DS-1994dc7b-6245-45da-a8c6-3e49a076a547,DISK], DatanodeInfoWithStorage[127.0.0.1:33349,DS-9c848a99-f5e1-4648-8c61-bcbfa7173e14,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.name.dir.restore
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1078556551-172.17.0.9-1598322716397:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43125,DS-35bc8d23-ea17-4460-9699-a82c8922fb9f,DISK], DatanodeInfoWithStorage[127.0.0.1:44771,DS-a49b5d0f-e8c5-49aa-93dc-45f7a8c5d8c6,DISK], DatanodeInfoWithStorage[127.0.0.1:38615,DS-e90ce1f8-3a43-4cf7-af53-054b2e5920e6,DISK], DatanodeInfoWithStorage[127.0.0.1:41082,DS-1110df8f-eb05-4439-82d6-489eae634934,DISK], DatanodeInfoWithStorage[127.0.0.1:35782,DS-76bd8d99-b624-43ad-af14-433eaedb8ad9,DISK], DatanodeInfoWithStorage[127.0.0.1:33769,DS-7fe7f136-5c1b-4020-b49e-3c1a4120329a,DISK], DatanodeInfoWithStorage[127.0.0.1:39837,DS-60329bca-0bd2-4239-93b4-a9930e7d121f,DISK], DatanodeInfoWithStorage[127.0.0.1:34116,DS-5abe201d-c0cf-4383-a307-a0fe39fad08c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1078556551-172.17.0.9-1598322716397:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43125,DS-35bc8d23-ea17-4460-9699-a82c8922fb9f,DISK], DatanodeInfoWithStorage[127.0.0.1:44771,DS-a49b5d0f-e8c5-49aa-93dc-45f7a8c5d8c6,DISK], DatanodeInfoWithStorage[127.0.0.1:38615,DS-e90ce1f8-3a43-4cf7-af53-054b2e5920e6,DISK], DatanodeInfoWithStorage[127.0.0.1:41082,DS-1110df8f-eb05-4439-82d6-489eae634934,DISK], DatanodeInfoWithStorage[127.0.0.1:35782,DS-76bd8d99-b624-43ad-af14-433eaedb8ad9,DISK], DatanodeInfoWithStorage[127.0.0.1:33769,DS-7fe7f136-5c1b-4020-b49e-3c1a4120329a,DISK], DatanodeInfoWithStorage[127.0.0.1:39837,DS-60329bca-0bd2-4239-93b4-a9930e7d121f,DISK], DatanodeInfoWithStorage[127.0.0.1:34116,DS-5abe201d-c0cf-4383-a307-a0fe39fad08c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.name.dir.restore
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-503915934-172.17.0.9-1598323058943:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42082,DS-6dfb2837-5b5b-482a-8225-7e54f8a09962,DISK], DatanodeInfoWithStorage[127.0.0.1:43609,DS-98bb372e-e75f-4234-b39a-08720eb83f65,DISK], DatanodeInfoWithStorage[127.0.0.1:44588,DS-a3beea9e-951b-4005-a377-bd8a0ef59b0b,DISK], DatanodeInfoWithStorage[127.0.0.1:32881,DS-9ddef498-e326-4c1f-a16b-858a265e8156,DISK], DatanodeInfoWithStorage[127.0.0.1:39017,DS-9ff7b8f3-468e-4ec4-a3b3-5cbb2e940a29,DISK], DatanodeInfoWithStorage[127.0.0.1:42024,DS-fee24f49-be33-41a2-b807-18794aedfeb2,DISK], DatanodeInfoWithStorage[127.0.0.1:41252,DS-3429b15d-66f0-43fc-ba3d-c85dff93dab6,DISK], DatanodeInfoWithStorage[127.0.0.1:43924,DS-6d5ba3bb-015a-48ae-a734-8dec2fa03649,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-503915934-172.17.0.9-1598323058943:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42082,DS-6dfb2837-5b5b-482a-8225-7e54f8a09962,DISK], DatanodeInfoWithStorage[127.0.0.1:43609,DS-98bb372e-e75f-4234-b39a-08720eb83f65,DISK], DatanodeInfoWithStorage[127.0.0.1:44588,DS-a3beea9e-951b-4005-a377-bd8a0ef59b0b,DISK], DatanodeInfoWithStorage[127.0.0.1:32881,DS-9ddef498-e326-4c1f-a16b-858a265e8156,DISK], DatanodeInfoWithStorage[127.0.0.1:39017,DS-9ff7b8f3-468e-4ec4-a3b3-5cbb2e940a29,DISK], DatanodeInfoWithStorage[127.0.0.1:42024,DS-fee24f49-be33-41a2-b807-18794aedfeb2,DISK], DatanodeInfoWithStorage[127.0.0.1:41252,DS-3429b15d-66f0-43fc-ba3d-c85dff93dab6,DISK], DatanodeInfoWithStorage[127.0.0.1:43924,DS-6d5ba3bb-015a-48ae-a734-8dec2fa03649,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.name.dir.restore
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1566194977-172.17.0.9-1598323129927:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41674,DS-e2ab264d-9c14-4332-af9b-38966d503447,DISK], DatanodeInfoWithStorage[127.0.0.1:37074,DS-182c8ecb-bba7-4730-8e7e-73421cc96d14,DISK], DatanodeInfoWithStorage[127.0.0.1:33748,DS-daea9c2b-ee4e-4c43-b0b9-d17ff294397e,DISK], DatanodeInfoWithStorage[127.0.0.1:36298,DS-6d2a2df0-895e-4702-8af3-5db73c855183,DISK], DatanodeInfoWithStorage[127.0.0.1:43359,DS-69842e25-a996-4fc3-8ef5-e485571705ad,DISK], DatanodeInfoWithStorage[127.0.0.1:44927,DS-eb532536-a381-48b0-8d1d-4b5d6a0f1756,DISK], DatanodeInfoWithStorage[127.0.0.1:38596,DS-d61dc314-bb1f-45d0-b2ea-d2eea3e9d252,DISK], DatanodeInfoWithStorage[127.0.0.1:45468,DS-4f511957-0f12-4288-b8f8-c086d0b78158,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1566194977-172.17.0.9-1598323129927:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41674,DS-e2ab264d-9c14-4332-af9b-38966d503447,DISK], DatanodeInfoWithStorage[127.0.0.1:37074,DS-182c8ecb-bba7-4730-8e7e-73421cc96d14,DISK], DatanodeInfoWithStorage[127.0.0.1:33748,DS-daea9c2b-ee4e-4c43-b0b9-d17ff294397e,DISK], DatanodeInfoWithStorage[127.0.0.1:36298,DS-6d2a2df0-895e-4702-8af3-5db73c855183,DISK], DatanodeInfoWithStorage[127.0.0.1:43359,DS-69842e25-a996-4fc3-8ef5-e485571705ad,DISK], DatanodeInfoWithStorage[127.0.0.1:44927,DS-eb532536-a381-48b0-8d1d-4b5d6a0f1756,DISK], DatanodeInfoWithStorage[127.0.0.1:38596,DS-d61dc314-bb1f-45d0-b2ea-d2eea3e9d252,DISK], DatanodeInfoWithStorage[127.0.0.1:45468,DS-4f511957-0f12-4288-b8f8-c086d0b78158,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.name.dir.restore
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-483263760-172.17.0.9-1598323268726:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38118,DS-e6703640-01d9-4684-befa-22becce02f1e,DISK], DatanodeInfoWithStorage[127.0.0.1:41466,DS-c344e499-addb-4613-a5e5-9849239bb22f,DISK], DatanodeInfoWithStorage[127.0.0.1:32949,DS-a71c8088-a811-408c-9691-9f3d3371bca1,DISK], DatanodeInfoWithStorage[127.0.0.1:45073,DS-2c8f8a17-17c0-4c4a-9014-36f7eea8e392,DISK], DatanodeInfoWithStorage[127.0.0.1:33704,DS-41d77f02-5be2-478f-ab9d-13ae4639a687,DISK], DatanodeInfoWithStorage[127.0.0.1:44537,DS-d793aedf-19cb-445e-8afd-6965c727b3a1,DISK], DatanodeInfoWithStorage[127.0.0.1:37696,DS-3a2861f5-3a7a-4645-bd31-3ec91b9c31c6,DISK], DatanodeInfoWithStorage[127.0.0.1:44221,DS-cd11950e-4416-4fe1-ac28-0aeb6e642ee6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-483263760-172.17.0.9-1598323268726:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38118,DS-e6703640-01d9-4684-befa-22becce02f1e,DISK], DatanodeInfoWithStorage[127.0.0.1:41466,DS-c344e499-addb-4613-a5e5-9849239bb22f,DISK], DatanodeInfoWithStorage[127.0.0.1:32949,DS-a71c8088-a811-408c-9691-9f3d3371bca1,DISK], DatanodeInfoWithStorage[127.0.0.1:45073,DS-2c8f8a17-17c0-4c4a-9014-36f7eea8e392,DISK], DatanodeInfoWithStorage[127.0.0.1:33704,DS-41d77f02-5be2-478f-ab9d-13ae4639a687,DISK], DatanodeInfoWithStorage[127.0.0.1:44537,DS-d793aedf-19cb-445e-8afd-6965c727b3a1,DISK], DatanodeInfoWithStorage[127.0.0.1:37696,DS-3a2861f5-3a7a-4645-bd31-3ec91b9c31c6,DISK], DatanodeInfoWithStorage[127.0.0.1:44221,DS-cd11950e-4416-4fe1-ac28-0aeb6e642ee6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.name.dir.restore
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-178037059-172.17.0.9-1598323545841:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44644,DS-97e17675-6a63-4588-8953-54240e361597,DISK], DatanodeInfoWithStorage[127.0.0.1:33039,DS-537aa11f-44ca-4681-8c43-0f9eb7528773,DISK], DatanodeInfoWithStorage[127.0.0.1:32809,DS-4284b88b-6aa7-4424-aa7a-dd3fee5b550f,DISK], DatanodeInfoWithStorage[127.0.0.1:36825,DS-3520dbcd-c6a7-4bfe-8b3a-a541a0ddd199,DISK], DatanodeInfoWithStorage[127.0.0.1:37818,DS-feb1d4e5-904c-4bcc-b636-badd9d2bac79,DISK], DatanodeInfoWithStorage[127.0.0.1:40894,DS-91edb6cf-a1ad-4b10-9566-ba6181b0d0e4,DISK], DatanodeInfoWithStorage[127.0.0.1:44574,DS-69040cdf-4774-4ecf-b5a8-b0b90748d265,DISK], DatanodeInfoWithStorage[127.0.0.1:38878,DS-8ef486b9-4bc2-435b-bf70-002e5dc94822,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-178037059-172.17.0.9-1598323545841:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44644,DS-97e17675-6a63-4588-8953-54240e361597,DISK], DatanodeInfoWithStorage[127.0.0.1:33039,DS-537aa11f-44ca-4681-8c43-0f9eb7528773,DISK], DatanodeInfoWithStorage[127.0.0.1:32809,DS-4284b88b-6aa7-4424-aa7a-dd3fee5b550f,DISK], DatanodeInfoWithStorage[127.0.0.1:36825,DS-3520dbcd-c6a7-4bfe-8b3a-a541a0ddd199,DISK], DatanodeInfoWithStorage[127.0.0.1:37818,DS-feb1d4e5-904c-4bcc-b636-badd9d2bac79,DISK], DatanodeInfoWithStorage[127.0.0.1:40894,DS-91edb6cf-a1ad-4b10-9566-ba6181b0d0e4,DISK], DatanodeInfoWithStorage[127.0.0.1:44574,DS-69040cdf-4774-4ecf-b5a8-b0b90748d265,DISK], DatanodeInfoWithStorage[127.0.0.1:38878,DS-8ef486b9-4bc2-435b-bf70-002e5dc94822,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.name.dir.restore
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1837269153-172.17.0.9-1598323767182:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44727,DS-d75948d4-5faf-474e-906a-d5f059c0b144,DISK], DatanodeInfoWithStorage[127.0.0.1:36281,DS-98e1a6f4-4ccc-4167-825e-138febf19e93,DISK], DatanodeInfoWithStorage[127.0.0.1:41903,DS-19541fd8-9cb0-4f06-b704-08f3135b42ca,DISK], DatanodeInfoWithStorage[127.0.0.1:45552,DS-d50bd07a-791e-4f3b-8ebb-cb0b3230715e,DISK], DatanodeInfoWithStorage[127.0.0.1:43755,DS-3673232b-8234-4a94-b10f-51ea24e8eb26,DISK], DatanodeInfoWithStorage[127.0.0.1:36895,DS-06eeb6ef-7c95-4135-b7db-a7bc7a6ecdbc,DISK], DatanodeInfoWithStorage[127.0.0.1:41285,DS-accf3f04-a97d-4723-9a69-1e687ea86e2b,DISK], DatanodeInfoWithStorage[127.0.0.1:39122,DS-ebbb8c25-d390-45e5-9191-caff11ad92b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1837269153-172.17.0.9-1598323767182:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44727,DS-d75948d4-5faf-474e-906a-d5f059c0b144,DISK], DatanodeInfoWithStorage[127.0.0.1:36281,DS-98e1a6f4-4ccc-4167-825e-138febf19e93,DISK], DatanodeInfoWithStorage[127.0.0.1:41903,DS-19541fd8-9cb0-4f06-b704-08f3135b42ca,DISK], DatanodeInfoWithStorage[127.0.0.1:45552,DS-d50bd07a-791e-4f3b-8ebb-cb0b3230715e,DISK], DatanodeInfoWithStorage[127.0.0.1:43755,DS-3673232b-8234-4a94-b10f-51ea24e8eb26,DISK], DatanodeInfoWithStorage[127.0.0.1:36895,DS-06eeb6ef-7c95-4135-b7db-a7bc7a6ecdbc,DISK], DatanodeInfoWithStorage[127.0.0.1:41285,DS-accf3f04-a97d-4723-9a69-1e687ea86e2b,DISK], DatanodeInfoWithStorage[127.0.0.1:39122,DS-ebbb8c25-d390-45e5-9191-caff11ad92b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.name.dir.restore
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1443515930-172.17.0.9-1598323916092:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45575,DS-2afbb516-c52e-4cf9-9abf-3f09525be4b4,DISK], DatanodeInfoWithStorage[127.0.0.1:33788,DS-d1771b24-b73e-46df-92e9-ffa016240fd0,DISK], DatanodeInfoWithStorage[127.0.0.1:44795,DS-8f99c737-b15f-4c6d-8c5b-c3d11456d4cc,DISK], DatanodeInfoWithStorage[127.0.0.1:34528,DS-5ad84922-ca0e-459c-b212-26be8ce4c0e8,DISK], DatanodeInfoWithStorage[127.0.0.1:46022,DS-2b6b2e74-5d0d-436d-90e6-dcfae9b293d3,DISK], DatanodeInfoWithStorage[127.0.0.1:43535,DS-c45604a9-19df-4ae0-bce1-31249d6f3696,DISK], DatanodeInfoWithStorage[127.0.0.1:46779,DS-0772e798-a31a-4f82-8c65-71bdb31a780f,DISK], DatanodeInfoWithStorage[127.0.0.1:42395,DS-ce03fccf-7028-4be5-abc0-6558bfbd6c29,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1443515930-172.17.0.9-1598323916092:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45575,DS-2afbb516-c52e-4cf9-9abf-3f09525be4b4,DISK], DatanodeInfoWithStorage[127.0.0.1:33788,DS-d1771b24-b73e-46df-92e9-ffa016240fd0,DISK], DatanodeInfoWithStorage[127.0.0.1:44795,DS-8f99c737-b15f-4c6d-8c5b-c3d11456d4cc,DISK], DatanodeInfoWithStorage[127.0.0.1:34528,DS-5ad84922-ca0e-459c-b212-26be8ce4c0e8,DISK], DatanodeInfoWithStorage[127.0.0.1:46022,DS-2b6b2e74-5d0d-436d-90e6-dcfae9b293d3,DISK], DatanodeInfoWithStorage[127.0.0.1:43535,DS-c45604a9-19df-4ae0-bce1-31249d6f3696,DISK], DatanodeInfoWithStorage[127.0.0.1:46779,DS-0772e798-a31a-4f82-8c65-71bdb31a780f,DISK], DatanodeInfoWithStorage[127.0.0.1:42395,DS-ce03fccf-7028-4be5-abc0-6558bfbd6c29,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.name.dir.restore
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1822472589-172.17.0.9-1598324330126:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34011,DS-f32e0ecc-5d2e-4e20-896b-02319e27e443,DISK], DatanodeInfoWithStorage[127.0.0.1:41576,DS-d0312961-c6e7-40d8-a068-a8cc81023807,DISK], DatanodeInfoWithStorage[127.0.0.1:37221,DS-315adbe7-b118-4a1a-9d0b-328aef64ff00,DISK], DatanodeInfoWithStorage[127.0.0.1:42589,DS-c2348ffe-0553-4cab-9e1b-884300a3f218,DISK], DatanodeInfoWithStorage[127.0.0.1:45006,DS-8ef22e83-f907-4fe7-ba01-f3087b7135e5,DISK], DatanodeInfoWithStorage[127.0.0.1:40931,DS-9d171cba-6af8-478a-9d2b-fdfef0d1e38c,DISK], DatanodeInfoWithStorage[127.0.0.1:33106,DS-63348f36-3b7c-4ce3-9c66-c0a280dceab7,DISK], DatanodeInfoWithStorage[127.0.0.1:43878,DS-39982b01-07ee-48de-a315-0fd72248874e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1822472589-172.17.0.9-1598324330126:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34011,DS-f32e0ecc-5d2e-4e20-896b-02319e27e443,DISK], DatanodeInfoWithStorage[127.0.0.1:41576,DS-d0312961-c6e7-40d8-a068-a8cc81023807,DISK], DatanodeInfoWithStorage[127.0.0.1:37221,DS-315adbe7-b118-4a1a-9d0b-328aef64ff00,DISK], DatanodeInfoWithStorage[127.0.0.1:42589,DS-c2348ffe-0553-4cab-9e1b-884300a3f218,DISK], DatanodeInfoWithStorage[127.0.0.1:45006,DS-8ef22e83-f907-4fe7-ba01-f3087b7135e5,DISK], DatanodeInfoWithStorage[127.0.0.1:40931,DS-9d171cba-6af8-478a-9d2b-fdfef0d1e38c,DISK], DatanodeInfoWithStorage[127.0.0.1:33106,DS-63348f36-3b7c-4ce3-9c66-c0a280dceab7,DISK], DatanodeInfoWithStorage[127.0.0.1:43878,DS-39982b01-07ee-48de-a315-0fd72248874e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.name.dir.restore
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-676966709-172.17.0.9-1598324569974:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42616,DS-b3d94a6d-4c10-4bb8-a38b-10e6e909596c,DISK], DatanodeInfoWithStorage[127.0.0.1:46849,DS-5ba5ca61-364f-4a9d-90db-ce1f1f34bdf6,DISK], DatanodeInfoWithStorage[127.0.0.1:39975,DS-c53320f5-4434-4dd0-ac98-49d0ec65189a,DISK], DatanodeInfoWithStorage[127.0.0.1:37629,DS-b87799e4-523d-4f68-b5cd-8a27ddd3d98f,DISK], DatanodeInfoWithStorage[127.0.0.1:33498,DS-52045e55-0569-4d08-a77d-72be34eaab95,DISK], DatanodeInfoWithStorage[127.0.0.1:44341,DS-a6900cc6-61ea-4c1a-92be-6b89f07755cf,DISK], DatanodeInfoWithStorage[127.0.0.1:33909,DS-611f1e3b-17f1-45ee-8262-5614fcd040f7,DISK], DatanodeInfoWithStorage[127.0.0.1:40495,DS-09a5936b-b1dd-45e8-be6e-26e6df2fcb24,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-676966709-172.17.0.9-1598324569974:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42616,DS-b3d94a6d-4c10-4bb8-a38b-10e6e909596c,DISK], DatanodeInfoWithStorage[127.0.0.1:46849,DS-5ba5ca61-364f-4a9d-90db-ce1f1f34bdf6,DISK], DatanodeInfoWithStorage[127.0.0.1:39975,DS-c53320f5-4434-4dd0-ac98-49d0ec65189a,DISK], DatanodeInfoWithStorage[127.0.0.1:37629,DS-b87799e4-523d-4f68-b5cd-8a27ddd3d98f,DISK], DatanodeInfoWithStorage[127.0.0.1:33498,DS-52045e55-0569-4d08-a77d-72be34eaab95,DISK], DatanodeInfoWithStorage[127.0.0.1:44341,DS-a6900cc6-61ea-4c1a-92be-6b89f07755cf,DISK], DatanodeInfoWithStorage[127.0.0.1:33909,DS-611f1e3b-17f1-45ee-8262-5614fcd040f7,DISK], DatanodeInfoWithStorage[127.0.0.1:40495,DS-09a5936b-b1dd-45e8-be6e-26e6df2fcb24,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.name.dir.restore
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-113154628-172.17.0.9-1598324608860:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33771,DS-5f3e66c0-edaf-4b0a-b0ee-2f019db287c7,DISK], DatanodeInfoWithStorage[127.0.0.1:35783,DS-550646e1-a23a-4858-b933-ecd9ca59340e,DISK], DatanodeInfoWithStorage[127.0.0.1:35027,DS-1d453182-db9b-48b9-a2d4-20367d166204,DISK], DatanodeInfoWithStorage[127.0.0.1:44400,DS-879b6ebb-5339-4bb9-9c71-db6326f1fd1f,DISK], DatanodeInfoWithStorage[127.0.0.1:41714,DS-15c3ac2b-2b6f-4b9c-ba16-b3dfd574581e,DISK], DatanodeInfoWithStorage[127.0.0.1:37228,DS-9bc8e2fc-e045-403e-887c-fc4911de78c1,DISK], DatanodeInfoWithStorage[127.0.0.1:39129,DS-2cec4fbe-e3da-4f1b-898b-da67ce08c0a6,DISK], DatanodeInfoWithStorage[127.0.0.1:45745,DS-5a72edfd-2438-404c-ae86-95b7fb7122ea,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-113154628-172.17.0.9-1598324608860:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33771,DS-5f3e66c0-edaf-4b0a-b0ee-2f019db287c7,DISK], DatanodeInfoWithStorage[127.0.0.1:35783,DS-550646e1-a23a-4858-b933-ecd9ca59340e,DISK], DatanodeInfoWithStorage[127.0.0.1:35027,DS-1d453182-db9b-48b9-a2d4-20367d166204,DISK], DatanodeInfoWithStorage[127.0.0.1:44400,DS-879b6ebb-5339-4bb9-9c71-db6326f1fd1f,DISK], DatanodeInfoWithStorage[127.0.0.1:41714,DS-15c3ac2b-2b6f-4b9c-ba16-b3dfd574581e,DISK], DatanodeInfoWithStorage[127.0.0.1:37228,DS-9bc8e2fc-e045-403e-887c-fc4911de78c1,DISK], DatanodeInfoWithStorage[127.0.0.1:39129,DS-2cec4fbe-e3da-4f1b-898b-da67ce08c0a6,DISK], DatanodeInfoWithStorage[127.0.0.1:45745,DS-5a72edfd-2438-404c-ae86-95b7fb7122ea,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.name.dir.restore
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-320578945-172.17.0.9-1598324926339:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43946,DS-5cc9c851-da75-4e91-94cc-648737130ca7,DISK], DatanodeInfoWithStorage[127.0.0.1:35556,DS-5f8562d3-8af2-4f81-b929-fd6e01af709b,DISK], DatanodeInfoWithStorage[127.0.0.1:46169,DS-b7736f45-8e2c-45d6-9fe9-9e1df27e5e59,DISK], DatanodeInfoWithStorage[127.0.0.1:46131,DS-668630b1-dc79-460a-9158-1916e1357afa,DISK], DatanodeInfoWithStorage[127.0.0.1:35097,DS-e5c67ff4-e5fa-4058-9c8b-afb05cd4c667,DISK], DatanodeInfoWithStorage[127.0.0.1:35385,DS-d1116122-f36a-4b55-945e-cbbc084fb4af,DISK], DatanodeInfoWithStorage[127.0.0.1:38242,DS-0065c18c-71d7-4f5d-bb5e-55f29f61b570,DISK], DatanodeInfoWithStorage[127.0.0.1:34695,DS-9a0c339d-7926-4e9b-8913-88df931f4703,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-320578945-172.17.0.9-1598324926339:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43946,DS-5cc9c851-da75-4e91-94cc-648737130ca7,DISK], DatanodeInfoWithStorage[127.0.0.1:35556,DS-5f8562d3-8af2-4f81-b929-fd6e01af709b,DISK], DatanodeInfoWithStorage[127.0.0.1:46169,DS-b7736f45-8e2c-45d6-9fe9-9e1df27e5e59,DISK], DatanodeInfoWithStorage[127.0.0.1:46131,DS-668630b1-dc79-460a-9158-1916e1357afa,DISK], DatanodeInfoWithStorage[127.0.0.1:35097,DS-e5c67ff4-e5fa-4058-9c8b-afb05cd4c667,DISK], DatanodeInfoWithStorage[127.0.0.1:35385,DS-d1116122-f36a-4b55-945e-cbbc084fb4af,DISK], DatanodeInfoWithStorage[127.0.0.1:38242,DS-0065c18c-71d7-4f5d-bb5e-55f29f61b570,DISK], DatanodeInfoWithStorage[127.0.0.1:34695,DS-9a0c339d-7926-4e9b-8913-88df931f4703,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.name.dir.restore
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2006477050-172.17.0.9-1598325008912:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42133,DS-bf457e88-ee13-4237-9314-cd8bc5564712,DISK], DatanodeInfoWithStorage[127.0.0.1:37753,DS-5b3b328d-39e4-4f86-82ad-035d8edd1e7b,DISK], DatanodeInfoWithStorage[127.0.0.1:44765,DS-e8fd081e-8ff4-498c-9d03-d09f161c5a9f,DISK], DatanodeInfoWithStorage[127.0.0.1:36204,DS-45704d4d-fdc0-4dee-bcb9-048c45c4bc65,DISK], DatanodeInfoWithStorage[127.0.0.1:36524,DS-25e3b8a2-695e-45c4-89a1-6948c4aeb1fd,DISK], DatanodeInfoWithStorage[127.0.0.1:37658,DS-30afddde-4a3b-4843-9485-f68dfb5e52b9,DISK], DatanodeInfoWithStorage[127.0.0.1:36760,DS-5c9d9e58-cc44-4936-8fd4-f90f575f41b7,DISK], DatanodeInfoWithStorage[127.0.0.1:37226,DS-1f52f33a-f562-4d37-ae28-5d35fc2f9275,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2006477050-172.17.0.9-1598325008912:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42133,DS-bf457e88-ee13-4237-9314-cd8bc5564712,DISK], DatanodeInfoWithStorage[127.0.0.1:37753,DS-5b3b328d-39e4-4f86-82ad-035d8edd1e7b,DISK], DatanodeInfoWithStorage[127.0.0.1:44765,DS-e8fd081e-8ff4-498c-9d03-d09f161c5a9f,DISK], DatanodeInfoWithStorage[127.0.0.1:36204,DS-45704d4d-fdc0-4dee-bcb9-048c45c4bc65,DISK], DatanodeInfoWithStorage[127.0.0.1:36524,DS-25e3b8a2-695e-45c4-89a1-6948c4aeb1fd,DISK], DatanodeInfoWithStorage[127.0.0.1:37658,DS-30afddde-4a3b-4843-9485-f68dfb5e52b9,DISK], DatanodeInfoWithStorage[127.0.0.1:36760,DS-5c9d9e58-cc44-4936-8fd4-f90f575f41b7,DISK], DatanodeInfoWithStorage[127.0.0.1:37226,DS-1f52f33a-f562-4d37-ae28-5d35fc2f9275,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.name.dir.restore
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-796559591-172.17.0.9-1598325355496:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33527,DS-2ecbdb2b-4210-468c-97f5-3ab69977953b,DISK], DatanodeInfoWithStorage[127.0.0.1:35241,DS-2e3753a8-9893-4585-a839-3634afa19b4e,DISK], DatanodeInfoWithStorage[127.0.0.1:46117,DS-87425ca8-48cb-4b00-812c-7362858c815c,DISK], DatanodeInfoWithStorage[127.0.0.1:43733,DS-2dcfa074-9ae4-48e1-9d03-f47a893fdec8,DISK], DatanodeInfoWithStorage[127.0.0.1:32803,DS-9f93a829-9cbc-41eb-87f3-92d1b1e6c828,DISK], DatanodeInfoWithStorage[127.0.0.1:35583,DS-d4ef105d-3a19-4e8e-b3c5-1b46edf12740,DISK], DatanodeInfoWithStorage[127.0.0.1:40342,DS-c0003c68-429e-40ee-a32e-59fe3e829821,DISK], DatanodeInfoWithStorage[127.0.0.1:34380,DS-6c39c242-2511-4cd1-8299-6950ecedfb2c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-796559591-172.17.0.9-1598325355496:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33527,DS-2ecbdb2b-4210-468c-97f5-3ab69977953b,DISK], DatanodeInfoWithStorage[127.0.0.1:35241,DS-2e3753a8-9893-4585-a839-3634afa19b4e,DISK], DatanodeInfoWithStorage[127.0.0.1:46117,DS-87425ca8-48cb-4b00-812c-7362858c815c,DISK], DatanodeInfoWithStorage[127.0.0.1:43733,DS-2dcfa074-9ae4-48e1-9d03-f47a893fdec8,DISK], DatanodeInfoWithStorage[127.0.0.1:32803,DS-9f93a829-9cbc-41eb-87f3-92d1b1e6c828,DISK], DatanodeInfoWithStorage[127.0.0.1:35583,DS-d4ef105d-3a19-4e8e-b3c5-1b46edf12740,DISK], DatanodeInfoWithStorage[127.0.0.1:40342,DS-c0003c68-429e-40ee-a32e-59fe3e829821,DISK], DatanodeInfoWithStorage[127.0.0.1:34380,DS-6c39c242-2511-4cd1-8299-6950ecedfb2c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.name.dir.restore
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-755205781-172.17.0.9-1598325396131:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36945,DS-3aba0e5c-7a1a-46a6-902f-aa7fc10e1f1e,DISK], DatanodeInfoWithStorage[127.0.0.1:36646,DS-e4165e2c-f508-42af-babf-f776fc379b47,DISK], DatanodeInfoWithStorage[127.0.0.1:45983,DS-bc9a09cb-06bc-4c1e-bd9d-65478776809a,DISK], DatanodeInfoWithStorage[127.0.0.1:46790,DS-184c2525-a2b5-4f80-9cdd-e362ffed0e2f,DISK], DatanodeInfoWithStorage[127.0.0.1:37962,DS-a46bc223-c7eb-4362-ba71-db9cded97dce,DISK], DatanodeInfoWithStorage[127.0.0.1:32936,DS-62898db0-7c00-4b46-a545-2f5d716b99ae,DISK], DatanodeInfoWithStorage[127.0.0.1:34296,DS-d9250a7a-9e80-4b01-8a83-00e9061567a8,DISK], DatanodeInfoWithStorage[127.0.0.1:34437,DS-7fc0f1c8-5aa7-4c36-94fb-aa2339eaabc1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-755205781-172.17.0.9-1598325396131:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36945,DS-3aba0e5c-7a1a-46a6-902f-aa7fc10e1f1e,DISK], DatanodeInfoWithStorage[127.0.0.1:36646,DS-e4165e2c-f508-42af-babf-f776fc379b47,DISK], DatanodeInfoWithStorage[127.0.0.1:45983,DS-bc9a09cb-06bc-4c1e-bd9d-65478776809a,DISK], DatanodeInfoWithStorage[127.0.0.1:46790,DS-184c2525-a2b5-4f80-9cdd-e362ffed0e2f,DISK], DatanodeInfoWithStorage[127.0.0.1:37962,DS-a46bc223-c7eb-4362-ba71-db9cded97dce,DISK], DatanodeInfoWithStorage[127.0.0.1:32936,DS-62898db0-7c00-4b46-a545-2f5d716b99ae,DISK], DatanodeInfoWithStorage[127.0.0.1:34296,DS-d9250a7a-9e80-4b01-8a83-00e9061567a8,DISK], DatanodeInfoWithStorage[127.0.0.1:34437,DS-7fc0f1c8-5aa7-4c36-94fb-aa2339eaabc1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.name.dir.restore
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2014091961-172.17.0.9-1598325512391:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43223,DS-820b4f27-f084-4a81-9e36-2d2b1e2917da,DISK], DatanodeInfoWithStorage[127.0.0.1:46370,DS-17efd3a7-584b-415b-b0e2-3389806f1bdc,DISK], DatanodeInfoWithStorage[127.0.0.1:41036,DS-d51888bb-6c4a-4abe-ae33-8f36db9a50a4,DISK], DatanodeInfoWithStorage[127.0.0.1:37907,DS-575ae86b-a035-4c84-a1f2-3d7f9d3cda47,DISK], DatanodeInfoWithStorage[127.0.0.1:44944,DS-87844f50-7ce6-474b-bc1f-f49d58f5df43,DISK], DatanodeInfoWithStorage[127.0.0.1:44002,DS-2880d985-7bec-469d-ab49-e612e71e9b1f,DISK], DatanodeInfoWithStorage[127.0.0.1:43744,DS-533b8ce7-a83f-487f-8f5d-283691007086,DISK], DatanodeInfoWithStorage[127.0.0.1:35765,DS-fbfe17c8-5e85-489e-84f0-e61cfbb02da2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2014091961-172.17.0.9-1598325512391:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43223,DS-820b4f27-f084-4a81-9e36-2d2b1e2917da,DISK], DatanodeInfoWithStorage[127.0.0.1:46370,DS-17efd3a7-584b-415b-b0e2-3389806f1bdc,DISK], DatanodeInfoWithStorage[127.0.0.1:41036,DS-d51888bb-6c4a-4abe-ae33-8f36db9a50a4,DISK], DatanodeInfoWithStorage[127.0.0.1:37907,DS-575ae86b-a035-4c84-a1f2-3d7f9d3cda47,DISK], DatanodeInfoWithStorage[127.0.0.1:44944,DS-87844f50-7ce6-474b-bc1f-f49d58f5df43,DISK], DatanodeInfoWithStorage[127.0.0.1:44002,DS-2880d985-7bec-469d-ab49-e612e71e9b1f,DISK], DatanodeInfoWithStorage[127.0.0.1:43744,DS-533b8ce7-a83f-487f-8f5d-283691007086,DISK], DatanodeInfoWithStorage[127.0.0.1:35765,DS-fbfe17c8-5e85-489e-84f0-e61cfbb02da2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.name.dir.restore
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-714824620-172.17.0.9-1598325802445:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40769,DS-7e8fa45a-baf4-4aad-bdde-3177cd9b4727,DISK], DatanodeInfoWithStorage[127.0.0.1:40155,DS-b6eb110b-6764-4cfc-81ce-3a31e48c14db,DISK], DatanodeInfoWithStorage[127.0.0.1:33060,DS-6ff32ccc-f040-4b2f-83bc-6dd15f269b47,DISK], DatanodeInfoWithStorage[127.0.0.1:36555,DS-20f7f8f0-0708-4340-b26e-c17e23de781a,DISK], DatanodeInfoWithStorage[127.0.0.1:43275,DS-809abf59-0707-43f4-a921-fd283ae276f5,DISK], DatanodeInfoWithStorage[127.0.0.1:40463,DS-e824fbdb-c152-4a08-8d25-36f827b8ae97,DISK], DatanodeInfoWithStorage[127.0.0.1:37221,DS-13da6937-9d0d-42a3-8f85-bb578158234d,DISK], DatanodeInfoWithStorage[127.0.0.1:35138,DS-7829224f-b688-4d80-8be4-3c8e30beb0e9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-714824620-172.17.0.9-1598325802445:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40769,DS-7e8fa45a-baf4-4aad-bdde-3177cd9b4727,DISK], DatanodeInfoWithStorage[127.0.0.1:40155,DS-b6eb110b-6764-4cfc-81ce-3a31e48c14db,DISK], DatanodeInfoWithStorage[127.0.0.1:33060,DS-6ff32ccc-f040-4b2f-83bc-6dd15f269b47,DISK], DatanodeInfoWithStorage[127.0.0.1:36555,DS-20f7f8f0-0708-4340-b26e-c17e23de781a,DISK], DatanodeInfoWithStorage[127.0.0.1:43275,DS-809abf59-0707-43f4-a921-fd283ae276f5,DISK], DatanodeInfoWithStorage[127.0.0.1:40463,DS-e824fbdb-c152-4a08-8d25-36f827b8ae97,DISK], DatanodeInfoWithStorage[127.0.0.1:37221,DS-13da6937-9d0d-42a3-8f85-bb578158234d,DISK], DatanodeInfoWithStorage[127.0.0.1:35138,DS-7829224f-b688-4d80-8be4-3c8e30beb0e9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.name.dir.restore
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-8822350-172.17.0.9-1598325842632:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36341,DS-0d211dfb-3548-4c3a-a091-9806942f23d1,DISK], DatanodeInfoWithStorage[127.0.0.1:46194,DS-a7aefdc9-cb31-40ca-be3c-3d0c09ff8b85,DISK], DatanodeInfoWithStorage[127.0.0.1:37049,DS-58cef9ee-be50-43e2-b55d-391385ce77c7,DISK], DatanodeInfoWithStorage[127.0.0.1:33610,DS-60bdd635-8f48-426c-bdaf-c84a3039c7ea,DISK], DatanodeInfoWithStorage[127.0.0.1:34417,DS-405a8fa1-3d49-48b7-a0af-d274840f735f,DISK], DatanodeInfoWithStorage[127.0.0.1:44015,DS-538f4ac5-b409-4b13-bf81-095cd2d1d4d7,DISK], DatanodeInfoWithStorage[127.0.0.1:46577,DS-be3a353b-fa63-463a-9fbf-9bfe444aafbd,DISK], DatanodeInfoWithStorage[127.0.0.1:36926,DS-677ffbc9-156a-4162-808f-b6647a0dcf1f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-8822350-172.17.0.9-1598325842632:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36341,DS-0d211dfb-3548-4c3a-a091-9806942f23d1,DISK], DatanodeInfoWithStorage[127.0.0.1:46194,DS-a7aefdc9-cb31-40ca-be3c-3d0c09ff8b85,DISK], DatanodeInfoWithStorage[127.0.0.1:37049,DS-58cef9ee-be50-43e2-b55d-391385ce77c7,DISK], DatanodeInfoWithStorage[127.0.0.1:33610,DS-60bdd635-8f48-426c-bdaf-c84a3039c7ea,DISK], DatanodeInfoWithStorage[127.0.0.1:34417,DS-405a8fa1-3d49-48b7-a0af-d274840f735f,DISK], DatanodeInfoWithStorage[127.0.0.1:44015,DS-538f4ac5-b409-4b13-bf81-095cd2d1d4d7,DISK], DatanodeInfoWithStorage[127.0.0.1:46577,DS-be3a353b-fa63-463a-9fbf-9bfe444aafbd,DISK], DatanodeInfoWithStorage[127.0.0.1:36926,DS-677ffbc9-156a-4162-808f-b6647a0dcf1f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.name.dir.restore
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-132126192-172.17.0.9-1598325881434:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44527,DS-5efe4cbf-ae67-49a7-a2b2-f8c756e59e22,DISK], DatanodeInfoWithStorage[127.0.0.1:38822,DS-8ba35cc7-5ba6-4649-a7f7-0672ae94c004,DISK], DatanodeInfoWithStorage[127.0.0.1:37919,DS-932cdbc5-3176-42d3-857d-ccb05b49d4cb,DISK], DatanodeInfoWithStorage[127.0.0.1:36804,DS-88143124-e56f-435a-a6ed-25024c23f4b1,DISK], DatanodeInfoWithStorage[127.0.0.1:45563,DS-9a87dbcb-722a-4b83-a7d2-b6a2b4321469,DISK], DatanodeInfoWithStorage[127.0.0.1:44229,DS-d9686799-cb57-4af3-8afa-cc974fe9c6ef,DISK], DatanodeInfoWithStorage[127.0.0.1:41138,DS-9d935d2e-e7fd-4941-b8ef-195c60805aae,DISK], DatanodeInfoWithStorage[127.0.0.1:39572,DS-3a82d666-311b-48a2-8732-7a824ea4deb3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-132126192-172.17.0.9-1598325881434:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44527,DS-5efe4cbf-ae67-49a7-a2b2-f8c756e59e22,DISK], DatanodeInfoWithStorage[127.0.0.1:38822,DS-8ba35cc7-5ba6-4649-a7f7-0672ae94c004,DISK], DatanodeInfoWithStorage[127.0.0.1:37919,DS-932cdbc5-3176-42d3-857d-ccb05b49d4cb,DISK], DatanodeInfoWithStorage[127.0.0.1:36804,DS-88143124-e56f-435a-a6ed-25024c23f4b1,DISK], DatanodeInfoWithStorage[127.0.0.1:45563,DS-9a87dbcb-722a-4b83-a7d2-b6a2b4321469,DISK], DatanodeInfoWithStorage[127.0.0.1:44229,DS-d9686799-cb57-4af3-8afa-cc974fe9c6ef,DISK], DatanodeInfoWithStorage[127.0.0.1:41138,DS-9d935d2e-e7fd-4941-b8ef-195c60805aae,DISK], DatanodeInfoWithStorage[127.0.0.1:39572,DS-3a82d666-311b-48a2-8732-7a824ea4deb3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.name.dir.restore
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1463503872-172.17.0.9-1598325955101:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41575,DS-54371afc-6ada-4508-a1f6-92f4a3f44207,DISK], DatanodeInfoWithStorage[127.0.0.1:42210,DS-8b8ad019-162d-4a19-87db-41e4296aac33,DISK], DatanodeInfoWithStorage[127.0.0.1:37845,DS-4bba7926-96a6-4a99-9768-647543e27487,DISK], DatanodeInfoWithStorage[127.0.0.1:38242,DS-0dbc4c6d-f4f8-4250-9d1b-da4cf2c22bd6,DISK], DatanodeInfoWithStorage[127.0.0.1:43173,DS-4799fb3b-2714-4ccc-9430-f6b1c6b399c5,DISK], DatanodeInfoWithStorage[127.0.0.1:35135,DS-e8b8c964-e57a-4df1-b4b7-1808f8f08e54,DISK], DatanodeInfoWithStorage[127.0.0.1:45171,DS-9e37911b-855d-421f-bffc-5ef065d0f480,DISK], DatanodeInfoWithStorage[127.0.0.1:35354,DS-5b10eb40-d760-4f9b-ab1d-4a9b52bd6041,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1463503872-172.17.0.9-1598325955101:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41575,DS-54371afc-6ada-4508-a1f6-92f4a3f44207,DISK], DatanodeInfoWithStorage[127.0.0.1:42210,DS-8b8ad019-162d-4a19-87db-41e4296aac33,DISK], DatanodeInfoWithStorage[127.0.0.1:37845,DS-4bba7926-96a6-4a99-9768-647543e27487,DISK], DatanodeInfoWithStorage[127.0.0.1:38242,DS-0dbc4c6d-f4f8-4250-9d1b-da4cf2c22bd6,DISK], DatanodeInfoWithStorage[127.0.0.1:43173,DS-4799fb3b-2714-4ccc-9430-f6b1c6b399c5,DISK], DatanodeInfoWithStorage[127.0.0.1:35135,DS-e8b8c964-e57a-4df1-b4b7-1808f8f08e54,DISK], DatanodeInfoWithStorage[127.0.0.1:45171,DS-9e37911b-855d-421f-bffc-5ef065d0f480,DISK], DatanodeInfoWithStorage[127.0.0.1:35354,DS-5b10eb40-d760-4f9b-ab1d-4a9b52bd6041,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.name.dir.restore
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-84938110-172.17.0.9-1598326225524:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45295,DS-0badecfc-2ad7-48cb-a52c-38f6e700f052,DISK], DatanodeInfoWithStorage[127.0.0.1:36750,DS-7b9beb10-dd8a-45c8-9609-1df698785363,DISK], DatanodeInfoWithStorage[127.0.0.1:36264,DS-b95708d8-1207-4a25-a002-fae4cd51212a,DISK], DatanodeInfoWithStorage[127.0.0.1:46125,DS-4d8d5839-3bca-442e-a5e9-2563ede773cd,DISK], DatanodeInfoWithStorage[127.0.0.1:43699,DS-b8a5703d-01c7-4b76-a77c-7a1627042681,DISK], DatanodeInfoWithStorage[127.0.0.1:34192,DS-93dadad5-54bb-441b-be24-abb9c08c426a,DISK], DatanodeInfoWithStorage[127.0.0.1:44835,DS-ce74a29e-927a-477c-8896-b925395ab86e,DISK], DatanodeInfoWithStorage[127.0.0.1:34759,DS-dacd757b-ba04-4afe-9cec-3040ca66501e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-84938110-172.17.0.9-1598326225524:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45295,DS-0badecfc-2ad7-48cb-a52c-38f6e700f052,DISK], DatanodeInfoWithStorage[127.0.0.1:36750,DS-7b9beb10-dd8a-45c8-9609-1df698785363,DISK], DatanodeInfoWithStorage[127.0.0.1:36264,DS-b95708d8-1207-4a25-a002-fae4cd51212a,DISK], DatanodeInfoWithStorage[127.0.0.1:46125,DS-4d8d5839-3bca-442e-a5e9-2563ede773cd,DISK], DatanodeInfoWithStorage[127.0.0.1:43699,DS-b8a5703d-01c7-4b76-a77c-7a1627042681,DISK], DatanodeInfoWithStorage[127.0.0.1:34192,DS-93dadad5-54bb-441b-be24-abb9c08c426a,DISK], DatanodeInfoWithStorage[127.0.0.1:44835,DS-ce74a29e-927a-477c-8896-b925395ab86e,DISK], DatanodeInfoWithStorage[127.0.0.1:34759,DS-dacd757b-ba04-4afe-9cec-3040ca66501e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.name.dir.restore
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1939016892-172.17.0.9-1598326359112:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39256,DS-e9db6618-55d2-475c-907a-c3415428d0b7,DISK], DatanodeInfoWithStorage[127.0.0.1:34972,DS-dac9be49-9811-41d1-b8b6-a6159b087726,DISK], DatanodeInfoWithStorage[127.0.0.1:45259,DS-caf6cee2-5c3b-48be-a2c3-52c81ec423d5,DISK], DatanodeInfoWithStorage[127.0.0.1:43232,DS-0bcaefdf-5b1b-4bf2-9549-daa895e129d0,DISK], DatanodeInfoWithStorage[127.0.0.1:34871,DS-0d4845f8-843d-4d66-98f4-17232c3e05f2,DISK], DatanodeInfoWithStorage[127.0.0.1:41805,DS-ebd664af-05c3-40a9-9343-ea558d9f4a85,DISK], DatanodeInfoWithStorage[127.0.0.1:38214,DS-d4cb6778-34c4-4352-9161-c80b3c2f9da6,DISK], DatanodeInfoWithStorage[127.0.0.1:41453,DS-217b20bf-7f0b-4317-8dbb-7021aedfde1e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1939016892-172.17.0.9-1598326359112:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39256,DS-e9db6618-55d2-475c-907a-c3415428d0b7,DISK], DatanodeInfoWithStorage[127.0.0.1:34972,DS-dac9be49-9811-41d1-b8b6-a6159b087726,DISK], DatanodeInfoWithStorage[127.0.0.1:45259,DS-caf6cee2-5c3b-48be-a2c3-52c81ec423d5,DISK], DatanodeInfoWithStorage[127.0.0.1:43232,DS-0bcaefdf-5b1b-4bf2-9549-daa895e129d0,DISK], DatanodeInfoWithStorage[127.0.0.1:34871,DS-0d4845f8-843d-4d66-98f4-17232c3e05f2,DISK], DatanodeInfoWithStorage[127.0.0.1:41805,DS-ebd664af-05c3-40a9-9343-ea558d9f4a85,DISK], DatanodeInfoWithStorage[127.0.0.1:38214,DS-d4cb6778-34c4-4352-9161-c80b3c2f9da6,DISK], DatanodeInfoWithStorage[127.0.0.1:41453,DS-217b20bf-7f0b-4317-8dbb-7021aedfde1e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.name.dir.restore
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-696914688-172.17.0.9-1598326428555:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35040,DS-4977ee41-fdac-4fd7-92c8-66deb63df566,DISK], DatanodeInfoWithStorage[127.0.0.1:39419,DS-120a313e-7c2e-471a-8b76-8eb76154e13b,DISK], DatanodeInfoWithStorage[127.0.0.1:37809,DS-4a13d706-25a7-48d9-802b-0146faef71e1,DISK], DatanodeInfoWithStorage[127.0.0.1:33707,DS-bca6161d-3612-4870-81d8-df2a0352b998,DISK], DatanodeInfoWithStorage[127.0.0.1:33071,DS-7648c64e-8468-41c0-844c-464ee10c104e,DISK], DatanodeInfoWithStorage[127.0.0.1:36329,DS-8240706f-8472-471f-bf8e-6926f75acc3d,DISK], DatanodeInfoWithStorage[127.0.0.1:45470,DS-94b817ef-391a-4832-b8cf-b8467ae89c59,DISK], DatanodeInfoWithStorage[127.0.0.1:38345,DS-cd50581f-4394-4ce6-b305-476bbb28eb0b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-696914688-172.17.0.9-1598326428555:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35040,DS-4977ee41-fdac-4fd7-92c8-66deb63df566,DISK], DatanodeInfoWithStorage[127.0.0.1:39419,DS-120a313e-7c2e-471a-8b76-8eb76154e13b,DISK], DatanodeInfoWithStorage[127.0.0.1:37809,DS-4a13d706-25a7-48d9-802b-0146faef71e1,DISK], DatanodeInfoWithStorage[127.0.0.1:33707,DS-bca6161d-3612-4870-81d8-df2a0352b998,DISK], DatanodeInfoWithStorage[127.0.0.1:33071,DS-7648c64e-8468-41c0-844c-464ee10c104e,DISK], DatanodeInfoWithStorage[127.0.0.1:36329,DS-8240706f-8472-471f-bf8e-6926f75acc3d,DISK], DatanodeInfoWithStorage[127.0.0.1:45470,DS-94b817ef-391a-4832-b8cf-b8467ae89c59,DISK], DatanodeInfoWithStorage[127.0.0.1:38345,DS-cd50581f-4394-4ce6-b305-476bbb28eb0b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.name.dir.restore
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1912141500-172.17.0.9-1598326494640:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38460,DS-60a3959e-29df-435a-9700-0c11ce4da50e,DISK], DatanodeInfoWithStorage[127.0.0.1:36918,DS-109fe0ed-048a-4db6-b3a0-59909da221b7,DISK], DatanodeInfoWithStorage[127.0.0.1:42380,DS-917d5240-8fb9-43ca-a08b-848ef0869f42,DISK], DatanodeInfoWithStorage[127.0.0.1:42182,DS-a09c3f47-3dd9-4cf0-83a6-7c35866fdc15,DISK], DatanodeInfoWithStorage[127.0.0.1:36579,DS-be2d10d9-a99f-41d8-b70c-a77e787e42f4,DISK], DatanodeInfoWithStorage[127.0.0.1:38158,DS-7e82567d-5a79-4fbe-bdca-4236a8021591,DISK], DatanodeInfoWithStorage[127.0.0.1:35794,DS-80683a84-755b-427b-b7e9-42ec2253d544,DISK], DatanodeInfoWithStorage[127.0.0.1:44655,DS-9dd9005d-ed55-4d2d-b61d-108eff2f1381,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1912141500-172.17.0.9-1598326494640:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38460,DS-60a3959e-29df-435a-9700-0c11ce4da50e,DISK], DatanodeInfoWithStorage[127.0.0.1:36918,DS-109fe0ed-048a-4db6-b3a0-59909da221b7,DISK], DatanodeInfoWithStorage[127.0.0.1:42380,DS-917d5240-8fb9-43ca-a08b-848ef0869f42,DISK], DatanodeInfoWithStorage[127.0.0.1:42182,DS-a09c3f47-3dd9-4cf0-83a6-7c35866fdc15,DISK], DatanodeInfoWithStorage[127.0.0.1:36579,DS-be2d10d9-a99f-41d8-b70c-a77e787e42f4,DISK], DatanodeInfoWithStorage[127.0.0.1:38158,DS-7e82567d-5a79-4fbe-bdca-4236a8021591,DISK], DatanodeInfoWithStorage[127.0.0.1:35794,DS-80683a84-755b-427b-b7e9-42ec2253d544,DISK], DatanodeInfoWithStorage[127.0.0.1:44655,DS-9dd9005d-ed55-4d2d-b61d-108eff2f1381,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.name.dir.restore
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-723181994-172.17.0.9-1598326846398:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41762,DS-b700f6aa-fc0d-40e6-9342-60d51e1c4dd4,DISK], DatanodeInfoWithStorage[127.0.0.1:45424,DS-05d5025e-7894-4263-9376-ae093486e571,DISK], DatanodeInfoWithStorage[127.0.0.1:42013,DS-f26ff45e-8e16-4638-a682-e0d831d2c9af,DISK], DatanodeInfoWithStorage[127.0.0.1:36907,DS-a010ef5a-ec31-40a1-941b-a0c50a78f4f9,DISK], DatanodeInfoWithStorage[127.0.0.1:44976,DS-ee1029a2-0487-4b61-9c3c-489b492d9960,DISK], DatanodeInfoWithStorage[127.0.0.1:33729,DS-10a804ec-98ea-4420-941b-dec5e3a20fea,DISK], DatanodeInfoWithStorage[127.0.0.1:34970,DS-06336923-5a9a-43b3-be82-6de3c0380051,DISK], DatanodeInfoWithStorage[127.0.0.1:40563,DS-2cb28dd9-2c36-4855-af53-5615237e550c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-723181994-172.17.0.9-1598326846398:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41762,DS-b700f6aa-fc0d-40e6-9342-60d51e1c4dd4,DISK], DatanodeInfoWithStorage[127.0.0.1:45424,DS-05d5025e-7894-4263-9376-ae093486e571,DISK], DatanodeInfoWithStorage[127.0.0.1:42013,DS-f26ff45e-8e16-4638-a682-e0d831d2c9af,DISK], DatanodeInfoWithStorage[127.0.0.1:36907,DS-a010ef5a-ec31-40a1-941b-a0c50a78f4f9,DISK], DatanodeInfoWithStorage[127.0.0.1:44976,DS-ee1029a2-0487-4b61-9c3c-489b492d9960,DISK], DatanodeInfoWithStorage[127.0.0.1:33729,DS-10a804ec-98ea-4420-941b-dec5e3a20fea,DISK], DatanodeInfoWithStorage[127.0.0.1:34970,DS-06336923-5a9a-43b3-be82-6de3c0380051,DISK], DatanodeInfoWithStorage[127.0.0.1:40563,DS-2cb28dd9-2c36-4855-af53-5615237e550c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.name.dir.restore
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-283171921-172.17.0.9-1598327214455:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34244,DS-a89e0e74-0a24-4109-a755-b4ee04214913,DISK], DatanodeInfoWithStorage[127.0.0.1:37239,DS-12aeb5d1-09a5-4ce0-a2bb-3d5645aec5b3,DISK], DatanodeInfoWithStorage[127.0.0.1:45167,DS-c39df7cd-b340-4599-84b9-7b8f02de2301,DISK], DatanodeInfoWithStorage[127.0.0.1:39506,DS-c898047f-d433-4aef-b67f-78323c3e5f5e,DISK], DatanodeInfoWithStorage[127.0.0.1:36385,DS-19272b2a-6fe8-41f6-9450-a17961cb3ad4,DISK], DatanodeInfoWithStorage[127.0.0.1:43313,DS-56ead250-09e1-4679-ada1-949b57138711,DISK], DatanodeInfoWithStorage[127.0.0.1:33299,DS-b1643946-36a1-4bb3-a1a2-77270e6cca13,DISK], DatanodeInfoWithStorage[127.0.0.1:42185,DS-9a6399cb-e25a-43b6-9a79-8ede815a5890,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-283171921-172.17.0.9-1598327214455:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34244,DS-a89e0e74-0a24-4109-a755-b4ee04214913,DISK], DatanodeInfoWithStorage[127.0.0.1:37239,DS-12aeb5d1-09a5-4ce0-a2bb-3d5645aec5b3,DISK], DatanodeInfoWithStorage[127.0.0.1:45167,DS-c39df7cd-b340-4599-84b9-7b8f02de2301,DISK], DatanodeInfoWithStorage[127.0.0.1:39506,DS-c898047f-d433-4aef-b67f-78323c3e5f5e,DISK], DatanodeInfoWithStorage[127.0.0.1:36385,DS-19272b2a-6fe8-41f6-9450-a17961cb3ad4,DISK], DatanodeInfoWithStorage[127.0.0.1:43313,DS-56ead250-09e1-4679-ada1-949b57138711,DISK], DatanodeInfoWithStorage[127.0.0.1:33299,DS-b1643946-36a1-4bb3-a1a2-77270e6cca13,DISK], DatanodeInfoWithStorage[127.0.0.1:42185,DS-9a6399cb-e25a-43b6-9a79-8ede815a5890,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.name.dir.restore
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1283448180-172.17.0.9-1598327274630:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34954,DS-378edbac-6af9-486a-bc04-b32681396de9,DISK], DatanodeInfoWithStorage[127.0.0.1:39764,DS-fae4ab2c-06cd-41bf-8dd7-f81facf639a9,DISK], DatanodeInfoWithStorage[127.0.0.1:45539,DS-74e8b40b-9aa9-49ed-b581-71de7cd67b7d,DISK], DatanodeInfoWithStorage[127.0.0.1:39278,DS-4e0cddc3-d9d9-404b-8cae-ee31a3ef51a8,DISK], DatanodeInfoWithStorage[127.0.0.1:43488,DS-36507811-040f-4378-be96-73285841f2ea,DISK], DatanodeInfoWithStorage[127.0.0.1:34250,DS-7c92a6c6-a93f-4439-a474-4134c64719c7,DISK], DatanodeInfoWithStorage[127.0.0.1:37943,DS-356db294-4b5d-474d-b860-33f6f3e39e09,DISK], DatanodeInfoWithStorage[127.0.0.1:45364,DS-4e30ff9c-37f8-44f9-8800-7c6bbad13174,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1283448180-172.17.0.9-1598327274630:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34954,DS-378edbac-6af9-486a-bc04-b32681396de9,DISK], DatanodeInfoWithStorage[127.0.0.1:39764,DS-fae4ab2c-06cd-41bf-8dd7-f81facf639a9,DISK], DatanodeInfoWithStorage[127.0.0.1:45539,DS-74e8b40b-9aa9-49ed-b581-71de7cd67b7d,DISK], DatanodeInfoWithStorage[127.0.0.1:39278,DS-4e0cddc3-d9d9-404b-8cae-ee31a3ef51a8,DISK], DatanodeInfoWithStorage[127.0.0.1:43488,DS-36507811-040f-4378-be96-73285841f2ea,DISK], DatanodeInfoWithStorage[127.0.0.1:34250,DS-7c92a6c6-a93f-4439-a474-4134c64719c7,DISK], DatanodeInfoWithStorage[127.0.0.1:37943,DS-356db294-4b5d-474d-b860-33f6f3e39e09,DISK], DatanodeInfoWithStorage[127.0.0.1:45364,DS-4e30ff9c-37f8-44f9-8800-7c6bbad13174,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.name.dir.restore
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-158957928-172.17.0.9-1598327356453:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45440,DS-cd7c26ca-d643-4758-8c34-63020f31fe31,DISK], DatanodeInfoWithStorage[127.0.0.1:36127,DS-a64420a3-b5b5-4c5b-8b63-e9608437445e,DISK], DatanodeInfoWithStorage[127.0.0.1:45088,DS-e87dc876-ca5c-4e70-b343-aaa8bfab8750,DISK], DatanodeInfoWithStorage[127.0.0.1:45098,DS-d755fadf-c1df-4c72-b448-3711c60cf1a7,DISK], DatanodeInfoWithStorage[127.0.0.1:46450,DS-b19144a3-cf84-44d5-8c19-6fb853f18fba,DISK], DatanodeInfoWithStorage[127.0.0.1:45733,DS-04af580f-13b4-40d4-91f5-7042eacf84da,DISK], DatanodeInfoWithStorage[127.0.0.1:36609,DS-bfe95816-b907-4af6-b88b-5532a0a34971,DISK], DatanodeInfoWithStorage[127.0.0.1:45921,DS-d6e5cb50-27d6-4dd1-ab8e-1bbaa8e48177,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-158957928-172.17.0.9-1598327356453:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45440,DS-cd7c26ca-d643-4758-8c34-63020f31fe31,DISK], DatanodeInfoWithStorage[127.0.0.1:36127,DS-a64420a3-b5b5-4c5b-8b63-e9608437445e,DISK], DatanodeInfoWithStorage[127.0.0.1:45088,DS-e87dc876-ca5c-4e70-b343-aaa8bfab8750,DISK], DatanodeInfoWithStorage[127.0.0.1:45098,DS-d755fadf-c1df-4c72-b448-3711c60cf1a7,DISK], DatanodeInfoWithStorage[127.0.0.1:46450,DS-b19144a3-cf84-44d5-8c19-6fb853f18fba,DISK], DatanodeInfoWithStorage[127.0.0.1:45733,DS-04af580f-13b4-40d4-91f5-7042eacf84da,DISK], DatanodeInfoWithStorage[127.0.0.1:36609,DS-bfe95816-b907-4af6-b88b-5532a0a34971,DISK], DatanodeInfoWithStorage[127.0.0.1:45921,DS-d6e5cb50-27d6-4dd1-ab8e-1bbaa8e48177,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.name.dir.restore
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-37137195-172.17.0.9-1598327468144:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46641,DS-2796096e-ba56-421c-bbb8-657ebdd53bf6,DISK], DatanodeInfoWithStorage[127.0.0.1:36595,DS-eaa2a0dc-e7f6-4ff4-b48f-57bba7492896,DISK], DatanodeInfoWithStorage[127.0.0.1:34085,DS-4f025981-b2d0-4ce3-8b7c-a31400adf4b4,DISK], DatanodeInfoWithStorage[127.0.0.1:38430,DS-12922e50-4b91-43c7-9ed2-272e4bf942cb,DISK], DatanodeInfoWithStorage[127.0.0.1:44751,DS-28a063e6-5c04-47c6-85d2-e5b724018e41,DISK], DatanodeInfoWithStorage[127.0.0.1:41024,DS-94af7956-a639-41d6-b0f2-47803dd059b2,DISK], DatanodeInfoWithStorage[127.0.0.1:44666,DS-8a70d2f4-027e-4853-84bf-673b1996bf55,DISK], DatanodeInfoWithStorage[127.0.0.1:39977,DS-f3086220-a7f1-4595-ad61-7688f47baefd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-37137195-172.17.0.9-1598327468144:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46641,DS-2796096e-ba56-421c-bbb8-657ebdd53bf6,DISK], DatanodeInfoWithStorage[127.0.0.1:36595,DS-eaa2a0dc-e7f6-4ff4-b48f-57bba7492896,DISK], DatanodeInfoWithStorage[127.0.0.1:34085,DS-4f025981-b2d0-4ce3-8b7c-a31400adf4b4,DISK], DatanodeInfoWithStorage[127.0.0.1:38430,DS-12922e50-4b91-43c7-9ed2-272e4bf942cb,DISK], DatanodeInfoWithStorage[127.0.0.1:44751,DS-28a063e6-5c04-47c6-85d2-e5b724018e41,DISK], DatanodeInfoWithStorage[127.0.0.1:41024,DS-94af7956-a639-41d6-b0f2-47803dd059b2,DISK], DatanodeInfoWithStorage[127.0.0.1:44666,DS-8a70d2f4-027e-4853-84bf-673b1996bf55,DISK], DatanodeInfoWithStorage[127.0.0.1:39977,DS-f3086220-a7f1-4595-ad61-7688f47baefd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.name.dir.restore
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-238885470-172.17.0.9-1598327551694:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33305,DS-9ed43392-370c-4545-b615-6fcc654a496c,DISK], DatanodeInfoWithStorage[127.0.0.1:37357,DS-fa835040-b28a-4323-8a4c-2a630d3f9f0b,DISK], DatanodeInfoWithStorage[127.0.0.1:46736,DS-6c73aa62-cf61-480f-acf7-4476a45bda84,DISK], DatanodeInfoWithStorage[127.0.0.1:43362,DS-dfde9ebb-9a12-4f84-842f-bb2328c90c0c,DISK], DatanodeInfoWithStorage[127.0.0.1:41879,DS-24f43504-061f-4b4d-a062-c4f866c5b0c3,DISK], DatanodeInfoWithStorage[127.0.0.1:40512,DS-18591ced-1a6b-487e-bb53-74751b79101d,DISK], DatanodeInfoWithStorage[127.0.0.1:43184,DS-7cc66574-056e-443c-bd55-c774c789103a,DISK], DatanodeInfoWithStorage[127.0.0.1:41418,DS-1f3c6621-296d-4078-ad24-9d9a1d2bdf02,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-238885470-172.17.0.9-1598327551694:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33305,DS-9ed43392-370c-4545-b615-6fcc654a496c,DISK], DatanodeInfoWithStorage[127.0.0.1:37357,DS-fa835040-b28a-4323-8a4c-2a630d3f9f0b,DISK], DatanodeInfoWithStorage[127.0.0.1:46736,DS-6c73aa62-cf61-480f-acf7-4476a45bda84,DISK], DatanodeInfoWithStorage[127.0.0.1:43362,DS-dfde9ebb-9a12-4f84-842f-bb2328c90c0c,DISK], DatanodeInfoWithStorage[127.0.0.1:41879,DS-24f43504-061f-4b4d-a062-c4f866c5b0c3,DISK], DatanodeInfoWithStorage[127.0.0.1:40512,DS-18591ced-1a6b-487e-bb53-74751b79101d,DISK], DatanodeInfoWithStorage[127.0.0.1:43184,DS-7cc66574-056e-443c-bd55-c774c789103a,DISK], DatanodeInfoWithStorage[127.0.0.1:41418,DS-1f3c6621-296d-4078-ad24-9d9a1d2bdf02,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.name.dir.restore
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1135258763-172.17.0.9-1598327751278:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34076,DS-c1745403-0e44-44a6-be1e-fc5acbb587dd,DISK], DatanodeInfoWithStorage[127.0.0.1:36497,DS-bb47e16f-1bf4-45bd-b408-f4c14941d305,DISK], DatanodeInfoWithStorage[127.0.0.1:39258,DS-97226a9a-d0ff-43a2-9e13-ddd2f8848e3f,DISK], DatanodeInfoWithStorage[127.0.0.1:40023,DS-3a8b4b27-9eaa-4160-bea2-cef54671475f,DISK], DatanodeInfoWithStorage[127.0.0.1:42369,DS-e488c7c3-f1aa-43c0-8e35-64222195ecf2,DISK], DatanodeInfoWithStorage[127.0.0.1:38603,DS-c31bd810-1b80-4004-ab25-c340766c3388,DISK], DatanodeInfoWithStorage[127.0.0.1:39316,DS-476d4fab-a952-4daf-9fd4-00f49277d330,DISK], DatanodeInfoWithStorage[127.0.0.1:42813,DS-5f72053a-5e14-42d9-812d-8fe3ddd12b0f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1135258763-172.17.0.9-1598327751278:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34076,DS-c1745403-0e44-44a6-be1e-fc5acbb587dd,DISK], DatanodeInfoWithStorage[127.0.0.1:36497,DS-bb47e16f-1bf4-45bd-b408-f4c14941d305,DISK], DatanodeInfoWithStorage[127.0.0.1:39258,DS-97226a9a-d0ff-43a2-9e13-ddd2f8848e3f,DISK], DatanodeInfoWithStorage[127.0.0.1:40023,DS-3a8b4b27-9eaa-4160-bea2-cef54671475f,DISK], DatanodeInfoWithStorage[127.0.0.1:42369,DS-e488c7c3-f1aa-43c0-8e35-64222195ecf2,DISK], DatanodeInfoWithStorage[127.0.0.1:38603,DS-c31bd810-1b80-4004-ab25-c340766c3388,DISK], DatanodeInfoWithStorage[127.0.0.1:39316,DS-476d4fab-a952-4daf-9fd4-00f49277d330,DISK], DatanodeInfoWithStorage[127.0.0.1:42813,DS-5f72053a-5e14-42d9-812d-8fe3ddd12b0f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.name.dir.restore
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-645433817-172.17.0.9-1598327791663:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33651,DS-42d003db-9b18-4f21-a95b-8549b51758f7,DISK], DatanodeInfoWithStorage[127.0.0.1:34767,DS-d723da1d-3878-44cc-9330-799622e289e9,DISK], DatanodeInfoWithStorage[127.0.0.1:41202,DS-7c3ecdb5-20df-4c3f-a6fc-32386acaa651,DISK], DatanodeInfoWithStorage[127.0.0.1:36481,DS-08bea676-e29f-4485-9132-b128f86aa120,DISK], DatanodeInfoWithStorage[127.0.0.1:41571,DS-9c45dff3-2bae-49bd-9994-d5ef3664616c,DISK], DatanodeInfoWithStorage[127.0.0.1:46275,DS-4895cf86-4ced-46b3-8dee-edc8a8f3e8d9,DISK], DatanodeInfoWithStorage[127.0.0.1:45538,DS-b76415ad-32ba-4196-8e53-c821a322fca9,DISK], DatanodeInfoWithStorage[127.0.0.1:35364,DS-21d84ca0-4bfd-4668-847a-f061460a432a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-645433817-172.17.0.9-1598327791663:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33651,DS-42d003db-9b18-4f21-a95b-8549b51758f7,DISK], DatanodeInfoWithStorage[127.0.0.1:34767,DS-d723da1d-3878-44cc-9330-799622e289e9,DISK], DatanodeInfoWithStorage[127.0.0.1:41202,DS-7c3ecdb5-20df-4c3f-a6fc-32386acaa651,DISK], DatanodeInfoWithStorage[127.0.0.1:36481,DS-08bea676-e29f-4485-9132-b128f86aa120,DISK], DatanodeInfoWithStorage[127.0.0.1:41571,DS-9c45dff3-2bae-49bd-9994-d5ef3664616c,DISK], DatanodeInfoWithStorage[127.0.0.1:46275,DS-4895cf86-4ced-46b3-8dee-edc8a8f3e8d9,DISK], DatanodeInfoWithStorage[127.0.0.1:45538,DS-b76415ad-32ba-4196-8e53-c821a322fca9,DISK], DatanodeInfoWithStorage[127.0.0.1:35364,DS-21d84ca0-4bfd-4668-847a-f061460a432a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.name.dir.restore
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1450129964-172.17.0.9-1598327870567:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37580,DS-51928baa-36eb-4469-8f8c-ed905d681b36,DISK], DatanodeInfoWithStorage[127.0.0.1:33434,DS-d9aab876-da85-4fb8-a24b-dc5c3842a97a,DISK], DatanodeInfoWithStorage[127.0.0.1:36872,DS-1735d7f8-2d2c-4d69-b99e-8d09834a009c,DISK], DatanodeInfoWithStorage[127.0.0.1:44569,DS-ddf29ae8-ac38-4ae6-bb2a-c8e16b88e42b,DISK], DatanodeInfoWithStorage[127.0.0.1:34214,DS-dd37e069-0707-4bc7-8a78-bc3dce89eee3,DISK], DatanodeInfoWithStorage[127.0.0.1:35128,DS-3d52077e-e8de-4633-8967-da221af40f5f,DISK], DatanodeInfoWithStorage[127.0.0.1:35589,DS-dda06308-0849-477d-bf4d-a3c658066a2f,DISK], DatanodeInfoWithStorage[127.0.0.1:39228,DS-241f9d8c-2aa9-4350-9ab2-c7bf417ce9dc,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1450129964-172.17.0.9-1598327870567:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37580,DS-51928baa-36eb-4469-8f8c-ed905d681b36,DISK], DatanodeInfoWithStorage[127.0.0.1:33434,DS-d9aab876-da85-4fb8-a24b-dc5c3842a97a,DISK], DatanodeInfoWithStorage[127.0.0.1:36872,DS-1735d7f8-2d2c-4d69-b99e-8d09834a009c,DISK], DatanodeInfoWithStorage[127.0.0.1:44569,DS-ddf29ae8-ac38-4ae6-bb2a-c8e16b88e42b,DISK], DatanodeInfoWithStorage[127.0.0.1:34214,DS-dd37e069-0707-4bc7-8a78-bc3dce89eee3,DISK], DatanodeInfoWithStorage[127.0.0.1:35128,DS-3d52077e-e8de-4633-8967-da221af40f5f,DISK], DatanodeInfoWithStorage[127.0.0.1:35589,DS-dda06308-0849-477d-bf4d-a3c658066a2f,DISK], DatanodeInfoWithStorage[127.0.0.1:39228,DS-241f9d8c-2aa9-4350-9ab2-c7bf417ce9dc,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 11 out of 50
v1v1v2v2 failed with probability 21 out of 50
result: false positive !!!
Total execution time in seconds : 5622
