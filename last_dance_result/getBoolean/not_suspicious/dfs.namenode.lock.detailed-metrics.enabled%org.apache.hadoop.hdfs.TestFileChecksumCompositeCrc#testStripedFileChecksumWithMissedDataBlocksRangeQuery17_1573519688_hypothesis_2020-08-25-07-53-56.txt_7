reconf_parameter: dfs.namenode.lock.detailed-metrics.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.lock.detailed-metrics.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1961112157-172.17.0.18-1598342363226:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36460,DS-6fe37944-98e7-4cad-98c0-1131ce414ccb,DISK], DatanodeInfoWithStorage[127.0.0.1:44127,DS-c6b06195-d8bb-4345-bbd1-472899a5fe98,DISK], DatanodeInfoWithStorage[127.0.0.1:39845,DS-fbeae759-9cdb-4f2d-9180-a6102bcf5f1b,DISK], DatanodeInfoWithStorage[127.0.0.1:43177,DS-99aaaef2-f668-4410-8829-5c240bdfcb4a,DISK], DatanodeInfoWithStorage[127.0.0.1:41217,DS-21b993da-b9c1-4381-904e-5e78d126a6f1,DISK], DatanodeInfoWithStorage[127.0.0.1:35831,DS-6c212b82-87d6-4fc7-9934-e161ee4eddc2,DISK], DatanodeInfoWithStorage[127.0.0.1:41784,DS-6f8c15bd-eed5-4d95-9f4e-ad77f48b8a74,DISK], DatanodeInfoWithStorage[127.0.0.1:40787,DS-9ad90807-e645-4019-adaa-2a6a2905e92d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1961112157-172.17.0.18-1598342363226:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36460,DS-6fe37944-98e7-4cad-98c0-1131ce414ccb,DISK], DatanodeInfoWithStorage[127.0.0.1:44127,DS-c6b06195-d8bb-4345-bbd1-472899a5fe98,DISK], DatanodeInfoWithStorage[127.0.0.1:39845,DS-fbeae759-9cdb-4f2d-9180-a6102bcf5f1b,DISK], DatanodeInfoWithStorage[127.0.0.1:43177,DS-99aaaef2-f668-4410-8829-5c240bdfcb4a,DISK], DatanodeInfoWithStorage[127.0.0.1:41217,DS-21b993da-b9c1-4381-904e-5e78d126a6f1,DISK], DatanodeInfoWithStorage[127.0.0.1:35831,DS-6c212b82-87d6-4fc7-9934-e161ee4eddc2,DISK], DatanodeInfoWithStorage[127.0.0.1:41784,DS-6f8c15bd-eed5-4d95-9f4e-ad77f48b8a74,DISK], DatanodeInfoWithStorage[127.0.0.1:40787,DS-9ad90807-e645-4019-adaa-2a6a2905e92d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.lock.detailed-metrics.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1307125378-172.17.0.18-1598342691452:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39137,DS-9fb1f461-df43-42e0-a225-a15e3bbcbb55,DISK], DatanodeInfoWithStorage[127.0.0.1:33886,DS-f48e8aff-aa8b-4eca-919e-d78a5a82488d,DISK], DatanodeInfoWithStorage[127.0.0.1:39309,DS-30ea3175-053f-4ced-9c67-dfc8f8103341,DISK], DatanodeInfoWithStorage[127.0.0.1:45469,DS-b625d038-fee0-4dc1-8e6b-cc69f0d934e2,DISK], DatanodeInfoWithStorage[127.0.0.1:40913,DS-9bf1d5f1-7728-4973-a364-cea2a803c531,DISK], DatanodeInfoWithStorage[127.0.0.1:41399,DS-a39dd928-b6f8-43b5-854a-5f7dc9cc290a,DISK], DatanodeInfoWithStorage[127.0.0.1:33493,DS-e1500b53-4e53-4bca-a65e-a55a052a9a50,DISK], DatanodeInfoWithStorage[127.0.0.1:40393,DS-a3572b45-63d1-45c4-81df-4374339ecfb3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1307125378-172.17.0.18-1598342691452:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39137,DS-9fb1f461-df43-42e0-a225-a15e3bbcbb55,DISK], DatanodeInfoWithStorage[127.0.0.1:33886,DS-f48e8aff-aa8b-4eca-919e-d78a5a82488d,DISK], DatanodeInfoWithStorage[127.0.0.1:39309,DS-30ea3175-053f-4ced-9c67-dfc8f8103341,DISK], DatanodeInfoWithStorage[127.0.0.1:45469,DS-b625d038-fee0-4dc1-8e6b-cc69f0d934e2,DISK], DatanodeInfoWithStorage[127.0.0.1:40913,DS-9bf1d5f1-7728-4973-a364-cea2a803c531,DISK], DatanodeInfoWithStorage[127.0.0.1:41399,DS-a39dd928-b6f8-43b5-854a-5f7dc9cc290a,DISK], DatanodeInfoWithStorage[127.0.0.1:33493,DS-e1500b53-4e53-4bca-a65e-a55a052a9a50,DISK], DatanodeInfoWithStorage[127.0.0.1:40393,DS-a3572b45-63d1-45c4-81df-4374339ecfb3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lock.detailed-metrics.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-643139692-172.17.0.18-1598343048973:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38194,DS-f81ef798-4aa9-4e40-83de-4df10c45170b,DISK], DatanodeInfoWithStorage[127.0.0.1:35527,DS-e9bc1264-ed8f-4ed4-9740-2e7469a5c843,DISK], DatanodeInfoWithStorage[127.0.0.1:45060,DS-766e8d59-5b39-4824-934d-d4d1782c9174,DISK], DatanodeInfoWithStorage[127.0.0.1:38610,DS-f84a2bd2-d9ed-45d5-8719-f6fa3d68ffa9,DISK], DatanodeInfoWithStorage[127.0.0.1:37677,DS-21b258df-a573-43fb-9a28-a2fd2c376d22,DISK], DatanodeInfoWithStorage[127.0.0.1:41496,DS-a6b7893d-6df9-4745-923b-d141b9b30da3,DISK], DatanodeInfoWithStorage[127.0.0.1:41909,DS-06a9ab29-d811-44b4-b755-6e866a0b64c6,DISK], DatanodeInfoWithStorage[127.0.0.1:45712,DS-b1dc872b-6328-425c-a7b4-c24e7cba1a56,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-643139692-172.17.0.18-1598343048973:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38194,DS-f81ef798-4aa9-4e40-83de-4df10c45170b,DISK], DatanodeInfoWithStorage[127.0.0.1:35527,DS-e9bc1264-ed8f-4ed4-9740-2e7469a5c843,DISK], DatanodeInfoWithStorage[127.0.0.1:45060,DS-766e8d59-5b39-4824-934d-d4d1782c9174,DISK], DatanodeInfoWithStorage[127.0.0.1:38610,DS-f84a2bd2-d9ed-45d5-8719-f6fa3d68ffa9,DISK], DatanodeInfoWithStorage[127.0.0.1:37677,DS-21b258df-a573-43fb-9a28-a2fd2c376d22,DISK], DatanodeInfoWithStorage[127.0.0.1:41496,DS-a6b7893d-6df9-4745-923b-d141b9b30da3,DISK], DatanodeInfoWithStorage[127.0.0.1:41909,DS-06a9ab29-d811-44b4-b755-6e866a0b64c6,DISK], DatanodeInfoWithStorage[127.0.0.1:45712,DS-b1dc872b-6328-425c-a7b4-c24e7cba1a56,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.lock.detailed-metrics.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1426609987-172.17.0.18-1598343077487:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43124,DS-a9da5de1-81fe-457b-b772-1daac4fc0013,DISK], DatanodeInfoWithStorage[127.0.0.1:45899,DS-748b757d-d25c-41bb-8020-984623db53c0,DISK], DatanodeInfoWithStorage[127.0.0.1:33192,DS-5b1ffad3-39f1-48a4-9886-0f31dc1cf7a7,DISK], DatanodeInfoWithStorage[127.0.0.1:44411,DS-ad5ec2f9-a0e0-4d12-9dfe-68d9db7051da,DISK], DatanodeInfoWithStorage[127.0.0.1:41973,DS-e5349eea-5c9e-4ea8-b435-3c00dff60652,DISK], DatanodeInfoWithStorage[127.0.0.1:42855,DS-8237c438-9bc9-43d3-a370-74b77bcaa9f2,DISK], DatanodeInfoWithStorage[127.0.0.1:38903,DS-3ebf3655-698b-45e2-8229-9129de540476,DISK], DatanodeInfoWithStorage[127.0.0.1:35950,DS-69d24ab2-6734-4c72-88f0-5027a67af136,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1426609987-172.17.0.18-1598343077487:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43124,DS-a9da5de1-81fe-457b-b772-1daac4fc0013,DISK], DatanodeInfoWithStorage[127.0.0.1:45899,DS-748b757d-d25c-41bb-8020-984623db53c0,DISK], DatanodeInfoWithStorage[127.0.0.1:33192,DS-5b1ffad3-39f1-48a4-9886-0f31dc1cf7a7,DISK], DatanodeInfoWithStorage[127.0.0.1:44411,DS-ad5ec2f9-a0e0-4d12-9dfe-68d9db7051da,DISK], DatanodeInfoWithStorage[127.0.0.1:41973,DS-e5349eea-5c9e-4ea8-b435-3c00dff60652,DISK], DatanodeInfoWithStorage[127.0.0.1:42855,DS-8237c438-9bc9-43d3-a370-74b77bcaa9f2,DISK], DatanodeInfoWithStorage[127.0.0.1:38903,DS-3ebf3655-698b-45e2-8229-9129de540476,DISK], DatanodeInfoWithStorage[127.0.0.1:35950,DS-69d24ab2-6734-4c72-88f0-5027a67af136,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lock.detailed-metrics.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-540471315-172.17.0.18-1598343635000:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45064,DS-b5a8ddc9-95e0-4a89-adeb-cf8b6b1c0286,DISK], DatanodeInfoWithStorage[127.0.0.1:41578,DS-47a40314-231f-40c1-9eb3-ce9b96d51e33,DISK], DatanodeInfoWithStorage[127.0.0.1:32985,DS-3d55d1fb-dab3-4a2a-8f3d-62220edfedad,DISK], DatanodeInfoWithStorage[127.0.0.1:36860,DS-29ff1f2b-86b6-47cf-877c-e532e87af01b,DISK], DatanodeInfoWithStorage[127.0.0.1:36790,DS-8985568c-713f-483c-a172-1361f77821e9,DISK], DatanodeInfoWithStorage[127.0.0.1:33041,DS-02b40d13-230b-45a5-93b4-2282fb819569,DISK], DatanodeInfoWithStorage[127.0.0.1:40978,DS-214f5d48-000c-4575-a2fe-e3636cdb1e0e,DISK], DatanodeInfoWithStorage[127.0.0.1:41778,DS-d1bf4b63-accf-42ae-b3a8-8c628eed19ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-540471315-172.17.0.18-1598343635000:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45064,DS-b5a8ddc9-95e0-4a89-adeb-cf8b6b1c0286,DISK], DatanodeInfoWithStorage[127.0.0.1:41578,DS-47a40314-231f-40c1-9eb3-ce9b96d51e33,DISK], DatanodeInfoWithStorage[127.0.0.1:32985,DS-3d55d1fb-dab3-4a2a-8f3d-62220edfedad,DISK], DatanodeInfoWithStorage[127.0.0.1:36860,DS-29ff1f2b-86b6-47cf-877c-e532e87af01b,DISK], DatanodeInfoWithStorage[127.0.0.1:36790,DS-8985568c-713f-483c-a172-1361f77821e9,DISK], DatanodeInfoWithStorage[127.0.0.1:33041,DS-02b40d13-230b-45a5-93b4-2282fb819569,DISK], DatanodeInfoWithStorage[127.0.0.1:40978,DS-214f5d48-000c-4575-a2fe-e3636cdb1e0e,DISK], DatanodeInfoWithStorage[127.0.0.1:41778,DS-d1bf4b63-accf-42ae-b3a8-8c628eed19ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lock.detailed-metrics.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-339447705-172.17.0.18-1598344209363:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33925,DS-d0e512c7-5e62-4c6e-ab73-f621f2596b68,DISK], DatanodeInfoWithStorage[127.0.0.1:33453,DS-6a8efadf-acc1-4c48-a235-99d1e5780b57,DISK], DatanodeInfoWithStorage[127.0.0.1:35372,DS-5d7e2777-3f10-4913-a8a9-ae047fc67db1,DISK], DatanodeInfoWithStorage[127.0.0.1:40499,DS-86fca5c7-d644-44a7-b251-4fd3c9d022b3,DISK], DatanodeInfoWithStorage[127.0.0.1:44612,DS-72791522-d6cc-4b17-b916-4d031d32e45f,DISK], DatanodeInfoWithStorage[127.0.0.1:37937,DS-e53b968c-471a-4863-8d70-82c387c8fd95,DISK], DatanodeInfoWithStorage[127.0.0.1:43455,DS-2c84de15-4fd8-47d4-952c-611a45eb7190,DISK], DatanodeInfoWithStorage[127.0.0.1:39099,DS-995b45d4-3ba8-4d4b-a315-b7e29bd7afa5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-339447705-172.17.0.18-1598344209363:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33925,DS-d0e512c7-5e62-4c6e-ab73-f621f2596b68,DISK], DatanodeInfoWithStorage[127.0.0.1:33453,DS-6a8efadf-acc1-4c48-a235-99d1e5780b57,DISK], DatanodeInfoWithStorage[127.0.0.1:35372,DS-5d7e2777-3f10-4913-a8a9-ae047fc67db1,DISK], DatanodeInfoWithStorage[127.0.0.1:40499,DS-86fca5c7-d644-44a7-b251-4fd3c9d022b3,DISK], DatanodeInfoWithStorage[127.0.0.1:44612,DS-72791522-d6cc-4b17-b916-4d031d32e45f,DISK], DatanodeInfoWithStorage[127.0.0.1:37937,DS-e53b968c-471a-4863-8d70-82c387c8fd95,DISK], DatanodeInfoWithStorage[127.0.0.1:43455,DS-2c84de15-4fd8-47d4-952c-611a45eb7190,DISK], DatanodeInfoWithStorage[127.0.0.1:39099,DS-995b45d4-3ba8-4d4b-a315-b7e29bd7afa5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lock.detailed-metrics.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-687314560-172.17.0.18-1598344315377:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46824,DS-c8d2f57c-fef4-413d-aa98-b5d27b97ffab,DISK], DatanodeInfoWithStorage[127.0.0.1:43592,DS-50d9e67a-2f7a-48b9-af0f-ee46857f71e4,DISK], DatanodeInfoWithStorage[127.0.0.1:36807,DS-0de17088-a9ec-4eac-8c14-764bffd06af1,DISK], DatanodeInfoWithStorage[127.0.0.1:35775,DS-dc6dcee8-04de-4fc7-a21d-b45bfb2db64d,DISK], DatanodeInfoWithStorage[127.0.0.1:35696,DS-0f7edd68-936c-414e-9422-0410ad49aa11,DISK], DatanodeInfoWithStorage[127.0.0.1:46662,DS-5df0c593-bb81-418b-9282-5fe8003749a8,DISK], DatanodeInfoWithStorage[127.0.0.1:41067,DS-db84ea9a-004a-42aa-a60e-16c26b1bae0c,DISK], DatanodeInfoWithStorage[127.0.0.1:35999,DS-c573d611-a039-47b3-88d9-2d5dac118c42,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-687314560-172.17.0.18-1598344315377:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46824,DS-c8d2f57c-fef4-413d-aa98-b5d27b97ffab,DISK], DatanodeInfoWithStorage[127.0.0.1:43592,DS-50d9e67a-2f7a-48b9-af0f-ee46857f71e4,DISK], DatanodeInfoWithStorage[127.0.0.1:36807,DS-0de17088-a9ec-4eac-8c14-764bffd06af1,DISK], DatanodeInfoWithStorage[127.0.0.1:35775,DS-dc6dcee8-04de-4fc7-a21d-b45bfb2db64d,DISK], DatanodeInfoWithStorage[127.0.0.1:35696,DS-0f7edd68-936c-414e-9422-0410ad49aa11,DISK], DatanodeInfoWithStorage[127.0.0.1:46662,DS-5df0c593-bb81-418b-9282-5fe8003749a8,DISK], DatanodeInfoWithStorage[127.0.0.1:41067,DS-db84ea9a-004a-42aa-a60e-16c26b1bae0c,DISK], DatanodeInfoWithStorage[127.0.0.1:35999,DS-c573d611-a039-47b3-88d9-2d5dac118c42,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lock.detailed-metrics.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1987831847-172.17.0.18-1598344733382:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45690,DS-1f22a6f9-c6ca-4cf2-abb2-6c2da10ff333,DISK], DatanodeInfoWithStorage[127.0.0.1:44536,DS-dd46b4db-77b2-4980-8046-215cba69ce27,DISK], DatanodeInfoWithStorage[127.0.0.1:33268,DS-996d8b0f-146d-4b03-a9fb-ad71172ac722,DISK], DatanodeInfoWithStorage[127.0.0.1:45147,DS-a8b3b694-1dfa-4656-b276-38654926db6d,DISK], DatanodeInfoWithStorage[127.0.0.1:41235,DS-ee85859d-cc42-47bb-a92e-27f454a5fd80,DISK], DatanodeInfoWithStorage[127.0.0.1:41894,DS-c270b449-20e7-4f98-9625-f4ed43ee688c,DISK], DatanodeInfoWithStorage[127.0.0.1:42337,DS-391674e9-edd6-4749-a953-7070ee022be3,DISK], DatanodeInfoWithStorage[127.0.0.1:46306,DS-e116a7ea-d999-4a9a-b01b-b28373ecdbb5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1987831847-172.17.0.18-1598344733382:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45690,DS-1f22a6f9-c6ca-4cf2-abb2-6c2da10ff333,DISK], DatanodeInfoWithStorage[127.0.0.1:44536,DS-dd46b4db-77b2-4980-8046-215cba69ce27,DISK], DatanodeInfoWithStorage[127.0.0.1:33268,DS-996d8b0f-146d-4b03-a9fb-ad71172ac722,DISK], DatanodeInfoWithStorage[127.0.0.1:45147,DS-a8b3b694-1dfa-4656-b276-38654926db6d,DISK], DatanodeInfoWithStorage[127.0.0.1:41235,DS-ee85859d-cc42-47bb-a92e-27f454a5fd80,DISK], DatanodeInfoWithStorage[127.0.0.1:41894,DS-c270b449-20e7-4f98-9625-f4ed43ee688c,DISK], DatanodeInfoWithStorage[127.0.0.1:42337,DS-391674e9-edd6-4749-a953-7070ee022be3,DISK], DatanodeInfoWithStorage[127.0.0.1:46306,DS-e116a7ea-d999-4a9a-b01b-b28373ecdbb5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lock.detailed-metrics.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1645704397-172.17.0.18-1598345493094:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33439,DS-af1007b1-8922-445c-8a69-7a161a7d848b,DISK], DatanodeInfoWithStorage[127.0.0.1:36221,DS-5d837c9d-c077-47d3-bad9-1f9bf53c6ab8,DISK], DatanodeInfoWithStorage[127.0.0.1:41477,DS-52a4fc74-2fba-4f64-9eb5-22de5d9891c0,DISK], DatanodeInfoWithStorage[127.0.0.1:43766,DS-3f218c75-a346-4c8f-baa0-8da3a3174abd,DISK], DatanodeInfoWithStorage[127.0.0.1:37434,DS-63bb7d7e-84cf-4547-a869-546d6eafe883,DISK], DatanodeInfoWithStorage[127.0.0.1:41347,DS-0b48e77a-5f75-40a3-b326-3c32fe1dd25d,DISK], DatanodeInfoWithStorage[127.0.0.1:38964,DS-e5360d56-7935-40c5-bdc2-798dbb1fb08c,DISK], DatanodeInfoWithStorage[127.0.0.1:43963,DS-5dc040dd-1b1b-4312-91df-1285b00c126c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1645704397-172.17.0.18-1598345493094:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33439,DS-af1007b1-8922-445c-8a69-7a161a7d848b,DISK], DatanodeInfoWithStorage[127.0.0.1:36221,DS-5d837c9d-c077-47d3-bad9-1f9bf53c6ab8,DISK], DatanodeInfoWithStorage[127.0.0.1:41477,DS-52a4fc74-2fba-4f64-9eb5-22de5d9891c0,DISK], DatanodeInfoWithStorage[127.0.0.1:43766,DS-3f218c75-a346-4c8f-baa0-8da3a3174abd,DISK], DatanodeInfoWithStorage[127.0.0.1:37434,DS-63bb7d7e-84cf-4547-a869-546d6eafe883,DISK], DatanodeInfoWithStorage[127.0.0.1:41347,DS-0b48e77a-5f75-40a3-b326-3c32fe1dd25d,DISK], DatanodeInfoWithStorage[127.0.0.1:38964,DS-e5360d56-7935-40c5-bdc2-798dbb1fb08c,DISK], DatanodeInfoWithStorage[127.0.0.1:43963,DS-5dc040dd-1b1b-4312-91df-1285b00c126c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 6 out of 50
result: false positive !!!
Total execution time in seconds : 5244
