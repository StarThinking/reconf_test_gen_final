reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1959656937-172.17.0.15-1598089290968:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41761,DS-8441a2a0-cc71-4cbc-96a3-bca976c15a6a,DISK], DatanodeInfoWithStorage[127.0.0.1:46175,DS-8c458633-8f9b-479e-a778-177e3f97aa0f,DISK], DatanodeInfoWithStorage[127.0.0.1:43857,DS-239070e4-a922-42a7-97ff-0429dc2387ba,DISK], DatanodeInfoWithStorage[127.0.0.1:40714,DS-cd70285f-9735-4fef-af9d-2e14038a268f,DISK], DatanodeInfoWithStorage[127.0.0.1:38655,DS-2c355437-6589-4cf8-84d2-07150c9f5187,DISK], DatanodeInfoWithStorage[127.0.0.1:41874,DS-e9a7f0e0-437c-4ba5-9039-1272789024ac,DISK], DatanodeInfoWithStorage[127.0.0.1:37778,DS-69082d4d-1bf4-42d3-8099-3f6c42bf3d64,DISK], DatanodeInfoWithStorage[127.0.0.1:34650,DS-d46a9e9b-8b37-4917-b842-0c34c14062b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1959656937-172.17.0.15-1598089290968:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41761,DS-8441a2a0-cc71-4cbc-96a3-bca976c15a6a,DISK], DatanodeInfoWithStorage[127.0.0.1:46175,DS-8c458633-8f9b-479e-a778-177e3f97aa0f,DISK], DatanodeInfoWithStorage[127.0.0.1:43857,DS-239070e4-a922-42a7-97ff-0429dc2387ba,DISK], DatanodeInfoWithStorage[127.0.0.1:40714,DS-cd70285f-9735-4fef-af9d-2e14038a268f,DISK], DatanodeInfoWithStorage[127.0.0.1:38655,DS-2c355437-6589-4cf8-84d2-07150c9f5187,DISK], DatanodeInfoWithStorage[127.0.0.1:41874,DS-e9a7f0e0-437c-4ba5-9039-1272789024ac,DISK], DatanodeInfoWithStorage[127.0.0.1:37778,DS-69082d4d-1bf4-42d3-8099-3f6c42bf3d64,DISK], DatanodeInfoWithStorage[127.0.0.1:34650,DS-d46a9e9b-8b37-4917-b842-0c34c14062b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-111066002-172.17.0.15-1598089428436:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46221,DS-4a93d972-352e-4ac4-949f-3b3965ad4b9d,DISK], DatanodeInfoWithStorage[127.0.0.1:40264,DS-8a70e740-a964-4ace-8cb3-510e952e594e,DISK], DatanodeInfoWithStorage[127.0.0.1:41201,DS-81b84070-bca4-4d60-b5ca-066abc888964,DISK], DatanodeInfoWithStorage[127.0.0.1:43259,DS-4ac16726-7a89-445b-87ab-3e23450e09e6,DISK], DatanodeInfoWithStorage[127.0.0.1:40616,DS-e5d865a7-46e2-4167-9a85-312c2d2beade,DISK], DatanodeInfoWithStorage[127.0.0.1:42637,DS-004adb1f-7de8-4669-a719-6a7631eb51f2,DISK], DatanodeInfoWithStorage[127.0.0.1:35203,DS-4d4d59b2-3169-4fa0-acd0-3d825a634534,DISK], DatanodeInfoWithStorage[127.0.0.1:33598,DS-27d4d7c4-7f46-4249-822f-18ce0d5f8fcd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-111066002-172.17.0.15-1598089428436:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46221,DS-4a93d972-352e-4ac4-949f-3b3965ad4b9d,DISK], DatanodeInfoWithStorage[127.0.0.1:40264,DS-8a70e740-a964-4ace-8cb3-510e952e594e,DISK], DatanodeInfoWithStorage[127.0.0.1:41201,DS-81b84070-bca4-4d60-b5ca-066abc888964,DISK], DatanodeInfoWithStorage[127.0.0.1:43259,DS-4ac16726-7a89-445b-87ab-3e23450e09e6,DISK], DatanodeInfoWithStorage[127.0.0.1:40616,DS-e5d865a7-46e2-4167-9a85-312c2d2beade,DISK], DatanodeInfoWithStorage[127.0.0.1:42637,DS-004adb1f-7de8-4669-a719-6a7631eb51f2,DISK], DatanodeInfoWithStorage[127.0.0.1:35203,DS-4d4d59b2-3169-4fa0-acd0-3d825a634534,DISK], DatanodeInfoWithStorage[127.0.0.1:33598,DS-27d4d7c4-7f46-4249-822f-18ce0d5f8fcd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1633398807-172.17.0.15-1598090167356:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35122,DS-42d2f6ef-9ea9-414b-951c-6d06e449c95f,DISK], DatanodeInfoWithStorage[127.0.0.1:42744,DS-d63ccd3a-6a3d-4c76-b598-7b882d3eb773,DISK], DatanodeInfoWithStorage[127.0.0.1:35151,DS-d74caa98-b37b-49d8-aec3-433ea03616e4,DISK], DatanodeInfoWithStorage[127.0.0.1:43216,DS-bfb34828-8e2e-4694-8889-b3009a641994,DISK], DatanodeInfoWithStorage[127.0.0.1:33979,DS-6674a01f-3ce1-42ad-ad76-5d8ffcbace82,DISK], DatanodeInfoWithStorage[127.0.0.1:38334,DS-a8ac4891-7b3a-4488-80b5-402402a2d54a,DISK], DatanodeInfoWithStorage[127.0.0.1:36153,DS-664236a7-eb9a-40ba-ae62-2ed854655435,DISK], DatanodeInfoWithStorage[127.0.0.1:43872,DS-054c86b2-70fe-48eb-a6c8-d00b4b66f2ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1633398807-172.17.0.15-1598090167356:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35122,DS-42d2f6ef-9ea9-414b-951c-6d06e449c95f,DISK], DatanodeInfoWithStorage[127.0.0.1:42744,DS-d63ccd3a-6a3d-4c76-b598-7b882d3eb773,DISK], DatanodeInfoWithStorage[127.0.0.1:35151,DS-d74caa98-b37b-49d8-aec3-433ea03616e4,DISK], DatanodeInfoWithStorage[127.0.0.1:43216,DS-bfb34828-8e2e-4694-8889-b3009a641994,DISK], DatanodeInfoWithStorage[127.0.0.1:33979,DS-6674a01f-3ce1-42ad-ad76-5d8ffcbace82,DISK], DatanodeInfoWithStorage[127.0.0.1:38334,DS-a8ac4891-7b3a-4488-80b5-402402a2d54a,DISK], DatanodeInfoWithStorage[127.0.0.1:36153,DS-664236a7-eb9a-40ba-ae62-2ed854655435,DISK], DatanodeInfoWithStorage[127.0.0.1:43872,DS-054c86b2-70fe-48eb-a6c8-d00b4b66f2ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1616393346-172.17.0.15-1598090316944:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35458,DS-833ddde0-ae35-4a0a-9fd9-bd69746b52cb,DISK], DatanodeInfoWithStorage[127.0.0.1:40736,DS-d482b340-be9e-4f91-8e05-f7339dc684cb,DISK], DatanodeInfoWithStorage[127.0.0.1:33479,DS-a74830da-8468-4e4a-bf18-424d3a21ed93,DISK], DatanodeInfoWithStorage[127.0.0.1:36949,DS-2f22c5e8-da30-4d89-90f2-9065d0ba3362,DISK], DatanodeInfoWithStorage[127.0.0.1:34146,DS-193d9e1b-86e9-4e82-babf-707c35ae595f,DISK], DatanodeInfoWithStorage[127.0.0.1:43954,DS-629142b5-9e5d-43db-b411-b1c4cb14f3c5,DISK], DatanodeInfoWithStorage[127.0.0.1:45953,DS-28b1d418-901b-4a47-bd8f-69b3ede69f4b,DISK], DatanodeInfoWithStorage[127.0.0.1:35913,DS-4b658b29-b686-4542-a75e-cb7ffe7a384b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1616393346-172.17.0.15-1598090316944:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35458,DS-833ddde0-ae35-4a0a-9fd9-bd69746b52cb,DISK], DatanodeInfoWithStorage[127.0.0.1:40736,DS-d482b340-be9e-4f91-8e05-f7339dc684cb,DISK], DatanodeInfoWithStorage[127.0.0.1:33479,DS-a74830da-8468-4e4a-bf18-424d3a21ed93,DISK], DatanodeInfoWithStorage[127.0.0.1:36949,DS-2f22c5e8-da30-4d89-90f2-9065d0ba3362,DISK], DatanodeInfoWithStorage[127.0.0.1:34146,DS-193d9e1b-86e9-4e82-babf-707c35ae595f,DISK], DatanodeInfoWithStorage[127.0.0.1:43954,DS-629142b5-9e5d-43db-b411-b1c4cb14f3c5,DISK], DatanodeInfoWithStorage[127.0.0.1:45953,DS-28b1d418-901b-4a47-bd8f-69b3ede69f4b,DISK], DatanodeInfoWithStorage[127.0.0.1:35913,DS-4b658b29-b686-4542-a75e-cb7ffe7a384b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1212958267-172.17.0.15-1598091000245:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38816,DS-ae5c2f11-e295-4fcc-a6eb-170a68dd4b37,DISK], DatanodeInfoWithStorage[127.0.0.1:46354,DS-f833859c-633d-4a63-8933-00b1c217c6d7,DISK], DatanodeInfoWithStorage[127.0.0.1:39415,DS-939c22b0-0d31-499a-87ee-b2d16ed6b0d7,DISK], DatanodeInfoWithStorage[127.0.0.1:43769,DS-47e59725-a280-402e-884b-3c50c41b4a4b,DISK], DatanodeInfoWithStorage[127.0.0.1:37706,DS-48a43761-27cc-4d84-8ae4-ec3e54393d71,DISK], DatanodeInfoWithStorage[127.0.0.1:34545,DS-93924602-14be-4806-8adf-9b2d161308c6,DISK], DatanodeInfoWithStorage[127.0.0.1:41428,DS-c0a09f75-b7ac-46d1-b6d8-8435fba5b6f1,DISK], DatanodeInfoWithStorage[127.0.0.1:38769,DS-57c353ed-84c4-4340-8570-0222864b92c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1212958267-172.17.0.15-1598091000245:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38816,DS-ae5c2f11-e295-4fcc-a6eb-170a68dd4b37,DISK], DatanodeInfoWithStorage[127.0.0.1:46354,DS-f833859c-633d-4a63-8933-00b1c217c6d7,DISK], DatanodeInfoWithStorage[127.0.0.1:39415,DS-939c22b0-0d31-499a-87ee-b2d16ed6b0d7,DISK], DatanodeInfoWithStorage[127.0.0.1:43769,DS-47e59725-a280-402e-884b-3c50c41b4a4b,DISK], DatanodeInfoWithStorage[127.0.0.1:37706,DS-48a43761-27cc-4d84-8ae4-ec3e54393d71,DISK], DatanodeInfoWithStorage[127.0.0.1:34545,DS-93924602-14be-4806-8adf-9b2d161308c6,DISK], DatanodeInfoWithStorage[127.0.0.1:41428,DS-c0a09f75-b7ac-46d1-b6d8-8435fba5b6f1,DISK], DatanodeInfoWithStorage[127.0.0.1:38769,DS-57c353ed-84c4-4340-8570-0222864b92c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2099898079-172.17.0.15-1598091495867:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43934,DS-a376e65c-fc79-4d33-a917-46816603d47b,DISK], DatanodeInfoWithStorage[127.0.0.1:42889,DS-c21635de-0c5b-4e06-975d-16c3567fae55,DISK], DatanodeInfoWithStorage[127.0.0.1:45697,DS-d54feddb-0177-41ed-83b7-e85e44f58edf,DISK], DatanodeInfoWithStorage[127.0.0.1:37974,DS-29dbaf47-b2fe-4af0-b1df-daf03c410204,DISK], DatanodeInfoWithStorage[127.0.0.1:36246,DS-041eb002-4e1c-47f8-97be-97785bd1e67c,DISK], DatanodeInfoWithStorage[127.0.0.1:42203,DS-21f5f091-442e-4a98-bc97-44ba08cb21e5,DISK], DatanodeInfoWithStorage[127.0.0.1:39933,DS-88b566df-8655-487e-a311-0fb861abffc1,DISK], DatanodeInfoWithStorage[127.0.0.1:37968,DS-819396a4-4bbb-45e6-9e9d-d86bd5918bdb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2099898079-172.17.0.15-1598091495867:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43934,DS-a376e65c-fc79-4d33-a917-46816603d47b,DISK], DatanodeInfoWithStorage[127.0.0.1:42889,DS-c21635de-0c5b-4e06-975d-16c3567fae55,DISK], DatanodeInfoWithStorage[127.0.0.1:45697,DS-d54feddb-0177-41ed-83b7-e85e44f58edf,DISK], DatanodeInfoWithStorage[127.0.0.1:37974,DS-29dbaf47-b2fe-4af0-b1df-daf03c410204,DISK], DatanodeInfoWithStorage[127.0.0.1:36246,DS-041eb002-4e1c-47f8-97be-97785bd1e67c,DISK], DatanodeInfoWithStorage[127.0.0.1:42203,DS-21f5f091-442e-4a98-bc97-44ba08cb21e5,DISK], DatanodeInfoWithStorage[127.0.0.1:39933,DS-88b566df-8655-487e-a311-0fb861abffc1,DISK], DatanodeInfoWithStorage[127.0.0.1:37968,DS-819396a4-4bbb-45e6-9e9d-d86bd5918bdb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2106699824-172.17.0.15-1598092030604:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40938,DS-7c75d616-031b-46d0-8e8f-79355138e6cc,DISK], DatanodeInfoWithStorage[127.0.0.1:36064,DS-62da6079-f1ca-48c9-9cab-df445e0734d9,DISK], DatanodeInfoWithStorage[127.0.0.1:38007,DS-d19c6f49-a418-4ea4-ad9c-ebc87a385540,DISK], DatanodeInfoWithStorage[127.0.0.1:39375,DS-f1ef38db-d077-4ebf-aba5-445c15ba4a04,DISK], DatanodeInfoWithStorage[127.0.0.1:41767,DS-1936f7fd-81e4-432d-9844-1b286bbd4eec,DISK], DatanodeInfoWithStorage[127.0.0.1:40482,DS-a2695520-9187-45be-b257-0005ade8c8ae,DISK], DatanodeInfoWithStorage[127.0.0.1:43356,DS-3cd6efd6-cc8b-4db5-9d75-4874350f3d4a,DISK], DatanodeInfoWithStorage[127.0.0.1:38678,DS-b1e096ea-f769-4822-9374-f8dac1d7ebb3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2106699824-172.17.0.15-1598092030604:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40938,DS-7c75d616-031b-46d0-8e8f-79355138e6cc,DISK], DatanodeInfoWithStorage[127.0.0.1:36064,DS-62da6079-f1ca-48c9-9cab-df445e0734d9,DISK], DatanodeInfoWithStorage[127.0.0.1:38007,DS-d19c6f49-a418-4ea4-ad9c-ebc87a385540,DISK], DatanodeInfoWithStorage[127.0.0.1:39375,DS-f1ef38db-d077-4ebf-aba5-445c15ba4a04,DISK], DatanodeInfoWithStorage[127.0.0.1:41767,DS-1936f7fd-81e4-432d-9844-1b286bbd4eec,DISK], DatanodeInfoWithStorage[127.0.0.1:40482,DS-a2695520-9187-45be-b257-0005ade8c8ae,DISK], DatanodeInfoWithStorage[127.0.0.1:43356,DS-3cd6efd6-cc8b-4db5-9d75-4874350f3d4a,DISK], DatanodeInfoWithStorage[127.0.0.1:38678,DS-b1e096ea-f769-4822-9374-f8dac1d7ebb3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1403862072-172.17.0.15-1598092112314:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37753,DS-a1e4e4f6-2a57-4d4c-9b18-ea9828612d6a,DISK], DatanodeInfoWithStorage[127.0.0.1:42287,DS-c6619bd7-dbc0-4363-b51c-45e707074a7c,DISK], DatanodeInfoWithStorage[127.0.0.1:40990,DS-6bb781c1-f02f-451f-b8b9-c9cf42f21aa9,DISK], DatanodeInfoWithStorage[127.0.0.1:43024,DS-07e635e1-007b-4f4a-a3dd-b42f755b9da2,DISK], DatanodeInfoWithStorage[127.0.0.1:43869,DS-1e6050d9-bb34-4f55-935b-4cc865b33532,DISK], DatanodeInfoWithStorage[127.0.0.1:37334,DS-3ab9bcdc-1a96-4f8a-96dc-f32b6faf596f,DISK], DatanodeInfoWithStorage[127.0.0.1:40766,DS-45030ec4-8fca-45a4-9dba-d86b51e47f8b,DISK], DatanodeInfoWithStorage[127.0.0.1:35909,DS-a66bdb0c-1108-49d9-a84a-a378623793b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1403862072-172.17.0.15-1598092112314:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37753,DS-a1e4e4f6-2a57-4d4c-9b18-ea9828612d6a,DISK], DatanodeInfoWithStorage[127.0.0.1:42287,DS-c6619bd7-dbc0-4363-b51c-45e707074a7c,DISK], DatanodeInfoWithStorage[127.0.0.1:40990,DS-6bb781c1-f02f-451f-b8b9-c9cf42f21aa9,DISK], DatanodeInfoWithStorage[127.0.0.1:43024,DS-07e635e1-007b-4f4a-a3dd-b42f755b9da2,DISK], DatanodeInfoWithStorage[127.0.0.1:43869,DS-1e6050d9-bb34-4f55-935b-4cc865b33532,DISK], DatanodeInfoWithStorage[127.0.0.1:37334,DS-3ab9bcdc-1a96-4f8a-96dc-f32b6faf596f,DISK], DatanodeInfoWithStorage[127.0.0.1:40766,DS-45030ec4-8fca-45a4-9dba-d86b51e47f8b,DISK], DatanodeInfoWithStorage[127.0.0.1:35909,DS-a66bdb0c-1108-49d9-a84a-a378623793b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-161259442-172.17.0.15-1598092202273:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39724,DS-b8f992a1-066b-4863-b415-415f3dc6894d,DISK], DatanodeInfoWithStorage[127.0.0.1:37586,DS-8689ca24-203f-44e0-8736-9319f82895e3,DISK], DatanodeInfoWithStorage[127.0.0.1:34706,DS-a5b71e86-7cc0-4949-90e1-5ca843d8315d,DISK], DatanodeInfoWithStorage[127.0.0.1:39882,DS-2cd8c254-15b4-4453-aebf-ce704f6cfd50,DISK], DatanodeInfoWithStorage[127.0.0.1:33363,DS-ac1610bc-6061-4289-bece-7b1d4870264b,DISK], DatanodeInfoWithStorage[127.0.0.1:44048,DS-b4b72049-bf7e-4c41-9942-8a05fdf9f136,DISK], DatanodeInfoWithStorage[127.0.0.1:45860,DS-093ea7d2-673c-45ac-b87d-9aea9c698302,DISK], DatanodeInfoWithStorage[127.0.0.1:33835,DS-72c0e071-c69b-4556-9bd1-bd88cbb59dcb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-161259442-172.17.0.15-1598092202273:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39724,DS-b8f992a1-066b-4863-b415-415f3dc6894d,DISK], DatanodeInfoWithStorage[127.0.0.1:37586,DS-8689ca24-203f-44e0-8736-9319f82895e3,DISK], DatanodeInfoWithStorage[127.0.0.1:34706,DS-a5b71e86-7cc0-4949-90e1-5ca843d8315d,DISK], DatanodeInfoWithStorage[127.0.0.1:39882,DS-2cd8c254-15b4-4453-aebf-ce704f6cfd50,DISK], DatanodeInfoWithStorage[127.0.0.1:33363,DS-ac1610bc-6061-4289-bece-7b1d4870264b,DISK], DatanodeInfoWithStorage[127.0.0.1:44048,DS-b4b72049-bf7e-4c41-9942-8a05fdf9f136,DISK], DatanodeInfoWithStorage[127.0.0.1:45860,DS-093ea7d2-673c-45ac-b87d-9aea9c698302,DISK], DatanodeInfoWithStorage[127.0.0.1:33835,DS-72c0e071-c69b-4556-9bd1-bd88cbb59dcb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-544344952-172.17.0.15-1598092479803:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33206,DS-c482d232-047b-4957-8100-4fde8ba87cdf,DISK], DatanodeInfoWithStorage[127.0.0.1:33276,DS-474d3580-e706-406a-ab1b-c2ae96313b67,DISK], DatanodeInfoWithStorage[127.0.0.1:38398,DS-a36c19b7-a0b8-447b-8c56-ad5a60e5faf3,DISK], DatanodeInfoWithStorage[127.0.0.1:36988,DS-93e07132-82c3-4710-a558-4f7ebddcb579,DISK], DatanodeInfoWithStorage[127.0.0.1:36936,DS-5bef2903-8018-4d28-b79d-a6778f2aca13,DISK], DatanodeInfoWithStorage[127.0.0.1:34248,DS-deade2a0-0bfa-42f1-8714-2891c7fbd4ed,DISK], DatanodeInfoWithStorage[127.0.0.1:46397,DS-9dda3cc7-279b-45bb-a77e-ade280383cb2,DISK], DatanodeInfoWithStorage[127.0.0.1:44085,DS-5fd5f8c1-5901-4894-80d0-206fba89f0d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-544344952-172.17.0.15-1598092479803:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33206,DS-c482d232-047b-4957-8100-4fde8ba87cdf,DISK], DatanodeInfoWithStorage[127.0.0.1:33276,DS-474d3580-e706-406a-ab1b-c2ae96313b67,DISK], DatanodeInfoWithStorage[127.0.0.1:38398,DS-a36c19b7-a0b8-447b-8c56-ad5a60e5faf3,DISK], DatanodeInfoWithStorage[127.0.0.1:36988,DS-93e07132-82c3-4710-a558-4f7ebddcb579,DISK], DatanodeInfoWithStorage[127.0.0.1:36936,DS-5bef2903-8018-4d28-b79d-a6778f2aca13,DISK], DatanodeInfoWithStorage[127.0.0.1:34248,DS-deade2a0-0bfa-42f1-8714-2891c7fbd4ed,DISK], DatanodeInfoWithStorage[127.0.0.1:46397,DS-9dda3cc7-279b-45bb-a77e-ade280383cb2,DISK], DatanodeInfoWithStorage[127.0.0.1:44085,DS-5fd5f8c1-5901-4894-80d0-206fba89f0d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1865342278-172.17.0.15-1598093620486:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33829,DS-ddce4b41-7f5d-44c1-a124-b1a2f5a94602,DISK], DatanodeInfoWithStorage[127.0.0.1:34228,DS-b10e8cc8-9b09-4096-93e0-d7348eca4eb2,DISK], DatanodeInfoWithStorage[127.0.0.1:34392,DS-93b36891-2413-4811-a737-3bcf2b9b2ef8,DISK], DatanodeInfoWithStorage[127.0.0.1:37293,DS-81e58df3-38ea-4291-8763-80c55cf476ec,DISK], DatanodeInfoWithStorage[127.0.0.1:41067,DS-3d113c6e-0f6f-40c1-b9ed-4460b7bc071d,DISK], DatanodeInfoWithStorage[127.0.0.1:40699,DS-9a6dc49c-9524-41ac-9e2f-a48681166c89,DISK], DatanodeInfoWithStorage[127.0.0.1:44500,DS-3a60a281-4011-4ee0-95d5-75e3d397cc31,DISK], DatanodeInfoWithStorage[127.0.0.1:37697,DS-d82e267e-7852-42ba-ad28-37c17b2057ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1865342278-172.17.0.15-1598093620486:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33829,DS-ddce4b41-7f5d-44c1-a124-b1a2f5a94602,DISK], DatanodeInfoWithStorage[127.0.0.1:34228,DS-b10e8cc8-9b09-4096-93e0-d7348eca4eb2,DISK], DatanodeInfoWithStorage[127.0.0.1:34392,DS-93b36891-2413-4811-a737-3bcf2b9b2ef8,DISK], DatanodeInfoWithStorage[127.0.0.1:37293,DS-81e58df3-38ea-4291-8763-80c55cf476ec,DISK], DatanodeInfoWithStorage[127.0.0.1:41067,DS-3d113c6e-0f6f-40c1-b9ed-4460b7bc071d,DISK], DatanodeInfoWithStorage[127.0.0.1:40699,DS-9a6dc49c-9524-41ac-9e2f-a48681166c89,DISK], DatanodeInfoWithStorage[127.0.0.1:44500,DS-3a60a281-4011-4ee0-95d5-75e3d397cc31,DISK], DatanodeInfoWithStorage[127.0.0.1:37697,DS-d82e267e-7852-42ba-ad28-37c17b2057ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2007925309-172.17.0.15-1598093896830:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37135,DS-df490669-e551-497f-895d-c8f4be058365,DISK], DatanodeInfoWithStorage[127.0.0.1:36985,DS-c4ac4f0f-d366-468a-be5c-b03057bb9951,DISK], DatanodeInfoWithStorage[127.0.0.1:36794,DS-4de4c007-b8bf-4481-a758-e4db0c5d60c8,DISK], DatanodeInfoWithStorage[127.0.0.1:40016,DS-9ca6f722-d436-45cb-838d-c380b230d793,DISK], DatanodeInfoWithStorage[127.0.0.1:45843,DS-24b39be4-e19d-4a8b-96cd-035061d7243b,DISK], DatanodeInfoWithStorage[127.0.0.1:37079,DS-74f7f4a0-11c5-4163-aab8-5548712c05f7,DISK], DatanodeInfoWithStorage[127.0.0.1:37854,DS-9f402b6c-d32e-4575-b39e-df3b41cc036f,DISK], DatanodeInfoWithStorage[127.0.0.1:43286,DS-c76cb69f-05ae-4cf6-970e-e02f6b06c498,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2007925309-172.17.0.15-1598093896830:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37135,DS-df490669-e551-497f-895d-c8f4be058365,DISK], DatanodeInfoWithStorage[127.0.0.1:36985,DS-c4ac4f0f-d366-468a-be5c-b03057bb9951,DISK], DatanodeInfoWithStorage[127.0.0.1:36794,DS-4de4c007-b8bf-4481-a758-e4db0c5d60c8,DISK], DatanodeInfoWithStorage[127.0.0.1:40016,DS-9ca6f722-d436-45cb-838d-c380b230d793,DISK], DatanodeInfoWithStorage[127.0.0.1:45843,DS-24b39be4-e19d-4a8b-96cd-035061d7243b,DISK], DatanodeInfoWithStorage[127.0.0.1:37079,DS-74f7f4a0-11c5-4163-aab8-5548712c05f7,DISK], DatanodeInfoWithStorage[127.0.0.1:37854,DS-9f402b6c-d32e-4575-b39e-df3b41cc036f,DISK], DatanodeInfoWithStorage[127.0.0.1:43286,DS-c76cb69f-05ae-4cf6-970e-e02f6b06c498,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 5709
