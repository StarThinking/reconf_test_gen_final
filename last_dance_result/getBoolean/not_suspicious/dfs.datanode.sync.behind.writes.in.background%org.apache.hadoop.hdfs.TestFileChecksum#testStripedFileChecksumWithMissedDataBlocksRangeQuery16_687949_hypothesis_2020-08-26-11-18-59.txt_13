reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-564308363-172.17.0.10-1598441014153:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35814,DS-fc5118fd-05ee-4cf3-91dd-6578c9d296ee,DISK], DatanodeInfoWithStorage[127.0.0.1:43605,DS-2179c5e3-b9a3-4d9d-bb1d-e4c45f936abd,DISK], DatanodeInfoWithStorage[127.0.0.1:43406,DS-1b00eacf-19f5-4592-91c9-733f81551b8a,DISK], DatanodeInfoWithStorage[127.0.0.1:37139,DS-e5386aa2-e31f-4b05-86f8-a9e150bcbd60,DISK], DatanodeInfoWithStorage[127.0.0.1:38977,DS-8d3bae72-e1db-4a58-aad0-45b1439682b7,DISK], DatanodeInfoWithStorage[127.0.0.1:38231,DS-71f4c827-61d6-4ea2-a5c7-4d76978f6d56,DISK], DatanodeInfoWithStorage[127.0.0.1:39990,DS-d57121e2-0801-4764-b16c-0352471a79a4,DISK], DatanodeInfoWithStorage[127.0.0.1:35645,DS-0505b589-68c0-4b9a-b99c-634e3a4c725a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-564308363-172.17.0.10-1598441014153:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35814,DS-fc5118fd-05ee-4cf3-91dd-6578c9d296ee,DISK], DatanodeInfoWithStorage[127.0.0.1:43605,DS-2179c5e3-b9a3-4d9d-bb1d-e4c45f936abd,DISK], DatanodeInfoWithStorage[127.0.0.1:43406,DS-1b00eacf-19f5-4592-91c9-733f81551b8a,DISK], DatanodeInfoWithStorage[127.0.0.1:37139,DS-e5386aa2-e31f-4b05-86f8-a9e150bcbd60,DISK], DatanodeInfoWithStorage[127.0.0.1:38977,DS-8d3bae72-e1db-4a58-aad0-45b1439682b7,DISK], DatanodeInfoWithStorage[127.0.0.1:38231,DS-71f4c827-61d6-4ea2-a5c7-4d76978f6d56,DISK], DatanodeInfoWithStorage[127.0.0.1:39990,DS-d57121e2-0801-4764-b16c-0352471a79a4,DISK], DatanodeInfoWithStorage[127.0.0.1:35645,DS-0505b589-68c0-4b9a-b99c-634e3a4c725a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1721072370-172.17.0.10-1598441532405:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33525,DS-dadda829-06be-433f-8046-d5f00d5b93d9,DISK], DatanodeInfoWithStorage[127.0.0.1:38305,DS-38418024-7f42-48e2-9fb1-29c0ed036403,DISK], DatanodeInfoWithStorage[127.0.0.1:42061,DS-8830a9c3-66a4-4c7e-9f78-22f0f1da17b3,DISK], DatanodeInfoWithStorage[127.0.0.1:44286,DS-f1ac65a1-90a7-40f8-9dca-fae3f4c044a5,DISK], DatanodeInfoWithStorage[127.0.0.1:33631,DS-9fa00620-a8b6-4824-af6b-2d69869c0f9c,DISK], DatanodeInfoWithStorage[127.0.0.1:38800,DS-352b2a50-198b-4b78-be57-e6b5a4de7e07,DISK], DatanodeInfoWithStorage[127.0.0.1:34603,DS-48179729-4a9a-41d6-9c35-6c16a5b94d7d,DISK], DatanodeInfoWithStorage[127.0.0.1:34780,DS-03563733-2078-4191-8077-61e3f10e4509,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1721072370-172.17.0.10-1598441532405:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33525,DS-dadda829-06be-433f-8046-d5f00d5b93d9,DISK], DatanodeInfoWithStorage[127.0.0.1:38305,DS-38418024-7f42-48e2-9fb1-29c0ed036403,DISK], DatanodeInfoWithStorage[127.0.0.1:42061,DS-8830a9c3-66a4-4c7e-9f78-22f0f1da17b3,DISK], DatanodeInfoWithStorage[127.0.0.1:44286,DS-f1ac65a1-90a7-40f8-9dca-fae3f4c044a5,DISK], DatanodeInfoWithStorage[127.0.0.1:33631,DS-9fa00620-a8b6-4824-af6b-2d69869c0f9c,DISK], DatanodeInfoWithStorage[127.0.0.1:38800,DS-352b2a50-198b-4b78-be57-e6b5a4de7e07,DISK], DatanodeInfoWithStorage[127.0.0.1:34603,DS-48179729-4a9a-41d6-9c35-6c16a5b94d7d,DISK], DatanodeInfoWithStorage[127.0.0.1:34780,DS-03563733-2078-4191-8077-61e3f10e4509,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-656064310-172.17.0.10-1598442010165:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38494,DS-ce0db3b5-d9fd-473d-865f-e539ef9ccf15,DISK], DatanodeInfoWithStorage[127.0.0.1:43915,DS-d4bb6221-d111-4db4-9abe-04f28e60aedc,DISK], DatanodeInfoWithStorage[127.0.0.1:45729,DS-bb1ed9fa-4608-405a-ae39-95acfb5049c5,DISK], DatanodeInfoWithStorage[127.0.0.1:39400,DS-212aa79a-c264-4357-8357-a44045c75c60,DISK], DatanodeInfoWithStorage[127.0.0.1:33131,DS-7bae274f-5489-4024-8290-0c02c8b938fd,DISK], DatanodeInfoWithStorage[127.0.0.1:44890,DS-93ee7ba1-fb60-49bb-9f0c-3adcc93de48e,DISK], DatanodeInfoWithStorage[127.0.0.1:35667,DS-9521b304-da9c-4ec4-bbdf-56259083b9e6,DISK], DatanodeInfoWithStorage[127.0.0.1:44241,DS-9bff6cfd-207e-458e-9ee5-839c3b161fca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-656064310-172.17.0.10-1598442010165:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38494,DS-ce0db3b5-d9fd-473d-865f-e539ef9ccf15,DISK], DatanodeInfoWithStorage[127.0.0.1:43915,DS-d4bb6221-d111-4db4-9abe-04f28e60aedc,DISK], DatanodeInfoWithStorage[127.0.0.1:45729,DS-bb1ed9fa-4608-405a-ae39-95acfb5049c5,DISK], DatanodeInfoWithStorage[127.0.0.1:39400,DS-212aa79a-c264-4357-8357-a44045c75c60,DISK], DatanodeInfoWithStorage[127.0.0.1:33131,DS-7bae274f-5489-4024-8290-0c02c8b938fd,DISK], DatanodeInfoWithStorage[127.0.0.1:44890,DS-93ee7ba1-fb60-49bb-9f0c-3adcc93de48e,DISK], DatanodeInfoWithStorage[127.0.0.1:35667,DS-9521b304-da9c-4ec4-bbdf-56259083b9e6,DISK], DatanodeInfoWithStorage[127.0.0.1:44241,DS-9bff6cfd-207e-458e-9ee5-839c3b161fca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2103554177-172.17.0.10-1598442081864:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45687,DS-dce6976d-b861-45e6-9f3c-4dc3806e2b81,DISK], DatanodeInfoWithStorage[127.0.0.1:42425,DS-719697c7-cf39-40d0-8ed1-df50bdbb89b3,DISK], DatanodeInfoWithStorage[127.0.0.1:41074,DS-0503b532-a9e2-4000-8e60-917e9d14c709,DISK], DatanodeInfoWithStorage[127.0.0.1:43644,DS-8e339df8-99e9-41b8-8ade-0f1bf28a0bd0,DISK], DatanodeInfoWithStorage[127.0.0.1:45998,DS-391aba65-6a12-493b-a5d0-06ff36731af9,DISK], DatanodeInfoWithStorage[127.0.0.1:41656,DS-b936f073-fb6a-4585-94d1-54724547bb6c,DISK], DatanodeInfoWithStorage[127.0.0.1:43385,DS-f54954e2-e353-4798-b969-ac23bba41740,DISK], DatanodeInfoWithStorage[127.0.0.1:40657,DS-425242ce-d8cf-4e54-9d80-6e2d4f0f6957,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2103554177-172.17.0.10-1598442081864:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45687,DS-dce6976d-b861-45e6-9f3c-4dc3806e2b81,DISK], DatanodeInfoWithStorage[127.0.0.1:42425,DS-719697c7-cf39-40d0-8ed1-df50bdbb89b3,DISK], DatanodeInfoWithStorage[127.0.0.1:41074,DS-0503b532-a9e2-4000-8e60-917e9d14c709,DISK], DatanodeInfoWithStorage[127.0.0.1:43644,DS-8e339df8-99e9-41b8-8ade-0f1bf28a0bd0,DISK], DatanodeInfoWithStorage[127.0.0.1:45998,DS-391aba65-6a12-493b-a5d0-06ff36731af9,DISK], DatanodeInfoWithStorage[127.0.0.1:41656,DS-b936f073-fb6a-4585-94d1-54724547bb6c,DISK], DatanodeInfoWithStorage[127.0.0.1:43385,DS-f54954e2-e353-4798-b969-ac23bba41740,DISK], DatanodeInfoWithStorage[127.0.0.1:40657,DS-425242ce-d8cf-4e54-9d80-6e2d4f0f6957,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1793707662-172.17.0.10-1598442643753:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33861,DS-1a47c00f-d203-42e7-9638-8bb5447810c0,DISK], DatanodeInfoWithStorage[127.0.0.1:35123,DS-dc2c8aaa-85ab-43b9-8797-d6925838b1b1,DISK], DatanodeInfoWithStorage[127.0.0.1:42571,DS-996841d7-3112-4c18-938f-ffe10721df00,DISK], DatanodeInfoWithStorage[127.0.0.1:35501,DS-703aec28-022b-4f8c-8906-5e5da1ed9a1e,DISK], DatanodeInfoWithStorage[127.0.0.1:44516,DS-5f673aec-647e-42ec-b12c-20dc2de3599e,DISK], DatanodeInfoWithStorage[127.0.0.1:32918,DS-d24c9bb2-18f5-4949-953e-87f484470094,DISK], DatanodeInfoWithStorage[127.0.0.1:36363,DS-ae5f5210-a520-4fb4-b501-26d2d3d10181,DISK], DatanodeInfoWithStorage[127.0.0.1:33454,DS-7bbd4ae8-d372-4203-a10e-1709fd90f5e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1793707662-172.17.0.10-1598442643753:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33861,DS-1a47c00f-d203-42e7-9638-8bb5447810c0,DISK], DatanodeInfoWithStorage[127.0.0.1:35123,DS-dc2c8aaa-85ab-43b9-8797-d6925838b1b1,DISK], DatanodeInfoWithStorage[127.0.0.1:42571,DS-996841d7-3112-4c18-938f-ffe10721df00,DISK], DatanodeInfoWithStorage[127.0.0.1:35501,DS-703aec28-022b-4f8c-8906-5e5da1ed9a1e,DISK], DatanodeInfoWithStorage[127.0.0.1:44516,DS-5f673aec-647e-42ec-b12c-20dc2de3599e,DISK], DatanodeInfoWithStorage[127.0.0.1:32918,DS-d24c9bb2-18f5-4949-953e-87f484470094,DISK], DatanodeInfoWithStorage[127.0.0.1:36363,DS-ae5f5210-a520-4fb4-b501-26d2d3d10181,DISK], DatanodeInfoWithStorage[127.0.0.1:33454,DS-7bbd4ae8-d372-4203-a10e-1709fd90f5e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-193064324-172.17.0.10-1598443640381:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44213,DS-0ff7f37a-4f88-482a-96bf-fd5639a798ce,DISK], DatanodeInfoWithStorage[127.0.0.1:38502,DS-64791df9-b4ce-4478-bff3-6442736253a6,DISK], DatanodeInfoWithStorage[127.0.0.1:36443,DS-82e6129f-31e3-440a-bf09-1e80d175c4b7,DISK], DatanodeInfoWithStorage[127.0.0.1:41138,DS-f4d6c952-b908-40d4-8a76-14432c9166de,DISK], DatanodeInfoWithStorage[127.0.0.1:41745,DS-650daec7-51e0-40c1-8488-d1e95743101c,DISK], DatanodeInfoWithStorage[127.0.0.1:39685,DS-e09d226b-3ee9-4c22-81ad-7c1ce63242bf,DISK], DatanodeInfoWithStorage[127.0.0.1:34009,DS-b0342341-c14b-4552-8661-80042995f9ae,DISK], DatanodeInfoWithStorage[127.0.0.1:33079,DS-04f2f9c4-d913-487e-91c8-1da961f0ebce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-193064324-172.17.0.10-1598443640381:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44213,DS-0ff7f37a-4f88-482a-96bf-fd5639a798ce,DISK], DatanodeInfoWithStorage[127.0.0.1:38502,DS-64791df9-b4ce-4478-bff3-6442736253a6,DISK], DatanodeInfoWithStorage[127.0.0.1:36443,DS-82e6129f-31e3-440a-bf09-1e80d175c4b7,DISK], DatanodeInfoWithStorage[127.0.0.1:41138,DS-f4d6c952-b908-40d4-8a76-14432c9166de,DISK], DatanodeInfoWithStorage[127.0.0.1:41745,DS-650daec7-51e0-40c1-8488-d1e95743101c,DISK], DatanodeInfoWithStorage[127.0.0.1:39685,DS-e09d226b-3ee9-4c22-81ad-7c1ce63242bf,DISK], DatanodeInfoWithStorage[127.0.0.1:34009,DS-b0342341-c14b-4552-8661-80042995f9ae,DISK], DatanodeInfoWithStorage[127.0.0.1:33079,DS-04f2f9c4-d913-487e-91c8-1da961f0ebce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1142870267-172.17.0.10-1598444042204:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45363,DS-336710fd-28a0-4df2-8bc3-72f6109a2deb,DISK], DatanodeInfoWithStorage[127.0.0.1:41400,DS-84e3e188-6742-4a08-82f2-348e3d7c1915,DISK], DatanodeInfoWithStorage[127.0.0.1:34229,DS-939364b4-dcfb-4bb3-8e6f-a7203eaa39b7,DISK], DatanodeInfoWithStorage[127.0.0.1:41222,DS-cbf09b0b-f3eb-40a7-b245-a633b8c7ecc5,DISK], DatanodeInfoWithStorage[127.0.0.1:38314,DS-515a0e78-abed-467c-a511-8cb07c863954,DISK], DatanodeInfoWithStorage[127.0.0.1:33097,DS-5ec7287b-fb41-4dde-9864-4b8493302e89,DISK], DatanodeInfoWithStorage[127.0.0.1:39996,DS-3c6d3a97-d0de-4577-843d-182b05b25731,DISK], DatanodeInfoWithStorage[127.0.0.1:33155,DS-dbf36639-68dd-439c-9bac-2df99aec5150,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1142870267-172.17.0.10-1598444042204:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45363,DS-336710fd-28a0-4df2-8bc3-72f6109a2deb,DISK], DatanodeInfoWithStorage[127.0.0.1:41400,DS-84e3e188-6742-4a08-82f2-348e3d7c1915,DISK], DatanodeInfoWithStorage[127.0.0.1:34229,DS-939364b4-dcfb-4bb3-8e6f-a7203eaa39b7,DISK], DatanodeInfoWithStorage[127.0.0.1:41222,DS-cbf09b0b-f3eb-40a7-b245-a633b8c7ecc5,DISK], DatanodeInfoWithStorage[127.0.0.1:38314,DS-515a0e78-abed-467c-a511-8cb07c863954,DISK], DatanodeInfoWithStorage[127.0.0.1:33097,DS-5ec7287b-fb41-4dde-9864-4b8493302e89,DISK], DatanodeInfoWithStorage[127.0.0.1:39996,DS-3c6d3a97-d0de-4577-843d-182b05b25731,DISK], DatanodeInfoWithStorage[127.0.0.1:33155,DS-dbf36639-68dd-439c-9bac-2df99aec5150,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1189333388-172.17.0.10-1598444255919:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37136,DS-4f2a5aff-6091-4ec4-81b9-01f7fd1bb7da,DISK], DatanodeInfoWithStorage[127.0.0.1:35079,DS-1a043820-face-477b-b1c6-12f7accef722,DISK], DatanodeInfoWithStorage[127.0.0.1:43192,DS-aa143f2c-cb00-4d1a-9777-955470fdbd3d,DISK], DatanodeInfoWithStorage[127.0.0.1:40336,DS-81c220ed-ced8-4424-9574-ca420e5b7e61,DISK], DatanodeInfoWithStorage[127.0.0.1:37756,DS-d27a8b8c-6ae1-47d9-a8c2-4f5ff63960d7,DISK], DatanodeInfoWithStorage[127.0.0.1:44825,DS-d42e58c9-4abd-432d-9369-7d3ab2e3f22b,DISK], DatanodeInfoWithStorage[127.0.0.1:44426,DS-a3a06a8b-92f6-446b-9713-79bdae6f0fd1,DISK], DatanodeInfoWithStorage[127.0.0.1:35323,DS-7c477b73-7e0d-459f-93f8-84cfcc598ee5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1189333388-172.17.0.10-1598444255919:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37136,DS-4f2a5aff-6091-4ec4-81b9-01f7fd1bb7da,DISK], DatanodeInfoWithStorage[127.0.0.1:35079,DS-1a043820-face-477b-b1c6-12f7accef722,DISK], DatanodeInfoWithStorage[127.0.0.1:43192,DS-aa143f2c-cb00-4d1a-9777-955470fdbd3d,DISK], DatanodeInfoWithStorage[127.0.0.1:40336,DS-81c220ed-ced8-4424-9574-ca420e5b7e61,DISK], DatanodeInfoWithStorage[127.0.0.1:37756,DS-d27a8b8c-6ae1-47d9-a8c2-4f5ff63960d7,DISK], DatanodeInfoWithStorage[127.0.0.1:44825,DS-d42e58c9-4abd-432d-9369-7d3ab2e3f22b,DISK], DatanodeInfoWithStorage[127.0.0.1:44426,DS-a3a06a8b-92f6-446b-9713-79bdae6f0fd1,DISK], DatanodeInfoWithStorage[127.0.0.1:35323,DS-7c477b73-7e0d-459f-93f8-84cfcc598ee5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-619080952-172.17.0.10-1598444388505:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37006,DS-d91bd955-8572-43c9-8dcb-25d59f83454f,DISK], DatanodeInfoWithStorage[127.0.0.1:38156,DS-a3d038b3-80f3-43ed-abec-06252fe59114,DISK], DatanodeInfoWithStorage[127.0.0.1:33979,DS-46f24555-78ed-4874-904d-6aa9d2943c0c,DISK], DatanodeInfoWithStorage[127.0.0.1:35203,DS-eb70dafa-f92c-42e3-82a7-2541c1243286,DISK], DatanodeInfoWithStorage[127.0.0.1:45600,DS-b5fb2078-4fa5-426e-9730-7cc02a73131e,DISK], DatanodeInfoWithStorage[127.0.0.1:39787,DS-42cdb712-eb9c-4ba8-bb4b-c4d0803a6b2b,DISK], DatanodeInfoWithStorage[127.0.0.1:38531,DS-04103991-edd1-4c71-bbb2-2594ee9bea46,DISK], DatanodeInfoWithStorage[127.0.0.1:34608,DS-2e4fe11a-1f1b-405f-a1a8-f0316bf294ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-619080952-172.17.0.10-1598444388505:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37006,DS-d91bd955-8572-43c9-8dcb-25d59f83454f,DISK], DatanodeInfoWithStorage[127.0.0.1:38156,DS-a3d038b3-80f3-43ed-abec-06252fe59114,DISK], DatanodeInfoWithStorage[127.0.0.1:33979,DS-46f24555-78ed-4874-904d-6aa9d2943c0c,DISK], DatanodeInfoWithStorage[127.0.0.1:35203,DS-eb70dafa-f92c-42e3-82a7-2541c1243286,DISK], DatanodeInfoWithStorage[127.0.0.1:45600,DS-b5fb2078-4fa5-426e-9730-7cc02a73131e,DISK], DatanodeInfoWithStorage[127.0.0.1:39787,DS-42cdb712-eb9c-4ba8-bb4b-c4d0803a6b2b,DISK], DatanodeInfoWithStorage[127.0.0.1:38531,DS-04103991-edd1-4c71-bbb2-2594ee9bea46,DISK], DatanodeInfoWithStorage[127.0.0.1:34608,DS-2e4fe11a-1f1b-405f-a1a8-f0316bf294ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1718309985-172.17.0.10-1598444640908:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45870,DS-bc6421b7-ba78-4b38-ba08-9fe331db4425,DISK], DatanodeInfoWithStorage[127.0.0.1:40946,DS-2652e554-c024-4387-a27d-e89d64415320,DISK], DatanodeInfoWithStorage[127.0.0.1:44359,DS-a423eb44-df31-4be5-ae3d-aa53ee450c25,DISK], DatanodeInfoWithStorage[127.0.0.1:42355,DS-07ab6aac-def9-4c69-ba9c-7fffd26d54ef,DISK], DatanodeInfoWithStorage[127.0.0.1:41206,DS-e99f147b-cab7-410a-8758-b434c8319270,DISK], DatanodeInfoWithStorage[127.0.0.1:43664,DS-7f1ee4e4-18e3-4e21-940c-84cbc8392c1e,DISK], DatanodeInfoWithStorage[127.0.0.1:43754,DS-4cbac937-cf68-4cfe-81da-8312cbf098c6,DISK], DatanodeInfoWithStorage[127.0.0.1:42139,DS-a07a1c11-9237-451a-87db-3f3a9eaf7211,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1718309985-172.17.0.10-1598444640908:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45870,DS-bc6421b7-ba78-4b38-ba08-9fe331db4425,DISK], DatanodeInfoWithStorage[127.0.0.1:40946,DS-2652e554-c024-4387-a27d-e89d64415320,DISK], DatanodeInfoWithStorage[127.0.0.1:44359,DS-a423eb44-df31-4be5-ae3d-aa53ee450c25,DISK], DatanodeInfoWithStorage[127.0.0.1:42355,DS-07ab6aac-def9-4c69-ba9c-7fffd26d54ef,DISK], DatanodeInfoWithStorage[127.0.0.1:41206,DS-e99f147b-cab7-410a-8758-b434c8319270,DISK], DatanodeInfoWithStorage[127.0.0.1:43664,DS-7f1ee4e4-18e3-4e21-940c-84cbc8392c1e,DISK], DatanodeInfoWithStorage[127.0.0.1:43754,DS-4cbac937-cf68-4cfe-81da-8312cbf098c6,DISK], DatanodeInfoWithStorage[127.0.0.1:42139,DS-a07a1c11-9237-451a-87db-3f3a9eaf7211,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1961219048-172.17.0.10-1598445202994:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40800,DS-571afe22-950b-4391-827f-6598d89cbd51,DISK], DatanodeInfoWithStorage[127.0.0.1:44709,DS-9d075370-4a51-43b8-9430-b7c6f14a1590,DISK], DatanodeInfoWithStorage[127.0.0.1:42992,DS-15e568ba-477b-41b6-8cdc-e079a275cdcd,DISK], DatanodeInfoWithStorage[127.0.0.1:37861,DS-2dbaca66-5e69-4998-a152-910652e3cfff,DISK], DatanodeInfoWithStorage[127.0.0.1:38704,DS-91a3de9e-70e9-4500-8f6a-d70de249a275,DISK], DatanodeInfoWithStorage[127.0.0.1:37526,DS-30a31ccf-abc3-4773-b5c7-694b14d5ca2d,DISK], DatanodeInfoWithStorage[127.0.0.1:45916,DS-8ba5e86f-22cd-4af4-90fd-293124bd5883,DISK], DatanodeInfoWithStorage[127.0.0.1:43478,DS-4489daf7-8c80-4d8e-84ed-4558eb237d29,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1961219048-172.17.0.10-1598445202994:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40800,DS-571afe22-950b-4391-827f-6598d89cbd51,DISK], DatanodeInfoWithStorage[127.0.0.1:44709,DS-9d075370-4a51-43b8-9430-b7c6f14a1590,DISK], DatanodeInfoWithStorage[127.0.0.1:42992,DS-15e568ba-477b-41b6-8cdc-e079a275cdcd,DISK], DatanodeInfoWithStorage[127.0.0.1:37861,DS-2dbaca66-5e69-4998-a152-910652e3cfff,DISK], DatanodeInfoWithStorage[127.0.0.1:38704,DS-91a3de9e-70e9-4500-8f6a-d70de249a275,DISK], DatanodeInfoWithStorage[127.0.0.1:37526,DS-30a31ccf-abc3-4773-b5c7-694b14d5ca2d,DISK], DatanodeInfoWithStorage[127.0.0.1:45916,DS-8ba5e86f-22cd-4af4-90fd-293124bd5883,DISK], DatanodeInfoWithStorage[127.0.0.1:43478,DS-4489daf7-8c80-4d8e-84ed-4558eb237d29,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-539795850-172.17.0.10-1598445460472:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36399,DS-cc27d076-6781-487b-b93d-e8b640f50352,DISK], DatanodeInfoWithStorage[127.0.0.1:42469,DS-6a472093-4e35-4332-8f8e-8b77a2a6b1ae,DISK], DatanodeInfoWithStorage[127.0.0.1:42205,DS-853b7221-65a1-4525-820e-a2126bc91f46,DISK], DatanodeInfoWithStorage[127.0.0.1:39108,DS-c07c81a0-0680-4b7c-b0d9-939937f1303e,DISK], DatanodeInfoWithStorage[127.0.0.1:46773,DS-22939f6d-8d78-4920-97d8-014e1ad1ae63,DISK], DatanodeInfoWithStorage[127.0.0.1:35166,DS-196ac835-72e0-45fa-8d58-60601d998c33,DISK], DatanodeInfoWithStorage[127.0.0.1:46306,DS-1ddd18f8-6fbc-4ae5-8460-30496f571271,DISK], DatanodeInfoWithStorage[127.0.0.1:45430,DS-1bd1f984-c09b-42d2-a4de-9767348c0f9c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-539795850-172.17.0.10-1598445460472:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36399,DS-cc27d076-6781-487b-b93d-e8b640f50352,DISK], DatanodeInfoWithStorage[127.0.0.1:42469,DS-6a472093-4e35-4332-8f8e-8b77a2a6b1ae,DISK], DatanodeInfoWithStorage[127.0.0.1:42205,DS-853b7221-65a1-4525-820e-a2126bc91f46,DISK], DatanodeInfoWithStorage[127.0.0.1:39108,DS-c07c81a0-0680-4b7c-b0d9-939937f1303e,DISK], DatanodeInfoWithStorage[127.0.0.1:46773,DS-22939f6d-8d78-4920-97d8-014e1ad1ae63,DISK], DatanodeInfoWithStorage[127.0.0.1:35166,DS-196ac835-72e0-45fa-8d58-60601d998c33,DISK], DatanodeInfoWithStorage[127.0.0.1:46306,DS-1ddd18f8-6fbc-4ae5-8460-30496f571271,DISK], DatanodeInfoWithStorage[127.0.0.1:45430,DS-1bd1f984-c09b-42d2-a4de-9767348c0f9c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 7 out of 50
result: false positive !!!
Total execution time in seconds : 5230
