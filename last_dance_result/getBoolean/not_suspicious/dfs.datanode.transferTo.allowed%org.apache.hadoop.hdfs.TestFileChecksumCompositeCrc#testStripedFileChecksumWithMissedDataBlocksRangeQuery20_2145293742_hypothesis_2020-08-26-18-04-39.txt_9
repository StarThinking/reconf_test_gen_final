reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1752915099-172.17.0.13-1598465125149:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44782,DS-83673023-3c0d-4d6b-9699-a4ad8ece04ae,DISK], DatanodeInfoWithStorage[127.0.0.1:39411,DS-d985e7f4-346d-44ba-a3c5-a6eb12b2cc61,DISK], DatanodeInfoWithStorage[127.0.0.1:35867,DS-6022c308-4e63-4def-9dae-94d1c5cfc663,DISK], DatanodeInfoWithStorage[127.0.0.1:41518,DS-63b50df7-9ffb-405a-b8a9-3967c59bb727,DISK], DatanodeInfoWithStorage[127.0.0.1:36621,DS-d523ff2d-ad01-4326-8900-4296bbf254ed,DISK], DatanodeInfoWithStorage[127.0.0.1:45835,DS-3d27a1be-f13e-494b-8c7c-4a1d63950b69,DISK], DatanodeInfoWithStorage[127.0.0.1:34643,DS-bc83cf42-c0af-42cc-b9c3-52d2df39b96a,DISK], DatanodeInfoWithStorage[127.0.0.1:42985,DS-94e3a4e5-dc73-411b-b7aa-589945bee83d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1752915099-172.17.0.13-1598465125149:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44782,DS-83673023-3c0d-4d6b-9699-a4ad8ece04ae,DISK], DatanodeInfoWithStorage[127.0.0.1:39411,DS-d985e7f4-346d-44ba-a3c5-a6eb12b2cc61,DISK], DatanodeInfoWithStorage[127.0.0.1:35867,DS-6022c308-4e63-4def-9dae-94d1c5cfc663,DISK], DatanodeInfoWithStorage[127.0.0.1:41518,DS-63b50df7-9ffb-405a-b8a9-3967c59bb727,DISK], DatanodeInfoWithStorage[127.0.0.1:36621,DS-d523ff2d-ad01-4326-8900-4296bbf254ed,DISK], DatanodeInfoWithStorage[127.0.0.1:45835,DS-3d27a1be-f13e-494b-8c7c-4a1d63950b69,DISK], DatanodeInfoWithStorage[127.0.0.1:34643,DS-bc83cf42-c0af-42cc-b9c3-52d2df39b96a,DISK], DatanodeInfoWithStorage[127.0.0.1:42985,DS-94e3a4e5-dc73-411b-b7aa-589945bee83d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1899467685-172.17.0.13-1598465271023:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35949,DS-2798fb6e-0ffd-4c96-85c9-7c6183012b85,DISK], DatanodeInfoWithStorage[127.0.0.1:38448,DS-0d98cac8-ef35-456d-8f96-531c313cd84b,DISK], DatanodeInfoWithStorage[127.0.0.1:37391,DS-1a9d4109-1251-4ab7-8240-1aea9b8567bb,DISK], DatanodeInfoWithStorage[127.0.0.1:39519,DS-1edae1af-4591-41e6-b62d-9b41216eb90d,DISK], DatanodeInfoWithStorage[127.0.0.1:35054,DS-4b937309-5121-416d-9bf7-38d207dfa693,DISK], DatanodeInfoWithStorage[127.0.0.1:40084,DS-defeda3b-e28c-4b9f-bb6b-eaa69944702c,DISK], DatanodeInfoWithStorage[127.0.0.1:43562,DS-5f743904-aafa-4de5-b724-484d0f580523,DISK], DatanodeInfoWithStorage[127.0.0.1:43782,DS-ba5284b3-9fe6-4d76-a7c6-04d5aba47235,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1899467685-172.17.0.13-1598465271023:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35949,DS-2798fb6e-0ffd-4c96-85c9-7c6183012b85,DISK], DatanodeInfoWithStorage[127.0.0.1:38448,DS-0d98cac8-ef35-456d-8f96-531c313cd84b,DISK], DatanodeInfoWithStorage[127.0.0.1:37391,DS-1a9d4109-1251-4ab7-8240-1aea9b8567bb,DISK], DatanodeInfoWithStorage[127.0.0.1:39519,DS-1edae1af-4591-41e6-b62d-9b41216eb90d,DISK], DatanodeInfoWithStorage[127.0.0.1:35054,DS-4b937309-5121-416d-9bf7-38d207dfa693,DISK], DatanodeInfoWithStorage[127.0.0.1:40084,DS-defeda3b-e28c-4b9f-bb6b-eaa69944702c,DISK], DatanodeInfoWithStorage[127.0.0.1:43562,DS-5f743904-aafa-4de5-b724-484d0f580523,DISK], DatanodeInfoWithStorage[127.0.0.1:43782,DS-ba5284b3-9fe6-4d76-a7c6-04d5aba47235,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1614053827-172.17.0.13-1598465453237:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34750,DS-c4c20505-6e4b-4fd8-a3ca-548aeab9dd6a,DISK], DatanodeInfoWithStorage[127.0.0.1:33592,DS-c2496666-3dc8-4a70-a727-9181198ea455,DISK], DatanodeInfoWithStorage[127.0.0.1:38060,DS-7fc45b8c-3e71-4d01-97a9-45cd4a232cce,DISK], DatanodeInfoWithStorage[127.0.0.1:33856,DS-fad39f69-27a0-4081-9062-bfce8e417e45,DISK], DatanodeInfoWithStorage[127.0.0.1:37475,DS-676378dd-bb9a-415d-99ec-121fd224fde4,DISK], DatanodeInfoWithStorage[127.0.0.1:34796,DS-2af76e67-f3a7-483d-a056-84e2af32c126,DISK], DatanodeInfoWithStorage[127.0.0.1:44140,DS-57de8374-8526-45aa-a6f0-c5c34bef399c,DISK], DatanodeInfoWithStorage[127.0.0.1:46729,DS-b5b5517a-661e-4b90-85bc-cdf8374f13f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1614053827-172.17.0.13-1598465453237:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34750,DS-c4c20505-6e4b-4fd8-a3ca-548aeab9dd6a,DISK], DatanodeInfoWithStorage[127.0.0.1:33592,DS-c2496666-3dc8-4a70-a727-9181198ea455,DISK], DatanodeInfoWithStorage[127.0.0.1:38060,DS-7fc45b8c-3e71-4d01-97a9-45cd4a232cce,DISK], DatanodeInfoWithStorage[127.0.0.1:33856,DS-fad39f69-27a0-4081-9062-bfce8e417e45,DISK], DatanodeInfoWithStorage[127.0.0.1:37475,DS-676378dd-bb9a-415d-99ec-121fd224fde4,DISK], DatanodeInfoWithStorage[127.0.0.1:34796,DS-2af76e67-f3a7-483d-a056-84e2af32c126,DISK], DatanodeInfoWithStorage[127.0.0.1:44140,DS-57de8374-8526-45aa-a6f0-c5c34bef399c,DISK], DatanodeInfoWithStorage[127.0.0.1:46729,DS-b5b5517a-661e-4b90-85bc-cdf8374f13f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1686103151-172.17.0.13-1598465719979:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36900,DS-21232b77-39ea-418d-b6c2-33330781fc68,DISK], DatanodeInfoWithStorage[127.0.0.1:42080,DS-36dfa767-98d5-4e22-9514-f53cf2dd0643,DISK], DatanodeInfoWithStorage[127.0.0.1:45037,DS-de06f0aa-90af-4526-a542-b4115d5042ee,DISK], DatanodeInfoWithStorage[127.0.0.1:33243,DS-ad1bb493-cbc5-484b-9dc6-71666f33bc72,DISK], DatanodeInfoWithStorage[127.0.0.1:41950,DS-f1593e68-8e35-4637-89ae-03aa54bb6e27,DISK], DatanodeInfoWithStorage[127.0.0.1:43645,DS-83327b59-454c-4b65-90cd-33d03a316a03,DISK], DatanodeInfoWithStorage[127.0.0.1:34955,DS-8ec3c348-e2da-4560-852e-6d623032d790,DISK], DatanodeInfoWithStorage[127.0.0.1:42747,DS-fa547623-5af9-45b2-9bf0-0d4be22e2101,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1686103151-172.17.0.13-1598465719979:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36900,DS-21232b77-39ea-418d-b6c2-33330781fc68,DISK], DatanodeInfoWithStorage[127.0.0.1:42080,DS-36dfa767-98d5-4e22-9514-f53cf2dd0643,DISK], DatanodeInfoWithStorage[127.0.0.1:45037,DS-de06f0aa-90af-4526-a542-b4115d5042ee,DISK], DatanodeInfoWithStorage[127.0.0.1:33243,DS-ad1bb493-cbc5-484b-9dc6-71666f33bc72,DISK], DatanodeInfoWithStorage[127.0.0.1:41950,DS-f1593e68-8e35-4637-89ae-03aa54bb6e27,DISK], DatanodeInfoWithStorage[127.0.0.1:43645,DS-83327b59-454c-4b65-90cd-33d03a316a03,DISK], DatanodeInfoWithStorage[127.0.0.1:34955,DS-8ec3c348-e2da-4560-852e-6d623032d790,DISK], DatanodeInfoWithStorage[127.0.0.1:42747,DS-fa547623-5af9-45b2-9bf0-0d4be22e2101,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-759639813-172.17.0.13-1598465780187:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40348,DS-e3fada17-0c46-4420-872c-ffe414495eb9,DISK], DatanodeInfoWithStorage[127.0.0.1:38292,DS-59073b48-f35d-4de9-b819-e7b17fd9df53,DISK], DatanodeInfoWithStorage[127.0.0.1:39742,DS-190241c9-b0ec-4bf2-ad41-695b8c3385a7,DISK], DatanodeInfoWithStorage[127.0.0.1:36856,DS-6d348993-e66f-4838-b7bb-2773892beb0b,DISK], DatanodeInfoWithStorage[127.0.0.1:42506,DS-8e779e48-73b3-4692-8d84-bda2aa70076c,DISK], DatanodeInfoWithStorage[127.0.0.1:36730,DS-bcc0ecfa-d6e2-4dde-9e6d-26a134bda7bc,DISK], DatanodeInfoWithStorage[127.0.0.1:34211,DS-25c447ca-508f-4cc3-9ceb-949594581fa8,DISK], DatanodeInfoWithStorage[127.0.0.1:39637,DS-4c70f4a8-1c01-4168-8a75-70693ef25646,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-759639813-172.17.0.13-1598465780187:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40348,DS-e3fada17-0c46-4420-872c-ffe414495eb9,DISK], DatanodeInfoWithStorage[127.0.0.1:38292,DS-59073b48-f35d-4de9-b819-e7b17fd9df53,DISK], DatanodeInfoWithStorage[127.0.0.1:39742,DS-190241c9-b0ec-4bf2-ad41-695b8c3385a7,DISK], DatanodeInfoWithStorage[127.0.0.1:36856,DS-6d348993-e66f-4838-b7bb-2773892beb0b,DISK], DatanodeInfoWithStorage[127.0.0.1:42506,DS-8e779e48-73b3-4692-8d84-bda2aa70076c,DISK], DatanodeInfoWithStorage[127.0.0.1:36730,DS-bcc0ecfa-d6e2-4dde-9e6d-26a134bda7bc,DISK], DatanodeInfoWithStorage[127.0.0.1:34211,DS-25c447ca-508f-4cc3-9ceb-949594581fa8,DISK], DatanodeInfoWithStorage[127.0.0.1:39637,DS-4c70f4a8-1c01-4168-8a75-70693ef25646,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-464373321-172.17.0.13-1598466035295:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36138,DS-880230e9-17e5-4cbf-bf1f-193241da21f4,DISK], DatanodeInfoWithStorage[127.0.0.1:40458,DS-7ba36ddf-34eb-4725-b896-36feb651efe5,DISK], DatanodeInfoWithStorage[127.0.0.1:42850,DS-12a779d5-dbe5-4360-b2eb-dbbfb90f68d4,DISK], DatanodeInfoWithStorage[127.0.0.1:39574,DS-456b36db-6a25-4b88-ad9c-0564e05c86dc,DISK], DatanodeInfoWithStorage[127.0.0.1:43120,DS-3e172690-3405-4215-af6b-2628c9ee8e21,DISK], DatanodeInfoWithStorage[127.0.0.1:37619,DS-f0248f82-7505-4baf-b48e-00f48bdd86ef,DISK], DatanodeInfoWithStorage[127.0.0.1:35131,DS-63189054-6b73-4694-8c8b-41128b40efc4,DISK], DatanodeInfoWithStorage[127.0.0.1:32975,DS-ff56650e-aeb2-45c6-ab85-b9831a9a51c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-464373321-172.17.0.13-1598466035295:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36138,DS-880230e9-17e5-4cbf-bf1f-193241da21f4,DISK], DatanodeInfoWithStorage[127.0.0.1:40458,DS-7ba36ddf-34eb-4725-b896-36feb651efe5,DISK], DatanodeInfoWithStorage[127.0.0.1:42850,DS-12a779d5-dbe5-4360-b2eb-dbbfb90f68d4,DISK], DatanodeInfoWithStorage[127.0.0.1:39574,DS-456b36db-6a25-4b88-ad9c-0564e05c86dc,DISK], DatanodeInfoWithStorage[127.0.0.1:43120,DS-3e172690-3405-4215-af6b-2628c9ee8e21,DISK], DatanodeInfoWithStorage[127.0.0.1:37619,DS-f0248f82-7505-4baf-b48e-00f48bdd86ef,DISK], DatanodeInfoWithStorage[127.0.0.1:35131,DS-63189054-6b73-4694-8c8b-41128b40efc4,DISK], DatanodeInfoWithStorage[127.0.0.1:32975,DS-ff56650e-aeb2-45c6-ab85-b9831a9a51c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1307374376-172.17.0.13-1598466208593:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36838,DS-42c1c91f-a655-41af-b9c1-b7aac9ac506b,DISK], DatanodeInfoWithStorage[127.0.0.1:35745,DS-3bc2ba20-73ec-4dec-bdfd-b335368c9637,DISK], DatanodeInfoWithStorage[127.0.0.1:45266,DS-cd0842ae-c8f7-426f-97f0-9278fa8f21a4,DISK], DatanodeInfoWithStorage[127.0.0.1:33728,DS-c018dc78-eb09-42be-aa24-85f36e8b11d3,DISK], DatanodeInfoWithStorage[127.0.0.1:44491,DS-c6c37d0d-6e98-43f8-b91d-f37ae1ed0eba,DISK], DatanodeInfoWithStorage[127.0.0.1:44994,DS-b608bde2-3d54-4ebe-9347-6ca6f4274333,DISK], DatanodeInfoWithStorage[127.0.0.1:40173,DS-6c8f2fae-1438-45e5-ae59-9abd6f0c03bc,DISK], DatanodeInfoWithStorage[127.0.0.1:38306,DS-d6133bff-eedd-4980-8016-eceeddeffefb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1307374376-172.17.0.13-1598466208593:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36838,DS-42c1c91f-a655-41af-b9c1-b7aac9ac506b,DISK], DatanodeInfoWithStorage[127.0.0.1:35745,DS-3bc2ba20-73ec-4dec-bdfd-b335368c9637,DISK], DatanodeInfoWithStorage[127.0.0.1:45266,DS-cd0842ae-c8f7-426f-97f0-9278fa8f21a4,DISK], DatanodeInfoWithStorage[127.0.0.1:33728,DS-c018dc78-eb09-42be-aa24-85f36e8b11d3,DISK], DatanodeInfoWithStorage[127.0.0.1:44491,DS-c6c37d0d-6e98-43f8-b91d-f37ae1ed0eba,DISK], DatanodeInfoWithStorage[127.0.0.1:44994,DS-b608bde2-3d54-4ebe-9347-6ca6f4274333,DISK], DatanodeInfoWithStorage[127.0.0.1:40173,DS-6c8f2fae-1438-45e5-ae59-9abd6f0c03bc,DISK], DatanodeInfoWithStorage[127.0.0.1:38306,DS-d6133bff-eedd-4980-8016-eceeddeffefb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2089470771-172.17.0.13-1598466306055:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39824,DS-f9fefa65-3cdb-43db-be27-ea7dc5cee117,DISK], DatanodeInfoWithStorage[127.0.0.1:45376,DS-20723477-41af-4814-9f21-79a86d4e1fde,DISK], DatanodeInfoWithStorage[127.0.0.1:46315,DS-a8cae4c1-5a7e-46ce-b49f-a8b95ec67788,DISK], DatanodeInfoWithStorage[127.0.0.1:44781,DS-98f126d7-101c-4c52-8765-31516cf4e844,DISK], DatanodeInfoWithStorage[127.0.0.1:35956,DS-e31da58e-659a-4d95-87b0-c1b8edac5553,DISK], DatanodeInfoWithStorage[127.0.0.1:34590,DS-f58873a7-1ccb-4668-bcf6-14ccd67ac181,DISK], DatanodeInfoWithStorage[127.0.0.1:44394,DS-d0f5b720-ab88-4525-95ad-c2e37e4b0c79,DISK], DatanodeInfoWithStorage[127.0.0.1:44246,DS-e993b1ec-06a7-4c67-8c05-43ac1a600fb3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2089470771-172.17.0.13-1598466306055:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39824,DS-f9fefa65-3cdb-43db-be27-ea7dc5cee117,DISK], DatanodeInfoWithStorage[127.0.0.1:45376,DS-20723477-41af-4814-9f21-79a86d4e1fde,DISK], DatanodeInfoWithStorage[127.0.0.1:46315,DS-a8cae4c1-5a7e-46ce-b49f-a8b95ec67788,DISK], DatanodeInfoWithStorage[127.0.0.1:44781,DS-98f126d7-101c-4c52-8765-31516cf4e844,DISK], DatanodeInfoWithStorage[127.0.0.1:35956,DS-e31da58e-659a-4d95-87b0-c1b8edac5553,DISK], DatanodeInfoWithStorage[127.0.0.1:34590,DS-f58873a7-1ccb-4668-bcf6-14ccd67ac181,DISK], DatanodeInfoWithStorage[127.0.0.1:44394,DS-d0f5b720-ab88-4525-95ad-c2e37e4b0c79,DISK], DatanodeInfoWithStorage[127.0.0.1:44246,DS-e993b1ec-06a7-4c67-8c05-43ac1a600fb3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-300972844-172.17.0.13-1598467119551:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40290,DS-cbfcbd80-129d-4997-864e-0286a418e6da,DISK], DatanodeInfoWithStorage[127.0.0.1:41157,DS-cafa33f2-090f-4065-8136-3688a4b419cf,DISK], DatanodeInfoWithStorage[127.0.0.1:37963,DS-33c8bdc0-e690-4dbe-8e89-ae4da878ab8f,DISK], DatanodeInfoWithStorage[127.0.0.1:33592,DS-20df2330-d53e-48fc-bc8e-f414027cf83a,DISK], DatanodeInfoWithStorage[127.0.0.1:35943,DS-7e3cf78e-eda0-4c04-aa45-6d4e9c16474a,DISK], DatanodeInfoWithStorage[127.0.0.1:41770,DS-40be6d62-a7b9-40a3-b9bb-3d3ed8b5f9f4,DISK], DatanodeInfoWithStorage[127.0.0.1:39983,DS-8d338022-d040-4e15-9534-4c2bf33be171,DISK], DatanodeInfoWithStorage[127.0.0.1:38703,DS-25fe92a8-359d-418a-951c-2b34fbc7e10f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-300972844-172.17.0.13-1598467119551:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40290,DS-cbfcbd80-129d-4997-864e-0286a418e6da,DISK], DatanodeInfoWithStorage[127.0.0.1:41157,DS-cafa33f2-090f-4065-8136-3688a4b419cf,DISK], DatanodeInfoWithStorage[127.0.0.1:37963,DS-33c8bdc0-e690-4dbe-8e89-ae4da878ab8f,DISK], DatanodeInfoWithStorage[127.0.0.1:33592,DS-20df2330-d53e-48fc-bc8e-f414027cf83a,DISK], DatanodeInfoWithStorage[127.0.0.1:35943,DS-7e3cf78e-eda0-4c04-aa45-6d4e9c16474a,DISK], DatanodeInfoWithStorage[127.0.0.1:41770,DS-40be6d62-a7b9-40a3-b9bb-3d3ed8b5f9f4,DISK], DatanodeInfoWithStorage[127.0.0.1:39983,DS-8d338022-d040-4e15-9534-4c2bf33be171,DISK], DatanodeInfoWithStorage[127.0.0.1:38703,DS-25fe92a8-359d-418a-951c-2b34fbc7e10f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1794028827-172.17.0.13-1598467266893:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41597,DS-3a33e49d-a4cd-4731-9c7c-1d7257889cf4,DISK], DatanodeInfoWithStorage[127.0.0.1:34550,DS-53ced9e5-0112-493b-bb98-0a8a46dc42aa,DISK], DatanodeInfoWithStorage[127.0.0.1:46011,DS-8a11d171-7bcd-4600-9cac-072c63792dc0,DISK], DatanodeInfoWithStorage[127.0.0.1:40643,DS-31f751eb-848e-4f83-8195-6a3ce053c38a,DISK], DatanodeInfoWithStorage[127.0.0.1:35209,DS-b6d88591-a176-44f4-8703-cd501bc215f4,DISK], DatanodeInfoWithStorage[127.0.0.1:41581,DS-ccfc994c-6b8f-4506-b6ed-4adf9dbc6791,DISK], DatanodeInfoWithStorage[127.0.0.1:39226,DS-75758350-e279-4b20-ace1-80c611b38a1a,DISK], DatanodeInfoWithStorage[127.0.0.1:32986,DS-6ef16389-a485-4322-a0ce-fab431899522,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1794028827-172.17.0.13-1598467266893:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41597,DS-3a33e49d-a4cd-4731-9c7c-1d7257889cf4,DISK], DatanodeInfoWithStorage[127.0.0.1:34550,DS-53ced9e5-0112-493b-bb98-0a8a46dc42aa,DISK], DatanodeInfoWithStorage[127.0.0.1:46011,DS-8a11d171-7bcd-4600-9cac-072c63792dc0,DISK], DatanodeInfoWithStorage[127.0.0.1:40643,DS-31f751eb-848e-4f83-8195-6a3ce053c38a,DISK], DatanodeInfoWithStorage[127.0.0.1:35209,DS-b6d88591-a176-44f4-8703-cd501bc215f4,DISK], DatanodeInfoWithStorage[127.0.0.1:41581,DS-ccfc994c-6b8f-4506-b6ed-4adf9dbc6791,DISK], DatanodeInfoWithStorage[127.0.0.1:39226,DS-75758350-e279-4b20-ace1-80c611b38a1a,DISK], DatanodeInfoWithStorage[127.0.0.1:32986,DS-6ef16389-a485-4322-a0ce-fab431899522,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1907559629-172.17.0.13-1598467342926:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35613,DS-ef369080-2e71-4cb2-be62-00a42d570770,DISK], DatanodeInfoWithStorage[127.0.0.1:34633,DS-683824b6-2b51-4238-9720-4d038c1dd657,DISK], DatanodeInfoWithStorage[127.0.0.1:42052,DS-13c2e520-0f12-4b65-ae39-5bc299b6971c,DISK], DatanodeInfoWithStorage[127.0.0.1:34136,DS-0de2fb12-76f5-4cf4-acd1-7307e6477ae2,DISK], DatanodeInfoWithStorage[127.0.0.1:41470,DS-21673131-9b29-459c-bb72-5c9557de6fde,DISK], DatanodeInfoWithStorage[127.0.0.1:37290,DS-e579046d-6fcd-4c5c-b3e6-3d1f14b897ab,DISK], DatanodeInfoWithStorage[127.0.0.1:41650,DS-c3a1a420-768b-469d-9fc2-f1f086c52edc,DISK], DatanodeInfoWithStorage[127.0.0.1:33431,DS-473df401-41cd-4568-9ecb-86d4deb1dd7d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1907559629-172.17.0.13-1598467342926:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35613,DS-ef369080-2e71-4cb2-be62-00a42d570770,DISK], DatanodeInfoWithStorage[127.0.0.1:34633,DS-683824b6-2b51-4238-9720-4d038c1dd657,DISK], DatanodeInfoWithStorage[127.0.0.1:42052,DS-13c2e520-0f12-4b65-ae39-5bc299b6971c,DISK], DatanodeInfoWithStorage[127.0.0.1:34136,DS-0de2fb12-76f5-4cf4-acd1-7307e6477ae2,DISK], DatanodeInfoWithStorage[127.0.0.1:41470,DS-21673131-9b29-459c-bb72-5c9557de6fde,DISK], DatanodeInfoWithStorage[127.0.0.1:37290,DS-e579046d-6fcd-4c5c-b3e6-3d1f14b897ab,DISK], DatanodeInfoWithStorage[127.0.0.1:41650,DS-c3a1a420-768b-469d-9fc2-f1f086c52edc,DISK], DatanodeInfoWithStorage[127.0.0.1:33431,DS-473df401-41cd-4568-9ecb-86d4deb1dd7d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-854060799-172.17.0.13-1598467642375:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39268,DS-1bf9c5d6-5c7e-47c9-abb4-e83af3f691e6,DISK], DatanodeInfoWithStorage[127.0.0.1:38856,DS-1e3d2262-fbc4-4011-914c-4a937b6cebc5,DISK], DatanodeInfoWithStorage[127.0.0.1:36461,DS-7dcfeca3-495d-4248-bf2f-bc495241ca9c,DISK], DatanodeInfoWithStorage[127.0.0.1:45733,DS-dd957d34-9906-4366-9c55-a23331aa01d5,DISK], DatanodeInfoWithStorage[127.0.0.1:33590,DS-95a38e40-62a6-4511-b1a5-482f6fa04f81,DISK], DatanodeInfoWithStorage[127.0.0.1:41125,DS-48537f73-a4bc-45c6-b1d0-b56374555755,DISK], DatanodeInfoWithStorage[127.0.0.1:39696,DS-374c28f2-c2e3-4891-bc5b-0adb4fe7a9c7,DISK], DatanodeInfoWithStorage[127.0.0.1:43822,DS-91fe4078-c461-40da-8915-3d00c0b6fcf1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-854060799-172.17.0.13-1598467642375:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39268,DS-1bf9c5d6-5c7e-47c9-abb4-e83af3f691e6,DISK], DatanodeInfoWithStorage[127.0.0.1:38856,DS-1e3d2262-fbc4-4011-914c-4a937b6cebc5,DISK], DatanodeInfoWithStorage[127.0.0.1:36461,DS-7dcfeca3-495d-4248-bf2f-bc495241ca9c,DISK], DatanodeInfoWithStorage[127.0.0.1:45733,DS-dd957d34-9906-4366-9c55-a23331aa01d5,DISK], DatanodeInfoWithStorage[127.0.0.1:33590,DS-95a38e40-62a6-4511-b1a5-482f6fa04f81,DISK], DatanodeInfoWithStorage[127.0.0.1:41125,DS-48537f73-a4bc-45c6-b1d0-b56374555755,DISK], DatanodeInfoWithStorage[127.0.0.1:39696,DS-374c28f2-c2e3-4891-bc5b-0adb4fe7a9c7,DISK], DatanodeInfoWithStorage[127.0.0.1:43822,DS-91fe4078-c461-40da-8915-3d00c0b6fcf1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1307974850-172.17.0.13-1598467900508:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44507,DS-a16707c2-1b73-459c-899e-d97f1627889d,DISK], DatanodeInfoWithStorage[127.0.0.1:37902,DS-3867743e-611b-4bf4-be36-550c25946635,DISK], DatanodeInfoWithStorage[127.0.0.1:41625,DS-96c0ddbc-efc8-44a3-8a00-3fd01ca6c807,DISK], DatanodeInfoWithStorage[127.0.0.1:44145,DS-a0ea7951-238f-4b56-a555-a53849a95df5,DISK], DatanodeInfoWithStorage[127.0.0.1:43149,DS-81a711b9-a361-47f6-ae5f-45fbd65fea29,DISK], DatanodeInfoWithStorage[127.0.0.1:38565,DS-f9a422f9-df88-452a-b46d-c45904a94703,DISK], DatanodeInfoWithStorage[127.0.0.1:34454,DS-03e24443-6227-408d-ae8a-459765cad429,DISK], DatanodeInfoWithStorage[127.0.0.1:41235,DS-bd2df47f-e857-4dd9-b613-ec6a32b00195,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1307974850-172.17.0.13-1598467900508:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44507,DS-a16707c2-1b73-459c-899e-d97f1627889d,DISK], DatanodeInfoWithStorage[127.0.0.1:37902,DS-3867743e-611b-4bf4-be36-550c25946635,DISK], DatanodeInfoWithStorage[127.0.0.1:41625,DS-96c0ddbc-efc8-44a3-8a00-3fd01ca6c807,DISK], DatanodeInfoWithStorage[127.0.0.1:44145,DS-a0ea7951-238f-4b56-a555-a53849a95df5,DISK], DatanodeInfoWithStorage[127.0.0.1:43149,DS-81a711b9-a361-47f6-ae5f-45fbd65fea29,DISK], DatanodeInfoWithStorage[127.0.0.1:38565,DS-f9a422f9-df88-452a-b46d-c45904a94703,DISK], DatanodeInfoWithStorage[127.0.0.1:34454,DS-03e24443-6227-408d-ae8a-459765cad429,DISK], DatanodeInfoWithStorage[127.0.0.1:41235,DS-bd2df47f-e857-4dd9-b613-ec6a32b00195,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1907981968-172.17.0.13-1598468313964:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37404,DS-78f4dbc3-5fb4-413c-b8e4-eba18ee0bc2b,DISK], DatanodeInfoWithStorage[127.0.0.1:41351,DS-8082c2f5-4afd-4e42-94a9-876eb43116df,DISK], DatanodeInfoWithStorage[127.0.0.1:43073,DS-af491788-ccbf-4b67-9533-4d08bdc03249,DISK], DatanodeInfoWithStorage[127.0.0.1:41358,DS-7236498d-5cc7-441c-a5c4-bf090685018b,DISK], DatanodeInfoWithStorage[127.0.0.1:39371,DS-87206357-f696-4919-b6cd-4bd6e116dc09,DISK], DatanodeInfoWithStorage[127.0.0.1:42888,DS-8c66d448-6abb-4385-b250-e88c72bfa274,DISK], DatanodeInfoWithStorage[127.0.0.1:37947,DS-fa9af628-659b-48da-b98c-8c5db72fca69,DISK], DatanodeInfoWithStorage[127.0.0.1:41271,DS-68ac2101-9aed-4f60-8387-32bb206c6662,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1907981968-172.17.0.13-1598468313964:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37404,DS-78f4dbc3-5fb4-413c-b8e4-eba18ee0bc2b,DISK], DatanodeInfoWithStorage[127.0.0.1:41351,DS-8082c2f5-4afd-4e42-94a9-876eb43116df,DISK], DatanodeInfoWithStorage[127.0.0.1:43073,DS-af491788-ccbf-4b67-9533-4d08bdc03249,DISK], DatanodeInfoWithStorage[127.0.0.1:41358,DS-7236498d-5cc7-441c-a5c4-bf090685018b,DISK], DatanodeInfoWithStorage[127.0.0.1:39371,DS-87206357-f696-4919-b6cd-4bd6e116dc09,DISK], DatanodeInfoWithStorage[127.0.0.1:42888,DS-8c66d448-6abb-4385-b250-e88c72bfa274,DISK], DatanodeInfoWithStorage[127.0.0.1:37947,DS-fa9af628-659b-48da-b98c-8c5db72fca69,DISK], DatanodeInfoWithStorage[127.0.0.1:41271,DS-68ac2101-9aed-4f60-8387-32bb206c6662,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-663579902-172.17.0.13-1598468392682:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39054,DS-aba5ee41-73c5-4ea8-89ae-c73441492d83,DISK], DatanodeInfoWithStorage[127.0.0.1:37761,DS-7996a01a-c376-40cc-be93-1fd76626ca3a,DISK], DatanodeInfoWithStorage[127.0.0.1:37493,DS-80f2d94e-88ed-42f9-9e5c-7a9ab71d80c3,DISK], DatanodeInfoWithStorage[127.0.0.1:44819,DS-d7b39c35-b883-402c-881c-35927806fabe,DISK], DatanodeInfoWithStorage[127.0.0.1:37672,DS-60862ed5-b271-4ea2-b031-b4e342a0a58a,DISK], DatanodeInfoWithStorage[127.0.0.1:38417,DS-a5500a45-96bc-48f2-ad3c-8de1f17db205,DISK], DatanodeInfoWithStorage[127.0.0.1:41140,DS-b75873e8-1baa-489d-bd6c-702cf0462e6a,DISK], DatanodeInfoWithStorage[127.0.0.1:46054,DS-bcc8f380-3464-4664-90ca-d78bab244f77,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-663579902-172.17.0.13-1598468392682:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39054,DS-aba5ee41-73c5-4ea8-89ae-c73441492d83,DISK], DatanodeInfoWithStorage[127.0.0.1:37761,DS-7996a01a-c376-40cc-be93-1fd76626ca3a,DISK], DatanodeInfoWithStorage[127.0.0.1:37493,DS-80f2d94e-88ed-42f9-9e5c-7a9ab71d80c3,DISK], DatanodeInfoWithStorage[127.0.0.1:44819,DS-d7b39c35-b883-402c-881c-35927806fabe,DISK], DatanodeInfoWithStorage[127.0.0.1:37672,DS-60862ed5-b271-4ea2-b031-b4e342a0a58a,DISK], DatanodeInfoWithStorage[127.0.0.1:38417,DS-a5500a45-96bc-48f2-ad3c-8de1f17db205,DISK], DatanodeInfoWithStorage[127.0.0.1:41140,DS-b75873e8-1baa-489d-bd6c-702cf0462e6a,DISK], DatanodeInfoWithStorage[127.0.0.1:46054,DS-bcc8f380-3464-4664-90ca-d78bab244f77,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1305594305-172.17.0.13-1598468564579:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36422,DS-52b44840-ec3a-4e05-945a-cacc6ac62588,DISK], DatanodeInfoWithStorage[127.0.0.1:33217,DS-d840fc64-7450-4945-9886-717eac6bba7a,DISK], DatanodeInfoWithStorage[127.0.0.1:44739,DS-deb21da5-f1fd-4c8a-9e51-30464e386699,DISK], DatanodeInfoWithStorage[127.0.0.1:42557,DS-9bd1e42a-cf15-4364-b2d2-4ca3409bee88,DISK], DatanodeInfoWithStorage[127.0.0.1:42625,DS-bf90485d-2eca-4ee2-b288-520680cd22db,DISK], DatanodeInfoWithStorage[127.0.0.1:35351,DS-44f8d378-9136-4111-b394-709627ab0235,DISK], DatanodeInfoWithStorage[127.0.0.1:33717,DS-284f762d-e6ea-4c98-a058-7730eb1ef3ba,DISK], DatanodeInfoWithStorage[127.0.0.1:46386,DS-ea9f2e10-5cf8-4128-aaeb-da2ea402e6bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1305594305-172.17.0.13-1598468564579:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36422,DS-52b44840-ec3a-4e05-945a-cacc6ac62588,DISK], DatanodeInfoWithStorage[127.0.0.1:33217,DS-d840fc64-7450-4945-9886-717eac6bba7a,DISK], DatanodeInfoWithStorage[127.0.0.1:44739,DS-deb21da5-f1fd-4c8a-9e51-30464e386699,DISK], DatanodeInfoWithStorage[127.0.0.1:42557,DS-9bd1e42a-cf15-4364-b2d2-4ca3409bee88,DISK], DatanodeInfoWithStorage[127.0.0.1:42625,DS-bf90485d-2eca-4ee2-b288-520680cd22db,DISK], DatanodeInfoWithStorage[127.0.0.1:35351,DS-44f8d378-9136-4111-b394-709627ab0235,DISK], DatanodeInfoWithStorage[127.0.0.1:33717,DS-284f762d-e6ea-4c98-a058-7730eb1ef3ba,DISK], DatanodeInfoWithStorage[127.0.0.1:46386,DS-ea9f2e10-5cf8-4128-aaeb-da2ea402e6bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-169275342-172.17.0.13-1598468853206:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44889,DS-2ad78545-86bb-4d87-8ebd-c2f61bf6dbae,DISK], DatanodeInfoWithStorage[127.0.0.1:37579,DS-17a8e071-04ee-4383-ad97-5e568216d460,DISK], DatanodeInfoWithStorage[127.0.0.1:44729,DS-b8e5207f-75ba-424a-96d5-aced777f4a6d,DISK], DatanodeInfoWithStorage[127.0.0.1:46578,DS-164d6031-9ec9-4851-bee2-bc5ef8005944,DISK], DatanodeInfoWithStorage[127.0.0.1:38772,DS-eaeaca49-9452-414b-92d9-b175bd418f92,DISK], DatanodeInfoWithStorage[127.0.0.1:42355,DS-78401e07-e6fe-4f91-bd6e-a87278519a74,DISK], DatanodeInfoWithStorage[127.0.0.1:35632,DS-8221f25e-3c4e-4162-a310-f372625dd1c6,DISK], DatanodeInfoWithStorage[127.0.0.1:42912,DS-0dc82589-c106-4079-a28e-4298cc6a97d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-169275342-172.17.0.13-1598468853206:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44889,DS-2ad78545-86bb-4d87-8ebd-c2f61bf6dbae,DISK], DatanodeInfoWithStorage[127.0.0.1:37579,DS-17a8e071-04ee-4383-ad97-5e568216d460,DISK], DatanodeInfoWithStorage[127.0.0.1:44729,DS-b8e5207f-75ba-424a-96d5-aced777f4a6d,DISK], DatanodeInfoWithStorage[127.0.0.1:46578,DS-164d6031-9ec9-4851-bee2-bc5ef8005944,DISK], DatanodeInfoWithStorage[127.0.0.1:38772,DS-eaeaca49-9452-414b-92d9-b175bd418f92,DISK], DatanodeInfoWithStorage[127.0.0.1:42355,DS-78401e07-e6fe-4f91-bd6e-a87278519a74,DISK], DatanodeInfoWithStorage[127.0.0.1:35632,DS-8221f25e-3c4e-4162-a310-f372625dd1c6,DISK], DatanodeInfoWithStorage[127.0.0.1:42912,DS-0dc82589-c106-4079-a28e-4298cc6a97d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2080040353-172.17.0.13-1598469272362:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36304,DS-b298be68-7993-4457-b231-6efe77213dc2,DISK], DatanodeInfoWithStorage[127.0.0.1:39055,DS-f053aa74-f18a-48b1-b63a-bf1d5475035a,DISK], DatanodeInfoWithStorage[127.0.0.1:35171,DS-72596aa6-4224-4185-99e5-51a7897df33c,DISK], DatanodeInfoWithStorage[127.0.0.1:44288,DS-b836386f-145b-4f80-bb14-a85dac119fd0,DISK], DatanodeInfoWithStorage[127.0.0.1:44562,DS-7126a5de-e8dc-41e5-8ee9-128d9eac3552,DISK], DatanodeInfoWithStorage[127.0.0.1:33919,DS-b9067b5e-bed1-4abb-9765-108223eb99e6,DISK], DatanodeInfoWithStorage[127.0.0.1:45702,DS-d869629b-3af4-4838-82a1-64df1d35cd0a,DISK], DatanodeInfoWithStorage[127.0.0.1:40227,DS-9dfb0574-ea2a-42b8-a52f-7a953e60686d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2080040353-172.17.0.13-1598469272362:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36304,DS-b298be68-7993-4457-b231-6efe77213dc2,DISK], DatanodeInfoWithStorage[127.0.0.1:39055,DS-f053aa74-f18a-48b1-b63a-bf1d5475035a,DISK], DatanodeInfoWithStorage[127.0.0.1:35171,DS-72596aa6-4224-4185-99e5-51a7897df33c,DISK], DatanodeInfoWithStorage[127.0.0.1:44288,DS-b836386f-145b-4f80-bb14-a85dac119fd0,DISK], DatanodeInfoWithStorage[127.0.0.1:44562,DS-7126a5de-e8dc-41e5-8ee9-128d9eac3552,DISK], DatanodeInfoWithStorage[127.0.0.1:33919,DS-b9067b5e-bed1-4abb-9765-108223eb99e6,DISK], DatanodeInfoWithStorage[127.0.0.1:45702,DS-d869629b-3af4-4838-82a1-64df1d35cd0a,DISK], DatanodeInfoWithStorage[127.0.0.1:40227,DS-9dfb0574-ea2a-42b8-a52f-7a953e60686d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1917419438-172.17.0.13-1598469525425:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39090,DS-2894d198-cfbb-416b-8da6-eb2974908031,DISK], DatanodeInfoWithStorage[127.0.0.1:39214,DS-19d4923f-a5ef-4d1d-9fe1-d7bccf8df4a6,DISK], DatanodeInfoWithStorage[127.0.0.1:40467,DS-f47be247-c632-4f37-b4ee-76bb288e776b,DISK], DatanodeInfoWithStorage[127.0.0.1:36599,DS-b028e4c6-d7cd-41fa-b4bc-9ea76e68c008,DISK], DatanodeInfoWithStorage[127.0.0.1:40592,DS-f5baf2fe-15bf-4d81-92ce-fc7a0d37b6da,DISK], DatanodeInfoWithStorage[127.0.0.1:37497,DS-3882de5c-67a4-46b2-b0a2-480f774c0da5,DISK], DatanodeInfoWithStorage[127.0.0.1:38222,DS-c2572fb5-cd2b-4948-991f-907ee90c3137,DISK], DatanodeInfoWithStorage[127.0.0.1:35938,DS-f6530239-ebc2-4385-bfd2-83194af92d50,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1917419438-172.17.0.13-1598469525425:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39090,DS-2894d198-cfbb-416b-8da6-eb2974908031,DISK], DatanodeInfoWithStorage[127.0.0.1:39214,DS-19d4923f-a5ef-4d1d-9fe1-d7bccf8df4a6,DISK], DatanodeInfoWithStorage[127.0.0.1:40467,DS-f47be247-c632-4f37-b4ee-76bb288e776b,DISK], DatanodeInfoWithStorage[127.0.0.1:36599,DS-b028e4c6-d7cd-41fa-b4bc-9ea76e68c008,DISK], DatanodeInfoWithStorage[127.0.0.1:40592,DS-f5baf2fe-15bf-4d81-92ce-fc7a0d37b6da,DISK], DatanodeInfoWithStorage[127.0.0.1:37497,DS-3882de5c-67a4-46b2-b0a2-480f774c0da5,DISK], DatanodeInfoWithStorage[127.0.0.1:38222,DS-c2572fb5-cd2b-4948-991f-907ee90c3137,DISK], DatanodeInfoWithStorage[127.0.0.1:35938,DS-f6530239-ebc2-4385-bfd2-83194af92d50,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-276658636-172.17.0.13-1598470459651:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34869,DS-d27d91b1-f653-4ab3-8e74-113ac409087b,DISK], DatanodeInfoWithStorage[127.0.0.1:37098,DS-a439715d-9fa1-4567-8d3d-cab4250b50bc,DISK], DatanodeInfoWithStorage[127.0.0.1:37042,DS-3ab6ec2a-b44d-4c89-88b1-c106ab7c8fd5,DISK], DatanodeInfoWithStorage[127.0.0.1:42300,DS-d5ff274c-1371-4818-8759-26e8d5904729,DISK], DatanodeInfoWithStorage[127.0.0.1:45357,DS-0c3c1e9f-3c89-41e4-8f8d-78f18f2405dd,DISK], DatanodeInfoWithStorage[127.0.0.1:39870,DS-6e6fc324-f0d5-49a5-8b87-7d4e722c8773,DISK], DatanodeInfoWithStorage[127.0.0.1:37606,DS-a0b97a29-e80f-4812-99e5-ad0b6b728596,DISK], DatanodeInfoWithStorage[127.0.0.1:42937,DS-aa65743f-14f3-4446-9597-936623e37b07,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-276658636-172.17.0.13-1598470459651:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34869,DS-d27d91b1-f653-4ab3-8e74-113ac409087b,DISK], DatanodeInfoWithStorage[127.0.0.1:37098,DS-a439715d-9fa1-4567-8d3d-cab4250b50bc,DISK], DatanodeInfoWithStorage[127.0.0.1:37042,DS-3ab6ec2a-b44d-4c89-88b1-c106ab7c8fd5,DISK], DatanodeInfoWithStorage[127.0.0.1:42300,DS-d5ff274c-1371-4818-8759-26e8d5904729,DISK], DatanodeInfoWithStorage[127.0.0.1:45357,DS-0c3c1e9f-3c89-41e4-8f8d-78f18f2405dd,DISK], DatanodeInfoWithStorage[127.0.0.1:39870,DS-6e6fc324-f0d5-49a5-8b87-7d4e722c8773,DISK], DatanodeInfoWithStorage[127.0.0.1:37606,DS-a0b97a29-e80f-4812-99e5-ad0b6b728596,DISK], DatanodeInfoWithStorage[127.0.0.1:42937,DS-aa65743f-14f3-4446-9597-936623e37b07,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5404
