reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1575074613-172.17.0.5-1598422276227:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43388,DS-15f5aac3-85de-42ed-9889-1bb51dd20acc,DISK], DatanodeInfoWithStorage[127.0.0.1:45230,DS-9e68a3ab-b02d-4725-b6ca-544a47be99a7,DISK], DatanodeInfoWithStorage[127.0.0.1:42843,DS-f1822a4f-f945-41d8-90e1-b49441e429cc,DISK], DatanodeInfoWithStorage[127.0.0.1:37713,DS-4a1564f9-b535-4721-ae49-c4fe252b72e4,DISK], DatanodeInfoWithStorage[127.0.0.1:45913,DS-6dc3b89c-2219-4715-a84a-56f404d47afe,DISK], DatanodeInfoWithStorage[127.0.0.1:39282,DS-ac4af65a-71af-4d51-9225-648f0cc7b8e6,DISK], DatanodeInfoWithStorage[127.0.0.1:39107,DS-6de6be16-34bd-41e5-90bf-85516c576729,DISK], DatanodeInfoWithStorage[127.0.0.1:34783,DS-f6b1328c-4d29-4ec2-9ce2-423989f33aa8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1575074613-172.17.0.5-1598422276227:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43388,DS-15f5aac3-85de-42ed-9889-1bb51dd20acc,DISK], DatanodeInfoWithStorage[127.0.0.1:45230,DS-9e68a3ab-b02d-4725-b6ca-544a47be99a7,DISK], DatanodeInfoWithStorage[127.0.0.1:42843,DS-f1822a4f-f945-41d8-90e1-b49441e429cc,DISK], DatanodeInfoWithStorage[127.0.0.1:37713,DS-4a1564f9-b535-4721-ae49-c4fe252b72e4,DISK], DatanodeInfoWithStorage[127.0.0.1:45913,DS-6dc3b89c-2219-4715-a84a-56f404d47afe,DISK], DatanodeInfoWithStorage[127.0.0.1:39282,DS-ac4af65a-71af-4d51-9225-648f0cc7b8e6,DISK], DatanodeInfoWithStorage[127.0.0.1:39107,DS-6de6be16-34bd-41e5-90bf-85516c576729,DISK], DatanodeInfoWithStorage[127.0.0.1:34783,DS-f6b1328c-4d29-4ec2-9ce2-423989f33aa8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-920346153-172.17.0.5-1598422345437:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45993,DS-8382cf7b-f1fb-4808-b3ba-24adc7f061ff,DISK], DatanodeInfoWithStorage[127.0.0.1:40873,DS-1f9bb72b-badf-4cef-b781-efc99b647505,DISK], DatanodeInfoWithStorage[127.0.0.1:46702,DS-5dc0c096-2c9e-47c6-850f-6823fd71a621,DISK], DatanodeInfoWithStorage[127.0.0.1:34420,DS-41970d8a-08eb-40e2-826e-bab058d547ab,DISK], DatanodeInfoWithStorage[127.0.0.1:41480,DS-047c303e-012f-4172-90d5-40f096c98f8f,DISK], DatanodeInfoWithStorage[127.0.0.1:32859,DS-1fcac2c4-ce9f-4717-ba3e-26fb69440ce9,DISK], DatanodeInfoWithStorage[127.0.0.1:34637,DS-ae657289-2484-4eaf-8548-23d018c67566,DISK], DatanodeInfoWithStorage[127.0.0.1:46837,DS-adb4b54d-7de0-4bb8-8fbb-1b51fe703e6e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-920346153-172.17.0.5-1598422345437:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45993,DS-8382cf7b-f1fb-4808-b3ba-24adc7f061ff,DISK], DatanodeInfoWithStorage[127.0.0.1:40873,DS-1f9bb72b-badf-4cef-b781-efc99b647505,DISK], DatanodeInfoWithStorage[127.0.0.1:46702,DS-5dc0c096-2c9e-47c6-850f-6823fd71a621,DISK], DatanodeInfoWithStorage[127.0.0.1:34420,DS-41970d8a-08eb-40e2-826e-bab058d547ab,DISK], DatanodeInfoWithStorage[127.0.0.1:41480,DS-047c303e-012f-4172-90d5-40f096c98f8f,DISK], DatanodeInfoWithStorage[127.0.0.1:32859,DS-1fcac2c4-ce9f-4717-ba3e-26fb69440ce9,DISK], DatanodeInfoWithStorage[127.0.0.1:34637,DS-ae657289-2484-4eaf-8548-23d018c67566,DISK], DatanodeInfoWithStorage[127.0.0.1:46837,DS-adb4b54d-7de0-4bb8-8fbb-1b51fe703e6e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1188944614-172.17.0.5-1598422533207:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37211,DS-e23d36e1-7ef4-42ad-9b54-34f63ee994c6,DISK], DatanodeInfoWithStorage[127.0.0.1:44450,DS-7b34b706-37a1-4ef7-a3fa-98d8c11508fa,DISK], DatanodeInfoWithStorage[127.0.0.1:39285,DS-80e2d3c6-5eba-4c63-8f9c-96e925ad32ec,DISK], DatanodeInfoWithStorage[127.0.0.1:42209,DS-806cf6f4-1437-45bb-a151-c1ca1d272da7,DISK], DatanodeInfoWithStorage[127.0.0.1:33492,DS-63c3a9c9-bf6f-405c-bb60-0ad99bfb96a5,DISK], DatanodeInfoWithStorage[127.0.0.1:44237,DS-adf308c0-65f5-4405-a402-85787f6e685c,DISK], DatanodeInfoWithStorage[127.0.0.1:35041,DS-9c62d281-a29c-469b-83e0-fcddea617617,DISK], DatanodeInfoWithStorage[127.0.0.1:35603,DS-e8cfaf68-84bc-4cb1-89ca-e239383ed3bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1188944614-172.17.0.5-1598422533207:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37211,DS-e23d36e1-7ef4-42ad-9b54-34f63ee994c6,DISK], DatanodeInfoWithStorage[127.0.0.1:44450,DS-7b34b706-37a1-4ef7-a3fa-98d8c11508fa,DISK], DatanodeInfoWithStorage[127.0.0.1:39285,DS-80e2d3c6-5eba-4c63-8f9c-96e925ad32ec,DISK], DatanodeInfoWithStorage[127.0.0.1:42209,DS-806cf6f4-1437-45bb-a151-c1ca1d272da7,DISK], DatanodeInfoWithStorage[127.0.0.1:33492,DS-63c3a9c9-bf6f-405c-bb60-0ad99bfb96a5,DISK], DatanodeInfoWithStorage[127.0.0.1:44237,DS-adf308c0-65f5-4405-a402-85787f6e685c,DISK], DatanodeInfoWithStorage[127.0.0.1:35041,DS-9c62d281-a29c-469b-83e0-fcddea617617,DISK], DatanodeInfoWithStorage[127.0.0.1:35603,DS-e8cfaf68-84bc-4cb1-89ca-e239383ed3bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-223355308-172.17.0.5-1598422665842:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46739,DS-388cb4a2-ccf5-4904-b356-3ce2efe9aa74,DISK], DatanodeInfoWithStorage[127.0.0.1:33473,DS-cfa7981f-a048-4692-8ee6-51c551507a7d,DISK], DatanodeInfoWithStorage[127.0.0.1:35888,DS-a84ea3ef-a782-4673-9c5d-94794594ce7e,DISK], DatanodeInfoWithStorage[127.0.0.1:35947,DS-de2a0b18-6906-426d-8c45-75a0f0964a59,DISK], DatanodeInfoWithStorage[127.0.0.1:44686,DS-3a9025c2-3cd6-43c1-a784-6a4952928714,DISK], DatanodeInfoWithStorage[127.0.0.1:34041,DS-1af4fd43-f2ed-40de-8a56-e5edb469b8ff,DISK], DatanodeInfoWithStorage[127.0.0.1:40041,DS-f4abfee1-ca70-4227-b5c6-05cba1bab2e3,DISK], DatanodeInfoWithStorage[127.0.0.1:42898,DS-27fe8b2b-067d-4f70-8d86-17f063c1753d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-223355308-172.17.0.5-1598422665842:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46739,DS-388cb4a2-ccf5-4904-b356-3ce2efe9aa74,DISK], DatanodeInfoWithStorage[127.0.0.1:33473,DS-cfa7981f-a048-4692-8ee6-51c551507a7d,DISK], DatanodeInfoWithStorage[127.0.0.1:35888,DS-a84ea3ef-a782-4673-9c5d-94794594ce7e,DISK], DatanodeInfoWithStorage[127.0.0.1:35947,DS-de2a0b18-6906-426d-8c45-75a0f0964a59,DISK], DatanodeInfoWithStorage[127.0.0.1:44686,DS-3a9025c2-3cd6-43c1-a784-6a4952928714,DISK], DatanodeInfoWithStorage[127.0.0.1:34041,DS-1af4fd43-f2ed-40de-8a56-e5edb469b8ff,DISK], DatanodeInfoWithStorage[127.0.0.1:40041,DS-f4abfee1-ca70-4227-b5c6-05cba1bab2e3,DISK], DatanodeInfoWithStorage[127.0.0.1:42898,DS-27fe8b2b-067d-4f70-8d86-17f063c1753d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-434247201-172.17.0.5-1598423260042:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37878,DS-54cda39e-cad7-4ebb-9a03-9216b591f558,DISK], DatanodeInfoWithStorage[127.0.0.1:35865,DS-966cfcd8-12c8-4ca8-9986-37ca4dd609b6,DISK], DatanodeInfoWithStorage[127.0.0.1:41675,DS-1b11b363-d538-4776-8241-7e2b022ce900,DISK], DatanodeInfoWithStorage[127.0.0.1:33465,DS-1eb13414-6a2c-4968-9cab-23374c89a512,DISK], DatanodeInfoWithStorage[127.0.0.1:41271,DS-30572737-eafe-4d55-a042-27a9391f35c0,DISK], DatanodeInfoWithStorage[127.0.0.1:46550,DS-c68c1bfb-926b-438c-98b9-dc49426e6e58,DISK], DatanodeInfoWithStorage[127.0.0.1:44916,DS-58ce146d-4c05-4b2e-9ce7-2ae0fe2a9482,DISK], DatanodeInfoWithStorage[127.0.0.1:34171,DS-ff1a81b3-974b-4d18-a460-26bb5f989d48,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-434247201-172.17.0.5-1598423260042:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37878,DS-54cda39e-cad7-4ebb-9a03-9216b591f558,DISK], DatanodeInfoWithStorage[127.0.0.1:35865,DS-966cfcd8-12c8-4ca8-9986-37ca4dd609b6,DISK], DatanodeInfoWithStorage[127.0.0.1:41675,DS-1b11b363-d538-4776-8241-7e2b022ce900,DISK], DatanodeInfoWithStorage[127.0.0.1:33465,DS-1eb13414-6a2c-4968-9cab-23374c89a512,DISK], DatanodeInfoWithStorage[127.0.0.1:41271,DS-30572737-eafe-4d55-a042-27a9391f35c0,DISK], DatanodeInfoWithStorage[127.0.0.1:46550,DS-c68c1bfb-926b-438c-98b9-dc49426e6e58,DISK], DatanodeInfoWithStorage[127.0.0.1:44916,DS-58ce146d-4c05-4b2e-9ce7-2ae0fe2a9482,DISK], DatanodeInfoWithStorage[127.0.0.1:34171,DS-ff1a81b3-974b-4d18-a460-26bb5f989d48,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1573429011-172.17.0.5-1598423409214:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33532,DS-a018711f-f5b7-49ce-a38d-5d3869bc43c3,DISK], DatanodeInfoWithStorage[127.0.0.1:44108,DS-7468c769-fb37-4702-943d-f0c6d7557f62,DISK], DatanodeInfoWithStorage[127.0.0.1:38348,DS-45cb1f8c-9ea8-4edf-9bc2-9f0ae05ce7c3,DISK], DatanodeInfoWithStorage[127.0.0.1:43429,DS-468075d8-8338-4554-bc58-8b599bc0a944,DISK], DatanodeInfoWithStorage[127.0.0.1:34166,DS-56aa317f-f4a2-4774-8bdd-925487037d46,DISK], DatanodeInfoWithStorage[127.0.0.1:33706,DS-8d19da4b-1cc6-4b4b-b4b6-f70722d3757a,DISK], DatanodeInfoWithStorage[127.0.0.1:36666,DS-01604c4f-7175-42eb-9060-5c485b8a0ad4,DISK], DatanodeInfoWithStorage[127.0.0.1:44155,DS-26372baa-91fa-4e79-af96-2c547422e465,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1573429011-172.17.0.5-1598423409214:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33532,DS-a018711f-f5b7-49ce-a38d-5d3869bc43c3,DISK], DatanodeInfoWithStorage[127.0.0.1:44108,DS-7468c769-fb37-4702-943d-f0c6d7557f62,DISK], DatanodeInfoWithStorage[127.0.0.1:38348,DS-45cb1f8c-9ea8-4edf-9bc2-9f0ae05ce7c3,DISK], DatanodeInfoWithStorage[127.0.0.1:43429,DS-468075d8-8338-4554-bc58-8b599bc0a944,DISK], DatanodeInfoWithStorage[127.0.0.1:34166,DS-56aa317f-f4a2-4774-8bdd-925487037d46,DISK], DatanodeInfoWithStorage[127.0.0.1:33706,DS-8d19da4b-1cc6-4b4b-b4b6-f70722d3757a,DISK], DatanodeInfoWithStorage[127.0.0.1:36666,DS-01604c4f-7175-42eb-9060-5c485b8a0ad4,DISK], DatanodeInfoWithStorage[127.0.0.1:44155,DS-26372baa-91fa-4e79-af96-2c547422e465,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-200703139-172.17.0.5-1598423442783:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34910,DS-b6428470-e993-43f5-85ee-c923966f0c55,DISK], DatanodeInfoWithStorage[127.0.0.1:36344,DS-d9a25845-dcaa-423a-b64b-77828ec5b86b,DISK], DatanodeInfoWithStorage[127.0.0.1:38228,DS-9bf37e15-32df-47e5-8e10-bd1f0c38836f,DISK], DatanodeInfoWithStorage[127.0.0.1:41954,DS-72bb5c12-7ad1-48ba-a8a2-18509394a5d7,DISK], DatanodeInfoWithStorage[127.0.0.1:33132,DS-6fca7aa8-5d22-488f-aff7-07dfbd2e964b,DISK], DatanodeInfoWithStorage[127.0.0.1:37236,DS-2a30a1dc-72ba-40bf-968c-e8fcfa6f5e25,DISK], DatanodeInfoWithStorage[127.0.0.1:43941,DS-d2206193-d148-4244-9004-2011ed2090b9,DISK], DatanodeInfoWithStorage[127.0.0.1:35244,DS-cf64f256-43dd-46d1-a238-e85fcae60761,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-200703139-172.17.0.5-1598423442783:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34910,DS-b6428470-e993-43f5-85ee-c923966f0c55,DISK], DatanodeInfoWithStorage[127.0.0.1:36344,DS-d9a25845-dcaa-423a-b64b-77828ec5b86b,DISK], DatanodeInfoWithStorage[127.0.0.1:38228,DS-9bf37e15-32df-47e5-8e10-bd1f0c38836f,DISK], DatanodeInfoWithStorage[127.0.0.1:41954,DS-72bb5c12-7ad1-48ba-a8a2-18509394a5d7,DISK], DatanodeInfoWithStorage[127.0.0.1:33132,DS-6fca7aa8-5d22-488f-aff7-07dfbd2e964b,DISK], DatanodeInfoWithStorage[127.0.0.1:37236,DS-2a30a1dc-72ba-40bf-968c-e8fcfa6f5e25,DISK], DatanodeInfoWithStorage[127.0.0.1:43941,DS-d2206193-d148-4244-9004-2011ed2090b9,DISK], DatanodeInfoWithStorage[127.0.0.1:35244,DS-cf64f256-43dd-46d1-a238-e85fcae60761,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-712036478-172.17.0.5-1598423535009:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32970,DS-739d8a98-1f73-4a36-b333-8afed00f5d7e,DISK], DatanodeInfoWithStorage[127.0.0.1:46584,DS-d9b9a794-1cc0-4171-bc3b-322470c94f7a,DISK], DatanodeInfoWithStorage[127.0.0.1:33502,DS-5b3ae872-5a7a-4d41-9367-e154cb290996,DISK], DatanodeInfoWithStorage[127.0.0.1:45777,DS-12850158-2f13-4ce1-b8d4-80c28aa1c450,DISK], DatanodeInfoWithStorage[127.0.0.1:39792,DS-ab07f98f-4586-4f23-ab29-e1781c849608,DISK], DatanodeInfoWithStorage[127.0.0.1:44897,DS-6b4efe0d-bd4d-4f9b-a5d8-76e4d98a766e,DISK], DatanodeInfoWithStorage[127.0.0.1:41177,DS-a1d6337a-4218-4845-97c2-8d90df0b9ce3,DISK], DatanodeInfoWithStorage[127.0.0.1:40533,DS-3bf9523d-2e76-4fc9-9e61-d60f673c71fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-712036478-172.17.0.5-1598423535009:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32970,DS-739d8a98-1f73-4a36-b333-8afed00f5d7e,DISK], DatanodeInfoWithStorage[127.0.0.1:46584,DS-d9b9a794-1cc0-4171-bc3b-322470c94f7a,DISK], DatanodeInfoWithStorage[127.0.0.1:33502,DS-5b3ae872-5a7a-4d41-9367-e154cb290996,DISK], DatanodeInfoWithStorage[127.0.0.1:45777,DS-12850158-2f13-4ce1-b8d4-80c28aa1c450,DISK], DatanodeInfoWithStorage[127.0.0.1:39792,DS-ab07f98f-4586-4f23-ab29-e1781c849608,DISK], DatanodeInfoWithStorage[127.0.0.1:44897,DS-6b4efe0d-bd4d-4f9b-a5d8-76e4d98a766e,DISK], DatanodeInfoWithStorage[127.0.0.1:41177,DS-a1d6337a-4218-4845-97c2-8d90df0b9ce3,DISK], DatanodeInfoWithStorage[127.0.0.1:40533,DS-3bf9523d-2e76-4fc9-9e61-d60f673c71fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1979023278-172.17.0.5-1598423749929:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42915,DS-439a6e8d-4ed6-44a6-9541-38b8d6174f99,DISK], DatanodeInfoWithStorage[127.0.0.1:38370,DS-6f3392a7-4249-4551-bfa0-17aa7dcf7b8e,DISK], DatanodeInfoWithStorage[127.0.0.1:33558,DS-09e6c0e7-19ba-481c-9eca-e2812a0f61eb,DISK], DatanodeInfoWithStorage[127.0.0.1:40011,DS-54414b71-d040-46f2-9c73-f03ccfa9fdb0,DISK], DatanodeInfoWithStorage[127.0.0.1:46476,DS-0cf92baf-c41d-4e3a-805d-a45692026558,DISK], DatanodeInfoWithStorage[127.0.0.1:45858,DS-37ae8d5e-0725-4727-ac0a-9646154493cb,DISK], DatanodeInfoWithStorage[127.0.0.1:45787,DS-3637469a-bec1-4c6e-b185-95b449440cb2,DISK], DatanodeInfoWithStorage[127.0.0.1:46570,DS-35b87544-c770-43e5-b9f9-3574159f4d86,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1979023278-172.17.0.5-1598423749929:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42915,DS-439a6e8d-4ed6-44a6-9541-38b8d6174f99,DISK], DatanodeInfoWithStorage[127.0.0.1:38370,DS-6f3392a7-4249-4551-bfa0-17aa7dcf7b8e,DISK], DatanodeInfoWithStorage[127.0.0.1:33558,DS-09e6c0e7-19ba-481c-9eca-e2812a0f61eb,DISK], DatanodeInfoWithStorage[127.0.0.1:40011,DS-54414b71-d040-46f2-9c73-f03ccfa9fdb0,DISK], DatanodeInfoWithStorage[127.0.0.1:46476,DS-0cf92baf-c41d-4e3a-805d-a45692026558,DISK], DatanodeInfoWithStorage[127.0.0.1:45858,DS-37ae8d5e-0725-4727-ac0a-9646154493cb,DISK], DatanodeInfoWithStorage[127.0.0.1:45787,DS-3637469a-bec1-4c6e-b185-95b449440cb2,DISK], DatanodeInfoWithStorage[127.0.0.1:46570,DS-35b87544-c770-43e5-b9f9-3574159f4d86,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-380249885-172.17.0.5-1598424515073:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41870,DS-41507211-c86a-4f4f-b2a7-39f5a0a8b9b1,DISK], DatanodeInfoWithStorage[127.0.0.1:40649,DS-e6f42a5f-b3da-4c29-a288-087627cf11b8,DISK], DatanodeInfoWithStorage[127.0.0.1:37096,DS-478abc17-b74f-426b-8a88-d1f98be43f38,DISK], DatanodeInfoWithStorage[127.0.0.1:46352,DS-53716a65-6fa7-4b0b-b061-32d1528e55d0,DISK], DatanodeInfoWithStorage[127.0.0.1:46019,DS-8d5b53d9-6dfa-4a4a-99d8-1f176e32add0,DISK], DatanodeInfoWithStorage[127.0.0.1:34194,DS-87ef3bd4-6157-428f-a48a-d7352678dfaf,DISK], DatanodeInfoWithStorage[127.0.0.1:46620,DS-89d576ee-c6a8-4321-85bf-22f481a7c7a3,DISK], DatanodeInfoWithStorage[127.0.0.1:43299,DS-485e1811-6d4c-413a-b26e-3fed55d42168,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-380249885-172.17.0.5-1598424515073:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41870,DS-41507211-c86a-4f4f-b2a7-39f5a0a8b9b1,DISK], DatanodeInfoWithStorage[127.0.0.1:40649,DS-e6f42a5f-b3da-4c29-a288-087627cf11b8,DISK], DatanodeInfoWithStorage[127.0.0.1:37096,DS-478abc17-b74f-426b-8a88-d1f98be43f38,DISK], DatanodeInfoWithStorage[127.0.0.1:46352,DS-53716a65-6fa7-4b0b-b061-32d1528e55d0,DISK], DatanodeInfoWithStorage[127.0.0.1:46019,DS-8d5b53d9-6dfa-4a4a-99d8-1f176e32add0,DISK], DatanodeInfoWithStorage[127.0.0.1:34194,DS-87ef3bd4-6157-428f-a48a-d7352678dfaf,DISK], DatanodeInfoWithStorage[127.0.0.1:46620,DS-89d576ee-c6a8-4321-85bf-22f481a7c7a3,DISK], DatanodeInfoWithStorage[127.0.0.1:43299,DS-485e1811-6d4c-413a-b26e-3fed55d42168,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1724420227-172.17.0.5-1598424742573:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41859,DS-795adce7-dd3c-4262-b653-cd6696dccc8f,DISK], DatanodeInfoWithStorage[127.0.0.1:38895,DS-504f37b0-6d75-44cc-8145-7e2fe6988d1d,DISK], DatanodeInfoWithStorage[127.0.0.1:40922,DS-725455a8-59c7-4383-b496-0404cbacb807,DISK], DatanodeInfoWithStorage[127.0.0.1:42475,DS-1c7e72af-c32f-451c-b91d-ea23634c5333,DISK], DatanodeInfoWithStorage[127.0.0.1:42823,DS-5bfd3189-2b3d-4378-92ef-06e04876c77b,DISK], DatanodeInfoWithStorage[127.0.0.1:37083,DS-2b6a06b8-95a2-443c-8ef7-cd87e237c164,DISK], DatanodeInfoWithStorage[127.0.0.1:33756,DS-bfcdc6f8-3591-4bb8-9faf-53d4d27d3097,DISK], DatanodeInfoWithStorage[127.0.0.1:45795,DS-043004e3-892b-4853-b0c3-9a7e5ae7c63f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1724420227-172.17.0.5-1598424742573:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41859,DS-795adce7-dd3c-4262-b653-cd6696dccc8f,DISK], DatanodeInfoWithStorage[127.0.0.1:38895,DS-504f37b0-6d75-44cc-8145-7e2fe6988d1d,DISK], DatanodeInfoWithStorage[127.0.0.1:40922,DS-725455a8-59c7-4383-b496-0404cbacb807,DISK], DatanodeInfoWithStorage[127.0.0.1:42475,DS-1c7e72af-c32f-451c-b91d-ea23634c5333,DISK], DatanodeInfoWithStorage[127.0.0.1:42823,DS-5bfd3189-2b3d-4378-92ef-06e04876c77b,DISK], DatanodeInfoWithStorage[127.0.0.1:37083,DS-2b6a06b8-95a2-443c-8ef7-cd87e237c164,DISK], DatanodeInfoWithStorage[127.0.0.1:33756,DS-bfcdc6f8-3591-4bb8-9faf-53d4d27d3097,DISK], DatanodeInfoWithStorage[127.0.0.1:45795,DS-043004e3-892b-4853-b0c3-9a7e5ae7c63f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1392231000-172.17.0.5-1598424928704:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37296,DS-34665a47-1ace-494c-825d-ce2be3550766,DISK], DatanodeInfoWithStorage[127.0.0.1:44091,DS-68da5b74-9d60-435e-9291-0019647cb896,DISK], DatanodeInfoWithStorage[127.0.0.1:42006,DS-6fcc67f9-df05-438c-a4d2-583b62a0e63c,DISK], DatanodeInfoWithStorage[127.0.0.1:40088,DS-34e8958c-7fd1-4cab-956e-f22a9e2b6240,DISK], DatanodeInfoWithStorage[127.0.0.1:38087,DS-1f2871c5-80d0-410e-b003-f5388a744c9d,DISK], DatanodeInfoWithStorage[127.0.0.1:45152,DS-c2adb57c-86c7-45a1-a1bb-cd36694410e6,DISK], DatanodeInfoWithStorage[127.0.0.1:38852,DS-783d1f14-cd93-44f6-8402-ce00574886b7,DISK], DatanodeInfoWithStorage[127.0.0.1:45422,DS-9eea4e65-31d2-4b2e-ace5-01dfda5c633e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1392231000-172.17.0.5-1598424928704:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37296,DS-34665a47-1ace-494c-825d-ce2be3550766,DISK], DatanodeInfoWithStorage[127.0.0.1:44091,DS-68da5b74-9d60-435e-9291-0019647cb896,DISK], DatanodeInfoWithStorage[127.0.0.1:42006,DS-6fcc67f9-df05-438c-a4d2-583b62a0e63c,DISK], DatanodeInfoWithStorage[127.0.0.1:40088,DS-34e8958c-7fd1-4cab-956e-f22a9e2b6240,DISK], DatanodeInfoWithStorage[127.0.0.1:38087,DS-1f2871c5-80d0-410e-b003-f5388a744c9d,DISK], DatanodeInfoWithStorage[127.0.0.1:45152,DS-c2adb57c-86c7-45a1-a1bb-cd36694410e6,DISK], DatanodeInfoWithStorage[127.0.0.1:38852,DS-783d1f14-cd93-44f6-8402-ce00574886b7,DISK], DatanodeInfoWithStorage[127.0.0.1:45422,DS-9eea4e65-31d2-4b2e-ace5-01dfda5c633e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-203128961-172.17.0.5-1598425307655:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46429,DS-f422d5d7-8d58-4ada-b43a-4d68592b5ff3,DISK], DatanodeInfoWithStorage[127.0.0.1:37237,DS-22e4629a-f03e-45c2-9b27-27380855697a,DISK], DatanodeInfoWithStorage[127.0.0.1:43769,DS-a11b3dcc-432b-46fb-9e2b-3591cc6777f7,DISK], DatanodeInfoWithStorage[127.0.0.1:37223,DS-22b1d3ea-62a1-450c-b97c-77a0eddcbdf5,DISK], DatanodeInfoWithStorage[127.0.0.1:45058,DS-2330ff37-99cb-4cff-a2c9-ce1a9e8c2bc7,DISK], DatanodeInfoWithStorage[127.0.0.1:40531,DS-c656170c-9737-428b-bd81-25a5e141223d,DISK], DatanodeInfoWithStorage[127.0.0.1:44450,DS-7296fac1-2063-4fca-b77b-810864bb43de,DISK], DatanodeInfoWithStorage[127.0.0.1:36855,DS-c323300f-1c1d-4a6b-953e-7c709eabd61f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-203128961-172.17.0.5-1598425307655:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46429,DS-f422d5d7-8d58-4ada-b43a-4d68592b5ff3,DISK], DatanodeInfoWithStorage[127.0.0.1:37237,DS-22e4629a-f03e-45c2-9b27-27380855697a,DISK], DatanodeInfoWithStorage[127.0.0.1:43769,DS-a11b3dcc-432b-46fb-9e2b-3591cc6777f7,DISK], DatanodeInfoWithStorage[127.0.0.1:37223,DS-22b1d3ea-62a1-450c-b97c-77a0eddcbdf5,DISK], DatanodeInfoWithStorage[127.0.0.1:45058,DS-2330ff37-99cb-4cff-a2c9-ce1a9e8c2bc7,DISK], DatanodeInfoWithStorage[127.0.0.1:40531,DS-c656170c-9737-428b-bd81-25a5e141223d,DISK], DatanodeInfoWithStorage[127.0.0.1:44450,DS-7296fac1-2063-4fca-b77b-810864bb43de,DISK], DatanodeInfoWithStorage[127.0.0.1:36855,DS-c323300f-1c1d-4a6b-953e-7c709eabd61f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-518837013-172.17.0.5-1598425513648:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36975,DS-d1d652ed-3aaa-4112-a421-337bf43a7f20,DISK], DatanodeInfoWithStorage[127.0.0.1:43446,DS-916cdafe-b42f-477e-ad8b-d77240c29bc8,DISK], DatanodeInfoWithStorage[127.0.0.1:39030,DS-77e89ee8-5624-4881-8f1c-7e9319a44e0e,DISK], DatanodeInfoWithStorage[127.0.0.1:44821,DS-66f5ff5d-a1ef-4514-a296-e55adc14460e,DISK], DatanodeInfoWithStorage[127.0.0.1:37583,DS-9e968ee2-5a94-49d4-a408-1674c0fc630f,DISK], DatanodeInfoWithStorage[127.0.0.1:35557,DS-9ea59ab4-a48d-4e4c-aaa8-7219929a2f70,DISK], DatanodeInfoWithStorage[127.0.0.1:46496,DS-1dd48dd8-235f-41de-b67e-b1721276e8c3,DISK], DatanodeInfoWithStorage[127.0.0.1:38547,DS-3a49934c-630d-4265-a513-ca5e2bda1607,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-518837013-172.17.0.5-1598425513648:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36975,DS-d1d652ed-3aaa-4112-a421-337bf43a7f20,DISK], DatanodeInfoWithStorage[127.0.0.1:43446,DS-916cdafe-b42f-477e-ad8b-d77240c29bc8,DISK], DatanodeInfoWithStorage[127.0.0.1:39030,DS-77e89ee8-5624-4881-8f1c-7e9319a44e0e,DISK], DatanodeInfoWithStorage[127.0.0.1:44821,DS-66f5ff5d-a1ef-4514-a296-e55adc14460e,DISK], DatanodeInfoWithStorage[127.0.0.1:37583,DS-9e968ee2-5a94-49d4-a408-1674c0fc630f,DISK], DatanodeInfoWithStorage[127.0.0.1:35557,DS-9ea59ab4-a48d-4e4c-aaa8-7219929a2f70,DISK], DatanodeInfoWithStorage[127.0.0.1:46496,DS-1dd48dd8-235f-41de-b67e-b1721276e8c3,DISK], DatanodeInfoWithStorage[127.0.0.1:38547,DS-3a49934c-630d-4265-a513-ca5e2bda1607,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-770372267-172.17.0.5-1598426215418:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34319,DS-1f5e17db-55f8-468b-bcf0-60707824e6e9,DISK], DatanodeInfoWithStorage[127.0.0.1:46033,DS-7e6f3366-28a7-4c9d-a9f4-ea6a26acdfea,DISK], DatanodeInfoWithStorage[127.0.0.1:37780,DS-4a46c4d9-6775-480b-85c2-ab19f21dfd41,DISK], DatanodeInfoWithStorage[127.0.0.1:39179,DS-fa52dbab-0232-4f08-8234-60acad3f448f,DISK], DatanodeInfoWithStorage[127.0.0.1:45343,DS-d40d3fa0-4cd0-4752-bc0c-fccb2f797c42,DISK], DatanodeInfoWithStorage[127.0.0.1:45350,DS-9b20958e-ff31-41a1-8f87-31d7ddb47355,DISK], DatanodeInfoWithStorage[127.0.0.1:35898,DS-5b3e666d-bc3b-455e-919b-ae628db7b9b8,DISK], DatanodeInfoWithStorage[127.0.0.1:42612,DS-ab9b96d2-8e68-4991-9706-19e347a79b78,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-770372267-172.17.0.5-1598426215418:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34319,DS-1f5e17db-55f8-468b-bcf0-60707824e6e9,DISK], DatanodeInfoWithStorage[127.0.0.1:46033,DS-7e6f3366-28a7-4c9d-a9f4-ea6a26acdfea,DISK], DatanodeInfoWithStorage[127.0.0.1:37780,DS-4a46c4d9-6775-480b-85c2-ab19f21dfd41,DISK], DatanodeInfoWithStorage[127.0.0.1:39179,DS-fa52dbab-0232-4f08-8234-60acad3f448f,DISK], DatanodeInfoWithStorage[127.0.0.1:45343,DS-d40d3fa0-4cd0-4752-bc0c-fccb2f797c42,DISK], DatanodeInfoWithStorage[127.0.0.1:45350,DS-9b20958e-ff31-41a1-8f87-31d7ddb47355,DISK], DatanodeInfoWithStorage[127.0.0.1:35898,DS-5b3e666d-bc3b-455e-919b-ae628db7b9b8,DISK], DatanodeInfoWithStorage[127.0.0.1:42612,DS-ab9b96d2-8e68-4991-9706-19e347a79b78,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-670119576-172.17.0.5-1598426640306:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35122,DS-7090f98f-b411-4c80-ba67-b56fec78c328,DISK], DatanodeInfoWithStorage[127.0.0.1:46088,DS-6ed33c9a-69cf-4e25-91f8-fa4c8bf47eec,DISK], DatanodeInfoWithStorage[127.0.0.1:34636,DS-bd2627dc-bd7b-4e8a-b0ae-f19c5d2a4e22,DISK], DatanodeInfoWithStorage[127.0.0.1:39920,DS-cb5da755-f1ef-4556-8e4a-905f715caca8,DISK], DatanodeInfoWithStorage[127.0.0.1:44074,DS-4c629f7e-dd85-4b4c-bf47-913250f39946,DISK], DatanodeInfoWithStorage[127.0.0.1:44938,DS-d70d0335-2b9f-4036-abb1-8fc011445e8b,DISK], DatanodeInfoWithStorage[127.0.0.1:35236,DS-5b65d72e-957c-4a2b-8fa5-6e4526603fa3,DISK], DatanodeInfoWithStorage[127.0.0.1:40099,DS-a7fd1373-50bf-4e9c-a032-0ef78585ff1a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-670119576-172.17.0.5-1598426640306:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35122,DS-7090f98f-b411-4c80-ba67-b56fec78c328,DISK], DatanodeInfoWithStorage[127.0.0.1:46088,DS-6ed33c9a-69cf-4e25-91f8-fa4c8bf47eec,DISK], DatanodeInfoWithStorage[127.0.0.1:34636,DS-bd2627dc-bd7b-4e8a-b0ae-f19c5d2a4e22,DISK], DatanodeInfoWithStorage[127.0.0.1:39920,DS-cb5da755-f1ef-4556-8e4a-905f715caca8,DISK], DatanodeInfoWithStorage[127.0.0.1:44074,DS-4c629f7e-dd85-4b4c-bf47-913250f39946,DISK], DatanodeInfoWithStorage[127.0.0.1:44938,DS-d70d0335-2b9f-4036-abb1-8fc011445e8b,DISK], DatanodeInfoWithStorage[127.0.0.1:35236,DS-5b65d72e-957c-4a2b-8fa5-6e4526603fa3,DISK], DatanodeInfoWithStorage[127.0.0.1:40099,DS-a7fd1373-50bf-4e9c-a032-0ef78585ff1a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-170942469-172.17.0.5-1598427033677:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33735,DS-0a826e70-0059-4050-b932-52c06a696443,DISK], DatanodeInfoWithStorage[127.0.0.1:34631,DS-f1f13ea1-5dd7-4df7-9bb0-caca0d33d430,DISK], DatanodeInfoWithStorage[127.0.0.1:44003,DS-10aec19e-1c9d-453d-9aab-9b102145984d,DISK], DatanodeInfoWithStorage[127.0.0.1:45191,DS-fb51e716-4acb-4bdf-a0da-5f3bdc99b0da,DISK], DatanodeInfoWithStorage[127.0.0.1:36048,DS-deb53553-a3ae-4b40-805e-c3594af7be9a,DISK], DatanodeInfoWithStorage[127.0.0.1:33751,DS-ace05a79-4c5e-4fb1-92d0-7066c7b3a2e8,DISK], DatanodeInfoWithStorage[127.0.0.1:40708,DS-4423f1ac-3319-4907-8456-1dc8484e4879,DISK], DatanodeInfoWithStorage[127.0.0.1:34048,DS-0d701b9c-93bc-475e-807f-87eb7bb0f37d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-170942469-172.17.0.5-1598427033677:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33735,DS-0a826e70-0059-4050-b932-52c06a696443,DISK], DatanodeInfoWithStorage[127.0.0.1:34631,DS-f1f13ea1-5dd7-4df7-9bb0-caca0d33d430,DISK], DatanodeInfoWithStorage[127.0.0.1:44003,DS-10aec19e-1c9d-453d-9aab-9b102145984d,DISK], DatanodeInfoWithStorage[127.0.0.1:45191,DS-fb51e716-4acb-4bdf-a0da-5f3bdc99b0da,DISK], DatanodeInfoWithStorage[127.0.0.1:36048,DS-deb53553-a3ae-4b40-805e-c3594af7be9a,DISK], DatanodeInfoWithStorage[127.0.0.1:33751,DS-ace05a79-4c5e-4fb1-92d0-7066c7b3a2e8,DISK], DatanodeInfoWithStorage[127.0.0.1:40708,DS-4423f1ac-3319-4907-8456-1dc8484e4879,DISK], DatanodeInfoWithStorage[127.0.0.1:34048,DS-0d701b9c-93bc-475e-807f-87eb7bb0f37d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1748443905-172.17.0.5-1598427065590:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45333,DS-bb54bc71-864e-4c77-b44b-f07e43ffb9ac,DISK], DatanodeInfoWithStorage[127.0.0.1:46740,DS-775a8ddf-3411-44f4-9948-a6895fd6784d,DISK], DatanodeInfoWithStorage[127.0.0.1:38550,DS-be97eb0f-707d-41bd-923a-315f33f8594d,DISK], DatanodeInfoWithStorage[127.0.0.1:35563,DS-6ebf1a7c-0359-4c73-b325-f78b23432864,DISK], DatanodeInfoWithStorage[127.0.0.1:45004,DS-49387555-5f61-4a4c-ae93-c321d9f92bbb,DISK], DatanodeInfoWithStorage[127.0.0.1:38300,DS-8dd94219-81f0-4178-bc05-76e0537de5e2,DISK], DatanodeInfoWithStorage[127.0.0.1:34587,DS-2e53b389-43f6-4733-a86b-919de57fab48,DISK], DatanodeInfoWithStorage[127.0.0.1:33549,DS-0fc9885c-7b5b-4f19-8a84-364bdc462a17,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1748443905-172.17.0.5-1598427065590:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45333,DS-bb54bc71-864e-4c77-b44b-f07e43ffb9ac,DISK], DatanodeInfoWithStorage[127.0.0.1:46740,DS-775a8ddf-3411-44f4-9948-a6895fd6784d,DISK], DatanodeInfoWithStorage[127.0.0.1:38550,DS-be97eb0f-707d-41bd-923a-315f33f8594d,DISK], DatanodeInfoWithStorage[127.0.0.1:35563,DS-6ebf1a7c-0359-4c73-b325-f78b23432864,DISK], DatanodeInfoWithStorage[127.0.0.1:45004,DS-49387555-5f61-4a4c-ae93-c321d9f92bbb,DISK], DatanodeInfoWithStorage[127.0.0.1:38300,DS-8dd94219-81f0-4178-bc05-76e0537de5e2,DISK], DatanodeInfoWithStorage[127.0.0.1:34587,DS-2e53b389-43f6-4733-a86b-919de57fab48,DISK], DatanodeInfoWithStorage[127.0.0.1:33549,DS-0fc9885c-7b5b-4f19-8a84-364bdc462a17,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5247
