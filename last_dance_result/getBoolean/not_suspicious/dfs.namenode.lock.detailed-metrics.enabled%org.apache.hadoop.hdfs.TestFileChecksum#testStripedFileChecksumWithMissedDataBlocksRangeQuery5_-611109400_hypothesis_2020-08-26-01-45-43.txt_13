reconf_parameter: dfs.namenode.lock.detailed-metrics.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lock.detailed-metrics.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-83826104-172.17.0.12-1598406507968:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41944,DS-21f10415-71b2-40a8-be72-e5d7e592a621,DISK], DatanodeInfoWithStorage[127.0.0.1:37679,DS-b0781bdc-397b-4913-a8b2-235cfb9356e9,DISK], DatanodeInfoWithStorage[127.0.0.1:41899,DS-5724c3eb-1003-41aa-a703-e7191f86327e,DISK], DatanodeInfoWithStorage[127.0.0.1:37616,DS-e53baa2c-0058-469e-971a-f2ab94b760aa,DISK], DatanodeInfoWithStorage[127.0.0.1:42578,DS-66824207-c85c-4e4f-b833-b454b86620c0,DISK], DatanodeInfoWithStorage[127.0.0.1:32996,DS-0cbcbc87-a6f9-461f-a6c8-c1d04d3483b9,DISK], DatanodeInfoWithStorage[127.0.0.1:39477,DS-f5ef65d6-9736-40e6-a117-72cf3bc1eff4,DISK], DatanodeInfoWithStorage[127.0.0.1:34754,DS-bccfc50a-68cf-4777-94d7-cea88d513440,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-83826104-172.17.0.12-1598406507968:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41944,DS-21f10415-71b2-40a8-be72-e5d7e592a621,DISK], DatanodeInfoWithStorage[127.0.0.1:37679,DS-b0781bdc-397b-4913-a8b2-235cfb9356e9,DISK], DatanodeInfoWithStorage[127.0.0.1:41899,DS-5724c3eb-1003-41aa-a703-e7191f86327e,DISK], DatanodeInfoWithStorage[127.0.0.1:37616,DS-e53baa2c-0058-469e-971a-f2ab94b760aa,DISK], DatanodeInfoWithStorage[127.0.0.1:42578,DS-66824207-c85c-4e4f-b833-b454b86620c0,DISK], DatanodeInfoWithStorage[127.0.0.1:32996,DS-0cbcbc87-a6f9-461f-a6c8-c1d04d3483b9,DISK], DatanodeInfoWithStorage[127.0.0.1:39477,DS-f5ef65d6-9736-40e6-a117-72cf3bc1eff4,DISK], DatanodeInfoWithStorage[127.0.0.1:34754,DS-bccfc50a-68cf-4777-94d7-cea88d513440,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lock.detailed-metrics.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-200104340-172.17.0.12-1598406723052:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34861,DS-dc09a7c4-37a5-451d-91f3-20a6983bf7cc,DISK], DatanodeInfoWithStorage[127.0.0.1:39821,DS-72007f28-a55b-4b9c-b01b-dd07f54ba6c8,DISK], DatanodeInfoWithStorage[127.0.0.1:42155,DS-607bdae8-347c-4c2e-81c8-45d355bb003c,DISK], DatanodeInfoWithStorage[127.0.0.1:40232,DS-e74f2667-46ea-4f65-ac10-a9979a209c17,DISK], DatanodeInfoWithStorage[127.0.0.1:38870,DS-c332bd51-4803-44b1-9ac0-acf52a99fc72,DISK], DatanodeInfoWithStorage[127.0.0.1:34914,DS-60995ee6-6316-4984-a223-4230eb9811b9,DISK], DatanodeInfoWithStorage[127.0.0.1:35939,DS-e95b6bb7-b6ba-4c92-8b45-41da7b65c162,DISK], DatanodeInfoWithStorage[127.0.0.1:35711,DS-c8258b40-df2c-4e5d-ad0f-32c3e53827ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-200104340-172.17.0.12-1598406723052:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34861,DS-dc09a7c4-37a5-451d-91f3-20a6983bf7cc,DISK], DatanodeInfoWithStorage[127.0.0.1:39821,DS-72007f28-a55b-4b9c-b01b-dd07f54ba6c8,DISK], DatanodeInfoWithStorage[127.0.0.1:42155,DS-607bdae8-347c-4c2e-81c8-45d355bb003c,DISK], DatanodeInfoWithStorage[127.0.0.1:40232,DS-e74f2667-46ea-4f65-ac10-a9979a209c17,DISK], DatanodeInfoWithStorage[127.0.0.1:38870,DS-c332bd51-4803-44b1-9ac0-acf52a99fc72,DISK], DatanodeInfoWithStorage[127.0.0.1:34914,DS-60995ee6-6316-4984-a223-4230eb9811b9,DISK], DatanodeInfoWithStorage[127.0.0.1:35939,DS-e95b6bb7-b6ba-4c92-8b45-41da7b65c162,DISK], DatanodeInfoWithStorage[127.0.0.1:35711,DS-c8258b40-df2c-4e5d-ad0f-32c3e53827ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.lock.detailed-metrics.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-119748562-172.17.0.12-1598407008009:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44359,DS-b149fd0b-9e82-4974-bdf5-74af6678b6bd,DISK], DatanodeInfoWithStorage[127.0.0.1:40447,DS-9bbf3bdf-9b55-4180-8557-e3deb5ccd242,DISK], DatanodeInfoWithStorage[127.0.0.1:42438,DS-d2b1166f-1100-4d86-8f10-f2ad7a79af2f,DISK], DatanodeInfoWithStorage[127.0.0.1:40158,DS-259eb52c-8101-4111-999d-704bd4f4d2b7,DISK], DatanodeInfoWithStorage[127.0.0.1:36206,DS-8814453c-cfee-4833-a35b-3c9510ad27f5,DISK], DatanodeInfoWithStorage[127.0.0.1:42284,DS-39abdf92-021c-482d-84ac-c9d276df62ce,DISK], DatanodeInfoWithStorage[127.0.0.1:34380,DS-3b776a28-4680-4c86-abf8-79df7a3f60c5,DISK], DatanodeInfoWithStorage[127.0.0.1:34172,DS-2c81c979-c6de-4053-a61f-21c32d624f34,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-119748562-172.17.0.12-1598407008009:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44359,DS-b149fd0b-9e82-4974-bdf5-74af6678b6bd,DISK], DatanodeInfoWithStorage[127.0.0.1:40447,DS-9bbf3bdf-9b55-4180-8557-e3deb5ccd242,DISK], DatanodeInfoWithStorage[127.0.0.1:42438,DS-d2b1166f-1100-4d86-8f10-f2ad7a79af2f,DISK], DatanodeInfoWithStorage[127.0.0.1:40158,DS-259eb52c-8101-4111-999d-704bd4f4d2b7,DISK], DatanodeInfoWithStorage[127.0.0.1:36206,DS-8814453c-cfee-4833-a35b-3c9510ad27f5,DISK], DatanodeInfoWithStorage[127.0.0.1:42284,DS-39abdf92-021c-482d-84ac-c9d276df62ce,DISK], DatanodeInfoWithStorage[127.0.0.1:34380,DS-3b776a28-4680-4c86-abf8-79df7a3f60c5,DISK], DatanodeInfoWithStorage[127.0.0.1:34172,DS-2c81c979-c6de-4053-a61f-21c32d624f34,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lock.detailed-metrics.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-528348389-172.17.0.12-1598408126357:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36622,DS-405280f6-73ed-43be-a3ca-1919564285d0,DISK], DatanodeInfoWithStorage[127.0.0.1:36599,DS-c7b8280d-4b90-44d8-ac61-79bef077ea7d,DISK], DatanodeInfoWithStorage[127.0.0.1:41213,DS-c450e7d7-7a80-4785-a34a-4cc8d9100fe9,DISK], DatanodeInfoWithStorage[127.0.0.1:33564,DS-b6163625-1647-4f51-a7b1-92f049aae2e2,DISK], DatanodeInfoWithStorage[127.0.0.1:39763,DS-63dc6a98-d00e-4045-9ef8-b8d18076115e,DISK], DatanodeInfoWithStorage[127.0.0.1:42090,DS-a2459cfa-5280-4473-9e43-51de8856866f,DISK], DatanodeInfoWithStorage[127.0.0.1:40958,DS-132a7005-18f2-412a-a28d-db7c6f9bb3fb,DISK], DatanodeInfoWithStorage[127.0.0.1:38720,DS-c5fb8e99-8f05-44dd-8fe3-eb8ed6e415a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-528348389-172.17.0.12-1598408126357:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36622,DS-405280f6-73ed-43be-a3ca-1919564285d0,DISK], DatanodeInfoWithStorage[127.0.0.1:36599,DS-c7b8280d-4b90-44d8-ac61-79bef077ea7d,DISK], DatanodeInfoWithStorage[127.0.0.1:41213,DS-c450e7d7-7a80-4785-a34a-4cc8d9100fe9,DISK], DatanodeInfoWithStorage[127.0.0.1:33564,DS-b6163625-1647-4f51-a7b1-92f049aae2e2,DISK], DatanodeInfoWithStorage[127.0.0.1:39763,DS-63dc6a98-d00e-4045-9ef8-b8d18076115e,DISK], DatanodeInfoWithStorage[127.0.0.1:42090,DS-a2459cfa-5280-4473-9e43-51de8856866f,DISK], DatanodeInfoWithStorage[127.0.0.1:40958,DS-132a7005-18f2-412a-a28d-db7c6f9bb3fb,DISK], DatanodeInfoWithStorage[127.0.0.1:38720,DS-c5fb8e99-8f05-44dd-8fe3-eb8ed6e415a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.lock.detailed-metrics.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1846739462-172.17.0.12-1598408795630:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33641,DS-93fd80cb-5920-459f-a973-49755cc5f9d1,DISK], DatanodeInfoWithStorage[127.0.0.1:43387,DS-4339bbd5-8b4d-4094-8395-c43e37827238,DISK], DatanodeInfoWithStorage[127.0.0.1:40533,DS-2d2c49ba-b96f-43b8-b055-61a2960055d4,DISK], DatanodeInfoWithStorage[127.0.0.1:34805,DS-817409a9-3b8e-4e39-98b5-a2eaaa6f52cb,DISK], DatanodeInfoWithStorage[127.0.0.1:45657,DS-b18d6b8e-df8e-475b-9cfd-10bbc845beb5,DISK], DatanodeInfoWithStorage[127.0.0.1:36331,DS-b1fb551c-9b3c-4b04-ae00-75c106547e9e,DISK], DatanodeInfoWithStorage[127.0.0.1:42684,DS-ce1ce99f-2fa8-48ac-9417-f140206b6a96,DISK], DatanodeInfoWithStorage[127.0.0.1:33506,DS-da8c266d-c3bd-4725-8155-7372f06daf5b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1846739462-172.17.0.12-1598408795630:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33641,DS-93fd80cb-5920-459f-a973-49755cc5f9d1,DISK], DatanodeInfoWithStorage[127.0.0.1:43387,DS-4339bbd5-8b4d-4094-8395-c43e37827238,DISK], DatanodeInfoWithStorage[127.0.0.1:40533,DS-2d2c49ba-b96f-43b8-b055-61a2960055d4,DISK], DatanodeInfoWithStorage[127.0.0.1:34805,DS-817409a9-3b8e-4e39-98b5-a2eaaa6f52cb,DISK], DatanodeInfoWithStorage[127.0.0.1:45657,DS-b18d6b8e-df8e-475b-9cfd-10bbc845beb5,DISK], DatanodeInfoWithStorage[127.0.0.1:36331,DS-b1fb551c-9b3c-4b04-ae00-75c106547e9e,DISK], DatanodeInfoWithStorage[127.0.0.1:42684,DS-ce1ce99f-2fa8-48ac-9417-f140206b6a96,DISK], DatanodeInfoWithStorage[127.0.0.1:33506,DS-da8c266d-c3bd-4725-8155-7372f06daf5b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lock.detailed-metrics.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-348958481-172.17.0.12-1598409069712:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34973,DS-96d0ea99-ae00-438a-a2d9-caf56ed66d5e,DISK], DatanodeInfoWithStorage[127.0.0.1:45175,DS-d7004ba4-465a-4870-90f3-e11fa7454097,DISK], DatanodeInfoWithStorage[127.0.0.1:35659,DS-45263d12-a1e9-4837-a7f6-5053fc9296a1,DISK], DatanodeInfoWithStorage[127.0.0.1:34349,DS-613ec66c-13b3-4cb7-bddd-c1bfa0d79bfc,DISK], DatanodeInfoWithStorage[127.0.0.1:34177,DS-b294e363-e4dd-467c-ad02-31ca28159ad2,DISK], DatanodeInfoWithStorage[127.0.0.1:46028,DS-223d5884-fa14-404f-a4fb-8cdd82ee1822,DISK], DatanodeInfoWithStorage[127.0.0.1:38575,DS-85ffdb37-d4ca-4bc9-8347-df9908d94585,DISK], DatanodeInfoWithStorage[127.0.0.1:41840,DS-709d5a84-acb0-4f03-88f4-816b861e3365,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-348958481-172.17.0.12-1598409069712:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34973,DS-96d0ea99-ae00-438a-a2d9-caf56ed66d5e,DISK], DatanodeInfoWithStorage[127.0.0.1:45175,DS-d7004ba4-465a-4870-90f3-e11fa7454097,DISK], DatanodeInfoWithStorage[127.0.0.1:35659,DS-45263d12-a1e9-4837-a7f6-5053fc9296a1,DISK], DatanodeInfoWithStorage[127.0.0.1:34349,DS-613ec66c-13b3-4cb7-bddd-c1bfa0d79bfc,DISK], DatanodeInfoWithStorage[127.0.0.1:34177,DS-b294e363-e4dd-467c-ad02-31ca28159ad2,DISK], DatanodeInfoWithStorage[127.0.0.1:46028,DS-223d5884-fa14-404f-a4fb-8cdd82ee1822,DISK], DatanodeInfoWithStorage[127.0.0.1:38575,DS-85ffdb37-d4ca-4bc9-8347-df9908d94585,DISK], DatanodeInfoWithStorage[127.0.0.1:41840,DS-709d5a84-acb0-4f03-88f4-816b861e3365,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.lock.detailed-metrics.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-932787981-172.17.0.12-1598409556370:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43633,DS-ef81f399-5f09-4605-8cd4-5c000c1004f7,DISK], DatanodeInfoWithStorage[127.0.0.1:40859,DS-974db99e-cf66-4a52-b49d-1e501cd4e663,DISK], DatanodeInfoWithStorage[127.0.0.1:40568,DS-e7a673b2-6c24-4ab2-af08-5f743f492bc7,DISK], DatanodeInfoWithStorage[127.0.0.1:35131,DS-d5b6496f-713c-49db-9d0e-46b433a5e616,DISK], DatanodeInfoWithStorage[127.0.0.1:40729,DS-a787595b-3835-49c8-b722-284cc00b7640,DISK], DatanodeInfoWithStorage[127.0.0.1:39485,DS-8ebae303-31de-4485-bc07-3f5db8c23c06,DISK], DatanodeInfoWithStorage[127.0.0.1:40312,DS-8826fd66-f741-4ec4-be5c-f7aa460170ef,DISK], DatanodeInfoWithStorage[127.0.0.1:38417,DS-119b2f53-ed32-41fc-ab9a-d9e1781c353e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-932787981-172.17.0.12-1598409556370:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43633,DS-ef81f399-5f09-4605-8cd4-5c000c1004f7,DISK], DatanodeInfoWithStorage[127.0.0.1:40859,DS-974db99e-cf66-4a52-b49d-1e501cd4e663,DISK], DatanodeInfoWithStorage[127.0.0.1:40568,DS-e7a673b2-6c24-4ab2-af08-5f743f492bc7,DISK], DatanodeInfoWithStorage[127.0.0.1:35131,DS-d5b6496f-713c-49db-9d0e-46b433a5e616,DISK], DatanodeInfoWithStorage[127.0.0.1:40729,DS-a787595b-3835-49c8-b722-284cc00b7640,DISK], DatanodeInfoWithStorage[127.0.0.1:39485,DS-8ebae303-31de-4485-bc07-3f5db8c23c06,DISK], DatanodeInfoWithStorage[127.0.0.1:40312,DS-8826fd66-f741-4ec4-be5c-f7aa460170ef,DISK], DatanodeInfoWithStorage[127.0.0.1:38417,DS-119b2f53-ed32-41fc-ab9a-d9e1781c353e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lock.detailed-metrics.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-312599556-172.17.0.12-1598409705823:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39734,DS-f93d4963-737a-46be-918b-7009926c870c,DISK], DatanodeInfoWithStorage[127.0.0.1:45048,DS-ce1010df-1726-41ca-b0c2-4fbaa15d84be,DISK], DatanodeInfoWithStorage[127.0.0.1:32797,DS-08269d40-e8f4-4a21-9aab-04a43caa8570,DISK], DatanodeInfoWithStorage[127.0.0.1:44522,DS-46625f92-ee73-4cea-8642-a44315fbfe7b,DISK], DatanodeInfoWithStorage[127.0.0.1:37317,DS-ac13457f-4221-4fb1-905f-832bcdbe9cfe,DISK], DatanodeInfoWithStorage[127.0.0.1:34502,DS-8cddd120-13d6-4021-846e-e59bac4f80d6,DISK], DatanodeInfoWithStorage[127.0.0.1:43963,DS-24e27a2a-0315-4732-92ca-2ca6efd3001d,DISK], DatanodeInfoWithStorage[127.0.0.1:38770,DS-1e3b9cd5-0b17-4e9d-a887-ee1bb9a339c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-312599556-172.17.0.12-1598409705823:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39734,DS-f93d4963-737a-46be-918b-7009926c870c,DISK], DatanodeInfoWithStorage[127.0.0.1:45048,DS-ce1010df-1726-41ca-b0c2-4fbaa15d84be,DISK], DatanodeInfoWithStorage[127.0.0.1:32797,DS-08269d40-e8f4-4a21-9aab-04a43caa8570,DISK], DatanodeInfoWithStorage[127.0.0.1:44522,DS-46625f92-ee73-4cea-8642-a44315fbfe7b,DISK], DatanodeInfoWithStorage[127.0.0.1:37317,DS-ac13457f-4221-4fb1-905f-832bcdbe9cfe,DISK], DatanodeInfoWithStorage[127.0.0.1:34502,DS-8cddd120-13d6-4021-846e-e59bac4f80d6,DISK], DatanodeInfoWithStorage[127.0.0.1:43963,DS-24e27a2a-0315-4732-92ca-2ca6efd3001d,DISK], DatanodeInfoWithStorage[127.0.0.1:38770,DS-1e3b9cd5-0b17-4e9d-a887-ee1bb9a339c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lock.detailed-metrics.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-67227832-172.17.0.12-1598410419122:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38973,DS-f40c2c91-f905-4001-b15d-8e519388a642,DISK], DatanodeInfoWithStorage[127.0.0.1:41334,DS-6588ea66-7f3d-4e9b-ba34-9180d11dc965,DISK], DatanodeInfoWithStorage[127.0.0.1:44003,DS-67b7037f-a143-4c72-a554-6aafa2b58287,DISK], DatanodeInfoWithStorage[127.0.0.1:41767,DS-803ff2d8-8586-4377-8a0f-d4bf3522bb37,DISK], DatanodeInfoWithStorage[127.0.0.1:40895,DS-289102cc-cb52-419d-a588-5c9104bb1862,DISK], DatanodeInfoWithStorage[127.0.0.1:38600,DS-22aa57bb-ed3f-4317-b7d2-2d465366318a,DISK], DatanodeInfoWithStorage[127.0.0.1:42301,DS-944941ad-7810-4877-864a-8044346d80b7,DISK], DatanodeInfoWithStorage[127.0.0.1:38320,DS-394d7f24-7850-4eb1-a634-14cae211509d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-67227832-172.17.0.12-1598410419122:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38973,DS-f40c2c91-f905-4001-b15d-8e519388a642,DISK], DatanodeInfoWithStorage[127.0.0.1:41334,DS-6588ea66-7f3d-4e9b-ba34-9180d11dc965,DISK], DatanodeInfoWithStorage[127.0.0.1:44003,DS-67b7037f-a143-4c72-a554-6aafa2b58287,DISK], DatanodeInfoWithStorage[127.0.0.1:41767,DS-803ff2d8-8586-4377-8a0f-d4bf3522bb37,DISK], DatanodeInfoWithStorage[127.0.0.1:40895,DS-289102cc-cb52-419d-a588-5c9104bb1862,DISK], DatanodeInfoWithStorage[127.0.0.1:38600,DS-22aa57bb-ed3f-4317-b7d2-2d465366318a,DISK], DatanodeInfoWithStorage[127.0.0.1:42301,DS-944941ad-7810-4877-864a-8044346d80b7,DISK], DatanodeInfoWithStorage[127.0.0.1:38320,DS-394d7f24-7850-4eb1-a634-14cae211509d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lock.detailed-metrics.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1064428339-172.17.0.12-1598410705325:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36070,DS-5c43a6a3-766c-4216-b6eb-55a65af0bdb5,DISK], DatanodeInfoWithStorage[127.0.0.1:42935,DS-6a49f62c-76c3-430e-8a69-57e180404995,DISK], DatanodeInfoWithStorage[127.0.0.1:39744,DS-9296ef28-631b-485c-93c0-588610a55bf5,DISK], DatanodeInfoWithStorage[127.0.0.1:33868,DS-0ee885fa-9c40-4519-8a85-5cdcbbaf2871,DISK], DatanodeInfoWithStorage[127.0.0.1:38590,DS-2b8508ef-8d54-4d91-9246-8eff23dffe17,DISK], DatanodeInfoWithStorage[127.0.0.1:41864,DS-0423a8bb-7f31-4195-b624-363b907e34f9,DISK], DatanodeInfoWithStorage[127.0.0.1:46757,DS-ca69c3e0-1f68-420f-8a35-c7675bc1819e,DISK], DatanodeInfoWithStorage[127.0.0.1:34546,DS-5f5ee43f-f5a5-4be0-81f9-f70f56891a33,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1064428339-172.17.0.12-1598410705325:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36070,DS-5c43a6a3-766c-4216-b6eb-55a65af0bdb5,DISK], DatanodeInfoWithStorage[127.0.0.1:42935,DS-6a49f62c-76c3-430e-8a69-57e180404995,DISK], DatanodeInfoWithStorage[127.0.0.1:39744,DS-9296ef28-631b-485c-93c0-588610a55bf5,DISK], DatanodeInfoWithStorage[127.0.0.1:33868,DS-0ee885fa-9c40-4519-8a85-5cdcbbaf2871,DISK], DatanodeInfoWithStorage[127.0.0.1:38590,DS-2b8508ef-8d54-4d91-9246-8eff23dffe17,DISK], DatanodeInfoWithStorage[127.0.0.1:41864,DS-0423a8bb-7f31-4195-b624-363b907e34f9,DISK], DatanodeInfoWithStorage[127.0.0.1:46757,DS-ca69c3e0-1f68-420f-8a35-c7675bc1819e,DISK], DatanodeInfoWithStorage[127.0.0.1:34546,DS-5f5ee43f-f5a5-4be0-81f9-f70f56891a33,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.lock.detailed-metrics.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2116824278-172.17.0.12-1598410842578:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33099,DS-8241cf7a-efbb-4f5c-93ae-f5cc12c09eb3,DISK], DatanodeInfoWithStorage[127.0.0.1:37143,DS-592ea25b-1948-4d7a-afb5-20f35c6cde1e,DISK], DatanodeInfoWithStorage[127.0.0.1:37620,DS-553ed240-4770-41f8-a2d0-715a26ad8d59,DISK], DatanodeInfoWithStorage[127.0.0.1:34191,DS-884b8d02-f42d-42c7-94d3-6bca483df1ff,DISK], DatanodeInfoWithStorage[127.0.0.1:39519,DS-7bed9e27-de5b-46b1-b57d-67ca15e19d72,DISK], DatanodeInfoWithStorage[127.0.0.1:43253,DS-6a51957b-226c-41e7-a0d5-f8511c7b95f6,DISK], DatanodeInfoWithStorage[127.0.0.1:45338,DS-a67e5768-e48c-436a-8452-67dddc409458,DISK], DatanodeInfoWithStorage[127.0.0.1:45989,DS-1f31b346-8af2-41fb-b625-db202236982c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2116824278-172.17.0.12-1598410842578:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33099,DS-8241cf7a-efbb-4f5c-93ae-f5cc12c09eb3,DISK], DatanodeInfoWithStorage[127.0.0.1:37143,DS-592ea25b-1948-4d7a-afb5-20f35c6cde1e,DISK], DatanodeInfoWithStorage[127.0.0.1:37620,DS-553ed240-4770-41f8-a2d0-715a26ad8d59,DISK], DatanodeInfoWithStorage[127.0.0.1:34191,DS-884b8d02-f42d-42c7-94d3-6bca483df1ff,DISK], DatanodeInfoWithStorage[127.0.0.1:39519,DS-7bed9e27-de5b-46b1-b57d-67ca15e19d72,DISK], DatanodeInfoWithStorage[127.0.0.1:43253,DS-6a51957b-226c-41e7-a0d5-f8511c7b95f6,DISK], DatanodeInfoWithStorage[127.0.0.1:45338,DS-a67e5768-e48c-436a-8452-67dddc409458,DISK], DatanodeInfoWithStorage[127.0.0.1:45989,DS-1f31b346-8af2-41fb-b625-db202236982c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.lock.detailed-metrics.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-553395995-172.17.0.12-1598411163168:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34989,DS-ae1b24e2-1951-4dd3-9de9-64f6d9011135,DISK], DatanodeInfoWithStorage[127.0.0.1:46813,DS-c875ef9f-c828-4869-9890-4d87f04beb1d,DISK], DatanodeInfoWithStorage[127.0.0.1:33591,DS-5ac7f7b0-6ef3-4ae4-a013-d8a6d1cb61bc,DISK], DatanodeInfoWithStorage[127.0.0.1:45188,DS-cfad8244-e260-4367-a53a-45a61172a64d,DISK], DatanodeInfoWithStorage[127.0.0.1:42489,DS-d524645f-6ace-4061-b4c7-adf97b02c666,DISK], DatanodeInfoWithStorage[127.0.0.1:41950,DS-3527784c-99d7-4cf3-947f-ac1adc5fa82f,DISK], DatanodeInfoWithStorage[127.0.0.1:45121,DS-8a95fb8a-0e60-4095-9464-1717f7377820,DISK], DatanodeInfoWithStorage[127.0.0.1:34213,DS-b6664d70-2995-4310-8f2d-4ad5f6098381,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-553395995-172.17.0.12-1598411163168:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34989,DS-ae1b24e2-1951-4dd3-9de9-64f6d9011135,DISK], DatanodeInfoWithStorage[127.0.0.1:46813,DS-c875ef9f-c828-4869-9890-4d87f04beb1d,DISK], DatanodeInfoWithStorage[127.0.0.1:33591,DS-5ac7f7b0-6ef3-4ae4-a013-d8a6d1cb61bc,DISK], DatanodeInfoWithStorage[127.0.0.1:45188,DS-cfad8244-e260-4367-a53a-45a61172a64d,DISK], DatanodeInfoWithStorage[127.0.0.1:42489,DS-d524645f-6ace-4061-b4c7-adf97b02c666,DISK], DatanodeInfoWithStorage[127.0.0.1:41950,DS-3527784c-99d7-4cf3-947f-ac1adc5fa82f,DISK], DatanodeInfoWithStorage[127.0.0.1:45121,DS-8a95fb8a-0e60-4095-9464-1717f7377820,DISK], DatanodeInfoWithStorage[127.0.0.1:34213,DS-b6664d70-2995-4310-8f2d-4ad5f6098381,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.lock.detailed-metrics.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1992028199-172.17.0.12-1598411268069:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36385,DS-84fdf9d3-ba9b-4ea2-beed-13006f7cd009,DISK], DatanodeInfoWithStorage[127.0.0.1:39395,DS-158110c4-bd29-4cab-8de7-b7424a99b675,DISK], DatanodeInfoWithStorage[127.0.0.1:42200,DS-0cc4b902-0cf6-4c3d-a787-0488a20e386e,DISK], DatanodeInfoWithStorage[127.0.0.1:45790,DS-ec8bc763-d571-45af-9b5e-bd84f8b0f2a6,DISK], DatanodeInfoWithStorage[127.0.0.1:36074,DS-410d09c1-3ea2-42c4-93ac-bbc5f44b749e,DISK], DatanodeInfoWithStorage[127.0.0.1:43795,DS-fa93b313-b157-4f18-8eb5-8ddb3361f8c7,DISK], DatanodeInfoWithStorage[127.0.0.1:34648,DS-8eb7777d-1ef9-47a3-9657-ec6c021f1d39,DISK], DatanodeInfoWithStorage[127.0.0.1:38931,DS-cb0984d1-d408-4a94-b515-9c76f5c79f75,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1992028199-172.17.0.12-1598411268069:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36385,DS-84fdf9d3-ba9b-4ea2-beed-13006f7cd009,DISK], DatanodeInfoWithStorage[127.0.0.1:39395,DS-158110c4-bd29-4cab-8de7-b7424a99b675,DISK], DatanodeInfoWithStorage[127.0.0.1:42200,DS-0cc4b902-0cf6-4c3d-a787-0488a20e386e,DISK], DatanodeInfoWithStorage[127.0.0.1:45790,DS-ec8bc763-d571-45af-9b5e-bd84f8b0f2a6,DISK], DatanodeInfoWithStorage[127.0.0.1:36074,DS-410d09c1-3ea2-42c4-93ac-bbc5f44b749e,DISK], DatanodeInfoWithStorage[127.0.0.1:43795,DS-fa93b313-b157-4f18-8eb5-8ddb3361f8c7,DISK], DatanodeInfoWithStorage[127.0.0.1:34648,DS-8eb7777d-1ef9-47a3-9657-ec6c021f1d39,DISK], DatanodeInfoWithStorage[127.0.0.1:38931,DS-cb0984d1-d408-4a94-b515-9c76f5c79f75,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 7 out of 50
result: false positive !!!
Total execution time in seconds : 5206
