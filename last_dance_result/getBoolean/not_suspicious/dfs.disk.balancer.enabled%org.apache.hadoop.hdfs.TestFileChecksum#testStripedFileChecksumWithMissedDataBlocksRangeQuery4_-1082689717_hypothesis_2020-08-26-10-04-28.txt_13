reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-560258915-172.17.0.4-1598437330326:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35615,DS-e32eb461-4630-4160-b581-24dfc41f640a,DISK], DatanodeInfoWithStorage[127.0.0.1:39881,DS-47774626-6319-4f2d-a93c-8f9b8e4c5499,DISK], DatanodeInfoWithStorage[127.0.0.1:43492,DS-8cb0d5b6-0363-4bbd-826a-6ce922707580,DISK], DatanodeInfoWithStorage[127.0.0.1:41026,DS-aa54fd46-5e2b-4bd0-9550-af4b3e111b5f,DISK], DatanodeInfoWithStorage[127.0.0.1:38314,DS-41e0d08c-6078-4626-bf06-9f2012e7f4e1,DISK], DatanodeInfoWithStorage[127.0.0.1:46461,DS-81ed463d-1979-4edb-927c-c9cfe6e2e090,DISK], DatanodeInfoWithStorage[127.0.0.1:44515,DS-9edb02e1-b66a-41e8-8cac-e78ee1d651a7,DISK], DatanodeInfoWithStorage[127.0.0.1:39191,DS-30b6756a-03cd-4010-8b69-e70e93f3fccd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-560258915-172.17.0.4-1598437330326:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35615,DS-e32eb461-4630-4160-b581-24dfc41f640a,DISK], DatanodeInfoWithStorage[127.0.0.1:39881,DS-47774626-6319-4f2d-a93c-8f9b8e4c5499,DISK], DatanodeInfoWithStorage[127.0.0.1:43492,DS-8cb0d5b6-0363-4bbd-826a-6ce922707580,DISK], DatanodeInfoWithStorage[127.0.0.1:41026,DS-aa54fd46-5e2b-4bd0-9550-af4b3e111b5f,DISK], DatanodeInfoWithStorage[127.0.0.1:38314,DS-41e0d08c-6078-4626-bf06-9f2012e7f4e1,DISK], DatanodeInfoWithStorage[127.0.0.1:46461,DS-81ed463d-1979-4edb-927c-c9cfe6e2e090,DISK], DatanodeInfoWithStorage[127.0.0.1:44515,DS-9edb02e1-b66a-41e8-8cac-e78ee1d651a7,DISK], DatanodeInfoWithStorage[127.0.0.1:39191,DS-30b6756a-03cd-4010-8b69-e70e93f3fccd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-770129296-172.17.0.4-1598437502392:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39917,DS-10e056e8-2fe8-43f0-b0c4-abc0c1747b4a,DISK], DatanodeInfoWithStorage[127.0.0.1:40404,DS-7b158d20-e2f7-4f56-a9cd-35b2606788f5,DISK], DatanodeInfoWithStorage[127.0.0.1:34403,DS-44e446c3-4860-4ec5-9a3c-3401d1deefd8,DISK], DatanodeInfoWithStorage[127.0.0.1:33187,DS-cf8d64c4-f6cd-4b10-83c6-63e9f3987d3b,DISK], DatanodeInfoWithStorage[127.0.0.1:39617,DS-44695432-0df0-4b00-bd1b-833a97590f86,DISK], DatanodeInfoWithStorage[127.0.0.1:43156,DS-84a7ac2f-49a5-4d0a-bb4b-d74d4803c5f7,DISK], DatanodeInfoWithStorage[127.0.0.1:35616,DS-1ff4da3e-acd5-4be9-a3c5-d4c1ee9b9a54,DISK], DatanodeInfoWithStorage[127.0.0.1:43325,DS-61aa33a9-4207-4b7f-b8f0-d95489717c54,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-770129296-172.17.0.4-1598437502392:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39917,DS-10e056e8-2fe8-43f0-b0c4-abc0c1747b4a,DISK], DatanodeInfoWithStorage[127.0.0.1:40404,DS-7b158d20-e2f7-4f56-a9cd-35b2606788f5,DISK], DatanodeInfoWithStorage[127.0.0.1:34403,DS-44e446c3-4860-4ec5-9a3c-3401d1deefd8,DISK], DatanodeInfoWithStorage[127.0.0.1:33187,DS-cf8d64c4-f6cd-4b10-83c6-63e9f3987d3b,DISK], DatanodeInfoWithStorage[127.0.0.1:39617,DS-44695432-0df0-4b00-bd1b-833a97590f86,DISK], DatanodeInfoWithStorage[127.0.0.1:43156,DS-84a7ac2f-49a5-4d0a-bb4b-d74d4803c5f7,DISK], DatanodeInfoWithStorage[127.0.0.1:35616,DS-1ff4da3e-acd5-4be9-a3c5-d4c1ee9b9a54,DISK], DatanodeInfoWithStorage[127.0.0.1:43325,DS-61aa33a9-4207-4b7f-b8f0-d95489717c54,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-875343414-172.17.0.4-1598438091396:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33099,DS-45606018-d562-41d9-bfc6-3b403e4282af,DISK], DatanodeInfoWithStorage[127.0.0.1:45161,DS-d1377d7f-a641-4277-ab11-a52a123f434c,DISK], DatanodeInfoWithStorage[127.0.0.1:38398,DS-ed1b2800-c23f-4d54-836c-0660573592f3,DISK], DatanodeInfoWithStorage[127.0.0.1:41227,DS-8c90452d-2771-4f63-82ed-4235cc70871f,DISK], DatanodeInfoWithStorage[127.0.0.1:42787,DS-8aa63e5a-4995-4e08-813d-4ff55a0971a4,DISK], DatanodeInfoWithStorage[127.0.0.1:42435,DS-14e4ffaa-9cb7-4e2e-bd04-91ac33fba919,DISK], DatanodeInfoWithStorage[127.0.0.1:34791,DS-28c80b16-8705-4da0-94b1-4806e0040bf7,DISK], DatanodeInfoWithStorage[127.0.0.1:34829,DS-63881102-349d-4a87-b8e6-fec20f231fae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-875343414-172.17.0.4-1598438091396:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33099,DS-45606018-d562-41d9-bfc6-3b403e4282af,DISK], DatanodeInfoWithStorage[127.0.0.1:45161,DS-d1377d7f-a641-4277-ab11-a52a123f434c,DISK], DatanodeInfoWithStorage[127.0.0.1:38398,DS-ed1b2800-c23f-4d54-836c-0660573592f3,DISK], DatanodeInfoWithStorage[127.0.0.1:41227,DS-8c90452d-2771-4f63-82ed-4235cc70871f,DISK], DatanodeInfoWithStorage[127.0.0.1:42787,DS-8aa63e5a-4995-4e08-813d-4ff55a0971a4,DISK], DatanodeInfoWithStorage[127.0.0.1:42435,DS-14e4ffaa-9cb7-4e2e-bd04-91ac33fba919,DISK], DatanodeInfoWithStorage[127.0.0.1:34791,DS-28c80b16-8705-4da0-94b1-4806e0040bf7,DISK], DatanodeInfoWithStorage[127.0.0.1:34829,DS-63881102-349d-4a87-b8e6-fec20f231fae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-41615507-172.17.0.4-1598438359172:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35359,DS-8be9360d-9484-4959-8d8b-f015a52fe1d0,DISK], DatanodeInfoWithStorage[127.0.0.1:44404,DS-fe887d65-b37c-4dfe-a65c-94f4f1a33924,DISK], DatanodeInfoWithStorage[127.0.0.1:36028,DS-3a4f3c86-9629-4579-a0a2-61e521cb459b,DISK], DatanodeInfoWithStorage[127.0.0.1:33494,DS-9315ce4a-15e7-4cbb-9956-31c429dc9cc9,DISK], DatanodeInfoWithStorage[127.0.0.1:37182,DS-103d5a8b-6784-452f-a7dc-269854a910c9,DISK], DatanodeInfoWithStorage[127.0.0.1:39981,DS-c51a14b1-73e7-41cf-8bbb-a9f13f88a67a,DISK], DatanodeInfoWithStorage[127.0.0.1:34352,DS-5aad7519-7986-42f3-80f6-67b393f2e5d5,DISK], DatanodeInfoWithStorage[127.0.0.1:35312,DS-b9e6ffd0-cf11-4f14-a662-d2803b845588,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-41615507-172.17.0.4-1598438359172:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35359,DS-8be9360d-9484-4959-8d8b-f015a52fe1d0,DISK], DatanodeInfoWithStorage[127.0.0.1:44404,DS-fe887d65-b37c-4dfe-a65c-94f4f1a33924,DISK], DatanodeInfoWithStorage[127.0.0.1:36028,DS-3a4f3c86-9629-4579-a0a2-61e521cb459b,DISK], DatanodeInfoWithStorage[127.0.0.1:33494,DS-9315ce4a-15e7-4cbb-9956-31c429dc9cc9,DISK], DatanodeInfoWithStorage[127.0.0.1:37182,DS-103d5a8b-6784-452f-a7dc-269854a910c9,DISK], DatanodeInfoWithStorage[127.0.0.1:39981,DS-c51a14b1-73e7-41cf-8bbb-a9f13f88a67a,DISK], DatanodeInfoWithStorage[127.0.0.1:34352,DS-5aad7519-7986-42f3-80f6-67b393f2e5d5,DISK], DatanodeInfoWithStorage[127.0.0.1:35312,DS-b9e6ffd0-cf11-4f14-a662-d2803b845588,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2091336783-172.17.0.4-1598439332760:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46265,DS-0967ae77-4639-4f37-9971-548d96246015,DISK], DatanodeInfoWithStorage[127.0.0.1:39904,DS-58ca6e34-1404-40c8-83fe-12e15c820bf1,DISK], DatanodeInfoWithStorage[127.0.0.1:35277,DS-0c951afa-8a90-4e00-a339-b36ce21ee591,DISK], DatanodeInfoWithStorage[127.0.0.1:46055,DS-be2ae599-ede9-40db-b51e-71b43449f6a1,DISK], DatanodeInfoWithStorage[127.0.0.1:35490,DS-290bf57e-031c-4bfb-a9bc-edb4065eef88,DISK], DatanodeInfoWithStorage[127.0.0.1:37073,DS-7048da6c-a3aa-41b0-a794-8587d5844402,DISK], DatanodeInfoWithStorage[127.0.0.1:39521,DS-a675c4c2-786f-4c4e-bcf3-09be465fb444,DISK], DatanodeInfoWithStorage[127.0.0.1:40552,DS-6938b05c-1874-48ea-9011-af0c6278b4e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2091336783-172.17.0.4-1598439332760:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46265,DS-0967ae77-4639-4f37-9971-548d96246015,DISK], DatanodeInfoWithStorage[127.0.0.1:39904,DS-58ca6e34-1404-40c8-83fe-12e15c820bf1,DISK], DatanodeInfoWithStorage[127.0.0.1:35277,DS-0c951afa-8a90-4e00-a339-b36ce21ee591,DISK], DatanodeInfoWithStorage[127.0.0.1:46055,DS-be2ae599-ede9-40db-b51e-71b43449f6a1,DISK], DatanodeInfoWithStorage[127.0.0.1:35490,DS-290bf57e-031c-4bfb-a9bc-edb4065eef88,DISK], DatanodeInfoWithStorage[127.0.0.1:37073,DS-7048da6c-a3aa-41b0-a794-8587d5844402,DISK], DatanodeInfoWithStorage[127.0.0.1:39521,DS-a675c4c2-786f-4c4e-bcf3-09be465fb444,DISK], DatanodeInfoWithStorage[127.0.0.1:40552,DS-6938b05c-1874-48ea-9011-af0c6278b4e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-923557181-172.17.0.4-1598439436392:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37287,DS-1c11595d-990e-4008-b657-9cc5eb07976d,DISK], DatanodeInfoWithStorage[127.0.0.1:37170,DS-6faab1fe-a60e-40bf-bd71-8cda77fbb760,DISK], DatanodeInfoWithStorage[127.0.0.1:39404,DS-3d7d5afe-1191-47e0-9038-9432ec553412,DISK], DatanodeInfoWithStorage[127.0.0.1:34634,DS-78745804-3cc5-4520-8220-463a5c248682,DISK], DatanodeInfoWithStorage[127.0.0.1:42468,DS-06da020c-d0c6-4fbf-ad16-356f06810bef,DISK], DatanodeInfoWithStorage[127.0.0.1:35480,DS-5be4df61-c029-4205-bafb-46a3280a858d,DISK], DatanodeInfoWithStorage[127.0.0.1:43433,DS-51b32982-4c65-4210-8ae1-a329bf0cc3f2,DISK], DatanodeInfoWithStorage[127.0.0.1:38892,DS-1b609bd5-7aef-4bcf-81c4-03365fe06efe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-923557181-172.17.0.4-1598439436392:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37287,DS-1c11595d-990e-4008-b657-9cc5eb07976d,DISK], DatanodeInfoWithStorage[127.0.0.1:37170,DS-6faab1fe-a60e-40bf-bd71-8cda77fbb760,DISK], DatanodeInfoWithStorage[127.0.0.1:39404,DS-3d7d5afe-1191-47e0-9038-9432ec553412,DISK], DatanodeInfoWithStorage[127.0.0.1:34634,DS-78745804-3cc5-4520-8220-463a5c248682,DISK], DatanodeInfoWithStorage[127.0.0.1:42468,DS-06da020c-d0c6-4fbf-ad16-356f06810bef,DISK], DatanodeInfoWithStorage[127.0.0.1:35480,DS-5be4df61-c029-4205-bafb-46a3280a858d,DISK], DatanodeInfoWithStorage[127.0.0.1:43433,DS-51b32982-4c65-4210-8ae1-a329bf0cc3f2,DISK], DatanodeInfoWithStorage[127.0.0.1:38892,DS-1b609bd5-7aef-4bcf-81c4-03365fe06efe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1292078787-172.17.0.4-1598439552548:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44481,DS-967005c2-1f4f-47f3-a8fa-fa8a77023c98,DISK], DatanodeInfoWithStorage[127.0.0.1:42388,DS-bbfe337b-b552-4cbf-bf0c-bdf6a0b9fd5d,DISK], DatanodeInfoWithStorage[127.0.0.1:34899,DS-da7e71d0-57d5-4245-a25d-7c3eae240546,DISK], DatanodeInfoWithStorage[127.0.0.1:42761,DS-c1372eb7-dd0c-4c52-9af5-9ab9fb74e0e1,DISK], DatanodeInfoWithStorage[127.0.0.1:33585,DS-276a910a-1890-453e-81e2-9b223a4a04fa,DISK], DatanodeInfoWithStorage[127.0.0.1:46583,DS-896de10e-c173-485f-8d5c-dabc71d56a9f,DISK], DatanodeInfoWithStorage[127.0.0.1:44072,DS-13d15be8-9ae1-4141-a22a-a8facd06b7eb,DISK], DatanodeInfoWithStorage[127.0.0.1:43553,DS-b424a2b4-5ba1-4210-80e3-87528d8b3a60,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1292078787-172.17.0.4-1598439552548:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44481,DS-967005c2-1f4f-47f3-a8fa-fa8a77023c98,DISK], DatanodeInfoWithStorage[127.0.0.1:42388,DS-bbfe337b-b552-4cbf-bf0c-bdf6a0b9fd5d,DISK], DatanodeInfoWithStorage[127.0.0.1:34899,DS-da7e71d0-57d5-4245-a25d-7c3eae240546,DISK], DatanodeInfoWithStorage[127.0.0.1:42761,DS-c1372eb7-dd0c-4c52-9af5-9ab9fb74e0e1,DISK], DatanodeInfoWithStorage[127.0.0.1:33585,DS-276a910a-1890-453e-81e2-9b223a4a04fa,DISK], DatanodeInfoWithStorage[127.0.0.1:46583,DS-896de10e-c173-485f-8d5c-dabc71d56a9f,DISK], DatanodeInfoWithStorage[127.0.0.1:44072,DS-13d15be8-9ae1-4141-a22a-a8facd06b7eb,DISK], DatanodeInfoWithStorage[127.0.0.1:43553,DS-b424a2b4-5ba1-4210-80e3-87528d8b3a60,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2104392240-172.17.0.4-1598440133842:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45655,DS-9d4f403b-4d8a-4638-bc6c-a58d401d287f,DISK], DatanodeInfoWithStorage[127.0.0.1:45985,DS-49249b7d-0c7f-41ae-852c-c93f08f174b7,DISK], DatanodeInfoWithStorage[127.0.0.1:33519,DS-f82dff27-2d36-4cff-89f5-4acf77417124,DISK], DatanodeInfoWithStorage[127.0.0.1:43495,DS-ce7ab472-3584-4959-a7de-643b18a69d26,DISK], DatanodeInfoWithStorage[127.0.0.1:45701,DS-f14be9e4-39f0-4fcc-ba48-8e92ccfd2fde,DISK], DatanodeInfoWithStorage[127.0.0.1:33687,DS-5a5ad68f-6a2c-47e2-88d2-908df06da05e,DISK], DatanodeInfoWithStorage[127.0.0.1:32989,DS-ad33a159-cc73-41e2-a4eb-ac8585d45ae1,DISK], DatanodeInfoWithStorage[127.0.0.1:45627,DS-633bc24c-2a1c-4fe8-b41b-2734047ab4eb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2104392240-172.17.0.4-1598440133842:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45655,DS-9d4f403b-4d8a-4638-bc6c-a58d401d287f,DISK], DatanodeInfoWithStorage[127.0.0.1:45985,DS-49249b7d-0c7f-41ae-852c-c93f08f174b7,DISK], DatanodeInfoWithStorage[127.0.0.1:33519,DS-f82dff27-2d36-4cff-89f5-4acf77417124,DISK], DatanodeInfoWithStorage[127.0.0.1:43495,DS-ce7ab472-3584-4959-a7de-643b18a69d26,DISK], DatanodeInfoWithStorage[127.0.0.1:45701,DS-f14be9e4-39f0-4fcc-ba48-8e92ccfd2fde,DISK], DatanodeInfoWithStorage[127.0.0.1:33687,DS-5a5ad68f-6a2c-47e2-88d2-908df06da05e,DISK], DatanodeInfoWithStorage[127.0.0.1:32989,DS-ad33a159-cc73-41e2-a4eb-ac8585d45ae1,DISK], DatanodeInfoWithStorage[127.0.0.1:45627,DS-633bc24c-2a1c-4fe8-b41b-2734047ab4eb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1186710938-172.17.0.4-1598440458915:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43404,DS-2a618683-d940-4de1-ad6e-01b6e9b23c6a,DISK], DatanodeInfoWithStorage[127.0.0.1:46665,DS-34d6c464-49be-4ca4-980b-e57fbe4b8ca5,DISK], DatanodeInfoWithStorage[127.0.0.1:44074,DS-20eb8f75-2022-4ab7-a677-c31519ce0591,DISK], DatanodeInfoWithStorage[127.0.0.1:40576,DS-a7666d28-0405-44a4-963a-195ec8a69ca4,DISK], DatanodeInfoWithStorage[127.0.0.1:34629,DS-cb7a9a1a-5694-4fae-8e2b-a3048590e9d2,DISK], DatanodeInfoWithStorage[127.0.0.1:40166,DS-e47ccc1c-7004-4043-aaab-f865df1c7dbf,DISK], DatanodeInfoWithStorage[127.0.0.1:43467,DS-f6f1618c-6a89-40e7-87e9-4d8c57e7d811,DISK], DatanodeInfoWithStorage[127.0.0.1:46105,DS-b3e0cb8e-54b7-4aaa-a0ec-5fdf2d415d93,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1186710938-172.17.0.4-1598440458915:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43404,DS-2a618683-d940-4de1-ad6e-01b6e9b23c6a,DISK], DatanodeInfoWithStorage[127.0.0.1:46665,DS-34d6c464-49be-4ca4-980b-e57fbe4b8ca5,DISK], DatanodeInfoWithStorage[127.0.0.1:44074,DS-20eb8f75-2022-4ab7-a677-c31519ce0591,DISK], DatanodeInfoWithStorage[127.0.0.1:40576,DS-a7666d28-0405-44a4-963a-195ec8a69ca4,DISK], DatanodeInfoWithStorage[127.0.0.1:34629,DS-cb7a9a1a-5694-4fae-8e2b-a3048590e9d2,DISK], DatanodeInfoWithStorage[127.0.0.1:40166,DS-e47ccc1c-7004-4043-aaab-f865df1c7dbf,DISK], DatanodeInfoWithStorage[127.0.0.1:43467,DS-f6f1618c-6a89-40e7-87e9-4d8c57e7d811,DISK], DatanodeInfoWithStorage[127.0.0.1:46105,DS-b3e0cb8e-54b7-4aaa-a0ec-5fdf2d415d93,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1944006331-172.17.0.4-1598440656417:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42835,DS-55d42743-48d9-464c-a495-23091fff37f1,DISK], DatanodeInfoWithStorage[127.0.0.1:39396,DS-b1fa570e-ef57-433b-a165-86fc1b164b6d,DISK], DatanodeInfoWithStorage[127.0.0.1:46133,DS-67f7dc0e-d5a5-4292-a8cb-a9c73c5d5889,DISK], DatanodeInfoWithStorage[127.0.0.1:36948,DS-351efb3b-3f0e-4177-b8e5-58f575002b54,DISK], DatanodeInfoWithStorage[127.0.0.1:38391,DS-93bafb7d-2287-43d0-9102-187eccd3bf55,DISK], DatanodeInfoWithStorage[127.0.0.1:37290,DS-f89d4bde-e9cb-4b9b-b5bf-db7dfbb18f83,DISK], DatanodeInfoWithStorage[127.0.0.1:44214,DS-63a76d05-ac15-42c5-adfd-0b74092a606f,DISK], DatanodeInfoWithStorage[127.0.0.1:37220,DS-b86df379-e1cc-40fe-b123-982450882c57,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1944006331-172.17.0.4-1598440656417:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42835,DS-55d42743-48d9-464c-a495-23091fff37f1,DISK], DatanodeInfoWithStorage[127.0.0.1:39396,DS-b1fa570e-ef57-433b-a165-86fc1b164b6d,DISK], DatanodeInfoWithStorage[127.0.0.1:46133,DS-67f7dc0e-d5a5-4292-a8cb-a9c73c5d5889,DISK], DatanodeInfoWithStorage[127.0.0.1:36948,DS-351efb3b-3f0e-4177-b8e5-58f575002b54,DISK], DatanodeInfoWithStorage[127.0.0.1:38391,DS-93bafb7d-2287-43d0-9102-187eccd3bf55,DISK], DatanodeInfoWithStorage[127.0.0.1:37290,DS-f89d4bde-e9cb-4b9b-b5bf-db7dfbb18f83,DISK], DatanodeInfoWithStorage[127.0.0.1:44214,DS-63a76d05-ac15-42c5-adfd-0b74092a606f,DISK], DatanodeInfoWithStorage[127.0.0.1:37220,DS-b86df379-e1cc-40fe-b123-982450882c57,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-561010196-172.17.0.4-1598440759056:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34721,DS-b5d44f20-1cd7-43f0-9626-2e6134acc796,DISK], DatanodeInfoWithStorage[127.0.0.1:41524,DS-e7729f83-4d46-4b93-b153-14300078464d,DISK], DatanodeInfoWithStorage[127.0.0.1:38975,DS-c3a2a02d-cd0d-49b7-a9ad-36a36042bce2,DISK], DatanodeInfoWithStorage[127.0.0.1:43344,DS-92e4257e-b572-4d7e-990c-a4edd8e59e24,DISK], DatanodeInfoWithStorage[127.0.0.1:38357,DS-64e3b928-8647-445f-99d3-20d9e6a44e13,DISK], DatanodeInfoWithStorage[127.0.0.1:42443,DS-e8d88933-f1de-4884-88ba-b57c1b513756,DISK], DatanodeInfoWithStorage[127.0.0.1:32854,DS-5d6c9807-6e26-479e-a58c-d780a4f50a13,DISK], DatanodeInfoWithStorage[127.0.0.1:45517,DS-e62695a2-7b82-4faa-98f4-ac2691edb2f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-561010196-172.17.0.4-1598440759056:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34721,DS-b5d44f20-1cd7-43f0-9626-2e6134acc796,DISK], DatanodeInfoWithStorage[127.0.0.1:41524,DS-e7729f83-4d46-4b93-b153-14300078464d,DISK], DatanodeInfoWithStorage[127.0.0.1:38975,DS-c3a2a02d-cd0d-49b7-a9ad-36a36042bce2,DISK], DatanodeInfoWithStorage[127.0.0.1:43344,DS-92e4257e-b572-4d7e-990c-a4edd8e59e24,DISK], DatanodeInfoWithStorage[127.0.0.1:38357,DS-64e3b928-8647-445f-99d3-20d9e6a44e13,DISK], DatanodeInfoWithStorage[127.0.0.1:42443,DS-e8d88933-f1de-4884-88ba-b57c1b513756,DISK], DatanodeInfoWithStorage[127.0.0.1:32854,DS-5d6c9807-6e26-479e-a58c-d780a4f50a13,DISK], DatanodeInfoWithStorage[127.0.0.1:45517,DS-e62695a2-7b82-4faa-98f4-ac2691edb2f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1285926595-172.17.0.4-1598441205461:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40272,DS-49678a08-1f3d-44d4-89d9-4f1d3f68e9d6,DISK], DatanodeInfoWithStorage[127.0.0.1:45463,DS-ade731ce-6f80-4105-bb4a-32879a9898bf,DISK], DatanodeInfoWithStorage[127.0.0.1:35296,DS-5beac4f9-34bc-458c-a65d-e8414a4e0c8c,DISK], DatanodeInfoWithStorage[127.0.0.1:34896,DS-5c8590ab-b96e-43ad-a915-a9cbab553514,DISK], DatanodeInfoWithStorage[127.0.0.1:33775,DS-99bcfecd-ce14-4a80-854d-2b5fd607c380,DISK], DatanodeInfoWithStorage[127.0.0.1:39750,DS-666a9c45-9b81-4a52-8e4f-2e7aa44925be,DISK], DatanodeInfoWithStorage[127.0.0.1:33920,DS-4ea7e579-cd1c-4ccd-8b58-a088b0ad4c5f,DISK], DatanodeInfoWithStorage[127.0.0.1:43631,DS-96e7684a-6826-459f-9f58-628653a25061,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1285926595-172.17.0.4-1598441205461:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40272,DS-49678a08-1f3d-44d4-89d9-4f1d3f68e9d6,DISK], DatanodeInfoWithStorage[127.0.0.1:45463,DS-ade731ce-6f80-4105-bb4a-32879a9898bf,DISK], DatanodeInfoWithStorage[127.0.0.1:35296,DS-5beac4f9-34bc-458c-a65d-e8414a4e0c8c,DISK], DatanodeInfoWithStorage[127.0.0.1:34896,DS-5c8590ab-b96e-43ad-a915-a9cbab553514,DISK], DatanodeInfoWithStorage[127.0.0.1:33775,DS-99bcfecd-ce14-4a80-854d-2b5fd607c380,DISK], DatanodeInfoWithStorage[127.0.0.1:39750,DS-666a9c45-9b81-4a52-8e4f-2e7aa44925be,DISK], DatanodeInfoWithStorage[127.0.0.1:33920,DS-4ea7e579-cd1c-4ccd-8b58-a088b0ad4c5f,DISK], DatanodeInfoWithStorage[127.0.0.1:43631,DS-96e7684a-6826-459f-9f58-628653a25061,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1667232103-172.17.0.4-1598441282157:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35027,DS-3f8c5114-723e-4e55-b28f-376a598dfafd,DISK], DatanodeInfoWithStorage[127.0.0.1:34609,DS-65738413-0401-434f-b48a-5f50b75e93f1,DISK], DatanodeInfoWithStorage[127.0.0.1:39403,DS-e34be41d-1b24-421b-ac36-c1d888228806,DISK], DatanodeInfoWithStorage[127.0.0.1:41951,DS-6ac4de40-e551-47d0-bff7-b9b29e326c1e,DISK], DatanodeInfoWithStorage[127.0.0.1:32976,DS-816e2efa-9870-419f-b6da-99b577641832,DISK], DatanodeInfoWithStorage[127.0.0.1:39327,DS-74fabbc7-4e6e-48c0-8aaf-ed4b256b4b7b,DISK], DatanodeInfoWithStorage[127.0.0.1:36643,DS-06d62249-7f59-48e4-8449-4a5fc47c59f5,DISK], DatanodeInfoWithStorage[127.0.0.1:35808,DS-6e725489-b982-4fea-9dda-6a69b0cb80e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1667232103-172.17.0.4-1598441282157:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35027,DS-3f8c5114-723e-4e55-b28f-376a598dfafd,DISK], DatanodeInfoWithStorage[127.0.0.1:34609,DS-65738413-0401-434f-b48a-5f50b75e93f1,DISK], DatanodeInfoWithStorage[127.0.0.1:39403,DS-e34be41d-1b24-421b-ac36-c1d888228806,DISK], DatanodeInfoWithStorage[127.0.0.1:41951,DS-6ac4de40-e551-47d0-bff7-b9b29e326c1e,DISK], DatanodeInfoWithStorage[127.0.0.1:32976,DS-816e2efa-9870-419f-b6da-99b577641832,DISK], DatanodeInfoWithStorage[127.0.0.1:39327,DS-74fabbc7-4e6e-48c0-8aaf-ed4b256b4b7b,DISK], DatanodeInfoWithStorage[127.0.0.1:36643,DS-06d62249-7f59-48e4-8449-4a5fc47c59f5,DISK], DatanodeInfoWithStorage[127.0.0.1:35808,DS-6e725489-b982-4fea-9dda-6a69b0cb80e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 5173
