reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-855878807-172.17.0.16-1598402388822:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39473,DS-0c90d942-d964-4260-b206-cb408cea39d7,DISK], DatanodeInfoWithStorage[127.0.0.1:37172,DS-08227912-3a42-4228-aecf-6f229b3f53ce,DISK], DatanodeInfoWithStorage[127.0.0.1:42868,DS-d519e72e-fdb9-49a6-9f1c-9037a8a5870d,DISK], DatanodeInfoWithStorage[127.0.0.1:42659,DS-d69abcc4-189f-4480-9530-e4e375487fa3,DISK], DatanodeInfoWithStorage[127.0.0.1:37735,DS-cc0ff42b-dd27-4885-9be5-0c4b60b482d7,DISK], DatanodeInfoWithStorage[127.0.0.1:41471,DS-e0b4a2c8-9777-4447-a3e8-ba3cce1b189b,DISK], DatanodeInfoWithStorage[127.0.0.1:43473,DS-cd2dfdfa-0c7a-44c8-98e5-c88e6d785a76,DISK], DatanodeInfoWithStorage[127.0.0.1:44607,DS-05563fdf-8e76-4058-becc-bf44d946969b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-855878807-172.17.0.16-1598402388822:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39473,DS-0c90d942-d964-4260-b206-cb408cea39d7,DISK], DatanodeInfoWithStorage[127.0.0.1:37172,DS-08227912-3a42-4228-aecf-6f229b3f53ce,DISK], DatanodeInfoWithStorage[127.0.0.1:42868,DS-d519e72e-fdb9-49a6-9f1c-9037a8a5870d,DISK], DatanodeInfoWithStorage[127.0.0.1:42659,DS-d69abcc4-189f-4480-9530-e4e375487fa3,DISK], DatanodeInfoWithStorage[127.0.0.1:37735,DS-cc0ff42b-dd27-4885-9be5-0c4b60b482d7,DISK], DatanodeInfoWithStorage[127.0.0.1:41471,DS-e0b4a2c8-9777-4447-a3e8-ba3cce1b189b,DISK], DatanodeInfoWithStorage[127.0.0.1:43473,DS-cd2dfdfa-0c7a-44c8-98e5-c88e6d785a76,DISK], DatanodeInfoWithStorage[127.0.0.1:44607,DS-05563fdf-8e76-4058-becc-bf44d946969b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1814056917-172.17.0.16-1598402715411:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45665,DS-52c8e575-3287-45b1-a078-cbc95df711e0,DISK], DatanodeInfoWithStorage[127.0.0.1:46663,DS-56031a46-1feb-4c5d-8b02-f27596d5582d,DISK], DatanodeInfoWithStorage[127.0.0.1:35151,DS-1c89daf3-a5f1-448c-b895-8ede352344ad,DISK], DatanodeInfoWithStorage[127.0.0.1:40945,DS-ab93069e-5c5b-4e5d-be02-b90738f81254,DISK], DatanodeInfoWithStorage[127.0.0.1:45572,DS-21e99533-9e06-4f86-9e53-728e19bccd95,DISK], DatanodeInfoWithStorage[127.0.0.1:40575,DS-39d7ecac-f705-4625-9d22-2d0706055c60,DISK], DatanodeInfoWithStorage[127.0.0.1:34076,DS-103d433f-9b58-464b-9f9e-3d089fcc654c,DISK], DatanodeInfoWithStorage[127.0.0.1:46531,DS-67d996bf-6e07-402c-8a53-be53aaa755d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1814056917-172.17.0.16-1598402715411:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45665,DS-52c8e575-3287-45b1-a078-cbc95df711e0,DISK], DatanodeInfoWithStorage[127.0.0.1:46663,DS-56031a46-1feb-4c5d-8b02-f27596d5582d,DISK], DatanodeInfoWithStorage[127.0.0.1:35151,DS-1c89daf3-a5f1-448c-b895-8ede352344ad,DISK], DatanodeInfoWithStorage[127.0.0.1:40945,DS-ab93069e-5c5b-4e5d-be02-b90738f81254,DISK], DatanodeInfoWithStorage[127.0.0.1:45572,DS-21e99533-9e06-4f86-9e53-728e19bccd95,DISK], DatanodeInfoWithStorage[127.0.0.1:40575,DS-39d7ecac-f705-4625-9d22-2d0706055c60,DISK], DatanodeInfoWithStorage[127.0.0.1:34076,DS-103d433f-9b58-464b-9f9e-3d089fcc654c,DISK], DatanodeInfoWithStorage[127.0.0.1:46531,DS-67d996bf-6e07-402c-8a53-be53aaa755d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1327333675-172.17.0.16-1598402786541:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41388,DS-a0e2b88c-e9eb-4f40-aff4-19384754bd82,DISK], DatanodeInfoWithStorage[127.0.0.1:34192,DS-5b26ed14-ce37-440d-8001-1365b1c66c82,DISK], DatanodeInfoWithStorage[127.0.0.1:38264,DS-6e6a2c21-2744-4fce-bc17-57c97ae0049f,DISK], DatanodeInfoWithStorage[127.0.0.1:33300,DS-b7b2b6dc-fef7-4b05-86a6-be824889191b,DISK], DatanodeInfoWithStorage[127.0.0.1:34673,DS-a7bef8d6-f5fa-4c8d-9496-511b20dc3b1a,DISK], DatanodeInfoWithStorage[127.0.0.1:38759,DS-b844ce16-a50f-468b-9ae1-cf3735f4a61e,DISK], DatanodeInfoWithStorage[127.0.0.1:39907,DS-f5254025-08da-4ba3-b2e2-31dfaba1cda1,DISK], DatanodeInfoWithStorage[127.0.0.1:35768,DS-79bf1474-8f75-49bf-8896-3b8f4a128fff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1327333675-172.17.0.16-1598402786541:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41388,DS-a0e2b88c-e9eb-4f40-aff4-19384754bd82,DISK], DatanodeInfoWithStorage[127.0.0.1:34192,DS-5b26ed14-ce37-440d-8001-1365b1c66c82,DISK], DatanodeInfoWithStorage[127.0.0.1:38264,DS-6e6a2c21-2744-4fce-bc17-57c97ae0049f,DISK], DatanodeInfoWithStorage[127.0.0.1:33300,DS-b7b2b6dc-fef7-4b05-86a6-be824889191b,DISK], DatanodeInfoWithStorage[127.0.0.1:34673,DS-a7bef8d6-f5fa-4c8d-9496-511b20dc3b1a,DISK], DatanodeInfoWithStorage[127.0.0.1:38759,DS-b844ce16-a50f-468b-9ae1-cf3735f4a61e,DISK], DatanodeInfoWithStorage[127.0.0.1:39907,DS-f5254025-08da-4ba3-b2e2-31dfaba1cda1,DISK], DatanodeInfoWithStorage[127.0.0.1:35768,DS-79bf1474-8f75-49bf-8896-3b8f4a128fff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-907157849-172.17.0.16-1598402863513:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40289,DS-b1aca795-f7cc-4180-94b4-b0581dace854,DISK], DatanodeInfoWithStorage[127.0.0.1:36678,DS-c6dcc0c8-1392-4b23-ae10-c4cb79ddefdb,DISK], DatanodeInfoWithStorage[127.0.0.1:41016,DS-04ae28ce-397a-4289-9820-2bfd5531a524,DISK], DatanodeInfoWithStorage[127.0.0.1:41921,DS-ba7cad27-27be-424d-9650-b59538350ea0,DISK], DatanodeInfoWithStorage[127.0.0.1:44475,DS-e8a4d0c2-e0ce-4543-a6df-aff4ea5d0c37,DISK], DatanodeInfoWithStorage[127.0.0.1:37556,DS-8c7bc437-10ac-4192-afc3-b023a65775bf,DISK], DatanodeInfoWithStorage[127.0.0.1:40507,DS-c44a3aab-5014-4f2e-9b87-74f6878965ed,DISK], DatanodeInfoWithStorage[127.0.0.1:42087,DS-7de279a8-4880-4bd8-821b-dd816b5e89b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-907157849-172.17.0.16-1598402863513:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40289,DS-b1aca795-f7cc-4180-94b4-b0581dace854,DISK], DatanodeInfoWithStorage[127.0.0.1:36678,DS-c6dcc0c8-1392-4b23-ae10-c4cb79ddefdb,DISK], DatanodeInfoWithStorage[127.0.0.1:41016,DS-04ae28ce-397a-4289-9820-2bfd5531a524,DISK], DatanodeInfoWithStorage[127.0.0.1:41921,DS-ba7cad27-27be-424d-9650-b59538350ea0,DISK], DatanodeInfoWithStorage[127.0.0.1:44475,DS-e8a4d0c2-e0ce-4543-a6df-aff4ea5d0c37,DISK], DatanodeInfoWithStorage[127.0.0.1:37556,DS-8c7bc437-10ac-4192-afc3-b023a65775bf,DISK], DatanodeInfoWithStorage[127.0.0.1:40507,DS-c44a3aab-5014-4f2e-9b87-74f6878965ed,DISK], DatanodeInfoWithStorage[127.0.0.1:42087,DS-7de279a8-4880-4bd8-821b-dd816b5e89b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-958132685-172.17.0.16-1598402929138:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38606,DS-c95dee03-acce-425e-9d7f-197e95e3a63e,DISK], DatanodeInfoWithStorage[127.0.0.1:40426,DS-dca3e88e-8bac-4f96-ac8d-b7cf8f765793,DISK], DatanodeInfoWithStorage[127.0.0.1:35666,DS-980d20eb-8644-4c88-b302-91bb3d02c2f8,DISK], DatanodeInfoWithStorage[127.0.0.1:34591,DS-9a39d010-e920-41a7-a276-225be75a6487,DISK], DatanodeInfoWithStorage[127.0.0.1:44200,DS-d1965efa-c7d4-4fe6-b100-b8e6ee29b157,DISK], DatanodeInfoWithStorage[127.0.0.1:40395,DS-966d298d-f237-4ff0-81c9-65a7ddaf79fc,DISK], DatanodeInfoWithStorage[127.0.0.1:34997,DS-e818d90c-2b08-4697-a49f-ac98f44b4de2,DISK], DatanodeInfoWithStorage[127.0.0.1:46155,DS-ac4421a8-4ac7-4627-8534-1f8e630d5119,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-958132685-172.17.0.16-1598402929138:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38606,DS-c95dee03-acce-425e-9d7f-197e95e3a63e,DISK], DatanodeInfoWithStorage[127.0.0.1:40426,DS-dca3e88e-8bac-4f96-ac8d-b7cf8f765793,DISK], DatanodeInfoWithStorage[127.0.0.1:35666,DS-980d20eb-8644-4c88-b302-91bb3d02c2f8,DISK], DatanodeInfoWithStorage[127.0.0.1:34591,DS-9a39d010-e920-41a7-a276-225be75a6487,DISK], DatanodeInfoWithStorage[127.0.0.1:44200,DS-d1965efa-c7d4-4fe6-b100-b8e6ee29b157,DISK], DatanodeInfoWithStorage[127.0.0.1:40395,DS-966d298d-f237-4ff0-81c9-65a7ddaf79fc,DISK], DatanodeInfoWithStorage[127.0.0.1:34997,DS-e818d90c-2b08-4697-a49f-ac98f44b4de2,DISK], DatanodeInfoWithStorage[127.0.0.1:46155,DS-ac4421a8-4ac7-4627-8534-1f8e630d5119,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1785521207-172.17.0.16-1598403034545:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35136,DS-3908dcb4-4a98-419b-b28a-56db5f9f0ba8,DISK], DatanodeInfoWithStorage[127.0.0.1:43688,DS-38decf2c-070c-4745-987c-f128d6fea47f,DISK], DatanodeInfoWithStorage[127.0.0.1:44956,DS-fcfa8fdc-2e4a-4600-9125-b2143d194e6c,DISK], DatanodeInfoWithStorage[127.0.0.1:44810,DS-ac7fc22c-a748-4909-a59b-68f47df2edef,DISK], DatanodeInfoWithStorage[127.0.0.1:40319,DS-cf1c0d35-d0ba-4ca7-8a45-cccbeee005db,DISK], DatanodeInfoWithStorage[127.0.0.1:33651,DS-56ff52b3-3e65-49e3-8797-cbdf92e1f11c,DISK], DatanodeInfoWithStorage[127.0.0.1:40875,DS-a562ed9c-17c2-4450-ae88-125b4c401b9c,DISK], DatanodeInfoWithStorage[127.0.0.1:34726,DS-835286e8-4d59-47ef-96f3-8f1df27b62ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1785521207-172.17.0.16-1598403034545:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35136,DS-3908dcb4-4a98-419b-b28a-56db5f9f0ba8,DISK], DatanodeInfoWithStorage[127.0.0.1:43688,DS-38decf2c-070c-4745-987c-f128d6fea47f,DISK], DatanodeInfoWithStorage[127.0.0.1:44956,DS-fcfa8fdc-2e4a-4600-9125-b2143d194e6c,DISK], DatanodeInfoWithStorage[127.0.0.1:44810,DS-ac7fc22c-a748-4909-a59b-68f47df2edef,DISK], DatanodeInfoWithStorage[127.0.0.1:40319,DS-cf1c0d35-d0ba-4ca7-8a45-cccbeee005db,DISK], DatanodeInfoWithStorage[127.0.0.1:33651,DS-56ff52b3-3e65-49e3-8797-cbdf92e1f11c,DISK], DatanodeInfoWithStorage[127.0.0.1:40875,DS-a562ed9c-17c2-4450-ae88-125b4c401b9c,DISK], DatanodeInfoWithStorage[127.0.0.1:34726,DS-835286e8-4d59-47ef-96f3-8f1df27b62ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1141661599-172.17.0.16-1598403318315:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41748,DS-2cdcb274-c8d4-4f45-a659-e938d83df588,DISK], DatanodeInfoWithStorage[127.0.0.1:37661,DS-e92f95a8-e5ae-451c-81a0-011c5ac033d0,DISK], DatanodeInfoWithStorage[127.0.0.1:37136,DS-14da7fbc-c229-4681-b1ae-5802785d81f1,DISK], DatanodeInfoWithStorage[127.0.0.1:40818,DS-1a0ca07e-b532-4fa4-8a58-549c108226b1,DISK], DatanodeInfoWithStorage[127.0.0.1:46566,DS-cdf4fdd6-6d61-437d-a290-edac00bb4663,DISK], DatanodeInfoWithStorage[127.0.0.1:45987,DS-739a66df-b628-4f40-84c8-86b7fde29815,DISK], DatanodeInfoWithStorage[127.0.0.1:45707,DS-45763c42-5cf1-43e2-bb68-6f92489d64ae,DISK], DatanodeInfoWithStorage[127.0.0.1:40359,DS-62f06bfe-943f-4e5d-adbc-73494a903487,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1141661599-172.17.0.16-1598403318315:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41748,DS-2cdcb274-c8d4-4f45-a659-e938d83df588,DISK], DatanodeInfoWithStorage[127.0.0.1:37661,DS-e92f95a8-e5ae-451c-81a0-011c5ac033d0,DISK], DatanodeInfoWithStorage[127.0.0.1:37136,DS-14da7fbc-c229-4681-b1ae-5802785d81f1,DISK], DatanodeInfoWithStorage[127.0.0.1:40818,DS-1a0ca07e-b532-4fa4-8a58-549c108226b1,DISK], DatanodeInfoWithStorage[127.0.0.1:46566,DS-cdf4fdd6-6d61-437d-a290-edac00bb4663,DISK], DatanodeInfoWithStorage[127.0.0.1:45987,DS-739a66df-b628-4f40-84c8-86b7fde29815,DISK], DatanodeInfoWithStorage[127.0.0.1:45707,DS-45763c42-5cf1-43e2-bb68-6f92489d64ae,DISK], DatanodeInfoWithStorage[127.0.0.1:40359,DS-62f06bfe-943f-4e5d-adbc-73494a903487,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-198461494-172.17.0.16-1598403684712:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37824,DS-35d7d92c-1add-48e4-8861-c63beb71b5e3,DISK], DatanodeInfoWithStorage[127.0.0.1:34588,DS-5b6418b0-cfe3-428e-9061-d4a522a2e096,DISK], DatanodeInfoWithStorage[127.0.0.1:40020,DS-dc37d088-8a91-43bc-aae8-c91b37b7dd9a,DISK], DatanodeInfoWithStorage[127.0.0.1:37136,DS-9e331a0e-181b-44b8-8135-d0a59d8742a5,DISK], DatanodeInfoWithStorage[127.0.0.1:42353,DS-20770c80-1d3e-4c35-b84f-f5ef60cdaaef,DISK], DatanodeInfoWithStorage[127.0.0.1:43344,DS-d23acf7a-46c4-4e9d-bce8-bd2c7a9dcf33,DISK], DatanodeInfoWithStorage[127.0.0.1:35768,DS-8b0f81ef-fe85-4190-b872-6eeb0bfd8a49,DISK], DatanodeInfoWithStorage[127.0.0.1:36070,DS-266c15c2-941a-47dc-9e1d-df9a5e464ef3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-198461494-172.17.0.16-1598403684712:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37824,DS-35d7d92c-1add-48e4-8861-c63beb71b5e3,DISK], DatanodeInfoWithStorage[127.0.0.1:34588,DS-5b6418b0-cfe3-428e-9061-d4a522a2e096,DISK], DatanodeInfoWithStorage[127.0.0.1:40020,DS-dc37d088-8a91-43bc-aae8-c91b37b7dd9a,DISK], DatanodeInfoWithStorage[127.0.0.1:37136,DS-9e331a0e-181b-44b8-8135-d0a59d8742a5,DISK], DatanodeInfoWithStorage[127.0.0.1:42353,DS-20770c80-1d3e-4c35-b84f-f5ef60cdaaef,DISK], DatanodeInfoWithStorage[127.0.0.1:43344,DS-d23acf7a-46c4-4e9d-bce8-bd2c7a9dcf33,DISK], DatanodeInfoWithStorage[127.0.0.1:35768,DS-8b0f81ef-fe85-4190-b872-6eeb0bfd8a49,DISK], DatanodeInfoWithStorage[127.0.0.1:36070,DS-266c15c2-941a-47dc-9e1d-df9a5e464ef3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-715327709-172.17.0.16-1598404591580:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40047,DS-a6dcfb2e-4874-4888-b4e8-5c2d86eb4c00,DISK], DatanodeInfoWithStorage[127.0.0.1:36435,DS-dc44d9ce-21f3-4b84-80ca-442d6931b55b,DISK], DatanodeInfoWithStorage[127.0.0.1:44544,DS-ae5136d8-b6d4-4735-a393-b73dd742590e,DISK], DatanodeInfoWithStorage[127.0.0.1:42649,DS-1a663fe2-eda7-48a8-9e8a-8898e8f7ee1d,DISK], DatanodeInfoWithStorage[127.0.0.1:46151,DS-5b334d6e-8043-41f9-aae5-3819d8a3dbbc,DISK], DatanodeInfoWithStorage[127.0.0.1:39656,DS-f03d975d-cbee-415c-8fe9-1e74dbcefc79,DISK], DatanodeInfoWithStorage[127.0.0.1:34661,DS-6529d780-9aa0-4608-849e-de1d4686cafa,DISK], DatanodeInfoWithStorage[127.0.0.1:42581,DS-a7a2f3c9-09a2-46ba-963e-db89698afa53,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-715327709-172.17.0.16-1598404591580:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40047,DS-a6dcfb2e-4874-4888-b4e8-5c2d86eb4c00,DISK], DatanodeInfoWithStorage[127.0.0.1:36435,DS-dc44d9ce-21f3-4b84-80ca-442d6931b55b,DISK], DatanodeInfoWithStorage[127.0.0.1:44544,DS-ae5136d8-b6d4-4735-a393-b73dd742590e,DISK], DatanodeInfoWithStorage[127.0.0.1:42649,DS-1a663fe2-eda7-48a8-9e8a-8898e8f7ee1d,DISK], DatanodeInfoWithStorage[127.0.0.1:46151,DS-5b334d6e-8043-41f9-aae5-3819d8a3dbbc,DISK], DatanodeInfoWithStorage[127.0.0.1:39656,DS-f03d975d-cbee-415c-8fe9-1e74dbcefc79,DISK], DatanodeInfoWithStorage[127.0.0.1:34661,DS-6529d780-9aa0-4608-849e-de1d4686cafa,DISK], DatanodeInfoWithStorage[127.0.0.1:42581,DS-a7a2f3c9-09a2-46ba-963e-db89698afa53,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-398319777-172.17.0.16-1598405357782:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39043,DS-4fdbbd06-4140-4c38-9319-6d3bd7381284,DISK], DatanodeInfoWithStorage[127.0.0.1:40505,DS-e1caa6da-af90-4b2f-bf48-0c9947c726fb,DISK], DatanodeInfoWithStorage[127.0.0.1:37331,DS-f4ea3678-1a93-427c-bd20-11992b9ce0c8,DISK], DatanodeInfoWithStorage[127.0.0.1:37940,DS-066f474f-a3ca-4051-bf7e-8c8a1ff96820,DISK], DatanodeInfoWithStorage[127.0.0.1:41392,DS-0b3b8dc4-87bd-4006-9821-68f0d80791bc,DISK], DatanodeInfoWithStorage[127.0.0.1:36980,DS-98a2ed38-4c29-493e-95f2-9a5f39acc803,DISK], DatanodeInfoWithStorage[127.0.0.1:34662,DS-f1ad1533-80c9-4945-9ded-e1dd0888efd3,DISK], DatanodeInfoWithStorage[127.0.0.1:38348,DS-45c908e4-9eb7-4c0c-ae81-6cae2a2e6e69,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-398319777-172.17.0.16-1598405357782:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39043,DS-4fdbbd06-4140-4c38-9319-6d3bd7381284,DISK], DatanodeInfoWithStorage[127.0.0.1:40505,DS-e1caa6da-af90-4b2f-bf48-0c9947c726fb,DISK], DatanodeInfoWithStorage[127.0.0.1:37331,DS-f4ea3678-1a93-427c-bd20-11992b9ce0c8,DISK], DatanodeInfoWithStorage[127.0.0.1:37940,DS-066f474f-a3ca-4051-bf7e-8c8a1ff96820,DISK], DatanodeInfoWithStorage[127.0.0.1:41392,DS-0b3b8dc4-87bd-4006-9821-68f0d80791bc,DISK], DatanodeInfoWithStorage[127.0.0.1:36980,DS-98a2ed38-4c29-493e-95f2-9a5f39acc803,DISK], DatanodeInfoWithStorage[127.0.0.1:34662,DS-f1ad1533-80c9-4945-9ded-e1dd0888efd3,DISK], DatanodeInfoWithStorage[127.0.0.1:38348,DS-45c908e4-9eb7-4c0c-ae81-6cae2a2e6e69,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-680922600-172.17.0.16-1598405741450:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35110,DS-80fd5fa0-523e-4b8c-b6a9-791600ef39cd,DISK], DatanodeInfoWithStorage[127.0.0.1:43614,DS-7f198c00-ee30-489d-a61b-2cee8dbfc53d,DISK], DatanodeInfoWithStorage[127.0.0.1:38599,DS-ae99d946-2f1a-4c9b-aa7c-d43fec7672cc,DISK], DatanodeInfoWithStorage[127.0.0.1:35811,DS-05dbbaea-c9a7-4fa3-82ba-c691cd3afaab,DISK], DatanodeInfoWithStorage[127.0.0.1:38736,DS-7963992e-2d6b-424a-909a-33194c4a81c5,DISK], DatanodeInfoWithStorage[127.0.0.1:32937,DS-6fc5182c-155f-4065-98c4-3dee269fd612,DISK], DatanodeInfoWithStorage[127.0.0.1:36488,DS-05c4fff6-d5fa-4ebb-baf9-2cfbca2f10b9,DISK], DatanodeInfoWithStorage[127.0.0.1:40972,DS-649b748a-ee04-46ca-a977-714125fd7436,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-680922600-172.17.0.16-1598405741450:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35110,DS-80fd5fa0-523e-4b8c-b6a9-791600ef39cd,DISK], DatanodeInfoWithStorage[127.0.0.1:43614,DS-7f198c00-ee30-489d-a61b-2cee8dbfc53d,DISK], DatanodeInfoWithStorage[127.0.0.1:38599,DS-ae99d946-2f1a-4c9b-aa7c-d43fec7672cc,DISK], DatanodeInfoWithStorage[127.0.0.1:35811,DS-05dbbaea-c9a7-4fa3-82ba-c691cd3afaab,DISK], DatanodeInfoWithStorage[127.0.0.1:38736,DS-7963992e-2d6b-424a-909a-33194c4a81c5,DISK], DatanodeInfoWithStorage[127.0.0.1:32937,DS-6fc5182c-155f-4065-98c4-3dee269fd612,DISK], DatanodeInfoWithStorage[127.0.0.1:36488,DS-05c4fff6-d5fa-4ebb-baf9-2cfbca2f10b9,DISK], DatanodeInfoWithStorage[127.0.0.1:40972,DS-649b748a-ee04-46ca-a977-714125fd7436,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1969902093-172.17.0.16-1598406019672:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44758,DS-d91eddac-05d5-4158-b3b5-0355997b4831,DISK], DatanodeInfoWithStorage[127.0.0.1:39415,DS-c14e8aae-41b2-430d-9f1f-9cf54d476445,DISK], DatanodeInfoWithStorage[127.0.0.1:37505,DS-e29f3d87-4b0b-472f-aad0-b57a324d7367,DISK], DatanodeInfoWithStorage[127.0.0.1:36022,DS-b2b89d9c-e220-4e6c-afdc-6e4515cf7dbd,DISK], DatanodeInfoWithStorage[127.0.0.1:43439,DS-44d75c5d-c28b-4466-ab06-3ef68f10d5bd,DISK], DatanodeInfoWithStorage[127.0.0.1:39977,DS-ba74ff82-637a-4425-84d4-2df2aa3780c0,DISK], DatanodeInfoWithStorage[127.0.0.1:41684,DS-ed163391-a856-45ef-9286-740149ba3507,DISK], DatanodeInfoWithStorage[127.0.0.1:42955,DS-67038fcf-6fdf-4b22-83b8-89fd762a7ae8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1969902093-172.17.0.16-1598406019672:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44758,DS-d91eddac-05d5-4158-b3b5-0355997b4831,DISK], DatanodeInfoWithStorage[127.0.0.1:39415,DS-c14e8aae-41b2-430d-9f1f-9cf54d476445,DISK], DatanodeInfoWithStorage[127.0.0.1:37505,DS-e29f3d87-4b0b-472f-aad0-b57a324d7367,DISK], DatanodeInfoWithStorage[127.0.0.1:36022,DS-b2b89d9c-e220-4e6c-afdc-6e4515cf7dbd,DISK], DatanodeInfoWithStorage[127.0.0.1:43439,DS-44d75c5d-c28b-4466-ab06-3ef68f10d5bd,DISK], DatanodeInfoWithStorage[127.0.0.1:39977,DS-ba74ff82-637a-4425-84d4-2df2aa3780c0,DISK], DatanodeInfoWithStorage[127.0.0.1:41684,DS-ed163391-a856-45ef-9286-740149ba3507,DISK], DatanodeInfoWithStorage[127.0.0.1:42955,DS-67038fcf-6fdf-4b22-83b8-89fd762a7ae8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1860986882-172.17.0.16-1598406266333:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33957,DS-f3b9d7b8-47a2-483b-8916-eae9827d97f1,DISK], DatanodeInfoWithStorage[127.0.0.1:43940,DS-09df7c6e-77bc-4810-91f6-69214f011c2a,DISK], DatanodeInfoWithStorage[127.0.0.1:33097,DS-cac0be5f-1130-4659-9eef-835965152724,DISK], DatanodeInfoWithStorage[127.0.0.1:44770,DS-a3e5bf55-928a-41c4-babc-87dee980c892,DISK], DatanodeInfoWithStorage[127.0.0.1:40354,DS-34d5534c-82c9-4954-98bf-efcf6672fc2f,DISK], DatanodeInfoWithStorage[127.0.0.1:43757,DS-89ab6283-42a0-443c-a335-ef8aabf5a640,DISK], DatanodeInfoWithStorage[127.0.0.1:43819,DS-ee3c87d3-5c41-4e38-80cf-4208ed972954,DISK], DatanodeInfoWithStorage[127.0.0.1:44667,DS-9c23dfea-a0d1-4efc-92e4-9dce9a321378,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1860986882-172.17.0.16-1598406266333:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33957,DS-f3b9d7b8-47a2-483b-8916-eae9827d97f1,DISK], DatanodeInfoWithStorage[127.0.0.1:43940,DS-09df7c6e-77bc-4810-91f6-69214f011c2a,DISK], DatanodeInfoWithStorage[127.0.0.1:33097,DS-cac0be5f-1130-4659-9eef-835965152724,DISK], DatanodeInfoWithStorage[127.0.0.1:44770,DS-a3e5bf55-928a-41c4-babc-87dee980c892,DISK], DatanodeInfoWithStorage[127.0.0.1:40354,DS-34d5534c-82c9-4954-98bf-efcf6672fc2f,DISK], DatanodeInfoWithStorage[127.0.0.1:43757,DS-89ab6283-42a0-443c-a335-ef8aabf5a640,DISK], DatanodeInfoWithStorage[127.0.0.1:43819,DS-ee3c87d3-5c41-4e38-80cf-4208ed972954,DISK], DatanodeInfoWithStorage[127.0.0.1:44667,DS-9c23dfea-a0d1-4efc-92e4-9dce9a321378,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-453992013-172.17.0.16-1598407101859:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34555,DS-7992e5c9-4008-4533-b940-64ce84c5d949,DISK], DatanodeInfoWithStorage[127.0.0.1:35874,DS-c70e967b-73b4-4fe2-b1ea-4f37c3e6af51,DISK], DatanodeInfoWithStorage[127.0.0.1:45609,DS-68c0da48-98fb-40db-b625-a69f5892534c,DISK], DatanodeInfoWithStorage[127.0.0.1:40286,DS-ea2cf30b-62cf-45a3-995a-efc96ac99efe,DISK], DatanodeInfoWithStorage[127.0.0.1:37618,DS-5751188c-e232-4eba-b332-e1c2134bb0b8,DISK], DatanodeInfoWithStorage[127.0.0.1:46096,DS-2f17e265-5472-409b-8588-ee8bf4dd3b53,DISK], DatanodeInfoWithStorage[127.0.0.1:44275,DS-6ef2c5f4-aca1-465a-84c4-160cda02e08e,DISK], DatanodeInfoWithStorage[127.0.0.1:38356,DS-f4d44ebb-aef8-40dd-aa13-51dbe13496a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-453992013-172.17.0.16-1598407101859:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34555,DS-7992e5c9-4008-4533-b940-64ce84c5d949,DISK], DatanodeInfoWithStorage[127.0.0.1:35874,DS-c70e967b-73b4-4fe2-b1ea-4f37c3e6af51,DISK], DatanodeInfoWithStorage[127.0.0.1:45609,DS-68c0da48-98fb-40db-b625-a69f5892534c,DISK], DatanodeInfoWithStorage[127.0.0.1:40286,DS-ea2cf30b-62cf-45a3-995a-efc96ac99efe,DISK], DatanodeInfoWithStorage[127.0.0.1:37618,DS-5751188c-e232-4eba-b332-e1c2134bb0b8,DISK], DatanodeInfoWithStorage[127.0.0.1:46096,DS-2f17e265-5472-409b-8588-ee8bf4dd3b53,DISK], DatanodeInfoWithStorage[127.0.0.1:44275,DS-6ef2c5f4-aca1-465a-84c4-160cda02e08e,DISK], DatanodeInfoWithStorage[127.0.0.1:38356,DS-f4d44ebb-aef8-40dd-aa13-51dbe13496a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2084806329-172.17.0.16-1598407166299:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36632,DS-a997e0ea-e3c9-4bf5-b5b7-a47db7230421,DISK], DatanodeInfoWithStorage[127.0.0.1:43140,DS-3a557f05-a6b8-4982-95fa-eff8a6b738d9,DISK], DatanodeInfoWithStorage[127.0.0.1:40733,DS-dcfd85cc-7131-4de2-a241-720b01b99653,DISK], DatanodeInfoWithStorage[127.0.0.1:36314,DS-82742d4e-7705-4a5a-b7ec-2336124bce1f,DISK], DatanodeInfoWithStorage[127.0.0.1:45637,DS-4368a321-d444-4c7e-bda8-1ae61d7825a5,DISK], DatanodeInfoWithStorage[127.0.0.1:44840,DS-220037f7-3079-41ef-820c-0f63e50dac32,DISK], DatanodeInfoWithStorage[127.0.0.1:41984,DS-b2d76364-a4b3-418f-bc2a-165a9b397943,DISK], DatanodeInfoWithStorage[127.0.0.1:33883,DS-ede47a2d-ce44-4401-b561-c0e32ada70cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2084806329-172.17.0.16-1598407166299:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36632,DS-a997e0ea-e3c9-4bf5-b5b7-a47db7230421,DISK], DatanodeInfoWithStorage[127.0.0.1:43140,DS-3a557f05-a6b8-4982-95fa-eff8a6b738d9,DISK], DatanodeInfoWithStorage[127.0.0.1:40733,DS-dcfd85cc-7131-4de2-a241-720b01b99653,DISK], DatanodeInfoWithStorage[127.0.0.1:36314,DS-82742d4e-7705-4a5a-b7ec-2336124bce1f,DISK], DatanodeInfoWithStorage[127.0.0.1:45637,DS-4368a321-d444-4c7e-bda8-1ae61d7825a5,DISK], DatanodeInfoWithStorage[127.0.0.1:44840,DS-220037f7-3079-41ef-820c-0f63e50dac32,DISK], DatanodeInfoWithStorage[127.0.0.1:41984,DS-b2d76364-a4b3-418f-bc2a-165a9b397943,DISK], DatanodeInfoWithStorage[127.0.0.1:33883,DS-ede47a2d-ce44-4401-b561-c0e32ada70cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5147
