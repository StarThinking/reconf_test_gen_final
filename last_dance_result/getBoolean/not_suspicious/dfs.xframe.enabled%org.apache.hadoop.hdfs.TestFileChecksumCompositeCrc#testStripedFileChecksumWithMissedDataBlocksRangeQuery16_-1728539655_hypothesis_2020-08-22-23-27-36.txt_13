reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-599895129-172.17.0.2-1598139086917:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34129,DS-d4d646b2-af0a-4884-bb3b-287314f99634,DISK], DatanodeInfoWithStorage[127.0.0.1:41232,DS-bb590f76-d485-470c-9fbc-8ffb407ba3bc,DISK], DatanodeInfoWithStorage[127.0.0.1:45155,DS-84a7ee8a-aa09-4e46-98b6-c104ba1f1a01,DISK], DatanodeInfoWithStorage[127.0.0.1:41439,DS-8f2bcf60-4be6-4341-99b8-8b3dfa4fbb66,DISK], DatanodeInfoWithStorage[127.0.0.1:41931,DS-572d95a8-1fce-4f91-97df-6610722e4a54,DISK], DatanodeInfoWithStorage[127.0.0.1:44339,DS-2918b499-907f-4cb6-8397-e82779bc3db4,DISK], DatanodeInfoWithStorage[127.0.0.1:34095,DS-780ba937-de9b-4ffa-b88a-94af0c6b3ae1,DISK], DatanodeInfoWithStorage[127.0.0.1:39506,DS-d59b9054-3417-48af-9496-cb973c62c706,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-599895129-172.17.0.2-1598139086917:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34129,DS-d4d646b2-af0a-4884-bb3b-287314f99634,DISK], DatanodeInfoWithStorage[127.0.0.1:41232,DS-bb590f76-d485-470c-9fbc-8ffb407ba3bc,DISK], DatanodeInfoWithStorage[127.0.0.1:45155,DS-84a7ee8a-aa09-4e46-98b6-c104ba1f1a01,DISK], DatanodeInfoWithStorage[127.0.0.1:41439,DS-8f2bcf60-4be6-4341-99b8-8b3dfa4fbb66,DISK], DatanodeInfoWithStorage[127.0.0.1:41931,DS-572d95a8-1fce-4f91-97df-6610722e4a54,DISK], DatanodeInfoWithStorage[127.0.0.1:44339,DS-2918b499-907f-4cb6-8397-e82779bc3db4,DISK], DatanodeInfoWithStorage[127.0.0.1:34095,DS-780ba937-de9b-4ffa-b88a-94af0c6b3ae1,DISK], DatanodeInfoWithStorage[127.0.0.1:39506,DS-d59b9054-3417-48af-9496-cb973c62c706,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1634197723-172.17.0.2-1598139234247:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36800,DS-396e8eb8-b064-4c41-80f5-9ea9ce1aeba7,DISK], DatanodeInfoWithStorage[127.0.0.1:46863,DS-1448a359-cc1b-4c7c-922e-2783d1184433,DISK], DatanodeInfoWithStorage[127.0.0.1:40680,DS-f2518815-a02b-4588-aab6-46eac331c504,DISK], DatanodeInfoWithStorage[127.0.0.1:38654,DS-58277250-7712-409b-887e-13bea1e69541,DISK], DatanodeInfoWithStorage[127.0.0.1:35722,DS-f9090f04-67de-47df-b3eb-4994b92a9861,DISK], DatanodeInfoWithStorage[127.0.0.1:45131,DS-00418238-97dc-4fb2-9877-0f4af5b10fe3,DISK], DatanodeInfoWithStorage[127.0.0.1:37141,DS-c60d8468-02a7-4e18-a3c4-2f1c1590ff8a,DISK], DatanodeInfoWithStorage[127.0.0.1:41014,DS-03550afd-eb36-475f-b25a-3277ec89cab4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1634197723-172.17.0.2-1598139234247:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36800,DS-396e8eb8-b064-4c41-80f5-9ea9ce1aeba7,DISK], DatanodeInfoWithStorage[127.0.0.1:46863,DS-1448a359-cc1b-4c7c-922e-2783d1184433,DISK], DatanodeInfoWithStorage[127.0.0.1:40680,DS-f2518815-a02b-4588-aab6-46eac331c504,DISK], DatanodeInfoWithStorage[127.0.0.1:38654,DS-58277250-7712-409b-887e-13bea1e69541,DISK], DatanodeInfoWithStorage[127.0.0.1:35722,DS-f9090f04-67de-47df-b3eb-4994b92a9861,DISK], DatanodeInfoWithStorage[127.0.0.1:45131,DS-00418238-97dc-4fb2-9877-0f4af5b10fe3,DISK], DatanodeInfoWithStorage[127.0.0.1:37141,DS-c60d8468-02a7-4e18-a3c4-2f1c1590ff8a,DISK], DatanodeInfoWithStorage[127.0.0.1:41014,DS-03550afd-eb36-475f-b25a-3277ec89cab4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2006372447-172.17.0.2-1598139569401:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37416,DS-35287a11-035d-48a1-b23a-acd15cda1cbb,DISK], DatanodeInfoWithStorage[127.0.0.1:37630,DS-e8fd0a2f-d7b6-4cfe-9d11-a05a86472a0d,DISK], DatanodeInfoWithStorage[127.0.0.1:44733,DS-49371c82-e021-4924-a716-74968380c14f,DISK], DatanodeInfoWithStorage[127.0.0.1:39437,DS-8a79342d-b824-41da-a547-ed4fff10afa7,DISK], DatanodeInfoWithStorage[127.0.0.1:39536,DS-3cceaeb1-c51d-401a-8b27-c398940fb558,DISK], DatanodeInfoWithStorage[127.0.0.1:39268,DS-f0da1ed5-276d-4cd7-a590-646926bd3316,DISK], DatanodeInfoWithStorage[127.0.0.1:42372,DS-eb73e163-f093-44c6-af03-fb65d0f310d0,DISK], DatanodeInfoWithStorage[127.0.0.1:38190,DS-372bcb80-06be-40db-ad3d-c188b2c4fb18,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2006372447-172.17.0.2-1598139569401:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37416,DS-35287a11-035d-48a1-b23a-acd15cda1cbb,DISK], DatanodeInfoWithStorage[127.0.0.1:37630,DS-e8fd0a2f-d7b6-4cfe-9d11-a05a86472a0d,DISK], DatanodeInfoWithStorage[127.0.0.1:44733,DS-49371c82-e021-4924-a716-74968380c14f,DISK], DatanodeInfoWithStorage[127.0.0.1:39437,DS-8a79342d-b824-41da-a547-ed4fff10afa7,DISK], DatanodeInfoWithStorage[127.0.0.1:39536,DS-3cceaeb1-c51d-401a-8b27-c398940fb558,DISK], DatanodeInfoWithStorage[127.0.0.1:39268,DS-f0da1ed5-276d-4cd7-a590-646926bd3316,DISK], DatanodeInfoWithStorage[127.0.0.1:42372,DS-eb73e163-f093-44c6-af03-fb65d0f310d0,DISK], DatanodeInfoWithStorage[127.0.0.1:38190,DS-372bcb80-06be-40db-ad3d-c188b2c4fb18,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-671815731-172.17.0.2-1598140143896:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37862,DS-16d05a29-32b7-4893-81e5-1b8615bd44ac,DISK], DatanodeInfoWithStorage[127.0.0.1:37890,DS-42c0a426-2578-431a-a53a-085b61696bf0,DISK], DatanodeInfoWithStorage[127.0.0.1:44287,DS-cbfa25f6-12f5-4097-a50e-a0c317826ba4,DISK], DatanodeInfoWithStorage[127.0.0.1:39536,DS-a865b2f6-456b-4425-90fe-cbb68905ed0a,DISK], DatanodeInfoWithStorage[127.0.0.1:46116,DS-298cbbdb-bece-40bf-99ec-03db89d1516a,DISK], DatanodeInfoWithStorage[127.0.0.1:41871,DS-e3516dfc-a2eb-4902-93c6-b898408b421b,DISK], DatanodeInfoWithStorage[127.0.0.1:34027,DS-de5bc44c-8f15-424c-9042-9bf28c354605,DISK], DatanodeInfoWithStorage[127.0.0.1:39934,DS-50e8099d-516b-4430-b656-1bb850958484,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-671815731-172.17.0.2-1598140143896:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37862,DS-16d05a29-32b7-4893-81e5-1b8615bd44ac,DISK], DatanodeInfoWithStorage[127.0.0.1:37890,DS-42c0a426-2578-431a-a53a-085b61696bf0,DISK], DatanodeInfoWithStorage[127.0.0.1:44287,DS-cbfa25f6-12f5-4097-a50e-a0c317826ba4,DISK], DatanodeInfoWithStorage[127.0.0.1:39536,DS-a865b2f6-456b-4425-90fe-cbb68905ed0a,DISK], DatanodeInfoWithStorage[127.0.0.1:46116,DS-298cbbdb-bece-40bf-99ec-03db89d1516a,DISK], DatanodeInfoWithStorage[127.0.0.1:41871,DS-e3516dfc-a2eb-4902-93c6-b898408b421b,DISK], DatanodeInfoWithStorage[127.0.0.1:34027,DS-de5bc44c-8f15-424c-9042-9bf28c354605,DISK], DatanodeInfoWithStorage[127.0.0.1:39934,DS-50e8099d-516b-4430-b656-1bb850958484,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-372175443-172.17.0.2-1598140494129:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39079,DS-b0cf2bbb-6209-4f9f-b205-c035fdd11d31,DISK], DatanodeInfoWithStorage[127.0.0.1:36121,DS-7a354276-d3c9-4497-a131-9f067426eb5a,DISK], DatanodeInfoWithStorage[127.0.0.1:41309,DS-8849f26b-efe5-43cd-810d-55b0aa7b6cbd,DISK], DatanodeInfoWithStorage[127.0.0.1:38839,DS-928b7a61-9158-4966-914d-f71a6dc5d5ce,DISK], DatanodeInfoWithStorage[127.0.0.1:36305,DS-b198cc2f-3a56-4b08-9a38-e3c01bb104e2,DISK], DatanodeInfoWithStorage[127.0.0.1:34712,DS-38926c20-5280-45c3-8983-052c4843353a,DISK], DatanodeInfoWithStorage[127.0.0.1:44502,DS-6680bd8b-6bdc-4efe-871d-e4cd28d85d0f,DISK], DatanodeInfoWithStorage[127.0.0.1:39457,DS-c2736d2e-284d-4d7d-bc3e-8f4691461e00,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-372175443-172.17.0.2-1598140494129:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39079,DS-b0cf2bbb-6209-4f9f-b205-c035fdd11d31,DISK], DatanodeInfoWithStorage[127.0.0.1:36121,DS-7a354276-d3c9-4497-a131-9f067426eb5a,DISK], DatanodeInfoWithStorage[127.0.0.1:41309,DS-8849f26b-efe5-43cd-810d-55b0aa7b6cbd,DISK], DatanodeInfoWithStorage[127.0.0.1:38839,DS-928b7a61-9158-4966-914d-f71a6dc5d5ce,DISK], DatanodeInfoWithStorage[127.0.0.1:36305,DS-b198cc2f-3a56-4b08-9a38-e3c01bb104e2,DISK], DatanodeInfoWithStorage[127.0.0.1:34712,DS-38926c20-5280-45c3-8983-052c4843353a,DISK], DatanodeInfoWithStorage[127.0.0.1:44502,DS-6680bd8b-6bdc-4efe-871d-e4cd28d85d0f,DISK], DatanodeInfoWithStorage[127.0.0.1:39457,DS-c2736d2e-284d-4d7d-bc3e-8f4691461e00,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-773159507-172.17.0.2-1598140629704:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41491,DS-87363afd-e6dc-4d2a-914a-0a42f047713a,DISK], DatanodeInfoWithStorage[127.0.0.1:35470,DS-eec3c77c-1f6e-4849-8769-639ce9a22749,DISK], DatanodeInfoWithStorage[127.0.0.1:43231,DS-8e92b469-11a9-4c9a-8283-8550371f672a,DISK], DatanodeInfoWithStorage[127.0.0.1:38728,DS-98d38852-d1e9-4f6a-96a3-4206e5d9908c,DISK], DatanodeInfoWithStorage[127.0.0.1:35992,DS-bd006933-9a27-4938-b695-7ec4505fa13b,DISK], DatanodeInfoWithStorage[127.0.0.1:37457,DS-0d41cb62-941d-45b5-abca-6c71590c5e7f,DISK], DatanodeInfoWithStorage[127.0.0.1:46319,DS-3b13b7a1-55c3-4ff2-9d9c-1325572d8895,DISK], DatanodeInfoWithStorage[127.0.0.1:45635,DS-b7abbc05-cf21-47ae-b38b-dc8387f69cee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-773159507-172.17.0.2-1598140629704:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41491,DS-87363afd-e6dc-4d2a-914a-0a42f047713a,DISK], DatanodeInfoWithStorage[127.0.0.1:35470,DS-eec3c77c-1f6e-4849-8769-639ce9a22749,DISK], DatanodeInfoWithStorage[127.0.0.1:43231,DS-8e92b469-11a9-4c9a-8283-8550371f672a,DISK], DatanodeInfoWithStorage[127.0.0.1:38728,DS-98d38852-d1e9-4f6a-96a3-4206e5d9908c,DISK], DatanodeInfoWithStorage[127.0.0.1:35992,DS-bd006933-9a27-4938-b695-7ec4505fa13b,DISK], DatanodeInfoWithStorage[127.0.0.1:37457,DS-0d41cb62-941d-45b5-abca-6c71590c5e7f,DISK], DatanodeInfoWithStorage[127.0.0.1:46319,DS-3b13b7a1-55c3-4ff2-9d9c-1325572d8895,DISK], DatanodeInfoWithStorage[127.0.0.1:45635,DS-b7abbc05-cf21-47ae-b38b-dc8387f69cee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-133743253-172.17.0.2-1598140663931:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45748,DS-bac4bd2a-b05d-4ce0-9363-eb045db16249,DISK], DatanodeInfoWithStorage[127.0.0.1:37558,DS-c6d09879-87f9-40eb-baa0-f6ecbc859526,DISK], DatanodeInfoWithStorage[127.0.0.1:45036,DS-dd47ca62-4351-4dfe-bb8f-b9d5bd09d3f2,DISK], DatanodeInfoWithStorage[127.0.0.1:36129,DS-86e9554a-755b-41d6-8d91-88260e010426,DISK], DatanodeInfoWithStorage[127.0.0.1:34879,DS-bd960f50-c44f-4092-b652-4b0aa058651c,DISK], DatanodeInfoWithStorage[127.0.0.1:39581,DS-2e8f0bfc-3dc6-4067-94b5-efba6f5aa52e,DISK], DatanodeInfoWithStorage[127.0.0.1:40305,DS-19de1c43-8268-482f-a1ca-13a98269107d,DISK], DatanodeInfoWithStorage[127.0.0.1:43658,DS-df218c9a-8aaa-48dc-8b85-f6894b96a49a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-133743253-172.17.0.2-1598140663931:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45748,DS-bac4bd2a-b05d-4ce0-9363-eb045db16249,DISK], DatanodeInfoWithStorage[127.0.0.1:37558,DS-c6d09879-87f9-40eb-baa0-f6ecbc859526,DISK], DatanodeInfoWithStorage[127.0.0.1:45036,DS-dd47ca62-4351-4dfe-bb8f-b9d5bd09d3f2,DISK], DatanodeInfoWithStorage[127.0.0.1:36129,DS-86e9554a-755b-41d6-8d91-88260e010426,DISK], DatanodeInfoWithStorage[127.0.0.1:34879,DS-bd960f50-c44f-4092-b652-4b0aa058651c,DISK], DatanodeInfoWithStorage[127.0.0.1:39581,DS-2e8f0bfc-3dc6-4067-94b5-efba6f5aa52e,DISK], DatanodeInfoWithStorage[127.0.0.1:40305,DS-19de1c43-8268-482f-a1ca-13a98269107d,DISK], DatanodeInfoWithStorage[127.0.0.1:43658,DS-df218c9a-8aaa-48dc-8b85-f6894b96a49a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1410027608-172.17.0.2-1598140937847:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36216,DS-daba4350-2b46-4484-b9d7-4260ebcee6f5,DISK], DatanodeInfoWithStorage[127.0.0.1:41630,DS-1af7b950-2a76-4107-b5f1-ed7d594b8220,DISK], DatanodeInfoWithStorage[127.0.0.1:36375,DS-9f462f68-36d3-47c5-a71e-7cadb567d3f9,DISK], DatanodeInfoWithStorage[127.0.0.1:38440,DS-774d883a-4ee9-4d77-bc76-a425d36e2828,DISK], DatanodeInfoWithStorage[127.0.0.1:32846,DS-8e32badf-8ce0-4771-bfaa-313348cb7e8f,DISK], DatanodeInfoWithStorage[127.0.0.1:46457,DS-16a08b29-a0d1-40da-8ff2-146245fd6968,DISK], DatanodeInfoWithStorage[127.0.0.1:33775,DS-844cdfc2-38c6-4ef9-9c7e-5a6d7e660597,DISK], DatanodeInfoWithStorage[127.0.0.1:41631,DS-20a24f90-ad37-4235-8823-a59a76a2eada,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1410027608-172.17.0.2-1598140937847:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36216,DS-daba4350-2b46-4484-b9d7-4260ebcee6f5,DISK], DatanodeInfoWithStorage[127.0.0.1:41630,DS-1af7b950-2a76-4107-b5f1-ed7d594b8220,DISK], DatanodeInfoWithStorage[127.0.0.1:36375,DS-9f462f68-36d3-47c5-a71e-7cadb567d3f9,DISK], DatanodeInfoWithStorage[127.0.0.1:38440,DS-774d883a-4ee9-4d77-bc76-a425d36e2828,DISK], DatanodeInfoWithStorage[127.0.0.1:32846,DS-8e32badf-8ce0-4771-bfaa-313348cb7e8f,DISK], DatanodeInfoWithStorage[127.0.0.1:46457,DS-16a08b29-a0d1-40da-8ff2-146245fd6968,DISK], DatanodeInfoWithStorage[127.0.0.1:33775,DS-844cdfc2-38c6-4ef9-9c7e-5a6d7e660597,DISK], DatanodeInfoWithStorage[127.0.0.1:41631,DS-20a24f90-ad37-4235-8823-a59a76a2eada,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-249512404-172.17.0.2-1598141183931:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42693,DS-27e137f3-23e1-4b54-8a8b-23e3821f562e,DISK], DatanodeInfoWithStorage[127.0.0.1:38385,DS-567c2efa-a7e1-44b7-bff7-5b06a221a1c7,DISK], DatanodeInfoWithStorage[127.0.0.1:43972,DS-aa7b6d6c-a951-46b3-93a1-fea43e0c047b,DISK], DatanodeInfoWithStorage[127.0.0.1:34700,DS-9b750453-f535-4c00-9241-d56e490e89c3,DISK], DatanodeInfoWithStorage[127.0.0.1:38855,DS-969bdb70-a1af-46c1-af0e-686535486870,DISK], DatanodeInfoWithStorage[127.0.0.1:44262,DS-5f862708-14a6-4a98-85ef-1f0ef22d1c56,DISK], DatanodeInfoWithStorage[127.0.0.1:34949,DS-646b5b6c-36d1-42ac-b169-b712811ec8bb,DISK], DatanodeInfoWithStorage[127.0.0.1:35967,DS-ca80f288-a176-466b-8855-444a44993389,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-249512404-172.17.0.2-1598141183931:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42693,DS-27e137f3-23e1-4b54-8a8b-23e3821f562e,DISK], DatanodeInfoWithStorage[127.0.0.1:38385,DS-567c2efa-a7e1-44b7-bff7-5b06a221a1c7,DISK], DatanodeInfoWithStorage[127.0.0.1:43972,DS-aa7b6d6c-a951-46b3-93a1-fea43e0c047b,DISK], DatanodeInfoWithStorage[127.0.0.1:34700,DS-9b750453-f535-4c00-9241-d56e490e89c3,DISK], DatanodeInfoWithStorage[127.0.0.1:38855,DS-969bdb70-a1af-46c1-af0e-686535486870,DISK], DatanodeInfoWithStorage[127.0.0.1:44262,DS-5f862708-14a6-4a98-85ef-1f0ef22d1c56,DISK], DatanodeInfoWithStorage[127.0.0.1:34949,DS-646b5b6c-36d1-42ac-b169-b712811ec8bb,DISK], DatanodeInfoWithStorage[127.0.0.1:35967,DS-ca80f288-a176-466b-8855-444a44993389,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1636923010-172.17.0.2-1598141860496:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46365,DS-ca2827f5-1583-42e6-8037-76768617fe5f,DISK], DatanodeInfoWithStorage[127.0.0.1:43190,DS-aa009b61-739f-4d70-9500-827610eb2355,DISK], DatanodeInfoWithStorage[127.0.0.1:41217,DS-54f039c9-bbbe-4537-a7af-234e99d53d9e,DISK], DatanodeInfoWithStorage[127.0.0.1:45290,DS-a07dfeaf-2362-4cd5-9f50-db025196a6f4,DISK], DatanodeInfoWithStorage[127.0.0.1:37984,DS-dd25ca75-6053-44af-918a-4878f94a16ee,DISK], DatanodeInfoWithStorage[127.0.0.1:35019,DS-e209e1ef-7de4-4379-ad41-5874580cf081,DISK], DatanodeInfoWithStorage[127.0.0.1:43742,DS-f8519ec6-e68d-4b8d-bd2c-83c476adf567,DISK], DatanodeInfoWithStorage[127.0.0.1:40150,DS-936e59c3-24be-48cf-bbb0-6ff3c70ada97,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1636923010-172.17.0.2-1598141860496:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46365,DS-ca2827f5-1583-42e6-8037-76768617fe5f,DISK], DatanodeInfoWithStorage[127.0.0.1:43190,DS-aa009b61-739f-4d70-9500-827610eb2355,DISK], DatanodeInfoWithStorage[127.0.0.1:41217,DS-54f039c9-bbbe-4537-a7af-234e99d53d9e,DISK], DatanodeInfoWithStorage[127.0.0.1:45290,DS-a07dfeaf-2362-4cd5-9f50-db025196a6f4,DISK], DatanodeInfoWithStorage[127.0.0.1:37984,DS-dd25ca75-6053-44af-918a-4878f94a16ee,DISK], DatanodeInfoWithStorage[127.0.0.1:35019,DS-e209e1ef-7de4-4379-ad41-5874580cf081,DISK], DatanodeInfoWithStorage[127.0.0.1:43742,DS-f8519ec6-e68d-4b8d-bd2c-83c476adf567,DISK], DatanodeInfoWithStorage[127.0.0.1:40150,DS-936e59c3-24be-48cf-bbb0-6ff3c70ada97,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1830896403-172.17.0.2-1598142215975:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39182,DS-744988e5-b73e-41d5-9915-faeb96113958,DISK], DatanodeInfoWithStorage[127.0.0.1:43696,DS-15d30b8c-d558-44e0-8ab5-a9588bc9d6af,DISK], DatanodeInfoWithStorage[127.0.0.1:42551,DS-52dcc3c2-74eb-4a8c-b63d-8561bbfda30a,DISK], DatanodeInfoWithStorage[127.0.0.1:38639,DS-f9627ff6-1123-415f-a615-5404ece83026,DISK], DatanodeInfoWithStorage[127.0.0.1:38590,DS-4141843f-bbf3-41ed-8707-e4b77b131517,DISK], DatanodeInfoWithStorage[127.0.0.1:46283,DS-180e76b4-5234-4e94-a66d-c966995a0346,DISK], DatanodeInfoWithStorage[127.0.0.1:38320,DS-4c04af08-ffce-407b-adfe-8c32f99f808b,DISK], DatanodeInfoWithStorage[127.0.0.1:39826,DS-16c0ca3a-b827-46f7-bc72-198de38ca793,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1830896403-172.17.0.2-1598142215975:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39182,DS-744988e5-b73e-41d5-9915-faeb96113958,DISK], DatanodeInfoWithStorage[127.0.0.1:43696,DS-15d30b8c-d558-44e0-8ab5-a9588bc9d6af,DISK], DatanodeInfoWithStorage[127.0.0.1:42551,DS-52dcc3c2-74eb-4a8c-b63d-8561bbfda30a,DISK], DatanodeInfoWithStorage[127.0.0.1:38639,DS-f9627ff6-1123-415f-a615-5404ece83026,DISK], DatanodeInfoWithStorage[127.0.0.1:38590,DS-4141843f-bbf3-41ed-8707-e4b77b131517,DISK], DatanodeInfoWithStorage[127.0.0.1:46283,DS-180e76b4-5234-4e94-a66d-c966995a0346,DISK], DatanodeInfoWithStorage[127.0.0.1:38320,DS-4c04af08-ffce-407b-adfe-8c32f99f808b,DISK], DatanodeInfoWithStorage[127.0.0.1:39826,DS-16c0ca3a-b827-46f7-bc72-198de38ca793,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-12430767-172.17.0.2-1598142319508:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35809,DS-5e7ff613-685a-4b9d-94a9-6d9746243f9b,DISK], DatanodeInfoWithStorage[127.0.0.1:39327,DS-9bb1f255-4c8c-4759-9c0e-663c992eae46,DISK], DatanodeInfoWithStorage[127.0.0.1:37280,DS-aa9ce235-4775-4578-8405-a72803e18357,DISK], DatanodeInfoWithStorage[127.0.0.1:45607,DS-34a10356-c1ee-4259-b127-7e70d6626365,DISK], DatanodeInfoWithStorage[127.0.0.1:36056,DS-ab87b668-65d0-4cf6-bc8c-c87b05d043e3,DISK], DatanodeInfoWithStorage[127.0.0.1:34787,DS-fee8e751-efa4-4fb6-ae5e-dd88ed1f995a,DISK], DatanodeInfoWithStorage[127.0.0.1:45172,DS-0a1b8950-ea9c-45a3-bb85-1ea28b422fce,DISK], DatanodeInfoWithStorage[127.0.0.1:42772,DS-b590a7fd-d793-41a7-8e04-26b81f71f55f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-12430767-172.17.0.2-1598142319508:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35809,DS-5e7ff613-685a-4b9d-94a9-6d9746243f9b,DISK], DatanodeInfoWithStorage[127.0.0.1:39327,DS-9bb1f255-4c8c-4759-9c0e-663c992eae46,DISK], DatanodeInfoWithStorage[127.0.0.1:37280,DS-aa9ce235-4775-4578-8405-a72803e18357,DISK], DatanodeInfoWithStorage[127.0.0.1:45607,DS-34a10356-c1ee-4259-b127-7e70d6626365,DISK], DatanodeInfoWithStorage[127.0.0.1:36056,DS-ab87b668-65d0-4cf6-bc8c-c87b05d043e3,DISK], DatanodeInfoWithStorage[127.0.0.1:34787,DS-fee8e751-efa4-4fb6-ae5e-dd88ed1f995a,DISK], DatanodeInfoWithStorage[127.0.0.1:45172,DS-0a1b8950-ea9c-45a3-bb85-1ea28b422fce,DISK], DatanodeInfoWithStorage[127.0.0.1:42772,DS-b590a7fd-d793-41a7-8e04-26b81f71f55f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1752169717-172.17.0.2-1598142871964:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46662,DS-b7995e0a-60ee-47b1-96c1-3a0ee4543614,DISK], DatanodeInfoWithStorage[127.0.0.1:41456,DS-89fba162-8261-4830-a624-f5b2c276c59d,DISK], DatanodeInfoWithStorage[127.0.0.1:34985,DS-6fe627df-2e83-40fb-a5de-6c06b01718aa,DISK], DatanodeInfoWithStorage[127.0.0.1:35908,DS-5a8e9de2-e898-49f3-81d4-c464f73c81e6,DISK], DatanodeInfoWithStorage[127.0.0.1:41184,DS-54521914-6659-41f7-8b58-d3b664a422ff,DISK], DatanodeInfoWithStorage[127.0.0.1:44983,DS-fcfb0174-30d6-44c0-ab67-4f774e88028c,DISK], DatanodeInfoWithStorage[127.0.0.1:42345,DS-c8437f2f-2a58-441b-a7ff-69925c7694b0,DISK], DatanodeInfoWithStorage[127.0.0.1:38210,DS-416ad3d5-4505-49bb-8d37-7ea574376808,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1752169717-172.17.0.2-1598142871964:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46662,DS-b7995e0a-60ee-47b1-96c1-3a0ee4543614,DISK], DatanodeInfoWithStorage[127.0.0.1:41456,DS-89fba162-8261-4830-a624-f5b2c276c59d,DISK], DatanodeInfoWithStorage[127.0.0.1:34985,DS-6fe627df-2e83-40fb-a5de-6c06b01718aa,DISK], DatanodeInfoWithStorage[127.0.0.1:35908,DS-5a8e9de2-e898-49f3-81d4-c464f73c81e6,DISK], DatanodeInfoWithStorage[127.0.0.1:41184,DS-54521914-6659-41f7-8b58-d3b664a422ff,DISK], DatanodeInfoWithStorage[127.0.0.1:44983,DS-fcfb0174-30d6-44c0-ab67-4f774e88028c,DISK], DatanodeInfoWithStorage[127.0.0.1:42345,DS-c8437f2f-2a58-441b-a7ff-69925c7694b0,DISK], DatanodeInfoWithStorage[127.0.0.1:38210,DS-416ad3d5-4505-49bb-8d37-7ea574376808,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-365158000-172.17.0.2-1598143687800:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46409,DS-6646c5b5-fecf-4857-b03b-c7e0ef593fe1,DISK], DatanodeInfoWithStorage[127.0.0.1:35740,DS-1f65cde4-8b67-490d-90e6-74096fd88f62,DISK], DatanodeInfoWithStorage[127.0.0.1:44414,DS-50e63601-a400-4a94-9aab-7374e0005748,DISK], DatanodeInfoWithStorage[127.0.0.1:33735,DS-ba049d89-99f8-43aa-b9b2-24512aba3034,DISK], DatanodeInfoWithStorage[127.0.0.1:44286,DS-11cbdb8d-d0d3-4aea-955c-a1447596b9c6,DISK], DatanodeInfoWithStorage[127.0.0.1:45659,DS-99730d4d-f93e-4fa3-96f6-3884a42ae863,DISK], DatanodeInfoWithStorage[127.0.0.1:43965,DS-a18b1f00-ec61-4489-86ca-b6280d77dfbc,DISK], DatanodeInfoWithStorage[127.0.0.1:35464,DS-b8aaf7ae-4dcd-4c36-9d14-51e6336e13d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-365158000-172.17.0.2-1598143687800:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46409,DS-6646c5b5-fecf-4857-b03b-c7e0ef593fe1,DISK], DatanodeInfoWithStorage[127.0.0.1:35740,DS-1f65cde4-8b67-490d-90e6-74096fd88f62,DISK], DatanodeInfoWithStorage[127.0.0.1:44414,DS-50e63601-a400-4a94-9aab-7374e0005748,DISK], DatanodeInfoWithStorage[127.0.0.1:33735,DS-ba049d89-99f8-43aa-b9b2-24512aba3034,DISK], DatanodeInfoWithStorage[127.0.0.1:44286,DS-11cbdb8d-d0d3-4aea-955c-a1447596b9c6,DISK], DatanodeInfoWithStorage[127.0.0.1:45659,DS-99730d4d-f93e-4fa3-96f6-3884a42ae863,DISK], DatanodeInfoWithStorage[127.0.0.1:43965,DS-a18b1f00-ec61-4489-86ca-b6280d77dfbc,DISK], DatanodeInfoWithStorage[127.0.0.1:35464,DS-b8aaf7ae-4dcd-4c36-9d14-51e6336e13d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1948337532-172.17.0.2-1598143719672:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46095,DS-29285a40-2dd9-4ff6-99ce-8a1524806dc0,DISK], DatanodeInfoWithStorage[127.0.0.1:43686,DS-179ab069-28f1-4f39-bde1-6aeb2db6ca0e,DISK], DatanodeInfoWithStorage[127.0.0.1:44011,DS-9b61c9f4-9eff-4dc6-8d16-0c70c0a381d6,DISK], DatanodeInfoWithStorage[127.0.0.1:38291,DS-c3f5de52-b98f-4b80-bd0f-e7fbf87a6ef0,DISK], DatanodeInfoWithStorage[127.0.0.1:46162,DS-cd76e595-aace-4ba5-a551-6ab3d1401dfd,DISK], DatanodeInfoWithStorage[127.0.0.1:41100,DS-2945a21f-519d-48cf-a106-5b24428abd5c,DISK], DatanodeInfoWithStorage[127.0.0.1:42582,DS-5018e397-2318-4be7-b0e7-de137bec0708,DISK], DatanodeInfoWithStorage[127.0.0.1:41967,DS-a766082a-0852-4d2d-a713-f4259164ff65,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1948337532-172.17.0.2-1598143719672:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46095,DS-29285a40-2dd9-4ff6-99ce-8a1524806dc0,DISK], DatanodeInfoWithStorage[127.0.0.1:43686,DS-179ab069-28f1-4f39-bde1-6aeb2db6ca0e,DISK], DatanodeInfoWithStorage[127.0.0.1:44011,DS-9b61c9f4-9eff-4dc6-8d16-0c70c0a381d6,DISK], DatanodeInfoWithStorage[127.0.0.1:38291,DS-c3f5de52-b98f-4b80-bd0f-e7fbf87a6ef0,DISK], DatanodeInfoWithStorage[127.0.0.1:46162,DS-cd76e595-aace-4ba5-a551-6ab3d1401dfd,DISK], DatanodeInfoWithStorage[127.0.0.1:41100,DS-2945a21f-519d-48cf-a106-5b24428abd5c,DISK], DatanodeInfoWithStorage[127.0.0.1:42582,DS-5018e397-2318-4be7-b0e7-de137bec0708,DISK], DatanodeInfoWithStorage[127.0.0.1:41967,DS-a766082a-0852-4d2d-a713-f4259164ff65,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-212417647-172.17.0.2-1598143963506:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34329,DS-f118f428-48d8-47b7-aa15-c9cd9597135d,DISK], DatanodeInfoWithStorage[127.0.0.1:33837,DS-452630a8-9619-419d-b7c3-17c3b213b320,DISK], DatanodeInfoWithStorage[127.0.0.1:43478,DS-58048bf5-cf2b-44bb-8fda-2aef109419b8,DISK], DatanodeInfoWithStorage[127.0.0.1:39046,DS-70530bf6-9225-439b-b40f-5822228df71f,DISK], DatanodeInfoWithStorage[127.0.0.1:43310,DS-37549863-99ce-401b-b04b-067db3d8a941,DISK], DatanodeInfoWithStorage[127.0.0.1:34292,DS-28f506e2-ea04-4ffe-95f3-162ef2a1d5c1,DISK], DatanodeInfoWithStorage[127.0.0.1:40506,DS-260f7e67-2c7f-4b4d-8bfa-ea463d7a0ff8,DISK], DatanodeInfoWithStorage[127.0.0.1:42679,DS-9526e490-54ba-4480-bd18-de4aec341e39,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-212417647-172.17.0.2-1598143963506:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34329,DS-f118f428-48d8-47b7-aa15-c9cd9597135d,DISK], DatanodeInfoWithStorage[127.0.0.1:33837,DS-452630a8-9619-419d-b7c3-17c3b213b320,DISK], DatanodeInfoWithStorage[127.0.0.1:43478,DS-58048bf5-cf2b-44bb-8fda-2aef109419b8,DISK], DatanodeInfoWithStorage[127.0.0.1:39046,DS-70530bf6-9225-439b-b40f-5822228df71f,DISK], DatanodeInfoWithStorage[127.0.0.1:43310,DS-37549863-99ce-401b-b04b-067db3d8a941,DISK], DatanodeInfoWithStorage[127.0.0.1:34292,DS-28f506e2-ea04-4ffe-95f3-162ef2a1d5c1,DISK], DatanodeInfoWithStorage[127.0.0.1:40506,DS-260f7e67-2c7f-4b4d-8bfa-ea463d7a0ff8,DISK], DatanodeInfoWithStorage[127.0.0.1:42679,DS-9526e490-54ba-4480-bd18-de4aec341e39,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5298
