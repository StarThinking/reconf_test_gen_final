reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-440185995-172.17.0.4-1598342040214:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37020,DS-83c877df-5780-4404-b0e8-87a4f2b8e627,DISK], DatanodeInfoWithStorage[127.0.0.1:40181,DS-1a62ec9a-66f6-4902-b580-866d07c80661,DISK], DatanodeInfoWithStorage[127.0.0.1:34169,DS-3c496241-43fb-41dd-9251-0cff6beaf10f,DISK], DatanodeInfoWithStorage[127.0.0.1:43998,DS-e59bbd4a-eb18-44f1-b30c-dbfe015e06db,DISK], DatanodeInfoWithStorage[127.0.0.1:45214,DS-b9345a77-8bce-413a-a2f2-5b74d43a1c1a,DISK], DatanodeInfoWithStorage[127.0.0.1:35611,DS-d7cf37dd-0517-47f1-99d2-ffeb079779f0,DISK], DatanodeInfoWithStorage[127.0.0.1:38393,DS-545dd54a-e90a-4599-acbe-466d071d51b4,DISK], DatanodeInfoWithStorage[127.0.0.1:35557,DS-e965a33b-2177-40c2-a116-f6e9a3f4dcd5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-440185995-172.17.0.4-1598342040214:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37020,DS-83c877df-5780-4404-b0e8-87a4f2b8e627,DISK], DatanodeInfoWithStorage[127.0.0.1:40181,DS-1a62ec9a-66f6-4902-b580-866d07c80661,DISK], DatanodeInfoWithStorage[127.0.0.1:34169,DS-3c496241-43fb-41dd-9251-0cff6beaf10f,DISK], DatanodeInfoWithStorage[127.0.0.1:43998,DS-e59bbd4a-eb18-44f1-b30c-dbfe015e06db,DISK], DatanodeInfoWithStorage[127.0.0.1:45214,DS-b9345a77-8bce-413a-a2f2-5b74d43a1c1a,DISK], DatanodeInfoWithStorage[127.0.0.1:35611,DS-d7cf37dd-0517-47f1-99d2-ffeb079779f0,DISK], DatanodeInfoWithStorage[127.0.0.1:38393,DS-545dd54a-e90a-4599-acbe-466d071d51b4,DISK], DatanodeInfoWithStorage[127.0.0.1:35557,DS-e965a33b-2177-40c2-a116-f6e9a3f4dcd5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1847930157-172.17.0.4-1598342431713:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39751,DS-8bf9911b-8775-4b6d-94cf-ccf841d126ad,DISK], DatanodeInfoWithStorage[127.0.0.1:45234,DS-d81a691a-f56d-4e97-ba2f-dd80515e5a05,DISK], DatanodeInfoWithStorage[127.0.0.1:36221,DS-226ece7d-e1f9-49c4-92cb-43f919a75306,DISK], DatanodeInfoWithStorage[127.0.0.1:46221,DS-c1788899-dc67-423b-b08c-aff2b1f0aa66,DISK], DatanodeInfoWithStorage[127.0.0.1:43012,DS-3388a33c-bd72-4c11-b3e4-14614f78d863,DISK], DatanodeInfoWithStorage[127.0.0.1:40491,DS-0a8fd368-1f3d-4939-aea7-accab1dbd77b,DISK], DatanodeInfoWithStorage[127.0.0.1:39071,DS-121f4c05-fc37-4b03-bef2-ef77c2d6e2f2,DISK], DatanodeInfoWithStorage[127.0.0.1:40671,DS-c3bc6cf5-923f-478d-87fe-cde787bd47a7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1847930157-172.17.0.4-1598342431713:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39751,DS-8bf9911b-8775-4b6d-94cf-ccf841d126ad,DISK], DatanodeInfoWithStorage[127.0.0.1:45234,DS-d81a691a-f56d-4e97-ba2f-dd80515e5a05,DISK], DatanodeInfoWithStorage[127.0.0.1:36221,DS-226ece7d-e1f9-49c4-92cb-43f919a75306,DISK], DatanodeInfoWithStorage[127.0.0.1:46221,DS-c1788899-dc67-423b-b08c-aff2b1f0aa66,DISK], DatanodeInfoWithStorage[127.0.0.1:43012,DS-3388a33c-bd72-4c11-b3e4-14614f78d863,DISK], DatanodeInfoWithStorage[127.0.0.1:40491,DS-0a8fd368-1f3d-4939-aea7-accab1dbd77b,DISK], DatanodeInfoWithStorage[127.0.0.1:39071,DS-121f4c05-fc37-4b03-bef2-ef77c2d6e2f2,DISK], DatanodeInfoWithStorage[127.0.0.1:40671,DS-c3bc6cf5-923f-478d-87fe-cde787bd47a7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1752938954-172.17.0.4-1598342511306:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34952,DS-5a149ffb-4452-4aad-bc6e-cb0a97a0b7b2,DISK], DatanodeInfoWithStorage[127.0.0.1:43618,DS-5bc9e660-e0bb-49e2-b9fd-3f07a469dd6e,DISK], DatanodeInfoWithStorage[127.0.0.1:39383,DS-d535bdfb-7a67-4742-8f4a-f7a83d3a1469,DISK], DatanodeInfoWithStorage[127.0.0.1:46067,DS-96d3fbea-bc39-4784-9741-580807527f88,DISK], DatanodeInfoWithStorage[127.0.0.1:40412,DS-b109d3ea-2893-4f63-974b-d678bb828379,DISK], DatanodeInfoWithStorage[127.0.0.1:45579,DS-ed2d9120-ab73-4326-ad86-7c1fc3c12280,DISK], DatanodeInfoWithStorage[127.0.0.1:44649,DS-654ac792-1763-4061-bc55-aea3ebe20938,DISK], DatanodeInfoWithStorage[127.0.0.1:32887,DS-d0a66807-0a63-4575-adad-aa1f90513dbc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1752938954-172.17.0.4-1598342511306:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34952,DS-5a149ffb-4452-4aad-bc6e-cb0a97a0b7b2,DISK], DatanodeInfoWithStorage[127.0.0.1:43618,DS-5bc9e660-e0bb-49e2-b9fd-3f07a469dd6e,DISK], DatanodeInfoWithStorage[127.0.0.1:39383,DS-d535bdfb-7a67-4742-8f4a-f7a83d3a1469,DISK], DatanodeInfoWithStorage[127.0.0.1:46067,DS-96d3fbea-bc39-4784-9741-580807527f88,DISK], DatanodeInfoWithStorage[127.0.0.1:40412,DS-b109d3ea-2893-4f63-974b-d678bb828379,DISK], DatanodeInfoWithStorage[127.0.0.1:45579,DS-ed2d9120-ab73-4326-ad86-7c1fc3c12280,DISK], DatanodeInfoWithStorage[127.0.0.1:44649,DS-654ac792-1763-4061-bc55-aea3ebe20938,DISK], DatanodeInfoWithStorage[127.0.0.1:32887,DS-d0a66807-0a63-4575-adad-aa1f90513dbc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1279540847-172.17.0.4-1598342584700:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37952,DS-f656883a-47d2-4f96-80ae-ac7c09e2011a,DISK], DatanodeInfoWithStorage[127.0.0.1:44599,DS-5ad2e90b-3135-4ce1-a5cc-65b97091390a,DISK], DatanodeInfoWithStorage[127.0.0.1:36827,DS-17ab01d7-9cc4-4c3c-8326-5bc79bf48122,DISK], DatanodeInfoWithStorage[127.0.0.1:34117,DS-74cf339e-580d-4c64-8b14-896de5de4380,DISK], DatanodeInfoWithStorage[127.0.0.1:36475,DS-eb0a6285-a80a-4f70-bdb2-f773b22d99b1,DISK], DatanodeInfoWithStorage[127.0.0.1:38810,DS-086ed9eb-bf96-4644-b4cb-29c47e0b4243,DISK], DatanodeInfoWithStorage[127.0.0.1:43710,DS-30f28a18-e742-424f-baf9-e0e215d8cdc4,DISK], DatanodeInfoWithStorage[127.0.0.1:44124,DS-4c7c405e-49ad-444d-98b6-706fc8dacda3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1279540847-172.17.0.4-1598342584700:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37952,DS-f656883a-47d2-4f96-80ae-ac7c09e2011a,DISK], DatanodeInfoWithStorage[127.0.0.1:44599,DS-5ad2e90b-3135-4ce1-a5cc-65b97091390a,DISK], DatanodeInfoWithStorage[127.0.0.1:36827,DS-17ab01d7-9cc4-4c3c-8326-5bc79bf48122,DISK], DatanodeInfoWithStorage[127.0.0.1:34117,DS-74cf339e-580d-4c64-8b14-896de5de4380,DISK], DatanodeInfoWithStorage[127.0.0.1:36475,DS-eb0a6285-a80a-4f70-bdb2-f773b22d99b1,DISK], DatanodeInfoWithStorage[127.0.0.1:38810,DS-086ed9eb-bf96-4644-b4cb-29c47e0b4243,DISK], DatanodeInfoWithStorage[127.0.0.1:43710,DS-30f28a18-e742-424f-baf9-e0e215d8cdc4,DISK], DatanodeInfoWithStorage[127.0.0.1:44124,DS-4c7c405e-49ad-444d-98b6-706fc8dacda3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-267079511-172.17.0.4-1598342696886:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46661,DS-9ed6cebf-3a96-4ec7-8bfa-3bc8a5ab9dae,DISK], DatanodeInfoWithStorage[127.0.0.1:41085,DS-d1c36c6d-5a2a-400e-8136-ea5c9b87595b,DISK], DatanodeInfoWithStorage[127.0.0.1:45922,DS-74ec67b5-4f29-4af1-bc37-aef14277f136,DISK], DatanodeInfoWithStorage[127.0.0.1:37781,DS-da331999-e76e-44e2-8cda-be093849eb73,DISK], DatanodeInfoWithStorage[127.0.0.1:40386,DS-3e83cef5-82cc-4527-9426-2d73540c2156,DISK], DatanodeInfoWithStorage[127.0.0.1:45043,DS-3a988215-95c0-4414-aa2a-10e1f68bb4de,DISK], DatanodeInfoWithStorage[127.0.0.1:44347,DS-baa6dcfb-24bf-43f4-8b5c-bd37f582dd4b,DISK], DatanodeInfoWithStorage[127.0.0.1:36978,DS-114c7aa6-eab7-4500-b2e9-b59b2a940322,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-267079511-172.17.0.4-1598342696886:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46661,DS-9ed6cebf-3a96-4ec7-8bfa-3bc8a5ab9dae,DISK], DatanodeInfoWithStorage[127.0.0.1:41085,DS-d1c36c6d-5a2a-400e-8136-ea5c9b87595b,DISK], DatanodeInfoWithStorage[127.0.0.1:45922,DS-74ec67b5-4f29-4af1-bc37-aef14277f136,DISK], DatanodeInfoWithStorage[127.0.0.1:37781,DS-da331999-e76e-44e2-8cda-be093849eb73,DISK], DatanodeInfoWithStorage[127.0.0.1:40386,DS-3e83cef5-82cc-4527-9426-2d73540c2156,DISK], DatanodeInfoWithStorage[127.0.0.1:45043,DS-3a988215-95c0-4414-aa2a-10e1f68bb4de,DISK], DatanodeInfoWithStorage[127.0.0.1:44347,DS-baa6dcfb-24bf-43f4-8b5c-bd37f582dd4b,DISK], DatanodeInfoWithStorage[127.0.0.1:36978,DS-114c7aa6-eab7-4500-b2e9-b59b2a940322,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2048451810-172.17.0.4-1598342732430:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45484,DS-b40b5253-5ef0-4520-aa26-336f1be13690,DISK], DatanodeInfoWithStorage[127.0.0.1:46108,DS-b91ceec6-0bf5-4c6a-adbb-2594f3065b82,DISK], DatanodeInfoWithStorage[127.0.0.1:43193,DS-75aaea82-ca3a-441b-80bd-a70584b7be84,DISK], DatanodeInfoWithStorage[127.0.0.1:36946,DS-2c751a92-c6fd-4c52-82a1-7fef26733f80,DISK], DatanodeInfoWithStorage[127.0.0.1:34720,DS-b1c39d01-f653-4dd8-9b19-3c44490b7169,DISK], DatanodeInfoWithStorage[127.0.0.1:46818,DS-98017f52-78ef-4039-869e-dc91c1253d03,DISK], DatanodeInfoWithStorage[127.0.0.1:41985,DS-dc238ba8-ec94-4926-a6a8-2347d2c35430,DISK], DatanodeInfoWithStorage[127.0.0.1:39582,DS-0cdc1507-9e63-461b-abea-583814b5b1a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2048451810-172.17.0.4-1598342732430:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45484,DS-b40b5253-5ef0-4520-aa26-336f1be13690,DISK], DatanodeInfoWithStorage[127.0.0.1:46108,DS-b91ceec6-0bf5-4c6a-adbb-2594f3065b82,DISK], DatanodeInfoWithStorage[127.0.0.1:43193,DS-75aaea82-ca3a-441b-80bd-a70584b7be84,DISK], DatanodeInfoWithStorage[127.0.0.1:36946,DS-2c751a92-c6fd-4c52-82a1-7fef26733f80,DISK], DatanodeInfoWithStorage[127.0.0.1:34720,DS-b1c39d01-f653-4dd8-9b19-3c44490b7169,DISK], DatanodeInfoWithStorage[127.0.0.1:46818,DS-98017f52-78ef-4039-869e-dc91c1253d03,DISK], DatanodeInfoWithStorage[127.0.0.1:41985,DS-dc238ba8-ec94-4926-a6a8-2347d2c35430,DISK], DatanodeInfoWithStorage[127.0.0.1:39582,DS-0cdc1507-9e63-461b-abea-583814b5b1a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1393461369-172.17.0.4-1598342770731:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38777,DS-781d17ea-a015-4b05-a6eb-3695eeecd2a7,DISK], DatanodeInfoWithStorage[127.0.0.1:40857,DS-fed33778-ed43-458f-993e-921d87bd87ab,DISK], DatanodeInfoWithStorage[127.0.0.1:42599,DS-b0b77273-f6d8-4a15-85e0-91444fd93b07,DISK], DatanodeInfoWithStorage[127.0.0.1:45441,DS-f3eee82a-b6bc-4ea5-b9b0-32cf6ab0d1c6,DISK], DatanodeInfoWithStorage[127.0.0.1:33627,DS-6c3ee821-3131-472b-acb5-4fbbc81b5118,DISK], DatanodeInfoWithStorage[127.0.0.1:44174,DS-4d5a8264-813e-47b3-ab1a-565f7002ff72,DISK], DatanodeInfoWithStorage[127.0.0.1:35573,DS-5fb86a04-28da-4051-96c6-4ce31607098b,DISK], DatanodeInfoWithStorage[127.0.0.1:40170,DS-52bba505-8ff4-427b-8281-0216987bdc0d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1393461369-172.17.0.4-1598342770731:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38777,DS-781d17ea-a015-4b05-a6eb-3695eeecd2a7,DISK], DatanodeInfoWithStorage[127.0.0.1:40857,DS-fed33778-ed43-458f-993e-921d87bd87ab,DISK], DatanodeInfoWithStorage[127.0.0.1:42599,DS-b0b77273-f6d8-4a15-85e0-91444fd93b07,DISK], DatanodeInfoWithStorage[127.0.0.1:45441,DS-f3eee82a-b6bc-4ea5-b9b0-32cf6ab0d1c6,DISK], DatanodeInfoWithStorage[127.0.0.1:33627,DS-6c3ee821-3131-472b-acb5-4fbbc81b5118,DISK], DatanodeInfoWithStorage[127.0.0.1:44174,DS-4d5a8264-813e-47b3-ab1a-565f7002ff72,DISK], DatanodeInfoWithStorage[127.0.0.1:35573,DS-5fb86a04-28da-4051-96c6-4ce31607098b,DISK], DatanodeInfoWithStorage[127.0.0.1:40170,DS-52bba505-8ff4-427b-8281-0216987bdc0d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1715283593-172.17.0.4-1598342919031:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34929,DS-de7a62b3-db6f-4b5d-98f6-a15d9e3943a6,DISK], DatanodeInfoWithStorage[127.0.0.1:46277,DS-30e8197c-0e8d-4876-b984-f5bb78efbe66,DISK], DatanodeInfoWithStorage[127.0.0.1:36822,DS-3ce312f7-e427-4992-acee-185fa6d3e809,DISK], DatanodeInfoWithStorage[127.0.0.1:43234,DS-5e1c6b06-4e71-4798-b235-f74fe4822468,DISK], DatanodeInfoWithStorage[127.0.0.1:43963,DS-5b05e70b-4650-4314-a43e-97b7751e6c34,DISK], DatanodeInfoWithStorage[127.0.0.1:37831,DS-249fb87a-25e8-4614-a66e-d89b5da649b8,DISK], DatanodeInfoWithStorage[127.0.0.1:34420,DS-9d0f41f1-fa65-4408-b7c7-e71b910bb3cd,DISK], DatanodeInfoWithStorage[127.0.0.1:41502,DS-96070dfd-bc30-4780-a99b-cd8a4de618fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1715283593-172.17.0.4-1598342919031:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34929,DS-de7a62b3-db6f-4b5d-98f6-a15d9e3943a6,DISK], DatanodeInfoWithStorage[127.0.0.1:46277,DS-30e8197c-0e8d-4876-b984-f5bb78efbe66,DISK], DatanodeInfoWithStorage[127.0.0.1:36822,DS-3ce312f7-e427-4992-acee-185fa6d3e809,DISK], DatanodeInfoWithStorage[127.0.0.1:43234,DS-5e1c6b06-4e71-4798-b235-f74fe4822468,DISK], DatanodeInfoWithStorage[127.0.0.1:43963,DS-5b05e70b-4650-4314-a43e-97b7751e6c34,DISK], DatanodeInfoWithStorage[127.0.0.1:37831,DS-249fb87a-25e8-4614-a66e-d89b5da649b8,DISK], DatanodeInfoWithStorage[127.0.0.1:34420,DS-9d0f41f1-fa65-4408-b7c7-e71b910bb3cd,DISK], DatanodeInfoWithStorage[127.0.0.1:41502,DS-96070dfd-bc30-4780-a99b-cd8a4de618fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-19413659-172.17.0.4-1598342958112:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43763,DS-bb1c51fb-e1c7-44bd-ae0c-17b768b56c7a,DISK], DatanodeInfoWithStorage[127.0.0.1:44872,DS-1db5bc65-562b-4fe9-a078-c49c41801caa,DISK], DatanodeInfoWithStorage[127.0.0.1:45843,DS-75b7c87a-2142-4ddb-9355-c7fe42d54b9e,DISK], DatanodeInfoWithStorage[127.0.0.1:45114,DS-fc73f5dd-07fe-41b9-8842-814aaa949c32,DISK], DatanodeInfoWithStorage[127.0.0.1:33357,DS-f668a024-9a21-4415-9731-776cdef0f126,DISK], DatanodeInfoWithStorage[127.0.0.1:32811,DS-4d092fee-1086-4eda-9256-52d71b7f8154,DISK], DatanodeInfoWithStorage[127.0.0.1:45732,DS-db6157f4-e93f-4e10-8814-e072382794ab,DISK], DatanodeInfoWithStorage[127.0.0.1:37910,DS-0c2dd725-d2f0-4b12-b323-e28a38829591,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-19413659-172.17.0.4-1598342958112:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43763,DS-bb1c51fb-e1c7-44bd-ae0c-17b768b56c7a,DISK], DatanodeInfoWithStorage[127.0.0.1:44872,DS-1db5bc65-562b-4fe9-a078-c49c41801caa,DISK], DatanodeInfoWithStorage[127.0.0.1:45843,DS-75b7c87a-2142-4ddb-9355-c7fe42d54b9e,DISK], DatanodeInfoWithStorage[127.0.0.1:45114,DS-fc73f5dd-07fe-41b9-8842-814aaa949c32,DISK], DatanodeInfoWithStorage[127.0.0.1:33357,DS-f668a024-9a21-4415-9731-776cdef0f126,DISK], DatanodeInfoWithStorage[127.0.0.1:32811,DS-4d092fee-1086-4eda-9256-52d71b7f8154,DISK], DatanodeInfoWithStorage[127.0.0.1:45732,DS-db6157f4-e93f-4e10-8814-e072382794ab,DISK], DatanodeInfoWithStorage[127.0.0.1:37910,DS-0c2dd725-d2f0-4b12-b323-e28a38829591,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2133458484-172.17.0.4-1598343037585:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43518,DS-bc539355-708f-45d2-937e-3b60298aa3c9,DISK], DatanodeInfoWithStorage[127.0.0.1:44369,DS-b9659a66-ed6e-4580-ae1f-411fa4ff7fdd,DISK], DatanodeInfoWithStorage[127.0.0.1:34973,DS-d4b089c9-6a55-42d7-8206-bddd150d4b0e,DISK], DatanodeInfoWithStorage[127.0.0.1:36607,DS-ce5fcfcb-3d96-48d2-a898-1c0095ea7491,DISK], DatanodeInfoWithStorage[127.0.0.1:34592,DS-e27d102c-432b-4e80-bee9-1c1ebb6eb5b0,DISK], DatanodeInfoWithStorage[127.0.0.1:37662,DS-9471ce2a-8bbc-4cad-b8a5-325cf29a396d,DISK], DatanodeInfoWithStorage[127.0.0.1:43863,DS-91a8a48e-ed81-4f1e-ad95-35866ddbd510,DISK], DatanodeInfoWithStorage[127.0.0.1:36915,DS-5501b0ce-16b6-42b1-bba0-cb2997a0a827,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2133458484-172.17.0.4-1598343037585:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43518,DS-bc539355-708f-45d2-937e-3b60298aa3c9,DISK], DatanodeInfoWithStorage[127.0.0.1:44369,DS-b9659a66-ed6e-4580-ae1f-411fa4ff7fdd,DISK], DatanodeInfoWithStorage[127.0.0.1:34973,DS-d4b089c9-6a55-42d7-8206-bddd150d4b0e,DISK], DatanodeInfoWithStorage[127.0.0.1:36607,DS-ce5fcfcb-3d96-48d2-a898-1c0095ea7491,DISK], DatanodeInfoWithStorage[127.0.0.1:34592,DS-e27d102c-432b-4e80-bee9-1c1ebb6eb5b0,DISK], DatanodeInfoWithStorage[127.0.0.1:37662,DS-9471ce2a-8bbc-4cad-b8a5-325cf29a396d,DISK], DatanodeInfoWithStorage[127.0.0.1:43863,DS-91a8a48e-ed81-4f1e-ad95-35866ddbd510,DISK], DatanodeInfoWithStorage[127.0.0.1:36915,DS-5501b0ce-16b6-42b1-bba0-cb2997a0a827,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1816666686-172.17.0.4-1598343191325:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33091,DS-8e62bebc-f2c6-47f9-a44f-1c6a547fde64,DISK], DatanodeInfoWithStorage[127.0.0.1:38480,DS-291cbce6-5125-435d-b30c-d46a4e55b19e,DISK], DatanodeInfoWithStorage[127.0.0.1:38323,DS-e598d51e-bafc-4202-9e59-51376d672276,DISK], DatanodeInfoWithStorage[127.0.0.1:33876,DS-93bce8e8-6a4b-4cb6-9a90-eed3d8971594,DISK], DatanodeInfoWithStorage[127.0.0.1:43072,DS-cf279ce4-0942-49cc-abf0-d66868cdcbd5,DISK], DatanodeInfoWithStorage[127.0.0.1:39381,DS-5c23ca72-be4c-4a75-bbf5-7e2bff2f8fab,DISK], DatanodeInfoWithStorage[127.0.0.1:43685,DS-418c5418-757a-49f2-b68b-7154d43bf15a,DISK], DatanodeInfoWithStorage[127.0.0.1:40992,DS-85f9a8fa-f2b3-4a41-a8b9-167a3c5b1ca0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1816666686-172.17.0.4-1598343191325:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33091,DS-8e62bebc-f2c6-47f9-a44f-1c6a547fde64,DISK], DatanodeInfoWithStorage[127.0.0.1:38480,DS-291cbce6-5125-435d-b30c-d46a4e55b19e,DISK], DatanodeInfoWithStorage[127.0.0.1:38323,DS-e598d51e-bafc-4202-9e59-51376d672276,DISK], DatanodeInfoWithStorage[127.0.0.1:33876,DS-93bce8e8-6a4b-4cb6-9a90-eed3d8971594,DISK], DatanodeInfoWithStorage[127.0.0.1:43072,DS-cf279ce4-0942-49cc-abf0-d66868cdcbd5,DISK], DatanodeInfoWithStorage[127.0.0.1:39381,DS-5c23ca72-be4c-4a75-bbf5-7e2bff2f8fab,DISK], DatanodeInfoWithStorage[127.0.0.1:43685,DS-418c5418-757a-49f2-b68b-7154d43bf15a,DISK], DatanodeInfoWithStorage[127.0.0.1:40992,DS-85f9a8fa-f2b3-4a41-a8b9-167a3c5b1ca0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-968278455-172.17.0.4-1598343340221:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39525,DS-7289428d-a317-493d-b61a-04dc0657c358,DISK], DatanodeInfoWithStorage[127.0.0.1:39606,DS-11699c63-9e3f-4515-8087-e5502992ea6b,DISK], DatanodeInfoWithStorage[127.0.0.1:33043,DS-c5aeddaa-7c27-4d8e-a059-4808382c881b,DISK], DatanodeInfoWithStorage[127.0.0.1:41044,DS-b1cf1af4-aac3-4e42-9de7-b2b09e9f0f9a,DISK], DatanodeInfoWithStorage[127.0.0.1:40237,DS-7e305daf-8bc5-49f2-ab77-7dc6f8fcc368,DISK], DatanodeInfoWithStorage[127.0.0.1:44948,DS-070bb7d1-b44b-4cad-9851-87ae58600ca5,DISK], DatanodeInfoWithStorage[127.0.0.1:42154,DS-beffe63f-2bf0-4b34-abeb-9dde65f13ecf,DISK], DatanodeInfoWithStorage[127.0.0.1:36197,DS-d8f1c127-81de-4896-8564-416c863cefb2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-968278455-172.17.0.4-1598343340221:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39525,DS-7289428d-a317-493d-b61a-04dc0657c358,DISK], DatanodeInfoWithStorage[127.0.0.1:39606,DS-11699c63-9e3f-4515-8087-e5502992ea6b,DISK], DatanodeInfoWithStorage[127.0.0.1:33043,DS-c5aeddaa-7c27-4d8e-a059-4808382c881b,DISK], DatanodeInfoWithStorage[127.0.0.1:41044,DS-b1cf1af4-aac3-4e42-9de7-b2b09e9f0f9a,DISK], DatanodeInfoWithStorage[127.0.0.1:40237,DS-7e305daf-8bc5-49f2-ab77-7dc6f8fcc368,DISK], DatanodeInfoWithStorage[127.0.0.1:44948,DS-070bb7d1-b44b-4cad-9851-87ae58600ca5,DISK], DatanodeInfoWithStorage[127.0.0.1:42154,DS-beffe63f-2bf0-4b34-abeb-9dde65f13ecf,DISK], DatanodeInfoWithStorage[127.0.0.1:36197,DS-d8f1c127-81de-4896-8564-416c863cefb2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-998065771-172.17.0.4-1598343626062:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36691,DS-f331e1da-148c-4c0d-9681-c64dd30f7369,DISK], DatanodeInfoWithStorage[127.0.0.1:37820,DS-6963377b-e0ec-44d6-ad06-1793e45d4f5c,DISK], DatanodeInfoWithStorage[127.0.0.1:35078,DS-df6d740c-f531-4c97-8e74-c0ee2ee9d9f3,DISK], DatanodeInfoWithStorage[127.0.0.1:35900,DS-702cd0d9-40b6-495d-b9be-28a1a64c8e7d,DISK], DatanodeInfoWithStorage[127.0.0.1:43568,DS-84056e3e-6892-4cff-b272-361a33525dc5,DISK], DatanodeInfoWithStorage[127.0.0.1:45696,DS-3171b469-847b-46c9-9da8-b4dd222c80fd,DISK], DatanodeInfoWithStorage[127.0.0.1:35031,DS-e9cb2614-1a55-4b38-b86d-8003e848701b,DISK], DatanodeInfoWithStorage[127.0.0.1:40263,DS-b32960e7-b2af-4c7e-b970-f983fc2c5b12,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-998065771-172.17.0.4-1598343626062:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36691,DS-f331e1da-148c-4c0d-9681-c64dd30f7369,DISK], DatanodeInfoWithStorage[127.0.0.1:37820,DS-6963377b-e0ec-44d6-ad06-1793e45d4f5c,DISK], DatanodeInfoWithStorage[127.0.0.1:35078,DS-df6d740c-f531-4c97-8e74-c0ee2ee9d9f3,DISK], DatanodeInfoWithStorage[127.0.0.1:35900,DS-702cd0d9-40b6-495d-b9be-28a1a64c8e7d,DISK], DatanodeInfoWithStorage[127.0.0.1:43568,DS-84056e3e-6892-4cff-b272-361a33525dc5,DISK], DatanodeInfoWithStorage[127.0.0.1:45696,DS-3171b469-847b-46c9-9da8-b4dd222c80fd,DISK], DatanodeInfoWithStorage[127.0.0.1:35031,DS-e9cb2614-1a55-4b38-b86d-8003e848701b,DISK], DatanodeInfoWithStorage[127.0.0.1:40263,DS-b32960e7-b2af-4c7e-b970-f983fc2c5b12,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-587339680-172.17.0.4-1598343946584:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34511,DS-16b8f1a6-2ab6-44f6-aee7-22efb19a8647,DISK], DatanodeInfoWithStorage[127.0.0.1:42069,DS-8a2a0449-f6bb-4922-bdb9-2fab2a85e917,DISK], DatanodeInfoWithStorage[127.0.0.1:33134,DS-8ea8e3b9-8ef6-4181-9709-d2062a6298c8,DISK], DatanodeInfoWithStorage[127.0.0.1:37525,DS-73466199-d3db-48d9-8433-81bf88d7c825,DISK], DatanodeInfoWithStorage[127.0.0.1:38850,DS-9b0fbafb-938d-4a8d-8c90-6d8bd0d66cee,DISK], DatanodeInfoWithStorage[127.0.0.1:39502,DS-e93d1686-ed73-452f-b7ca-18eece0491a7,DISK], DatanodeInfoWithStorage[127.0.0.1:45852,DS-bdf3f77d-edee-47f1-861a-41687324d5ff,DISK], DatanodeInfoWithStorage[127.0.0.1:33933,DS-970bd927-b81e-41b5-a35d-ea8b090d5009,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-587339680-172.17.0.4-1598343946584:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34511,DS-16b8f1a6-2ab6-44f6-aee7-22efb19a8647,DISK], DatanodeInfoWithStorage[127.0.0.1:42069,DS-8a2a0449-f6bb-4922-bdb9-2fab2a85e917,DISK], DatanodeInfoWithStorage[127.0.0.1:33134,DS-8ea8e3b9-8ef6-4181-9709-d2062a6298c8,DISK], DatanodeInfoWithStorage[127.0.0.1:37525,DS-73466199-d3db-48d9-8433-81bf88d7c825,DISK], DatanodeInfoWithStorage[127.0.0.1:38850,DS-9b0fbafb-938d-4a8d-8c90-6d8bd0d66cee,DISK], DatanodeInfoWithStorage[127.0.0.1:39502,DS-e93d1686-ed73-452f-b7ca-18eece0491a7,DISK], DatanodeInfoWithStorage[127.0.0.1:45852,DS-bdf3f77d-edee-47f1-861a-41687324d5ff,DISK], DatanodeInfoWithStorage[127.0.0.1:33933,DS-970bd927-b81e-41b5-a35d-ea8b090d5009,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1732714554-172.17.0.4-1598343985161:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36986,DS-c2d75a3e-49ec-474d-b629-bf59ed7035e4,DISK], DatanodeInfoWithStorage[127.0.0.1:36341,DS-012546d5-a79a-4d8c-be8c-eae6ec1dbba2,DISK], DatanodeInfoWithStorage[127.0.0.1:40598,DS-7a48e897-d13e-40f1-bf3f-d997da97eddb,DISK], DatanodeInfoWithStorage[127.0.0.1:41600,DS-48855c53-926e-435b-a4e7-d5abd6d63b47,DISK], DatanodeInfoWithStorage[127.0.0.1:36489,DS-9f9e2ddb-5f62-4d84-9dfd-c74a552c5ab1,DISK], DatanodeInfoWithStorage[127.0.0.1:34303,DS-d836aa98-b1c6-44d5-8c2f-0f988f86511f,DISK], DatanodeInfoWithStorage[127.0.0.1:33503,DS-19bc8b02-3362-46f4-9a6a-36ab52a3c56b,DISK], DatanodeInfoWithStorage[127.0.0.1:45596,DS-e06cc169-8391-4a0b-a839-bbfd173484bb,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1732714554-172.17.0.4-1598343985161:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36986,DS-c2d75a3e-49ec-474d-b629-bf59ed7035e4,DISK], DatanodeInfoWithStorage[127.0.0.1:36341,DS-012546d5-a79a-4d8c-be8c-eae6ec1dbba2,DISK], DatanodeInfoWithStorage[127.0.0.1:40598,DS-7a48e897-d13e-40f1-bf3f-d997da97eddb,DISK], DatanodeInfoWithStorage[127.0.0.1:41600,DS-48855c53-926e-435b-a4e7-d5abd6d63b47,DISK], DatanodeInfoWithStorage[127.0.0.1:36489,DS-9f9e2ddb-5f62-4d84-9dfd-c74a552c5ab1,DISK], DatanodeInfoWithStorage[127.0.0.1:34303,DS-d836aa98-b1c6-44d5-8c2f-0f988f86511f,DISK], DatanodeInfoWithStorage[127.0.0.1:33503,DS-19bc8b02-3362-46f4-9a6a-36ab52a3c56b,DISK], DatanodeInfoWithStorage[127.0.0.1:45596,DS-e06cc169-8391-4a0b-a839-bbfd173484bb,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1501711916-172.17.0.4-1598344064370:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45370,DS-5d36d00b-f2ba-4b67-b4e4-f717d5593766,DISK], DatanodeInfoWithStorage[127.0.0.1:33122,DS-4829b91e-b7c4-44ed-ae1f-b97f57fd7a2a,DISK], DatanodeInfoWithStorage[127.0.0.1:42369,DS-2b5575e4-0d00-44ff-81d5-f1acd8af6680,DISK], DatanodeInfoWithStorage[127.0.0.1:33212,DS-e9cb8acf-d157-4a9b-b325-acc6b0c0e75c,DISK], DatanodeInfoWithStorage[127.0.0.1:36131,DS-0de83ef4-d868-4e93-82ce-ef4ddbc1521e,DISK], DatanodeInfoWithStorage[127.0.0.1:37846,DS-b7bdb54c-1cf4-49b8-9ac8-ddb2f596a269,DISK], DatanodeInfoWithStorage[127.0.0.1:46374,DS-22de7c47-00b2-4d61-b22f-e5e5dbbaa918,DISK], DatanodeInfoWithStorage[127.0.0.1:41873,DS-001fb1c9-424d-491b-b9c7-6262d9970526,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1501711916-172.17.0.4-1598344064370:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45370,DS-5d36d00b-f2ba-4b67-b4e4-f717d5593766,DISK], DatanodeInfoWithStorage[127.0.0.1:33122,DS-4829b91e-b7c4-44ed-ae1f-b97f57fd7a2a,DISK], DatanodeInfoWithStorage[127.0.0.1:42369,DS-2b5575e4-0d00-44ff-81d5-f1acd8af6680,DISK], DatanodeInfoWithStorage[127.0.0.1:33212,DS-e9cb8acf-d157-4a9b-b325-acc6b0c0e75c,DISK], DatanodeInfoWithStorage[127.0.0.1:36131,DS-0de83ef4-d868-4e93-82ce-ef4ddbc1521e,DISK], DatanodeInfoWithStorage[127.0.0.1:37846,DS-b7bdb54c-1cf4-49b8-9ac8-ddb2f596a269,DISK], DatanodeInfoWithStorage[127.0.0.1:46374,DS-22de7c47-00b2-4d61-b22f-e5e5dbbaa918,DISK], DatanodeInfoWithStorage[127.0.0.1:41873,DS-001fb1c9-424d-491b-b9c7-6262d9970526,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-114840482-172.17.0.4-1598344137589:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46517,DS-3bfcca76-47f3-4334-8158-f8dcb43234db,DISK], DatanodeInfoWithStorage[127.0.0.1:41589,DS-35272ecf-a123-40fe-b8af-dd6358c6be79,DISK], DatanodeInfoWithStorage[127.0.0.1:37031,DS-ff221a3c-c2ef-4d53-9d13-9428570a6e15,DISK], DatanodeInfoWithStorage[127.0.0.1:41907,DS-a0788c81-83ed-4f01-98dc-6cf2c112f77c,DISK], DatanodeInfoWithStorage[127.0.0.1:34730,DS-4080ec5a-5e39-4062-b1b3-af8ce7aac3c6,DISK], DatanodeInfoWithStorage[127.0.0.1:45025,DS-d2e5d9da-8687-4338-bfce-2abae70211c7,DISK], DatanodeInfoWithStorage[127.0.0.1:43431,DS-cbd79e4c-c284-429d-8adb-770ba2bf1a15,DISK], DatanodeInfoWithStorage[127.0.0.1:36330,DS-4c622d82-eda9-4885-bfdc-e036b6afe54b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-114840482-172.17.0.4-1598344137589:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46517,DS-3bfcca76-47f3-4334-8158-f8dcb43234db,DISK], DatanodeInfoWithStorage[127.0.0.1:41589,DS-35272ecf-a123-40fe-b8af-dd6358c6be79,DISK], DatanodeInfoWithStorage[127.0.0.1:37031,DS-ff221a3c-c2ef-4d53-9d13-9428570a6e15,DISK], DatanodeInfoWithStorage[127.0.0.1:41907,DS-a0788c81-83ed-4f01-98dc-6cf2c112f77c,DISK], DatanodeInfoWithStorage[127.0.0.1:34730,DS-4080ec5a-5e39-4062-b1b3-af8ce7aac3c6,DISK], DatanodeInfoWithStorage[127.0.0.1:45025,DS-d2e5d9da-8687-4338-bfce-2abae70211c7,DISK], DatanodeInfoWithStorage[127.0.0.1:43431,DS-cbd79e4c-c284-429d-8adb-770ba2bf1a15,DISK], DatanodeInfoWithStorage[127.0.0.1:36330,DS-4c622d82-eda9-4885-bfdc-e036b6afe54b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-117619210-172.17.0.4-1598344330126:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45393,DS-7a53c2c8-a572-49ef-9a85-b590a4a88e76,DISK], DatanodeInfoWithStorage[127.0.0.1:44276,DS-22f10092-d1df-4005-80de-d3253e45f397,DISK], DatanodeInfoWithStorage[127.0.0.1:38300,DS-1518d591-c4fd-4f60-8fc8-0cde049f4aed,DISK], DatanodeInfoWithStorage[127.0.0.1:41633,DS-4b799fc6-d357-47b0-98b1-27d57e5b65d6,DISK], DatanodeInfoWithStorage[127.0.0.1:41356,DS-0adaf419-c81f-4aa4-abcd-8e9b3254abd6,DISK], DatanodeInfoWithStorage[127.0.0.1:38152,DS-e1d85957-3fec-4517-b2d2-311f4f012e3f,DISK], DatanodeInfoWithStorage[127.0.0.1:42447,DS-b137d08f-2f25-4102-8043-a54e876d52db,DISK], DatanodeInfoWithStorage[127.0.0.1:34045,DS-c0f8bfd6-d650-4f38-9299-c15ad10ddb82,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-117619210-172.17.0.4-1598344330126:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45393,DS-7a53c2c8-a572-49ef-9a85-b590a4a88e76,DISK], DatanodeInfoWithStorage[127.0.0.1:44276,DS-22f10092-d1df-4005-80de-d3253e45f397,DISK], DatanodeInfoWithStorage[127.0.0.1:38300,DS-1518d591-c4fd-4f60-8fc8-0cde049f4aed,DISK], DatanodeInfoWithStorage[127.0.0.1:41633,DS-4b799fc6-d357-47b0-98b1-27d57e5b65d6,DISK], DatanodeInfoWithStorage[127.0.0.1:41356,DS-0adaf419-c81f-4aa4-abcd-8e9b3254abd6,DISK], DatanodeInfoWithStorage[127.0.0.1:38152,DS-e1d85957-3fec-4517-b2d2-311f4f012e3f,DISK], DatanodeInfoWithStorage[127.0.0.1:42447,DS-b137d08f-2f25-4102-8043-a54e876d52db,DISK], DatanodeInfoWithStorage[127.0.0.1:34045,DS-c0f8bfd6-d650-4f38-9299-c15ad10ddb82,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-304589521-172.17.0.4-1598344365747:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34060,DS-9bc79925-c594-4dbf-88b1-0d4e642cc4dc,DISK], DatanodeInfoWithStorage[127.0.0.1:36684,DS-8d209d95-1114-4b78-9642-02c3d59250c0,DISK], DatanodeInfoWithStorage[127.0.0.1:45818,DS-4b8d2213-ec8f-4dd7-bb51-4849243c60b1,DISK], DatanodeInfoWithStorage[127.0.0.1:35041,DS-21fe3684-75de-4bb8-9f03-7cd4dcb76cfc,DISK], DatanodeInfoWithStorage[127.0.0.1:41075,DS-37d991b3-351b-47d6-9594-1407a5099df9,DISK], DatanodeInfoWithStorage[127.0.0.1:35176,DS-63b7d7a7-bf10-49e9-8b6c-80901e070f36,DISK], DatanodeInfoWithStorage[127.0.0.1:39515,DS-ff178169-16bf-4157-b8ea-e430d68aa2a3,DISK], DatanodeInfoWithStorage[127.0.0.1:46348,DS-dd8fadcc-afdc-46a7-8181-4e6495579703,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-304589521-172.17.0.4-1598344365747:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34060,DS-9bc79925-c594-4dbf-88b1-0d4e642cc4dc,DISK], DatanodeInfoWithStorage[127.0.0.1:36684,DS-8d209d95-1114-4b78-9642-02c3d59250c0,DISK], DatanodeInfoWithStorage[127.0.0.1:45818,DS-4b8d2213-ec8f-4dd7-bb51-4849243c60b1,DISK], DatanodeInfoWithStorage[127.0.0.1:35041,DS-21fe3684-75de-4bb8-9f03-7cd4dcb76cfc,DISK], DatanodeInfoWithStorage[127.0.0.1:41075,DS-37d991b3-351b-47d6-9594-1407a5099df9,DISK], DatanodeInfoWithStorage[127.0.0.1:35176,DS-63b7d7a7-bf10-49e9-8b6c-80901e070f36,DISK], DatanodeInfoWithStorage[127.0.0.1:39515,DS-ff178169-16bf-4157-b8ea-e430d68aa2a3,DISK], DatanodeInfoWithStorage[127.0.0.1:46348,DS-dd8fadcc-afdc-46a7-8181-4e6495579703,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1346268337-172.17.0.4-1598344450407:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44711,DS-5920a210-71ea-4225-a2cd-0b532ccd25aa,DISK], DatanodeInfoWithStorage[127.0.0.1:38672,DS-337dcf89-de78-4364-8798-10c20dfce1ad,DISK], DatanodeInfoWithStorage[127.0.0.1:35084,DS-5b188946-3d10-41a6-a67f-868a98adfd89,DISK], DatanodeInfoWithStorage[127.0.0.1:42298,DS-8c15d077-4b86-4e2e-9b18-3fa7b19df317,DISK], DatanodeInfoWithStorage[127.0.0.1:35847,DS-22f0adfb-85c4-481b-9bfc-4d47eea23324,DISK], DatanodeInfoWithStorage[127.0.0.1:46753,DS-5dff54df-6b02-4dcf-ba53-d119e4778c69,DISK], DatanodeInfoWithStorage[127.0.0.1:40109,DS-2a63a8be-5ed3-47e0-b26c-628992782aae,DISK], DatanodeInfoWithStorage[127.0.0.1:33398,DS-1f84874b-fffa-48fb-bc3a-13c5840796dc,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1346268337-172.17.0.4-1598344450407:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44711,DS-5920a210-71ea-4225-a2cd-0b532ccd25aa,DISK], DatanodeInfoWithStorage[127.0.0.1:38672,DS-337dcf89-de78-4364-8798-10c20dfce1ad,DISK], DatanodeInfoWithStorage[127.0.0.1:35084,DS-5b188946-3d10-41a6-a67f-868a98adfd89,DISK], DatanodeInfoWithStorage[127.0.0.1:42298,DS-8c15d077-4b86-4e2e-9b18-3fa7b19df317,DISK], DatanodeInfoWithStorage[127.0.0.1:35847,DS-22f0adfb-85c4-481b-9bfc-4d47eea23324,DISK], DatanodeInfoWithStorage[127.0.0.1:46753,DS-5dff54df-6b02-4dcf-ba53-d119e4778c69,DISK], DatanodeInfoWithStorage[127.0.0.1:40109,DS-2a63a8be-5ed3-47e0-b26c-628992782aae,DISK], DatanodeInfoWithStorage[127.0.0.1:33398,DS-1f84874b-fffa-48fb-bc3a-13c5840796dc,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1727739452-172.17.0.4-1598344589541:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32780,DS-f71b0d51-9afc-4eae-89dd-980213ccefe2,DISK], DatanodeInfoWithStorage[127.0.0.1:33707,DS-6d39cea5-4b9a-4baf-846b-534da54e6f42,DISK], DatanodeInfoWithStorage[127.0.0.1:40481,DS-900602ce-2dcd-422c-81f4-b49b15797ff0,DISK], DatanodeInfoWithStorage[127.0.0.1:40770,DS-b28117ef-e685-46c0-a810-f41e6cf36651,DISK], DatanodeInfoWithStorage[127.0.0.1:40432,DS-b0ab22b1-aa3d-4f74-a812-37c08a2fbdd4,DISK], DatanodeInfoWithStorage[127.0.0.1:37368,DS-6ea0d284-9129-4453-91b3-9dd826ae3b49,DISK], DatanodeInfoWithStorage[127.0.0.1:46090,DS-4ec6e9f8-5d52-4e63-886a-d167d9efd39b,DISK], DatanodeInfoWithStorage[127.0.0.1:40209,DS-0d3abdab-48e7-4f3d-9790-a355724323e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1727739452-172.17.0.4-1598344589541:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32780,DS-f71b0d51-9afc-4eae-89dd-980213ccefe2,DISK], DatanodeInfoWithStorage[127.0.0.1:33707,DS-6d39cea5-4b9a-4baf-846b-534da54e6f42,DISK], DatanodeInfoWithStorage[127.0.0.1:40481,DS-900602ce-2dcd-422c-81f4-b49b15797ff0,DISK], DatanodeInfoWithStorage[127.0.0.1:40770,DS-b28117ef-e685-46c0-a810-f41e6cf36651,DISK], DatanodeInfoWithStorage[127.0.0.1:40432,DS-b0ab22b1-aa3d-4f74-a812-37c08a2fbdd4,DISK], DatanodeInfoWithStorage[127.0.0.1:37368,DS-6ea0d284-9129-4453-91b3-9dd826ae3b49,DISK], DatanodeInfoWithStorage[127.0.0.1:46090,DS-4ec6e9f8-5d52-4e63-886a-d167d9efd39b,DISK], DatanodeInfoWithStorage[127.0.0.1:40209,DS-0d3abdab-48e7-4f3d-9790-a355724323e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-614715634-172.17.0.4-1598344619683:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39266,DS-0d61bf27-e93b-4787-a137-89f1ca270b5f,DISK], DatanodeInfoWithStorage[127.0.0.1:37005,DS-928a4a75-0d3d-4ac9-8dcf-8f67693a5da7,DISK], DatanodeInfoWithStorage[127.0.0.1:36658,DS-dcead54b-3bc8-4207-970f-547c2e144039,DISK], DatanodeInfoWithStorage[127.0.0.1:38075,DS-74002f36-b120-4242-9e17-bb5ebc113104,DISK], DatanodeInfoWithStorage[127.0.0.1:40434,DS-b4ea03eb-1ae6-4713-8428-18c90df07427,DISK], DatanodeInfoWithStorage[127.0.0.1:32777,DS-0f914f8b-f00e-49f7-bee5-bc9b45bb9819,DISK], DatanodeInfoWithStorage[127.0.0.1:32955,DS-50cb2060-d82c-4437-a2dd-0b637fb8ed57,DISK], DatanodeInfoWithStorage[127.0.0.1:36506,DS-0a01de38-f34d-4a66-af38-05ea92ddcded,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-614715634-172.17.0.4-1598344619683:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39266,DS-0d61bf27-e93b-4787-a137-89f1ca270b5f,DISK], DatanodeInfoWithStorage[127.0.0.1:37005,DS-928a4a75-0d3d-4ac9-8dcf-8f67693a5da7,DISK], DatanodeInfoWithStorage[127.0.0.1:36658,DS-dcead54b-3bc8-4207-970f-547c2e144039,DISK], DatanodeInfoWithStorage[127.0.0.1:38075,DS-74002f36-b120-4242-9e17-bb5ebc113104,DISK], DatanodeInfoWithStorage[127.0.0.1:40434,DS-b4ea03eb-1ae6-4713-8428-18c90df07427,DISK], DatanodeInfoWithStorage[127.0.0.1:32777,DS-0f914f8b-f00e-49f7-bee5-bc9b45bb9819,DISK], DatanodeInfoWithStorage[127.0.0.1:32955,DS-50cb2060-d82c-4437-a2dd-0b637fb8ed57,DISK], DatanodeInfoWithStorage[127.0.0.1:36506,DS-0a01de38-f34d-4a66-af38-05ea92ddcded,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-36290674-172.17.0.4-1598344769121:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46400,DS-11ddd340-6c30-40e9-a28e-fca265dc540c,DISK], DatanodeInfoWithStorage[127.0.0.1:43813,DS-c27bbc16-45ea-4587-9408-188cb205c175,DISK], DatanodeInfoWithStorage[127.0.0.1:46797,DS-bbf4a5d4-1321-45b0-b1ed-a202c47ac894,DISK], DatanodeInfoWithStorage[127.0.0.1:34453,DS-4192dd36-7b8c-42a2-aacb-a31f23929a86,DISK], DatanodeInfoWithStorage[127.0.0.1:32886,DS-a5c29546-3314-426f-a79e-1130753889eb,DISK], DatanodeInfoWithStorage[127.0.0.1:39564,DS-a44456ca-c903-4183-bf87-cd369fd3558a,DISK], DatanodeInfoWithStorage[127.0.0.1:35912,DS-b203a957-d6ce-411c-8dfd-e131d844dbfc,DISK], DatanodeInfoWithStorage[127.0.0.1:45235,DS-508af07a-3362-48a1-bf80-dd932c9c2740,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-36290674-172.17.0.4-1598344769121:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46400,DS-11ddd340-6c30-40e9-a28e-fca265dc540c,DISK], DatanodeInfoWithStorage[127.0.0.1:43813,DS-c27bbc16-45ea-4587-9408-188cb205c175,DISK], DatanodeInfoWithStorage[127.0.0.1:46797,DS-bbf4a5d4-1321-45b0-b1ed-a202c47ac894,DISK], DatanodeInfoWithStorage[127.0.0.1:34453,DS-4192dd36-7b8c-42a2-aacb-a31f23929a86,DISK], DatanodeInfoWithStorage[127.0.0.1:32886,DS-a5c29546-3314-426f-a79e-1130753889eb,DISK], DatanodeInfoWithStorage[127.0.0.1:39564,DS-a44456ca-c903-4183-bf87-cd369fd3558a,DISK], DatanodeInfoWithStorage[127.0.0.1:35912,DS-b203a957-d6ce-411c-8dfd-e131d844dbfc,DISK], DatanodeInfoWithStorage[127.0.0.1:45235,DS-508af07a-3362-48a1-bf80-dd932c9c2740,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-546437056-172.17.0.4-1598345077820:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34942,DS-e66dd8ce-66cb-487d-bd29-8172f1af8496,DISK], DatanodeInfoWithStorage[127.0.0.1:40372,DS-20de87f2-c82b-437f-8072-58cb5ce08d2f,DISK], DatanodeInfoWithStorage[127.0.0.1:41479,DS-a4053757-a683-451a-b81c-c7b3d131b1bf,DISK], DatanodeInfoWithStorage[127.0.0.1:34307,DS-4b3001db-1d7c-4fbb-b9c1-d04fef0b6755,DISK], DatanodeInfoWithStorage[127.0.0.1:44640,DS-3220fb0e-aaee-4453-b29b-bd5acc02fc9e,DISK], DatanodeInfoWithStorage[127.0.0.1:40343,DS-231f6cca-14ba-4bd4-98ed-a4c3b82c0521,DISK], DatanodeInfoWithStorage[127.0.0.1:36041,DS-7c512f16-3b19-440c-aaa9-636d94ef1d1e,DISK], DatanodeInfoWithStorage[127.0.0.1:43916,DS-4f1841eb-21d5-437b-95f2-40239eba8d84,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-546437056-172.17.0.4-1598345077820:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34942,DS-e66dd8ce-66cb-487d-bd29-8172f1af8496,DISK], DatanodeInfoWithStorage[127.0.0.1:40372,DS-20de87f2-c82b-437f-8072-58cb5ce08d2f,DISK], DatanodeInfoWithStorage[127.0.0.1:41479,DS-a4053757-a683-451a-b81c-c7b3d131b1bf,DISK], DatanodeInfoWithStorage[127.0.0.1:34307,DS-4b3001db-1d7c-4fbb-b9c1-d04fef0b6755,DISK], DatanodeInfoWithStorage[127.0.0.1:44640,DS-3220fb0e-aaee-4453-b29b-bd5acc02fc9e,DISK], DatanodeInfoWithStorage[127.0.0.1:40343,DS-231f6cca-14ba-4bd4-98ed-a4c3b82c0521,DISK], DatanodeInfoWithStorage[127.0.0.1:36041,DS-7c512f16-3b19-440c-aaa9-636d94ef1d1e,DISK], DatanodeInfoWithStorage[127.0.0.1:43916,DS-4f1841eb-21d5-437b-95f2-40239eba8d84,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2012147289-172.17.0.4-1598345178177:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46411,DS-ec205436-5056-46f7-a540-07229e6ecfb2,DISK], DatanodeInfoWithStorage[127.0.0.1:33438,DS-319c2afe-8aef-4bd6-a34b-5d565ece520e,DISK], DatanodeInfoWithStorage[127.0.0.1:40508,DS-c050ae36-3192-43f0-ace1-08d37d403907,DISK], DatanodeInfoWithStorage[127.0.0.1:40535,DS-0a701245-ff08-452a-8282-769935e79dfd,DISK], DatanodeInfoWithStorage[127.0.0.1:40562,DS-611e90ee-63dc-4148-a866-8aa3afe1f84e,DISK], DatanodeInfoWithStorage[127.0.0.1:35844,DS-5926609b-be76-41e8-920a-27711fed42b2,DISK], DatanodeInfoWithStorage[127.0.0.1:38551,DS-adab9446-e0ad-4bbd-94b2-18bc741aa34d,DISK], DatanodeInfoWithStorage[127.0.0.1:37505,DS-1ab99e42-d9b4-4e10-962c-a7ec4bef7ed9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2012147289-172.17.0.4-1598345178177:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46411,DS-ec205436-5056-46f7-a540-07229e6ecfb2,DISK], DatanodeInfoWithStorage[127.0.0.1:33438,DS-319c2afe-8aef-4bd6-a34b-5d565ece520e,DISK], DatanodeInfoWithStorage[127.0.0.1:40508,DS-c050ae36-3192-43f0-ace1-08d37d403907,DISK], DatanodeInfoWithStorage[127.0.0.1:40535,DS-0a701245-ff08-452a-8282-769935e79dfd,DISK], DatanodeInfoWithStorage[127.0.0.1:40562,DS-611e90ee-63dc-4148-a866-8aa3afe1f84e,DISK], DatanodeInfoWithStorage[127.0.0.1:35844,DS-5926609b-be76-41e8-920a-27711fed42b2,DISK], DatanodeInfoWithStorage[127.0.0.1:38551,DS-adab9446-e0ad-4bbd-94b2-18bc741aa34d,DISK], DatanodeInfoWithStorage[127.0.0.1:37505,DS-1ab99e42-d9b4-4e10-962c-a7ec4bef7ed9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-483536587-172.17.0.4-1598345286950:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43669,DS-19453d50-31de-473e-9341-2eda3ab232ea,DISK], DatanodeInfoWithStorage[127.0.0.1:43357,DS-ba6a8c19-83fc-4d5a-9e0c-7ca5372fdbc5,DISK], DatanodeInfoWithStorage[127.0.0.1:35986,DS-c00954d2-e4df-466d-aa88-efca9871a6fa,DISK], DatanodeInfoWithStorage[127.0.0.1:36276,DS-30556d44-2dd6-441a-84ed-c5b648a16985,DISK], DatanodeInfoWithStorage[127.0.0.1:33964,DS-8eea7dab-bbbf-4a15-9294-915d998d94cc,DISK], DatanodeInfoWithStorage[127.0.0.1:44577,DS-6c816891-3530-401a-8926-7cee0caf1824,DISK], DatanodeInfoWithStorage[127.0.0.1:39533,DS-18637336-7883-49da-a69b-c7a19f9d108c,DISK], DatanodeInfoWithStorage[127.0.0.1:36576,DS-c7dd5ce1-f27d-4e02-8f5e-8b409df59aa0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-483536587-172.17.0.4-1598345286950:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43669,DS-19453d50-31de-473e-9341-2eda3ab232ea,DISK], DatanodeInfoWithStorage[127.0.0.1:43357,DS-ba6a8c19-83fc-4d5a-9e0c-7ca5372fdbc5,DISK], DatanodeInfoWithStorage[127.0.0.1:35986,DS-c00954d2-e4df-466d-aa88-efca9871a6fa,DISK], DatanodeInfoWithStorage[127.0.0.1:36276,DS-30556d44-2dd6-441a-84ed-c5b648a16985,DISK], DatanodeInfoWithStorage[127.0.0.1:33964,DS-8eea7dab-bbbf-4a15-9294-915d998d94cc,DISK], DatanodeInfoWithStorage[127.0.0.1:44577,DS-6c816891-3530-401a-8926-7cee0caf1824,DISK], DatanodeInfoWithStorage[127.0.0.1:39533,DS-18637336-7883-49da-a69b-c7a19f9d108c,DISK], DatanodeInfoWithStorage[127.0.0.1:36576,DS-c7dd5ce1-f27d-4e02-8f5e-8b409df59aa0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-549553094-172.17.0.4-1598345838492:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39699,DS-efd9293d-7ef4-4de4-9d14-7dde6429ace2,DISK], DatanodeInfoWithStorage[127.0.0.1:43954,DS-559b1334-57fd-4caa-aacf-2f6dc35dffca,DISK], DatanodeInfoWithStorage[127.0.0.1:41565,DS-a8d6b2fe-b6f6-48b4-9047-83d174aab00c,DISK], DatanodeInfoWithStorage[127.0.0.1:45469,DS-6c8b6532-faad-4e41-bdbb-8a678cfef405,DISK], DatanodeInfoWithStorage[127.0.0.1:34161,DS-91ba1ff3-2698-4ba2-8a0e-977327ea36a9,DISK], DatanodeInfoWithStorage[127.0.0.1:46527,DS-05cad849-9f68-479f-813d-2cf5771338e9,DISK], DatanodeInfoWithStorage[127.0.0.1:43484,DS-9e9ab9ca-fc69-40d3-84a4-5e0862ab3092,DISK], DatanodeInfoWithStorage[127.0.0.1:34202,DS-8edc3400-22c6-4376-b388-f2ccf7d448a0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-549553094-172.17.0.4-1598345838492:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39699,DS-efd9293d-7ef4-4de4-9d14-7dde6429ace2,DISK], DatanodeInfoWithStorage[127.0.0.1:43954,DS-559b1334-57fd-4caa-aacf-2f6dc35dffca,DISK], DatanodeInfoWithStorage[127.0.0.1:41565,DS-a8d6b2fe-b6f6-48b4-9047-83d174aab00c,DISK], DatanodeInfoWithStorage[127.0.0.1:45469,DS-6c8b6532-faad-4e41-bdbb-8a678cfef405,DISK], DatanodeInfoWithStorage[127.0.0.1:34161,DS-91ba1ff3-2698-4ba2-8a0e-977327ea36a9,DISK], DatanodeInfoWithStorage[127.0.0.1:46527,DS-05cad849-9f68-479f-813d-2cf5771338e9,DISK], DatanodeInfoWithStorage[127.0.0.1:43484,DS-9e9ab9ca-fc69-40d3-84a4-5e0862ab3092,DISK], DatanodeInfoWithStorage[127.0.0.1:34202,DS-8edc3400-22c6-4376-b388-f2ccf7d448a0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2012448683-172.17.0.4-1598345881472:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46578,DS-7b646c38-da5a-452c-9f86-5800930d7287,DISK], DatanodeInfoWithStorage[127.0.0.1:41743,DS-d72c8f49-13cf-41a8-8652-b6d90b956c14,DISK], DatanodeInfoWithStorage[127.0.0.1:44568,DS-baf4e0b9-c810-4d76-b9a3-5a19dde954f6,DISK], DatanodeInfoWithStorage[127.0.0.1:37666,DS-4ea6bdc8-36c3-434f-b12a-ea37b3be7252,DISK], DatanodeInfoWithStorage[127.0.0.1:34848,DS-7c43ac49-24e3-443f-901f-ddb7aa6c6862,DISK], DatanodeInfoWithStorage[127.0.0.1:41581,DS-d647b452-b4eb-4429-9ce7-b1af0c37fe6e,DISK], DatanodeInfoWithStorage[127.0.0.1:44093,DS-74edd021-ceb8-485b-9d18-fab2a3ef54a4,DISK], DatanodeInfoWithStorage[127.0.0.1:45532,DS-02fa2c63-1783-408a-9731-ba84f6939f6e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2012448683-172.17.0.4-1598345881472:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46578,DS-7b646c38-da5a-452c-9f86-5800930d7287,DISK], DatanodeInfoWithStorage[127.0.0.1:41743,DS-d72c8f49-13cf-41a8-8652-b6d90b956c14,DISK], DatanodeInfoWithStorage[127.0.0.1:44568,DS-baf4e0b9-c810-4d76-b9a3-5a19dde954f6,DISK], DatanodeInfoWithStorage[127.0.0.1:37666,DS-4ea6bdc8-36c3-434f-b12a-ea37b3be7252,DISK], DatanodeInfoWithStorage[127.0.0.1:34848,DS-7c43ac49-24e3-443f-901f-ddb7aa6c6862,DISK], DatanodeInfoWithStorage[127.0.0.1:41581,DS-d647b452-b4eb-4429-9ce7-b1af0c37fe6e,DISK], DatanodeInfoWithStorage[127.0.0.1:44093,DS-74edd021-ceb8-485b-9d18-fab2a3ef54a4,DISK], DatanodeInfoWithStorage[127.0.0.1:45532,DS-02fa2c63-1783-408a-9731-ba84f6939f6e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-982379848-172.17.0.4-1598345915313:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36417,DS-fb130f64-2544-4dc9-ac3c-29ed181b3f07,DISK], DatanodeInfoWithStorage[127.0.0.1:46878,DS-df4e73f1-3ba6-42b5-b001-a44b42e3cf2c,DISK], DatanodeInfoWithStorage[127.0.0.1:36802,DS-00a80b38-c7a2-4427-a19d-6151ea7b1756,DISK], DatanodeInfoWithStorage[127.0.0.1:37274,DS-a4c5d89f-30c7-482b-b920-81a53c2eedf7,DISK], DatanodeInfoWithStorage[127.0.0.1:44567,DS-d87d6d0e-c891-4097-a3d6-e3032b00d12d,DISK], DatanodeInfoWithStorage[127.0.0.1:34870,DS-493ed60e-824f-454b-9a64-ec6efa7d245a,DISK], DatanodeInfoWithStorage[127.0.0.1:34783,DS-9ed9c010-fb5d-43ad-91cd-887bf42df561,DISK], DatanodeInfoWithStorage[127.0.0.1:33423,DS-fb667d10-052e-4f7e-962a-0ea1984d1490,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-982379848-172.17.0.4-1598345915313:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36417,DS-fb130f64-2544-4dc9-ac3c-29ed181b3f07,DISK], DatanodeInfoWithStorage[127.0.0.1:46878,DS-df4e73f1-3ba6-42b5-b001-a44b42e3cf2c,DISK], DatanodeInfoWithStorage[127.0.0.1:36802,DS-00a80b38-c7a2-4427-a19d-6151ea7b1756,DISK], DatanodeInfoWithStorage[127.0.0.1:37274,DS-a4c5d89f-30c7-482b-b920-81a53c2eedf7,DISK], DatanodeInfoWithStorage[127.0.0.1:44567,DS-d87d6d0e-c891-4097-a3d6-e3032b00d12d,DISK], DatanodeInfoWithStorage[127.0.0.1:34870,DS-493ed60e-824f-454b-9a64-ec6efa7d245a,DISK], DatanodeInfoWithStorage[127.0.0.1:34783,DS-9ed9c010-fb5d-43ad-91cd-887bf42df561,DISK], DatanodeInfoWithStorage[127.0.0.1:33423,DS-fb667d10-052e-4f7e-962a-0ea1984d1490,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2024169241-172.17.0.4-1598345974535:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40435,DS-d288dac1-bf79-4233-98d2-7660ebaf2657,DISK], DatanodeInfoWithStorage[127.0.0.1:34056,DS-eb93dbaa-d22d-40ea-8f21-b3dafd9dcbe4,DISK], DatanodeInfoWithStorage[127.0.0.1:41417,DS-50d484ab-4af6-45fd-b196-89d0d4f9c4eb,DISK], DatanodeInfoWithStorage[127.0.0.1:32974,DS-fbf82699-1281-4f07-a480-acd110a8e7fb,DISK], DatanodeInfoWithStorage[127.0.0.1:34681,DS-44e5717b-ef27-49e0-95b2-79540c5e87ab,DISK], DatanodeInfoWithStorage[127.0.0.1:46619,DS-ec1b02b0-cfbb-44e3-9705-d6546960432d,DISK], DatanodeInfoWithStorage[127.0.0.1:43726,DS-d413e3e5-2d49-4e61-bdd3-79f00d1b6fcb,DISK], DatanodeInfoWithStorage[127.0.0.1:36853,DS-bfee983f-f8bc-4f81-922d-ebefeff6ec01,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2024169241-172.17.0.4-1598345974535:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40435,DS-d288dac1-bf79-4233-98d2-7660ebaf2657,DISK], DatanodeInfoWithStorage[127.0.0.1:34056,DS-eb93dbaa-d22d-40ea-8f21-b3dafd9dcbe4,DISK], DatanodeInfoWithStorage[127.0.0.1:41417,DS-50d484ab-4af6-45fd-b196-89d0d4f9c4eb,DISK], DatanodeInfoWithStorage[127.0.0.1:32974,DS-fbf82699-1281-4f07-a480-acd110a8e7fb,DISK], DatanodeInfoWithStorage[127.0.0.1:34681,DS-44e5717b-ef27-49e0-95b2-79540c5e87ab,DISK], DatanodeInfoWithStorage[127.0.0.1:46619,DS-ec1b02b0-cfbb-44e3-9705-d6546960432d,DISK], DatanodeInfoWithStorage[127.0.0.1:43726,DS-d413e3e5-2d49-4e61-bdd3-79f00d1b6fcb,DISK], DatanodeInfoWithStorage[127.0.0.1:36853,DS-bfee983f-f8bc-4f81-922d-ebefeff6ec01,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1829218499-172.17.0.4-1598346144854:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43323,DS-0f5f195b-4377-4a36-9b29-a446eeef0272,DISK], DatanodeInfoWithStorage[127.0.0.1:42487,DS-a5483b7b-92b2-4c8f-8242-67175158d576,DISK], DatanodeInfoWithStorage[127.0.0.1:46352,DS-b95d6dfd-987b-4921-9e8b-bb68433c69d4,DISK], DatanodeInfoWithStorage[127.0.0.1:39716,DS-ecf4ff40-4411-4257-bb2d-4108612f1d37,DISK], DatanodeInfoWithStorage[127.0.0.1:33325,DS-f7b69222-1d80-497f-a44c-8c69355a1d1c,DISK], DatanodeInfoWithStorage[127.0.0.1:40350,DS-f3ff1f5c-1b7c-41dc-a632-6730be378a85,DISK], DatanodeInfoWithStorage[127.0.0.1:43849,DS-f7fb2d7e-2bf3-41ea-bb89-c9a2c9a4b44c,DISK], DatanodeInfoWithStorage[127.0.0.1:46348,DS-cad09c88-2f72-448e-83ac-41d45b270ed8,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1829218499-172.17.0.4-1598346144854:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43323,DS-0f5f195b-4377-4a36-9b29-a446eeef0272,DISK], DatanodeInfoWithStorage[127.0.0.1:42487,DS-a5483b7b-92b2-4c8f-8242-67175158d576,DISK], DatanodeInfoWithStorage[127.0.0.1:46352,DS-b95d6dfd-987b-4921-9e8b-bb68433c69d4,DISK], DatanodeInfoWithStorage[127.0.0.1:39716,DS-ecf4ff40-4411-4257-bb2d-4108612f1d37,DISK], DatanodeInfoWithStorage[127.0.0.1:33325,DS-f7b69222-1d80-497f-a44c-8c69355a1d1c,DISK], DatanodeInfoWithStorage[127.0.0.1:40350,DS-f3ff1f5c-1b7c-41dc-a632-6730be378a85,DISK], DatanodeInfoWithStorage[127.0.0.1:43849,DS-f7fb2d7e-2bf3-41ea-bb89-c9a2c9a4b44c,DISK], DatanodeInfoWithStorage[127.0.0.1:46348,DS-cad09c88-2f72-448e-83ac-41d45b270ed8,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-483828925-172.17.0.4-1598346219834:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34746,DS-00b16e67-ec44-4ad9-820f-6f799274496e,DISK], DatanodeInfoWithStorage[127.0.0.1:33082,DS-8e89258f-1333-440b-af29-81e65ecc371b,DISK], DatanodeInfoWithStorage[127.0.0.1:42881,DS-76b96785-c582-44d2-bd99-1d07bc67a655,DISK], DatanodeInfoWithStorage[127.0.0.1:43886,DS-ab9931d9-9cf9-4931-98f7-71a812a87f1e,DISK], DatanodeInfoWithStorage[127.0.0.1:45200,DS-1eb08fdc-e7f5-48d8-9d93-2443d3cc2ccf,DISK], DatanodeInfoWithStorage[127.0.0.1:36670,DS-8ede3453-dbae-42b1-9e34-cb53b0886246,DISK], DatanodeInfoWithStorage[127.0.0.1:45580,DS-f359aa30-e0ea-481a-940f-4758fc7c8d7b,DISK], DatanodeInfoWithStorage[127.0.0.1:39986,DS-810681b7-f125-4326-8bbf-831b38c6b457,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-483828925-172.17.0.4-1598346219834:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34746,DS-00b16e67-ec44-4ad9-820f-6f799274496e,DISK], DatanodeInfoWithStorage[127.0.0.1:33082,DS-8e89258f-1333-440b-af29-81e65ecc371b,DISK], DatanodeInfoWithStorage[127.0.0.1:42881,DS-76b96785-c582-44d2-bd99-1d07bc67a655,DISK], DatanodeInfoWithStorage[127.0.0.1:43886,DS-ab9931d9-9cf9-4931-98f7-71a812a87f1e,DISK], DatanodeInfoWithStorage[127.0.0.1:45200,DS-1eb08fdc-e7f5-48d8-9d93-2443d3cc2ccf,DISK], DatanodeInfoWithStorage[127.0.0.1:36670,DS-8ede3453-dbae-42b1-9e34-cb53b0886246,DISK], DatanodeInfoWithStorage[127.0.0.1:45580,DS-f359aa30-e0ea-481a-940f-4758fc7c8d7b,DISK], DatanodeInfoWithStorage[127.0.0.1:39986,DS-810681b7-f125-4326-8bbf-831b38c6b457,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-89322865-172.17.0.4-1598346652387:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41917,DS-3759bb85-9a44-4328-8229-cd799802400b,DISK], DatanodeInfoWithStorage[127.0.0.1:38303,DS-a15f5370-c41b-45ad-a621-90bf41ad8c32,DISK], DatanodeInfoWithStorage[127.0.0.1:34769,DS-82e32e83-de73-4303-8f7d-f9023b5e7824,DISK], DatanodeInfoWithStorage[127.0.0.1:40460,DS-64968273-829a-4309-a712-fb870ed47635,DISK], DatanodeInfoWithStorage[127.0.0.1:32872,DS-1febd8bc-d4c4-4afb-80ce-2db12cb8b644,DISK], DatanodeInfoWithStorage[127.0.0.1:37249,DS-027133d1-6c9f-45c5-9eb7-c7c1daddea31,DISK], DatanodeInfoWithStorage[127.0.0.1:36729,DS-ebd6581f-f668-4ca2-8f35-9604b201550d,DISK], DatanodeInfoWithStorage[127.0.0.1:42808,DS-a3e49f18-3a69-46c5-8147-27ff1049788d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-89322865-172.17.0.4-1598346652387:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41917,DS-3759bb85-9a44-4328-8229-cd799802400b,DISK], DatanodeInfoWithStorage[127.0.0.1:38303,DS-a15f5370-c41b-45ad-a621-90bf41ad8c32,DISK], DatanodeInfoWithStorage[127.0.0.1:34769,DS-82e32e83-de73-4303-8f7d-f9023b5e7824,DISK], DatanodeInfoWithStorage[127.0.0.1:40460,DS-64968273-829a-4309-a712-fb870ed47635,DISK], DatanodeInfoWithStorage[127.0.0.1:32872,DS-1febd8bc-d4c4-4afb-80ce-2db12cb8b644,DISK], DatanodeInfoWithStorage[127.0.0.1:37249,DS-027133d1-6c9f-45c5-9eb7-c7c1daddea31,DISK], DatanodeInfoWithStorage[127.0.0.1:36729,DS-ebd6581f-f668-4ca2-8f35-9604b201550d,DISK], DatanodeInfoWithStorage[127.0.0.1:42808,DS-a3e49f18-3a69-46c5-8147-27ff1049788d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-556847089-172.17.0.4-1598346688256:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44383,DS-f2993f1c-3c08-4e2f-8ffe-9fe83997ec14,DISK], DatanodeInfoWithStorage[127.0.0.1:40637,DS-374d8c6f-82d5-403d-a4b0-72feded52503,DISK], DatanodeInfoWithStorage[127.0.0.1:44467,DS-03406739-2eda-4daa-8cde-d5c890bc6018,DISK], DatanodeInfoWithStorage[127.0.0.1:38966,DS-a5e904ee-efe5-42ad-9fc9-d6b7e9a1c3ac,DISK], DatanodeInfoWithStorage[127.0.0.1:45761,DS-e4b4a185-a492-42ae-8384-999d3c66e90c,DISK], DatanodeInfoWithStorage[127.0.0.1:34483,DS-a82ee472-7c14-43b4-8522-92eddc4d6289,DISK], DatanodeInfoWithStorage[127.0.0.1:40964,DS-90af97bc-5a79-49c9-abd7-9359648445dc,DISK], DatanodeInfoWithStorage[127.0.0.1:37776,DS-c63a3bd0-3128-45d8-9266-63e1a7a71522,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-556847089-172.17.0.4-1598346688256:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44383,DS-f2993f1c-3c08-4e2f-8ffe-9fe83997ec14,DISK], DatanodeInfoWithStorage[127.0.0.1:40637,DS-374d8c6f-82d5-403d-a4b0-72feded52503,DISK], DatanodeInfoWithStorage[127.0.0.1:44467,DS-03406739-2eda-4daa-8cde-d5c890bc6018,DISK], DatanodeInfoWithStorage[127.0.0.1:38966,DS-a5e904ee-efe5-42ad-9fc9-d6b7e9a1c3ac,DISK], DatanodeInfoWithStorage[127.0.0.1:45761,DS-e4b4a185-a492-42ae-8384-999d3c66e90c,DISK], DatanodeInfoWithStorage[127.0.0.1:34483,DS-a82ee472-7c14-43b4-8522-92eddc4d6289,DISK], DatanodeInfoWithStorage[127.0.0.1:40964,DS-90af97bc-5a79-49c9-abd7-9359648445dc,DISK], DatanodeInfoWithStorage[127.0.0.1:37776,DS-c63a3bd0-3128-45d8-9266-63e1a7a71522,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-748008007-172.17.0.4-1598346767922:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39778,DS-d121c076-3009-438e-95c3-6b54590e754b,DISK], DatanodeInfoWithStorage[127.0.0.1:37054,DS-929ea8b5-a35f-41ef-ae15-a86d625ca430,DISK], DatanodeInfoWithStorage[127.0.0.1:41316,DS-bb91288f-a583-403f-826e-bdd26d330ad2,DISK], DatanodeInfoWithStorage[127.0.0.1:36298,DS-0a8c929e-24c9-4757-8527-7edafedb91a6,DISK], DatanodeInfoWithStorage[127.0.0.1:44379,DS-78e42ac4-5ca5-4c4e-8f89-4d712d53ae91,DISK], DatanodeInfoWithStorage[127.0.0.1:39912,DS-049d9e8b-600e-43c5-b2eb-3da531b74a8d,DISK], DatanodeInfoWithStorage[127.0.0.1:42718,DS-01cf4552-79d3-4b84-b6d0-8250e52c1e45,DISK], DatanodeInfoWithStorage[127.0.0.1:41777,DS-f4cd15c7-e8c2-4bf8-a3fc-88bf36d10e74,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-748008007-172.17.0.4-1598346767922:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39778,DS-d121c076-3009-438e-95c3-6b54590e754b,DISK], DatanodeInfoWithStorage[127.0.0.1:37054,DS-929ea8b5-a35f-41ef-ae15-a86d625ca430,DISK], DatanodeInfoWithStorage[127.0.0.1:41316,DS-bb91288f-a583-403f-826e-bdd26d330ad2,DISK], DatanodeInfoWithStorage[127.0.0.1:36298,DS-0a8c929e-24c9-4757-8527-7edafedb91a6,DISK], DatanodeInfoWithStorage[127.0.0.1:44379,DS-78e42ac4-5ca5-4c4e-8f89-4d712d53ae91,DISK], DatanodeInfoWithStorage[127.0.0.1:39912,DS-049d9e8b-600e-43c5-b2eb-3da531b74a8d,DISK], DatanodeInfoWithStorage[127.0.0.1:42718,DS-01cf4552-79d3-4b84-b6d0-8250e52c1e45,DISK], DatanodeInfoWithStorage[127.0.0.1:41777,DS-f4cd15c7-e8c2-4bf8-a3fc-88bf36d10e74,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1911875835-172.17.0.4-1598346921598:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36875,DS-dae90e93-5536-4abd-9e1c-ead3107d9d6f,DISK], DatanodeInfoWithStorage[127.0.0.1:34828,DS-2a2bd040-ab11-4b01-a43e-79d73e19e594,DISK], DatanodeInfoWithStorage[127.0.0.1:35767,DS-d0aac673-c5af-4501-b135-dca47abffcbd,DISK], DatanodeInfoWithStorage[127.0.0.1:34882,DS-e22ba4ef-b0d0-4461-b641-8c4215725a3a,DISK], DatanodeInfoWithStorage[127.0.0.1:40347,DS-df45ebb9-c4c4-42ba-ba54-415fe307d4e0,DISK], DatanodeInfoWithStorage[127.0.0.1:35506,DS-c40a581b-138f-4e0d-91e2-603168dfe541,DISK], DatanodeInfoWithStorage[127.0.0.1:44162,DS-6002d433-8d3a-4983-9c62-49aa1efe9d01,DISK], DatanodeInfoWithStorage[127.0.0.1:41676,DS-47d0d023-5529-4c99-a5cf-a629317f25b4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1911875835-172.17.0.4-1598346921598:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36875,DS-dae90e93-5536-4abd-9e1c-ead3107d9d6f,DISK], DatanodeInfoWithStorage[127.0.0.1:34828,DS-2a2bd040-ab11-4b01-a43e-79d73e19e594,DISK], DatanodeInfoWithStorage[127.0.0.1:35767,DS-d0aac673-c5af-4501-b135-dca47abffcbd,DISK], DatanodeInfoWithStorage[127.0.0.1:34882,DS-e22ba4ef-b0d0-4461-b641-8c4215725a3a,DISK], DatanodeInfoWithStorage[127.0.0.1:40347,DS-df45ebb9-c4c4-42ba-ba54-415fe307d4e0,DISK], DatanodeInfoWithStorage[127.0.0.1:35506,DS-c40a581b-138f-4e0d-91e2-603168dfe541,DISK], DatanodeInfoWithStorage[127.0.0.1:44162,DS-6002d433-8d3a-4983-9c62-49aa1efe9d01,DISK], DatanodeInfoWithStorage[127.0.0.1:41676,DS-47d0d023-5529-4c99-a5cf-a629317f25b4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1966418975-172.17.0.4-1598346998231:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44203,DS-d4f7129b-6d28-433e-aa24-f4bad6045470,DISK], DatanodeInfoWithStorage[127.0.0.1:45413,DS-08b771e9-77b1-43d5-8d72-1afcce11dfb5,DISK], DatanodeInfoWithStorage[127.0.0.1:36080,DS-d2d1ede1-1d52-4330-9d01-010a1146d1a1,DISK], DatanodeInfoWithStorage[127.0.0.1:33710,DS-805cbb99-9462-4717-8acd-74439aee77ae,DISK], DatanodeInfoWithStorage[127.0.0.1:35040,DS-26068d13-7969-4411-896f-133b17994d63,DISK], DatanodeInfoWithStorage[127.0.0.1:39431,DS-59ad7c97-9ff9-4605-99bc-534ea535ed24,DISK], DatanodeInfoWithStorage[127.0.0.1:43634,DS-7dd1da03-5cb9-46a1-9ffb-f42dc46baedd,DISK], DatanodeInfoWithStorage[127.0.0.1:41623,DS-0321d461-3adf-48f9-8f35-b4d7cb4459e1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1966418975-172.17.0.4-1598346998231:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44203,DS-d4f7129b-6d28-433e-aa24-f4bad6045470,DISK], DatanodeInfoWithStorage[127.0.0.1:45413,DS-08b771e9-77b1-43d5-8d72-1afcce11dfb5,DISK], DatanodeInfoWithStorage[127.0.0.1:36080,DS-d2d1ede1-1d52-4330-9d01-010a1146d1a1,DISK], DatanodeInfoWithStorage[127.0.0.1:33710,DS-805cbb99-9462-4717-8acd-74439aee77ae,DISK], DatanodeInfoWithStorage[127.0.0.1:35040,DS-26068d13-7969-4411-896f-133b17994d63,DISK], DatanodeInfoWithStorage[127.0.0.1:39431,DS-59ad7c97-9ff9-4605-99bc-534ea535ed24,DISK], DatanodeInfoWithStorage[127.0.0.1:43634,DS-7dd1da03-5cb9-46a1-9ffb-f42dc46baedd,DISK], DatanodeInfoWithStorage[127.0.0.1:41623,DS-0321d461-3adf-48f9-8f35-b4d7cb4459e1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-919581473-172.17.0.4-1598347456472:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38410,DS-8077a597-28b7-4c73-9ae5-34c32f5c53c6,DISK], DatanodeInfoWithStorage[127.0.0.1:38408,DS-c5241248-4227-4d54-bfff-fafa22641696,DISK], DatanodeInfoWithStorage[127.0.0.1:41956,DS-1dc205b6-caee-4219-a39e-36d67a2dbf38,DISK], DatanodeInfoWithStorage[127.0.0.1:38904,DS-fb076025-6a6a-4403-913a-a1bcce73bd04,DISK], DatanodeInfoWithStorage[127.0.0.1:39954,DS-68522b59-f10a-46bc-85d5-f8654738d9e1,DISK], DatanodeInfoWithStorage[127.0.0.1:38597,DS-37bdfdf1-c88e-4fac-84b7-a5ecc4bd1063,DISK], DatanodeInfoWithStorage[127.0.0.1:41824,DS-c81da627-fe07-4565-b1ab-2ea2221858d7,DISK], DatanodeInfoWithStorage[127.0.0.1:34988,DS-7a935d9d-74ee-475d-b58a-05cb7db0a1d0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-919581473-172.17.0.4-1598347456472:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38410,DS-8077a597-28b7-4c73-9ae5-34c32f5c53c6,DISK], DatanodeInfoWithStorage[127.0.0.1:38408,DS-c5241248-4227-4d54-bfff-fafa22641696,DISK], DatanodeInfoWithStorage[127.0.0.1:41956,DS-1dc205b6-caee-4219-a39e-36d67a2dbf38,DISK], DatanodeInfoWithStorage[127.0.0.1:38904,DS-fb076025-6a6a-4403-913a-a1bcce73bd04,DISK], DatanodeInfoWithStorage[127.0.0.1:39954,DS-68522b59-f10a-46bc-85d5-f8654738d9e1,DISK], DatanodeInfoWithStorage[127.0.0.1:38597,DS-37bdfdf1-c88e-4fac-84b7-a5ecc4bd1063,DISK], DatanodeInfoWithStorage[127.0.0.1:41824,DS-c81da627-fe07-4565-b1ab-2ea2221858d7,DISK], DatanodeInfoWithStorage[127.0.0.1:34988,DS-7a935d9d-74ee-475d-b58a-05cb7db0a1d0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 12 out of 50
v1v1v2v2 failed with probability 21 out of 50
result: false positive !!!
Total execution time in seconds : 5524
