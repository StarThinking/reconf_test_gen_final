reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-354684094-172.17.0.10-1598390069478:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37167,DS-f4eb0964-809f-4d37-bbb0-a4fbf27fc5c2,DISK], DatanodeInfoWithStorage[127.0.0.1:40517,DS-65caa894-d0f1-47bb-97c5-c4f1f40c5e4a,DISK], DatanodeInfoWithStorage[127.0.0.1:38309,DS-118f87dd-0ce8-404c-8b57-166e0c3bf44f,DISK], DatanodeInfoWithStorage[127.0.0.1:33830,DS-3aa13db9-425f-4692-b9a2-075b571bc483,DISK], DatanodeInfoWithStorage[127.0.0.1:45432,DS-282d1194-3b3d-4e13-b0c6-1367f931eb71,DISK], DatanodeInfoWithStorage[127.0.0.1:44646,DS-14d203a3-005f-453d-8b0d-5144eeb8005c,DISK], DatanodeInfoWithStorage[127.0.0.1:42935,DS-1fb135df-9f40-4263-9776-b15325ce6760,DISK], DatanodeInfoWithStorage[127.0.0.1:43873,DS-0b0aca39-df4f-47d0-846e-3df6422189c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-354684094-172.17.0.10-1598390069478:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37167,DS-f4eb0964-809f-4d37-bbb0-a4fbf27fc5c2,DISK], DatanodeInfoWithStorage[127.0.0.1:40517,DS-65caa894-d0f1-47bb-97c5-c4f1f40c5e4a,DISK], DatanodeInfoWithStorage[127.0.0.1:38309,DS-118f87dd-0ce8-404c-8b57-166e0c3bf44f,DISK], DatanodeInfoWithStorage[127.0.0.1:33830,DS-3aa13db9-425f-4692-b9a2-075b571bc483,DISK], DatanodeInfoWithStorage[127.0.0.1:45432,DS-282d1194-3b3d-4e13-b0c6-1367f931eb71,DISK], DatanodeInfoWithStorage[127.0.0.1:44646,DS-14d203a3-005f-453d-8b0d-5144eeb8005c,DISK], DatanodeInfoWithStorage[127.0.0.1:42935,DS-1fb135df-9f40-4263-9776-b15325ce6760,DISK], DatanodeInfoWithStorage[127.0.0.1:43873,DS-0b0aca39-df4f-47d0-846e-3df6422189c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1573825182-172.17.0.10-1598390319288:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34299,DS-8bea6238-cb9e-453a-97cb-9255ab9f7e2d,DISK], DatanodeInfoWithStorage[127.0.0.1:40765,DS-16ffc0df-8722-4b95-8b4d-446fcf063653,DISK], DatanodeInfoWithStorage[127.0.0.1:42899,DS-208a0a1b-eea7-4e5d-9835-bf6f17e9e06e,DISK], DatanodeInfoWithStorage[127.0.0.1:36368,DS-72732193-6587-4e70-86c6-5b87f1a77b07,DISK], DatanodeInfoWithStorage[127.0.0.1:33679,DS-9f096fb1-f89c-418b-9eb0-73759ad98f15,DISK], DatanodeInfoWithStorage[127.0.0.1:36916,DS-8807ebae-945e-4c73-bc8f-01651caebe70,DISK], DatanodeInfoWithStorage[127.0.0.1:43330,DS-b6e74195-46ae-417f-be4a-a2446c345235,DISK], DatanodeInfoWithStorage[127.0.0.1:39555,DS-49051574-888f-4410-9fa2-aa7c3b45c152,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1573825182-172.17.0.10-1598390319288:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34299,DS-8bea6238-cb9e-453a-97cb-9255ab9f7e2d,DISK], DatanodeInfoWithStorage[127.0.0.1:40765,DS-16ffc0df-8722-4b95-8b4d-446fcf063653,DISK], DatanodeInfoWithStorage[127.0.0.1:42899,DS-208a0a1b-eea7-4e5d-9835-bf6f17e9e06e,DISK], DatanodeInfoWithStorage[127.0.0.1:36368,DS-72732193-6587-4e70-86c6-5b87f1a77b07,DISK], DatanodeInfoWithStorage[127.0.0.1:33679,DS-9f096fb1-f89c-418b-9eb0-73759ad98f15,DISK], DatanodeInfoWithStorage[127.0.0.1:36916,DS-8807ebae-945e-4c73-bc8f-01651caebe70,DISK], DatanodeInfoWithStorage[127.0.0.1:43330,DS-b6e74195-46ae-417f-be4a-a2446c345235,DISK], DatanodeInfoWithStorage[127.0.0.1:39555,DS-49051574-888f-4410-9fa2-aa7c3b45c152,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1819177112-172.17.0.10-1598390790131:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35037,DS-7071a5e5-cf70-4f28-b77a-af8e9cfb575c,DISK], DatanodeInfoWithStorage[127.0.0.1:34908,DS-d534a727-0cda-47e2-9945-1667093aa59a,DISK], DatanodeInfoWithStorage[127.0.0.1:45982,DS-a5d51c22-056d-4dbf-815a-5b25f4c2cc3f,DISK], DatanodeInfoWithStorage[127.0.0.1:37602,DS-8eb0cf63-6384-4760-9bcd-71cac407127e,DISK], DatanodeInfoWithStorage[127.0.0.1:38577,DS-f1fdb677-c516-46d2-a0cc-7d1eb78418e7,DISK], DatanodeInfoWithStorage[127.0.0.1:41815,DS-b52f0638-7aba-4003-9fe6-b8c83e6114c7,DISK], DatanodeInfoWithStorage[127.0.0.1:36947,DS-ac4aced3-9da9-4ed5-ac4b-0a2c8ff78387,DISK], DatanodeInfoWithStorage[127.0.0.1:34711,DS-6fa61aad-efea-402e-a8d8-fd933ccc2dab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1819177112-172.17.0.10-1598390790131:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35037,DS-7071a5e5-cf70-4f28-b77a-af8e9cfb575c,DISK], DatanodeInfoWithStorage[127.0.0.1:34908,DS-d534a727-0cda-47e2-9945-1667093aa59a,DISK], DatanodeInfoWithStorage[127.0.0.1:45982,DS-a5d51c22-056d-4dbf-815a-5b25f4c2cc3f,DISK], DatanodeInfoWithStorage[127.0.0.1:37602,DS-8eb0cf63-6384-4760-9bcd-71cac407127e,DISK], DatanodeInfoWithStorage[127.0.0.1:38577,DS-f1fdb677-c516-46d2-a0cc-7d1eb78418e7,DISK], DatanodeInfoWithStorage[127.0.0.1:41815,DS-b52f0638-7aba-4003-9fe6-b8c83e6114c7,DISK], DatanodeInfoWithStorage[127.0.0.1:36947,DS-ac4aced3-9da9-4ed5-ac4b-0a2c8ff78387,DISK], DatanodeInfoWithStorage[127.0.0.1:34711,DS-6fa61aad-efea-402e-a8d8-fd933ccc2dab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1055891507-172.17.0.10-1598390933592:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44076,DS-6c2b4c9c-814c-4e44-a94d-9917087f51b4,DISK], DatanodeInfoWithStorage[127.0.0.1:35014,DS-e65c6be8-6704-439d-8072-d468e305acf9,DISK], DatanodeInfoWithStorage[127.0.0.1:40469,DS-71d6fc97-34a1-4b72-99b3-c5919e8fcf09,DISK], DatanodeInfoWithStorage[127.0.0.1:43794,DS-1a003866-87b5-4d68-8d61-73deab29a9a5,DISK], DatanodeInfoWithStorage[127.0.0.1:39577,DS-6a52e292-b132-4466-983c-94cb42017a40,DISK], DatanodeInfoWithStorage[127.0.0.1:38770,DS-6a4c9980-c618-470a-8aad-488492d30163,DISK], DatanodeInfoWithStorage[127.0.0.1:32876,DS-42e060c9-20ba-4af7-b9d0-03cab2f22f0a,DISK], DatanodeInfoWithStorage[127.0.0.1:33466,DS-919c8ea7-69d5-4591-8a82-238d5d7f51a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1055891507-172.17.0.10-1598390933592:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44076,DS-6c2b4c9c-814c-4e44-a94d-9917087f51b4,DISK], DatanodeInfoWithStorage[127.0.0.1:35014,DS-e65c6be8-6704-439d-8072-d468e305acf9,DISK], DatanodeInfoWithStorage[127.0.0.1:40469,DS-71d6fc97-34a1-4b72-99b3-c5919e8fcf09,DISK], DatanodeInfoWithStorage[127.0.0.1:43794,DS-1a003866-87b5-4d68-8d61-73deab29a9a5,DISK], DatanodeInfoWithStorage[127.0.0.1:39577,DS-6a52e292-b132-4466-983c-94cb42017a40,DISK], DatanodeInfoWithStorage[127.0.0.1:38770,DS-6a4c9980-c618-470a-8aad-488492d30163,DISK], DatanodeInfoWithStorage[127.0.0.1:32876,DS-42e060c9-20ba-4af7-b9d0-03cab2f22f0a,DISK], DatanodeInfoWithStorage[127.0.0.1:33466,DS-919c8ea7-69d5-4591-8a82-238d5d7f51a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2135401740-172.17.0.10-1598390966435:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38456,DS-32504574-424d-4171-b403-e9c369a22956,DISK], DatanodeInfoWithStorage[127.0.0.1:39101,DS-f8c1712a-1fe0-42e4-acd4-f3c0477cf2b7,DISK], DatanodeInfoWithStorage[127.0.0.1:41029,DS-b01aeb46-473a-4b45-9a16-6aca7e4c0ba9,DISK], DatanodeInfoWithStorage[127.0.0.1:34340,DS-8cb46d2e-b258-463b-b758-ff0c957accd2,DISK], DatanodeInfoWithStorage[127.0.0.1:38271,DS-e4d59c88-569f-42f0-ab28-8a1d61af6b8d,DISK], DatanodeInfoWithStorage[127.0.0.1:45570,DS-0db7e493-cf24-4440-adb4-91cdfa38a982,DISK], DatanodeInfoWithStorage[127.0.0.1:44969,DS-eade2a44-05cc-4162-8e84-41ebe1fc9cf7,DISK], DatanodeInfoWithStorage[127.0.0.1:37840,DS-af92a336-afa7-4171-861e-8934b107ad84,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2135401740-172.17.0.10-1598390966435:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38456,DS-32504574-424d-4171-b403-e9c369a22956,DISK], DatanodeInfoWithStorage[127.0.0.1:39101,DS-f8c1712a-1fe0-42e4-acd4-f3c0477cf2b7,DISK], DatanodeInfoWithStorage[127.0.0.1:41029,DS-b01aeb46-473a-4b45-9a16-6aca7e4c0ba9,DISK], DatanodeInfoWithStorage[127.0.0.1:34340,DS-8cb46d2e-b258-463b-b758-ff0c957accd2,DISK], DatanodeInfoWithStorage[127.0.0.1:38271,DS-e4d59c88-569f-42f0-ab28-8a1d61af6b8d,DISK], DatanodeInfoWithStorage[127.0.0.1:45570,DS-0db7e493-cf24-4440-adb4-91cdfa38a982,DISK], DatanodeInfoWithStorage[127.0.0.1:44969,DS-eade2a44-05cc-4162-8e84-41ebe1fc9cf7,DISK], DatanodeInfoWithStorage[127.0.0.1:37840,DS-af92a336-afa7-4171-861e-8934b107ad84,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1943542185-172.17.0.10-1598391698582:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42032,DS-76b1fb61-8437-46b8-ba0f-5bc748381da4,DISK], DatanodeInfoWithStorage[127.0.0.1:37262,DS-ade8fd42-3c05-47b2-b3eb-2efc92319b36,DISK], DatanodeInfoWithStorage[127.0.0.1:45085,DS-5a40377b-d4ed-450a-906f-62b8c12540cf,DISK], DatanodeInfoWithStorage[127.0.0.1:46070,DS-0925ec6b-b1a5-4836-ad71-4eb28a9ea691,DISK], DatanodeInfoWithStorage[127.0.0.1:38728,DS-18e65308-8f5f-43ed-8fe0-9857f9842517,DISK], DatanodeInfoWithStorage[127.0.0.1:40121,DS-da7b1d9e-92b8-4a33-8e33-b7258c982b56,DISK], DatanodeInfoWithStorage[127.0.0.1:42270,DS-0d9461d7-3e90-4fa8-9e98-0517a529c1b9,DISK], DatanodeInfoWithStorage[127.0.0.1:37598,DS-c4b245a7-b030-40a3-86da-189a07a4f31b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1943542185-172.17.0.10-1598391698582:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42032,DS-76b1fb61-8437-46b8-ba0f-5bc748381da4,DISK], DatanodeInfoWithStorage[127.0.0.1:37262,DS-ade8fd42-3c05-47b2-b3eb-2efc92319b36,DISK], DatanodeInfoWithStorage[127.0.0.1:45085,DS-5a40377b-d4ed-450a-906f-62b8c12540cf,DISK], DatanodeInfoWithStorage[127.0.0.1:46070,DS-0925ec6b-b1a5-4836-ad71-4eb28a9ea691,DISK], DatanodeInfoWithStorage[127.0.0.1:38728,DS-18e65308-8f5f-43ed-8fe0-9857f9842517,DISK], DatanodeInfoWithStorage[127.0.0.1:40121,DS-da7b1d9e-92b8-4a33-8e33-b7258c982b56,DISK], DatanodeInfoWithStorage[127.0.0.1:42270,DS-0d9461d7-3e90-4fa8-9e98-0517a529c1b9,DISK], DatanodeInfoWithStorage[127.0.0.1:37598,DS-c4b245a7-b030-40a3-86da-189a07a4f31b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1981370038-172.17.0.10-1598391844152:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37088,DS-ea720f7c-deef-4492-bfe5-c5074e7ee811,DISK], DatanodeInfoWithStorage[127.0.0.1:35951,DS-0675829f-d241-46e8-9e1a-90c794c70e6b,DISK], DatanodeInfoWithStorage[127.0.0.1:35688,DS-c12a7db4-efd7-4aeb-8fad-02bd1a626b1d,DISK], DatanodeInfoWithStorage[127.0.0.1:35501,DS-bfe750fb-88d7-405c-b7c3-262331eeae2c,DISK], DatanodeInfoWithStorage[127.0.0.1:34096,DS-f3f70ae1-e607-472a-95dc-c56502f1d9b5,DISK], DatanodeInfoWithStorage[127.0.0.1:41421,DS-786e487f-533f-4ff1-9408-8d07cc9c0e7d,DISK], DatanodeInfoWithStorage[127.0.0.1:35042,DS-1e562474-a78c-4b50-8beb-037dc52275f2,DISK], DatanodeInfoWithStorage[127.0.0.1:39280,DS-54dc54c6-b5c2-468d-adf1-1a6db8fd7611,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1981370038-172.17.0.10-1598391844152:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37088,DS-ea720f7c-deef-4492-bfe5-c5074e7ee811,DISK], DatanodeInfoWithStorage[127.0.0.1:35951,DS-0675829f-d241-46e8-9e1a-90c794c70e6b,DISK], DatanodeInfoWithStorage[127.0.0.1:35688,DS-c12a7db4-efd7-4aeb-8fad-02bd1a626b1d,DISK], DatanodeInfoWithStorage[127.0.0.1:35501,DS-bfe750fb-88d7-405c-b7c3-262331eeae2c,DISK], DatanodeInfoWithStorage[127.0.0.1:34096,DS-f3f70ae1-e607-472a-95dc-c56502f1d9b5,DISK], DatanodeInfoWithStorage[127.0.0.1:41421,DS-786e487f-533f-4ff1-9408-8d07cc9c0e7d,DISK], DatanodeInfoWithStorage[127.0.0.1:35042,DS-1e562474-a78c-4b50-8beb-037dc52275f2,DISK], DatanodeInfoWithStorage[127.0.0.1:39280,DS-54dc54c6-b5c2-468d-adf1-1a6db8fd7611,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-172833896-172.17.0.10-1598391986250:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33299,DS-b42287a2-93ba-4af3-a34c-5c42020397c6,DISK], DatanodeInfoWithStorage[127.0.0.1:44298,DS-37a40a68-4b5e-4f76-ba36-ceb3ef871519,DISK], DatanodeInfoWithStorage[127.0.0.1:38715,DS-206a0a52-e8b1-444a-a2bf-156be1c736a8,DISK], DatanodeInfoWithStorage[127.0.0.1:46163,DS-45c3c8f8-548d-45c5-86f0-7595ad4bed1d,DISK], DatanodeInfoWithStorage[127.0.0.1:33951,DS-ec16879a-6034-425d-b35b-a55080abd81f,DISK], DatanodeInfoWithStorage[127.0.0.1:44086,DS-c92914ce-5f05-4a4d-a728-720f4110393b,DISK], DatanodeInfoWithStorage[127.0.0.1:44857,DS-375ac16e-403e-435f-a4d6-e2a400a436f4,DISK], DatanodeInfoWithStorage[127.0.0.1:34863,DS-a3754bbf-3748-4d2f-a556-002a4ccf8501,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-172833896-172.17.0.10-1598391986250:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33299,DS-b42287a2-93ba-4af3-a34c-5c42020397c6,DISK], DatanodeInfoWithStorage[127.0.0.1:44298,DS-37a40a68-4b5e-4f76-ba36-ceb3ef871519,DISK], DatanodeInfoWithStorage[127.0.0.1:38715,DS-206a0a52-e8b1-444a-a2bf-156be1c736a8,DISK], DatanodeInfoWithStorage[127.0.0.1:46163,DS-45c3c8f8-548d-45c5-86f0-7595ad4bed1d,DISK], DatanodeInfoWithStorage[127.0.0.1:33951,DS-ec16879a-6034-425d-b35b-a55080abd81f,DISK], DatanodeInfoWithStorage[127.0.0.1:44086,DS-c92914ce-5f05-4a4d-a728-720f4110393b,DISK], DatanodeInfoWithStorage[127.0.0.1:44857,DS-375ac16e-403e-435f-a4d6-e2a400a436f4,DISK], DatanodeInfoWithStorage[127.0.0.1:34863,DS-a3754bbf-3748-4d2f-a556-002a4ccf8501,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-862221701-172.17.0.10-1598392170926:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36748,DS-8a9c689b-fea9-4d5c-a9b3-178c0cda7741,DISK], DatanodeInfoWithStorage[127.0.0.1:39697,DS-0ad89bd0-b854-496e-840a-dcf89871d2c8,DISK], DatanodeInfoWithStorage[127.0.0.1:44518,DS-6af3c973-a10f-4085-b9b6-95dc411328e2,DISK], DatanodeInfoWithStorage[127.0.0.1:44230,DS-eab47997-c6af-43d7-9af3-4ef579014ab4,DISK], DatanodeInfoWithStorage[127.0.0.1:38885,DS-cdcf7394-32dd-4bf6-83a2-e6f688bd4d34,DISK], DatanodeInfoWithStorage[127.0.0.1:44453,DS-87189f25-c86f-479e-9412-b88977c916f3,DISK], DatanodeInfoWithStorage[127.0.0.1:46255,DS-a03d6eca-ff86-4606-9338-f0a7c3f986d2,DISK], DatanodeInfoWithStorage[127.0.0.1:42099,DS-39c77ca0-39fa-42ad-97c3-234cc4acd918,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-862221701-172.17.0.10-1598392170926:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36748,DS-8a9c689b-fea9-4d5c-a9b3-178c0cda7741,DISK], DatanodeInfoWithStorage[127.0.0.1:39697,DS-0ad89bd0-b854-496e-840a-dcf89871d2c8,DISK], DatanodeInfoWithStorage[127.0.0.1:44518,DS-6af3c973-a10f-4085-b9b6-95dc411328e2,DISK], DatanodeInfoWithStorage[127.0.0.1:44230,DS-eab47997-c6af-43d7-9af3-4ef579014ab4,DISK], DatanodeInfoWithStorage[127.0.0.1:38885,DS-cdcf7394-32dd-4bf6-83a2-e6f688bd4d34,DISK], DatanodeInfoWithStorage[127.0.0.1:44453,DS-87189f25-c86f-479e-9412-b88977c916f3,DISK], DatanodeInfoWithStorage[127.0.0.1:46255,DS-a03d6eca-ff86-4606-9338-f0a7c3f986d2,DISK], DatanodeInfoWithStorage[127.0.0.1:42099,DS-39c77ca0-39fa-42ad-97c3-234cc4acd918,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1266144672-172.17.0.10-1598392424682:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43424,DS-7972c9b1-b82f-44f5-a920-de834e4b2b2c,DISK], DatanodeInfoWithStorage[127.0.0.1:35505,DS-3e6de1f6-41aa-4ab3-91b7-1a40df3fbb6e,DISK], DatanodeInfoWithStorage[127.0.0.1:40858,DS-2164db7f-1f22-487d-8af5-fbd84223e5a2,DISK], DatanodeInfoWithStorage[127.0.0.1:38092,DS-4deea4f8-92d7-4398-a134-1eb9f0ffe7cd,DISK], DatanodeInfoWithStorage[127.0.0.1:33667,DS-23a890d3-fc0c-4fca-b270-08f3106cbd70,DISK], DatanodeInfoWithStorage[127.0.0.1:37205,DS-229a57f1-fffd-4cf0-97bc-9b1309c57b79,DISK], DatanodeInfoWithStorage[127.0.0.1:39689,DS-2a812b90-2502-42c6-bf49-fd8d159aa2b0,DISK], DatanodeInfoWithStorage[127.0.0.1:40954,DS-a80882b8-be94-4c62-86c0-4575c2bc7a0e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1266144672-172.17.0.10-1598392424682:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43424,DS-7972c9b1-b82f-44f5-a920-de834e4b2b2c,DISK], DatanodeInfoWithStorage[127.0.0.1:35505,DS-3e6de1f6-41aa-4ab3-91b7-1a40df3fbb6e,DISK], DatanodeInfoWithStorage[127.0.0.1:40858,DS-2164db7f-1f22-487d-8af5-fbd84223e5a2,DISK], DatanodeInfoWithStorage[127.0.0.1:38092,DS-4deea4f8-92d7-4398-a134-1eb9f0ffe7cd,DISK], DatanodeInfoWithStorage[127.0.0.1:33667,DS-23a890d3-fc0c-4fca-b270-08f3106cbd70,DISK], DatanodeInfoWithStorage[127.0.0.1:37205,DS-229a57f1-fffd-4cf0-97bc-9b1309c57b79,DISK], DatanodeInfoWithStorage[127.0.0.1:39689,DS-2a812b90-2502-42c6-bf49-fd8d159aa2b0,DISK], DatanodeInfoWithStorage[127.0.0.1:40954,DS-a80882b8-be94-4c62-86c0-4575c2bc7a0e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1656479682-172.17.0.10-1598392855309:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36024,DS-910a9db7-eb57-46f8-a489-f0b69e9a023e,DISK], DatanodeInfoWithStorage[127.0.0.1:35821,DS-0269a434-654e-4e6d-89fd-774c4db7fe18,DISK], DatanodeInfoWithStorage[127.0.0.1:44321,DS-e39fde60-16ff-4910-9271-43dd0f18bd35,DISK], DatanodeInfoWithStorage[127.0.0.1:37379,DS-b59b2b51-1f7d-4943-82d5-03b41e55316b,DISK], DatanodeInfoWithStorage[127.0.0.1:45170,DS-120579e6-52db-410a-9471-851f48589c7b,DISK], DatanodeInfoWithStorage[127.0.0.1:41700,DS-5f3d4b20-4d47-43d3-ab90-e41f7e88a3c9,DISK], DatanodeInfoWithStorage[127.0.0.1:32834,DS-86ad9842-2b26-4ff1-a599-ce7f9a873f85,DISK], DatanodeInfoWithStorage[127.0.0.1:45568,DS-988dd948-b822-49b9-ab44-612a18b745a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1656479682-172.17.0.10-1598392855309:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36024,DS-910a9db7-eb57-46f8-a489-f0b69e9a023e,DISK], DatanodeInfoWithStorage[127.0.0.1:35821,DS-0269a434-654e-4e6d-89fd-774c4db7fe18,DISK], DatanodeInfoWithStorage[127.0.0.1:44321,DS-e39fde60-16ff-4910-9271-43dd0f18bd35,DISK], DatanodeInfoWithStorage[127.0.0.1:37379,DS-b59b2b51-1f7d-4943-82d5-03b41e55316b,DISK], DatanodeInfoWithStorage[127.0.0.1:45170,DS-120579e6-52db-410a-9471-851f48589c7b,DISK], DatanodeInfoWithStorage[127.0.0.1:41700,DS-5f3d4b20-4d47-43d3-ab90-e41f7e88a3c9,DISK], DatanodeInfoWithStorage[127.0.0.1:32834,DS-86ad9842-2b26-4ff1-a599-ce7f9a873f85,DISK], DatanodeInfoWithStorage[127.0.0.1:45568,DS-988dd948-b822-49b9-ab44-612a18b745a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2035457993-172.17.0.10-1598392992725:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39843,DS-8259829d-5558-4ae1-af64-612eda4fc0fa,DISK], DatanodeInfoWithStorage[127.0.0.1:38123,DS-53cba553-e495-4436-9f64-5d4f7dd75448,DISK], DatanodeInfoWithStorage[127.0.0.1:44954,DS-c15ebab5-978e-492e-b6ec-959090a307a8,DISK], DatanodeInfoWithStorage[127.0.0.1:35555,DS-5c034e00-8e54-4c01-a54c-7c2db5974009,DISK], DatanodeInfoWithStorage[127.0.0.1:46579,DS-5c01b80d-60ef-4f3f-97df-b9e0dc4a8f17,DISK], DatanodeInfoWithStorage[127.0.0.1:33690,DS-4af03b9f-94a8-4e93-bdbb-032e37be0ea3,DISK], DatanodeInfoWithStorage[127.0.0.1:45061,DS-d84f2a27-2333-4be5-bcf0-c56d12a38a65,DISK], DatanodeInfoWithStorage[127.0.0.1:33770,DS-88d8529e-66f5-47fc-b535-45cfe53e9c68,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2035457993-172.17.0.10-1598392992725:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39843,DS-8259829d-5558-4ae1-af64-612eda4fc0fa,DISK], DatanodeInfoWithStorage[127.0.0.1:38123,DS-53cba553-e495-4436-9f64-5d4f7dd75448,DISK], DatanodeInfoWithStorage[127.0.0.1:44954,DS-c15ebab5-978e-492e-b6ec-959090a307a8,DISK], DatanodeInfoWithStorage[127.0.0.1:35555,DS-5c034e00-8e54-4c01-a54c-7c2db5974009,DISK], DatanodeInfoWithStorage[127.0.0.1:46579,DS-5c01b80d-60ef-4f3f-97df-b9e0dc4a8f17,DISK], DatanodeInfoWithStorage[127.0.0.1:33690,DS-4af03b9f-94a8-4e93-bdbb-032e37be0ea3,DISK], DatanodeInfoWithStorage[127.0.0.1:45061,DS-d84f2a27-2333-4be5-bcf0-c56d12a38a65,DISK], DatanodeInfoWithStorage[127.0.0.1:33770,DS-88d8529e-66f5-47fc-b535-45cfe53e9c68,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-248767224-172.17.0.10-1598393460170:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44662,DS-e55c1c43-d700-46cf-a3ea-1d0b34e3c651,DISK], DatanodeInfoWithStorage[127.0.0.1:41968,DS-ec421399-21ee-448f-88d6-6e49f38ba3b9,DISK], DatanodeInfoWithStorage[127.0.0.1:33168,DS-8b6e5c19-cb97-4be0-b138-0f85a1a6b912,DISK], DatanodeInfoWithStorage[127.0.0.1:45037,DS-780c510f-a695-41f1-ab53-710c6e3aa179,DISK], DatanodeInfoWithStorage[127.0.0.1:45710,DS-252b0128-fad0-4103-a5db-7c7ff02a6a9b,DISK], DatanodeInfoWithStorage[127.0.0.1:43477,DS-30185b44-ffeb-4b90-b3f0-d951f18907fd,DISK], DatanodeInfoWithStorage[127.0.0.1:41226,DS-38ce6090-4866-4a1a-87d3-a5f7aef24e56,DISK], DatanodeInfoWithStorage[127.0.0.1:44616,DS-16387cb1-4026-46c3-9bb8-641058485bbd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-248767224-172.17.0.10-1598393460170:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44662,DS-e55c1c43-d700-46cf-a3ea-1d0b34e3c651,DISK], DatanodeInfoWithStorage[127.0.0.1:41968,DS-ec421399-21ee-448f-88d6-6e49f38ba3b9,DISK], DatanodeInfoWithStorage[127.0.0.1:33168,DS-8b6e5c19-cb97-4be0-b138-0f85a1a6b912,DISK], DatanodeInfoWithStorage[127.0.0.1:45037,DS-780c510f-a695-41f1-ab53-710c6e3aa179,DISK], DatanodeInfoWithStorage[127.0.0.1:45710,DS-252b0128-fad0-4103-a5db-7c7ff02a6a9b,DISK], DatanodeInfoWithStorage[127.0.0.1:43477,DS-30185b44-ffeb-4b90-b3f0-d951f18907fd,DISK], DatanodeInfoWithStorage[127.0.0.1:41226,DS-38ce6090-4866-4a1a-87d3-a5f7aef24e56,DISK], DatanodeInfoWithStorage[127.0.0.1:44616,DS-16387cb1-4026-46c3-9bb8-641058485bbd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1906067009-172.17.0.10-1598393923805:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44024,DS-077550dc-5150-4a88-a224-55876f7c15c2,DISK], DatanodeInfoWithStorage[127.0.0.1:45994,DS-ca7bf778-608d-4244-be19-18409cb199ec,DISK], DatanodeInfoWithStorage[127.0.0.1:44439,DS-28179428-2c2f-4c6e-9ba2-767b101e263a,DISK], DatanodeInfoWithStorage[127.0.0.1:41609,DS-31807f9f-1ad8-49fe-97cf-f9879b6cea85,DISK], DatanodeInfoWithStorage[127.0.0.1:44706,DS-cf7b0bff-0ba9-4018-bf16-9b66d2d2953f,DISK], DatanodeInfoWithStorage[127.0.0.1:36967,DS-82e5282c-d453-4504-b67b-3b871c0c9ea1,DISK], DatanodeInfoWithStorage[127.0.0.1:43304,DS-08054428-9ee0-4a4c-8cc5-a7c472fcde3f,DISK], DatanodeInfoWithStorage[127.0.0.1:41342,DS-845842e6-5fe9-410f-9773-1b04e0f79143,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1906067009-172.17.0.10-1598393923805:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44024,DS-077550dc-5150-4a88-a224-55876f7c15c2,DISK], DatanodeInfoWithStorage[127.0.0.1:45994,DS-ca7bf778-608d-4244-be19-18409cb199ec,DISK], DatanodeInfoWithStorage[127.0.0.1:44439,DS-28179428-2c2f-4c6e-9ba2-767b101e263a,DISK], DatanodeInfoWithStorage[127.0.0.1:41609,DS-31807f9f-1ad8-49fe-97cf-f9879b6cea85,DISK], DatanodeInfoWithStorage[127.0.0.1:44706,DS-cf7b0bff-0ba9-4018-bf16-9b66d2d2953f,DISK], DatanodeInfoWithStorage[127.0.0.1:36967,DS-82e5282c-d453-4504-b67b-3b871c0c9ea1,DISK], DatanodeInfoWithStorage[127.0.0.1:43304,DS-08054428-9ee0-4a4c-8cc5-a7c472fcde3f,DISK], DatanodeInfoWithStorage[127.0.0.1:41342,DS-845842e6-5fe9-410f-9773-1b04e0f79143,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1505299583-172.17.0.10-1598394385344:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39303,DS-89a57023-bb68-40ea-9a1f-19ae3106093f,DISK], DatanodeInfoWithStorage[127.0.0.1:37299,DS-92740ee5-d3d1-46cd-a46f-b2b300a23dc0,DISK], DatanodeInfoWithStorage[127.0.0.1:35807,DS-de0dc7db-95bf-478a-9550-d03c348c2095,DISK], DatanodeInfoWithStorage[127.0.0.1:41199,DS-f81190c4-839a-4b41-b12c-ea21de5b4fb6,DISK], DatanodeInfoWithStorage[127.0.0.1:45495,DS-55c0c5b8-c110-4897-9fce-c0bd7cedd392,DISK], DatanodeInfoWithStorage[127.0.0.1:43322,DS-cca3234f-32e5-4d15-8f0d-0ecfe02ca732,DISK], DatanodeInfoWithStorage[127.0.0.1:45927,DS-48775631-63af-4a7c-9b6c-1f7bb3f7f742,DISK], DatanodeInfoWithStorage[127.0.0.1:45844,DS-f2c60a51-d946-45b7-b36f-f2d42167a8f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1505299583-172.17.0.10-1598394385344:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39303,DS-89a57023-bb68-40ea-9a1f-19ae3106093f,DISK], DatanodeInfoWithStorage[127.0.0.1:37299,DS-92740ee5-d3d1-46cd-a46f-b2b300a23dc0,DISK], DatanodeInfoWithStorage[127.0.0.1:35807,DS-de0dc7db-95bf-478a-9550-d03c348c2095,DISK], DatanodeInfoWithStorage[127.0.0.1:41199,DS-f81190c4-839a-4b41-b12c-ea21de5b4fb6,DISK], DatanodeInfoWithStorage[127.0.0.1:45495,DS-55c0c5b8-c110-4897-9fce-c0bd7cedd392,DISK], DatanodeInfoWithStorage[127.0.0.1:43322,DS-cca3234f-32e5-4d15-8f0d-0ecfe02ca732,DISK], DatanodeInfoWithStorage[127.0.0.1:45927,DS-48775631-63af-4a7c-9b6c-1f7bb3f7f742,DISK], DatanodeInfoWithStorage[127.0.0.1:45844,DS-f2c60a51-d946-45b7-b36f-f2d42167a8f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1489336923-172.17.0.10-1598394943484:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36519,DS-df01ae5e-e216-4d4c-b0a6-302183b225f7,DISK], DatanodeInfoWithStorage[127.0.0.1:41541,DS-08f1c40e-d35c-4822-9414-a8ad33ba0496,DISK], DatanodeInfoWithStorage[127.0.0.1:45528,DS-eff6ea67-54c6-4d7e-ae07-50404a8af579,DISK], DatanodeInfoWithStorage[127.0.0.1:46220,DS-85ebe890-0e67-4545-8425-0b6b723327af,DISK], DatanodeInfoWithStorage[127.0.0.1:42553,DS-0e1f476f-1952-44b9-a13c-71f0b03a0173,DISK], DatanodeInfoWithStorage[127.0.0.1:37757,DS-c94d7ab4-4013-400c-a217-2d520233cd46,DISK], DatanodeInfoWithStorage[127.0.0.1:46649,DS-d943ea57-dbbe-438f-9566-997d4aaaebf8,DISK], DatanodeInfoWithStorage[127.0.0.1:42842,DS-b7b97212-48dd-4221-ac81-e27099eeed31,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1489336923-172.17.0.10-1598394943484:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36519,DS-df01ae5e-e216-4d4c-b0a6-302183b225f7,DISK], DatanodeInfoWithStorage[127.0.0.1:41541,DS-08f1c40e-d35c-4822-9414-a8ad33ba0496,DISK], DatanodeInfoWithStorage[127.0.0.1:45528,DS-eff6ea67-54c6-4d7e-ae07-50404a8af579,DISK], DatanodeInfoWithStorage[127.0.0.1:46220,DS-85ebe890-0e67-4545-8425-0b6b723327af,DISK], DatanodeInfoWithStorage[127.0.0.1:42553,DS-0e1f476f-1952-44b9-a13c-71f0b03a0173,DISK], DatanodeInfoWithStorage[127.0.0.1:37757,DS-c94d7ab4-4013-400c-a217-2d520233cd46,DISK], DatanodeInfoWithStorage[127.0.0.1:46649,DS-d943ea57-dbbe-438f-9566-997d4aaaebf8,DISK], DatanodeInfoWithStorage[127.0.0.1:42842,DS-b7b97212-48dd-4221-ac81-e27099eeed31,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5171
