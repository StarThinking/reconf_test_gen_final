reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-737837549-172.17.0.20-1598417777104:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36452,DS-1506c0d2-9bb9-4a8b-8a12-7f04ffdf9906,DISK], DatanodeInfoWithStorage[127.0.0.1:44739,DS-f0e300a8-83a3-4cc6-84cc-9b57b6971770,DISK], DatanodeInfoWithStorage[127.0.0.1:36778,DS-d1b1f04c-3cf3-4050-a773-9ab0ef3d8d8d,DISK], DatanodeInfoWithStorage[127.0.0.1:36613,DS-a1edde2c-4755-468f-a342-d4186d448e0b,DISK], DatanodeInfoWithStorage[127.0.0.1:42397,DS-d96c5043-9ea5-4ecf-93cc-586e57ad8655,DISK], DatanodeInfoWithStorage[127.0.0.1:34954,DS-c8eaa5bc-bacc-40cd-a1d0-a3e65a562728,DISK], DatanodeInfoWithStorage[127.0.0.1:41003,DS-92fc2dc7-08f0-4e6a-8053-d5b9fa655e14,DISK], DatanodeInfoWithStorage[127.0.0.1:43995,DS-9d8a2b1d-4205-4932-b57f-83b718a1d7aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-737837549-172.17.0.20-1598417777104:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36452,DS-1506c0d2-9bb9-4a8b-8a12-7f04ffdf9906,DISK], DatanodeInfoWithStorage[127.0.0.1:44739,DS-f0e300a8-83a3-4cc6-84cc-9b57b6971770,DISK], DatanodeInfoWithStorage[127.0.0.1:36778,DS-d1b1f04c-3cf3-4050-a773-9ab0ef3d8d8d,DISK], DatanodeInfoWithStorage[127.0.0.1:36613,DS-a1edde2c-4755-468f-a342-d4186d448e0b,DISK], DatanodeInfoWithStorage[127.0.0.1:42397,DS-d96c5043-9ea5-4ecf-93cc-586e57ad8655,DISK], DatanodeInfoWithStorage[127.0.0.1:34954,DS-c8eaa5bc-bacc-40cd-a1d0-a3e65a562728,DISK], DatanodeInfoWithStorage[127.0.0.1:41003,DS-92fc2dc7-08f0-4e6a-8053-d5b9fa655e14,DISK], DatanodeInfoWithStorage[127.0.0.1:43995,DS-9d8a2b1d-4205-4932-b57f-83b718a1d7aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-844098918-172.17.0.20-1598418104817:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44426,DS-6d90b3a5-1057-4d5d-a978-f01219ccf0df,DISK], DatanodeInfoWithStorage[127.0.0.1:35718,DS-317f1b9a-a3de-4667-ae93-581b0140896c,DISK], DatanodeInfoWithStorage[127.0.0.1:43063,DS-b846d2b9-84f2-4413-8215-79a4cbd8710e,DISK], DatanodeInfoWithStorage[127.0.0.1:34049,DS-b25f5673-2a89-4414-b4e8-4f747fb1a296,DISK], DatanodeInfoWithStorage[127.0.0.1:43076,DS-e96c8f4a-1211-4dd9-9950-739ed0ab3e9d,DISK], DatanodeInfoWithStorage[127.0.0.1:43445,DS-b9078d79-98c2-40a0-abbc-a2f3e10656e7,DISK], DatanodeInfoWithStorage[127.0.0.1:36411,DS-3900a7b8-b6ff-4264-91b6-adaf1b8b1a79,DISK], DatanodeInfoWithStorage[127.0.0.1:45136,DS-633d1369-017b-4510-ab4a-30a2934b1f67,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-844098918-172.17.0.20-1598418104817:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44426,DS-6d90b3a5-1057-4d5d-a978-f01219ccf0df,DISK], DatanodeInfoWithStorage[127.0.0.1:35718,DS-317f1b9a-a3de-4667-ae93-581b0140896c,DISK], DatanodeInfoWithStorage[127.0.0.1:43063,DS-b846d2b9-84f2-4413-8215-79a4cbd8710e,DISK], DatanodeInfoWithStorage[127.0.0.1:34049,DS-b25f5673-2a89-4414-b4e8-4f747fb1a296,DISK], DatanodeInfoWithStorage[127.0.0.1:43076,DS-e96c8f4a-1211-4dd9-9950-739ed0ab3e9d,DISK], DatanodeInfoWithStorage[127.0.0.1:43445,DS-b9078d79-98c2-40a0-abbc-a2f3e10656e7,DISK], DatanodeInfoWithStorage[127.0.0.1:36411,DS-3900a7b8-b6ff-4264-91b6-adaf1b8b1a79,DISK], DatanodeInfoWithStorage[127.0.0.1:45136,DS-633d1369-017b-4510-ab4a-30a2934b1f67,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-934952550-172.17.0.20-1598418177859:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34951,DS-1f93a4cc-7aec-454d-9995-0ed4fbc7f6a4,DISK], DatanodeInfoWithStorage[127.0.0.1:39111,DS-ff869f07-4de8-48af-a418-5e1892d8ba1f,DISK], DatanodeInfoWithStorage[127.0.0.1:37495,DS-15deca20-da6e-4cd1-938e-c08662d3f1c2,DISK], DatanodeInfoWithStorage[127.0.0.1:42886,DS-54901267-f1e0-469c-af0d-9045c9bf0f9e,DISK], DatanodeInfoWithStorage[127.0.0.1:41526,DS-0fd3a03d-f9b8-40b2-8b5f-395489f24d6c,DISK], DatanodeInfoWithStorage[127.0.0.1:33041,DS-ffc28323-705e-4353-9626-a26d3efee56e,DISK], DatanodeInfoWithStorage[127.0.0.1:33384,DS-af4a7242-3224-4393-bc00-468f5e77cea6,DISK], DatanodeInfoWithStorage[127.0.0.1:40601,DS-fa0a38f0-1c38-4c2c-a523-eb77372ea30d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-934952550-172.17.0.20-1598418177859:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34951,DS-1f93a4cc-7aec-454d-9995-0ed4fbc7f6a4,DISK], DatanodeInfoWithStorage[127.0.0.1:39111,DS-ff869f07-4de8-48af-a418-5e1892d8ba1f,DISK], DatanodeInfoWithStorage[127.0.0.1:37495,DS-15deca20-da6e-4cd1-938e-c08662d3f1c2,DISK], DatanodeInfoWithStorage[127.0.0.1:42886,DS-54901267-f1e0-469c-af0d-9045c9bf0f9e,DISK], DatanodeInfoWithStorage[127.0.0.1:41526,DS-0fd3a03d-f9b8-40b2-8b5f-395489f24d6c,DISK], DatanodeInfoWithStorage[127.0.0.1:33041,DS-ffc28323-705e-4353-9626-a26d3efee56e,DISK], DatanodeInfoWithStorage[127.0.0.1:33384,DS-af4a7242-3224-4393-bc00-468f5e77cea6,DISK], DatanodeInfoWithStorage[127.0.0.1:40601,DS-fa0a38f0-1c38-4c2c-a523-eb77372ea30d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-543506398-172.17.0.20-1598418667054:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41427,DS-f4ebd254-7309-438b-a836-cfbf9eb6c8d0,DISK], DatanodeInfoWithStorage[127.0.0.1:34392,DS-8aa7de28-3b83-4656-8394-d5754b92d97a,DISK], DatanodeInfoWithStorage[127.0.0.1:46246,DS-67b3802a-6424-49a4-a9b2-99fd2392f563,DISK], DatanodeInfoWithStorage[127.0.0.1:44968,DS-be3bcb9f-d6e3-4065-8830-4b7d9de12fa7,DISK], DatanodeInfoWithStorage[127.0.0.1:46764,DS-516fbfc1-69e9-438e-94f8-082118def29e,DISK], DatanodeInfoWithStorage[127.0.0.1:42601,DS-3703d179-d569-4594-95cc-c9be125d3d62,DISK], DatanodeInfoWithStorage[127.0.0.1:45832,DS-8b60eabb-6bf9-4572-bca5-e16f9615e42e,DISK], DatanodeInfoWithStorage[127.0.0.1:37789,DS-74a7ad05-fa31-4246-9a9b-a5805ea84751,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-543506398-172.17.0.20-1598418667054:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41427,DS-f4ebd254-7309-438b-a836-cfbf9eb6c8d0,DISK], DatanodeInfoWithStorage[127.0.0.1:34392,DS-8aa7de28-3b83-4656-8394-d5754b92d97a,DISK], DatanodeInfoWithStorage[127.0.0.1:46246,DS-67b3802a-6424-49a4-a9b2-99fd2392f563,DISK], DatanodeInfoWithStorage[127.0.0.1:44968,DS-be3bcb9f-d6e3-4065-8830-4b7d9de12fa7,DISK], DatanodeInfoWithStorage[127.0.0.1:46764,DS-516fbfc1-69e9-438e-94f8-082118def29e,DISK], DatanodeInfoWithStorage[127.0.0.1:42601,DS-3703d179-d569-4594-95cc-c9be125d3d62,DISK], DatanodeInfoWithStorage[127.0.0.1:45832,DS-8b60eabb-6bf9-4572-bca5-e16f9615e42e,DISK], DatanodeInfoWithStorage[127.0.0.1:37789,DS-74a7ad05-fa31-4246-9a9b-a5805ea84751,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-319011113-172.17.0.20-1598419129871:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39761,DS-99f35cf0-c2a1-4e61-8edd-6c13ef12e356,DISK], DatanodeInfoWithStorage[127.0.0.1:39094,DS-b3bf3d10-54ab-48c8-ae91-4fb41b078924,DISK], DatanodeInfoWithStorage[127.0.0.1:42854,DS-13ac5ec2-64ef-4765-b2b6-1f1562590436,DISK], DatanodeInfoWithStorage[127.0.0.1:43774,DS-d32bca0d-45b3-43c3-8314-d505ed4b7e6f,DISK], DatanodeInfoWithStorage[127.0.0.1:37657,DS-b9d41561-1cb1-415e-88d8-6883a3bb044c,DISK], DatanodeInfoWithStorage[127.0.0.1:35172,DS-899c4103-ba8f-4071-8b7b-c8289f5d9c96,DISK], DatanodeInfoWithStorage[127.0.0.1:46872,DS-f714fdaa-cd90-4f0a-92cc-81fbdfb4be0b,DISK], DatanodeInfoWithStorage[127.0.0.1:35968,DS-bda5bcf6-1658-4fe8-a445-d654819197e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-319011113-172.17.0.20-1598419129871:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39761,DS-99f35cf0-c2a1-4e61-8edd-6c13ef12e356,DISK], DatanodeInfoWithStorage[127.0.0.1:39094,DS-b3bf3d10-54ab-48c8-ae91-4fb41b078924,DISK], DatanodeInfoWithStorage[127.0.0.1:42854,DS-13ac5ec2-64ef-4765-b2b6-1f1562590436,DISK], DatanodeInfoWithStorage[127.0.0.1:43774,DS-d32bca0d-45b3-43c3-8314-d505ed4b7e6f,DISK], DatanodeInfoWithStorage[127.0.0.1:37657,DS-b9d41561-1cb1-415e-88d8-6883a3bb044c,DISK], DatanodeInfoWithStorage[127.0.0.1:35172,DS-899c4103-ba8f-4071-8b7b-c8289f5d9c96,DISK], DatanodeInfoWithStorage[127.0.0.1:46872,DS-f714fdaa-cd90-4f0a-92cc-81fbdfb4be0b,DISK], DatanodeInfoWithStorage[127.0.0.1:35968,DS-bda5bcf6-1658-4fe8-a445-d654819197e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1634296099-172.17.0.20-1598419635700:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34051,DS-9b6835e5-3061-4062-b417-d6cd89b3fb26,DISK], DatanodeInfoWithStorage[127.0.0.1:36279,DS-db4cf001-f9c5-4032-97c0-7456b71b162e,DISK], DatanodeInfoWithStorage[127.0.0.1:41381,DS-134cbed9-9fd4-44b0-b0bc-a3a7f1bcf088,DISK], DatanodeInfoWithStorage[127.0.0.1:43753,DS-4c14a352-d6e9-4fb8-b4ad-a5766df3824a,DISK], DatanodeInfoWithStorage[127.0.0.1:36485,DS-83476b25-f906-4058-8455-ed4d25b8216c,DISK], DatanodeInfoWithStorage[127.0.0.1:40414,DS-58e72c4b-9308-4873-8ed0-595a0fdb1e18,DISK], DatanodeInfoWithStorage[127.0.0.1:35076,DS-6e31c78c-4fae-46b0-8745-9855a07b99a1,DISK], DatanodeInfoWithStorage[127.0.0.1:35141,DS-eb76a3af-f168-4309-9aa2-fecc5120f03a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1634296099-172.17.0.20-1598419635700:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34051,DS-9b6835e5-3061-4062-b417-d6cd89b3fb26,DISK], DatanodeInfoWithStorage[127.0.0.1:36279,DS-db4cf001-f9c5-4032-97c0-7456b71b162e,DISK], DatanodeInfoWithStorage[127.0.0.1:41381,DS-134cbed9-9fd4-44b0-b0bc-a3a7f1bcf088,DISK], DatanodeInfoWithStorage[127.0.0.1:43753,DS-4c14a352-d6e9-4fb8-b4ad-a5766df3824a,DISK], DatanodeInfoWithStorage[127.0.0.1:36485,DS-83476b25-f906-4058-8455-ed4d25b8216c,DISK], DatanodeInfoWithStorage[127.0.0.1:40414,DS-58e72c4b-9308-4873-8ed0-595a0fdb1e18,DISK], DatanodeInfoWithStorage[127.0.0.1:35076,DS-6e31c78c-4fae-46b0-8745-9855a07b99a1,DISK], DatanodeInfoWithStorage[127.0.0.1:35141,DS-eb76a3af-f168-4309-9aa2-fecc5120f03a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2144040771-172.17.0.20-1598420093607:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33949,DS-c3b864ca-2a82-4318-adea-c14a8ee31ab0,DISK], DatanodeInfoWithStorage[127.0.0.1:35661,DS-3f97446e-ef1b-42fa-bcd3-ef0a66bd4d14,DISK], DatanodeInfoWithStorage[127.0.0.1:34562,DS-d441bb7e-acc3-428f-9f97-6bb146c27673,DISK], DatanodeInfoWithStorage[127.0.0.1:38673,DS-4417bb94-f9b6-42eb-8443-2579804bc715,DISK], DatanodeInfoWithStorage[127.0.0.1:41377,DS-067b328e-1548-4fdb-b58f-aa16b0c8155b,DISK], DatanodeInfoWithStorage[127.0.0.1:35744,DS-945d7d57-3e48-486d-8642-a554871fd328,DISK], DatanodeInfoWithStorage[127.0.0.1:32834,DS-9065c5ad-b136-4088-ae57-d13d60b52505,DISK], DatanodeInfoWithStorage[127.0.0.1:44239,DS-363475ef-499c-4c7f-9863-80062ff867c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2144040771-172.17.0.20-1598420093607:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33949,DS-c3b864ca-2a82-4318-adea-c14a8ee31ab0,DISK], DatanodeInfoWithStorage[127.0.0.1:35661,DS-3f97446e-ef1b-42fa-bcd3-ef0a66bd4d14,DISK], DatanodeInfoWithStorage[127.0.0.1:34562,DS-d441bb7e-acc3-428f-9f97-6bb146c27673,DISK], DatanodeInfoWithStorage[127.0.0.1:38673,DS-4417bb94-f9b6-42eb-8443-2579804bc715,DISK], DatanodeInfoWithStorage[127.0.0.1:41377,DS-067b328e-1548-4fdb-b58f-aa16b0c8155b,DISK], DatanodeInfoWithStorage[127.0.0.1:35744,DS-945d7d57-3e48-486d-8642-a554871fd328,DISK], DatanodeInfoWithStorage[127.0.0.1:32834,DS-9065c5ad-b136-4088-ae57-d13d60b52505,DISK], DatanodeInfoWithStorage[127.0.0.1:44239,DS-363475ef-499c-4c7f-9863-80062ff867c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1915233081-172.17.0.20-1598420670253:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44739,DS-dbfd9ee7-65eb-41b7-8cff-08e67b0298cb,DISK], DatanodeInfoWithStorage[127.0.0.1:46438,DS-9a9c524f-afcf-4a91-b200-aba8b5b6f38c,DISK], DatanodeInfoWithStorage[127.0.0.1:41357,DS-795dc944-b16b-4793-862f-e0c13c7fbe98,DISK], DatanodeInfoWithStorage[127.0.0.1:37317,DS-c78065c5-8335-413f-92f0-38d9713e2b66,DISK], DatanodeInfoWithStorage[127.0.0.1:36086,DS-df23afdd-4df5-4f87-8221-989412c189cd,DISK], DatanodeInfoWithStorage[127.0.0.1:36979,DS-4274e915-771a-4a09-a4ec-939692a37946,DISK], DatanodeInfoWithStorage[127.0.0.1:46219,DS-82dda53b-9428-444c-96e5-e5a1c282e85c,DISK], DatanodeInfoWithStorage[127.0.0.1:41210,DS-6391238c-8c0e-488f-b5f9-f2c7292c8ad2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1915233081-172.17.0.20-1598420670253:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44739,DS-dbfd9ee7-65eb-41b7-8cff-08e67b0298cb,DISK], DatanodeInfoWithStorage[127.0.0.1:46438,DS-9a9c524f-afcf-4a91-b200-aba8b5b6f38c,DISK], DatanodeInfoWithStorage[127.0.0.1:41357,DS-795dc944-b16b-4793-862f-e0c13c7fbe98,DISK], DatanodeInfoWithStorage[127.0.0.1:37317,DS-c78065c5-8335-413f-92f0-38d9713e2b66,DISK], DatanodeInfoWithStorage[127.0.0.1:36086,DS-df23afdd-4df5-4f87-8221-989412c189cd,DISK], DatanodeInfoWithStorage[127.0.0.1:36979,DS-4274e915-771a-4a09-a4ec-939692a37946,DISK], DatanodeInfoWithStorage[127.0.0.1:46219,DS-82dda53b-9428-444c-96e5-e5a1c282e85c,DISK], DatanodeInfoWithStorage[127.0.0.1:41210,DS-6391238c-8c0e-488f-b5f9-f2c7292c8ad2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-482650479-172.17.0.20-1598421103799:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44920,DS-cf54ad65-be0b-4488-a97b-5c3cde72abd3,DISK], DatanodeInfoWithStorage[127.0.0.1:35305,DS-a63e3563-5ac6-46a3-9511-a88d06cc268a,DISK], DatanodeInfoWithStorage[127.0.0.1:34849,DS-f05f0355-83c4-4e5f-999a-3296a027ddc7,DISK], DatanodeInfoWithStorage[127.0.0.1:34441,DS-c1377907-df11-421f-ad59-97b7b5d94735,DISK], DatanodeInfoWithStorage[127.0.0.1:38622,DS-753ef2d0-6f61-4168-9e2d-53b6614dbc79,DISK], DatanodeInfoWithStorage[127.0.0.1:43803,DS-8f420797-7cb6-4a0c-a72d-7aac9bd71b33,DISK], DatanodeInfoWithStorage[127.0.0.1:38260,DS-7bcf72c3-8fa7-4cf0-9a11-e2c12d164305,DISK], DatanodeInfoWithStorage[127.0.0.1:45267,DS-bf9e57b0-d899-4f3a-84c9-7941f76a2538,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-482650479-172.17.0.20-1598421103799:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44920,DS-cf54ad65-be0b-4488-a97b-5c3cde72abd3,DISK], DatanodeInfoWithStorage[127.0.0.1:35305,DS-a63e3563-5ac6-46a3-9511-a88d06cc268a,DISK], DatanodeInfoWithStorage[127.0.0.1:34849,DS-f05f0355-83c4-4e5f-999a-3296a027ddc7,DISK], DatanodeInfoWithStorage[127.0.0.1:34441,DS-c1377907-df11-421f-ad59-97b7b5d94735,DISK], DatanodeInfoWithStorage[127.0.0.1:38622,DS-753ef2d0-6f61-4168-9e2d-53b6614dbc79,DISK], DatanodeInfoWithStorage[127.0.0.1:43803,DS-8f420797-7cb6-4a0c-a72d-7aac9bd71b33,DISK], DatanodeInfoWithStorage[127.0.0.1:38260,DS-7bcf72c3-8fa7-4cf0-9a11-e2c12d164305,DISK], DatanodeInfoWithStorage[127.0.0.1:45267,DS-bf9e57b0-d899-4f3a-84c9-7941f76a2538,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-284175058-172.17.0.20-1598421437056:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33040,DS-bbb21151-f4dd-4787-b492-b2e5d5e3af0b,DISK], DatanodeInfoWithStorage[127.0.0.1:45172,DS-89292f0d-9d7f-4309-b1b8-60272a906cbc,DISK], DatanodeInfoWithStorage[127.0.0.1:43806,DS-b3f2b6c6-b6f8-418b-848a-37c51a48670e,DISK], DatanodeInfoWithStorage[127.0.0.1:45968,DS-65ce0959-f0d4-40d9-89fe-058c8c0ba199,DISK], DatanodeInfoWithStorage[127.0.0.1:43171,DS-b91cc419-73a0-4e69-a2fb-410f2ef09a5d,DISK], DatanodeInfoWithStorage[127.0.0.1:38444,DS-9f1b68e8-479d-49ce-91aa-9e56cab08fba,DISK], DatanodeInfoWithStorage[127.0.0.1:34576,DS-0791c24e-2702-4c21-9a8a-0296593ff44b,DISK], DatanodeInfoWithStorage[127.0.0.1:41448,DS-8cd10bbc-1e69-4c8f-ab63-2bfcccb54219,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-284175058-172.17.0.20-1598421437056:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33040,DS-bbb21151-f4dd-4787-b492-b2e5d5e3af0b,DISK], DatanodeInfoWithStorage[127.0.0.1:45172,DS-89292f0d-9d7f-4309-b1b8-60272a906cbc,DISK], DatanodeInfoWithStorage[127.0.0.1:43806,DS-b3f2b6c6-b6f8-418b-848a-37c51a48670e,DISK], DatanodeInfoWithStorage[127.0.0.1:45968,DS-65ce0959-f0d4-40d9-89fe-058c8c0ba199,DISK], DatanodeInfoWithStorage[127.0.0.1:43171,DS-b91cc419-73a0-4e69-a2fb-410f2ef09a5d,DISK], DatanodeInfoWithStorage[127.0.0.1:38444,DS-9f1b68e8-479d-49ce-91aa-9e56cab08fba,DISK], DatanodeInfoWithStorage[127.0.0.1:34576,DS-0791c24e-2702-4c21-9a8a-0296593ff44b,DISK], DatanodeInfoWithStorage[127.0.0.1:41448,DS-8cd10bbc-1e69-4c8f-ab63-2bfcccb54219,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-77787526-172.17.0.20-1598421860407:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34844,DS-a1106649-3f99-48b9-8fc5-0246c1f35f33,DISK], DatanodeInfoWithStorage[127.0.0.1:38212,DS-f10a0f6f-33c3-4161-8161-b2ad168b57b4,DISK], DatanodeInfoWithStorage[127.0.0.1:35568,DS-e4c978cd-6590-4f78-bdb7-8224ebf50e31,DISK], DatanodeInfoWithStorage[127.0.0.1:36846,DS-b41aa1f6-a3a4-48a4-9c98-1a2690b235bc,DISK], DatanodeInfoWithStorage[127.0.0.1:39338,DS-cf4c831f-d3e6-445c-941c-6f5f569df6d7,DISK], DatanodeInfoWithStorage[127.0.0.1:36379,DS-9ff53cc9-55b5-4f81-8f34-1702a733ed22,DISK], DatanodeInfoWithStorage[127.0.0.1:40573,DS-046da951-0405-424f-93ab-c65ab69ea03a,DISK], DatanodeInfoWithStorage[127.0.0.1:39061,DS-577023a3-c60f-426f-9739-fd84943cc684,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-77787526-172.17.0.20-1598421860407:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34844,DS-a1106649-3f99-48b9-8fc5-0246c1f35f33,DISK], DatanodeInfoWithStorage[127.0.0.1:38212,DS-f10a0f6f-33c3-4161-8161-b2ad168b57b4,DISK], DatanodeInfoWithStorage[127.0.0.1:35568,DS-e4c978cd-6590-4f78-bdb7-8224ebf50e31,DISK], DatanodeInfoWithStorage[127.0.0.1:36846,DS-b41aa1f6-a3a4-48a4-9c98-1a2690b235bc,DISK], DatanodeInfoWithStorage[127.0.0.1:39338,DS-cf4c831f-d3e6-445c-941c-6f5f569df6d7,DISK], DatanodeInfoWithStorage[127.0.0.1:36379,DS-9ff53cc9-55b5-4f81-8f34-1702a733ed22,DISK], DatanodeInfoWithStorage[127.0.0.1:40573,DS-046da951-0405-424f-93ab-c65ab69ea03a,DISK], DatanodeInfoWithStorage[127.0.0.1:39061,DS-577023a3-c60f-426f-9739-fd84943cc684,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-643640609-172.17.0.20-1598421958195:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42233,DS-9979d70c-757d-4060-bd38-08565bddd8ee,DISK], DatanodeInfoWithStorage[127.0.0.1:46061,DS-31e7283b-5640-450d-af46-8a863b8ccfad,DISK], DatanodeInfoWithStorage[127.0.0.1:39005,DS-1222647e-c6b7-4f11-a43b-31297f6c9e77,DISK], DatanodeInfoWithStorage[127.0.0.1:34676,DS-3a8e302d-3334-4cc3-a53e-7b78416aad63,DISK], DatanodeInfoWithStorage[127.0.0.1:34479,DS-59737d34-1039-49ce-be6e-8bcf057e6b19,DISK], DatanodeInfoWithStorage[127.0.0.1:38036,DS-d6181282-cf71-4e6c-b868-25e7d5156aaa,DISK], DatanodeInfoWithStorage[127.0.0.1:34802,DS-4b66b9d5-3c3b-480b-905f-411417143d21,DISK], DatanodeInfoWithStorage[127.0.0.1:41221,DS-51392676-55bd-4c31-89c3-7e5e89af19e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-643640609-172.17.0.20-1598421958195:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42233,DS-9979d70c-757d-4060-bd38-08565bddd8ee,DISK], DatanodeInfoWithStorage[127.0.0.1:46061,DS-31e7283b-5640-450d-af46-8a863b8ccfad,DISK], DatanodeInfoWithStorage[127.0.0.1:39005,DS-1222647e-c6b7-4f11-a43b-31297f6c9e77,DISK], DatanodeInfoWithStorage[127.0.0.1:34676,DS-3a8e302d-3334-4cc3-a53e-7b78416aad63,DISK], DatanodeInfoWithStorage[127.0.0.1:34479,DS-59737d34-1039-49ce-be6e-8bcf057e6b19,DISK], DatanodeInfoWithStorage[127.0.0.1:38036,DS-d6181282-cf71-4e6c-b868-25e7d5156aaa,DISK], DatanodeInfoWithStorage[127.0.0.1:34802,DS-4b66b9d5-3c3b-480b-905f-411417143d21,DISK], DatanodeInfoWithStorage[127.0.0.1:41221,DS-51392676-55bd-4c31-89c3-7e5e89af19e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1700410015-172.17.0.20-1598422208593:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41914,DS-425e61c0-e079-4152-8d75-563f56b44eb7,DISK], DatanodeInfoWithStorage[127.0.0.1:46300,DS-b3b933d0-c98b-4e19-8bb7-366b2b410d2d,DISK], DatanodeInfoWithStorage[127.0.0.1:46662,DS-e35d6b84-07ad-4c20-abb7-8e8b25606e24,DISK], DatanodeInfoWithStorage[127.0.0.1:37102,DS-66a6df43-c424-483e-a156-fea84c94232e,DISK], DatanodeInfoWithStorage[127.0.0.1:34726,DS-077d1615-c09a-4fc2-bd04-9c95f0e41225,DISK], DatanodeInfoWithStorage[127.0.0.1:37556,DS-fa74cfc4-d74f-4226-a19a-7e2bd1d47786,DISK], DatanodeInfoWithStorage[127.0.0.1:37860,DS-3bb54b76-62b2-4472-a3de-b71f14a10326,DISK], DatanodeInfoWithStorage[127.0.0.1:40760,DS-e1c9a657-93e4-4e6a-b6ad-85ca5fde4eed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1700410015-172.17.0.20-1598422208593:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41914,DS-425e61c0-e079-4152-8d75-563f56b44eb7,DISK], DatanodeInfoWithStorage[127.0.0.1:46300,DS-b3b933d0-c98b-4e19-8bb7-366b2b410d2d,DISK], DatanodeInfoWithStorage[127.0.0.1:46662,DS-e35d6b84-07ad-4c20-abb7-8e8b25606e24,DISK], DatanodeInfoWithStorage[127.0.0.1:37102,DS-66a6df43-c424-483e-a156-fea84c94232e,DISK], DatanodeInfoWithStorage[127.0.0.1:34726,DS-077d1615-c09a-4fc2-bd04-9c95f0e41225,DISK], DatanodeInfoWithStorage[127.0.0.1:37556,DS-fa74cfc4-d74f-4226-a19a-7e2bd1d47786,DISK], DatanodeInfoWithStorage[127.0.0.1:37860,DS-3bb54b76-62b2-4472-a3de-b71f14a10326,DISK], DatanodeInfoWithStorage[127.0.0.1:40760,DS-e1c9a657-93e4-4e6a-b6ad-85ca5fde4eed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-853819167-172.17.0.20-1598422348696:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45943,DS-b69ad852-99d0-481b-a04f-7555e0b65488,DISK], DatanodeInfoWithStorage[127.0.0.1:37586,DS-d2ed6275-7706-4957-b082-a62218ec8c4a,DISK], DatanodeInfoWithStorage[127.0.0.1:33244,DS-237b39df-6eec-46c8-83f4-d20f26d5c0cf,DISK], DatanodeInfoWithStorage[127.0.0.1:34170,DS-27447899-7665-406f-989b-c1b81a9a8abb,DISK], DatanodeInfoWithStorage[127.0.0.1:33080,DS-b8d4f13b-31b5-42c8-a690-aab93524ae98,DISK], DatanodeInfoWithStorage[127.0.0.1:42310,DS-77fc2b2f-c8c6-48e9-b0a4-741a9a042f9e,DISK], DatanodeInfoWithStorage[127.0.0.1:43398,DS-360da0ef-6da8-4e3c-a124-0489c57ff7ec,DISK], DatanodeInfoWithStorage[127.0.0.1:43043,DS-c6b36f44-4a12-4f8a-8450-4cff806e98df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-853819167-172.17.0.20-1598422348696:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45943,DS-b69ad852-99d0-481b-a04f-7555e0b65488,DISK], DatanodeInfoWithStorage[127.0.0.1:37586,DS-d2ed6275-7706-4957-b082-a62218ec8c4a,DISK], DatanodeInfoWithStorage[127.0.0.1:33244,DS-237b39df-6eec-46c8-83f4-d20f26d5c0cf,DISK], DatanodeInfoWithStorage[127.0.0.1:34170,DS-27447899-7665-406f-989b-c1b81a9a8abb,DISK], DatanodeInfoWithStorage[127.0.0.1:33080,DS-b8d4f13b-31b5-42c8-a690-aab93524ae98,DISK], DatanodeInfoWithStorage[127.0.0.1:42310,DS-77fc2b2f-c8c6-48e9-b0a4-741a9a042f9e,DISK], DatanodeInfoWithStorage[127.0.0.1:43398,DS-360da0ef-6da8-4e3c-a124-0489c57ff7ec,DISK], DatanodeInfoWithStorage[127.0.0.1:43043,DS-c6b36f44-4a12-4f8a-8450-4cff806e98df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1143398782-172.17.0.20-1598422481489:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46415,DS-52ccd8aa-1d37-4e39-a98e-da91629b93c8,DISK], DatanodeInfoWithStorage[127.0.0.1:37809,DS-ac11fd03-adc3-42ae-b320-7906ca643cbd,DISK], DatanodeInfoWithStorage[127.0.0.1:43647,DS-8410ab18-d1e7-4405-b56a-6f970fa1b257,DISK], DatanodeInfoWithStorage[127.0.0.1:45804,DS-2e1bad41-e5f0-4277-b004-289aa427055a,DISK], DatanodeInfoWithStorage[127.0.0.1:38057,DS-9b5cc593-86e1-4709-9de9-6ff035cc2587,DISK], DatanodeInfoWithStorage[127.0.0.1:46794,DS-94ffeba8-b198-4bda-bdf2-0ba6acd294f1,DISK], DatanodeInfoWithStorage[127.0.0.1:34953,DS-1219724a-0bac-4cd6-8d6e-2881b2a17cde,DISK], DatanodeInfoWithStorage[127.0.0.1:34693,DS-f2dcc569-83ce-447c-9be0-f770ec2101f4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1143398782-172.17.0.20-1598422481489:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46415,DS-52ccd8aa-1d37-4e39-a98e-da91629b93c8,DISK], DatanodeInfoWithStorage[127.0.0.1:37809,DS-ac11fd03-adc3-42ae-b320-7906ca643cbd,DISK], DatanodeInfoWithStorage[127.0.0.1:43647,DS-8410ab18-d1e7-4405-b56a-6f970fa1b257,DISK], DatanodeInfoWithStorage[127.0.0.1:45804,DS-2e1bad41-e5f0-4277-b004-289aa427055a,DISK], DatanodeInfoWithStorage[127.0.0.1:38057,DS-9b5cc593-86e1-4709-9de9-6ff035cc2587,DISK], DatanodeInfoWithStorage[127.0.0.1:46794,DS-94ffeba8-b198-4bda-bdf2-0ba6acd294f1,DISK], DatanodeInfoWithStorage[127.0.0.1:34953,DS-1219724a-0bac-4cd6-8d6e-2881b2a17cde,DISK], DatanodeInfoWithStorage[127.0.0.1:34693,DS-f2dcc569-83ce-447c-9be0-f770ec2101f4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1203235751-172.17.0.20-1598422680713:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41466,DS-edc76efe-9070-4472-9e70-3a7e0ebf6240,DISK], DatanodeInfoWithStorage[127.0.0.1:36795,DS-bbfae31d-58fc-4b1b-8fae-9b3ef6ed8a27,DISK], DatanodeInfoWithStorage[127.0.0.1:41048,DS-fb99ac25-6bb1-4c2e-a557-aa03cc77db2c,DISK], DatanodeInfoWithStorage[127.0.0.1:38867,DS-fc13f447-d7a7-43d2-ac5d-1178f151102e,DISK], DatanodeInfoWithStorage[127.0.0.1:42652,DS-772a0f49-52e6-47e3-9b46-6bd51cf3d311,DISK], DatanodeInfoWithStorage[127.0.0.1:43281,DS-be80bf10-3be5-4426-904e-1faa4cb95eef,DISK], DatanodeInfoWithStorage[127.0.0.1:43027,DS-80a72da9-66ad-4ef7-8b97-50a982683618,DISK], DatanodeInfoWithStorage[127.0.0.1:35679,DS-08ec4d83-e01f-400f-a8bc-d0e7ee208cd8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1203235751-172.17.0.20-1598422680713:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41466,DS-edc76efe-9070-4472-9e70-3a7e0ebf6240,DISK], DatanodeInfoWithStorage[127.0.0.1:36795,DS-bbfae31d-58fc-4b1b-8fae-9b3ef6ed8a27,DISK], DatanodeInfoWithStorage[127.0.0.1:41048,DS-fb99ac25-6bb1-4c2e-a557-aa03cc77db2c,DISK], DatanodeInfoWithStorage[127.0.0.1:38867,DS-fc13f447-d7a7-43d2-ac5d-1178f151102e,DISK], DatanodeInfoWithStorage[127.0.0.1:42652,DS-772a0f49-52e6-47e3-9b46-6bd51cf3d311,DISK], DatanodeInfoWithStorage[127.0.0.1:43281,DS-be80bf10-3be5-4426-904e-1faa4cb95eef,DISK], DatanodeInfoWithStorage[127.0.0.1:43027,DS-80a72da9-66ad-4ef7-8b97-50a982683618,DISK], DatanodeInfoWithStorage[127.0.0.1:35679,DS-08ec4d83-e01f-400f-a8bc-d0e7ee208cd8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5156
