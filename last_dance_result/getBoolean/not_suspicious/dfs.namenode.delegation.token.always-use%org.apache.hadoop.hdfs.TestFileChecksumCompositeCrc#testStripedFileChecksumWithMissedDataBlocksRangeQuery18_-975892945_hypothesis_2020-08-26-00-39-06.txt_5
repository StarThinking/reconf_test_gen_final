reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1505955020-172.17.0.7-1598403379623:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35219,DS-d76aa466-23a0-40b6-b52b-790a4f4a0ef1,DISK], DatanodeInfoWithStorage[127.0.0.1:40592,DS-3e6850af-ade3-45e1-a68e-218988f857f5,DISK], DatanodeInfoWithStorage[127.0.0.1:35390,DS-f956b3d6-77ca-4d09-8ba6-f22bf480fe2c,DISK], DatanodeInfoWithStorage[127.0.0.1:41135,DS-b9efdf64-3925-4112-b7a7-32fd2d40768a,DISK], DatanodeInfoWithStorage[127.0.0.1:34443,DS-a8e4e96f-79da-43db-b016-6726bfadd15f,DISK], DatanodeInfoWithStorage[127.0.0.1:43709,DS-e62905b6-57ca-4044-bd4e-9249a80039dc,DISK], DatanodeInfoWithStorage[127.0.0.1:43233,DS-11081360-d2bb-4b5f-b60c-4becb5bb273f,DISK], DatanodeInfoWithStorage[127.0.0.1:46810,DS-93494e10-7d1d-4b94-a63e-007a2cad5010,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1505955020-172.17.0.7-1598403379623:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35219,DS-d76aa466-23a0-40b6-b52b-790a4f4a0ef1,DISK], DatanodeInfoWithStorage[127.0.0.1:40592,DS-3e6850af-ade3-45e1-a68e-218988f857f5,DISK], DatanodeInfoWithStorage[127.0.0.1:35390,DS-f956b3d6-77ca-4d09-8ba6-f22bf480fe2c,DISK], DatanodeInfoWithStorage[127.0.0.1:41135,DS-b9efdf64-3925-4112-b7a7-32fd2d40768a,DISK], DatanodeInfoWithStorage[127.0.0.1:34443,DS-a8e4e96f-79da-43db-b016-6726bfadd15f,DISK], DatanodeInfoWithStorage[127.0.0.1:43709,DS-e62905b6-57ca-4044-bd4e-9249a80039dc,DISK], DatanodeInfoWithStorage[127.0.0.1:43233,DS-11081360-d2bb-4b5f-b60c-4becb5bb273f,DISK], DatanodeInfoWithStorage[127.0.0.1:46810,DS-93494e10-7d1d-4b94-a63e-007a2cad5010,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-660174051-172.17.0.7-1598403667547:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37810,DS-619a262c-5c89-4475-9c71-282ac097620e,DISK], DatanodeInfoWithStorage[127.0.0.1:39229,DS-002e233a-0827-41ad-be31-c8222f48a300,DISK], DatanodeInfoWithStorage[127.0.0.1:34958,DS-5b5322c9-6b07-44ac-aae1-b9b5878ef7e6,DISK], DatanodeInfoWithStorage[127.0.0.1:35763,DS-246bf2e7-7552-4f96-8a09-da805886e52a,DISK], DatanodeInfoWithStorage[127.0.0.1:34308,DS-5822cfee-522b-4f68-92db-ebd4fe093551,DISK], DatanodeInfoWithStorage[127.0.0.1:39351,DS-b4eed39e-2b58-436b-af8e-6383fa2478b5,DISK], DatanodeInfoWithStorage[127.0.0.1:34932,DS-8c3696fd-ce1c-4e8a-a7be-3dbd81f2f426,DISK], DatanodeInfoWithStorage[127.0.0.1:42463,DS-833de33b-96e7-4d52-ba65-3630742deb8a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-660174051-172.17.0.7-1598403667547:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37810,DS-619a262c-5c89-4475-9c71-282ac097620e,DISK], DatanodeInfoWithStorage[127.0.0.1:39229,DS-002e233a-0827-41ad-be31-c8222f48a300,DISK], DatanodeInfoWithStorage[127.0.0.1:34958,DS-5b5322c9-6b07-44ac-aae1-b9b5878ef7e6,DISK], DatanodeInfoWithStorage[127.0.0.1:35763,DS-246bf2e7-7552-4f96-8a09-da805886e52a,DISK], DatanodeInfoWithStorage[127.0.0.1:34308,DS-5822cfee-522b-4f68-92db-ebd4fe093551,DISK], DatanodeInfoWithStorage[127.0.0.1:39351,DS-b4eed39e-2b58-436b-af8e-6383fa2478b5,DISK], DatanodeInfoWithStorage[127.0.0.1:34932,DS-8c3696fd-ce1c-4e8a-a7be-3dbd81f2f426,DISK], DatanodeInfoWithStorage[127.0.0.1:42463,DS-833de33b-96e7-4d52-ba65-3630742deb8a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-910097189-172.17.0.7-1598404347470:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44104,DS-72d3f3a0-21c8-4e0d-bc11-dabb88abfa05,DISK], DatanodeInfoWithStorage[127.0.0.1:44486,DS-92138284-d859-4cdb-9b80-4f9dd0871853,DISK], DatanodeInfoWithStorage[127.0.0.1:35226,DS-6cd7d030-cabc-460f-b614-567b6eb81b40,DISK], DatanodeInfoWithStorage[127.0.0.1:38344,DS-29ff14b3-a499-463c-b25c-fa380b47d7c6,DISK], DatanodeInfoWithStorage[127.0.0.1:42762,DS-68a95b82-9155-41da-8c6a-b1db308f51db,DISK], DatanodeInfoWithStorage[127.0.0.1:45144,DS-f9af41eb-2fdc-450a-a6be-dd1fe3d2bef0,DISK], DatanodeInfoWithStorage[127.0.0.1:35619,DS-10a73b1a-1c69-4c6f-89c3-74ae06a2a4c7,DISK], DatanodeInfoWithStorage[127.0.0.1:35527,DS-c1bc55f1-1625-4561-9a49-1ef9aecfa9a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-910097189-172.17.0.7-1598404347470:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44104,DS-72d3f3a0-21c8-4e0d-bc11-dabb88abfa05,DISK], DatanodeInfoWithStorage[127.0.0.1:44486,DS-92138284-d859-4cdb-9b80-4f9dd0871853,DISK], DatanodeInfoWithStorage[127.0.0.1:35226,DS-6cd7d030-cabc-460f-b614-567b6eb81b40,DISK], DatanodeInfoWithStorage[127.0.0.1:38344,DS-29ff14b3-a499-463c-b25c-fa380b47d7c6,DISK], DatanodeInfoWithStorage[127.0.0.1:42762,DS-68a95b82-9155-41da-8c6a-b1db308f51db,DISK], DatanodeInfoWithStorage[127.0.0.1:45144,DS-f9af41eb-2fdc-450a-a6be-dd1fe3d2bef0,DISK], DatanodeInfoWithStorage[127.0.0.1:35619,DS-10a73b1a-1c69-4c6f-89c3-74ae06a2a4c7,DISK], DatanodeInfoWithStorage[127.0.0.1:35527,DS-c1bc55f1-1625-4561-9a49-1ef9aecfa9a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2138241428-172.17.0.7-1598404634318:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41318,DS-000642da-7dcf-4246-bad1-5b7b3fde6971,DISK], DatanodeInfoWithStorage[127.0.0.1:43706,DS-8ecf95a3-34e1-423c-90c1-3b8596e1222b,DISK], DatanodeInfoWithStorage[127.0.0.1:45265,DS-3f8e368e-5df4-4e17-b004-029a9c4f86cb,DISK], DatanodeInfoWithStorage[127.0.0.1:40517,DS-83c72601-fc5f-4e69-ada4-77ce35680839,DISK], DatanodeInfoWithStorage[127.0.0.1:37031,DS-1f867b52-f865-4898-83ab-9a279a90cb8b,DISK], DatanodeInfoWithStorage[127.0.0.1:42335,DS-4b11846a-0101-40b4-b636-ae2d2af274c4,DISK], DatanodeInfoWithStorage[127.0.0.1:37888,DS-906d7c8b-4cae-4373-b76d-f61b248dfa90,DISK], DatanodeInfoWithStorage[127.0.0.1:33772,DS-834f1f3e-2ce9-46c5-bd66-0d888a4590bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2138241428-172.17.0.7-1598404634318:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41318,DS-000642da-7dcf-4246-bad1-5b7b3fde6971,DISK], DatanodeInfoWithStorage[127.0.0.1:43706,DS-8ecf95a3-34e1-423c-90c1-3b8596e1222b,DISK], DatanodeInfoWithStorage[127.0.0.1:45265,DS-3f8e368e-5df4-4e17-b004-029a9c4f86cb,DISK], DatanodeInfoWithStorage[127.0.0.1:40517,DS-83c72601-fc5f-4e69-ada4-77ce35680839,DISK], DatanodeInfoWithStorage[127.0.0.1:37031,DS-1f867b52-f865-4898-83ab-9a279a90cb8b,DISK], DatanodeInfoWithStorage[127.0.0.1:42335,DS-4b11846a-0101-40b4-b636-ae2d2af274c4,DISK], DatanodeInfoWithStorage[127.0.0.1:37888,DS-906d7c8b-4cae-4373-b76d-f61b248dfa90,DISK], DatanodeInfoWithStorage[127.0.0.1:33772,DS-834f1f3e-2ce9-46c5-bd66-0d888a4590bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-456783354-172.17.0.7-1598405442782:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32888,DS-97e6edb6-a44a-40cb-8bb0-9a4f4eb01e7a,DISK], DatanodeInfoWithStorage[127.0.0.1:38461,DS-83824928-9a1f-48e2-a0d5-b470357bfa71,DISK], DatanodeInfoWithStorage[127.0.0.1:41575,DS-67b98ca2-5eda-43b6-aae1-6849d69eb9d4,DISK], DatanodeInfoWithStorage[127.0.0.1:36995,DS-342aa46a-e9fc-40b1-bede-5a0e714de88b,DISK], DatanodeInfoWithStorage[127.0.0.1:46529,DS-c0c6d2ab-2f9d-4531-98b4-b428b7e381e7,DISK], DatanodeInfoWithStorage[127.0.0.1:34231,DS-8f9f72eb-9860-4a1e-a22b-7f2c5978b26d,DISK], DatanodeInfoWithStorage[127.0.0.1:45906,DS-e5f2f775-1013-49f1-abe6-bd7b31774663,DISK], DatanodeInfoWithStorage[127.0.0.1:35802,DS-2c363152-7549-4c68-a46d-fb42af414852,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-456783354-172.17.0.7-1598405442782:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32888,DS-97e6edb6-a44a-40cb-8bb0-9a4f4eb01e7a,DISK], DatanodeInfoWithStorage[127.0.0.1:38461,DS-83824928-9a1f-48e2-a0d5-b470357bfa71,DISK], DatanodeInfoWithStorage[127.0.0.1:41575,DS-67b98ca2-5eda-43b6-aae1-6849d69eb9d4,DISK], DatanodeInfoWithStorage[127.0.0.1:36995,DS-342aa46a-e9fc-40b1-bede-5a0e714de88b,DISK], DatanodeInfoWithStorage[127.0.0.1:46529,DS-c0c6d2ab-2f9d-4531-98b4-b428b7e381e7,DISK], DatanodeInfoWithStorage[127.0.0.1:34231,DS-8f9f72eb-9860-4a1e-a22b-7f2c5978b26d,DISK], DatanodeInfoWithStorage[127.0.0.1:45906,DS-e5f2f775-1013-49f1-abe6-bd7b31774663,DISK], DatanodeInfoWithStorage[127.0.0.1:35802,DS-2c363152-7549-4c68-a46d-fb42af414852,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1305176402-172.17.0.7-1598405777468:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34687,DS-9dd740c4-44b5-4df1-9610-6a6dceb53b1f,DISK], DatanodeInfoWithStorage[127.0.0.1:39364,DS-3e03a956-4719-4fc7-b364-ff06bd8c5962,DISK], DatanodeInfoWithStorage[127.0.0.1:36401,DS-029bbcbf-872e-4871-bb30-1ca046944f21,DISK], DatanodeInfoWithStorage[127.0.0.1:33714,DS-4a10857b-748e-4709-a7b4-6704b3779628,DISK], DatanodeInfoWithStorage[127.0.0.1:45635,DS-288306c7-bbf8-4f3e-b14e-8147bb2a5741,DISK], DatanodeInfoWithStorage[127.0.0.1:40043,DS-1aa55c22-3168-458b-b63a-15bf8eb832d4,DISK], DatanodeInfoWithStorage[127.0.0.1:44622,DS-912d15db-213b-46f7-9780-b50d6671539e,DISK], DatanodeInfoWithStorage[127.0.0.1:35405,DS-090e6c85-25a3-4089-ad81-17e01d14a46c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1305176402-172.17.0.7-1598405777468:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34687,DS-9dd740c4-44b5-4df1-9610-6a6dceb53b1f,DISK], DatanodeInfoWithStorage[127.0.0.1:39364,DS-3e03a956-4719-4fc7-b364-ff06bd8c5962,DISK], DatanodeInfoWithStorage[127.0.0.1:36401,DS-029bbcbf-872e-4871-bb30-1ca046944f21,DISK], DatanodeInfoWithStorage[127.0.0.1:33714,DS-4a10857b-748e-4709-a7b4-6704b3779628,DISK], DatanodeInfoWithStorage[127.0.0.1:45635,DS-288306c7-bbf8-4f3e-b14e-8147bb2a5741,DISK], DatanodeInfoWithStorage[127.0.0.1:40043,DS-1aa55c22-3168-458b-b63a-15bf8eb832d4,DISK], DatanodeInfoWithStorage[127.0.0.1:44622,DS-912d15db-213b-46f7-9780-b50d6671539e,DISK], DatanodeInfoWithStorage[127.0.0.1:35405,DS-090e6c85-25a3-4089-ad81-17e01d14a46c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1315948489-172.17.0.7-1598405852414:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33230,DS-9e194214-1cf6-4405-b16c-c35782da2c7f,DISK], DatanodeInfoWithStorage[127.0.0.1:45834,DS-1754ee36-481f-4002-8ad9-0b1a2523d59a,DISK], DatanodeInfoWithStorage[127.0.0.1:38111,DS-168a0770-8219-45dc-9c3e-d25aec49c8f9,DISK], DatanodeInfoWithStorage[127.0.0.1:34019,DS-ae4ae932-3f12-488b-bee6-a118e22085f2,DISK], DatanodeInfoWithStorage[127.0.0.1:43488,DS-a5805d60-9af8-4052-bf29-e42a4c730084,DISK], DatanodeInfoWithStorage[127.0.0.1:43873,DS-ef01d242-3a1d-4626-b870-58a608e3422a,DISK], DatanodeInfoWithStorage[127.0.0.1:36687,DS-0a0ef97f-3adb-4914-b7c3-a14d914e7eba,DISK], DatanodeInfoWithStorage[127.0.0.1:39964,DS-46a7ba65-cd28-48f9-afa8-906bc05e25a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1315948489-172.17.0.7-1598405852414:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33230,DS-9e194214-1cf6-4405-b16c-c35782da2c7f,DISK], DatanodeInfoWithStorage[127.0.0.1:45834,DS-1754ee36-481f-4002-8ad9-0b1a2523d59a,DISK], DatanodeInfoWithStorage[127.0.0.1:38111,DS-168a0770-8219-45dc-9c3e-d25aec49c8f9,DISK], DatanodeInfoWithStorage[127.0.0.1:34019,DS-ae4ae932-3f12-488b-bee6-a118e22085f2,DISK], DatanodeInfoWithStorage[127.0.0.1:43488,DS-a5805d60-9af8-4052-bf29-e42a4c730084,DISK], DatanodeInfoWithStorage[127.0.0.1:43873,DS-ef01d242-3a1d-4626-b870-58a608e3422a,DISK], DatanodeInfoWithStorage[127.0.0.1:36687,DS-0a0ef97f-3adb-4914-b7c3-a14d914e7eba,DISK], DatanodeInfoWithStorage[127.0.0.1:39964,DS-46a7ba65-cd28-48f9-afa8-906bc05e25a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1384912952-172.17.0.7-1598406111849:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36609,DS-4dc0307e-7977-4f42-8198-afea112576ea,DISK], DatanodeInfoWithStorage[127.0.0.1:34336,DS-8df7e9aa-a555-4a90-a969-a58b1baaea5b,DISK], DatanodeInfoWithStorage[127.0.0.1:45590,DS-f9d15176-8292-4809-9525-28a9199f6a18,DISK], DatanodeInfoWithStorage[127.0.0.1:34528,DS-2f0eb71b-89fe-4d81-9fe1-8f1e9c92594a,DISK], DatanodeInfoWithStorage[127.0.0.1:41598,DS-c43de48a-3302-40c8-ae83-984681761145,DISK], DatanodeInfoWithStorage[127.0.0.1:41987,DS-3f99dee6-e998-4307-961f-def355fb2868,DISK], DatanodeInfoWithStorage[127.0.0.1:34148,DS-45a7ba74-be7f-4225-8945-18b7dbda4a66,DISK], DatanodeInfoWithStorage[127.0.0.1:40149,DS-66706baf-0666-4574-9cd0-87a02da8372a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1384912952-172.17.0.7-1598406111849:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36609,DS-4dc0307e-7977-4f42-8198-afea112576ea,DISK], DatanodeInfoWithStorage[127.0.0.1:34336,DS-8df7e9aa-a555-4a90-a969-a58b1baaea5b,DISK], DatanodeInfoWithStorage[127.0.0.1:45590,DS-f9d15176-8292-4809-9525-28a9199f6a18,DISK], DatanodeInfoWithStorage[127.0.0.1:34528,DS-2f0eb71b-89fe-4d81-9fe1-8f1e9c92594a,DISK], DatanodeInfoWithStorage[127.0.0.1:41598,DS-c43de48a-3302-40c8-ae83-984681761145,DISK], DatanodeInfoWithStorage[127.0.0.1:41987,DS-3f99dee6-e998-4307-961f-def355fb2868,DISK], DatanodeInfoWithStorage[127.0.0.1:34148,DS-45a7ba74-be7f-4225-8945-18b7dbda4a66,DISK], DatanodeInfoWithStorage[127.0.0.1:40149,DS-66706baf-0666-4574-9cd0-87a02da8372a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-821958577-172.17.0.7-1598406256000:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44985,DS-afec8831-216c-4899-baaa-a9987175f49d,DISK], DatanodeInfoWithStorage[127.0.0.1:40612,DS-c763ada1-f2a9-43d9-8a68-c58e1127384b,DISK], DatanodeInfoWithStorage[127.0.0.1:43243,DS-a036b025-c6fc-4e4e-89bc-5de39786093f,DISK], DatanodeInfoWithStorage[127.0.0.1:41980,DS-2d3dcea6-053c-48c3-84fd-ca75aac93a70,DISK], DatanodeInfoWithStorage[127.0.0.1:33252,DS-f4c299b1-c37b-44be-af4d-cd410bfcc83b,DISK], DatanodeInfoWithStorage[127.0.0.1:38156,DS-f171616c-118e-46bf-bd42-e0ae9cbba94c,DISK], DatanodeInfoWithStorage[127.0.0.1:34159,DS-5355d72d-6479-424c-9eed-122194360a4e,DISK], DatanodeInfoWithStorage[127.0.0.1:46745,DS-e6301640-c2fd-44ec-a475-a6aaa14b79aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-821958577-172.17.0.7-1598406256000:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44985,DS-afec8831-216c-4899-baaa-a9987175f49d,DISK], DatanodeInfoWithStorage[127.0.0.1:40612,DS-c763ada1-f2a9-43d9-8a68-c58e1127384b,DISK], DatanodeInfoWithStorage[127.0.0.1:43243,DS-a036b025-c6fc-4e4e-89bc-5de39786093f,DISK], DatanodeInfoWithStorage[127.0.0.1:41980,DS-2d3dcea6-053c-48c3-84fd-ca75aac93a70,DISK], DatanodeInfoWithStorage[127.0.0.1:33252,DS-f4c299b1-c37b-44be-af4d-cd410bfcc83b,DISK], DatanodeInfoWithStorage[127.0.0.1:38156,DS-f171616c-118e-46bf-bd42-e0ae9cbba94c,DISK], DatanodeInfoWithStorage[127.0.0.1:34159,DS-5355d72d-6479-424c-9eed-122194360a4e,DISK], DatanodeInfoWithStorage[127.0.0.1:46745,DS-e6301640-c2fd-44ec-a475-a6aaa14b79aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-172561729-172.17.0.7-1598406291724:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34919,DS-df05b345-a237-4d69-9d86-5c7fcfd565d6,DISK], DatanodeInfoWithStorage[127.0.0.1:43460,DS-71741146-61e8-4932-b6aa-97937e4e8c92,DISK], DatanodeInfoWithStorage[127.0.0.1:42178,DS-f452d195-97b8-4ef8-93a2-0404d2c8c043,DISK], DatanodeInfoWithStorage[127.0.0.1:44993,DS-3e756885-5388-4046-a91c-974c857cba41,DISK], DatanodeInfoWithStorage[127.0.0.1:44742,DS-aad3ed76-45a2-4015-bd91-56cd8a024cf6,DISK], DatanodeInfoWithStorage[127.0.0.1:42709,DS-5130480a-d2f2-4f8f-85e3-1a9c36ab4c8c,DISK], DatanodeInfoWithStorage[127.0.0.1:32823,DS-5a1c2ce9-7e33-45d8-a02b-00ef46a284ce,DISK], DatanodeInfoWithStorage[127.0.0.1:32948,DS-aac698b9-2aae-4d43-859c-a6a8fdfa1c1a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-172561729-172.17.0.7-1598406291724:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34919,DS-df05b345-a237-4d69-9d86-5c7fcfd565d6,DISK], DatanodeInfoWithStorage[127.0.0.1:43460,DS-71741146-61e8-4932-b6aa-97937e4e8c92,DISK], DatanodeInfoWithStorage[127.0.0.1:42178,DS-f452d195-97b8-4ef8-93a2-0404d2c8c043,DISK], DatanodeInfoWithStorage[127.0.0.1:44993,DS-3e756885-5388-4046-a91c-974c857cba41,DISK], DatanodeInfoWithStorage[127.0.0.1:44742,DS-aad3ed76-45a2-4015-bd91-56cd8a024cf6,DISK], DatanodeInfoWithStorage[127.0.0.1:42709,DS-5130480a-d2f2-4f8f-85e3-1a9c36ab4c8c,DISK], DatanodeInfoWithStorage[127.0.0.1:32823,DS-5a1c2ce9-7e33-45d8-a02b-00ef46a284ce,DISK], DatanodeInfoWithStorage[127.0.0.1:32948,DS-aac698b9-2aae-4d43-859c-a6a8fdfa1c1a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-7216400-172.17.0.7-1598406439981:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42612,DS-7d66125a-bce6-40f1-9bd5-0ef407b488e5,DISK], DatanodeInfoWithStorage[127.0.0.1:39629,DS-ecadefcd-50c4-488b-a5a1-fb80ccbf2d88,DISK], DatanodeInfoWithStorage[127.0.0.1:35807,DS-46a25579-c717-45ed-a56a-4da4068fd0b7,DISK], DatanodeInfoWithStorage[127.0.0.1:35512,DS-fd8af71f-97a1-4fb7-9aa7-11a058af6dfe,DISK], DatanodeInfoWithStorage[127.0.0.1:46826,DS-76373610-d1d4-4f61-a502-55c27ca2436f,DISK], DatanodeInfoWithStorage[127.0.0.1:37272,DS-2b73dc4e-9603-413d-b1a7-26d192714c03,DISK], DatanodeInfoWithStorage[127.0.0.1:33829,DS-e1e734b2-d418-4a4b-87a5-ab370afcc8f8,DISK], DatanodeInfoWithStorage[127.0.0.1:42607,DS-9502d2b9-1dbd-423a-b68a-e7caa92134ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-7216400-172.17.0.7-1598406439981:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42612,DS-7d66125a-bce6-40f1-9bd5-0ef407b488e5,DISK], DatanodeInfoWithStorage[127.0.0.1:39629,DS-ecadefcd-50c4-488b-a5a1-fb80ccbf2d88,DISK], DatanodeInfoWithStorage[127.0.0.1:35807,DS-46a25579-c717-45ed-a56a-4da4068fd0b7,DISK], DatanodeInfoWithStorage[127.0.0.1:35512,DS-fd8af71f-97a1-4fb7-9aa7-11a058af6dfe,DISK], DatanodeInfoWithStorage[127.0.0.1:46826,DS-76373610-d1d4-4f61-a502-55c27ca2436f,DISK], DatanodeInfoWithStorage[127.0.0.1:37272,DS-2b73dc4e-9603-413d-b1a7-26d192714c03,DISK], DatanodeInfoWithStorage[127.0.0.1:33829,DS-e1e734b2-d418-4a4b-87a5-ab370afcc8f8,DISK], DatanodeInfoWithStorage[127.0.0.1:42607,DS-9502d2b9-1dbd-423a-b68a-e7caa92134ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2111665279-172.17.0.7-1598406998459:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39744,DS-dd116c78-36e3-4ffe-afdb-abc0d8a28d8a,DISK], DatanodeInfoWithStorage[127.0.0.1:35498,DS-3b1d3d34-08e0-43fe-a2d2-5363d0ed8af9,DISK], DatanodeInfoWithStorage[127.0.0.1:35507,DS-1cd91ccd-96d0-46a2-90b0-fcd7952ea16e,DISK], DatanodeInfoWithStorage[127.0.0.1:42642,DS-256191f8-365b-41ff-a966-3521fb3f026c,DISK], DatanodeInfoWithStorage[127.0.0.1:38863,DS-d32ba5a5-ff89-451f-bdd3-82f32a8e7e48,DISK], DatanodeInfoWithStorage[127.0.0.1:42385,DS-28fe2440-ec62-43f3-a0a2-8611732828f5,DISK], DatanodeInfoWithStorage[127.0.0.1:36048,DS-524e9c1e-c481-4eec-8196-efacf93fdcd3,DISK], DatanodeInfoWithStorage[127.0.0.1:44435,DS-5f895107-8116-4ce0-bc8d-8c09584ec78e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2111665279-172.17.0.7-1598406998459:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39744,DS-dd116c78-36e3-4ffe-afdb-abc0d8a28d8a,DISK], DatanodeInfoWithStorage[127.0.0.1:35498,DS-3b1d3d34-08e0-43fe-a2d2-5363d0ed8af9,DISK], DatanodeInfoWithStorage[127.0.0.1:35507,DS-1cd91ccd-96d0-46a2-90b0-fcd7952ea16e,DISK], DatanodeInfoWithStorage[127.0.0.1:42642,DS-256191f8-365b-41ff-a966-3521fb3f026c,DISK], DatanodeInfoWithStorage[127.0.0.1:38863,DS-d32ba5a5-ff89-451f-bdd3-82f32a8e7e48,DISK], DatanodeInfoWithStorage[127.0.0.1:42385,DS-28fe2440-ec62-43f3-a0a2-8611732828f5,DISK], DatanodeInfoWithStorage[127.0.0.1:36048,DS-524e9c1e-c481-4eec-8196-efacf93fdcd3,DISK], DatanodeInfoWithStorage[127.0.0.1:44435,DS-5f895107-8116-4ce0-bc8d-8c09584ec78e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-722178187-172.17.0.7-1598407065498:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45646,DS-68a0d97a-e073-4c09-a1b0-920dd625b313,DISK], DatanodeInfoWithStorage[127.0.0.1:43653,DS-88b31387-0184-4079-bdc7-6e3296759137,DISK], DatanodeInfoWithStorage[127.0.0.1:43385,DS-6e47e063-4da4-4762-b3e2-2a501fae8186,DISK], DatanodeInfoWithStorage[127.0.0.1:35201,DS-aca8a3ba-ce72-4483-9c6e-6121b489ef82,DISK], DatanodeInfoWithStorage[127.0.0.1:40984,DS-3a042cba-0081-4e22-9bfc-051268ec099b,DISK], DatanodeInfoWithStorage[127.0.0.1:35625,DS-9affd44d-d43a-41e1-9ad8-888aeb4f2cca,DISK], DatanodeInfoWithStorage[127.0.0.1:40013,DS-16a308aa-c972-4264-b051-4d44ef16cd2c,DISK], DatanodeInfoWithStorage[127.0.0.1:43714,DS-364b5b69-02e1-4b25-b9d6-0f7d3dec8603,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-722178187-172.17.0.7-1598407065498:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45646,DS-68a0d97a-e073-4c09-a1b0-920dd625b313,DISK], DatanodeInfoWithStorage[127.0.0.1:43653,DS-88b31387-0184-4079-bdc7-6e3296759137,DISK], DatanodeInfoWithStorage[127.0.0.1:43385,DS-6e47e063-4da4-4762-b3e2-2a501fae8186,DISK], DatanodeInfoWithStorage[127.0.0.1:35201,DS-aca8a3ba-ce72-4483-9c6e-6121b489ef82,DISK], DatanodeInfoWithStorage[127.0.0.1:40984,DS-3a042cba-0081-4e22-9bfc-051268ec099b,DISK], DatanodeInfoWithStorage[127.0.0.1:35625,DS-9affd44d-d43a-41e1-9ad8-888aeb4f2cca,DISK], DatanodeInfoWithStorage[127.0.0.1:40013,DS-16a308aa-c972-4264-b051-4d44ef16cd2c,DISK], DatanodeInfoWithStorage[127.0.0.1:43714,DS-364b5b69-02e1-4b25-b9d6-0f7d3dec8603,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5064
