reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1217174698-172.17.0.21-1598448871125:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33816,DS-1e10b689-1aa6-4374-8d0c-7fc6ce3b73be,DISK], DatanodeInfoWithStorage[127.0.0.1:33805,DS-397514e2-6df8-457e-8240-9c2951d83a19,DISK], DatanodeInfoWithStorage[127.0.0.1:39648,DS-f49e7de8-7acf-457c-bbd7-fb7716aaa7ed,DISK], DatanodeInfoWithStorage[127.0.0.1:34061,DS-727ce5e2-c3c8-4a53-8e90-a51db2e1f43f,DISK], DatanodeInfoWithStorage[127.0.0.1:34785,DS-16c0b459-7247-4df8-b4fd-bf566d5abf76,DISK], DatanodeInfoWithStorage[127.0.0.1:35738,DS-220a6c15-d192-46fe-b27c-83b67863aa3a,DISK], DatanodeInfoWithStorage[127.0.0.1:44897,DS-dba8fe8e-9eb3-4b92-a42d-4fa013c5e694,DISK], DatanodeInfoWithStorage[127.0.0.1:39375,DS-5e124ffc-0b50-4419-8c67-69bdea8018bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1217174698-172.17.0.21-1598448871125:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33816,DS-1e10b689-1aa6-4374-8d0c-7fc6ce3b73be,DISK], DatanodeInfoWithStorage[127.0.0.1:33805,DS-397514e2-6df8-457e-8240-9c2951d83a19,DISK], DatanodeInfoWithStorage[127.0.0.1:39648,DS-f49e7de8-7acf-457c-bbd7-fb7716aaa7ed,DISK], DatanodeInfoWithStorage[127.0.0.1:34061,DS-727ce5e2-c3c8-4a53-8e90-a51db2e1f43f,DISK], DatanodeInfoWithStorage[127.0.0.1:34785,DS-16c0b459-7247-4df8-b4fd-bf566d5abf76,DISK], DatanodeInfoWithStorage[127.0.0.1:35738,DS-220a6c15-d192-46fe-b27c-83b67863aa3a,DISK], DatanodeInfoWithStorage[127.0.0.1:44897,DS-dba8fe8e-9eb3-4b92-a42d-4fa013c5e694,DISK], DatanodeInfoWithStorage[127.0.0.1:39375,DS-5e124ffc-0b50-4419-8c67-69bdea8018bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-827211238-172.17.0.21-1598448904317:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44147,DS-73956d75-0341-4e52-950d-4858beccacd7,DISK], DatanodeInfoWithStorage[127.0.0.1:34360,DS-91a60a48-3116-4e1e-b7ba-861ed084edec,DISK], DatanodeInfoWithStorage[127.0.0.1:46874,DS-1050b45f-97cf-4228-88c3-d9ffb2de2a47,DISK], DatanodeInfoWithStorage[127.0.0.1:37008,DS-dd64595c-0019-4942-af69-7e99a816ceb7,DISK], DatanodeInfoWithStorage[127.0.0.1:37105,DS-7b6c87f0-30f5-47db-b1b1-b45703e463ec,DISK], DatanodeInfoWithStorage[127.0.0.1:44093,DS-e37a3ba0-535a-441e-8470-bc7a0e43fe73,DISK], DatanodeInfoWithStorage[127.0.0.1:38721,DS-9dc3cce1-c674-4789-9544-189a9ee5ce6b,DISK], DatanodeInfoWithStorage[127.0.0.1:33462,DS-9e2e948e-e895-4e57-9090-33c7dde8baff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-827211238-172.17.0.21-1598448904317:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44147,DS-73956d75-0341-4e52-950d-4858beccacd7,DISK], DatanodeInfoWithStorage[127.0.0.1:34360,DS-91a60a48-3116-4e1e-b7ba-861ed084edec,DISK], DatanodeInfoWithStorage[127.0.0.1:46874,DS-1050b45f-97cf-4228-88c3-d9ffb2de2a47,DISK], DatanodeInfoWithStorage[127.0.0.1:37008,DS-dd64595c-0019-4942-af69-7e99a816ceb7,DISK], DatanodeInfoWithStorage[127.0.0.1:37105,DS-7b6c87f0-30f5-47db-b1b1-b45703e463ec,DISK], DatanodeInfoWithStorage[127.0.0.1:44093,DS-e37a3ba0-535a-441e-8470-bc7a0e43fe73,DISK], DatanodeInfoWithStorage[127.0.0.1:38721,DS-9dc3cce1-c674-4789-9544-189a9ee5ce6b,DISK], DatanodeInfoWithStorage[127.0.0.1:33462,DS-9e2e948e-e895-4e57-9090-33c7dde8baff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1019686442-172.17.0.21-1598448975837:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40560,DS-1f41084c-a131-45a2-8335-211a39623b40,DISK], DatanodeInfoWithStorage[127.0.0.1:41808,DS-1ace24df-8249-4151-8ccc-cfeaaaf1f98a,DISK], DatanodeInfoWithStorage[127.0.0.1:43309,DS-9242adaa-fdd4-4cec-8ca1-3e03cee32905,DISK], DatanodeInfoWithStorage[127.0.0.1:42032,DS-8f65efe1-7384-42a7-99f6-16775a6157ca,DISK], DatanodeInfoWithStorage[127.0.0.1:41335,DS-17de749c-7498-4d11-88f9-1eac40da27e6,DISK], DatanodeInfoWithStorage[127.0.0.1:46340,DS-2790d982-ec1d-4756-b3af-0198e53b1f50,DISK], DatanodeInfoWithStorage[127.0.0.1:35139,DS-a57ccfd5-b18b-4f11-981b-ccfae4f757b2,DISK], DatanodeInfoWithStorage[127.0.0.1:44044,DS-5784f3d0-e54b-4410-9c78-071cd626d09b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1019686442-172.17.0.21-1598448975837:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40560,DS-1f41084c-a131-45a2-8335-211a39623b40,DISK], DatanodeInfoWithStorage[127.0.0.1:41808,DS-1ace24df-8249-4151-8ccc-cfeaaaf1f98a,DISK], DatanodeInfoWithStorage[127.0.0.1:43309,DS-9242adaa-fdd4-4cec-8ca1-3e03cee32905,DISK], DatanodeInfoWithStorage[127.0.0.1:42032,DS-8f65efe1-7384-42a7-99f6-16775a6157ca,DISK], DatanodeInfoWithStorage[127.0.0.1:41335,DS-17de749c-7498-4d11-88f9-1eac40da27e6,DISK], DatanodeInfoWithStorage[127.0.0.1:46340,DS-2790d982-ec1d-4756-b3af-0198e53b1f50,DISK], DatanodeInfoWithStorage[127.0.0.1:35139,DS-a57ccfd5-b18b-4f11-981b-ccfae4f757b2,DISK], DatanodeInfoWithStorage[127.0.0.1:44044,DS-5784f3d0-e54b-4410-9c78-071cd626d09b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2075323312-172.17.0.21-1598449093551:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38352,DS-255d0702-40ea-4c31-ab84-a1d16d24b0f2,DISK], DatanodeInfoWithStorage[127.0.0.1:37170,DS-37f99b0f-eff7-4fd1-8ed9-9a1281eb0b2f,DISK], DatanodeInfoWithStorage[127.0.0.1:33226,DS-b6526ca0-8908-4cbe-964b-433d9989f977,DISK], DatanodeInfoWithStorage[127.0.0.1:42474,DS-e22237d0-1848-4149-b6ed-90f6f96e81f8,DISK], DatanodeInfoWithStorage[127.0.0.1:34757,DS-97b1420c-5273-4b15-a0c1-f838f6adbf86,DISK], DatanodeInfoWithStorage[127.0.0.1:37294,DS-884043d9-9772-439b-ad74-0f67e7ceb244,DISK], DatanodeInfoWithStorage[127.0.0.1:42116,DS-8a1b9bed-d54e-46a9-b3f0-dfada4dde858,DISK], DatanodeInfoWithStorage[127.0.0.1:41515,DS-c459b021-22c8-4b8b-b0f8-cea3eb9e88f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2075323312-172.17.0.21-1598449093551:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38352,DS-255d0702-40ea-4c31-ab84-a1d16d24b0f2,DISK], DatanodeInfoWithStorage[127.0.0.1:37170,DS-37f99b0f-eff7-4fd1-8ed9-9a1281eb0b2f,DISK], DatanodeInfoWithStorage[127.0.0.1:33226,DS-b6526ca0-8908-4cbe-964b-433d9989f977,DISK], DatanodeInfoWithStorage[127.0.0.1:42474,DS-e22237d0-1848-4149-b6ed-90f6f96e81f8,DISK], DatanodeInfoWithStorage[127.0.0.1:34757,DS-97b1420c-5273-4b15-a0c1-f838f6adbf86,DISK], DatanodeInfoWithStorage[127.0.0.1:37294,DS-884043d9-9772-439b-ad74-0f67e7ceb244,DISK], DatanodeInfoWithStorage[127.0.0.1:42116,DS-8a1b9bed-d54e-46a9-b3f0-dfada4dde858,DISK], DatanodeInfoWithStorage[127.0.0.1:41515,DS-c459b021-22c8-4b8b-b0f8-cea3eb9e88f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1122169721-172.17.0.21-1598449225847:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33549,DS-86172678-bbe1-46c6-821b-319ced2d7daf,DISK], DatanodeInfoWithStorage[127.0.0.1:43980,DS-42f4edce-d72a-4307-b512-b926ec8ae2c4,DISK], DatanodeInfoWithStorage[127.0.0.1:44220,DS-844ae50c-a06d-4b11-a1cf-80c940aa9bd1,DISK], DatanodeInfoWithStorage[127.0.0.1:35767,DS-14da745f-5a1f-4733-b849-850775b0da10,DISK], DatanodeInfoWithStorage[127.0.0.1:36499,DS-e932e8fe-0aa7-45c8-8979-9559ac8db611,DISK], DatanodeInfoWithStorage[127.0.0.1:35012,DS-580ac196-77dc-45ce-b420-a4f5d9fe018a,DISK], DatanodeInfoWithStorage[127.0.0.1:36658,DS-a9a75578-3fbd-46ab-a7a9-3072c2ba1b18,DISK], DatanodeInfoWithStorage[127.0.0.1:34145,DS-0bd03347-0e5c-4002-ac29-ad9473ad7152,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1122169721-172.17.0.21-1598449225847:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33549,DS-86172678-bbe1-46c6-821b-319ced2d7daf,DISK], DatanodeInfoWithStorage[127.0.0.1:43980,DS-42f4edce-d72a-4307-b512-b926ec8ae2c4,DISK], DatanodeInfoWithStorage[127.0.0.1:44220,DS-844ae50c-a06d-4b11-a1cf-80c940aa9bd1,DISK], DatanodeInfoWithStorage[127.0.0.1:35767,DS-14da745f-5a1f-4733-b849-850775b0da10,DISK], DatanodeInfoWithStorage[127.0.0.1:36499,DS-e932e8fe-0aa7-45c8-8979-9559ac8db611,DISK], DatanodeInfoWithStorage[127.0.0.1:35012,DS-580ac196-77dc-45ce-b420-a4f5d9fe018a,DISK], DatanodeInfoWithStorage[127.0.0.1:36658,DS-a9a75578-3fbd-46ab-a7a9-3072c2ba1b18,DISK], DatanodeInfoWithStorage[127.0.0.1:34145,DS-0bd03347-0e5c-4002-ac29-ad9473ad7152,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-172764536-172.17.0.21-1598449362066:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37181,DS-96c0d168-88d4-4fed-90b6-88e96ea8cfa0,DISK], DatanodeInfoWithStorage[127.0.0.1:44634,DS-67c992ce-e9ce-46c1-996c-ce8ae51c1c42,DISK], DatanodeInfoWithStorage[127.0.0.1:40450,DS-256cf669-e2ac-4b52-b4a0-b2533d3d4b6d,DISK], DatanodeInfoWithStorage[127.0.0.1:33755,DS-4531e7f7-906e-41ee-9e36-cbc3826a2920,DISK], DatanodeInfoWithStorage[127.0.0.1:38897,DS-837a3f1f-8584-41a3-9a31-d730e856e35e,DISK], DatanodeInfoWithStorage[127.0.0.1:40194,DS-03b620e9-47c1-4cb4-82d5-10341ab42bd4,DISK], DatanodeInfoWithStorage[127.0.0.1:37199,DS-9858b45a-d1b4-4d67-a110-ea526cf1d139,DISK], DatanodeInfoWithStorage[127.0.0.1:34990,DS-cfd26a2f-b6e8-405e-953c-0af5cf12b3d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-172764536-172.17.0.21-1598449362066:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37181,DS-96c0d168-88d4-4fed-90b6-88e96ea8cfa0,DISK], DatanodeInfoWithStorage[127.0.0.1:44634,DS-67c992ce-e9ce-46c1-996c-ce8ae51c1c42,DISK], DatanodeInfoWithStorage[127.0.0.1:40450,DS-256cf669-e2ac-4b52-b4a0-b2533d3d4b6d,DISK], DatanodeInfoWithStorage[127.0.0.1:33755,DS-4531e7f7-906e-41ee-9e36-cbc3826a2920,DISK], DatanodeInfoWithStorage[127.0.0.1:38897,DS-837a3f1f-8584-41a3-9a31-d730e856e35e,DISK], DatanodeInfoWithStorage[127.0.0.1:40194,DS-03b620e9-47c1-4cb4-82d5-10341ab42bd4,DISK], DatanodeInfoWithStorage[127.0.0.1:37199,DS-9858b45a-d1b4-4d67-a110-ea526cf1d139,DISK], DatanodeInfoWithStorage[127.0.0.1:34990,DS-cfd26a2f-b6e8-405e-953c-0af5cf12b3d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2071362275-172.17.0.21-1598449576341:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38143,DS-cdf7dde0-d932-4aba-bb26-bb5ca5902370,DISK], DatanodeInfoWithStorage[127.0.0.1:34789,DS-dab6324f-eae5-4d40-9c89-b5b0eea78010,DISK], DatanodeInfoWithStorage[127.0.0.1:45451,DS-8fbedac6-c373-4fd6-bc3c-dee0a8b3c39f,DISK], DatanodeInfoWithStorage[127.0.0.1:43729,DS-fa68f292-3cc7-4a45-b7b7-6e14cdaab294,DISK], DatanodeInfoWithStorage[127.0.0.1:35576,DS-30247f13-348e-4b58-af1b-30b2cfb05a4e,DISK], DatanodeInfoWithStorage[127.0.0.1:44297,DS-6ca08887-b43a-4a76-a7d7-368c03ac9819,DISK], DatanodeInfoWithStorage[127.0.0.1:36811,DS-d0ffe9fd-f39f-4899-a064-1cd24c13d637,DISK], DatanodeInfoWithStorage[127.0.0.1:34933,DS-a9666d5c-f2f6-4b8c-b0c1-95e37ef5bd33,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2071362275-172.17.0.21-1598449576341:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38143,DS-cdf7dde0-d932-4aba-bb26-bb5ca5902370,DISK], DatanodeInfoWithStorage[127.0.0.1:34789,DS-dab6324f-eae5-4d40-9c89-b5b0eea78010,DISK], DatanodeInfoWithStorage[127.0.0.1:45451,DS-8fbedac6-c373-4fd6-bc3c-dee0a8b3c39f,DISK], DatanodeInfoWithStorage[127.0.0.1:43729,DS-fa68f292-3cc7-4a45-b7b7-6e14cdaab294,DISK], DatanodeInfoWithStorage[127.0.0.1:35576,DS-30247f13-348e-4b58-af1b-30b2cfb05a4e,DISK], DatanodeInfoWithStorage[127.0.0.1:44297,DS-6ca08887-b43a-4a76-a7d7-368c03ac9819,DISK], DatanodeInfoWithStorage[127.0.0.1:36811,DS-d0ffe9fd-f39f-4899-a064-1cd24c13d637,DISK], DatanodeInfoWithStorage[127.0.0.1:34933,DS-a9666d5c-f2f6-4b8c-b0c1-95e37ef5bd33,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-544897312-172.17.0.21-1598450098757:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33725,DS-99995252-feae-4fde-8264-c2d5ee1a2f8f,DISK], DatanodeInfoWithStorage[127.0.0.1:45047,DS-c39350eb-0dc2-4b6a-804a-c38b56e5b03e,DISK], DatanodeInfoWithStorage[127.0.0.1:42730,DS-244ee078-076e-4936-8bd1-1c5f958fc1b5,DISK], DatanodeInfoWithStorage[127.0.0.1:37545,DS-9eab670c-cc31-475c-98cb-7d8a3fc08248,DISK], DatanodeInfoWithStorage[127.0.0.1:44225,DS-f4b6817d-3ef1-4a0b-bf22-ff0e81fd7095,DISK], DatanodeInfoWithStorage[127.0.0.1:33260,DS-0ca8a081-6bc0-470c-bcbb-ac548db4c2f5,DISK], DatanodeInfoWithStorage[127.0.0.1:36263,DS-2e362f95-813f-4026-981b-27ef898b237a,DISK], DatanodeInfoWithStorage[127.0.0.1:39184,DS-881335ea-492c-4a37-8433-f31110d20bc1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-544897312-172.17.0.21-1598450098757:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33725,DS-99995252-feae-4fde-8264-c2d5ee1a2f8f,DISK], DatanodeInfoWithStorage[127.0.0.1:45047,DS-c39350eb-0dc2-4b6a-804a-c38b56e5b03e,DISK], DatanodeInfoWithStorage[127.0.0.1:42730,DS-244ee078-076e-4936-8bd1-1c5f958fc1b5,DISK], DatanodeInfoWithStorage[127.0.0.1:37545,DS-9eab670c-cc31-475c-98cb-7d8a3fc08248,DISK], DatanodeInfoWithStorage[127.0.0.1:44225,DS-f4b6817d-3ef1-4a0b-bf22-ff0e81fd7095,DISK], DatanodeInfoWithStorage[127.0.0.1:33260,DS-0ca8a081-6bc0-470c-bcbb-ac548db4c2f5,DISK], DatanodeInfoWithStorage[127.0.0.1:36263,DS-2e362f95-813f-4026-981b-27ef898b237a,DISK], DatanodeInfoWithStorage[127.0.0.1:39184,DS-881335ea-492c-4a37-8433-f31110d20bc1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2097416846-172.17.0.21-1598451047768:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33219,DS-13b60eda-97ca-4c8e-a3ca-4ec3a537fb6d,DISK], DatanodeInfoWithStorage[127.0.0.1:35177,DS-7e5291e2-e10b-4cf8-9a41-117c83beb66a,DISK], DatanodeInfoWithStorage[127.0.0.1:35543,DS-60fad322-ed5e-4b3e-9029-d8f079ec7a7f,DISK], DatanodeInfoWithStorage[127.0.0.1:34992,DS-40b4fe10-527a-4dc3-ad12-18ed9be63167,DISK], DatanodeInfoWithStorage[127.0.0.1:40421,DS-6c9221fa-29a3-4ff3-829e-85919157d967,DISK], DatanodeInfoWithStorage[127.0.0.1:46569,DS-9fd6b11e-68d6-4bec-bd1b-8a851b217ccc,DISK], DatanodeInfoWithStorage[127.0.0.1:34898,DS-b8121df6-fc80-4d1c-8f36-eff2058fb80e,DISK], DatanodeInfoWithStorage[127.0.0.1:46665,DS-8c45d749-036b-4c78-b86d-264179ad4075,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2097416846-172.17.0.21-1598451047768:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33219,DS-13b60eda-97ca-4c8e-a3ca-4ec3a537fb6d,DISK], DatanodeInfoWithStorage[127.0.0.1:35177,DS-7e5291e2-e10b-4cf8-9a41-117c83beb66a,DISK], DatanodeInfoWithStorage[127.0.0.1:35543,DS-60fad322-ed5e-4b3e-9029-d8f079ec7a7f,DISK], DatanodeInfoWithStorage[127.0.0.1:34992,DS-40b4fe10-527a-4dc3-ad12-18ed9be63167,DISK], DatanodeInfoWithStorage[127.0.0.1:40421,DS-6c9221fa-29a3-4ff3-829e-85919157d967,DISK], DatanodeInfoWithStorage[127.0.0.1:46569,DS-9fd6b11e-68d6-4bec-bd1b-8a851b217ccc,DISK], DatanodeInfoWithStorage[127.0.0.1:34898,DS-b8121df6-fc80-4d1c-8f36-eff2058fb80e,DISK], DatanodeInfoWithStorage[127.0.0.1:46665,DS-8c45d749-036b-4c78-b86d-264179ad4075,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-746939043-172.17.0.21-1598451117683:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45549,DS-25d33f6d-6009-4e2d-bb0c-1f96b5b0616f,DISK], DatanodeInfoWithStorage[127.0.0.1:44765,DS-9f3f82fb-0712-4cf8-af22-2039cc978c80,DISK], DatanodeInfoWithStorage[127.0.0.1:38351,DS-1af663b5-b1c3-4ff2-bf37-4f77f26bd6cf,DISK], DatanodeInfoWithStorage[127.0.0.1:35330,DS-968ebeca-8f4f-409e-bcee-c3a4b8911cde,DISK], DatanodeInfoWithStorage[127.0.0.1:36096,DS-bd09fc2a-70a8-415a-b92f-b798d5d6c441,DISK], DatanodeInfoWithStorage[127.0.0.1:40526,DS-255cccc2-c90b-4596-a06b-4af0bc4d6482,DISK], DatanodeInfoWithStorage[127.0.0.1:45003,DS-e7875cc9-ef26-495f-bd63-218630866a8a,DISK], DatanodeInfoWithStorage[127.0.0.1:35784,DS-2bceeaba-a5f1-45bd-874b-e75fc7239870,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-746939043-172.17.0.21-1598451117683:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45549,DS-25d33f6d-6009-4e2d-bb0c-1f96b5b0616f,DISK], DatanodeInfoWithStorage[127.0.0.1:44765,DS-9f3f82fb-0712-4cf8-af22-2039cc978c80,DISK], DatanodeInfoWithStorage[127.0.0.1:38351,DS-1af663b5-b1c3-4ff2-bf37-4f77f26bd6cf,DISK], DatanodeInfoWithStorage[127.0.0.1:35330,DS-968ebeca-8f4f-409e-bcee-c3a4b8911cde,DISK], DatanodeInfoWithStorage[127.0.0.1:36096,DS-bd09fc2a-70a8-415a-b92f-b798d5d6c441,DISK], DatanodeInfoWithStorage[127.0.0.1:40526,DS-255cccc2-c90b-4596-a06b-4af0bc4d6482,DISK], DatanodeInfoWithStorage[127.0.0.1:45003,DS-e7875cc9-ef26-495f-bd63-218630866a8a,DISK], DatanodeInfoWithStorage[127.0.0.1:35784,DS-2bceeaba-a5f1-45bd-874b-e75fc7239870,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-969238746-172.17.0.21-1598451385198:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39817,DS-4bace54f-ca67-4f44-9442-9ba1cbcad29e,DISK], DatanodeInfoWithStorage[127.0.0.1:46829,DS-35e3b79f-850e-49ba-9623-c4fb3c4b0f63,DISK], DatanodeInfoWithStorage[127.0.0.1:35726,DS-e529a035-b856-4977-be43-ce4f076796fc,DISK], DatanodeInfoWithStorage[127.0.0.1:39855,DS-03f9da29-fe95-4133-9931-f62aceba3378,DISK], DatanodeInfoWithStorage[127.0.0.1:44939,DS-ea22ea4d-d4c3-4506-965f-64d43248973e,DISK], DatanodeInfoWithStorage[127.0.0.1:43319,DS-4ab5a3e1-501d-4aac-8dcd-eea7b23def2a,DISK], DatanodeInfoWithStorage[127.0.0.1:37540,DS-b98065d5-ceb7-4bb4-9e25-7666ee466742,DISK], DatanodeInfoWithStorage[127.0.0.1:36967,DS-f599a255-3a82-416b-a67b-c95d61d5c070,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-969238746-172.17.0.21-1598451385198:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39817,DS-4bace54f-ca67-4f44-9442-9ba1cbcad29e,DISK], DatanodeInfoWithStorage[127.0.0.1:46829,DS-35e3b79f-850e-49ba-9623-c4fb3c4b0f63,DISK], DatanodeInfoWithStorage[127.0.0.1:35726,DS-e529a035-b856-4977-be43-ce4f076796fc,DISK], DatanodeInfoWithStorage[127.0.0.1:39855,DS-03f9da29-fe95-4133-9931-f62aceba3378,DISK], DatanodeInfoWithStorage[127.0.0.1:44939,DS-ea22ea4d-d4c3-4506-965f-64d43248973e,DISK], DatanodeInfoWithStorage[127.0.0.1:43319,DS-4ab5a3e1-501d-4aac-8dcd-eea7b23def2a,DISK], DatanodeInfoWithStorage[127.0.0.1:37540,DS-b98065d5-ceb7-4bb4-9e25-7666ee466742,DISK], DatanodeInfoWithStorage[127.0.0.1:36967,DS-f599a255-3a82-416b-a67b-c95d61d5c070,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1310697534-172.17.0.21-1598451618613:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38360,DS-76e46065-073c-4918-9d70-80b5392a6a83,DISK], DatanodeInfoWithStorage[127.0.0.1:45146,DS-406cb142-04b3-4381-b079-230560da592d,DISK], DatanodeInfoWithStorage[127.0.0.1:34505,DS-79296a8b-b95e-4588-a708-3857e8a59065,DISK], DatanodeInfoWithStorage[127.0.0.1:32879,DS-2d07fefd-bd43-4876-b6dc-852d8354ce96,DISK], DatanodeInfoWithStorage[127.0.0.1:43529,DS-0ae40557-2003-42e6-b3fb-3655707ac418,DISK], DatanodeInfoWithStorage[127.0.0.1:42391,DS-311fa27e-a604-48f8-853e-95fac7906098,DISK], DatanodeInfoWithStorage[127.0.0.1:37726,DS-27587152-8db3-4887-b82e-b7be5c50f6f0,DISK], DatanodeInfoWithStorage[127.0.0.1:36057,DS-dd801e10-0a14-4b79-847e-33bdcf593cae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1310697534-172.17.0.21-1598451618613:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38360,DS-76e46065-073c-4918-9d70-80b5392a6a83,DISK], DatanodeInfoWithStorage[127.0.0.1:45146,DS-406cb142-04b3-4381-b079-230560da592d,DISK], DatanodeInfoWithStorage[127.0.0.1:34505,DS-79296a8b-b95e-4588-a708-3857e8a59065,DISK], DatanodeInfoWithStorage[127.0.0.1:32879,DS-2d07fefd-bd43-4876-b6dc-852d8354ce96,DISK], DatanodeInfoWithStorage[127.0.0.1:43529,DS-0ae40557-2003-42e6-b3fb-3655707ac418,DISK], DatanodeInfoWithStorage[127.0.0.1:42391,DS-311fa27e-a604-48f8-853e-95fac7906098,DISK], DatanodeInfoWithStorage[127.0.0.1:37726,DS-27587152-8db3-4887-b82e-b7be5c50f6f0,DISK], DatanodeInfoWithStorage[127.0.0.1:36057,DS-dd801e10-0a14-4b79-847e-33bdcf593cae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1594779279-172.17.0.21-1598452154469:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43181,DS-bf0af515-ee56-4559-b104-ae945c557e5d,DISK], DatanodeInfoWithStorage[127.0.0.1:40299,DS-12433a44-34ce-4eed-8285-4d1d844e9c73,DISK], DatanodeInfoWithStorage[127.0.0.1:44533,DS-aaabc5a7-782b-47be-a962-b14c65757c4b,DISK], DatanodeInfoWithStorage[127.0.0.1:45486,DS-6158da37-3288-46b8-93eb-b1593598d5e6,DISK], DatanodeInfoWithStorage[127.0.0.1:33559,DS-46ca4fc2-5529-42ef-a75c-6c9ccee3c578,DISK], DatanodeInfoWithStorage[127.0.0.1:40629,DS-de577e77-f02c-4eff-b9c7-1ae967c2166e,DISK], DatanodeInfoWithStorage[127.0.0.1:40771,DS-20cc006f-6fd9-4496-8343-0a8c99827a60,DISK], DatanodeInfoWithStorage[127.0.0.1:40036,DS-e164a570-9cc6-46fa-8078-191153a5b5b7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1594779279-172.17.0.21-1598452154469:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43181,DS-bf0af515-ee56-4559-b104-ae945c557e5d,DISK], DatanodeInfoWithStorage[127.0.0.1:40299,DS-12433a44-34ce-4eed-8285-4d1d844e9c73,DISK], DatanodeInfoWithStorage[127.0.0.1:44533,DS-aaabc5a7-782b-47be-a962-b14c65757c4b,DISK], DatanodeInfoWithStorage[127.0.0.1:45486,DS-6158da37-3288-46b8-93eb-b1593598d5e6,DISK], DatanodeInfoWithStorage[127.0.0.1:33559,DS-46ca4fc2-5529-42ef-a75c-6c9ccee3c578,DISK], DatanodeInfoWithStorage[127.0.0.1:40629,DS-de577e77-f02c-4eff-b9c7-1ae967c2166e,DISK], DatanodeInfoWithStorage[127.0.0.1:40771,DS-20cc006f-6fd9-4496-8343-0a8c99827a60,DISK], DatanodeInfoWithStorage[127.0.0.1:40036,DS-e164a570-9cc6-46fa-8078-191153a5b5b7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1972993349-172.17.0.21-1598452256661:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44695,DS-3981408a-c004-4ac5-a823-2bae9fce06c8,DISK], DatanodeInfoWithStorage[127.0.0.1:34318,DS-2e19dd28-e9ac-4610-8e33-16d8efd84a65,DISK], DatanodeInfoWithStorage[127.0.0.1:34220,DS-6d789231-8c22-4dfb-9d1a-5630d2716d53,DISK], DatanodeInfoWithStorage[127.0.0.1:41547,DS-ba9db9b1-8d22-4d3c-aedb-0cf12cea5913,DISK], DatanodeInfoWithStorage[127.0.0.1:43104,DS-d631599e-28db-4cd9-b349-7a29eebe387a,DISK], DatanodeInfoWithStorage[127.0.0.1:43460,DS-1ad18a5c-1d2b-4912-b05c-a0241bc9f471,DISK], DatanodeInfoWithStorage[127.0.0.1:36829,DS-95803754-7e5e-4f68-83ab-ce8aeb4e9a4d,DISK], DatanodeInfoWithStorage[127.0.0.1:43455,DS-b4190e4b-28bb-47a5-900c-68e256d9f448,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1972993349-172.17.0.21-1598452256661:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44695,DS-3981408a-c004-4ac5-a823-2bae9fce06c8,DISK], DatanodeInfoWithStorage[127.0.0.1:34318,DS-2e19dd28-e9ac-4610-8e33-16d8efd84a65,DISK], DatanodeInfoWithStorage[127.0.0.1:34220,DS-6d789231-8c22-4dfb-9d1a-5630d2716d53,DISK], DatanodeInfoWithStorage[127.0.0.1:41547,DS-ba9db9b1-8d22-4d3c-aedb-0cf12cea5913,DISK], DatanodeInfoWithStorage[127.0.0.1:43104,DS-d631599e-28db-4cd9-b349-7a29eebe387a,DISK], DatanodeInfoWithStorage[127.0.0.1:43460,DS-1ad18a5c-1d2b-4912-b05c-a0241bc9f471,DISK], DatanodeInfoWithStorage[127.0.0.1:36829,DS-95803754-7e5e-4f68-83ab-ce8aeb4e9a4d,DISK], DatanodeInfoWithStorage[127.0.0.1:43455,DS-b4190e4b-28bb-47a5-900c-68e256d9f448,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2010085605-172.17.0.21-1598452435953:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45331,DS-7e15d7d3-f997-42f5-9064-61e2f19d7e4f,DISK], DatanodeInfoWithStorage[127.0.0.1:38347,DS-7e6cf1fd-a3ee-4e7f-8ef3-d1c37fb299ba,DISK], DatanodeInfoWithStorage[127.0.0.1:38121,DS-c447cf28-fdeb-4817-a97b-0d4e4e06ae67,DISK], DatanodeInfoWithStorage[127.0.0.1:36726,DS-0a2ab6dd-8e68-4d39-b3b0-9bf5bce14297,DISK], DatanodeInfoWithStorage[127.0.0.1:45522,DS-7e50cf54-5895-48d5-b9da-85b3c2299719,DISK], DatanodeInfoWithStorage[127.0.0.1:44354,DS-a810ca72-6fcb-4c5e-a077-13e29a7de43f,DISK], DatanodeInfoWithStorage[127.0.0.1:33758,DS-fbd00dfd-c848-45e2-a1bb-e90fb2430d81,DISK], DatanodeInfoWithStorage[127.0.0.1:40946,DS-03e70131-35a3-44d0-b2ef-e58812575d91,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2010085605-172.17.0.21-1598452435953:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45331,DS-7e15d7d3-f997-42f5-9064-61e2f19d7e4f,DISK], DatanodeInfoWithStorage[127.0.0.1:38347,DS-7e6cf1fd-a3ee-4e7f-8ef3-d1c37fb299ba,DISK], DatanodeInfoWithStorage[127.0.0.1:38121,DS-c447cf28-fdeb-4817-a97b-0d4e4e06ae67,DISK], DatanodeInfoWithStorage[127.0.0.1:36726,DS-0a2ab6dd-8e68-4d39-b3b0-9bf5bce14297,DISK], DatanodeInfoWithStorage[127.0.0.1:45522,DS-7e50cf54-5895-48d5-b9da-85b3c2299719,DISK], DatanodeInfoWithStorage[127.0.0.1:44354,DS-a810ca72-6fcb-4c5e-a077-13e29a7de43f,DISK], DatanodeInfoWithStorage[127.0.0.1:33758,DS-fbd00dfd-c848-45e2-a1bb-e90fb2430d81,DISK], DatanodeInfoWithStorage[127.0.0.1:40946,DS-03e70131-35a3-44d0-b2ef-e58812575d91,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1570055731-172.17.0.21-1598452517570:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38631,DS-e7b93a1b-4eae-4571-b0b2-474741416249,DISK], DatanodeInfoWithStorage[127.0.0.1:44883,DS-8eff6a3b-5c29-4f59-984d-3d0d402997c5,DISK], DatanodeInfoWithStorage[127.0.0.1:39647,DS-e1368c76-8ff2-400b-afbf-bedb0abc9f9a,DISK], DatanodeInfoWithStorage[127.0.0.1:36927,DS-45704272-4d20-4cbb-9776-8a76c17c2a2f,DISK], DatanodeInfoWithStorage[127.0.0.1:37262,DS-bdf3fc40-0816-4708-8213-4ef0c51b5024,DISK], DatanodeInfoWithStorage[127.0.0.1:46164,DS-b91909fc-721b-4712-b001-20ef86f74e2d,DISK], DatanodeInfoWithStorage[127.0.0.1:42443,DS-bd02901b-d403-4d07-8a65-3d03c4cf436d,DISK], DatanodeInfoWithStorage[127.0.0.1:41623,DS-af706b5e-4bd7-490e-bd14-7d0798dfeffd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1570055731-172.17.0.21-1598452517570:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38631,DS-e7b93a1b-4eae-4571-b0b2-474741416249,DISK], DatanodeInfoWithStorage[127.0.0.1:44883,DS-8eff6a3b-5c29-4f59-984d-3d0d402997c5,DISK], DatanodeInfoWithStorage[127.0.0.1:39647,DS-e1368c76-8ff2-400b-afbf-bedb0abc9f9a,DISK], DatanodeInfoWithStorage[127.0.0.1:36927,DS-45704272-4d20-4cbb-9776-8a76c17c2a2f,DISK], DatanodeInfoWithStorage[127.0.0.1:37262,DS-bdf3fc40-0816-4708-8213-4ef0c51b5024,DISK], DatanodeInfoWithStorage[127.0.0.1:46164,DS-b91909fc-721b-4712-b001-20ef86f74e2d,DISK], DatanodeInfoWithStorage[127.0.0.1:42443,DS-bd02901b-d403-4d07-8a65-3d03c4cf436d,DISK], DatanodeInfoWithStorage[127.0.0.1:41623,DS-af706b5e-4bd7-490e-bd14-7d0798dfeffd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-214999916-172.17.0.21-1598452658001:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45716,DS-e797e181-d92e-41bf-82e4-4c552640d0b3,DISK], DatanodeInfoWithStorage[127.0.0.1:36012,DS-01894c28-d7cc-4578-80a4-46e34489eafc,DISK], DatanodeInfoWithStorage[127.0.0.1:39927,DS-97b2adef-7ae8-42b5-9698-d6ac3c13baf2,DISK], DatanodeInfoWithStorage[127.0.0.1:45848,DS-e9aa55e4-59e1-485f-b5e8-76dd8ab0873f,DISK], DatanodeInfoWithStorage[127.0.0.1:45251,DS-bbafe7a0-9517-4042-aaa1-1a2dbd9c65c5,DISK], DatanodeInfoWithStorage[127.0.0.1:33252,DS-daee18b1-7218-4cd8-bb37-ec4aeadbd65c,DISK], DatanodeInfoWithStorage[127.0.0.1:43836,DS-670e35f8-fb2f-4e4b-8b5f-a9490c53cedc,DISK], DatanodeInfoWithStorage[127.0.0.1:40225,DS-3ab18ffb-a0cf-4ba2-8ccb-472496726b19,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-214999916-172.17.0.21-1598452658001:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45716,DS-e797e181-d92e-41bf-82e4-4c552640d0b3,DISK], DatanodeInfoWithStorage[127.0.0.1:36012,DS-01894c28-d7cc-4578-80a4-46e34489eafc,DISK], DatanodeInfoWithStorage[127.0.0.1:39927,DS-97b2adef-7ae8-42b5-9698-d6ac3c13baf2,DISK], DatanodeInfoWithStorage[127.0.0.1:45848,DS-e9aa55e4-59e1-485f-b5e8-76dd8ab0873f,DISK], DatanodeInfoWithStorage[127.0.0.1:45251,DS-bbafe7a0-9517-4042-aaa1-1a2dbd9c65c5,DISK], DatanodeInfoWithStorage[127.0.0.1:33252,DS-daee18b1-7218-4cd8-bb37-ec4aeadbd65c,DISK], DatanodeInfoWithStorage[127.0.0.1:43836,DS-670e35f8-fb2f-4e4b-8b5f-a9490c53cedc,DISK], DatanodeInfoWithStorage[127.0.0.1:40225,DS-3ab18ffb-a0cf-4ba2-8ccb-472496726b19,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-742420732-172.17.0.21-1598453600297:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38045,DS-dbb41139-662f-41d6-ac39-d4812b595128,DISK], DatanodeInfoWithStorage[127.0.0.1:35174,DS-4d7b1d66-0143-4bbe-beeb-f5bf82add1b4,DISK], DatanodeInfoWithStorage[127.0.0.1:45835,DS-94e4968e-5eb8-4665-b25e-5e23fc38eb5c,DISK], DatanodeInfoWithStorage[127.0.0.1:39962,DS-4d1ff1ff-2ab0-4bf2-94a0-a891a0656071,DISK], DatanodeInfoWithStorage[127.0.0.1:39038,DS-2e16bc94-e98b-4877-82bd-1392614dc459,DISK], DatanodeInfoWithStorage[127.0.0.1:42741,DS-ca432d02-f891-4e81-bc4e-eb41477d946e,DISK], DatanodeInfoWithStorage[127.0.0.1:33859,DS-ea64f8ab-a7a4-427a-b448-b85d0f288a44,DISK], DatanodeInfoWithStorage[127.0.0.1:46382,DS-be130012-3e8b-45be-ae55-902cc8459bef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-742420732-172.17.0.21-1598453600297:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38045,DS-dbb41139-662f-41d6-ac39-d4812b595128,DISK], DatanodeInfoWithStorage[127.0.0.1:35174,DS-4d7b1d66-0143-4bbe-beeb-f5bf82add1b4,DISK], DatanodeInfoWithStorage[127.0.0.1:45835,DS-94e4968e-5eb8-4665-b25e-5e23fc38eb5c,DISK], DatanodeInfoWithStorage[127.0.0.1:39962,DS-4d1ff1ff-2ab0-4bf2-94a0-a891a0656071,DISK], DatanodeInfoWithStorage[127.0.0.1:39038,DS-2e16bc94-e98b-4877-82bd-1392614dc459,DISK], DatanodeInfoWithStorage[127.0.0.1:42741,DS-ca432d02-f891-4e81-bc4e-eb41477d946e,DISK], DatanodeInfoWithStorage[127.0.0.1:33859,DS-ea64f8ab-a7a4-427a-b448-b85d0f288a44,DISK], DatanodeInfoWithStorage[127.0.0.1:46382,DS-be130012-3e8b-45be-ae55-902cc8459bef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-662719523-172.17.0.21-1598454076154:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40142,DS-86161a51-56ec-4f0c-bdeb-d078930681ce,DISK], DatanodeInfoWithStorage[127.0.0.1:43097,DS-fd0e2876-d7bd-4137-810c-fd9b57155ac5,DISK], DatanodeInfoWithStorage[127.0.0.1:46461,DS-7a4e2533-84d8-42a5-acca-8ae6093b5421,DISK], DatanodeInfoWithStorage[127.0.0.1:34178,DS-cc3581c9-54ff-40f6-88e5-d4e43e0a33a4,DISK], DatanodeInfoWithStorage[127.0.0.1:35950,DS-c99f22de-579d-4a8b-bee1-3b445c432f0c,DISK], DatanodeInfoWithStorage[127.0.0.1:40191,DS-de1012bd-2a51-4cc2-83f2-fcc76f128e16,DISK], DatanodeInfoWithStorage[127.0.0.1:42182,DS-60e8d03b-a0a9-43a2-9e51-13710c68d0a6,DISK], DatanodeInfoWithStorage[127.0.0.1:33356,DS-456835ae-819f-4e22-83cb-ad1bce92307b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-662719523-172.17.0.21-1598454076154:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40142,DS-86161a51-56ec-4f0c-bdeb-d078930681ce,DISK], DatanodeInfoWithStorage[127.0.0.1:43097,DS-fd0e2876-d7bd-4137-810c-fd9b57155ac5,DISK], DatanodeInfoWithStorage[127.0.0.1:46461,DS-7a4e2533-84d8-42a5-acca-8ae6093b5421,DISK], DatanodeInfoWithStorage[127.0.0.1:34178,DS-cc3581c9-54ff-40f6-88e5-d4e43e0a33a4,DISK], DatanodeInfoWithStorage[127.0.0.1:35950,DS-c99f22de-579d-4a8b-bee1-3b445c432f0c,DISK], DatanodeInfoWithStorage[127.0.0.1:40191,DS-de1012bd-2a51-4cc2-83f2-fcc76f128e16,DISK], DatanodeInfoWithStorage[127.0.0.1:42182,DS-60e8d03b-a0a9-43a2-9e51-13710c68d0a6,DISK], DatanodeInfoWithStorage[127.0.0.1:33356,DS-456835ae-819f-4e22-83cb-ad1bce92307b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 14 out of 50
result: false positive !!!
Total execution time in seconds : 5385
