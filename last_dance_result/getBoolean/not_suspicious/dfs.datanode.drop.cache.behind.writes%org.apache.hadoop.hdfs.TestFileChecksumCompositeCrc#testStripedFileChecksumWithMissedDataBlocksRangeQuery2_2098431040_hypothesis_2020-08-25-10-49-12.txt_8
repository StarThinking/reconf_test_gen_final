reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-148855808-172.17.0.16-1598352564196:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36408,DS-30c61bf6-4ea6-4ff1-9126-23643fa4fc9d,DISK], DatanodeInfoWithStorage[127.0.0.1:37833,DS-0b21315d-ace2-47a0-9df4-e63b0e90f72d,DISK], DatanodeInfoWithStorage[127.0.0.1:43335,DS-0df3d4d9-fbed-466d-b936-0f7afbcde831,DISK], DatanodeInfoWithStorage[127.0.0.1:44867,DS-1a3d179f-fb25-4f39-80a9-11416194fc4d,DISK], DatanodeInfoWithStorage[127.0.0.1:37815,DS-ffbc3b3f-df66-4bb7-ae9a-1f9fcf9907f4,DISK], DatanodeInfoWithStorage[127.0.0.1:40240,DS-23d2d7d4-3147-4539-9b16-1beef594afc1,DISK], DatanodeInfoWithStorage[127.0.0.1:40811,DS-b4b7ee91-a747-4811-8dbc-dd5280ac7abd,DISK], DatanodeInfoWithStorage[127.0.0.1:43728,DS-3705faa2-9029-47fb-8c46-352043862542,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-148855808-172.17.0.16-1598352564196:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36408,DS-30c61bf6-4ea6-4ff1-9126-23643fa4fc9d,DISK], DatanodeInfoWithStorage[127.0.0.1:37833,DS-0b21315d-ace2-47a0-9df4-e63b0e90f72d,DISK], DatanodeInfoWithStorage[127.0.0.1:43335,DS-0df3d4d9-fbed-466d-b936-0f7afbcde831,DISK], DatanodeInfoWithStorage[127.0.0.1:44867,DS-1a3d179f-fb25-4f39-80a9-11416194fc4d,DISK], DatanodeInfoWithStorage[127.0.0.1:37815,DS-ffbc3b3f-df66-4bb7-ae9a-1f9fcf9907f4,DISK], DatanodeInfoWithStorage[127.0.0.1:40240,DS-23d2d7d4-3147-4539-9b16-1beef594afc1,DISK], DatanodeInfoWithStorage[127.0.0.1:40811,DS-b4b7ee91-a747-4811-8dbc-dd5280ac7abd,DISK], DatanodeInfoWithStorage[127.0.0.1:43728,DS-3705faa2-9029-47fb-8c46-352043862542,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-946324173-172.17.0.16-1598353012418:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39142,DS-a24c68e7-1ef4-47c2-907d-96e209f6b094,DISK], DatanodeInfoWithStorage[127.0.0.1:42739,DS-10ec6072-0d62-436c-ba09-63c32462c748,DISK], DatanodeInfoWithStorage[127.0.0.1:34303,DS-55da8604-4c30-4e8c-8151-e3ff45fde8d7,DISK], DatanodeInfoWithStorage[127.0.0.1:36920,DS-9803dd9f-294e-4f40-a362-d661095a4483,DISK], DatanodeInfoWithStorage[127.0.0.1:41080,DS-0c308c78-1db6-4a12-b614-7d243cb0f4f0,DISK], DatanodeInfoWithStorage[127.0.0.1:38216,DS-f3660a6f-bcd6-4090-995c-5ada9aeeaa1e,DISK], DatanodeInfoWithStorage[127.0.0.1:32868,DS-5a12affa-3211-4d90-a632-d65def6f01ec,DISK], DatanodeInfoWithStorage[127.0.0.1:38110,DS-e22369fe-d15e-41c9-9dad-3d36e70eb79d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-946324173-172.17.0.16-1598353012418:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39142,DS-a24c68e7-1ef4-47c2-907d-96e209f6b094,DISK], DatanodeInfoWithStorage[127.0.0.1:42739,DS-10ec6072-0d62-436c-ba09-63c32462c748,DISK], DatanodeInfoWithStorage[127.0.0.1:34303,DS-55da8604-4c30-4e8c-8151-e3ff45fde8d7,DISK], DatanodeInfoWithStorage[127.0.0.1:36920,DS-9803dd9f-294e-4f40-a362-d661095a4483,DISK], DatanodeInfoWithStorage[127.0.0.1:41080,DS-0c308c78-1db6-4a12-b614-7d243cb0f4f0,DISK], DatanodeInfoWithStorage[127.0.0.1:38216,DS-f3660a6f-bcd6-4090-995c-5ada9aeeaa1e,DISK], DatanodeInfoWithStorage[127.0.0.1:32868,DS-5a12affa-3211-4d90-a632-d65def6f01ec,DISK], DatanodeInfoWithStorage[127.0.0.1:38110,DS-e22369fe-d15e-41c9-9dad-3d36e70eb79d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1387336150-172.17.0.16-1598353306257:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35436,DS-bbf75071-dc5c-4107-a9c2-831ddcd8a646,DISK], DatanodeInfoWithStorage[127.0.0.1:45451,DS-9e97ff28-283f-4e01-8ac8-4c7f817e0c8b,DISK], DatanodeInfoWithStorage[127.0.0.1:44413,DS-a4a6b422-a093-495e-ac64-78cd963547ec,DISK], DatanodeInfoWithStorage[127.0.0.1:41564,DS-7bda7e19-2b3f-4e7f-9eab-858551887f49,DISK], DatanodeInfoWithStorage[127.0.0.1:46019,DS-75b7dbfe-e370-4c43-bc78-aaaf2e05b163,DISK], DatanodeInfoWithStorage[127.0.0.1:44757,DS-ff096c96-00c5-4019-a82d-bcd740f8de25,DISK], DatanodeInfoWithStorage[127.0.0.1:35475,DS-b2324572-4a31-4824-bb5f-d5789dc7676a,DISK], DatanodeInfoWithStorage[127.0.0.1:46073,DS-f80814f2-b54d-42a8-abce-aa9bdaf219d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1387336150-172.17.0.16-1598353306257:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35436,DS-bbf75071-dc5c-4107-a9c2-831ddcd8a646,DISK], DatanodeInfoWithStorage[127.0.0.1:45451,DS-9e97ff28-283f-4e01-8ac8-4c7f817e0c8b,DISK], DatanodeInfoWithStorage[127.0.0.1:44413,DS-a4a6b422-a093-495e-ac64-78cd963547ec,DISK], DatanodeInfoWithStorage[127.0.0.1:41564,DS-7bda7e19-2b3f-4e7f-9eab-858551887f49,DISK], DatanodeInfoWithStorage[127.0.0.1:46019,DS-75b7dbfe-e370-4c43-bc78-aaaf2e05b163,DISK], DatanodeInfoWithStorage[127.0.0.1:44757,DS-ff096c96-00c5-4019-a82d-bcd740f8de25,DISK], DatanodeInfoWithStorage[127.0.0.1:35475,DS-b2324572-4a31-4824-bb5f-d5789dc7676a,DISK], DatanodeInfoWithStorage[127.0.0.1:46073,DS-f80814f2-b54d-42a8-abce-aa9bdaf219d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1704016964-172.17.0.16-1598353493820:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45294,DS-b90db436-f842-4a10-beb7-b4774997e91b,DISK], DatanodeInfoWithStorage[127.0.0.1:41847,DS-f6637b16-e70b-448e-8b40-6439cf0b0e2b,DISK], DatanodeInfoWithStorage[127.0.0.1:33961,DS-ff56d14b-9857-4940-864f-b3495d8965fe,DISK], DatanodeInfoWithStorage[127.0.0.1:41096,DS-589198a8-2e44-4ac7-9e70-fe6f15f8b222,DISK], DatanodeInfoWithStorage[127.0.0.1:40485,DS-379c6f58-1e27-4093-b358-7760c8c084e0,DISK], DatanodeInfoWithStorage[127.0.0.1:46689,DS-03cc9c2c-2059-41fe-a669-3297b35b7431,DISK], DatanodeInfoWithStorage[127.0.0.1:33231,DS-a30cd86d-0712-41cc-8ea0-61933458235e,DISK], DatanodeInfoWithStorage[127.0.0.1:45178,DS-722d31ce-7b86-4c33-997b-410a7235a733,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1704016964-172.17.0.16-1598353493820:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45294,DS-b90db436-f842-4a10-beb7-b4774997e91b,DISK], DatanodeInfoWithStorage[127.0.0.1:41847,DS-f6637b16-e70b-448e-8b40-6439cf0b0e2b,DISK], DatanodeInfoWithStorage[127.0.0.1:33961,DS-ff56d14b-9857-4940-864f-b3495d8965fe,DISK], DatanodeInfoWithStorage[127.0.0.1:41096,DS-589198a8-2e44-4ac7-9e70-fe6f15f8b222,DISK], DatanodeInfoWithStorage[127.0.0.1:40485,DS-379c6f58-1e27-4093-b358-7760c8c084e0,DISK], DatanodeInfoWithStorage[127.0.0.1:46689,DS-03cc9c2c-2059-41fe-a669-3297b35b7431,DISK], DatanodeInfoWithStorage[127.0.0.1:33231,DS-a30cd86d-0712-41cc-8ea0-61933458235e,DISK], DatanodeInfoWithStorage[127.0.0.1:45178,DS-722d31ce-7b86-4c33-997b-410a7235a733,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1870840559-172.17.0.16-1598353569732:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44775,DS-f24e79cb-0a5e-478d-a6d8-a34a2cd9fee0,DISK], DatanodeInfoWithStorage[127.0.0.1:39224,DS-8dab87e5-2abd-4d72-b051-67c64ffd22f8,DISK], DatanodeInfoWithStorage[127.0.0.1:38920,DS-387b9a8f-5623-4c60-a24f-e04b69788a42,DISK], DatanodeInfoWithStorage[127.0.0.1:45689,DS-098adabe-b0f6-4fa0-afc5-1b75b8462655,DISK], DatanodeInfoWithStorage[127.0.0.1:46826,DS-32a5779f-679e-4c5d-8fd1-6af8dbba050a,DISK], DatanodeInfoWithStorage[127.0.0.1:32881,DS-a1816b3d-3679-4c43-b20e-d1c94885e385,DISK], DatanodeInfoWithStorage[127.0.0.1:36776,DS-05f7567a-f1c7-452e-8a2d-7120028203a7,DISK], DatanodeInfoWithStorage[127.0.0.1:36424,DS-c8c92eb5-6baf-4300-9891-ace8010b0eb0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1870840559-172.17.0.16-1598353569732:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44775,DS-f24e79cb-0a5e-478d-a6d8-a34a2cd9fee0,DISK], DatanodeInfoWithStorage[127.0.0.1:39224,DS-8dab87e5-2abd-4d72-b051-67c64ffd22f8,DISK], DatanodeInfoWithStorage[127.0.0.1:38920,DS-387b9a8f-5623-4c60-a24f-e04b69788a42,DISK], DatanodeInfoWithStorage[127.0.0.1:45689,DS-098adabe-b0f6-4fa0-afc5-1b75b8462655,DISK], DatanodeInfoWithStorage[127.0.0.1:46826,DS-32a5779f-679e-4c5d-8fd1-6af8dbba050a,DISK], DatanodeInfoWithStorage[127.0.0.1:32881,DS-a1816b3d-3679-4c43-b20e-d1c94885e385,DISK], DatanodeInfoWithStorage[127.0.0.1:36776,DS-05f7567a-f1c7-452e-8a2d-7120028203a7,DISK], DatanodeInfoWithStorage[127.0.0.1:36424,DS-c8c92eb5-6baf-4300-9891-ace8010b0eb0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-878242938-172.17.0.16-1598354522121:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33325,DS-19dea369-cce4-4a87-9ccd-6629c8eabc08,DISK], DatanodeInfoWithStorage[127.0.0.1:37209,DS-ca712e0c-bded-4c5a-8cab-32a67c2c46f9,DISK], DatanodeInfoWithStorage[127.0.0.1:33049,DS-c2ca3b27-a9f4-4e2e-9845-71192518ff40,DISK], DatanodeInfoWithStorage[127.0.0.1:45268,DS-fcf4e66e-6b45-4082-9fb2-6c000b5fae3d,DISK], DatanodeInfoWithStorage[127.0.0.1:37942,DS-acc810a1-e399-45b3-8401-7bcd5afc50d8,DISK], DatanodeInfoWithStorage[127.0.0.1:41736,DS-6d6d7465-1cc8-4a97-8415-0fd416688523,DISK], DatanodeInfoWithStorage[127.0.0.1:46141,DS-95552112-a1a8-4c78-84ad-d763da5276f1,DISK], DatanodeInfoWithStorage[127.0.0.1:38752,DS-1eff24b0-0c9c-4c11-b9d6-fe8a80a75e20,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-878242938-172.17.0.16-1598354522121:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33325,DS-19dea369-cce4-4a87-9ccd-6629c8eabc08,DISK], DatanodeInfoWithStorage[127.0.0.1:37209,DS-ca712e0c-bded-4c5a-8cab-32a67c2c46f9,DISK], DatanodeInfoWithStorage[127.0.0.1:33049,DS-c2ca3b27-a9f4-4e2e-9845-71192518ff40,DISK], DatanodeInfoWithStorage[127.0.0.1:45268,DS-fcf4e66e-6b45-4082-9fb2-6c000b5fae3d,DISK], DatanodeInfoWithStorage[127.0.0.1:37942,DS-acc810a1-e399-45b3-8401-7bcd5afc50d8,DISK], DatanodeInfoWithStorage[127.0.0.1:41736,DS-6d6d7465-1cc8-4a97-8415-0fd416688523,DISK], DatanodeInfoWithStorage[127.0.0.1:46141,DS-95552112-a1a8-4c78-84ad-d763da5276f1,DISK], DatanodeInfoWithStorage[127.0.0.1:38752,DS-1eff24b0-0c9c-4c11-b9d6-fe8a80a75e20,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-178796900-172.17.0.16-1598354836410:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44497,DS-122180d3-025f-4ce6-b405-921475daba94,DISK], DatanodeInfoWithStorage[127.0.0.1:40404,DS-2b0c78cb-4e49-413f-b16b-d058058fb29d,DISK], DatanodeInfoWithStorage[127.0.0.1:39563,DS-8c4bf10b-bc23-477f-8db8-728865b9280e,DISK], DatanodeInfoWithStorage[127.0.0.1:45274,DS-b8cff49e-d824-4796-86cc-fde04bb31611,DISK], DatanodeInfoWithStorage[127.0.0.1:39353,DS-78c32a21-bc11-466a-9392-30c02d2e94b4,DISK], DatanodeInfoWithStorage[127.0.0.1:41711,DS-a435e122-7b09-4db8-a940-bef23e9d4965,DISK], DatanodeInfoWithStorage[127.0.0.1:45895,DS-dc6a5656-8db3-4e12-b799-df19aeb0f603,DISK], DatanodeInfoWithStorage[127.0.0.1:44056,DS-82e87096-bf87-4e3f-af56-a3ec7950e4e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-178796900-172.17.0.16-1598354836410:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44497,DS-122180d3-025f-4ce6-b405-921475daba94,DISK], DatanodeInfoWithStorage[127.0.0.1:40404,DS-2b0c78cb-4e49-413f-b16b-d058058fb29d,DISK], DatanodeInfoWithStorage[127.0.0.1:39563,DS-8c4bf10b-bc23-477f-8db8-728865b9280e,DISK], DatanodeInfoWithStorage[127.0.0.1:45274,DS-b8cff49e-d824-4796-86cc-fde04bb31611,DISK], DatanodeInfoWithStorage[127.0.0.1:39353,DS-78c32a21-bc11-466a-9392-30c02d2e94b4,DISK], DatanodeInfoWithStorage[127.0.0.1:41711,DS-a435e122-7b09-4db8-a940-bef23e9d4965,DISK], DatanodeInfoWithStorage[127.0.0.1:45895,DS-dc6a5656-8db3-4e12-b799-df19aeb0f603,DISK], DatanodeInfoWithStorage[127.0.0.1:44056,DS-82e87096-bf87-4e3f-af56-a3ec7950e4e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-995998760-172.17.0.16-1598354947295:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37448,DS-29016a8d-4b65-402f-8c4f-46ddd2be456a,DISK], DatanodeInfoWithStorage[127.0.0.1:45403,DS-1a188d40-09d1-4772-a87b-3dc7024cfba2,DISK], DatanodeInfoWithStorage[127.0.0.1:45171,DS-be370286-1467-4bca-aacc-61b281074dcf,DISK], DatanodeInfoWithStorage[127.0.0.1:37132,DS-6703dbd9-76ab-427e-8dba-7138739bb2ff,DISK], DatanodeInfoWithStorage[127.0.0.1:41114,DS-ecad2665-a7aa-4715-bba1-5bae4f55b67b,DISK], DatanodeInfoWithStorage[127.0.0.1:41650,DS-baadecef-e953-49fd-864b-6e91db8c621a,DISK], DatanodeInfoWithStorage[127.0.0.1:43158,DS-29bcbfb3-0617-4718-b0a2-e8fb939b979a,DISK], DatanodeInfoWithStorage[127.0.0.1:33065,DS-c5ccc97d-7543-40cf-b3b0-9e7aeb4cb913,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-995998760-172.17.0.16-1598354947295:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37448,DS-29016a8d-4b65-402f-8c4f-46ddd2be456a,DISK], DatanodeInfoWithStorage[127.0.0.1:45403,DS-1a188d40-09d1-4772-a87b-3dc7024cfba2,DISK], DatanodeInfoWithStorage[127.0.0.1:45171,DS-be370286-1467-4bca-aacc-61b281074dcf,DISK], DatanodeInfoWithStorage[127.0.0.1:37132,DS-6703dbd9-76ab-427e-8dba-7138739bb2ff,DISK], DatanodeInfoWithStorage[127.0.0.1:41114,DS-ecad2665-a7aa-4715-bba1-5bae4f55b67b,DISK], DatanodeInfoWithStorage[127.0.0.1:41650,DS-baadecef-e953-49fd-864b-6e91db8c621a,DISK], DatanodeInfoWithStorage[127.0.0.1:43158,DS-29bcbfb3-0617-4718-b0a2-e8fb939b979a,DISK], DatanodeInfoWithStorage[127.0.0.1:33065,DS-c5ccc97d-7543-40cf-b3b0-9e7aeb4cb913,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-798562387-172.17.0.16-1598355105299:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45459,DS-770409e0-3f2b-4831-a2e2-c3a31c5f8d1a,DISK], DatanodeInfoWithStorage[127.0.0.1:36701,DS-10d49e37-898d-4a7b-a769-c2917540e156,DISK], DatanodeInfoWithStorage[127.0.0.1:37068,DS-f1a3c38e-cbdb-4677-b7ff-924e4b3feafb,DISK], DatanodeInfoWithStorage[127.0.0.1:33072,DS-e89b2ab9-16ac-4e81-836b-a1342069f12d,DISK], DatanodeInfoWithStorage[127.0.0.1:35142,DS-d41799cf-afb9-4e28-ab95-51a23aa14b71,DISK], DatanodeInfoWithStorage[127.0.0.1:46375,DS-ded7a85a-0aee-4cad-8f3b-a3f1de561e52,DISK], DatanodeInfoWithStorage[127.0.0.1:42015,DS-4f3d03ed-6a39-4569-a1af-c30bfa671678,DISK], DatanodeInfoWithStorage[127.0.0.1:36374,DS-d75bd03f-afa8-454d-ad25-1322601c1201,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-798562387-172.17.0.16-1598355105299:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45459,DS-770409e0-3f2b-4831-a2e2-c3a31c5f8d1a,DISK], DatanodeInfoWithStorage[127.0.0.1:36701,DS-10d49e37-898d-4a7b-a769-c2917540e156,DISK], DatanodeInfoWithStorage[127.0.0.1:37068,DS-f1a3c38e-cbdb-4677-b7ff-924e4b3feafb,DISK], DatanodeInfoWithStorage[127.0.0.1:33072,DS-e89b2ab9-16ac-4e81-836b-a1342069f12d,DISK], DatanodeInfoWithStorage[127.0.0.1:35142,DS-d41799cf-afb9-4e28-ab95-51a23aa14b71,DISK], DatanodeInfoWithStorage[127.0.0.1:46375,DS-ded7a85a-0aee-4cad-8f3b-a3f1de561e52,DISK], DatanodeInfoWithStorage[127.0.0.1:42015,DS-4f3d03ed-6a39-4569-a1af-c30bfa671678,DISK], DatanodeInfoWithStorage[127.0.0.1:36374,DS-d75bd03f-afa8-454d-ad25-1322601c1201,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1894462744-172.17.0.16-1598355434767:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46364,DS-4d2cf7e9-6a12-46ba-a3ca-200febfb138d,DISK], DatanodeInfoWithStorage[127.0.0.1:42147,DS-72617c1b-46cb-4505-b9ff-09c72f02f77b,DISK], DatanodeInfoWithStorage[127.0.0.1:33779,DS-47e169b2-5a2a-425a-979e-3a09cc31ad6d,DISK], DatanodeInfoWithStorage[127.0.0.1:44868,DS-69fd5ff6-e4e8-45b3-903d-140bf762d0d7,DISK], DatanodeInfoWithStorage[127.0.0.1:33854,DS-6e17dcf0-8999-42e1-8fb0-0160c3b434cb,DISK], DatanodeInfoWithStorage[127.0.0.1:43781,DS-630bfd43-d0d7-473d-a851-f33eb4d4c4c3,DISK], DatanodeInfoWithStorage[127.0.0.1:38781,DS-b6cb317d-ccec-456d-a524-f146ba7dfdc6,DISK], DatanodeInfoWithStorage[127.0.0.1:46108,DS-63d12dba-9402-46d8-87d3-97770272fe2e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1894462744-172.17.0.16-1598355434767:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46364,DS-4d2cf7e9-6a12-46ba-a3ca-200febfb138d,DISK], DatanodeInfoWithStorage[127.0.0.1:42147,DS-72617c1b-46cb-4505-b9ff-09c72f02f77b,DISK], DatanodeInfoWithStorage[127.0.0.1:33779,DS-47e169b2-5a2a-425a-979e-3a09cc31ad6d,DISK], DatanodeInfoWithStorage[127.0.0.1:44868,DS-69fd5ff6-e4e8-45b3-903d-140bf762d0d7,DISK], DatanodeInfoWithStorage[127.0.0.1:33854,DS-6e17dcf0-8999-42e1-8fb0-0160c3b434cb,DISK], DatanodeInfoWithStorage[127.0.0.1:43781,DS-630bfd43-d0d7-473d-a851-f33eb4d4c4c3,DISK], DatanodeInfoWithStorage[127.0.0.1:38781,DS-b6cb317d-ccec-456d-a524-f146ba7dfdc6,DISK], DatanodeInfoWithStorage[127.0.0.1:46108,DS-63d12dba-9402-46d8-87d3-97770272fe2e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1389254325-172.17.0.16-1598355503354:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43749,DS-325d81fd-1c24-4d39-85b0-02d5a0a206aa,DISK], DatanodeInfoWithStorage[127.0.0.1:33486,DS-c4357191-f36c-41c2-8f7c-8f34e8589fc5,DISK], DatanodeInfoWithStorage[127.0.0.1:36068,DS-170e5959-605f-43eb-9c3b-d261dfe862c2,DISK], DatanodeInfoWithStorage[127.0.0.1:39671,DS-94d680b8-3ba7-4a7d-9bfe-27a8979682bb,DISK], DatanodeInfoWithStorage[127.0.0.1:45068,DS-ab67373f-6d95-48f7-99e2-9e595f02a22d,DISK], DatanodeInfoWithStorage[127.0.0.1:38201,DS-ade99a32-60e3-44e7-bb7d-91ec0e51afab,DISK], DatanodeInfoWithStorage[127.0.0.1:45064,DS-117594d9-cef8-487f-8b94-17e283050c25,DISK], DatanodeInfoWithStorage[127.0.0.1:45025,DS-a344abd3-95b9-41b0-aa9d-43dc65c1fa4a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1389254325-172.17.0.16-1598355503354:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43749,DS-325d81fd-1c24-4d39-85b0-02d5a0a206aa,DISK], DatanodeInfoWithStorage[127.0.0.1:33486,DS-c4357191-f36c-41c2-8f7c-8f34e8589fc5,DISK], DatanodeInfoWithStorage[127.0.0.1:36068,DS-170e5959-605f-43eb-9c3b-d261dfe862c2,DISK], DatanodeInfoWithStorage[127.0.0.1:39671,DS-94d680b8-3ba7-4a7d-9bfe-27a8979682bb,DISK], DatanodeInfoWithStorage[127.0.0.1:45068,DS-ab67373f-6d95-48f7-99e2-9e595f02a22d,DISK], DatanodeInfoWithStorage[127.0.0.1:38201,DS-ade99a32-60e3-44e7-bb7d-91ec0e51afab,DISK], DatanodeInfoWithStorage[127.0.0.1:45064,DS-117594d9-cef8-487f-8b94-17e283050c25,DISK], DatanodeInfoWithStorage[127.0.0.1:45025,DS-a344abd3-95b9-41b0-aa9d-43dc65c1fa4a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1758195545-172.17.0.16-1598355539077:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42240,DS-b2a1042f-d47f-4473-8524-6078e8aaf8f1,DISK], DatanodeInfoWithStorage[127.0.0.1:42513,DS-1a90d521-c70d-48cc-b565-10e26d1ae40c,DISK], DatanodeInfoWithStorage[127.0.0.1:38501,DS-c6b9070f-51b4-417d-b2a4-a2cb4d961b59,DISK], DatanodeInfoWithStorage[127.0.0.1:36888,DS-e68b8963-54c7-4d41-a462-08ec12562f5c,DISK], DatanodeInfoWithStorage[127.0.0.1:44437,DS-798dbc4e-97ea-4008-ab65-06d7b5902f3e,DISK], DatanodeInfoWithStorage[127.0.0.1:46237,DS-44ed8bc0-5381-42c6-82a7-07b5e997e77e,DISK], DatanodeInfoWithStorage[127.0.0.1:38808,DS-82b1421a-aefc-4065-908f-438e70d6ecd5,DISK], DatanodeInfoWithStorage[127.0.0.1:34112,DS-548ae88b-5956-4102-9404-a91c4797daaf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1758195545-172.17.0.16-1598355539077:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42240,DS-b2a1042f-d47f-4473-8524-6078e8aaf8f1,DISK], DatanodeInfoWithStorage[127.0.0.1:42513,DS-1a90d521-c70d-48cc-b565-10e26d1ae40c,DISK], DatanodeInfoWithStorage[127.0.0.1:38501,DS-c6b9070f-51b4-417d-b2a4-a2cb4d961b59,DISK], DatanodeInfoWithStorage[127.0.0.1:36888,DS-e68b8963-54c7-4d41-a462-08ec12562f5c,DISK], DatanodeInfoWithStorage[127.0.0.1:44437,DS-798dbc4e-97ea-4008-ab65-06d7b5902f3e,DISK], DatanodeInfoWithStorage[127.0.0.1:46237,DS-44ed8bc0-5381-42c6-82a7-07b5e997e77e,DISK], DatanodeInfoWithStorage[127.0.0.1:38808,DS-82b1421a-aefc-4065-908f-438e70d6ecd5,DISK], DatanodeInfoWithStorage[127.0.0.1:34112,DS-548ae88b-5956-4102-9404-a91c4797daaf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1663424995-172.17.0.16-1598356049887:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43683,DS-d7804778-1e69-4388-8b01-c9121bcb7488,DISK], DatanodeInfoWithStorage[127.0.0.1:45828,DS-85c6236d-8759-4e01-b964-005c8888eeda,DISK], DatanodeInfoWithStorage[127.0.0.1:46635,DS-7da1b70f-b4fd-4882-968f-41fd775ac608,DISK], DatanodeInfoWithStorage[127.0.0.1:43742,DS-46ea0744-6875-4d9d-a005-cb28eb60234f,DISK], DatanodeInfoWithStorage[127.0.0.1:44681,DS-bf56eb55-83f6-4191-95ee-d549ea849c69,DISK], DatanodeInfoWithStorage[127.0.0.1:37126,DS-20911dbb-e76c-4610-b1d1-392ec5646f88,DISK], DatanodeInfoWithStorage[127.0.0.1:45059,DS-a3dcf154-71cc-4e83-a4a1-93ef0f289f3f,DISK], DatanodeInfoWithStorage[127.0.0.1:34164,DS-9d3aefcc-e5db-4bcb-8017-8b994e110d5f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1663424995-172.17.0.16-1598356049887:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43683,DS-d7804778-1e69-4388-8b01-c9121bcb7488,DISK], DatanodeInfoWithStorage[127.0.0.1:45828,DS-85c6236d-8759-4e01-b964-005c8888eeda,DISK], DatanodeInfoWithStorage[127.0.0.1:46635,DS-7da1b70f-b4fd-4882-968f-41fd775ac608,DISK], DatanodeInfoWithStorage[127.0.0.1:43742,DS-46ea0744-6875-4d9d-a005-cb28eb60234f,DISK], DatanodeInfoWithStorage[127.0.0.1:44681,DS-bf56eb55-83f6-4191-95ee-d549ea849c69,DISK], DatanodeInfoWithStorage[127.0.0.1:37126,DS-20911dbb-e76c-4610-b1d1-392ec5646f88,DISK], DatanodeInfoWithStorage[127.0.0.1:45059,DS-a3dcf154-71cc-4e83-a4a1-93ef0f289f3f,DISK], DatanodeInfoWithStorage[127.0.0.1:34164,DS-9d3aefcc-e5db-4bcb-8017-8b994e110d5f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1486887473-172.17.0.16-1598356364756:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46769,DS-b3cf1bfc-dbd6-448e-9c79-3ff2704a2b60,DISK], DatanodeInfoWithStorage[127.0.0.1:37039,DS-61fabf2c-f2f7-4a93-8411-6300cfe3f6e9,DISK], DatanodeInfoWithStorage[127.0.0.1:35157,DS-dc489779-fdcd-40e2-86e1-72d42636e552,DISK], DatanodeInfoWithStorage[127.0.0.1:38845,DS-de53a7c9-6ca6-41c5-a8e5-93aabf3a6511,DISK], DatanodeInfoWithStorage[127.0.0.1:38473,DS-3c93a5ab-a4fd-47cc-94c1-3b9869dc73bd,DISK], DatanodeInfoWithStorage[127.0.0.1:42181,DS-453887ef-da99-49a9-837b-8f980242bda7,DISK], DatanodeInfoWithStorage[127.0.0.1:40757,DS-16a16d76-d0c7-458b-8fe8-87e541279a83,DISK], DatanodeInfoWithStorage[127.0.0.1:41914,DS-8b7dcc98-2254-4b62-9e24-69a9521c07fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1486887473-172.17.0.16-1598356364756:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46769,DS-b3cf1bfc-dbd6-448e-9c79-3ff2704a2b60,DISK], DatanodeInfoWithStorage[127.0.0.1:37039,DS-61fabf2c-f2f7-4a93-8411-6300cfe3f6e9,DISK], DatanodeInfoWithStorage[127.0.0.1:35157,DS-dc489779-fdcd-40e2-86e1-72d42636e552,DISK], DatanodeInfoWithStorage[127.0.0.1:38845,DS-de53a7c9-6ca6-41c5-a8e5-93aabf3a6511,DISK], DatanodeInfoWithStorage[127.0.0.1:38473,DS-3c93a5ab-a4fd-47cc-94c1-3b9869dc73bd,DISK], DatanodeInfoWithStorage[127.0.0.1:42181,DS-453887ef-da99-49a9-837b-8f980242bda7,DISK], DatanodeInfoWithStorage[127.0.0.1:40757,DS-16a16d76-d0c7-458b-8fe8-87e541279a83,DISK], DatanodeInfoWithStorage[127.0.0.1:41914,DS-8b7dcc98-2254-4b62-9e24-69a9521c07fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1003672855-172.17.0.16-1598356477611:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43464,DS-5520a10b-a77c-4d31-ab94-4fb858726b9f,DISK], DatanodeInfoWithStorage[127.0.0.1:33891,DS-59eefdd7-2612-4e4a-98b5-fe06bf386093,DISK], DatanodeInfoWithStorage[127.0.0.1:43066,DS-9ac393c2-68fe-450b-aff6-c1ec206ab285,DISK], DatanodeInfoWithStorage[127.0.0.1:43716,DS-d75ad66f-9d8b-46ca-8fcb-961fcdd37cfb,DISK], DatanodeInfoWithStorage[127.0.0.1:39583,DS-0bce0465-3695-4205-b679-df0d9d92a943,DISK], DatanodeInfoWithStorage[127.0.0.1:37808,DS-5e343542-1ce1-4b46-96a8-c59363db1806,DISK], DatanodeInfoWithStorage[127.0.0.1:41203,DS-515d0919-61c8-46b3-b2e6-ea28e5d83dff,DISK], DatanodeInfoWithStorage[127.0.0.1:34658,DS-48a8594a-3eb6-4564-8906-aba62fff55be,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1003672855-172.17.0.16-1598356477611:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43464,DS-5520a10b-a77c-4d31-ab94-4fb858726b9f,DISK], DatanodeInfoWithStorage[127.0.0.1:33891,DS-59eefdd7-2612-4e4a-98b5-fe06bf386093,DISK], DatanodeInfoWithStorage[127.0.0.1:43066,DS-9ac393c2-68fe-450b-aff6-c1ec206ab285,DISK], DatanodeInfoWithStorage[127.0.0.1:43716,DS-d75ad66f-9d8b-46ca-8fcb-961fcdd37cfb,DISK], DatanodeInfoWithStorage[127.0.0.1:39583,DS-0bce0465-3695-4205-b679-df0d9d92a943,DISK], DatanodeInfoWithStorage[127.0.0.1:37808,DS-5e343542-1ce1-4b46-96a8-c59363db1806,DISK], DatanodeInfoWithStorage[127.0.0.1:41203,DS-515d0919-61c8-46b3-b2e6-ea28e5d83dff,DISK], DatanodeInfoWithStorage[127.0.0.1:34658,DS-48a8594a-3eb6-4564-8906-aba62fff55be,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1328019919-172.17.0.16-1598357214151:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36569,DS-3a4fed69-64d5-4e7c-a191-ba4995e1729e,DISK], DatanodeInfoWithStorage[127.0.0.1:37815,DS-605225dc-ff61-4d33-a223-1bfefc29887c,DISK], DatanodeInfoWithStorage[127.0.0.1:44216,DS-d2ac1a13-78de-4d9f-b4a9-2919032d0ec0,DISK], DatanodeInfoWithStorage[127.0.0.1:45554,DS-fce8e223-cb80-4de0-9687-21f64e38097f,DISK], DatanodeInfoWithStorage[127.0.0.1:33093,DS-9fa62fe1-d9ce-45af-a4d6-08626fba6801,DISK], DatanodeInfoWithStorage[127.0.0.1:41669,DS-9108afaa-b015-4abf-9f2f-7dd9058eb5b8,DISK], DatanodeInfoWithStorage[127.0.0.1:39382,DS-87f2a5c5-8b2a-451c-9264-f9cd906a648e,DISK], DatanodeInfoWithStorage[127.0.0.1:35907,DS-35426e2a-db3d-4045-822c-9e1293bef20b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1328019919-172.17.0.16-1598357214151:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36569,DS-3a4fed69-64d5-4e7c-a191-ba4995e1729e,DISK], DatanodeInfoWithStorage[127.0.0.1:37815,DS-605225dc-ff61-4d33-a223-1bfefc29887c,DISK], DatanodeInfoWithStorage[127.0.0.1:44216,DS-d2ac1a13-78de-4d9f-b4a9-2919032d0ec0,DISK], DatanodeInfoWithStorage[127.0.0.1:45554,DS-fce8e223-cb80-4de0-9687-21f64e38097f,DISK], DatanodeInfoWithStorage[127.0.0.1:33093,DS-9fa62fe1-d9ce-45af-a4d6-08626fba6801,DISK], DatanodeInfoWithStorage[127.0.0.1:41669,DS-9108afaa-b015-4abf-9f2f-7dd9058eb5b8,DISK], DatanodeInfoWithStorage[127.0.0.1:39382,DS-87f2a5c5-8b2a-451c-9264-f9cd906a648e,DISK], DatanodeInfoWithStorage[127.0.0.1:35907,DS-35426e2a-db3d-4045-822c-9e1293bef20b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1920650062-172.17.0.16-1598357563727:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44875,DS-4d5175aa-1980-4a2d-893e-1d9419ac416f,DISK], DatanodeInfoWithStorage[127.0.0.1:32842,DS-bb0960d5-cbd1-4d44-9539-5144121fce39,DISK], DatanodeInfoWithStorage[127.0.0.1:42013,DS-54327914-bde7-43ef-a357-de99e23f6d6a,DISK], DatanodeInfoWithStorage[127.0.0.1:36388,DS-c64d18e4-5cdf-44fa-950f-a10f86fc894b,DISK], DatanodeInfoWithStorage[127.0.0.1:40225,DS-52d0134f-e2b5-42d4-8ff3-81511a94177d,DISK], DatanodeInfoWithStorage[127.0.0.1:46375,DS-dd152515-64e6-4478-b0b3-21b4d0467dbd,DISK], DatanodeInfoWithStorage[127.0.0.1:44065,DS-83d256c0-151b-42e4-b93e-5ab19c2073df,DISK], DatanodeInfoWithStorage[127.0.0.1:41007,DS-16700e1b-418c-4c5a-a9e9-8b377aa61723,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1920650062-172.17.0.16-1598357563727:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44875,DS-4d5175aa-1980-4a2d-893e-1d9419ac416f,DISK], DatanodeInfoWithStorage[127.0.0.1:32842,DS-bb0960d5-cbd1-4d44-9539-5144121fce39,DISK], DatanodeInfoWithStorage[127.0.0.1:42013,DS-54327914-bde7-43ef-a357-de99e23f6d6a,DISK], DatanodeInfoWithStorage[127.0.0.1:36388,DS-c64d18e4-5cdf-44fa-950f-a10f86fc894b,DISK], DatanodeInfoWithStorage[127.0.0.1:40225,DS-52d0134f-e2b5-42d4-8ff3-81511a94177d,DISK], DatanodeInfoWithStorage[127.0.0.1:46375,DS-dd152515-64e6-4478-b0b3-21b4d0467dbd,DISK], DatanodeInfoWithStorage[127.0.0.1:44065,DS-83d256c0-151b-42e4-b93e-5ab19c2073df,DISK], DatanodeInfoWithStorage[127.0.0.1:41007,DS-16700e1b-418c-4c5a-a9e9-8b377aa61723,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1096468674-172.17.0.16-1598357913829:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33291,DS-f0ab6db8-3c3d-49c2-80dc-334d0f8414a5,DISK], DatanodeInfoWithStorage[127.0.0.1:42430,DS-042dd74d-2739-4246-91e5-7dcf732ddcd2,DISK], DatanodeInfoWithStorage[127.0.0.1:40544,DS-6a264dfc-c280-4c4b-a19d-ed3c1b530e18,DISK], DatanodeInfoWithStorage[127.0.0.1:43714,DS-ee9eb835-5951-4e43-ab41-7f734602dfa7,DISK], DatanodeInfoWithStorage[127.0.0.1:38693,DS-22767952-2e45-4b62-aaa4-e57a83209458,DISK], DatanodeInfoWithStorage[127.0.0.1:34212,DS-4e6ec3f4-d44d-4e69-9ae1-a6b71b09c139,DISK], DatanodeInfoWithStorage[127.0.0.1:36413,DS-3ed73be6-eeaf-46da-af23-c0362a454550,DISK], DatanodeInfoWithStorage[127.0.0.1:42001,DS-7747f386-9748-4d36-a189-de0623935dbe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1096468674-172.17.0.16-1598357913829:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33291,DS-f0ab6db8-3c3d-49c2-80dc-334d0f8414a5,DISK], DatanodeInfoWithStorage[127.0.0.1:42430,DS-042dd74d-2739-4246-91e5-7dcf732ddcd2,DISK], DatanodeInfoWithStorage[127.0.0.1:40544,DS-6a264dfc-c280-4c4b-a19d-ed3c1b530e18,DISK], DatanodeInfoWithStorage[127.0.0.1:43714,DS-ee9eb835-5951-4e43-ab41-7f734602dfa7,DISK], DatanodeInfoWithStorage[127.0.0.1:38693,DS-22767952-2e45-4b62-aaa4-e57a83209458,DISK], DatanodeInfoWithStorage[127.0.0.1:34212,DS-4e6ec3f4-d44d-4e69-9ae1-a6b71b09c139,DISK], DatanodeInfoWithStorage[127.0.0.1:36413,DS-3ed73be6-eeaf-46da-af23-c0362a454550,DISK], DatanodeInfoWithStorage[127.0.0.1:42001,DS-7747f386-9748-4d36-a189-de0623935dbe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 10 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: might be true error
Total execution time in seconds : 5384
