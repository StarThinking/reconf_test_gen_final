reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-624123532-172.17.0.4-1598142151268:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44305,DS-c0c812b0-b313-4a33-907e-682d6d53cad2,DISK], DatanodeInfoWithStorage[127.0.0.1:45146,DS-a0c3dfe2-a483-4eab-8bf3-1fb539a0777f,DISK], DatanodeInfoWithStorage[127.0.0.1:37310,DS-6000b625-9a3b-476b-8ecc-bba598a904aa,DISK], DatanodeInfoWithStorage[127.0.0.1:45286,DS-3be284f3-98cc-472b-98ba-47c9e8d33b26,DISK], DatanodeInfoWithStorage[127.0.0.1:42870,DS-69afab4b-e78c-40a4-a113-1d9785af9e82,DISK], DatanodeInfoWithStorage[127.0.0.1:42077,DS-d7bcea34-4882-4cb4-a598-952d549b5040,DISK], DatanodeInfoWithStorage[127.0.0.1:38939,DS-7aa74eb3-7498-44cc-8794-353f9883695d,DISK], DatanodeInfoWithStorage[127.0.0.1:35166,DS-3568bba7-818f-469b-97c0-1b5274af342e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-624123532-172.17.0.4-1598142151268:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44305,DS-c0c812b0-b313-4a33-907e-682d6d53cad2,DISK], DatanodeInfoWithStorage[127.0.0.1:45146,DS-a0c3dfe2-a483-4eab-8bf3-1fb539a0777f,DISK], DatanodeInfoWithStorage[127.0.0.1:37310,DS-6000b625-9a3b-476b-8ecc-bba598a904aa,DISK], DatanodeInfoWithStorage[127.0.0.1:45286,DS-3be284f3-98cc-472b-98ba-47c9e8d33b26,DISK], DatanodeInfoWithStorage[127.0.0.1:42870,DS-69afab4b-e78c-40a4-a113-1d9785af9e82,DISK], DatanodeInfoWithStorage[127.0.0.1:42077,DS-d7bcea34-4882-4cb4-a598-952d549b5040,DISK], DatanodeInfoWithStorage[127.0.0.1:38939,DS-7aa74eb3-7498-44cc-8794-353f9883695d,DISK], DatanodeInfoWithStorage[127.0.0.1:35166,DS-3568bba7-818f-469b-97c0-1b5274af342e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2086250159-172.17.0.4-1598142309152:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46866,DS-e63712eb-dfd3-476a-a912-38520f6c4f6c,DISK], DatanodeInfoWithStorage[127.0.0.1:40032,DS-a59f6ed9-1b0b-4b35-ba2f-57ac995c1fa2,DISK], DatanodeInfoWithStorage[127.0.0.1:45146,DS-07df7f83-d901-4b17-b011-43a52f768689,DISK], DatanodeInfoWithStorage[127.0.0.1:46012,DS-178a939a-7346-4603-ae1a-e7a615ecd37d,DISK], DatanodeInfoWithStorage[127.0.0.1:42684,DS-e42cdc09-b3e1-4e6a-9537-32fafb67e541,DISK], DatanodeInfoWithStorage[127.0.0.1:41824,DS-72a83a67-8e35-44a7-b229-518036b029df,DISK], DatanodeInfoWithStorage[127.0.0.1:33163,DS-8969d365-3f5f-417c-8991-2d681e809bc9,DISK], DatanodeInfoWithStorage[127.0.0.1:40692,DS-750a2c95-c304-4562-abdb-71d66d054bbb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2086250159-172.17.0.4-1598142309152:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46866,DS-e63712eb-dfd3-476a-a912-38520f6c4f6c,DISK], DatanodeInfoWithStorage[127.0.0.1:40032,DS-a59f6ed9-1b0b-4b35-ba2f-57ac995c1fa2,DISK], DatanodeInfoWithStorage[127.0.0.1:45146,DS-07df7f83-d901-4b17-b011-43a52f768689,DISK], DatanodeInfoWithStorage[127.0.0.1:46012,DS-178a939a-7346-4603-ae1a-e7a615ecd37d,DISK], DatanodeInfoWithStorage[127.0.0.1:42684,DS-e42cdc09-b3e1-4e6a-9537-32fafb67e541,DISK], DatanodeInfoWithStorage[127.0.0.1:41824,DS-72a83a67-8e35-44a7-b229-518036b029df,DISK], DatanodeInfoWithStorage[127.0.0.1:33163,DS-8969d365-3f5f-417c-8991-2d681e809bc9,DISK], DatanodeInfoWithStorage[127.0.0.1:40692,DS-750a2c95-c304-4562-abdb-71d66d054bbb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-404119795-172.17.0.4-1598142473400:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35754,DS-04c31287-0712-443d-b45f-e45ac5802d4a,DISK], DatanodeInfoWithStorage[127.0.0.1:42814,DS-662a60cd-a52b-488e-8a38-92c926732a6e,DISK], DatanodeInfoWithStorage[127.0.0.1:33142,DS-fcf7bae1-8d40-48a7-9643-0a6d92feffed,DISK], DatanodeInfoWithStorage[127.0.0.1:36949,DS-6a2299a0-d63c-4bd6-8e69-5516c13200e9,DISK], DatanodeInfoWithStorage[127.0.0.1:36885,DS-94e2c49e-bd93-429b-98b3-e51b57a5375d,DISK], DatanodeInfoWithStorage[127.0.0.1:41402,DS-d6b34084-2b45-4579-9d07-2265aa557bb1,DISK], DatanodeInfoWithStorage[127.0.0.1:44576,DS-b1951693-a5d8-41c6-8d3a-8f3d40516b88,DISK], DatanodeInfoWithStorage[127.0.0.1:34626,DS-a4bdcc59-c15c-43ac-8c2c-b9fca5d81222,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-404119795-172.17.0.4-1598142473400:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35754,DS-04c31287-0712-443d-b45f-e45ac5802d4a,DISK], DatanodeInfoWithStorage[127.0.0.1:42814,DS-662a60cd-a52b-488e-8a38-92c926732a6e,DISK], DatanodeInfoWithStorage[127.0.0.1:33142,DS-fcf7bae1-8d40-48a7-9643-0a6d92feffed,DISK], DatanodeInfoWithStorage[127.0.0.1:36949,DS-6a2299a0-d63c-4bd6-8e69-5516c13200e9,DISK], DatanodeInfoWithStorage[127.0.0.1:36885,DS-94e2c49e-bd93-429b-98b3-e51b57a5375d,DISK], DatanodeInfoWithStorage[127.0.0.1:41402,DS-d6b34084-2b45-4579-9d07-2265aa557bb1,DISK], DatanodeInfoWithStorage[127.0.0.1:44576,DS-b1951693-a5d8-41c6-8d3a-8f3d40516b88,DISK], DatanodeInfoWithStorage[127.0.0.1:34626,DS-a4bdcc59-c15c-43ac-8c2c-b9fca5d81222,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1731740932-172.17.0.4-1598142770685:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42107,DS-28106681-89c0-48ef-a930-74723221b83a,DISK], DatanodeInfoWithStorage[127.0.0.1:43317,DS-b4d6bbfa-ea57-4630-877f-c17c26d43e63,DISK], DatanodeInfoWithStorage[127.0.0.1:36538,DS-66ade5f8-1ffa-4484-b406-1f6a3946ca95,DISK], DatanodeInfoWithStorage[127.0.0.1:41759,DS-b67cb2f7-7f81-4245-93a3-2104be94613b,DISK], DatanodeInfoWithStorage[127.0.0.1:42381,DS-d8462726-e12f-43b3-a893-98897b1cbc01,DISK], DatanodeInfoWithStorage[127.0.0.1:42948,DS-122063a1-576c-4318-bb23-8658e7c52fd5,DISK], DatanodeInfoWithStorage[127.0.0.1:45252,DS-475b2e7d-b5cf-4cd6-a7da-2884992ba048,DISK], DatanodeInfoWithStorage[127.0.0.1:42697,DS-619faafc-bdd2-47b3-969b-74aded312995,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1731740932-172.17.0.4-1598142770685:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42107,DS-28106681-89c0-48ef-a930-74723221b83a,DISK], DatanodeInfoWithStorage[127.0.0.1:43317,DS-b4d6bbfa-ea57-4630-877f-c17c26d43e63,DISK], DatanodeInfoWithStorage[127.0.0.1:36538,DS-66ade5f8-1ffa-4484-b406-1f6a3946ca95,DISK], DatanodeInfoWithStorage[127.0.0.1:41759,DS-b67cb2f7-7f81-4245-93a3-2104be94613b,DISK], DatanodeInfoWithStorage[127.0.0.1:42381,DS-d8462726-e12f-43b3-a893-98897b1cbc01,DISK], DatanodeInfoWithStorage[127.0.0.1:42948,DS-122063a1-576c-4318-bb23-8658e7c52fd5,DISK], DatanodeInfoWithStorage[127.0.0.1:45252,DS-475b2e7d-b5cf-4cd6-a7da-2884992ba048,DISK], DatanodeInfoWithStorage[127.0.0.1:42697,DS-619faafc-bdd2-47b3-969b-74aded312995,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1299008369-172.17.0.4-1598142949806:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38124,DS-82f9a722-154a-459f-ab83-8e57cc94005e,DISK], DatanodeInfoWithStorage[127.0.0.1:38169,DS-7858b8a9-0ffd-43bc-9769-0fe0b06beb0f,DISK], DatanodeInfoWithStorage[127.0.0.1:38966,DS-59cd47f8-8d5b-4acb-8dff-30d46d1fbdd4,DISK], DatanodeInfoWithStorage[127.0.0.1:39763,DS-92f31ba2-0d33-43dd-bc03-962983b17ed5,DISK], DatanodeInfoWithStorage[127.0.0.1:42420,DS-c2bc71f3-7ff4-4c90-8571-f74ee238f11d,DISK], DatanodeInfoWithStorage[127.0.0.1:44582,DS-c6c9bc6c-6f65-4156-be00-ad03efc1874d,DISK], DatanodeInfoWithStorage[127.0.0.1:46242,DS-f36e08e6-f596-4f69-8240-7d1e5a280fd7,DISK], DatanodeInfoWithStorage[127.0.0.1:40898,DS-d568d381-a4d4-4269-acc4-a4aba0760d8b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1299008369-172.17.0.4-1598142949806:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38124,DS-82f9a722-154a-459f-ab83-8e57cc94005e,DISK], DatanodeInfoWithStorage[127.0.0.1:38169,DS-7858b8a9-0ffd-43bc-9769-0fe0b06beb0f,DISK], DatanodeInfoWithStorage[127.0.0.1:38966,DS-59cd47f8-8d5b-4acb-8dff-30d46d1fbdd4,DISK], DatanodeInfoWithStorage[127.0.0.1:39763,DS-92f31ba2-0d33-43dd-bc03-962983b17ed5,DISK], DatanodeInfoWithStorage[127.0.0.1:42420,DS-c2bc71f3-7ff4-4c90-8571-f74ee238f11d,DISK], DatanodeInfoWithStorage[127.0.0.1:44582,DS-c6c9bc6c-6f65-4156-be00-ad03efc1874d,DISK], DatanodeInfoWithStorage[127.0.0.1:46242,DS-f36e08e6-f596-4f69-8240-7d1e5a280fd7,DISK], DatanodeInfoWithStorage[127.0.0.1:40898,DS-d568d381-a4d4-4269-acc4-a4aba0760d8b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-287690731-172.17.0.4-1598143029775:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37447,DS-352b8c46-665d-4b61-8232-5d88cb794b3a,DISK], DatanodeInfoWithStorage[127.0.0.1:38021,DS-87e7dad8-7825-47c5-902b-5e5740ddbf13,DISK], DatanodeInfoWithStorage[127.0.0.1:37833,DS-bde84faf-c57d-4cd8-a54c-d0c10908783a,DISK], DatanodeInfoWithStorage[127.0.0.1:33246,DS-95539a88-08b3-4dd0-a1a2-be64b53478b5,DISK], DatanodeInfoWithStorage[127.0.0.1:46721,DS-1b7c8bb5-581d-4096-a277-c7e4e760d6a0,DISK], DatanodeInfoWithStorage[127.0.0.1:34922,DS-05e3ac22-0e6f-437d-bf12-96545e15a867,DISK], DatanodeInfoWithStorage[127.0.0.1:39458,DS-901ea0dc-982b-44b1-95f8-930ce9db12b4,DISK], DatanodeInfoWithStorage[127.0.0.1:39459,DS-65017339-ab87-4044-a5a5-8cc7c935a965,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-287690731-172.17.0.4-1598143029775:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37447,DS-352b8c46-665d-4b61-8232-5d88cb794b3a,DISK], DatanodeInfoWithStorage[127.0.0.1:38021,DS-87e7dad8-7825-47c5-902b-5e5740ddbf13,DISK], DatanodeInfoWithStorage[127.0.0.1:37833,DS-bde84faf-c57d-4cd8-a54c-d0c10908783a,DISK], DatanodeInfoWithStorage[127.0.0.1:33246,DS-95539a88-08b3-4dd0-a1a2-be64b53478b5,DISK], DatanodeInfoWithStorage[127.0.0.1:46721,DS-1b7c8bb5-581d-4096-a277-c7e4e760d6a0,DISK], DatanodeInfoWithStorage[127.0.0.1:34922,DS-05e3ac22-0e6f-437d-bf12-96545e15a867,DISK], DatanodeInfoWithStorage[127.0.0.1:39458,DS-901ea0dc-982b-44b1-95f8-930ce9db12b4,DISK], DatanodeInfoWithStorage[127.0.0.1:39459,DS-65017339-ab87-4044-a5a5-8cc7c935a965,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-168069532-172.17.0.4-1598143552206:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38158,DS-4de1a056-e1df-4b26-841d-2e7032c50b00,DISK], DatanodeInfoWithStorage[127.0.0.1:34781,DS-a3603625-c5eb-441b-bb0d-2a37039a4687,DISK], DatanodeInfoWithStorage[127.0.0.1:40069,DS-48658842-31d3-4a06-830e-6ab1ecd45c2c,DISK], DatanodeInfoWithStorage[127.0.0.1:46658,DS-ce3a29fb-21cf-41bd-b7da-5cfde1bc1ecc,DISK], DatanodeInfoWithStorage[127.0.0.1:38682,DS-7f20f5d4-c729-46a6-a396-d55be8884c3c,DISK], DatanodeInfoWithStorage[127.0.0.1:36817,DS-b694e15f-af63-4eeb-98e5-340baab2f468,DISK], DatanodeInfoWithStorage[127.0.0.1:42713,DS-e8b4f2b1-e728-435d-acb4-2271f764e151,DISK], DatanodeInfoWithStorage[127.0.0.1:39994,DS-31ab5fb7-0f3a-48a6-bf89-6c0f1ea0e98e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-168069532-172.17.0.4-1598143552206:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38158,DS-4de1a056-e1df-4b26-841d-2e7032c50b00,DISK], DatanodeInfoWithStorage[127.0.0.1:34781,DS-a3603625-c5eb-441b-bb0d-2a37039a4687,DISK], DatanodeInfoWithStorage[127.0.0.1:40069,DS-48658842-31d3-4a06-830e-6ab1ecd45c2c,DISK], DatanodeInfoWithStorage[127.0.0.1:46658,DS-ce3a29fb-21cf-41bd-b7da-5cfde1bc1ecc,DISK], DatanodeInfoWithStorage[127.0.0.1:38682,DS-7f20f5d4-c729-46a6-a396-d55be8884c3c,DISK], DatanodeInfoWithStorage[127.0.0.1:36817,DS-b694e15f-af63-4eeb-98e5-340baab2f468,DISK], DatanodeInfoWithStorage[127.0.0.1:42713,DS-e8b4f2b1-e728-435d-acb4-2271f764e151,DISK], DatanodeInfoWithStorage[127.0.0.1:39994,DS-31ab5fb7-0f3a-48a6-bf89-6c0f1ea0e98e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1416766875-172.17.0.4-1598143876858:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34892,DS-1fb606fa-09f1-4e23-bf06-3375e22f3cf5,DISK], DatanodeInfoWithStorage[127.0.0.1:39287,DS-f833f7df-34b2-4595-bf17-6bef49bc3604,DISK], DatanodeInfoWithStorage[127.0.0.1:35461,DS-dc8b2123-d74d-46f2-a04f-d77e2936ab06,DISK], DatanodeInfoWithStorage[127.0.0.1:41313,DS-20861a7b-1bcf-4943-a06e-79c12ec26f7f,DISK], DatanodeInfoWithStorage[127.0.0.1:40268,DS-613f7f51-bdc5-4e2b-9e3b-e0201e1fab89,DISK], DatanodeInfoWithStorage[127.0.0.1:35444,DS-7e8e92ec-30e3-45cb-9ba5-21a33b03f322,DISK], DatanodeInfoWithStorage[127.0.0.1:42307,DS-de0002ba-2fd9-477c-a542-26714b903e4e,DISK], DatanodeInfoWithStorage[127.0.0.1:33172,DS-ac5a2801-8ee6-4598-a383-7ceaba049c2a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1416766875-172.17.0.4-1598143876858:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34892,DS-1fb606fa-09f1-4e23-bf06-3375e22f3cf5,DISK], DatanodeInfoWithStorage[127.0.0.1:39287,DS-f833f7df-34b2-4595-bf17-6bef49bc3604,DISK], DatanodeInfoWithStorage[127.0.0.1:35461,DS-dc8b2123-d74d-46f2-a04f-d77e2936ab06,DISK], DatanodeInfoWithStorage[127.0.0.1:41313,DS-20861a7b-1bcf-4943-a06e-79c12ec26f7f,DISK], DatanodeInfoWithStorage[127.0.0.1:40268,DS-613f7f51-bdc5-4e2b-9e3b-e0201e1fab89,DISK], DatanodeInfoWithStorage[127.0.0.1:35444,DS-7e8e92ec-30e3-45cb-9ba5-21a33b03f322,DISK], DatanodeInfoWithStorage[127.0.0.1:42307,DS-de0002ba-2fd9-477c-a542-26714b903e4e,DISK], DatanodeInfoWithStorage[127.0.0.1:33172,DS-ac5a2801-8ee6-4598-a383-7ceaba049c2a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-414190390-172.17.0.4-1598144255544:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35708,DS-b4d84901-5532-4579-95c2-a5226a3606a5,DISK], DatanodeInfoWithStorage[127.0.0.1:45571,DS-9c486f9d-3216-439a-b58b-334d2877169d,DISK], DatanodeInfoWithStorage[127.0.0.1:44324,DS-249b198c-4bbb-4493-9637-88ded49cdfb3,DISK], DatanodeInfoWithStorage[127.0.0.1:37474,DS-eadb6021-eb07-47cf-99d6-fd4163249e2c,DISK], DatanodeInfoWithStorage[127.0.0.1:45702,DS-e71df726-6e43-4902-8292-2ce25e9a92ef,DISK], DatanodeInfoWithStorage[127.0.0.1:46787,DS-c17fb42e-e4ce-4fab-880a-8b9209b09e03,DISK], DatanodeInfoWithStorage[127.0.0.1:35543,DS-111d95c8-7ed7-4d16-9b96-b5dca9816baf,DISK], DatanodeInfoWithStorage[127.0.0.1:35104,DS-c3ca6d9c-5829-41ac-b282-18e04e4f2e0a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-414190390-172.17.0.4-1598144255544:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35708,DS-b4d84901-5532-4579-95c2-a5226a3606a5,DISK], DatanodeInfoWithStorage[127.0.0.1:45571,DS-9c486f9d-3216-439a-b58b-334d2877169d,DISK], DatanodeInfoWithStorage[127.0.0.1:44324,DS-249b198c-4bbb-4493-9637-88ded49cdfb3,DISK], DatanodeInfoWithStorage[127.0.0.1:37474,DS-eadb6021-eb07-47cf-99d6-fd4163249e2c,DISK], DatanodeInfoWithStorage[127.0.0.1:45702,DS-e71df726-6e43-4902-8292-2ce25e9a92ef,DISK], DatanodeInfoWithStorage[127.0.0.1:46787,DS-c17fb42e-e4ce-4fab-880a-8b9209b09e03,DISK], DatanodeInfoWithStorage[127.0.0.1:35543,DS-111d95c8-7ed7-4d16-9b96-b5dca9816baf,DISK], DatanodeInfoWithStorage[127.0.0.1:35104,DS-c3ca6d9c-5829-41ac-b282-18e04e4f2e0a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-745876400-172.17.0.4-1598144680216:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46771,DS-4798c9d0-aa1c-4375-bda3-1db644fbedd0,DISK], DatanodeInfoWithStorage[127.0.0.1:40464,DS-b1c98310-5325-4653-9df2-377264215ead,DISK], DatanodeInfoWithStorage[127.0.0.1:39779,DS-a6c42a4d-85cf-4fa3-82a8-b3860a55aaa4,DISK], DatanodeInfoWithStorage[127.0.0.1:46751,DS-54fbc03f-a76e-4c93-9062-841da739f325,DISK], DatanodeInfoWithStorage[127.0.0.1:45941,DS-a8553ade-e587-4466-bdd3-f70789e5526a,DISK], DatanodeInfoWithStorage[127.0.0.1:36058,DS-500300be-0ad9-4b7d-acba-e6c52f501367,DISK], DatanodeInfoWithStorage[127.0.0.1:43013,DS-27fb47ae-18e8-47dc-8271-c7c1c52cdf8b,DISK], DatanodeInfoWithStorage[127.0.0.1:35595,DS-5706358f-9ced-42ba-b7b3-88c0d7e8c620,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-745876400-172.17.0.4-1598144680216:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46771,DS-4798c9d0-aa1c-4375-bda3-1db644fbedd0,DISK], DatanodeInfoWithStorage[127.0.0.1:40464,DS-b1c98310-5325-4653-9df2-377264215ead,DISK], DatanodeInfoWithStorage[127.0.0.1:39779,DS-a6c42a4d-85cf-4fa3-82a8-b3860a55aaa4,DISK], DatanodeInfoWithStorage[127.0.0.1:46751,DS-54fbc03f-a76e-4c93-9062-841da739f325,DISK], DatanodeInfoWithStorage[127.0.0.1:45941,DS-a8553ade-e587-4466-bdd3-f70789e5526a,DISK], DatanodeInfoWithStorage[127.0.0.1:36058,DS-500300be-0ad9-4b7d-acba-e6c52f501367,DISK], DatanodeInfoWithStorage[127.0.0.1:43013,DS-27fb47ae-18e8-47dc-8271-c7c1c52cdf8b,DISK], DatanodeInfoWithStorage[127.0.0.1:35595,DS-5706358f-9ced-42ba-b7b3-88c0d7e8c620,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-26080826-172.17.0.4-1598144726205:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42699,DS-df64ea37-7ed7-4de4-8459-4d942a1df441,DISK], DatanodeInfoWithStorage[127.0.0.1:35726,DS-354caa3e-2f5e-487a-8c65-78f7c1f640f7,DISK], DatanodeInfoWithStorage[127.0.0.1:34597,DS-1e7f214a-a422-4e42-848f-e5934e978a65,DISK], DatanodeInfoWithStorage[127.0.0.1:40883,DS-884873be-b3bd-4622-8b94-57627a31a154,DISK], DatanodeInfoWithStorage[127.0.0.1:37430,DS-562e5efa-41eb-4549-a129-f72bfea828da,DISK], DatanodeInfoWithStorage[127.0.0.1:42565,DS-b0cd7184-43c9-4afb-b3e8-68f459c065ce,DISK], DatanodeInfoWithStorage[127.0.0.1:34986,DS-3fcdc817-4d54-40d4-8264-2323313d2d5f,DISK], DatanodeInfoWithStorage[127.0.0.1:33053,DS-8f95b2ad-edd1-4886-83b7-14398da37e5c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-26080826-172.17.0.4-1598144726205:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42699,DS-df64ea37-7ed7-4de4-8459-4d942a1df441,DISK], DatanodeInfoWithStorage[127.0.0.1:35726,DS-354caa3e-2f5e-487a-8c65-78f7c1f640f7,DISK], DatanodeInfoWithStorage[127.0.0.1:34597,DS-1e7f214a-a422-4e42-848f-e5934e978a65,DISK], DatanodeInfoWithStorage[127.0.0.1:40883,DS-884873be-b3bd-4622-8b94-57627a31a154,DISK], DatanodeInfoWithStorage[127.0.0.1:37430,DS-562e5efa-41eb-4549-a129-f72bfea828da,DISK], DatanodeInfoWithStorage[127.0.0.1:42565,DS-b0cd7184-43c9-4afb-b3e8-68f459c065ce,DISK], DatanodeInfoWithStorage[127.0.0.1:34986,DS-3fcdc817-4d54-40d4-8264-2323313d2d5f,DISK], DatanodeInfoWithStorage[127.0.0.1:33053,DS-8f95b2ad-edd1-4886-83b7-14398da37e5c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-887685688-172.17.0.4-1598144855136:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38337,DS-416fd667-cdd6-43b0-9746-8517b4e71cce,DISK], DatanodeInfoWithStorage[127.0.0.1:40952,DS-d9c90c28-bc0a-4d4d-82b2-f34b0a80e081,DISK], DatanodeInfoWithStorage[127.0.0.1:34426,DS-0d2a5063-6cc1-401e-8290-85b46be74a66,DISK], DatanodeInfoWithStorage[127.0.0.1:37402,DS-07e1421d-bef6-40a6-8568-237f71235218,DISK], DatanodeInfoWithStorage[127.0.0.1:36193,DS-e7db7039-658c-42f6-85d9-9cef4f6b4419,DISK], DatanodeInfoWithStorage[127.0.0.1:35922,DS-55c005c0-e60c-4962-b0f9-2698e508ffb1,DISK], DatanodeInfoWithStorage[127.0.0.1:40504,DS-75718057-d4b9-4a92-9409-a6f1e696a791,DISK], DatanodeInfoWithStorage[127.0.0.1:41009,DS-b1794224-a398-430f-8ef6-e7613a711b1c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-887685688-172.17.0.4-1598144855136:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38337,DS-416fd667-cdd6-43b0-9746-8517b4e71cce,DISK], DatanodeInfoWithStorage[127.0.0.1:40952,DS-d9c90c28-bc0a-4d4d-82b2-f34b0a80e081,DISK], DatanodeInfoWithStorage[127.0.0.1:34426,DS-0d2a5063-6cc1-401e-8290-85b46be74a66,DISK], DatanodeInfoWithStorage[127.0.0.1:37402,DS-07e1421d-bef6-40a6-8568-237f71235218,DISK], DatanodeInfoWithStorage[127.0.0.1:36193,DS-e7db7039-658c-42f6-85d9-9cef4f6b4419,DISK], DatanodeInfoWithStorage[127.0.0.1:35922,DS-55c005c0-e60c-4962-b0f9-2698e508ffb1,DISK], DatanodeInfoWithStorage[127.0.0.1:40504,DS-75718057-d4b9-4a92-9409-a6f1e696a791,DISK], DatanodeInfoWithStorage[127.0.0.1:41009,DS-b1794224-a398-430f-8ef6-e7613a711b1c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-652384374-172.17.0.4-1598145238367:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42348,DS-d42d2327-646f-4b8a-8bf6-3f930de483c3,DISK], DatanodeInfoWithStorage[127.0.0.1:39034,DS-c18ca2df-2d23-4fae-89af-02d0915397f0,DISK], DatanodeInfoWithStorage[127.0.0.1:41481,DS-b5b57f6f-c6a7-487b-b0f8-96315f9c9967,DISK], DatanodeInfoWithStorage[127.0.0.1:38809,DS-91144a39-ea07-4f14-b4e6-4f1b4a876801,DISK], DatanodeInfoWithStorage[127.0.0.1:39060,DS-f7bcdfc5-0ac5-4022-875c-d94ec8f22690,DISK], DatanodeInfoWithStorage[127.0.0.1:39388,DS-e933c97e-09d2-40e7-a6fc-b60cd558fea1,DISK], DatanodeInfoWithStorage[127.0.0.1:43973,DS-35f047ef-e1df-4c5c-be02-298aa1b49e64,DISK], DatanodeInfoWithStorage[127.0.0.1:39308,DS-ea7b93d9-0140-4647-a338-e49d19741ed7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-652384374-172.17.0.4-1598145238367:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42348,DS-d42d2327-646f-4b8a-8bf6-3f930de483c3,DISK], DatanodeInfoWithStorage[127.0.0.1:39034,DS-c18ca2df-2d23-4fae-89af-02d0915397f0,DISK], DatanodeInfoWithStorage[127.0.0.1:41481,DS-b5b57f6f-c6a7-487b-b0f8-96315f9c9967,DISK], DatanodeInfoWithStorage[127.0.0.1:38809,DS-91144a39-ea07-4f14-b4e6-4f1b4a876801,DISK], DatanodeInfoWithStorage[127.0.0.1:39060,DS-f7bcdfc5-0ac5-4022-875c-d94ec8f22690,DISK], DatanodeInfoWithStorage[127.0.0.1:39388,DS-e933c97e-09d2-40e7-a6fc-b60cd558fea1,DISK], DatanodeInfoWithStorage[127.0.0.1:43973,DS-35f047ef-e1df-4c5c-be02-298aa1b49e64,DISK], DatanodeInfoWithStorage[127.0.0.1:39308,DS-ea7b93d9-0140-4647-a338-e49d19741ed7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-203906472-172.17.0.4-1598145443957:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41816,DS-02eb9b0b-b2b2-48e9-9153-d85252445999,DISK], DatanodeInfoWithStorage[127.0.0.1:34808,DS-75726796-379b-44d0-a398-1a932f0d0a69,DISK], DatanodeInfoWithStorage[127.0.0.1:38480,DS-6a283355-14e2-4bf7-a3d4-bbb71c71ec22,DISK], DatanodeInfoWithStorage[127.0.0.1:36813,DS-824d744f-824a-47b1-a8aa-c1f88db51cec,DISK], DatanodeInfoWithStorage[127.0.0.1:44207,DS-1a887018-3e02-4688-8c56-3cc52ca4ef92,DISK], DatanodeInfoWithStorage[127.0.0.1:41953,DS-13bf19e7-bcd8-42bf-a07b-62bebea04893,DISK], DatanodeInfoWithStorage[127.0.0.1:45516,DS-506eb954-e3f7-4cb0-b77a-025bad7aaee6,DISK], DatanodeInfoWithStorage[127.0.0.1:41991,DS-87842b2b-d1e8-4b6a-9f32-570c7cfb7ed2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-203906472-172.17.0.4-1598145443957:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41816,DS-02eb9b0b-b2b2-48e9-9153-d85252445999,DISK], DatanodeInfoWithStorage[127.0.0.1:34808,DS-75726796-379b-44d0-a398-1a932f0d0a69,DISK], DatanodeInfoWithStorage[127.0.0.1:38480,DS-6a283355-14e2-4bf7-a3d4-bbb71c71ec22,DISK], DatanodeInfoWithStorage[127.0.0.1:36813,DS-824d744f-824a-47b1-a8aa-c1f88db51cec,DISK], DatanodeInfoWithStorage[127.0.0.1:44207,DS-1a887018-3e02-4688-8c56-3cc52ca4ef92,DISK], DatanodeInfoWithStorage[127.0.0.1:41953,DS-13bf19e7-bcd8-42bf-a07b-62bebea04893,DISK], DatanodeInfoWithStorage[127.0.0.1:45516,DS-506eb954-e3f7-4cb0-b77a-025bad7aaee6,DISK], DatanodeInfoWithStorage[127.0.0.1:41991,DS-87842b2b-d1e8-4b6a-9f32-570c7cfb7ed2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-508996869-172.17.0.4-1598145785976:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42382,DS-f3aa06de-9c14-4c2f-8a6b-3ca0e2c43644,DISK], DatanodeInfoWithStorage[127.0.0.1:36155,DS-a27214c5-9501-4550-9905-fb538958dec0,DISK], DatanodeInfoWithStorage[127.0.0.1:44952,DS-c76699f2-4aca-4346-9b36-c8be89b8f3bb,DISK], DatanodeInfoWithStorage[127.0.0.1:42992,DS-06409042-c4c0-47f7-b364-3e098e3701fb,DISK], DatanodeInfoWithStorage[127.0.0.1:43402,DS-8bc5fd41-c5fe-42a7-af8f-d2b2b7e5497a,DISK], DatanodeInfoWithStorage[127.0.0.1:37246,DS-77c5b813-4f4f-4a03-bfbe-720451715106,DISK], DatanodeInfoWithStorage[127.0.0.1:38499,DS-7aeb8b69-149f-43ea-8b30-2b2b5c763cb2,DISK], DatanodeInfoWithStorage[127.0.0.1:42710,DS-1deab30c-97b4-4281-9504-67d1d388fdf9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-508996869-172.17.0.4-1598145785976:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42382,DS-f3aa06de-9c14-4c2f-8a6b-3ca0e2c43644,DISK], DatanodeInfoWithStorage[127.0.0.1:36155,DS-a27214c5-9501-4550-9905-fb538958dec0,DISK], DatanodeInfoWithStorage[127.0.0.1:44952,DS-c76699f2-4aca-4346-9b36-c8be89b8f3bb,DISK], DatanodeInfoWithStorage[127.0.0.1:42992,DS-06409042-c4c0-47f7-b364-3e098e3701fb,DISK], DatanodeInfoWithStorage[127.0.0.1:43402,DS-8bc5fd41-c5fe-42a7-af8f-d2b2b7e5497a,DISK], DatanodeInfoWithStorage[127.0.0.1:37246,DS-77c5b813-4f4f-4a03-bfbe-720451715106,DISK], DatanodeInfoWithStorage[127.0.0.1:38499,DS-7aeb8b69-149f-43ea-8b30-2b2b5c763cb2,DISK], DatanodeInfoWithStorage[127.0.0.1:42710,DS-1deab30c-97b4-4281-9504-67d1d388fdf9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-321485545-172.17.0.4-1598145953122:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34268,DS-e6260ac2-b24b-4912-8789-24c9b004b521,DISK], DatanodeInfoWithStorage[127.0.0.1:38131,DS-370fb5d0-3812-4521-8cc8-a313f51d9977,DISK], DatanodeInfoWithStorage[127.0.0.1:39395,DS-e117f9ce-40b7-4fa9-80d3-72057c8c3b09,DISK], DatanodeInfoWithStorage[127.0.0.1:37332,DS-ecaf8298-32ed-40bb-8cd9-716360b781b9,DISK], DatanodeInfoWithStorage[127.0.0.1:41249,DS-d26266da-1d44-4990-a4a9-5c1ef193e737,DISK], DatanodeInfoWithStorage[127.0.0.1:35792,DS-325c9912-869c-4302-a824-9231db24124e,DISK], DatanodeInfoWithStorage[127.0.0.1:35707,DS-59c74585-dda6-4906-b781-a885a545308b,DISK], DatanodeInfoWithStorage[127.0.0.1:36324,DS-8f74aa39-146b-41f5-9454-9d08b681eb99,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-321485545-172.17.0.4-1598145953122:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34268,DS-e6260ac2-b24b-4912-8789-24c9b004b521,DISK], DatanodeInfoWithStorage[127.0.0.1:38131,DS-370fb5d0-3812-4521-8cc8-a313f51d9977,DISK], DatanodeInfoWithStorage[127.0.0.1:39395,DS-e117f9ce-40b7-4fa9-80d3-72057c8c3b09,DISK], DatanodeInfoWithStorage[127.0.0.1:37332,DS-ecaf8298-32ed-40bb-8cd9-716360b781b9,DISK], DatanodeInfoWithStorage[127.0.0.1:41249,DS-d26266da-1d44-4990-a4a9-5c1ef193e737,DISK], DatanodeInfoWithStorage[127.0.0.1:35792,DS-325c9912-869c-4302-a824-9231db24124e,DISK], DatanodeInfoWithStorage[127.0.0.1:35707,DS-59c74585-dda6-4906-b781-a885a545308b,DISK], DatanodeInfoWithStorage[127.0.0.1:36324,DS-8f74aa39-146b-41f5-9454-9d08b681eb99,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-586952994-172.17.0.4-1598146123155:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37230,DS-724dff29-8ee6-4fdc-a481-71e8acd66067,DISK], DatanodeInfoWithStorage[127.0.0.1:45917,DS-6ca12a1a-a263-43cc-af63-0e4e22e8f132,DISK], DatanodeInfoWithStorage[127.0.0.1:43273,DS-de41e152-f253-40f1-ab5b-99c11614bc29,DISK], DatanodeInfoWithStorage[127.0.0.1:42995,DS-5a321689-6196-409b-8039-10e4976ded5e,DISK], DatanodeInfoWithStorage[127.0.0.1:44961,DS-c985710c-d10c-4de6-8351-5f93da76670a,DISK], DatanodeInfoWithStorage[127.0.0.1:36781,DS-a2506ebf-8919-420a-b473-db636b942b12,DISK], DatanodeInfoWithStorage[127.0.0.1:39727,DS-1888c14a-44d9-42b2-9295-f1a69d6aba49,DISK], DatanodeInfoWithStorage[127.0.0.1:43782,DS-6286fa98-e48d-4dab-bd18-fd4c4b2bb42a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-586952994-172.17.0.4-1598146123155:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37230,DS-724dff29-8ee6-4fdc-a481-71e8acd66067,DISK], DatanodeInfoWithStorage[127.0.0.1:45917,DS-6ca12a1a-a263-43cc-af63-0e4e22e8f132,DISK], DatanodeInfoWithStorage[127.0.0.1:43273,DS-de41e152-f253-40f1-ab5b-99c11614bc29,DISK], DatanodeInfoWithStorage[127.0.0.1:42995,DS-5a321689-6196-409b-8039-10e4976ded5e,DISK], DatanodeInfoWithStorage[127.0.0.1:44961,DS-c985710c-d10c-4de6-8351-5f93da76670a,DISK], DatanodeInfoWithStorage[127.0.0.1:36781,DS-a2506ebf-8919-420a-b473-db636b942b12,DISK], DatanodeInfoWithStorage[127.0.0.1:39727,DS-1888c14a-44d9-42b2-9295-f1a69d6aba49,DISK], DatanodeInfoWithStorage[127.0.0.1:43782,DS-6286fa98-e48d-4dab-bd18-fd4c4b2bb42a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-260354601-172.17.0.4-1598146216150:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45973,DS-79f38de1-4836-41ea-a3e0-b891a33288c3,DISK], DatanodeInfoWithStorage[127.0.0.1:35192,DS-1f8c186c-8b36-48ff-9db2-3cfb49ec91e9,DISK], DatanodeInfoWithStorage[127.0.0.1:42646,DS-6b92d7c4-05e3-4b39-a2a7-1a31b73d9624,DISK], DatanodeInfoWithStorage[127.0.0.1:45742,DS-727f1aec-778b-4d96-8aee-fe216c3373f2,DISK], DatanodeInfoWithStorage[127.0.0.1:43266,DS-aa18c1fb-f06e-4680-b65a-cdde11aa27b3,DISK], DatanodeInfoWithStorage[127.0.0.1:43035,DS-9f072c93-febc-4aa1-8886-3b497ce5abba,DISK], DatanodeInfoWithStorage[127.0.0.1:43437,DS-6bd3442d-84d4-4334-8271-a1465b245aa0,DISK], DatanodeInfoWithStorage[127.0.0.1:33741,DS-202d85f9-e459-4954-b228-918b5b74801b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-260354601-172.17.0.4-1598146216150:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45973,DS-79f38de1-4836-41ea-a3e0-b891a33288c3,DISK], DatanodeInfoWithStorage[127.0.0.1:35192,DS-1f8c186c-8b36-48ff-9db2-3cfb49ec91e9,DISK], DatanodeInfoWithStorage[127.0.0.1:42646,DS-6b92d7c4-05e3-4b39-a2a7-1a31b73d9624,DISK], DatanodeInfoWithStorage[127.0.0.1:45742,DS-727f1aec-778b-4d96-8aee-fe216c3373f2,DISK], DatanodeInfoWithStorage[127.0.0.1:43266,DS-aa18c1fb-f06e-4680-b65a-cdde11aa27b3,DISK], DatanodeInfoWithStorage[127.0.0.1:43035,DS-9f072c93-febc-4aa1-8886-3b497ce5abba,DISK], DatanodeInfoWithStorage[127.0.0.1:43437,DS-6bd3442d-84d4-4334-8271-a1465b245aa0,DISK], DatanodeInfoWithStorage[127.0.0.1:33741,DS-202d85f9-e459-4954-b228-918b5b74801b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-772245592-172.17.0.4-1598147042804:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35407,DS-83a00bc0-bc28-4f75-81bc-3fe3e63c98d4,DISK], DatanodeInfoWithStorage[127.0.0.1:41251,DS-c7d961ca-75ab-49b2-b959-503fcfc1aaa1,DISK], DatanodeInfoWithStorage[127.0.0.1:42747,DS-8720e8b7-940d-47bb-b95b-da47e24dc889,DISK], DatanodeInfoWithStorage[127.0.0.1:35381,DS-f2730841-9904-4543-9f53-8124dd17eedd,DISK], DatanodeInfoWithStorage[127.0.0.1:43485,DS-18b18617-0e2b-4ec6-87aa-2fcf538c42c9,DISK], DatanodeInfoWithStorage[127.0.0.1:37373,DS-88a7845a-2809-4951-8dda-56aa6a4e3500,DISK], DatanodeInfoWithStorage[127.0.0.1:34582,DS-5a2d8ca6-6f3a-44ff-99d2-e3492e6e8804,DISK], DatanodeInfoWithStorage[127.0.0.1:43000,DS-bd32911d-051b-4995-887b-850f1250d6c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-772245592-172.17.0.4-1598147042804:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35407,DS-83a00bc0-bc28-4f75-81bc-3fe3e63c98d4,DISK], DatanodeInfoWithStorage[127.0.0.1:41251,DS-c7d961ca-75ab-49b2-b959-503fcfc1aaa1,DISK], DatanodeInfoWithStorage[127.0.0.1:42747,DS-8720e8b7-940d-47bb-b95b-da47e24dc889,DISK], DatanodeInfoWithStorage[127.0.0.1:35381,DS-f2730841-9904-4543-9f53-8124dd17eedd,DISK], DatanodeInfoWithStorage[127.0.0.1:43485,DS-18b18617-0e2b-4ec6-87aa-2fcf538c42c9,DISK], DatanodeInfoWithStorage[127.0.0.1:37373,DS-88a7845a-2809-4951-8dda-56aa6a4e3500,DISK], DatanodeInfoWithStorage[127.0.0.1:34582,DS-5a2d8ca6-6f3a-44ff-99d2-e3492e6e8804,DISK], DatanodeInfoWithStorage[127.0.0.1:43000,DS-bd32911d-051b-4995-887b-850f1250d6c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-475699064-172.17.0.4-1598147225560:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41896,DS-16200060-3f2c-4727-a0b5-dd093be9a7b9,DISK], DatanodeInfoWithStorage[127.0.0.1:33862,DS-7d1d474e-c7a0-44ff-afe1-198f86af3db7,DISK], DatanodeInfoWithStorage[127.0.0.1:45721,DS-27fd4327-ffc9-41b4-886a-a9eb8db2a80b,DISK], DatanodeInfoWithStorage[127.0.0.1:44466,DS-23acd354-4f95-4f4a-b84f-a788ce54b6c7,DISK], DatanodeInfoWithStorage[127.0.0.1:33065,DS-a21ac193-8757-47ad-bb9e-950d2fe6a209,DISK], DatanodeInfoWithStorage[127.0.0.1:41809,DS-e5142d0b-d705-416e-b588-874af8fea684,DISK], DatanodeInfoWithStorage[127.0.0.1:45277,DS-b769971d-b3f9-4df7-9baa-100aed0d301a,DISK], DatanodeInfoWithStorage[127.0.0.1:35506,DS-01db6d3b-dfbc-41ca-a9cc-0b265fc6b1a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-475699064-172.17.0.4-1598147225560:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41896,DS-16200060-3f2c-4727-a0b5-dd093be9a7b9,DISK], DatanodeInfoWithStorage[127.0.0.1:33862,DS-7d1d474e-c7a0-44ff-afe1-198f86af3db7,DISK], DatanodeInfoWithStorage[127.0.0.1:45721,DS-27fd4327-ffc9-41b4-886a-a9eb8db2a80b,DISK], DatanodeInfoWithStorage[127.0.0.1:44466,DS-23acd354-4f95-4f4a-b84f-a788ce54b6c7,DISK], DatanodeInfoWithStorage[127.0.0.1:33065,DS-a21ac193-8757-47ad-bb9e-950d2fe6a209,DISK], DatanodeInfoWithStorage[127.0.0.1:41809,DS-e5142d0b-d705-416e-b588-874af8fea684,DISK], DatanodeInfoWithStorage[127.0.0.1:45277,DS-b769971d-b3f9-4df7-9baa-100aed0d301a,DISK], DatanodeInfoWithStorage[127.0.0.1:35506,DS-01db6d3b-dfbc-41ca-a9cc-0b265fc6b1a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1915976928-172.17.0.4-1598147585079:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37296,DS-5285c3b1-c262-4831-bb22-94149aef25d8,DISK], DatanodeInfoWithStorage[127.0.0.1:36123,DS-7cf7dcd3-2727-467f-afe1-db55f32ce4a1,DISK], DatanodeInfoWithStorage[127.0.0.1:35864,DS-d3936b0e-ace6-4401-8693-05447528f626,DISK], DatanodeInfoWithStorage[127.0.0.1:45000,DS-433185d4-7285-467f-84f4-48885b4dbad3,DISK], DatanodeInfoWithStorage[127.0.0.1:44513,DS-a066f488-4105-4353-9577-f7bbbb7151d6,DISK], DatanodeInfoWithStorage[127.0.0.1:45380,DS-4e197a88-05d8-4ad6-bde2-f17c425db683,DISK], DatanodeInfoWithStorage[127.0.0.1:34088,DS-311adc5c-ea1c-4d24-b6e9-eda727507a6b,DISK], DatanodeInfoWithStorage[127.0.0.1:39241,DS-b100251f-e86a-4da1-97c4-94d3d8dc18d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1915976928-172.17.0.4-1598147585079:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37296,DS-5285c3b1-c262-4831-bb22-94149aef25d8,DISK], DatanodeInfoWithStorage[127.0.0.1:36123,DS-7cf7dcd3-2727-467f-afe1-db55f32ce4a1,DISK], DatanodeInfoWithStorage[127.0.0.1:35864,DS-d3936b0e-ace6-4401-8693-05447528f626,DISK], DatanodeInfoWithStorage[127.0.0.1:45000,DS-433185d4-7285-467f-84f4-48885b4dbad3,DISK], DatanodeInfoWithStorage[127.0.0.1:44513,DS-a066f488-4105-4353-9577-f7bbbb7151d6,DISK], DatanodeInfoWithStorage[127.0.0.1:45380,DS-4e197a88-05d8-4ad6-bde2-f17c425db683,DISK], DatanodeInfoWithStorage[127.0.0.1:34088,DS-311adc5c-ea1c-4d24-b6e9-eda727507a6b,DISK], DatanodeInfoWithStorage[127.0.0.1:39241,DS-b100251f-e86a-4da1-97c4-94d3d8dc18d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1574230309-172.17.0.4-1598148086148:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38449,DS-ae08efec-4166-42ec-b8eb-b27f26cc240f,DISK], DatanodeInfoWithStorage[127.0.0.1:36412,DS-4ac2f41c-3f2c-4bbd-b82f-18de658c86a8,DISK], DatanodeInfoWithStorage[127.0.0.1:40237,DS-b1bc8d73-7552-4898-b620-a052d608a110,DISK], DatanodeInfoWithStorage[127.0.0.1:35817,DS-61620dc0-305e-4964-a63d-44b638753d01,DISK], DatanodeInfoWithStorage[127.0.0.1:41444,DS-f7c1032b-c273-42ae-be08-6c7bb3292cac,DISK], DatanodeInfoWithStorage[127.0.0.1:37008,DS-89738987-993b-43ab-a3ed-31d562020584,DISK], DatanodeInfoWithStorage[127.0.0.1:39092,DS-ed3fc768-51d0-4700-ad6f-b2738cea124b,DISK], DatanodeInfoWithStorage[127.0.0.1:44073,DS-d4b7522b-46ab-4bf7-a169-3d5946d428a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1574230309-172.17.0.4-1598148086148:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38449,DS-ae08efec-4166-42ec-b8eb-b27f26cc240f,DISK], DatanodeInfoWithStorage[127.0.0.1:36412,DS-4ac2f41c-3f2c-4bbd-b82f-18de658c86a8,DISK], DatanodeInfoWithStorage[127.0.0.1:40237,DS-b1bc8d73-7552-4898-b620-a052d608a110,DISK], DatanodeInfoWithStorage[127.0.0.1:35817,DS-61620dc0-305e-4964-a63d-44b638753d01,DISK], DatanodeInfoWithStorage[127.0.0.1:41444,DS-f7c1032b-c273-42ae-be08-6c7bb3292cac,DISK], DatanodeInfoWithStorage[127.0.0.1:37008,DS-89738987-993b-43ab-a3ed-31d562020584,DISK], DatanodeInfoWithStorage[127.0.0.1:39092,DS-ed3fc768-51d0-4700-ad6f-b2738cea124b,DISK], DatanodeInfoWithStorage[127.0.0.1:44073,DS-d4b7522b-46ab-4bf7-a169-3d5946d428a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-573329539-172.17.0.4-1598148260754:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41762,DS-d442761c-7b61-4165-aa35-aa6b43da1fb0,DISK], DatanodeInfoWithStorage[127.0.0.1:45477,DS-b6cf1229-3527-4176-938f-23a046e97ca9,DISK], DatanodeInfoWithStorage[127.0.0.1:43465,DS-dce7a89e-cb39-4a89-a80e-9330d981abbc,DISK], DatanodeInfoWithStorage[127.0.0.1:35302,DS-23f99543-e4db-4feb-a98f-29c4308c889b,DISK], DatanodeInfoWithStorage[127.0.0.1:46811,DS-4e34424e-5f04-4fdd-b5de-2248a724fa6d,DISK], DatanodeInfoWithStorage[127.0.0.1:36318,DS-1c55fc55-f55d-4c56-a688-406648d6fc57,DISK], DatanodeInfoWithStorage[127.0.0.1:44125,DS-0ae780ef-a786-4e61-b836-163a3875e10d,DISK], DatanodeInfoWithStorage[127.0.0.1:43888,DS-e1c28361-0742-44cb-8157-666ec393dd78,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-573329539-172.17.0.4-1598148260754:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41762,DS-d442761c-7b61-4165-aa35-aa6b43da1fb0,DISK], DatanodeInfoWithStorage[127.0.0.1:45477,DS-b6cf1229-3527-4176-938f-23a046e97ca9,DISK], DatanodeInfoWithStorage[127.0.0.1:43465,DS-dce7a89e-cb39-4a89-a80e-9330d981abbc,DISK], DatanodeInfoWithStorage[127.0.0.1:35302,DS-23f99543-e4db-4feb-a98f-29c4308c889b,DISK], DatanodeInfoWithStorage[127.0.0.1:46811,DS-4e34424e-5f04-4fdd-b5de-2248a724fa6d,DISK], DatanodeInfoWithStorage[127.0.0.1:36318,DS-1c55fc55-f55d-4c56-a688-406648d6fc57,DISK], DatanodeInfoWithStorage[127.0.0.1:44125,DS-0ae780ef-a786-4e61-b836-163a3875e10d,DISK], DatanodeInfoWithStorage[127.0.0.1:43888,DS-e1c28361-0742-44cb-8157-666ec393dd78,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 11 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 6453
