reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-425461255-172.17.0.11-1598146684347:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34433,DS-60d82d9d-9e87-4375-b1b8-1ac10bfef624,DISK], DatanodeInfoWithStorage[127.0.0.1:41539,DS-bf6ffe55-c711-4996-8e92-903d0a8edb2c,DISK], DatanodeInfoWithStorage[127.0.0.1:45197,DS-e3c58978-5779-48fc-b027-535216245850,DISK], DatanodeInfoWithStorage[127.0.0.1:43180,DS-b1056d0b-c388-42c3-a60c-e45f73de5ec7,DISK], DatanodeInfoWithStorage[127.0.0.1:41981,DS-173b44f9-4f8d-4224-8ac0-0c78109e2670,DISK], DatanodeInfoWithStorage[127.0.0.1:39988,DS-120c3a9e-2821-48a6-88bd-234286c9ca64,DISK], DatanodeInfoWithStorage[127.0.0.1:34993,DS-674cb66b-4286-4fcd-b850-b31ff0cbc018,DISK], DatanodeInfoWithStorage[127.0.0.1:40699,DS-db0283aa-15c6-4219-b53c-3eca4f00a6b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-425461255-172.17.0.11-1598146684347:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34433,DS-60d82d9d-9e87-4375-b1b8-1ac10bfef624,DISK], DatanodeInfoWithStorage[127.0.0.1:41539,DS-bf6ffe55-c711-4996-8e92-903d0a8edb2c,DISK], DatanodeInfoWithStorage[127.0.0.1:45197,DS-e3c58978-5779-48fc-b027-535216245850,DISK], DatanodeInfoWithStorage[127.0.0.1:43180,DS-b1056d0b-c388-42c3-a60c-e45f73de5ec7,DISK], DatanodeInfoWithStorage[127.0.0.1:41981,DS-173b44f9-4f8d-4224-8ac0-0c78109e2670,DISK], DatanodeInfoWithStorage[127.0.0.1:39988,DS-120c3a9e-2821-48a6-88bd-234286c9ca64,DISK], DatanodeInfoWithStorage[127.0.0.1:34993,DS-674cb66b-4286-4fcd-b850-b31ff0cbc018,DISK], DatanodeInfoWithStorage[127.0.0.1:40699,DS-db0283aa-15c6-4219-b53c-3eca4f00a6b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-239787098-172.17.0.11-1598146716401:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33997,DS-c1dd44d9-616d-4d5f-a62b-b1ef9665b4c6,DISK], DatanodeInfoWithStorage[127.0.0.1:43608,DS-35fdd060-b591-4f3c-82a8-1191053c5466,DISK], DatanodeInfoWithStorage[127.0.0.1:40560,DS-c0cd9ae2-179c-41a5-a40e-20c2a0eec2c8,DISK], DatanodeInfoWithStorage[127.0.0.1:45110,DS-0f9714d3-bde4-427f-b45e-2898dfba428e,DISK], DatanodeInfoWithStorage[127.0.0.1:44566,DS-89f7dd49-00b7-42ab-a9f4-0eb5389765ff,DISK], DatanodeInfoWithStorage[127.0.0.1:35937,DS-c75d92e4-59d7-4fed-b9e1-63a54311f1c1,DISK], DatanodeInfoWithStorage[127.0.0.1:46681,DS-a2a67d9e-a43b-4687-9083-180856006734,DISK], DatanodeInfoWithStorage[127.0.0.1:38366,DS-8e915744-df94-4e78-9942-be6bf2a6a8ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-239787098-172.17.0.11-1598146716401:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33997,DS-c1dd44d9-616d-4d5f-a62b-b1ef9665b4c6,DISK], DatanodeInfoWithStorage[127.0.0.1:43608,DS-35fdd060-b591-4f3c-82a8-1191053c5466,DISK], DatanodeInfoWithStorage[127.0.0.1:40560,DS-c0cd9ae2-179c-41a5-a40e-20c2a0eec2c8,DISK], DatanodeInfoWithStorage[127.0.0.1:45110,DS-0f9714d3-bde4-427f-b45e-2898dfba428e,DISK], DatanodeInfoWithStorage[127.0.0.1:44566,DS-89f7dd49-00b7-42ab-a9f4-0eb5389765ff,DISK], DatanodeInfoWithStorage[127.0.0.1:35937,DS-c75d92e4-59d7-4fed-b9e1-63a54311f1c1,DISK], DatanodeInfoWithStorage[127.0.0.1:46681,DS-a2a67d9e-a43b-4687-9083-180856006734,DISK], DatanodeInfoWithStorage[127.0.0.1:38366,DS-8e915744-df94-4e78-9942-be6bf2a6a8ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-675571971-172.17.0.11-1598147138263:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45013,DS-c9993212-c276-4a4c-8c83-b045078aa6a0,DISK], DatanodeInfoWithStorage[127.0.0.1:45948,DS-57736a96-5366-4394-97b7-aab9168bbec8,DISK], DatanodeInfoWithStorage[127.0.0.1:40984,DS-2e076e86-3237-41d3-8680-b0e7b7fdb1c7,DISK], DatanodeInfoWithStorage[127.0.0.1:37942,DS-8e98a915-e1ad-4ff2-be28-c22fac9070e5,DISK], DatanodeInfoWithStorage[127.0.0.1:45377,DS-0fbf1be1-dfa5-4def-9b0a-e4a163251f40,DISK], DatanodeInfoWithStorage[127.0.0.1:45290,DS-6916ce26-b393-4f1b-8337-9422934b5299,DISK], DatanodeInfoWithStorage[127.0.0.1:45027,DS-227439e6-6264-4fbb-8cbf-2fe45249319c,DISK], DatanodeInfoWithStorage[127.0.0.1:42953,DS-19f64035-0e75-4e59-9929-fb417fe0f223,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-675571971-172.17.0.11-1598147138263:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45013,DS-c9993212-c276-4a4c-8c83-b045078aa6a0,DISK], DatanodeInfoWithStorage[127.0.0.1:45948,DS-57736a96-5366-4394-97b7-aab9168bbec8,DISK], DatanodeInfoWithStorage[127.0.0.1:40984,DS-2e076e86-3237-41d3-8680-b0e7b7fdb1c7,DISK], DatanodeInfoWithStorage[127.0.0.1:37942,DS-8e98a915-e1ad-4ff2-be28-c22fac9070e5,DISK], DatanodeInfoWithStorage[127.0.0.1:45377,DS-0fbf1be1-dfa5-4def-9b0a-e4a163251f40,DISK], DatanodeInfoWithStorage[127.0.0.1:45290,DS-6916ce26-b393-4f1b-8337-9422934b5299,DISK], DatanodeInfoWithStorage[127.0.0.1:45027,DS-227439e6-6264-4fbb-8cbf-2fe45249319c,DISK], DatanodeInfoWithStorage[127.0.0.1:42953,DS-19f64035-0e75-4e59-9929-fb417fe0f223,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-450669013-172.17.0.11-1598147332885:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43318,DS-2abb61bf-9103-4cca-893f-0bcb177f918a,DISK], DatanodeInfoWithStorage[127.0.0.1:42662,DS-00e1e929-8415-4c0d-930f-577cc929deae,DISK], DatanodeInfoWithStorage[127.0.0.1:34735,DS-ffafb6f8-8e02-4794-a690-9e1251496976,DISK], DatanodeInfoWithStorage[127.0.0.1:45826,DS-992b0120-1ef2-40e4-9913-b0e1b4e92416,DISK], DatanodeInfoWithStorage[127.0.0.1:39715,DS-6bf30763-ccbb-41f2-8fa7-461c64d7414a,DISK], DatanodeInfoWithStorage[127.0.0.1:32830,DS-b1440739-9bce-400f-bd87-f9d7d97a6de8,DISK], DatanodeInfoWithStorage[127.0.0.1:45384,DS-85e01a54-c80a-4519-abd3-1f71b8546700,DISK], DatanodeInfoWithStorage[127.0.0.1:40343,DS-c0a89877-6e41-4915-8638-136474db9633,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-450669013-172.17.0.11-1598147332885:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43318,DS-2abb61bf-9103-4cca-893f-0bcb177f918a,DISK], DatanodeInfoWithStorage[127.0.0.1:42662,DS-00e1e929-8415-4c0d-930f-577cc929deae,DISK], DatanodeInfoWithStorage[127.0.0.1:34735,DS-ffafb6f8-8e02-4794-a690-9e1251496976,DISK], DatanodeInfoWithStorage[127.0.0.1:45826,DS-992b0120-1ef2-40e4-9913-b0e1b4e92416,DISK], DatanodeInfoWithStorage[127.0.0.1:39715,DS-6bf30763-ccbb-41f2-8fa7-461c64d7414a,DISK], DatanodeInfoWithStorage[127.0.0.1:32830,DS-b1440739-9bce-400f-bd87-f9d7d97a6de8,DISK], DatanodeInfoWithStorage[127.0.0.1:45384,DS-85e01a54-c80a-4519-abd3-1f71b8546700,DISK], DatanodeInfoWithStorage[127.0.0.1:40343,DS-c0a89877-6e41-4915-8638-136474db9633,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1104689526-172.17.0.11-1598147404195:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46839,DS-ae170fea-d1be-484c-9656-be98bb8f00b0,DISK], DatanodeInfoWithStorage[127.0.0.1:38230,DS-4474087d-d128-4cc9-8299-8faccb50dd4d,DISK], DatanodeInfoWithStorage[127.0.0.1:37478,DS-ce038ef2-70a5-4a86-96e0-8f999c14dfbb,DISK], DatanodeInfoWithStorage[127.0.0.1:41557,DS-c656ab1c-1408-424b-b1b5-d668cb874953,DISK], DatanodeInfoWithStorage[127.0.0.1:37368,DS-08ef8480-beb5-40f3-a8ff-8bfacb241084,DISK], DatanodeInfoWithStorage[127.0.0.1:36448,DS-944ba3d3-10ce-4c83-b66c-a3c26d3e63da,DISK], DatanodeInfoWithStorage[127.0.0.1:36444,DS-4d68c8bc-96f8-49d7-90ed-a6617d36e0df,DISK], DatanodeInfoWithStorage[127.0.0.1:41452,DS-2ff2bd1e-f374-49b5-97f9-755978bc7dd8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1104689526-172.17.0.11-1598147404195:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46839,DS-ae170fea-d1be-484c-9656-be98bb8f00b0,DISK], DatanodeInfoWithStorage[127.0.0.1:38230,DS-4474087d-d128-4cc9-8299-8faccb50dd4d,DISK], DatanodeInfoWithStorage[127.0.0.1:37478,DS-ce038ef2-70a5-4a86-96e0-8f999c14dfbb,DISK], DatanodeInfoWithStorage[127.0.0.1:41557,DS-c656ab1c-1408-424b-b1b5-d668cb874953,DISK], DatanodeInfoWithStorage[127.0.0.1:37368,DS-08ef8480-beb5-40f3-a8ff-8bfacb241084,DISK], DatanodeInfoWithStorage[127.0.0.1:36448,DS-944ba3d3-10ce-4c83-b66c-a3c26d3e63da,DISK], DatanodeInfoWithStorage[127.0.0.1:36444,DS-4d68c8bc-96f8-49d7-90ed-a6617d36e0df,DISK], DatanodeInfoWithStorage[127.0.0.1:41452,DS-2ff2bd1e-f374-49b5-97f9-755978bc7dd8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-120636478-172.17.0.11-1598147547709:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44196,DS-8a6dbe02-0b3a-4e3b-ada2-2001f93b864b,DISK], DatanodeInfoWithStorage[127.0.0.1:34287,DS-f222a620-817b-4f78-be11-30bd8e55360e,DISK], DatanodeInfoWithStorage[127.0.0.1:37467,DS-2516197f-50a4-433e-a5d5-35a758adcd00,DISK], DatanodeInfoWithStorage[127.0.0.1:32864,DS-f9b11f62-849a-4b2d-af8a-52c066cef009,DISK], DatanodeInfoWithStorage[127.0.0.1:45660,DS-27578908-ef69-4ea2-9eea-56ddc5d0fa45,DISK], DatanodeInfoWithStorage[127.0.0.1:37698,DS-0c848bb2-dee8-4458-a2dc-b1781ad63538,DISK], DatanodeInfoWithStorage[127.0.0.1:44551,DS-c24066af-ba30-4af9-8dc7-7aef9d4c62eb,DISK], DatanodeInfoWithStorage[127.0.0.1:34452,DS-5719c970-89f1-49e0-a959-eaeced868a53,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-120636478-172.17.0.11-1598147547709:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44196,DS-8a6dbe02-0b3a-4e3b-ada2-2001f93b864b,DISK], DatanodeInfoWithStorage[127.0.0.1:34287,DS-f222a620-817b-4f78-be11-30bd8e55360e,DISK], DatanodeInfoWithStorage[127.0.0.1:37467,DS-2516197f-50a4-433e-a5d5-35a758adcd00,DISK], DatanodeInfoWithStorage[127.0.0.1:32864,DS-f9b11f62-849a-4b2d-af8a-52c066cef009,DISK], DatanodeInfoWithStorage[127.0.0.1:45660,DS-27578908-ef69-4ea2-9eea-56ddc5d0fa45,DISK], DatanodeInfoWithStorage[127.0.0.1:37698,DS-0c848bb2-dee8-4458-a2dc-b1781ad63538,DISK], DatanodeInfoWithStorage[127.0.0.1:44551,DS-c24066af-ba30-4af9-8dc7-7aef9d4c62eb,DISK], DatanodeInfoWithStorage[127.0.0.1:34452,DS-5719c970-89f1-49e0-a959-eaeced868a53,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-469456206-172.17.0.11-1598147650970:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33712,DS-4a19c4b8-7317-4c55-9f11-58c5b4f3c2f5,DISK], DatanodeInfoWithStorage[127.0.0.1:40233,DS-63d7909a-f6cf-451f-9e20-558d2f33d655,DISK], DatanodeInfoWithStorage[127.0.0.1:38661,DS-713416c8-bd54-4085-bed8-44dcd0cea282,DISK], DatanodeInfoWithStorage[127.0.0.1:35716,DS-c01fbd7a-87f3-4b45-8e5b-65bfb067054c,DISK], DatanodeInfoWithStorage[127.0.0.1:39423,DS-3bd9a510-4cf9-4e7c-9d67-5584fe87690b,DISK], DatanodeInfoWithStorage[127.0.0.1:40411,DS-1d968ea8-f542-4e78-af26-4a2e1894bc60,DISK], DatanodeInfoWithStorage[127.0.0.1:33620,DS-ff5920ca-7214-4f5d-9191-fd71650a8069,DISK], DatanodeInfoWithStorage[127.0.0.1:35450,DS-ff3a8b4e-4e39-4493-b051-cc2d4ec57bde,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-469456206-172.17.0.11-1598147650970:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33712,DS-4a19c4b8-7317-4c55-9f11-58c5b4f3c2f5,DISK], DatanodeInfoWithStorage[127.0.0.1:40233,DS-63d7909a-f6cf-451f-9e20-558d2f33d655,DISK], DatanodeInfoWithStorage[127.0.0.1:38661,DS-713416c8-bd54-4085-bed8-44dcd0cea282,DISK], DatanodeInfoWithStorage[127.0.0.1:35716,DS-c01fbd7a-87f3-4b45-8e5b-65bfb067054c,DISK], DatanodeInfoWithStorage[127.0.0.1:39423,DS-3bd9a510-4cf9-4e7c-9d67-5584fe87690b,DISK], DatanodeInfoWithStorage[127.0.0.1:40411,DS-1d968ea8-f542-4e78-af26-4a2e1894bc60,DISK], DatanodeInfoWithStorage[127.0.0.1:33620,DS-ff5920ca-7214-4f5d-9191-fd71650a8069,DISK], DatanodeInfoWithStorage[127.0.0.1:35450,DS-ff3a8b4e-4e39-4493-b051-cc2d4ec57bde,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-237260590-172.17.0.11-1598147947660:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40782,DS-1a1ee617-3766-49a9-a3b1-4eb876c97526,DISK], DatanodeInfoWithStorage[127.0.0.1:33176,DS-d6454ef6-731b-4328-a4bc-7fee2cde2ce7,DISK], DatanodeInfoWithStorage[127.0.0.1:40119,DS-06342ae0-acd9-4c1b-970b-8dc45168a658,DISK], DatanodeInfoWithStorage[127.0.0.1:39603,DS-05e92b14-721a-4abd-99a5-973ddbf23f1e,DISK], DatanodeInfoWithStorage[127.0.0.1:37942,DS-d900679c-a30b-4d2d-8241-4f5a2cd36d10,DISK], DatanodeInfoWithStorage[127.0.0.1:37193,DS-49ec49eb-0518-4ed1-87ef-00e92a2506db,DISK], DatanodeInfoWithStorage[127.0.0.1:40030,DS-af242f66-f88c-4e0c-992d-a774de08e99b,DISK], DatanodeInfoWithStorage[127.0.0.1:39263,DS-71bc09ae-8d32-49e5-ac3e-6f4f13103cce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-237260590-172.17.0.11-1598147947660:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40782,DS-1a1ee617-3766-49a9-a3b1-4eb876c97526,DISK], DatanodeInfoWithStorage[127.0.0.1:33176,DS-d6454ef6-731b-4328-a4bc-7fee2cde2ce7,DISK], DatanodeInfoWithStorage[127.0.0.1:40119,DS-06342ae0-acd9-4c1b-970b-8dc45168a658,DISK], DatanodeInfoWithStorage[127.0.0.1:39603,DS-05e92b14-721a-4abd-99a5-973ddbf23f1e,DISK], DatanodeInfoWithStorage[127.0.0.1:37942,DS-d900679c-a30b-4d2d-8241-4f5a2cd36d10,DISK], DatanodeInfoWithStorage[127.0.0.1:37193,DS-49ec49eb-0518-4ed1-87ef-00e92a2506db,DISK], DatanodeInfoWithStorage[127.0.0.1:40030,DS-af242f66-f88c-4e0c-992d-a774de08e99b,DISK], DatanodeInfoWithStorage[127.0.0.1:39263,DS-71bc09ae-8d32-49e5-ac3e-6f4f13103cce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-362973529-172.17.0.11-1598148330880:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45252,DS-12be4081-70ca-4f2c-8121-23ac6a25c7ae,DISK], DatanodeInfoWithStorage[127.0.0.1:43390,DS-9bf9e78f-2c44-4cfa-b06b-8ac5fe04ff61,DISK], DatanodeInfoWithStorage[127.0.0.1:34644,DS-337c53c7-be3c-4305-ba3a-e7b7aff23a13,DISK], DatanodeInfoWithStorage[127.0.0.1:33526,DS-f71a3c46-99e9-4e29-a04d-5ef886cbe387,DISK], DatanodeInfoWithStorage[127.0.0.1:35697,DS-b4bb6688-c10c-4b64-806e-ab8a01244374,DISK], DatanodeInfoWithStorage[127.0.0.1:35966,DS-8302e546-5894-48fb-8276-7810d92febe5,DISK], DatanodeInfoWithStorage[127.0.0.1:38126,DS-3fb3ea1d-a341-4c21-8682-6dcf5ea5f174,DISK], DatanodeInfoWithStorage[127.0.0.1:33942,DS-517d4928-1f3f-412c-87f1-5fcff17e056c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-362973529-172.17.0.11-1598148330880:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45252,DS-12be4081-70ca-4f2c-8121-23ac6a25c7ae,DISK], DatanodeInfoWithStorage[127.0.0.1:43390,DS-9bf9e78f-2c44-4cfa-b06b-8ac5fe04ff61,DISK], DatanodeInfoWithStorage[127.0.0.1:34644,DS-337c53c7-be3c-4305-ba3a-e7b7aff23a13,DISK], DatanodeInfoWithStorage[127.0.0.1:33526,DS-f71a3c46-99e9-4e29-a04d-5ef886cbe387,DISK], DatanodeInfoWithStorage[127.0.0.1:35697,DS-b4bb6688-c10c-4b64-806e-ab8a01244374,DISK], DatanodeInfoWithStorage[127.0.0.1:35966,DS-8302e546-5894-48fb-8276-7810d92febe5,DISK], DatanodeInfoWithStorage[127.0.0.1:38126,DS-3fb3ea1d-a341-4c21-8682-6dcf5ea5f174,DISK], DatanodeInfoWithStorage[127.0.0.1:33942,DS-517d4928-1f3f-412c-87f1-5fcff17e056c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1360903609-172.17.0.11-1598148372219:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33481,DS-a8294606-1d09-4fda-a836-5bc768c2a2a1,DISK], DatanodeInfoWithStorage[127.0.0.1:40170,DS-1f9827d4-24cd-423a-b5aa-d0048886bb18,DISK], DatanodeInfoWithStorage[127.0.0.1:46532,DS-e5fa6bb3-b5d2-47a7-8a65-572fdaa0c155,DISK], DatanodeInfoWithStorage[127.0.0.1:44385,DS-3b534991-5226-4233-af81-dd2f524110e1,DISK], DatanodeInfoWithStorage[127.0.0.1:38998,DS-928e46e5-f17e-4636-b149-673e0139b41e,DISK], DatanodeInfoWithStorage[127.0.0.1:38409,DS-42990c50-455d-4f65-81ab-8abd11e43893,DISK], DatanodeInfoWithStorage[127.0.0.1:45605,DS-3f9ccc2a-b359-424c-a2be-91da7b7fdd84,DISK], DatanodeInfoWithStorage[127.0.0.1:37818,DS-9a42d70c-6ba9-4458-b35f-83076be956a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1360903609-172.17.0.11-1598148372219:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33481,DS-a8294606-1d09-4fda-a836-5bc768c2a2a1,DISK], DatanodeInfoWithStorage[127.0.0.1:40170,DS-1f9827d4-24cd-423a-b5aa-d0048886bb18,DISK], DatanodeInfoWithStorage[127.0.0.1:46532,DS-e5fa6bb3-b5d2-47a7-8a65-572fdaa0c155,DISK], DatanodeInfoWithStorage[127.0.0.1:44385,DS-3b534991-5226-4233-af81-dd2f524110e1,DISK], DatanodeInfoWithStorage[127.0.0.1:38998,DS-928e46e5-f17e-4636-b149-673e0139b41e,DISK], DatanodeInfoWithStorage[127.0.0.1:38409,DS-42990c50-455d-4f65-81ab-8abd11e43893,DISK], DatanodeInfoWithStorage[127.0.0.1:45605,DS-3f9ccc2a-b359-424c-a2be-91da7b7fdd84,DISK], DatanodeInfoWithStorage[127.0.0.1:37818,DS-9a42d70c-6ba9-4458-b35f-83076be956a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-983603987-172.17.0.11-1598148907733:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33676,DS-c6fe56e0-2a4f-4794-a84a-2feb0e0ccd55,DISK], DatanodeInfoWithStorage[127.0.0.1:37468,DS-c6a1aa7d-3c04-436c-9686-bd2b410843c2,DISK], DatanodeInfoWithStorage[127.0.0.1:39778,DS-9dfae27b-8ce4-4dc0-9bf6-e9b1a8b002cf,DISK], DatanodeInfoWithStorage[127.0.0.1:45434,DS-4254ecb8-7246-47b5-9d68-2408ca28f34b,DISK], DatanodeInfoWithStorage[127.0.0.1:42356,DS-bcdcf98d-f4c1-4e8d-9158-4bcad0f7be70,DISK], DatanodeInfoWithStorage[127.0.0.1:35363,DS-ffe35a7a-cf53-4d25-b871-29278d26d291,DISK], DatanodeInfoWithStorage[127.0.0.1:46500,DS-7b5b785d-7a30-4821-b699-b1d24a555863,DISK], DatanodeInfoWithStorage[127.0.0.1:39056,DS-6d98d5da-b8be-404a-bfcd-586070424efa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-983603987-172.17.0.11-1598148907733:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33676,DS-c6fe56e0-2a4f-4794-a84a-2feb0e0ccd55,DISK], DatanodeInfoWithStorage[127.0.0.1:37468,DS-c6a1aa7d-3c04-436c-9686-bd2b410843c2,DISK], DatanodeInfoWithStorage[127.0.0.1:39778,DS-9dfae27b-8ce4-4dc0-9bf6-e9b1a8b002cf,DISK], DatanodeInfoWithStorage[127.0.0.1:45434,DS-4254ecb8-7246-47b5-9d68-2408ca28f34b,DISK], DatanodeInfoWithStorage[127.0.0.1:42356,DS-bcdcf98d-f4c1-4e8d-9158-4bcad0f7be70,DISK], DatanodeInfoWithStorage[127.0.0.1:35363,DS-ffe35a7a-cf53-4d25-b871-29278d26d291,DISK], DatanodeInfoWithStorage[127.0.0.1:46500,DS-7b5b785d-7a30-4821-b699-b1d24a555863,DISK], DatanodeInfoWithStorage[127.0.0.1:39056,DS-6d98d5da-b8be-404a-bfcd-586070424efa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-701454999-172.17.0.11-1598149135215:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42458,DS-85e248c6-6093-4785-b28d-1166f8e659fd,DISK], DatanodeInfoWithStorage[127.0.0.1:39469,DS-f971cd4c-0f96-4b1e-8d07-ee90b7717a34,DISK], DatanodeInfoWithStorage[127.0.0.1:40765,DS-6a9b45e8-05a7-47e9-b17d-2cb1b0092230,DISK], DatanodeInfoWithStorage[127.0.0.1:45078,DS-e0addefe-4fca-48eb-aea1-2c2ed8067a0f,DISK], DatanodeInfoWithStorage[127.0.0.1:41490,DS-4dd96faf-ba5f-49f5-872c-b45f4d8af9b2,DISK], DatanodeInfoWithStorage[127.0.0.1:43101,DS-d1da5e92-d3be-4810-b150-6c0bb2bacdda,DISK], DatanodeInfoWithStorage[127.0.0.1:39754,DS-4db4325c-4c2f-40c6-be80-cc43b02337ba,DISK], DatanodeInfoWithStorage[127.0.0.1:42813,DS-600e58de-1dfa-4ea3-9e28-c073b01a6a9b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-701454999-172.17.0.11-1598149135215:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42458,DS-85e248c6-6093-4785-b28d-1166f8e659fd,DISK], DatanodeInfoWithStorage[127.0.0.1:39469,DS-f971cd4c-0f96-4b1e-8d07-ee90b7717a34,DISK], DatanodeInfoWithStorage[127.0.0.1:40765,DS-6a9b45e8-05a7-47e9-b17d-2cb1b0092230,DISK], DatanodeInfoWithStorage[127.0.0.1:45078,DS-e0addefe-4fca-48eb-aea1-2c2ed8067a0f,DISK], DatanodeInfoWithStorage[127.0.0.1:41490,DS-4dd96faf-ba5f-49f5-872c-b45f4d8af9b2,DISK], DatanodeInfoWithStorage[127.0.0.1:43101,DS-d1da5e92-d3be-4810-b150-6c0bb2bacdda,DISK], DatanodeInfoWithStorage[127.0.0.1:39754,DS-4db4325c-4c2f-40c6-be80-cc43b02337ba,DISK], DatanodeInfoWithStorage[127.0.0.1:42813,DS-600e58de-1dfa-4ea3-9e28-c073b01a6a9b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-744730453-172.17.0.11-1598149205562:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46571,DS-f4a4ae1e-2e83-4a30-adcf-5f779b056514,DISK], DatanodeInfoWithStorage[127.0.0.1:38776,DS-b67e1487-f820-46b6-af0b-b294f071015e,DISK], DatanodeInfoWithStorage[127.0.0.1:33768,DS-955b6559-cc42-440d-8240-b614df6ae84b,DISK], DatanodeInfoWithStorage[127.0.0.1:44278,DS-cd48851d-8897-4ae0-8d2b-7e930a95b4cc,DISK], DatanodeInfoWithStorage[127.0.0.1:36443,DS-f3c4dd6e-c73a-4aea-afce-a09f24e03051,DISK], DatanodeInfoWithStorage[127.0.0.1:45708,DS-a0c7a7e1-246e-4d0f-a181-5d9b2602a0fe,DISK], DatanodeInfoWithStorage[127.0.0.1:36411,DS-4509a37f-9f53-4153-a97e-82a90d256a1d,DISK], DatanodeInfoWithStorage[127.0.0.1:44753,DS-540f6e3c-4c94-45c6-a778-e7b9301ac5b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-744730453-172.17.0.11-1598149205562:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46571,DS-f4a4ae1e-2e83-4a30-adcf-5f779b056514,DISK], DatanodeInfoWithStorage[127.0.0.1:38776,DS-b67e1487-f820-46b6-af0b-b294f071015e,DISK], DatanodeInfoWithStorage[127.0.0.1:33768,DS-955b6559-cc42-440d-8240-b614df6ae84b,DISK], DatanodeInfoWithStorage[127.0.0.1:44278,DS-cd48851d-8897-4ae0-8d2b-7e930a95b4cc,DISK], DatanodeInfoWithStorage[127.0.0.1:36443,DS-f3c4dd6e-c73a-4aea-afce-a09f24e03051,DISK], DatanodeInfoWithStorage[127.0.0.1:45708,DS-a0c7a7e1-246e-4d0f-a181-5d9b2602a0fe,DISK], DatanodeInfoWithStorage[127.0.0.1:36411,DS-4509a37f-9f53-4153-a97e-82a90d256a1d,DISK], DatanodeInfoWithStorage[127.0.0.1:44753,DS-540f6e3c-4c94-45c6-a778-e7b9301ac5b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1702575393-172.17.0.11-1598149312625:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38742,DS-9f48433b-8086-4d05-8d23-7e7de12ace7e,DISK], DatanodeInfoWithStorage[127.0.0.1:38926,DS-d5f4144e-4a9d-4b11-a4bb-37ffb8bbed14,DISK], DatanodeInfoWithStorage[127.0.0.1:33042,DS-848640a5-cf8b-4b6c-8976-680a8576d010,DISK], DatanodeInfoWithStorage[127.0.0.1:37345,DS-ba5204e0-bf99-41e3-851e-24c3fd15974f,DISK], DatanodeInfoWithStorage[127.0.0.1:38146,DS-55ca519d-9bbf-4e54-806c-b9a1608c58ba,DISK], DatanodeInfoWithStorage[127.0.0.1:44981,DS-cdee2c9d-16d0-4f60-83ed-d94c52038b39,DISK], DatanodeInfoWithStorage[127.0.0.1:44182,DS-1e495669-a9e0-4b6f-bf98-2b65f8760151,DISK], DatanodeInfoWithStorage[127.0.0.1:35825,DS-0a8cae90-adf7-43d2-9440-6c1fae33b856,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1702575393-172.17.0.11-1598149312625:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38742,DS-9f48433b-8086-4d05-8d23-7e7de12ace7e,DISK], DatanodeInfoWithStorage[127.0.0.1:38926,DS-d5f4144e-4a9d-4b11-a4bb-37ffb8bbed14,DISK], DatanodeInfoWithStorage[127.0.0.1:33042,DS-848640a5-cf8b-4b6c-8976-680a8576d010,DISK], DatanodeInfoWithStorage[127.0.0.1:37345,DS-ba5204e0-bf99-41e3-851e-24c3fd15974f,DISK], DatanodeInfoWithStorage[127.0.0.1:38146,DS-55ca519d-9bbf-4e54-806c-b9a1608c58ba,DISK], DatanodeInfoWithStorage[127.0.0.1:44981,DS-cdee2c9d-16d0-4f60-83ed-d94c52038b39,DISK], DatanodeInfoWithStorage[127.0.0.1:44182,DS-1e495669-a9e0-4b6f-bf98-2b65f8760151,DISK], DatanodeInfoWithStorage[127.0.0.1:35825,DS-0a8cae90-adf7-43d2-9440-6c1fae33b856,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1804871332-172.17.0.11-1598149766312:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36539,DS-03e347f7-d69f-4bc4-aaae-ce936eed2f63,DISK], DatanodeInfoWithStorage[127.0.0.1:38762,DS-1bf91fd8-0bcf-48a8-b4d8-f13556cf57c5,DISK], DatanodeInfoWithStorage[127.0.0.1:46680,DS-712e707f-012c-4cc8-aa04-af4fb72a84cc,DISK], DatanodeInfoWithStorage[127.0.0.1:46503,DS-959aa7f5-99cb-402f-9500-373493d9fcb3,DISK], DatanodeInfoWithStorage[127.0.0.1:40218,DS-e68d9b29-d3f4-47ad-b145-425524b8a80e,DISK], DatanodeInfoWithStorage[127.0.0.1:37599,DS-cd0fb7e7-5668-4ca6-b607-edcb99fae6c4,DISK], DatanodeInfoWithStorage[127.0.0.1:39944,DS-fb4b647e-97aa-46da-a003-295864ee7c88,DISK], DatanodeInfoWithStorage[127.0.0.1:39683,DS-2a804379-8cef-4b71-9a53-9728507a53dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1804871332-172.17.0.11-1598149766312:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36539,DS-03e347f7-d69f-4bc4-aaae-ce936eed2f63,DISK], DatanodeInfoWithStorage[127.0.0.1:38762,DS-1bf91fd8-0bcf-48a8-b4d8-f13556cf57c5,DISK], DatanodeInfoWithStorage[127.0.0.1:46680,DS-712e707f-012c-4cc8-aa04-af4fb72a84cc,DISK], DatanodeInfoWithStorage[127.0.0.1:46503,DS-959aa7f5-99cb-402f-9500-373493d9fcb3,DISK], DatanodeInfoWithStorage[127.0.0.1:40218,DS-e68d9b29-d3f4-47ad-b145-425524b8a80e,DISK], DatanodeInfoWithStorage[127.0.0.1:37599,DS-cd0fb7e7-5668-4ca6-b607-edcb99fae6c4,DISK], DatanodeInfoWithStorage[127.0.0.1:39944,DS-fb4b647e-97aa-46da-a003-295864ee7c88,DISK], DatanodeInfoWithStorage[127.0.0.1:39683,DS-2a804379-8cef-4b71-9a53-9728507a53dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-190978063-172.17.0.11-1598149881732:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37912,DS-6409ddb0-d0e2-45d2-9d91-50af3faa73d4,DISK], DatanodeInfoWithStorage[127.0.0.1:36163,DS-e8b62e48-e996-4c22-86a5-6e3bf0a4a310,DISK], DatanodeInfoWithStorage[127.0.0.1:46675,DS-7b1efe91-e8bc-445c-9775-2c1d10e20f83,DISK], DatanodeInfoWithStorage[127.0.0.1:34951,DS-e7a02dd6-557d-4a13-939f-51d9f8e6b827,DISK], DatanodeInfoWithStorage[127.0.0.1:41339,DS-49236ea2-4164-4f92-befa-daf3ba4ed4df,DISK], DatanodeInfoWithStorage[127.0.0.1:43426,DS-7e2e23e7-38ff-4e5b-8791-8ebf99eb2d62,DISK], DatanodeInfoWithStorage[127.0.0.1:43674,DS-7f6cf95e-2e19-4c19-a4bc-24d0bbad2390,DISK], DatanodeInfoWithStorage[127.0.0.1:43617,DS-8b8dbd34-a937-4926-ab50-30a176f00b57,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-190978063-172.17.0.11-1598149881732:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37912,DS-6409ddb0-d0e2-45d2-9d91-50af3faa73d4,DISK], DatanodeInfoWithStorage[127.0.0.1:36163,DS-e8b62e48-e996-4c22-86a5-6e3bf0a4a310,DISK], DatanodeInfoWithStorage[127.0.0.1:46675,DS-7b1efe91-e8bc-445c-9775-2c1d10e20f83,DISK], DatanodeInfoWithStorage[127.0.0.1:34951,DS-e7a02dd6-557d-4a13-939f-51d9f8e6b827,DISK], DatanodeInfoWithStorage[127.0.0.1:41339,DS-49236ea2-4164-4f92-befa-daf3ba4ed4df,DISK], DatanodeInfoWithStorage[127.0.0.1:43426,DS-7e2e23e7-38ff-4e5b-8791-8ebf99eb2d62,DISK], DatanodeInfoWithStorage[127.0.0.1:43674,DS-7f6cf95e-2e19-4c19-a4bc-24d0bbad2390,DISK], DatanodeInfoWithStorage[127.0.0.1:43617,DS-8b8dbd34-a937-4926-ab50-30a176f00b57,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-90678351-172.17.0.11-1598150239014:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36533,DS-ac74e39d-3c52-43b7-9b87-2f4cea87872a,DISK], DatanodeInfoWithStorage[127.0.0.1:41348,DS-07112609-1c7a-40cc-8f19-055b8fd55397,DISK], DatanodeInfoWithStorage[127.0.0.1:45649,DS-d7f8b019-6f70-4739-858b-ace10b5252e2,DISK], DatanodeInfoWithStorage[127.0.0.1:42470,DS-bd2afa4a-e152-43e9-9d8f-d80644339e4d,DISK], DatanodeInfoWithStorage[127.0.0.1:35421,DS-077b6763-fe31-4d84-b585-ca13b3fb2706,DISK], DatanodeInfoWithStorage[127.0.0.1:40211,DS-995de58d-bbd2-487d-ae6e-c9500811c5f9,DISK], DatanodeInfoWithStorage[127.0.0.1:32907,DS-a87409d6-8aa5-414b-82ee-f91a95816f9b,DISK], DatanodeInfoWithStorage[127.0.0.1:35191,DS-8cfa0b50-0670-4399-850c-f4d956b3c923,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-90678351-172.17.0.11-1598150239014:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36533,DS-ac74e39d-3c52-43b7-9b87-2f4cea87872a,DISK], DatanodeInfoWithStorage[127.0.0.1:41348,DS-07112609-1c7a-40cc-8f19-055b8fd55397,DISK], DatanodeInfoWithStorage[127.0.0.1:45649,DS-d7f8b019-6f70-4739-858b-ace10b5252e2,DISK], DatanodeInfoWithStorage[127.0.0.1:42470,DS-bd2afa4a-e152-43e9-9d8f-d80644339e4d,DISK], DatanodeInfoWithStorage[127.0.0.1:35421,DS-077b6763-fe31-4d84-b585-ca13b3fb2706,DISK], DatanodeInfoWithStorage[127.0.0.1:40211,DS-995de58d-bbd2-487d-ae6e-c9500811c5f9,DISK], DatanodeInfoWithStorage[127.0.0.1:32907,DS-a87409d6-8aa5-414b-82ee-f91a95816f9b,DISK], DatanodeInfoWithStorage[127.0.0.1:35191,DS-8cfa0b50-0670-4399-850c-f4d956b3c923,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-912173965-172.17.0.11-1598150472073:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33677,DS-f74fcd65-bab8-41b4-9414-03634913cad8,DISK], DatanodeInfoWithStorage[127.0.0.1:36353,DS-29ca1c58-83c4-473f-af79-2844018252d8,DISK], DatanodeInfoWithStorage[127.0.0.1:40748,DS-db1d7611-0700-415c-a4e1-12076567316e,DISK], DatanodeInfoWithStorage[127.0.0.1:35378,DS-225e1389-6eaf-45ec-a827-b72adbc4c5dd,DISK], DatanodeInfoWithStorage[127.0.0.1:45820,DS-0e83224b-f7a4-4034-8ca5-ae1f18ab333f,DISK], DatanodeInfoWithStorage[127.0.0.1:46793,DS-a56f623b-bf78-4fb0-ae99-df526a261285,DISK], DatanodeInfoWithStorage[127.0.0.1:33282,DS-3c627989-e2d5-46fd-8942-ff9ba136edfa,DISK], DatanodeInfoWithStorage[127.0.0.1:43324,DS-7f7a6b47-8706-4e99-9cb8-29c07a6f165a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-912173965-172.17.0.11-1598150472073:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33677,DS-f74fcd65-bab8-41b4-9414-03634913cad8,DISK], DatanodeInfoWithStorage[127.0.0.1:36353,DS-29ca1c58-83c4-473f-af79-2844018252d8,DISK], DatanodeInfoWithStorage[127.0.0.1:40748,DS-db1d7611-0700-415c-a4e1-12076567316e,DISK], DatanodeInfoWithStorage[127.0.0.1:35378,DS-225e1389-6eaf-45ec-a827-b72adbc4c5dd,DISK], DatanodeInfoWithStorage[127.0.0.1:45820,DS-0e83224b-f7a4-4034-8ca5-ae1f18ab333f,DISK], DatanodeInfoWithStorage[127.0.0.1:46793,DS-a56f623b-bf78-4fb0-ae99-df526a261285,DISK], DatanodeInfoWithStorage[127.0.0.1:33282,DS-3c627989-e2d5-46fd-8942-ff9ba136edfa,DISK], DatanodeInfoWithStorage[127.0.0.1:43324,DS-7f7a6b47-8706-4e99-9cb8-29c07a6f165a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1334710443-172.17.0.11-1598150580333:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37870,DS-540759e2-c3a6-4bd4-8a4e-5da50b8f6969,DISK], DatanodeInfoWithStorage[127.0.0.1:45691,DS-eef69cb8-53eb-4803-8db9-2691fbcf13a2,DISK], DatanodeInfoWithStorage[127.0.0.1:42710,DS-cd77e10e-9eda-455e-92f0-59c7ba489100,DISK], DatanodeInfoWithStorage[127.0.0.1:36720,DS-2edfd75d-0d27-42c8-8379-b0b07c9dcb61,DISK], DatanodeInfoWithStorage[127.0.0.1:46477,DS-8d098ba1-21e4-4a6b-a78b-d830b68832e3,DISK], DatanodeInfoWithStorage[127.0.0.1:40261,DS-da808ffe-4304-4d92-9a3a-f049d6d94275,DISK], DatanodeInfoWithStorage[127.0.0.1:42408,DS-b8eb9022-239a-449d-a4d0-40778700dea1,DISK], DatanodeInfoWithStorage[127.0.0.1:36151,DS-916ee820-e023-462d-a7bc-252786e4cd1b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1334710443-172.17.0.11-1598150580333:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37870,DS-540759e2-c3a6-4bd4-8a4e-5da50b8f6969,DISK], DatanodeInfoWithStorage[127.0.0.1:45691,DS-eef69cb8-53eb-4803-8db9-2691fbcf13a2,DISK], DatanodeInfoWithStorage[127.0.0.1:42710,DS-cd77e10e-9eda-455e-92f0-59c7ba489100,DISK], DatanodeInfoWithStorage[127.0.0.1:36720,DS-2edfd75d-0d27-42c8-8379-b0b07c9dcb61,DISK], DatanodeInfoWithStorage[127.0.0.1:46477,DS-8d098ba1-21e4-4a6b-a78b-d830b68832e3,DISK], DatanodeInfoWithStorage[127.0.0.1:40261,DS-da808ffe-4304-4d92-9a3a-f049d6d94275,DISK], DatanodeInfoWithStorage[127.0.0.1:42408,DS-b8eb9022-239a-449d-a4d0-40778700dea1,DISK], DatanodeInfoWithStorage[127.0.0.1:36151,DS-916ee820-e023-462d-a7bc-252786e4cd1b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-275593397-172.17.0.11-1598150898697:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42058,DS-c4a08c30-13dc-44d7-a2fe-02daed860318,DISK], DatanodeInfoWithStorage[127.0.0.1:36995,DS-fcd47bce-54b9-499b-9b3e-a01afc6da29f,DISK], DatanodeInfoWithStorage[127.0.0.1:35746,DS-866d25e9-3159-45cc-8f9c-4807f5ba8986,DISK], DatanodeInfoWithStorage[127.0.0.1:35382,DS-9df2fa0c-d38d-4f39-80e2-3e2c63a3ffe8,DISK], DatanodeInfoWithStorage[127.0.0.1:43935,DS-a0c8943f-ce57-40f6-ab19-4e6a9be9feb8,DISK], DatanodeInfoWithStorage[127.0.0.1:39127,DS-c4b848ff-5fc6-431f-810c-6c77469d28ad,DISK], DatanodeInfoWithStorage[127.0.0.1:40351,DS-aa89b482-31f9-4caf-a845-5ed916a70399,DISK], DatanodeInfoWithStorage[127.0.0.1:40152,DS-66078de4-1504-4037-becf-15d171eecd91,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-275593397-172.17.0.11-1598150898697:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42058,DS-c4a08c30-13dc-44d7-a2fe-02daed860318,DISK], DatanodeInfoWithStorage[127.0.0.1:36995,DS-fcd47bce-54b9-499b-9b3e-a01afc6da29f,DISK], DatanodeInfoWithStorage[127.0.0.1:35746,DS-866d25e9-3159-45cc-8f9c-4807f5ba8986,DISK], DatanodeInfoWithStorage[127.0.0.1:35382,DS-9df2fa0c-d38d-4f39-80e2-3e2c63a3ffe8,DISK], DatanodeInfoWithStorage[127.0.0.1:43935,DS-a0c8943f-ce57-40f6-ab19-4e6a9be9feb8,DISK], DatanodeInfoWithStorage[127.0.0.1:39127,DS-c4b848ff-5fc6-431f-810c-6c77469d28ad,DISK], DatanodeInfoWithStorage[127.0.0.1:40351,DS-aa89b482-31f9-4caf-a845-5ed916a70399,DISK], DatanodeInfoWithStorage[127.0.0.1:40152,DS-66078de4-1504-4037-becf-15d171eecd91,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1138725436-172.17.0.11-1598150971388:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43575,DS-b421a07c-5d92-420f-8088-e9646c4f9ce8,DISK], DatanodeInfoWithStorage[127.0.0.1:41410,DS-2481bd50-c7d3-4512-8090-b2c080bc8430,DISK], DatanodeInfoWithStorage[127.0.0.1:37004,DS-005fd480-c768-4f28-9663-2b23f6d26b8e,DISK], DatanodeInfoWithStorage[127.0.0.1:35327,DS-0556dbb6-5150-4bde-823e-9a9118bb7cf2,DISK], DatanodeInfoWithStorage[127.0.0.1:39892,DS-935f4efb-1563-4a0d-b8de-ec1795fcd192,DISK], DatanodeInfoWithStorage[127.0.0.1:33653,DS-98f31c36-5bc1-4baa-ad45-cd65d9106607,DISK], DatanodeInfoWithStorage[127.0.0.1:42682,DS-b16c0b18-6dbe-40fe-a4e3-b83224bf0953,DISK], DatanodeInfoWithStorage[127.0.0.1:42814,DS-d6965f88-54ab-4db8-ae0b-6fde08edfc02,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1138725436-172.17.0.11-1598150971388:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43575,DS-b421a07c-5d92-420f-8088-e9646c4f9ce8,DISK], DatanodeInfoWithStorage[127.0.0.1:41410,DS-2481bd50-c7d3-4512-8090-b2c080bc8430,DISK], DatanodeInfoWithStorage[127.0.0.1:37004,DS-005fd480-c768-4f28-9663-2b23f6d26b8e,DISK], DatanodeInfoWithStorage[127.0.0.1:35327,DS-0556dbb6-5150-4bde-823e-9a9118bb7cf2,DISK], DatanodeInfoWithStorage[127.0.0.1:39892,DS-935f4efb-1563-4a0d-b8de-ec1795fcd192,DISK], DatanodeInfoWithStorage[127.0.0.1:33653,DS-98f31c36-5bc1-4baa-ad45-cd65d9106607,DISK], DatanodeInfoWithStorage[127.0.0.1:42682,DS-b16c0b18-6dbe-40fe-a4e3-b83224bf0953,DISK], DatanodeInfoWithStorage[127.0.0.1:42814,DS-d6965f88-54ab-4db8-ae0b-6fde08edfc02,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-546962362-172.17.0.11-1598151012256:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40835,DS-6a7520cf-7454-4bfc-89f3-ebd753bde472,DISK], DatanodeInfoWithStorage[127.0.0.1:40360,DS-619070b1-4a47-4d87-aa30-77b9bd551c33,DISK], DatanodeInfoWithStorage[127.0.0.1:32968,DS-f9ea57c8-eb3f-4497-be15-3d71bbe0aa7e,DISK], DatanodeInfoWithStorage[127.0.0.1:43497,DS-f7ec5e1e-7223-408f-9ed9-6303145e1a9d,DISK], DatanodeInfoWithStorage[127.0.0.1:41089,DS-5181de58-e27d-4917-a1b6-567345cbb808,DISK], DatanodeInfoWithStorage[127.0.0.1:35981,DS-72fd3881-d6d2-40d9-9c4b-9c91b339b248,DISK], DatanodeInfoWithStorage[127.0.0.1:40930,DS-25755796-fdd3-4c2d-8e08-24be112b5739,DISK], DatanodeInfoWithStorage[127.0.0.1:42554,DS-57e364f3-83a4-41b0-b2f1-22d6bd10a01f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-546962362-172.17.0.11-1598151012256:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40835,DS-6a7520cf-7454-4bfc-89f3-ebd753bde472,DISK], DatanodeInfoWithStorage[127.0.0.1:40360,DS-619070b1-4a47-4d87-aa30-77b9bd551c33,DISK], DatanodeInfoWithStorage[127.0.0.1:32968,DS-f9ea57c8-eb3f-4497-be15-3d71bbe0aa7e,DISK], DatanodeInfoWithStorage[127.0.0.1:43497,DS-f7ec5e1e-7223-408f-9ed9-6303145e1a9d,DISK], DatanodeInfoWithStorage[127.0.0.1:41089,DS-5181de58-e27d-4917-a1b6-567345cbb808,DISK], DatanodeInfoWithStorage[127.0.0.1:35981,DS-72fd3881-d6d2-40d9-9c4b-9c91b339b248,DISK], DatanodeInfoWithStorage[127.0.0.1:40930,DS-25755796-fdd3-4c2d-8e08-24be112b5739,DISK], DatanodeInfoWithStorage[127.0.0.1:42554,DS-57e364f3-83a4-41b0-b2f1-22d6bd10a01f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-991388467-172.17.0.11-1598151308093:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36135,DS-d79714b0-f0e8-4d4a-b386-dbf9f462ef9a,DISK], DatanodeInfoWithStorage[127.0.0.1:45011,DS-935c0fa4-0ecb-4dcd-ba31-e9660d967e70,DISK], DatanodeInfoWithStorage[127.0.0.1:37094,DS-4ce412e0-982a-4f11-a0e4-e29fb4a8c0eb,DISK], DatanodeInfoWithStorage[127.0.0.1:38378,DS-9c5ca3d9-5311-4f7c-8485-5edbe0ed007c,DISK], DatanodeInfoWithStorage[127.0.0.1:43735,DS-0c4fb344-735f-421c-be02-93d96d8c2508,DISK], DatanodeInfoWithStorage[127.0.0.1:36989,DS-29562012-25cd-4383-b4bd-5fbc56d58140,DISK], DatanodeInfoWithStorage[127.0.0.1:37297,DS-e2dff5a8-fd67-4733-81c2-afccbf17b1a9,DISK], DatanodeInfoWithStorage[127.0.0.1:37364,DS-c12e2271-1840-44ac-aaf8-303aae93a0c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-991388467-172.17.0.11-1598151308093:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36135,DS-d79714b0-f0e8-4d4a-b386-dbf9f462ef9a,DISK], DatanodeInfoWithStorage[127.0.0.1:45011,DS-935c0fa4-0ecb-4dcd-ba31-e9660d967e70,DISK], DatanodeInfoWithStorage[127.0.0.1:37094,DS-4ce412e0-982a-4f11-a0e4-e29fb4a8c0eb,DISK], DatanodeInfoWithStorage[127.0.0.1:38378,DS-9c5ca3d9-5311-4f7c-8485-5edbe0ed007c,DISK], DatanodeInfoWithStorage[127.0.0.1:43735,DS-0c4fb344-735f-421c-be02-93d96d8c2508,DISK], DatanodeInfoWithStorage[127.0.0.1:36989,DS-29562012-25cd-4383-b4bd-5fbc56d58140,DISK], DatanodeInfoWithStorage[127.0.0.1:37297,DS-e2dff5a8-fd67-4733-81c2-afccbf17b1a9,DISK], DatanodeInfoWithStorage[127.0.0.1:37364,DS-c12e2271-1840-44ac-aaf8-303aae93a0c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1171990719-172.17.0.11-1598151424752:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39768,DS-711264db-faba-462c-9eff-b97cbf81652b,DISK], DatanodeInfoWithStorage[127.0.0.1:34565,DS-3389e391-7e20-49c1-9597-c934e732e6e6,DISK], DatanodeInfoWithStorage[127.0.0.1:42062,DS-062a8002-b6a0-407b-b2cf-b4c71d2d3a7c,DISK], DatanodeInfoWithStorage[127.0.0.1:46319,DS-53233cf4-133d-4567-a623-708b2a5d61ff,DISK], DatanodeInfoWithStorage[127.0.0.1:35919,DS-fc3217fe-3d7b-4b73-a77c-bac54e29bd81,DISK], DatanodeInfoWithStorage[127.0.0.1:44577,DS-8bb47b09-be05-4b27-ac95-75eec18e80f8,DISK], DatanodeInfoWithStorage[127.0.0.1:33473,DS-61c664f6-19b5-4f8e-a890-d82fe9baf67e,DISK], DatanodeInfoWithStorage[127.0.0.1:38551,DS-c52d1978-5747-4b67-9901-1aa15c53ec78,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1171990719-172.17.0.11-1598151424752:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39768,DS-711264db-faba-462c-9eff-b97cbf81652b,DISK], DatanodeInfoWithStorage[127.0.0.1:34565,DS-3389e391-7e20-49c1-9597-c934e732e6e6,DISK], DatanodeInfoWithStorage[127.0.0.1:42062,DS-062a8002-b6a0-407b-b2cf-b4c71d2d3a7c,DISK], DatanodeInfoWithStorage[127.0.0.1:46319,DS-53233cf4-133d-4567-a623-708b2a5d61ff,DISK], DatanodeInfoWithStorage[127.0.0.1:35919,DS-fc3217fe-3d7b-4b73-a77c-bac54e29bd81,DISK], DatanodeInfoWithStorage[127.0.0.1:44577,DS-8bb47b09-be05-4b27-ac95-75eec18e80f8,DISK], DatanodeInfoWithStorage[127.0.0.1:33473,DS-61c664f6-19b5-4f8e-a890-d82fe9baf67e,DISK], DatanodeInfoWithStorage[127.0.0.1:38551,DS-c52d1978-5747-4b67-9901-1aa15c53ec78,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1169911220-172.17.0.11-1598151500109:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35517,DS-b2088f5f-999e-4ada-b537-4d8fc9638e55,DISK], DatanodeInfoWithStorage[127.0.0.1:42799,DS-21fd92dd-65a8-4d02-84fa-1482da8c804f,DISK], DatanodeInfoWithStorage[127.0.0.1:34673,DS-75cada37-3df2-4556-b5e9-8fc9a4774d34,DISK], DatanodeInfoWithStorage[127.0.0.1:37317,DS-a1790c16-885d-44ad-9fde-e32dde12c268,DISK], DatanodeInfoWithStorage[127.0.0.1:44621,DS-a2d1a9cb-0a72-4bfe-9d76-4a3c0a3791cc,DISK], DatanodeInfoWithStorage[127.0.0.1:44900,DS-4d3941e6-0a76-4b08-b417-85da07c759a1,DISK], DatanodeInfoWithStorage[127.0.0.1:42326,DS-8534cd97-c7d2-44ca-844d-02bd246af616,DISK], DatanodeInfoWithStorage[127.0.0.1:42859,DS-0e121b34-f2e6-4d48-b76d-cb5e7778988b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1169911220-172.17.0.11-1598151500109:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35517,DS-b2088f5f-999e-4ada-b537-4d8fc9638e55,DISK], DatanodeInfoWithStorage[127.0.0.1:42799,DS-21fd92dd-65a8-4d02-84fa-1482da8c804f,DISK], DatanodeInfoWithStorage[127.0.0.1:34673,DS-75cada37-3df2-4556-b5e9-8fc9a4774d34,DISK], DatanodeInfoWithStorage[127.0.0.1:37317,DS-a1790c16-885d-44ad-9fde-e32dde12c268,DISK], DatanodeInfoWithStorage[127.0.0.1:44621,DS-a2d1a9cb-0a72-4bfe-9d76-4a3c0a3791cc,DISK], DatanodeInfoWithStorage[127.0.0.1:44900,DS-4d3941e6-0a76-4b08-b417-85da07c759a1,DISK], DatanodeInfoWithStorage[127.0.0.1:42326,DS-8534cd97-c7d2-44ca-844d-02bd246af616,DISK], DatanodeInfoWithStorage[127.0.0.1:42859,DS-0e121b34-f2e6-4d48-b76d-cb5e7778988b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 12 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5350
