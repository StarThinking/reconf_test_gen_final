reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-549446354-172.17.0.17-1598324753778:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44300,DS-776f25f5-a6dd-4b53-aa05-e59ae82ce4c9,DISK], DatanodeInfoWithStorage[127.0.0.1:44927,DS-7ebf43f4-fe7d-4c33-8fde-36526f668f97,DISK], DatanodeInfoWithStorage[127.0.0.1:35484,DS-8f89a197-ce63-4e51-9181-28e4a3e80a40,DISK], DatanodeInfoWithStorage[127.0.0.1:36573,DS-43be4962-34e0-4dde-a3fc-8bf347cdce67,DISK], DatanodeInfoWithStorage[127.0.0.1:44369,DS-49d26bde-1d13-4c0b-8c2b-438d8fde6e11,DISK], DatanodeInfoWithStorage[127.0.0.1:36104,DS-63d4a400-0be6-44d4-8310-68512bca627b,DISK], DatanodeInfoWithStorage[127.0.0.1:33335,DS-f72832fd-2106-456c-8bb6-fce3e71f3fd7,DISK], DatanodeInfoWithStorage[127.0.0.1:38820,DS-5d58fd03-6387-418d-a991-0dab9bf6f1ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-549446354-172.17.0.17-1598324753778:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44300,DS-776f25f5-a6dd-4b53-aa05-e59ae82ce4c9,DISK], DatanodeInfoWithStorage[127.0.0.1:44927,DS-7ebf43f4-fe7d-4c33-8fde-36526f668f97,DISK], DatanodeInfoWithStorage[127.0.0.1:35484,DS-8f89a197-ce63-4e51-9181-28e4a3e80a40,DISK], DatanodeInfoWithStorage[127.0.0.1:36573,DS-43be4962-34e0-4dde-a3fc-8bf347cdce67,DISK], DatanodeInfoWithStorage[127.0.0.1:44369,DS-49d26bde-1d13-4c0b-8c2b-438d8fde6e11,DISK], DatanodeInfoWithStorage[127.0.0.1:36104,DS-63d4a400-0be6-44d4-8310-68512bca627b,DISK], DatanodeInfoWithStorage[127.0.0.1:33335,DS-f72832fd-2106-456c-8bb6-fce3e71f3fd7,DISK], DatanodeInfoWithStorage[127.0.0.1:38820,DS-5d58fd03-6387-418d-a991-0dab9bf6f1ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1676174117-172.17.0.17-1598324826504:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45147,DS-1e09c823-3dbd-4829-8b3f-b7f1fbddff5b,DISK], DatanodeInfoWithStorage[127.0.0.1:43879,DS-769d55e2-a61e-47c4-879a-1e11db0a67f0,DISK], DatanodeInfoWithStorage[127.0.0.1:34143,DS-e63bbdff-6ec9-48be-b5b7-d0dd20ba7048,DISK], DatanodeInfoWithStorage[127.0.0.1:44905,DS-58dacb8a-9554-44c4-a09e-d233c7c0ae7d,DISK], DatanodeInfoWithStorage[127.0.0.1:44811,DS-3fe0ab58-8071-4dfc-acdf-a719268f1bba,DISK], DatanodeInfoWithStorage[127.0.0.1:40403,DS-a642f1cd-9dee-46b5-9dc6-85f9cc7b72ac,DISK], DatanodeInfoWithStorage[127.0.0.1:34679,DS-c3b6ac1d-41c4-4205-b3ff-deea91e0d4fe,DISK], DatanodeInfoWithStorage[127.0.0.1:42878,DS-ba6cb0bf-d054-405c-ac40-4a460e026524,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1676174117-172.17.0.17-1598324826504:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45147,DS-1e09c823-3dbd-4829-8b3f-b7f1fbddff5b,DISK], DatanodeInfoWithStorage[127.0.0.1:43879,DS-769d55e2-a61e-47c4-879a-1e11db0a67f0,DISK], DatanodeInfoWithStorage[127.0.0.1:34143,DS-e63bbdff-6ec9-48be-b5b7-d0dd20ba7048,DISK], DatanodeInfoWithStorage[127.0.0.1:44905,DS-58dacb8a-9554-44c4-a09e-d233c7c0ae7d,DISK], DatanodeInfoWithStorage[127.0.0.1:44811,DS-3fe0ab58-8071-4dfc-acdf-a719268f1bba,DISK], DatanodeInfoWithStorage[127.0.0.1:40403,DS-a642f1cd-9dee-46b5-9dc6-85f9cc7b72ac,DISK], DatanodeInfoWithStorage[127.0.0.1:34679,DS-c3b6ac1d-41c4-4205-b3ff-deea91e0d4fe,DISK], DatanodeInfoWithStorage[127.0.0.1:42878,DS-ba6cb0bf-d054-405c-ac40-4a460e026524,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-803191567-172.17.0.17-1598326161411:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36673,DS-38bbf31f-ea6e-4bb1-90d1-0b61e8d248ff,DISK], DatanodeInfoWithStorage[127.0.0.1:46324,DS-112df897-9997-454e-83c9-6404377aa4e5,DISK], DatanodeInfoWithStorage[127.0.0.1:44609,DS-f8254917-192b-4140-a18d-2410757aeabd,DISK], DatanodeInfoWithStorage[127.0.0.1:40309,DS-a5189645-bfa6-42e6-975c-4d0c02e9b3ed,DISK], DatanodeInfoWithStorage[127.0.0.1:43871,DS-f12ccfc4-1252-47ea-8885-312b187e43ae,DISK], DatanodeInfoWithStorage[127.0.0.1:36818,DS-6b584cbd-eba4-4e54-9d42-ff89c3e21401,DISK], DatanodeInfoWithStorage[127.0.0.1:38490,DS-b81bb720-8e51-44e5-b4de-6c30f065ff92,DISK], DatanodeInfoWithStorage[127.0.0.1:42275,DS-234db622-2d73-43cb-ba0c-770523dfac82,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-803191567-172.17.0.17-1598326161411:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36673,DS-38bbf31f-ea6e-4bb1-90d1-0b61e8d248ff,DISK], DatanodeInfoWithStorage[127.0.0.1:46324,DS-112df897-9997-454e-83c9-6404377aa4e5,DISK], DatanodeInfoWithStorage[127.0.0.1:44609,DS-f8254917-192b-4140-a18d-2410757aeabd,DISK], DatanodeInfoWithStorage[127.0.0.1:40309,DS-a5189645-bfa6-42e6-975c-4d0c02e9b3ed,DISK], DatanodeInfoWithStorage[127.0.0.1:43871,DS-f12ccfc4-1252-47ea-8885-312b187e43ae,DISK], DatanodeInfoWithStorage[127.0.0.1:36818,DS-6b584cbd-eba4-4e54-9d42-ff89c3e21401,DISK], DatanodeInfoWithStorage[127.0.0.1:38490,DS-b81bb720-8e51-44e5-b4de-6c30f065ff92,DISK], DatanodeInfoWithStorage[127.0.0.1:42275,DS-234db622-2d73-43cb-ba0c-770523dfac82,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1379846613-172.17.0.17-1598326230848:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46671,DS-733656b2-328d-4f62-9e1b-1081314f3e8f,DISK], DatanodeInfoWithStorage[127.0.0.1:45294,DS-2e0bc417-723d-448f-a8a6-cd2e09321063,DISK], DatanodeInfoWithStorage[127.0.0.1:41446,DS-f489d88b-2e21-4867-882d-87776ab0a646,DISK], DatanodeInfoWithStorage[127.0.0.1:38876,DS-6d016826-3d5d-4511-a413-b6663cce762a,DISK], DatanodeInfoWithStorage[127.0.0.1:42394,DS-3007794f-75b0-4052-b581-cc1aa4ca7ca9,DISK], DatanodeInfoWithStorage[127.0.0.1:42857,DS-d9d4e9dc-14c3-44d4-8a03-048cc9f4592a,DISK], DatanodeInfoWithStorage[127.0.0.1:43357,DS-531d0181-7891-4071-a373-7483ca36f850,DISK], DatanodeInfoWithStorage[127.0.0.1:43466,DS-d942e329-74a2-49dd-b37a-e14e87562888,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1379846613-172.17.0.17-1598326230848:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46671,DS-733656b2-328d-4f62-9e1b-1081314f3e8f,DISK], DatanodeInfoWithStorage[127.0.0.1:45294,DS-2e0bc417-723d-448f-a8a6-cd2e09321063,DISK], DatanodeInfoWithStorage[127.0.0.1:41446,DS-f489d88b-2e21-4867-882d-87776ab0a646,DISK], DatanodeInfoWithStorage[127.0.0.1:38876,DS-6d016826-3d5d-4511-a413-b6663cce762a,DISK], DatanodeInfoWithStorage[127.0.0.1:42394,DS-3007794f-75b0-4052-b581-cc1aa4ca7ca9,DISK], DatanodeInfoWithStorage[127.0.0.1:42857,DS-d9d4e9dc-14c3-44d4-8a03-048cc9f4592a,DISK], DatanodeInfoWithStorage[127.0.0.1:43357,DS-531d0181-7891-4071-a373-7483ca36f850,DISK], DatanodeInfoWithStorage[127.0.0.1:43466,DS-d942e329-74a2-49dd-b37a-e14e87562888,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1688026420-172.17.0.17-1598326380479:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41441,DS-9c02e27a-a9e0-444d-8468-5160a4b7da96,DISK], DatanodeInfoWithStorage[127.0.0.1:35727,DS-87324b7e-bbb8-4551-b223-6effb9e03b50,DISK], DatanodeInfoWithStorage[127.0.0.1:33188,DS-c65f692a-8587-43d0-91b1-8538db1950a3,DISK], DatanodeInfoWithStorage[127.0.0.1:45846,DS-8e6ec823-2494-4f90-a706-e9241d2bc3ca,DISK], DatanodeInfoWithStorage[127.0.0.1:45918,DS-94a3d27d-d585-4c51-bfec-01d0dbc6ac7c,DISK], DatanodeInfoWithStorage[127.0.0.1:38004,DS-5e80a49a-2a84-4c95-92fb-54306450c54c,DISK], DatanodeInfoWithStorage[127.0.0.1:33760,DS-88528815-9c77-4804-b2f2-95280b404054,DISK], DatanodeInfoWithStorage[127.0.0.1:44886,DS-b59f66cf-98cc-4fa6-9d36-c747cc62b11b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1688026420-172.17.0.17-1598326380479:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41441,DS-9c02e27a-a9e0-444d-8468-5160a4b7da96,DISK], DatanodeInfoWithStorage[127.0.0.1:35727,DS-87324b7e-bbb8-4551-b223-6effb9e03b50,DISK], DatanodeInfoWithStorage[127.0.0.1:33188,DS-c65f692a-8587-43d0-91b1-8538db1950a3,DISK], DatanodeInfoWithStorage[127.0.0.1:45846,DS-8e6ec823-2494-4f90-a706-e9241d2bc3ca,DISK], DatanodeInfoWithStorage[127.0.0.1:45918,DS-94a3d27d-d585-4c51-bfec-01d0dbc6ac7c,DISK], DatanodeInfoWithStorage[127.0.0.1:38004,DS-5e80a49a-2a84-4c95-92fb-54306450c54c,DISK], DatanodeInfoWithStorage[127.0.0.1:33760,DS-88528815-9c77-4804-b2f2-95280b404054,DISK], DatanodeInfoWithStorage[127.0.0.1:44886,DS-b59f66cf-98cc-4fa6-9d36-c747cc62b11b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-204465054-172.17.0.17-1598326477732:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40974,DS-97f56ab0-d92f-42af-a833-2fdc29bb9946,DISK], DatanodeInfoWithStorage[127.0.0.1:33147,DS-10aa5382-0f47-4ea2-8ca6-62b1207f59ba,DISK], DatanodeInfoWithStorage[127.0.0.1:40608,DS-64f1bf15-600f-4992-9e07-dfcb2ec82e77,DISK], DatanodeInfoWithStorage[127.0.0.1:38759,DS-d99d27cc-0760-4f6c-9724-66fd59ea211b,DISK], DatanodeInfoWithStorage[127.0.0.1:39278,DS-5e3ed178-43c1-43aa-ace1-62f01d96f007,DISK], DatanodeInfoWithStorage[127.0.0.1:41675,DS-afb1f216-9f08-4fb8-8702-f135c4466026,DISK], DatanodeInfoWithStorage[127.0.0.1:45287,DS-d8dad28e-16ae-4f94-b6d0-c114ac68f3bb,DISK], DatanodeInfoWithStorage[127.0.0.1:33333,DS-d4662515-3f74-4138-b2cd-75f2d4f7f496,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-204465054-172.17.0.17-1598326477732:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40974,DS-97f56ab0-d92f-42af-a833-2fdc29bb9946,DISK], DatanodeInfoWithStorage[127.0.0.1:33147,DS-10aa5382-0f47-4ea2-8ca6-62b1207f59ba,DISK], DatanodeInfoWithStorage[127.0.0.1:40608,DS-64f1bf15-600f-4992-9e07-dfcb2ec82e77,DISK], DatanodeInfoWithStorage[127.0.0.1:38759,DS-d99d27cc-0760-4f6c-9724-66fd59ea211b,DISK], DatanodeInfoWithStorage[127.0.0.1:39278,DS-5e3ed178-43c1-43aa-ace1-62f01d96f007,DISK], DatanodeInfoWithStorage[127.0.0.1:41675,DS-afb1f216-9f08-4fb8-8702-f135c4466026,DISK], DatanodeInfoWithStorage[127.0.0.1:45287,DS-d8dad28e-16ae-4f94-b6d0-c114ac68f3bb,DISK], DatanodeInfoWithStorage[127.0.0.1:33333,DS-d4662515-3f74-4138-b2cd-75f2d4f7f496,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1275558131-172.17.0.17-1598327182708:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33056,DS-8a9ad16a-6b7b-4f45-bb4d-93e3fb6c8e19,DISK], DatanodeInfoWithStorage[127.0.0.1:37026,DS-084d48d3-d77f-48c3-9772-82e04bf1c24d,DISK], DatanodeInfoWithStorage[127.0.0.1:35312,DS-c708dacc-4cf1-4713-aa06-a5102df360d3,DISK], DatanodeInfoWithStorage[127.0.0.1:45261,DS-e41aeb11-409c-4ce2-b19e-76401eef6b2a,DISK], DatanodeInfoWithStorage[127.0.0.1:38599,DS-ba8db1b5-750e-4a6b-8e89-652046664193,DISK], DatanodeInfoWithStorage[127.0.0.1:36873,DS-108b1834-4402-4ab0-aaa0-39698ccb02a2,DISK], DatanodeInfoWithStorage[127.0.0.1:38433,DS-1d22d18c-ca4a-4280-9859-36f904a1bea1,DISK], DatanodeInfoWithStorage[127.0.0.1:36855,DS-b473ed86-c6b8-4867-9d3c-337a3f83c36e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1275558131-172.17.0.17-1598327182708:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33056,DS-8a9ad16a-6b7b-4f45-bb4d-93e3fb6c8e19,DISK], DatanodeInfoWithStorage[127.0.0.1:37026,DS-084d48d3-d77f-48c3-9772-82e04bf1c24d,DISK], DatanodeInfoWithStorage[127.0.0.1:35312,DS-c708dacc-4cf1-4713-aa06-a5102df360d3,DISK], DatanodeInfoWithStorage[127.0.0.1:45261,DS-e41aeb11-409c-4ce2-b19e-76401eef6b2a,DISK], DatanodeInfoWithStorage[127.0.0.1:38599,DS-ba8db1b5-750e-4a6b-8e89-652046664193,DISK], DatanodeInfoWithStorage[127.0.0.1:36873,DS-108b1834-4402-4ab0-aaa0-39698ccb02a2,DISK], DatanodeInfoWithStorage[127.0.0.1:38433,DS-1d22d18c-ca4a-4280-9859-36f904a1bea1,DISK], DatanodeInfoWithStorage[127.0.0.1:36855,DS-b473ed86-c6b8-4867-9d3c-337a3f83c36e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-150242601-172.17.0.17-1598327972552:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45527,DS-39967435-665d-4e11-b8d5-41a18d7c12ae,DISK], DatanodeInfoWithStorage[127.0.0.1:45633,DS-95d0a4fc-1912-4290-aa04-f326cdaae2cb,DISK], DatanodeInfoWithStorage[127.0.0.1:37839,DS-38dad68f-e1b8-431b-9759-e9caa9c27b3a,DISK], DatanodeInfoWithStorage[127.0.0.1:38785,DS-c7d9bd99-62ec-4381-ae32-1c9568d519ec,DISK], DatanodeInfoWithStorage[127.0.0.1:44753,DS-d76e6034-ef82-45a3-a589-e62e2a6356ef,DISK], DatanodeInfoWithStorage[127.0.0.1:42791,DS-7bffc987-6ebc-4e30-93d0-e6844488754a,DISK], DatanodeInfoWithStorage[127.0.0.1:37635,DS-35f263df-8bf7-434e-b66f-384c8a07b91d,DISK], DatanodeInfoWithStorage[127.0.0.1:35409,DS-01a305a0-9327-4e2e-892a-d64f6906eddc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-150242601-172.17.0.17-1598327972552:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45527,DS-39967435-665d-4e11-b8d5-41a18d7c12ae,DISK], DatanodeInfoWithStorage[127.0.0.1:45633,DS-95d0a4fc-1912-4290-aa04-f326cdaae2cb,DISK], DatanodeInfoWithStorage[127.0.0.1:37839,DS-38dad68f-e1b8-431b-9759-e9caa9c27b3a,DISK], DatanodeInfoWithStorage[127.0.0.1:38785,DS-c7d9bd99-62ec-4381-ae32-1c9568d519ec,DISK], DatanodeInfoWithStorage[127.0.0.1:44753,DS-d76e6034-ef82-45a3-a589-e62e2a6356ef,DISK], DatanodeInfoWithStorage[127.0.0.1:42791,DS-7bffc987-6ebc-4e30-93d0-e6844488754a,DISK], DatanodeInfoWithStorage[127.0.0.1:37635,DS-35f263df-8bf7-434e-b66f-384c8a07b91d,DISK], DatanodeInfoWithStorage[127.0.0.1:35409,DS-01a305a0-9327-4e2e-892a-d64f6906eddc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-717065782-172.17.0.17-1598328015414:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34866,DS-4e4c4547-42b6-4f7d-9a63-d2585dfbbb7d,DISK], DatanodeInfoWithStorage[127.0.0.1:37026,DS-c4ba300d-63f0-4cbc-b1fa-b433a3b0dea4,DISK], DatanodeInfoWithStorage[127.0.0.1:45035,DS-3420e3bb-caed-472d-a519-709ced2c234f,DISK], DatanodeInfoWithStorage[127.0.0.1:35039,DS-98d059ba-212d-4465-bf43-40b44c4c3fe8,DISK], DatanodeInfoWithStorage[127.0.0.1:44148,DS-7f51dae1-9a8e-4b00-916e-8343f9f285b6,DISK], DatanodeInfoWithStorage[127.0.0.1:38828,DS-3dca8a33-fa1f-422c-bb2e-d04408c385d7,DISK], DatanodeInfoWithStorage[127.0.0.1:39216,DS-3e94dc90-16cd-4880-9ad5-64a281fbfc48,DISK], DatanodeInfoWithStorage[127.0.0.1:43524,DS-a22299e8-7ec9-47f0-9b3f-6da8a031b84d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-717065782-172.17.0.17-1598328015414:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34866,DS-4e4c4547-42b6-4f7d-9a63-d2585dfbbb7d,DISK], DatanodeInfoWithStorage[127.0.0.1:37026,DS-c4ba300d-63f0-4cbc-b1fa-b433a3b0dea4,DISK], DatanodeInfoWithStorage[127.0.0.1:45035,DS-3420e3bb-caed-472d-a519-709ced2c234f,DISK], DatanodeInfoWithStorage[127.0.0.1:35039,DS-98d059ba-212d-4465-bf43-40b44c4c3fe8,DISK], DatanodeInfoWithStorage[127.0.0.1:44148,DS-7f51dae1-9a8e-4b00-916e-8343f9f285b6,DISK], DatanodeInfoWithStorage[127.0.0.1:38828,DS-3dca8a33-fa1f-422c-bb2e-d04408c385d7,DISK], DatanodeInfoWithStorage[127.0.0.1:39216,DS-3e94dc90-16cd-4880-9ad5-64a281fbfc48,DISK], DatanodeInfoWithStorage[127.0.0.1:43524,DS-a22299e8-7ec9-47f0-9b3f-6da8a031b84d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-982467643-172.17.0.17-1598328542783:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40468,DS-52594b84-dc30-427b-96dd-eacae9b12962,DISK], DatanodeInfoWithStorage[127.0.0.1:44787,DS-25abcd3d-f10e-4f98-8e0a-975ea0dc7721,DISK], DatanodeInfoWithStorage[127.0.0.1:40740,DS-4879d12d-d799-4901-b119-1a2e42ed4a17,DISK], DatanodeInfoWithStorage[127.0.0.1:46584,DS-04b67982-aefc-42fe-8780-402ac0ae8303,DISK], DatanodeInfoWithStorage[127.0.0.1:40624,DS-fd5ccdda-6311-4270-9cff-dc976c8edfb8,DISK], DatanodeInfoWithStorage[127.0.0.1:40210,DS-e77f0dc3-6a85-48ff-97fb-1ae9ee12fe4a,DISK], DatanodeInfoWithStorage[127.0.0.1:43508,DS-0e23f3ce-7e59-4163-a8bf-2326314d7d83,DISK], DatanodeInfoWithStorage[127.0.0.1:38489,DS-1765bd47-a568-407e-a859-067c74b1926a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-982467643-172.17.0.17-1598328542783:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40468,DS-52594b84-dc30-427b-96dd-eacae9b12962,DISK], DatanodeInfoWithStorage[127.0.0.1:44787,DS-25abcd3d-f10e-4f98-8e0a-975ea0dc7721,DISK], DatanodeInfoWithStorage[127.0.0.1:40740,DS-4879d12d-d799-4901-b119-1a2e42ed4a17,DISK], DatanodeInfoWithStorage[127.0.0.1:46584,DS-04b67982-aefc-42fe-8780-402ac0ae8303,DISK], DatanodeInfoWithStorage[127.0.0.1:40624,DS-fd5ccdda-6311-4270-9cff-dc976c8edfb8,DISK], DatanodeInfoWithStorage[127.0.0.1:40210,DS-e77f0dc3-6a85-48ff-97fb-1ae9ee12fe4a,DISK], DatanodeInfoWithStorage[127.0.0.1:43508,DS-0e23f3ce-7e59-4163-a8bf-2326314d7d83,DISK], DatanodeInfoWithStorage[127.0.0.1:38489,DS-1765bd47-a568-407e-a859-067c74b1926a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-934461269-172.17.0.17-1598328582215:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44641,DS-07b0a83f-12e4-4156-a398-76be4eb1d96a,DISK], DatanodeInfoWithStorage[127.0.0.1:39405,DS-2dc82c65-7d3b-4c93-9921-c22f90528098,DISK], DatanodeInfoWithStorage[127.0.0.1:42333,DS-e4fdd0e9-b670-432d-952a-38e80ce36708,DISK], DatanodeInfoWithStorage[127.0.0.1:45480,DS-9defa994-b42e-450c-926e-70d513d05409,DISK], DatanodeInfoWithStorage[127.0.0.1:36313,DS-f8696a61-b478-44f7-86a1-270bef660bf0,DISK], DatanodeInfoWithStorage[127.0.0.1:37865,DS-4d089f0a-92ea-47aa-837b-59878dce7244,DISK], DatanodeInfoWithStorage[127.0.0.1:34355,DS-3a6ff8d7-1fb8-4285-9067-1ea7ad430b97,DISK], DatanodeInfoWithStorage[127.0.0.1:45963,DS-521acc0c-fd9b-424f-9f97-40b59820bdea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-934461269-172.17.0.17-1598328582215:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44641,DS-07b0a83f-12e4-4156-a398-76be4eb1d96a,DISK], DatanodeInfoWithStorage[127.0.0.1:39405,DS-2dc82c65-7d3b-4c93-9921-c22f90528098,DISK], DatanodeInfoWithStorage[127.0.0.1:42333,DS-e4fdd0e9-b670-432d-952a-38e80ce36708,DISK], DatanodeInfoWithStorage[127.0.0.1:45480,DS-9defa994-b42e-450c-926e-70d513d05409,DISK], DatanodeInfoWithStorage[127.0.0.1:36313,DS-f8696a61-b478-44f7-86a1-270bef660bf0,DISK], DatanodeInfoWithStorage[127.0.0.1:37865,DS-4d089f0a-92ea-47aa-837b-59878dce7244,DISK], DatanodeInfoWithStorage[127.0.0.1:34355,DS-3a6ff8d7-1fb8-4285-9067-1ea7ad430b97,DISK], DatanodeInfoWithStorage[127.0.0.1:45963,DS-521acc0c-fd9b-424f-9f97-40b59820bdea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-208719236-172.17.0.17-1598328742521:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36544,DS-a6875f1f-1152-441c-9357-7c0e0a5123be,DISK], DatanodeInfoWithStorage[127.0.0.1:35673,DS-40f23a6f-0b51-4728-8315-9291c614b3c5,DISK], DatanodeInfoWithStorage[127.0.0.1:32959,DS-f234473b-6739-4d37-af96-48b3cd018542,DISK], DatanodeInfoWithStorage[127.0.0.1:36352,DS-f1e8846d-141b-4b36-8467-005e326e6c6e,DISK], DatanodeInfoWithStorage[127.0.0.1:45637,DS-1e1e0e57-7a07-40cb-b86e-72acefb19803,DISK], DatanodeInfoWithStorage[127.0.0.1:44252,DS-244e03d6-e37f-4dec-9781-81f9d9cd1161,DISK], DatanodeInfoWithStorage[127.0.0.1:41495,DS-04f12cba-d0fc-4c96-925d-d4e7abb36d1f,DISK], DatanodeInfoWithStorage[127.0.0.1:45468,DS-7a66cc9d-6907-4ed8-9533-186777701f13,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-208719236-172.17.0.17-1598328742521:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36544,DS-a6875f1f-1152-441c-9357-7c0e0a5123be,DISK], DatanodeInfoWithStorage[127.0.0.1:35673,DS-40f23a6f-0b51-4728-8315-9291c614b3c5,DISK], DatanodeInfoWithStorage[127.0.0.1:32959,DS-f234473b-6739-4d37-af96-48b3cd018542,DISK], DatanodeInfoWithStorage[127.0.0.1:36352,DS-f1e8846d-141b-4b36-8467-005e326e6c6e,DISK], DatanodeInfoWithStorage[127.0.0.1:45637,DS-1e1e0e57-7a07-40cb-b86e-72acefb19803,DISK], DatanodeInfoWithStorage[127.0.0.1:44252,DS-244e03d6-e37f-4dec-9781-81f9d9cd1161,DISK], DatanodeInfoWithStorage[127.0.0.1:41495,DS-04f12cba-d0fc-4c96-925d-d4e7abb36d1f,DISK], DatanodeInfoWithStorage[127.0.0.1:45468,DS-7a66cc9d-6907-4ed8-9533-186777701f13,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-772622883-172.17.0.17-1598329004595:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34649,DS-9aaa080a-edaa-4400-ad87-231428d83104,DISK], DatanodeInfoWithStorage[127.0.0.1:39173,DS-5369ac35-5947-49fa-95d6-9e9eb1d7473a,DISK], DatanodeInfoWithStorage[127.0.0.1:44777,DS-dda68c4c-b953-46e0-9214-b36aad71762d,DISK], DatanodeInfoWithStorage[127.0.0.1:38095,DS-0bf1c485-e466-4852-889c-763b3dedeedb,DISK], DatanodeInfoWithStorage[127.0.0.1:42879,DS-b1a6be62-eeb0-439d-8863-2a593d4d542d,DISK], DatanodeInfoWithStorage[127.0.0.1:38181,DS-426309cf-a2e2-4f27-8d08-6c3fbeb0cb9e,DISK], DatanodeInfoWithStorage[127.0.0.1:34212,DS-3c05d798-f745-4ea6-aec0-639ff4b77c1f,DISK], DatanodeInfoWithStorage[127.0.0.1:34190,DS-0b0bdbeb-449a-453b-9322-49f7adadbee1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-772622883-172.17.0.17-1598329004595:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34649,DS-9aaa080a-edaa-4400-ad87-231428d83104,DISK], DatanodeInfoWithStorage[127.0.0.1:39173,DS-5369ac35-5947-49fa-95d6-9e9eb1d7473a,DISK], DatanodeInfoWithStorage[127.0.0.1:44777,DS-dda68c4c-b953-46e0-9214-b36aad71762d,DISK], DatanodeInfoWithStorage[127.0.0.1:38095,DS-0bf1c485-e466-4852-889c-763b3dedeedb,DISK], DatanodeInfoWithStorage[127.0.0.1:42879,DS-b1a6be62-eeb0-439d-8863-2a593d4d542d,DISK], DatanodeInfoWithStorage[127.0.0.1:38181,DS-426309cf-a2e2-4f27-8d08-6c3fbeb0cb9e,DISK], DatanodeInfoWithStorage[127.0.0.1:34212,DS-3c05d798-f745-4ea6-aec0-639ff4b77c1f,DISK], DatanodeInfoWithStorage[127.0.0.1:34190,DS-0b0bdbeb-449a-453b-9322-49f7adadbee1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1818025775-172.17.0.17-1598329211141:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42887,DS-2096fe34-59b6-4357-a678-50c46d95654c,DISK], DatanodeInfoWithStorage[127.0.0.1:41259,DS-508a3c49-135e-48b8-adac-2606d085abd3,DISK], DatanodeInfoWithStorage[127.0.0.1:42099,DS-c89a55d0-ecee-4695-bcce-b246cc2c8141,DISK], DatanodeInfoWithStorage[127.0.0.1:42153,DS-830dfb82-ff6a-420a-a8a1-ba2bc57a791e,DISK], DatanodeInfoWithStorage[127.0.0.1:45495,DS-eeac98de-c45f-43cf-ae2b-ca13b9268069,DISK], DatanodeInfoWithStorage[127.0.0.1:35166,DS-d3bb8a69-dc18-4ec2-8d32-601c559a2892,DISK], DatanodeInfoWithStorage[127.0.0.1:43236,DS-441feb10-e159-4c3c-a22b-e4df9f5d28fe,DISK], DatanodeInfoWithStorage[127.0.0.1:45157,DS-832130fd-6a93-44ca-ba52-a5a06ea99f21,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1818025775-172.17.0.17-1598329211141:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42887,DS-2096fe34-59b6-4357-a678-50c46d95654c,DISK], DatanodeInfoWithStorage[127.0.0.1:41259,DS-508a3c49-135e-48b8-adac-2606d085abd3,DISK], DatanodeInfoWithStorage[127.0.0.1:42099,DS-c89a55d0-ecee-4695-bcce-b246cc2c8141,DISK], DatanodeInfoWithStorage[127.0.0.1:42153,DS-830dfb82-ff6a-420a-a8a1-ba2bc57a791e,DISK], DatanodeInfoWithStorage[127.0.0.1:45495,DS-eeac98de-c45f-43cf-ae2b-ca13b9268069,DISK], DatanodeInfoWithStorage[127.0.0.1:35166,DS-d3bb8a69-dc18-4ec2-8d32-601c559a2892,DISK], DatanodeInfoWithStorage[127.0.0.1:43236,DS-441feb10-e159-4c3c-a22b-e4df9f5d28fe,DISK], DatanodeInfoWithStorage[127.0.0.1:45157,DS-832130fd-6a93-44ca-ba52-a5a06ea99f21,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-673665800-172.17.0.17-1598329472803:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40939,DS-f80b7b3d-1002-4f31-89be-eaea146993b1,DISK], DatanodeInfoWithStorage[127.0.0.1:35818,DS-1b7f226c-435f-472e-97c1-cc62aeadc091,DISK], DatanodeInfoWithStorage[127.0.0.1:43775,DS-280229d5-87eb-437f-8b30-f8f40f34a748,DISK], DatanodeInfoWithStorage[127.0.0.1:46801,DS-f0391e7c-0df3-41dd-80a3-e2b06dce8a1e,DISK], DatanodeInfoWithStorage[127.0.0.1:37446,DS-032cb798-9b03-478a-8530-29a1212e43e6,DISK], DatanodeInfoWithStorage[127.0.0.1:42849,DS-9f429217-aed1-4ed8-a79a-48a170703fcb,DISK], DatanodeInfoWithStorage[127.0.0.1:44799,DS-97cdd425-37f6-4dde-9404-bbf392007b49,DISK], DatanodeInfoWithStorage[127.0.0.1:45633,DS-cd213da8-2b94-4bc4-bdbc-1f8eebff4b45,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-673665800-172.17.0.17-1598329472803:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40939,DS-f80b7b3d-1002-4f31-89be-eaea146993b1,DISK], DatanodeInfoWithStorage[127.0.0.1:35818,DS-1b7f226c-435f-472e-97c1-cc62aeadc091,DISK], DatanodeInfoWithStorage[127.0.0.1:43775,DS-280229d5-87eb-437f-8b30-f8f40f34a748,DISK], DatanodeInfoWithStorage[127.0.0.1:46801,DS-f0391e7c-0df3-41dd-80a3-e2b06dce8a1e,DISK], DatanodeInfoWithStorage[127.0.0.1:37446,DS-032cb798-9b03-478a-8530-29a1212e43e6,DISK], DatanodeInfoWithStorage[127.0.0.1:42849,DS-9f429217-aed1-4ed8-a79a-48a170703fcb,DISK], DatanodeInfoWithStorage[127.0.0.1:44799,DS-97cdd425-37f6-4dde-9404-bbf392007b49,DISK], DatanodeInfoWithStorage[127.0.0.1:45633,DS-cd213da8-2b94-4bc4-bdbc-1f8eebff4b45,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1759495428-172.17.0.17-1598330058146:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41934,DS-a485c73f-288b-4d25-b6f1-4136e43fb945,DISK], DatanodeInfoWithStorage[127.0.0.1:32978,DS-05be7206-1c63-41ee-9e6e-a577ee850d69,DISK], DatanodeInfoWithStorage[127.0.0.1:46601,DS-27b35530-e5d3-4c73-b5fe-3b316d73133a,DISK], DatanodeInfoWithStorage[127.0.0.1:43787,DS-9b2ec771-de82-4404-bb46-e08f6fa593de,DISK], DatanodeInfoWithStorage[127.0.0.1:46267,DS-f2d5ec5a-7dff-43b2-ae7f-f34daf0a07c2,DISK], DatanodeInfoWithStorage[127.0.0.1:45061,DS-98f1a8f9-6a04-43df-a387-ad8540395a84,DISK], DatanodeInfoWithStorage[127.0.0.1:38766,DS-d2b8e7a6-cf64-4f8f-9d24-3210be58a3a9,DISK], DatanodeInfoWithStorage[127.0.0.1:45704,DS-056c8d8b-7069-4ade-bc20-0771180c0d35,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1759495428-172.17.0.17-1598330058146:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41934,DS-a485c73f-288b-4d25-b6f1-4136e43fb945,DISK], DatanodeInfoWithStorage[127.0.0.1:32978,DS-05be7206-1c63-41ee-9e6e-a577ee850d69,DISK], DatanodeInfoWithStorage[127.0.0.1:46601,DS-27b35530-e5d3-4c73-b5fe-3b316d73133a,DISK], DatanodeInfoWithStorage[127.0.0.1:43787,DS-9b2ec771-de82-4404-bb46-e08f6fa593de,DISK], DatanodeInfoWithStorage[127.0.0.1:46267,DS-f2d5ec5a-7dff-43b2-ae7f-f34daf0a07c2,DISK], DatanodeInfoWithStorage[127.0.0.1:45061,DS-98f1a8f9-6a04-43df-a387-ad8540395a84,DISK], DatanodeInfoWithStorage[127.0.0.1:38766,DS-d2b8e7a6-cf64-4f8f-9d24-3210be58a3a9,DISK], DatanodeInfoWithStorage[127.0.0.1:45704,DS-056c8d8b-7069-4ade-bc20-0771180c0d35,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-807560059-172.17.0.17-1598330097141:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41421,DS-28f5c14a-4a88-4950-8f8a-1a5ea3bf366b,DISK], DatanodeInfoWithStorage[127.0.0.1:33118,DS-926af731-ea03-41bc-9026-075b5d84bb21,DISK], DatanodeInfoWithStorage[127.0.0.1:46725,DS-7d28ce21-d763-4377-98c1-41c3f04b7f5b,DISK], DatanodeInfoWithStorage[127.0.0.1:33994,DS-b17410d8-75ad-4dea-b464-4070c8c71899,DISK], DatanodeInfoWithStorage[127.0.0.1:44297,DS-6efa86bd-ec9f-4b39-9ab1-4680ae6c789a,DISK], DatanodeInfoWithStorage[127.0.0.1:46247,DS-14cfe117-0c65-404e-bcf3-ad7e21a699d2,DISK], DatanodeInfoWithStorage[127.0.0.1:38157,DS-20602c58-fc80-4a71-a370-05c6faa31e63,DISK], DatanodeInfoWithStorage[127.0.0.1:43018,DS-b21b358b-fe89-4a2d-b4f2-10e18fb44209,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-807560059-172.17.0.17-1598330097141:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41421,DS-28f5c14a-4a88-4950-8f8a-1a5ea3bf366b,DISK], DatanodeInfoWithStorage[127.0.0.1:33118,DS-926af731-ea03-41bc-9026-075b5d84bb21,DISK], DatanodeInfoWithStorage[127.0.0.1:46725,DS-7d28ce21-d763-4377-98c1-41c3f04b7f5b,DISK], DatanodeInfoWithStorage[127.0.0.1:33994,DS-b17410d8-75ad-4dea-b464-4070c8c71899,DISK], DatanodeInfoWithStorage[127.0.0.1:44297,DS-6efa86bd-ec9f-4b39-9ab1-4680ae6c789a,DISK], DatanodeInfoWithStorage[127.0.0.1:46247,DS-14cfe117-0c65-404e-bcf3-ad7e21a699d2,DISK], DatanodeInfoWithStorage[127.0.0.1:38157,DS-20602c58-fc80-4a71-a370-05c6faa31e63,DISK], DatanodeInfoWithStorage[127.0.0.1:43018,DS-b21b358b-fe89-4a2d-b4f2-10e18fb44209,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 5696
