reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-91855344-172.17.0.2-1598162393226:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46456,DS-20ad1c30-1b86-4d85-9b7f-dfaf29e6b172,DISK], DatanodeInfoWithStorage[127.0.0.1:40217,DS-e51ace78-57e2-41af-8494-b111743ff5b1,DISK], DatanodeInfoWithStorage[127.0.0.1:37675,DS-997143e4-63ba-42a1-a1b1-9569b216db5d,DISK], DatanodeInfoWithStorage[127.0.0.1:45349,DS-d841931d-b62d-49e5-b704-96e5f5c5b63f,DISK], DatanodeInfoWithStorage[127.0.0.1:35625,DS-cdba8a22-dc1c-4145-82c9-38acfd03602a,DISK], DatanodeInfoWithStorage[127.0.0.1:43407,DS-466eb438-7b0b-4582-9ca6-5d123d5a47f4,DISK], DatanodeInfoWithStorage[127.0.0.1:36362,DS-462e2cc2-6405-4d43-9939-146fb3f24326,DISK], DatanodeInfoWithStorage[127.0.0.1:44229,DS-fa801c1c-86df-48e6-bccd-c7fdb0d9fe3c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-91855344-172.17.0.2-1598162393226:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46456,DS-20ad1c30-1b86-4d85-9b7f-dfaf29e6b172,DISK], DatanodeInfoWithStorage[127.0.0.1:40217,DS-e51ace78-57e2-41af-8494-b111743ff5b1,DISK], DatanodeInfoWithStorage[127.0.0.1:37675,DS-997143e4-63ba-42a1-a1b1-9569b216db5d,DISK], DatanodeInfoWithStorage[127.0.0.1:45349,DS-d841931d-b62d-49e5-b704-96e5f5c5b63f,DISK], DatanodeInfoWithStorage[127.0.0.1:35625,DS-cdba8a22-dc1c-4145-82c9-38acfd03602a,DISK], DatanodeInfoWithStorage[127.0.0.1:43407,DS-466eb438-7b0b-4582-9ca6-5d123d5a47f4,DISK], DatanodeInfoWithStorage[127.0.0.1:36362,DS-462e2cc2-6405-4d43-9939-146fb3f24326,DISK], DatanodeInfoWithStorage[127.0.0.1:44229,DS-fa801c1c-86df-48e6-bccd-c7fdb0d9fe3c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1931446776-172.17.0.2-1598163012527:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40110,DS-cee450f3-0b98-4773-a8f8-329cab250592,DISK], DatanodeInfoWithStorage[127.0.0.1:37271,DS-a1e0576d-fdea-45d4-9952-6e9562423513,DISK], DatanodeInfoWithStorage[127.0.0.1:44826,DS-4e325064-c554-45da-b612-9c83830e7de6,DISK], DatanodeInfoWithStorage[127.0.0.1:34672,DS-5465db66-d54b-4a00-a9e5-9f38448cbecd,DISK], DatanodeInfoWithStorage[127.0.0.1:44491,DS-28568a22-5ea0-4a8a-a9f4-cd3a63a6c2fe,DISK], DatanodeInfoWithStorage[127.0.0.1:45316,DS-0e6f7c4e-6d8f-407e-aed0-275a81859013,DISK], DatanodeInfoWithStorage[127.0.0.1:34091,DS-cff33aeb-4431-4294-91f3-6d9feeb95fe4,DISK], DatanodeInfoWithStorage[127.0.0.1:35624,DS-e042e1ee-b964-4316-8b25-c673b89f0e0f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1931446776-172.17.0.2-1598163012527:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40110,DS-cee450f3-0b98-4773-a8f8-329cab250592,DISK], DatanodeInfoWithStorage[127.0.0.1:37271,DS-a1e0576d-fdea-45d4-9952-6e9562423513,DISK], DatanodeInfoWithStorage[127.0.0.1:44826,DS-4e325064-c554-45da-b612-9c83830e7de6,DISK], DatanodeInfoWithStorage[127.0.0.1:34672,DS-5465db66-d54b-4a00-a9e5-9f38448cbecd,DISK], DatanodeInfoWithStorage[127.0.0.1:44491,DS-28568a22-5ea0-4a8a-a9f4-cd3a63a6c2fe,DISK], DatanodeInfoWithStorage[127.0.0.1:45316,DS-0e6f7c4e-6d8f-407e-aed0-275a81859013,DISK], DatanodeInfoWithStorage[127.0.0.1:34091,DS-cff33aeb-4431-4294-91f3-6d9feeb95fe4,DISK], DatanodeInfoWithStorage[127.0.0.1:35624,DS-e042e1ee-b964-4316-8b25-c673b89f0e0f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1837232713-172.17.0.2-1598163106333:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34038,DS-a4d5b20e-bf0c-4f20-9980-ba8b52812f15,DISK], DatanodeInfoWithStorage[127.0.0.1:42152,DS-26c85d44-430f-4ab9-8742-a59766db22e7,DISK], DatanodeInfoWithStorage[127.0.0.1:32778,DS-4f60b163-9c5f-4d84-b14c-9d42ef16981e,DISK], DatanodeInfoWithStorage[127.0.0.1:42725,DS-e3bebe3b-230f-4b76-a09f-fb3c2f362901,DISK], DatanodeInfoWithStorage[127.0.0.1:38214,DS-905ac4cb-1d9a-44dd-b429-60b81ca7d95c,DISK], DatanodeInfoWithStorage[127.0.0.1:35922,DS-248d9e2e-588d-4f1f-8e51-f6420e3d397e,DISK], DatanodeInfoWithStorage[127.0.0.1:44825,DS-c0700e58-5ad1-4f3c-9ab2-bef2e7d5aa05,DISK], DatanodeInfoWithStorage[127.0.0.1:39272,DS-ed32c7d5-713c-4220-800c-c8fb9bb67850,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1837232713-172.17.0.2-1598163106333:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34038,DS-a4d5b20e-bf0c-4f20-9980-ba8b52812f15,DISK], DatanodeInfoWithStorage[127.0.0.1:42152,DS-26c85d44-430f-4ab9-8742-a59766db22e7,DISK], DatanodeInfoWithStorage[127.0.0.1:32778,DS-4f60b163-9c5f-4d84-b14c-9d42ef16981e,DISK], DatanodeInfoWithStorage[127.0.0.1:42725,DS-e3bebe3b-230f-4b76-a09f-fb3c2f362901,DISK], DatanodeInfoWithStorage[127.0.0.1:38214,DS-905ac4cb-1d9a-44dd-b429-60b81ca7d95c,DISK], DatanodeInfoWithStorage[127.0.0.1:35922,DS-248d9e2e-588d-4f1f-8e51-f6420e3d397e,DISK], DatanodeInfoWithStorage[127.0.0.1:44825,DS-c0700e58-5ad1-4f3c-9ab2-bef2e7d5aa05,DISK], DatanodeInfoWithStorage[127.0.0.1:39272,DS-ed32c7d5-713c-4220-800c-c8fb9bb67850,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-999741691-172.17.0.2-1598163516702:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43962,DS-773fca21-4dbb-4476-be51-9b6f55a62ade,DISK], DatanodeInfoWithStorage[127.0.0.1:39743,DS-3bcff36a-75d6-4e96-82a1-e7fc2eaeb926,DISK], DatanodeInfoWithStorage[127.0.0.1:38921,DS-cf9c0ce2-8fe6-46bb-a5f2-d21cfedf31b9,DISK], DatanodeInfoWithStorage[127.0.0.1:33905,DS-a4531953-7a4d-45c5-8c5e-fda354a0affc,DISK], DatanodeInfoWithStorage[127.0.0.1:37359,DS-8995aa3c-ae24-4af4-a384-229472bea430,DISK], DatanodeInfoWithStorage[127.0.0.1:36177,DS-96fa85c9-4af7-46a3-858e-246bba7de7b4,DISK], DatanodeInfoWithStorage[127.0.0.1:39163,DS-663a1bea-a64a-4b0a-af28-336075be6454,DISK], DatanodeInfoWithStorage[127.0.0.1:45851,DS-eec256be-9974-4cd9-a65e-641131fdecce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-999741691-172.17.0.2-1598163516702:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43962,DS-773fca21-4dbb-4476-be51-9b6f55a62ade,DISK], DatanodeInfoWithStorage[127.0.0.1:39743,DS-3bcff36a-75d6-4e96-82a1-e7fc2eaeb926,DISK], DatanodeInfoWithStorage[127.0.0.1:38921,DS-cf9c0ce2-8fe6-46bb-a5f2-d21cfedf31b9,DISK], DatanodeInfoWithStorage[127.0.0.1:33905,DS-a4531953-7a4d-45c5-8c5e-fda354a0affc,DISK], DatanodeInfoWithStorage[127.0.0.1:37359,DS-8995aa3c-ae24-4af4-a384-229472bea430,DISK], DatanodeInfoWithStorage[127.0.0.1:36177,DS-96fa85c9-4af7-46a3-858e-246bba7de7b4,DISK], DatanodeInfoWithStorage[127.0.0.1:39163,DS-663a1bea-a64a-4b0a-af28-336075be6454,DISK], DatanodeInfoWithStorage[127.0.0.1:45851,DS-eec256be-9974-4cd9-a65e-641131fdecce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-218464848-172.17.0.2-1598163554460:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43334,DS-96603db3-1e54-4e26-a565-a80c6424b745,DISK], DatanodeInfoWithStorage[127.0.0.1:39467,DS-cff0a994-289a-47b1-885a-40f95dc6942e,DISK], DatanodeInfoWithStorage[127.0.0.1:41588,DS-038e6eb1-4111-4d18-9ba4-056d2d0f8581,DISK], DatanodeInfoWithStorage[127.0.0.1:33609,DS-9a83e6ee-411d-45a8-87e4-1fad22e2af72,DISK], DatanodeInfoWithStorage[127.0.0.1:34188,DS-7920a161-b3a5-4d57-a58f-4d3af700fc3c,DISK], DatanodeInfoWithStorage[127.0.0.1:34745,DS-d66591fe-5ddd-4728-828a-add6a6fef184,DISK], DatanodeInfoWithStorage[127.0.0.1:40307,DS-1edc49f1-68c2-4839-946f-108dacc0aabe,DISK], DatanodeInfoWithStorage[127.0.0.1:38751,DS-4b94aa68-dd00-4ebd-b932-92a3bc4b8113,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-218464848-172.17.0.2-1598163554460:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43334,DS-96603db3-1e54-4e26-a565-a80c6424b745,DISK], DatanodeInfoWithStorage[127.0.0.1:39467,DS-cff0a994-289a-47b1-885a-40f95dc6942e,DISK], DatanodeInfoWithStorage[127.0.0.1:41588,DS-038e6eb1-4111-4d18-9ba4-056d2d0f8581,DISK], DatanodeInfoWithStorage[127.0.0.1:33609,DS-9a83e6ee-411d-45a8-87e4-1fad22e2af72,DISK], DatanodeInfoWithStorage[127.0.0.1:34188,DS-7920a161-b3a5-4d57-a58f-4d3af700fc3c,DISK], DatanodeInfoWithStorage[127.0.0.1:34745,DS-d66591fe-5ddd-4728-828a-add6a6fef184,DISK], DatanodeInfoWithStorage[127.0.0.1:40307,DS-1edc49f1-68c2-4839-946f-108dacc0aabe,DISK], DatanodeInfoWithStorage[127.0.0.1:38751,DS-4b94aa68-dd00-4ebd-b932-92a3bc4b8113,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1289702244-172.17.0.2-1598163698527:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37508,DS-cf9e5656-9ce0-4336-b053-29f8400fbbc3,DISK], DatanodeInfoWithStorage[127.0.0.1:42658,DS-6ae32995-57d9-4496-9101-e4a8fbd7246d,DISK], DatanodeInfoWithStorage[127.0.0.1:42057,DS-a2d1e1c4-3a68-4be5-928d-329a0b88c552,DISK], DatanodeInfoWithStorage[127.0.0.1:35062,DS-d23b18b3-f762-4a9e-8817-23b507b8d50c,DISK], DatanodeInfoWithStorage[127.0.0.1:34084,DS-aa54a95f-7221-4095-8239-cb00be592238,DISK], DatanodeInfoWithStorage[127.0.0.1:39399,DS-4d557a16-ac18-44de-ab84-f1699c43ddd0,DISK], DatanodeInfoWithStorage[127.0.0.1:36853,DS-b1058044-208b-4c0c-aaff-45a0e28953b1,DISK], DatanodeInfoWithStorage[127.0.0.1:34475,DS-fc87add7-9b00-4c6f-8564-76491be0dedc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1289702244-172.17.0.2-1598163698527:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37508,DS-cf9e5656-9ce0-4336-b053-29f8400fbbc3,DISK], DatanodeInfoWithStorage[127.0.0.1:42658,DS-6ae32995-57d9-4496-9101-e4a8fbd7246d,DISK], DatanodeInfoWithStorage[127.0.0.1:42057,DS-a2d1e1c4-3a68-4be5-928d-329a0b88c552,DISK], DatanodeInfoWithStorage[127.0.0.1:35062,DS-d23b18b3-f762-4a9e-8817-23b507b8d50c,DISK], DatanodeInfoWithStorage[127.0.0.1:34084,DS-aa54a95f-7221-4095-8239-cb00be592238,DISK], DatanodeInfoWithStorage[127.0.0.1:39399,DS-4d557a16-ac18-44de-ab84-f1699c43ddd0,DISK], DatanodeInfoWithStorage[127.0.0.1:36853,DS-b1058044-208b-4c0c-aaff-45a0e28953b1,DISK], DatanodeInfoWithStorage[127.0.0.1:34475,DS-fc87add7-9b00-4c6f-8564-76491be0dedc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-12627667-172.17.0.2-1598163978958:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39010,DS-c83d6ef5-7ad1-40eb-93c5-7943353c40c6,DISK], DatanodeInfoWithStorage[127.0.0.1:34221,DS-4756b24b-105f-4ab0-a5b2-2e5229e73bea,DISK], DatanodeInfoWithStorage[127.0.0.1:37076,DS-896262eb-41e2-4614-ac77-1c3543fb759b,DISK], DatanodeInfoWithStorage[127.0.0.1:37935,DS-27a1222e-4d98-4b76-aded-21a37edb2661,DISK], DatanodeInfoWithStorage[127.0.0.1:36032,DS-88166e25-ffac-4426-a85a-10b9b0ffd317,DISK], DatanodeInfoWithStorage[127.0.0.1:38066,DS-22ba46e6-a55b-4896-b4f5-dac293329d58,DISK], DatanodeInfoWithStorage[127.0.0.1:34223,DS-3eee186a-88d0-4f2e-b386-7db2624a0d5d,DISK], DatanodeInfoWithStorage[127.0.0.1:33231,DS-c700cb14-3766-4aa1-8cb4-864b74e76e6a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-12627667-172.17.0.2-1598163978958:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39010,DS-c83d6ef5-7ad1-40eb-93c5-7943353c40c6,DISK], DatanodeInfoWithStorage[127.0.0.1:34221,DS-4756b24b-105f-4ab0-a5b2-2e5229e73bea,DISK], DatanodeInfoWithStorage[127.0.0.1:37076,DS-896262eb-41e2-4614-ac77-1c3543fb759b,DISK], DatanodeInfoWithStorage[127.0.0.1:37935,DS-27a1222e-4d98-4b76-aded-21a37edb2661,DISK], DatanodeInfoWithStorage[127.0.0.1:36032,DS-88166e25-ffac-4426-a85a-10b9b0ffd317,DISK], DatanodeInfoWithStorage[127.0.0.1:38066,DS-22ba46e6-a55b-4896-b4f5-dac293329d58,DISK], DatanodeInfoWithStorage[127.0.0.1:34223,DS-3eee186a-88d0-4f2e-b386-7db2624a0d5d,DISK], DatanodeInfoWithStorage[127.0.0.1:33231,DS-c700cb14-3766-4aa1-8cb4-864b74e76e6a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1840113598-172.17.0.2-1598164292608:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36302,DS-f9573830-3fd2-4459-ad5c-1b1fcdb37e36,DISK], DatanodeInfoWithStorage[127.0.0.1:33566,DS-4d24a12a-6ed0-488f-a972-d6df809ec600,DISK], DatanodeInfoWithStorage[127.0.0.1:42463,DS-4d606d48-d78b-4f3a-811c-21cc08ff2ebd,DISK], DatanodeInfoWithStorage[127.0.0.1:34775,DS-6a271dd7-4375-49ad-868a-001d02bb08fc,DISK], DatanodeInfoWithStorage[127.0.0.1:40423,DS-5c273f6b-ae94-4f2c-b0d7-45bb5fe40ae1,DISK], DatanodeInfoWithStorage[127.0.0.1:39678,DS-46063546-cd39-40b9-8fae-005b6fc76d57,DISK], DatanodeInfoWithStorage[127.0.0.1:46486,DS-41fbccc4-98c9-413b-8861-02c3f3251df3,DISK], DatanodeInfoWithStorage[127.0.0.1:46831,DS-17299afc-dd27-494a-acd5-da4a122bcc1b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1840113598-172.17.0.2-1598164292608:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36302,DS-f9573830-3fd2-4459-ad5c-1b1fcdb37e36,DISK], DatanodeInfoWithStorage[127.0.0.1:33566,DS-4d24a12a-6ed0-488f-a972-d6df809ec600,DISK], DatanodeInfoWithStorage[127.0.0.1:42463,DS-4d606d48-d78b-4f3a-811c-21cc08ff2ebd,DISK], DatanodeInfoWithStorage[127.0.0.1:34775,DS-6a271dd7-4375-49ad-868a-001d02bb08fc,DISK], DatanodeInfoWithStorage[127.0.0.1:40423,DS-5c273f6b-ae94-4f2c-b0d7-45bb5fe40ae1,DISK], DatanodeInfoWithStorage[127.0.0.1:39678,DS-46063546-cd39-40b9-8fae-005b6fc76d57,DISK], DatanodeInfoWithStorage[127.0.0.1:46486,DS-41fbccc4-98c9-413b-8861-02c3f3251df3,DISK], DatanodeInfoWithStorage[127.0.0.1:46831,DS-17299afc-dd27-494a-acd5-da4a122bcc1b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-891376647-172.17.0.2-1598164618154:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43081,DS-8ab90610-1010-4151-b7d7-09a7fef739f8,DISK], DatanodeInfoWithStorage[127.0.0.1:45500,DS-f0d4ceff-8189-4d14-ba5b-16779f591b4d,DISK], DatanodeInfoWithStorage[127.0.0.1:33759,DS-cb1d1147-7ba2-400d-9907-4b7f8979cf23,DISK], DatanodeInfoWithStorage[127.0.0.1:43034,DS-2a66407d-381d-4a1c-ae72-6ef96da96e95,DISK], DatanodeInfoWithStorage[127.0.0.1:36724,DS-e415ac27-6898-4dfb-bd3f-e243737b2759,DISK], DatanodeInfoWithStorage[127.0.0.1:43899,DS-b3289d43-2a7a-4f48-a146-774e8fd18fb3,DISK], DatanodeInfoWithStorage[127.0.0.1:42576,DS-f633898e-8133-4a56-bc3a-59d618d693df,DISK], DatanodeInfoWithStorage[127.0.0.1:34874,DS-93bec1c6-467d-4da4-b339-4394507542a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-891376647-172.17.0.2-1598164618154:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43081,DS-8ab90610-1010-4151-b7d7-09a7fef739f8,DISK], DatanodeInfoWithStorage[127.0.0.1:45500,DS-f0d4ceff-8189-4d14-ba5b-16779f591b4d,DISK], DatanodeInfoWithStorage[127.0.0.1:33759,DS-cb1d1147-7ba2-400d-9907-4b7f8979cf23,DISK], DatanodeInfoWithStorage[127.0.0.1:43034,DS-2a66407d-381d-4a1c-ae72-6ef96da96e95,DISK], DatanodeInfoWithStorage[127.0.0.1:36724,DS-e415ac27-6898-4dfb-bd3f-e243737b2759,DISK], DatanodeInfoWithStorage[127.0.0.1:43899,DS-b3289d43-2a7a-4f48-a146-774e8fd18fb3,DISK], DatanodeInfoWithStorage[127.0.0.1:42576,DS-f633898e-8133-4a56-bc3a-59d618d693df,DISK], DatanodeInfoWithStorage[127.0.0.1:34874,DS-93bec1c6-467d-4da4-b339-4394507542a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1067813947-172.17.0.2-1598164854287:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45663,DS-e9ba01ca-20be-4c3a-9c8a-514a2fb6bf2f,DISK], DatanodeInfoWithStorage[127.0.0.1:40267,DS-7257bcaa-9c7a-49ee-8b72-1daedb0e637f,DISK], DatanodeInfoWithStorage[127.0.0.1:44518,DS-6e5121cc-e1d7-40d1-aaeb-402a7605e73b,DISK], DatanodeInfoWithStorage[127.0.0.1:38118,DS-c37c999c-521a-4960-8332-dec1ae3bac5c,DISK], DatanodeInfoWithStorage[127.0.0.1:37513,DS-cc5a3efc-b8c0-421a-9b5d-13c4c7aa4ec0,DISK], DatanodeInfoWithStorage[127.0.0.1:40190,DS-8a995264-b526-484f-80f0-d425c916bd37,DISK], DatanodeInfoWithStorage[127.0.0.1:35698,DS-5e7accd7-db30-47e2-b738-36246effd9e0,DISK], DatanodeInfoWithStorage[127.0.0.1:40743,DS-2f9cec54-429e-492e-99cd-4026608d6fea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1067813947-172.17.0.2-1598164854287:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45663,DS-e9ba01ca-20be-4c3a-9c8a-514a2fb6bf2f,DISK], DatanodeInfoWithStorage[127.0.0.1:40267,DS-7257bcaa-9c7a-49ee-8b72-1daedb0e637f,DISK], DatanodeInfoWithStorage[127.0.0.1:44518,DS-6e5121cc-e1d7-40d1-aaeb-402a7605e73b,DISK], DatanodeInfoWithStorage[127.0.0.1:38118,DS-c37c999c-521a-4960-8332-dec1ae3bac5c,DISK], DatanodeInfoWithStorage[127.0.0.1:37513,DS-cc5a3efc-b8c0-421a-9b5d-13c4c7aa4ec0,DISK], DatanodeInfoWithStorage[127.0.0.1:40190,DS-8a995264-b526-484f-80f0-d425c916bd37,DISK], DatanodeInfoWithStorage[127.0.0.1:35698,DS-5e7accd7-db30-47e2-b738-36246effd9e0,DISK], DatanodeInfoWithStorage[127.0.0.1:40743,DS-2f9cec54-429e-492e-99cd-4026608d6fea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-785620273-172.17.0.2-1598165308473:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37320,DS-b8cbd9a2-ef3b-4173-b739-4f97ddf1267c,DISK], DatanodeInfoWithStorage[127.0.0.1:42402,DS-9ddf6183-e589-4885-9cfa-7bbc3895a486,DISK], DatanodeInfoWithStorage[127.0.0.1:39653,DS-4d3d70f5-3f5d-47d7-99d2-edd44e5a9a82,DISK], DatanodeInfoWithStorage[127.0.0.1:45757,DS-cc4be8d0-9271-4a47-b106-755cbce4d69c,DISK], DatanodeInfoWithStorage[127.0.0.1:34419,DS-f9eac8a6-9537-44bf-b19f-7ac48d4758c3,DISK], DatanodeInfoWithStorage[127.0.0.1:38334,DS-89f756af-77ba-49f1-abcc-e342b04a543c,DISK], DatanodeInfoWithStorage[127.0.0.1:37074,DS-39230e3b-f90a-49a1-a125-02d989ffcc52,DISK], DatanodeInfoWithStorage[127.0.0.1:33167,DS-780e6a60-0fad-49ca-b750-6f2aef45a02d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-785620273-172.17.0.2-1598165308473:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37320,DS-b8cbd9a2-ef3b-4173-b739-4f97ddf1267c,DISK], DatanodeInfoWithStorage[127.0.0.1:42402,DS-9ddf6183-e589-4885-9cfa-7bbc3895a486,DISK], DatanodeInfoWithStorage[127.0.0.1:39653,DS-4d3d70f5-3f5d-47d7-99d2-edd44e5a9a82,DISK], DatanodeInfoWithStorage[127.0.0.1:45757,DS-cc4be8d0-9271-4a47-b106-755cbce4d69c,DISK], DatanodeInfoWithStorage[127.0.0.1:34419,DS-f9eac8a6-9537-44bf-b19f-7ac48d4758c3,DISK], DatanodeInfoWithStorage[127.0.0.1:38334,DS-89f756af-77ba-49f1-abcc-e342b04a543c,DISK], DatanodeInfoWithStorage[127.0.0.1:37074,DS-39230e3b-f90a-49a1-a125-02d989ffcc52,DISK], DatanodeInfoWithStorage[127.0.0.1:33167,DS-780e6a60-0fad-49ca-b750-6f2aef45a02d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-884136309-172.17.0.2-1598165377975:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35713,DS-088bc680-9d55-40a1-ae2b-44480b995d90,DISK], DatanodeInfoWithStorage[127.0.0.1:46872,DS-ddc3eb26-599d-4941-86a9-081195c9c947,DISK], DatanodeInfoWithStorage[127.0.0.1:44033,DS-ed89f9cb-b7e7-4774-81a5-dfc6220724e8,DISK], DatanodeInfoWithStorage[127.0.0.1:40697,DS-805d41a4-7e30-404b-a0be-25340b566a79,DISK], DatanodeInfoWithStorage[127.0.0.1:45217,DS-39dc5e3e-2ef1-4c0c-b494-e806042c4bf9,DISK], DatanodeInfoWithStorage[127.0.0.1:38527,DS-6c0405fe-3235-415e-ae04-12402df766ac,DISK], DatanodeInfoWithStorage[127.0.0.1:42891,DS-e38ebf36-7337-4c59-98d0-cbc554ffef81,DISK], DatanodeInfoWithStorage[127.0.0.1:36980,DS-8e6713db-009b-4ba3-8014-afe3d06cc626,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-884136309-172.17.0.2-1598165377975:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35713,DS-088bc680-9d55-40a1-ae2b-44480b995d90,DISK], DatanodeInfoWithStorage[127.0.0.1:46872,DS-ddc3eb26-599d-4941-86a9-081195c9c947,DISK], DatanodeInfoWithStorage[127.0.0.1:44033,DS-ed89f9cb-b7e7-4774-81a5-dfc6220724e8,DISK], DatanodeInfoWithStorage[127.0.0.1:40697,DS-805d41a4-7e30-404b-a0be-25340b566a79,DISK], DatanodeInfoWithStorage[127.0.0.1:45217,DS-39dc5e3e-2ef1-4c0c-b494-e806042c4bf9,DISK], DatanodeInfoWithStorage[127.0.0.1:38527,DS-6c0405fe-3235-415e-ae04-12402df766ac,DISK], DatanodeInfoWithStorage[127.0.0.1:42891,DS-e38ebf36-7337-4c59-98d0-cbc554ffef81,DISK], DatanodeInfoWithStorage[127.0.0.1:36980,DS-8e6713db-009b-4ba3-8014-afe3d06cc626,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1074473727-172.17.0.2-1598165679473:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45671,DS-8c780e16-2ab8-46d0-8cac-c82e952e6bb6,DISK], DatanodeInfoWithStorage[127.0.0.1:46594,DS-749d8228-ff33-421f-8e76-42251a21af87,DISK], DatanodeInfoWithStorage[127.0.0.1:33154,DS-2323fd99-829d-4323-9843-830550c549f2,DISK], DatanodeInfoWithStorage[127.0.0.1:38275,DS-6c7c2687-9576-4f3d-a496-063c451d3d39,DISK], DatanodeInfoWithStorage[127.0.0.1:36433,DS-ef9b185d-49b1-46ab-952a-5af2a7e0c968,DISK], DatanodeInfoWithStorage[127.0.0.1:33636,DS-49312ba3-79d0-4323-bc0b-40e89b467c40,DISK], DatanodeInfoWithStorage[127.0.0.1:38212,DS-8c77cd85-3a38-416d-95df-ff981f31b641,DISK], DatanodeInfoWithStorage[127.0.0.1:40318,DS-2942a38b-172f-4224-b985-372336bafebc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1074473727-172.17.0.2-1598165679473:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45671,DS-8c780e16-2ab8-46d0-8cac-c82e952e6bb6,DISK], DatanodeInfoWithStorage[127.0.0.1:46594,DS-749d8228-ff33-421f-8e76-42251a21af87,DISK], DatanodeInfoWithStorage[127.0.0.1:33154,DS-2323fd99-829d-4323-9843-830550c549f2,DISK], DatanodeInfoWithStorage[127.0.0.1:38275,DS-6c7c2687-9576-4f3d-a496-063c451d3d39,DISK], DatanodeInfoWithStorage[127.0.0.1:36433,DS-ef9b185d-49b1-46ab-952a-5af2a7e0c968,DISK], DatanodeInfoWithStorage[127.0.0.1:33636,DS-49312ba3-79d0-4323-bc0b-40e89b467c40,DISK], DatanodeInfoWithStorage[127.0.0.1:38212,DS-8c77cd85-3a38-416d-95df-ff981f31b641,DISK], DatanodeInfoWithStorage[127.0.0.1:40318,DS-2942a38b-172f-4224-b985-372336bafebc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1911938512-172.17.0.2-1598165757857:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33288,DS-4d5c5a1a-b6bc-499c-9f08-5d2356f12d46,DISK], DatanodeInfoWithStorage[127.0.0.1:44159,DS-e2d37273-94fc-48ec-acc8-0052e142e2b8,DISK], DatanodeInfoWithStorage[127.0.0.1:42712,DS-e9c3686f-09fc-442e-a54f-69da639412a2,DISK], DatanodeInfoWithStorage[127.0.0.1:41564,DS-644d7765-88e5-4727-8dcf-10d6fd6bb4f6,DISK], DatanodeInfoWithStorage[127.0.0.1:35268,DS-1775e738-6ec7-44bb-b332-9240a827b824,DISK], DatanodeInfoWithStorage[127.0.0.1:43720,DS-aa8f68d3-a4b0-4a46-8962-d9b30a616bdc,DISK], DatanodeInfoWithStorage[127.0.0.1:43016,DS-98158bc7-a935-40c0-bc49-f2fd89dfafea,DISK], DatanodeInfoWithStorage[127.0.0.1:42475,DS-e84f4215-a367-4a12-a587-d9df4712bb05,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1911938512-172.17.0.2-1598165757857:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33288,DS-4d5c5a1a-b6bc-499c-9f08-5d2356f12d46,DISK], DatanodeInfoWithStorage[127.0.0.1:44159,DS-e2d37273-94fc-48ec-acc8-0052e142e2b8,DISK], DatanodeInfoWithStorage[127.0.0.1:42712,DS-e9c3686f-09fc-442e-a54f-69da639412a2,DISK], DatanodeInfoWithStorage[127.0.0.1:41564,DS-644d7765-88e5-4727-8dcf-10d6fd6bb4f6,DISK], DatanodeInfoWithStorage[127.0.0.1:35268,DS-1775e738-6ec7-44bb-b332-9240a827b824,DISK], DatanodeInfoWithStorage[127.0.0.1:43720,DS-aa8f68d3-a4b0-4a46-8962-d9b30a616bdc,DISK], DatanodeInfoWithStorage[127.0.0.1:43016,DS-98158bc7-a935-40c0-bc49-f2fd89dfafea,DISK], DatanodeInfoWithStorage[127.0.0.1:42475,DS-e84f4215-a367-4a12-a587-d9df4712bb05,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1149834770-172.17.0.2-1598165840380:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38955,DS-368536c8-5985-446d-931f-1a788c36e95a,DISK], DatanodeInfoWithStorage[127.0.0.1:35135,DS-bcbd8c41-fd3f-4950-8fc0-95c9e9907dda,DISK], DatanodeInfoWithStorage[127.0.0.1:35894,DS-01e13b49-a7a6-400b-982b-0d1dae199b1b,DISK], DatanodeInfoWithStorage[127.0.0.1:46809,DS-089b5ec9-7f3f-44f2-a25a-5e53947b1c8b,DISK], DatanodeInfoWithStorage[127.0.0.1:41645,DS-dc832a85-a2f0-41f3-b4a3-7f3cc4ede463,DISK], DatanodeInfoWithStorage[127.0.0.1:33900,DS-075b833c-efd5-42d1-8c2b-a9abbb9449de,DISK], DatanodeInfoWithStorage[127.0.0.1:46295,DS-8484d517-b6c4-49cd-b8a3-824da766492e,DISK], DatanodeInfoWithStorage[127.0.0.1:38546,DS-41e5cb3d-c360-4ba0-8a41-e4efc9a99ecf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1149834770-172.17.0.2-1598165840380:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38955,DS-368536c8-5985-446d-931f-1a788c36e95a,DISK], DatanodeInfoWithStorage[127.0.0.1:35135,DS-bcbd8c41-fd3f-4950-8fc0-95c9e9907dda,DISK], DatanodeInfoWithStorage[127.0.0.1:35894,DS-01e13b49-a7a6-400b-982b-0d1dae199b1b,DISK], DatanodeInfoWithStorage[127.0.0.1:46809,DS-089b5ec9-7f3f-44f2-a25a-5e53947b1c8b,DISK], DatanodeInfoWithStorage[127.0.0.1:41645,DS-dc832a85-a2f0-41f3-b4a3-7f3cc4ede463,DISK], DatanodeInfoWithStorage[127.0.0.1:33900,DS-075b833c-efd5-42d1-8c2b-a9abbb9449de,DISK], DatanodeInfoWithStorage[127.0.0.1:46295,DS-8484d517-b6c4-49cd-b8a3-824da766492e,DISK], DatanodeInfoWithStorage[127.0.0.1:38546,DS-41e5cb3d-c360-4ba0-8a41-e4efc9a99ecf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1696068712-172.17.0.2-1598165951156:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46866,DS-b305acf5-ac83-4756-b4f2-196bd5f271ef,DISK], DatanodeInfoWithStorage[127.0.0.1:34082,DS-552446b4-28d5-4c98-ba13-873c8da7fb8c,DISK], DatanodeInfoWithStorage[127.0.0.1:39403,DS-257f8296-1e2c-4ae8-a49f-cb46a4b6d990,DISK], DatanodeInfoWithStorage[127.0.0.1:35149,DS-a623b1cb-04c6-4c25-b24d-9efbbbb6eef4,DISK], DatanodeInfoWithStorage[127.0.0.1:39225,DS-c93401db-8fd7-4eaf-a887-c2d2b6ad89f9,DISK], DatanodeInfoWithStorage[127.0.0.1:43674,DS-1a19998c-ea5f-4d23-84d3-d4334ec43838,DISK], DatanodeInfoWithStorage[127.0.0.1:46380,DS-73ad8481-f33a-48e0-8e85-876b488aef31,DISK], DatanodeInfoWithStorage[127.0.0.1:44983,DS-02b4f27f-01ac-45b8-b36f-e22a761b967c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1696068712-172.17.0.2-1598165951156:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46866,DS-b305acf5-ac83-4756-b4f2-196bd5f271ef,DISK], DatanodeInfoWithStorage[127.0.0.1:34082,DS-552446b4-28d5-4c98-ba13-873c8da7fb8c,DISK], DatanodeInfoWithStorage[127.0.0.1:39403,DS-257f8296-1e2c-4ae8-a49f-cb46a4b6d990,DISK], DatanodeInfoWithStorage[127.0.0.1:35149,DS-a623b1cb-04c6-4c25-b24d-9efbbbb6eef4,DISK], DatanodeInfoWithStorage[127.0.0.1:39225,DS-c93401db-8fd7-4eaf-a887-c2d2b6ad89f9,DISK], DatanodeInfoWithStorage[127.0.0.1:43674,DS-1a19998c-ea5f-4d23-84d3-d4334ec43838,DISK], DatanodeInfoWithStorage[127.0.0.1:46380,DS-73ad8481-f33a-48e0-8e85-876b488aef31,DISK], DatanodeInfoWithStorage[127.0.0.1:44983,DS-02b4f27f-01ac-45b8-b36f-e22a761b967c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-426281605-172.17.0.2-1598166518329:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39899,DS-67fb74c3-aee3-4821-b626-d802b00bf20c,DISK], DatanodeInfoWithStorage[127.0.0.1:41173,DS-9e30a445-460b-48d0-a3e1-98bbf1d58232,DISK], DatanodeInfoWithStorage[127.0.0.1:43561,DS-7418c3ca-05c2-4465-b623-4a7757eab893,DISK], DatanodeInfoWithStorage[127.0.0.1:43256,DS-25c4b3bd-7624-45c3-8e3f-cae35b89981e,DISK], DatanodeInfoWithStorage[127.0.0.1:38758,DS-c0bc901f-b6c9-48db-b76d-901773cf4723,DISK], DatanodeInfoWithStorage[127.0.0.1:42744,DS-dd412d6c-1401-4ad3-be93-3b6095f5a48a,DISK], DatanodeInfoWithStorage[127.0.0.1:43793,DS-5f1d900a-f20a-4c16-96d5-92a699d43ea3,DISK], DatanodeInfoWithStorage[127.0.0.1:34172,DS-f6c0d4fb-14fd-4a45-b715-7a56a0412b07,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-426281605-172.17.0.2-1598166518329:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39899,DS-67fb74c3-aee3-4821-b626-d802b00bf20c,DISK], DatanodeInfoWithStorage[127.0.0.1:41173,DS-9e30a445-460b-48d0-a3e1-98bbf1d58232,DISK], DatanodeInfoWithStorage[127.0.0.1:43561,DS-7418c3ca-05c2-4465-b623-4a7757eab893,DISK], DatanodeInfoWithStorage[127.0.0.1:43256,DS-25c4b3bd-7624-45c3-8e3f-cae35b89981e,DISK], DatanodeInfoWithStorage[127.0.0.1:38758,DS-c0bc901f-b6c9-48db-b76d-901773cf4723,DISK], DatanodeInfoWithStorage[127.0.0.1:42744,DS-dd412d6c-1401-4ad3-be93-3b6095f5a48a,DISK], DatanodeInfoWithStorage[127.0.0.1:43793,DS-5f1d900a-f20a-4c16-96d5-92a699d43ea3,DISK], DatanodeInfoWithStorage[127.0.0.1:34172,DS-f6c0d4fb-14fd-4a45-b715-7a56a0412b07,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-623673353-172.17.0.2-1598167181476:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45154,DS-3d3ba11a-ef1f-4850-908f-8796cbc73a3b,DISK], DatanodeInfoWithStorage[127.0.0.1:45696,DS-8ae3a6b1-419a-438e-872f-8be683006c7a,DISK], DatanodeInfoWithStorage[127.0.0.1:40759,DS-0027828b-8fca-4534-bf59-183d70482f17,DISK], DatanodeInfoWithStorage[127.0.0.1:44736,DS-64cb4a8b-a8ad-4693-b577-84794768618f,DISK], DatanodeInfoWithStorage[127.0.0.1:38826,DS-15e36f27-4bc3-4d25-acf7-4528d9777cb2,DISK], DatanodeInfoWithStorage[127.0.0.1:42636,DS-ca7e1efe-8dda-4be5-b978-24d3a8c6913f,DISK], DatanodeInfoWithStorage[127.0.0.1:36681,DS-fd5244dd-2152-401d-b4f5-89a8cbbfc8e7,DISK], DatanodeInfoWithStorage[127.0.0.1:37717,DS-c5926741-5928-4b69-96e6-9fec7a574b50,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-623673353-172.17.0.2-1598167181476:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45154,DS-3d3ba11a-ef1f-4850-908f-8796cbc73a3b,DISK], DatanodeInfoWithStorage[127.0.0.1:45696,DS-8ae3a6b1-419a-438e-872f-8be683006c7a,DISK], DatanodeInfoWithStorage[127.0.0.1:40759,DS-0027828b-8fca-4534-bf59-183d70482f17,DISK], DatanodeInfoWithStorage[127.0.0.1:44736,DS-64cb4a8b-a8ad-4693-b577-84794768618f,DISK], DatanodeInfoWithStorage[127.0.0.1:38826,DS-15e36f27-4bc3-4d25-acf7-4528d9777cb2,DISK], DatanodeInfoWithStorage[127.0.0.1:42636,DS-ca7e1efe-8dda-4be5-b978-24d3a8c6913f,DISK], DatanodeInfoWithStorage[127.0.0.1:36681,DS-fd5244dd-2152-401d-b4f5-89a8cbbfc8e7,DISK], DatanodeInfoWithStorage[127.0.0.1:37717,DS-c5926741-5928-4b69-96e6-9fec7a574b50,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-365196874-172.17.0.2-1598167211079:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44405,DS-b21b9d72-d077-46b7-9a11-c535055e157e,DISK], DatanodeInfoWithStorage[127.0.0.1:33507,DS-9c41fb2f-07ea-4afd-adc7-06cb9281f755,DISK], DatanodeInfoWithStorage[127.0.0.1:43732,DS-121d2386-61e7-4799-868b-017295e0b5c8,DISK], DatanodeInfoWithStorage[127.0.0.1:44340,DS-c7fa60cc-aa40-4297-9d0c-6da501c8b889,DISK], DatanodeInfoWithStorage[127.0.0.1:38697,DS-8ff49aa5-7dbe-4ca4-9b72-ff33d08a0a2a,DISK], DatanodeInfoWithStorage[127.0.0.1:39286,DS-3c1890a3-3f3d-44ba-982b-e672c46fdb82,DISK], DatanodeInfoWithStorage[127.0.0.1:39030,DS-4a42d8e3-a786-4c06-a385-db5d325ef882,DISK], DatanodeInfoWithStorage[127.0.0.1:39199,DS-a4580aae-d413-4c10-93a8-b29dd732fa2d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-365196874-172.17.0.2-1598167211079:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44405,DS-b21b9d72-d077-46b7-9a11-c535055e157e,DISK], DatanodeInfoWithStorage[127.0.0.1:33507,DS-9c41fb2f-07ea-4afd-adc7-06cb9281f755,DISK], DatanodeInfoWithStorage[127.0.0.1:43732,DS-121d2386-61e7-4799-868b-017295e0b5c8,DISK], DatanodeInfoWithStorage[127.0.0.1:44340,DS-c7fa60cc-aa40-4297-9d0c-6da501c8b889,DISK], DatanodeInfoWithStorage[127.0.0.1:38697,DS-8ff49aa5-7dbe-4ca4-9b72-ff33d08a0a2a,DISK], DatanodeInfoWithStorage[127.0.0.1:39286,DS-3c1890a3-3f3d-44ba-982b-e672c46fdb82,DISK], DatanodeInfoWithStorage[127.0.0.1:39030,DS-4a42d8e3-a786-4c06-a385-db5d325ef882,DISK], DatanodeInfoWithStorage[127.0.0.1:39199,DS-a4580aae-d413-4c10-93a8-b29dd732fa2d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-456301548-172.17.0.2-1598167497226:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33791,DS-5929462c-244d-4614-9089-0e1368b357a5,DISK], DatanodeInfoWithStorage[127.0.0.1:40272,DS-2de82ccf-3f09-4db0-bb40-cdc6c334e5ca,DISK], DatanodeInfoWithStorage[127.0.0.1:44072,DS-4db908a6-abbb-4a96-bf78-842ccf69c3e5,DISK], DatanodeInfoWithStorage[127.0.0.1:33475,DS-93f0506b-a79c-44cd-90cb-d9be8df59c69,DISK], DatanodeInfoWithStorage[127.0.0.1:44196,DS-09869b2a-0507-4a50-be4e-350a759c1564,DISK], DatanodeInfoWithStorage[127.0.0.1:46874,DS-f364d2d1-1f58-42b4-b943-0d6401fc8183,DISK], DatanodeInfoWithStorage[127.0.0.1:41650,DS-b83b4108-f66b-465a-a663-14cf55a3c525,DISK], DatanodeInfoWithStorage[127.0.0.1:35951,DS-d4f637d5-e6db-4d16-b64c-4d830618ba33,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-456301548-172.17.0.2-1598167497226:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33791,DS-5929462c-244d-4614-9089-0e1368b357a5,DISK], DatanodeInfoWithStorage[127.0.0.1:40272,DS-2de82ccf-3f09-4db0-bb40-cdc6c334e5ca,DISK], DatanodeInfoWithStorage[127.0.0.1:44072,DS-4db908a6-abbb-4a96-bf78-842ccf69c3e5,DISK], DatanodeInfoWithStorage[127.0.0.1:33475,DS-93f0506b-a79c-44cd-90cb-d9be8df59c69,DISK], DatanodeInfoWithStorage[127.0.0.1:44196,DS-09869b2a-0507-4a50-be4e-350a759c1564,DISK], DatanodeInfoWithStorage[127.0.0.1:46874,DS-f364d2d1-1f58-42b4-b943-0d6401fc8183,DISK], DatanodeInfoWithStorage[127.0.0.1:41650,DS-b83b4108-f66b-465a-a663-14cf55a3c525,DISK], DatanodeInfoWithStorage[127.0.0.1:35951,DS-d4f637d5-e6db-4d16-b64c-4d830618ba33,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-369118963-172.17.0.2-1598167611399:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39993,DS-b5bed440-6d46-4b23-820f-cbd2faeb00d8,DISK], DatanodeInfoWithStorage[127.0.0.1:41121,DS-96c03f8d-de23-4df7-a6f3-9a1290ac7c62,DISK], DatanodeInfoWithStorage[127.0.0.1:39836,DS-da74e226-f411-4786-86b2-8d947541eb3c,DISK], DatanodeInfoWithStorage[127.0.0.1:38857,DS-f62c83f9-ba88-47d6-8e64-db9ef576f330,DISK], DatanodeInfoWithStorage[127.0.0.1:40580,DS-897e3ab3-b769-4648-804a-82c0e853a764,DISK], DatanodeInfoWithStorage[127.0.0.1:41492,DS-fe89c630-3eae-42ea-8653-d7dad0fcf164,DISK], DatanodeInfoWithStorage[127.0.0.1:36168,DS-0335dbee-ca2d-4619-ad45-6922555e0a6d,DISK], DatanodeInfoWithStorage[127.0.0.1:38478,DS-c53612b9-a43f-4878-86d6-126cd3959d4e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-369118963-172.17.0.2-1598167611399:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39993,DS-b5bed440-6d46-4b23-820f-cbd2faeb00d8,DISK], DatanodeInfoWithStorage[127.0.0.1:41121,DS-96c03f8d-de23-4df7-a6f3-9a1290ac7c62,DISK], DatanodeInfoWithStorage[127.0.0.1:39836,DS-da74e226-f411-4786-86b2-8d947541eb3c,DISK], DatanodeInfoWithStorage[127.0.0.1:38857,DS-f62c83f9-ba88-47d6-8e64-db9ef576f330,DISK], DatanodeInfoWithStorage[127.0.0.1:40580,DS-897e3ab3-b769-4648-804a-82c0e853a764,DISK], DatanodeInfoWithStorage[127.0.0.1:41492,DS-fe89c630-3eae-42ea-8653-d7dad0fcf164,DISK], DatanodeInfoWithStorage[127.0.0.1:36168,DS-0335dbee-ca2d-4619-ad45-6922555e0a6d,DISK], DatanodeInfoWithStorage[127.0.0.1:38478,DS-c53612b9-a43f-4878-86d6-126cd3959d4e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 5604
