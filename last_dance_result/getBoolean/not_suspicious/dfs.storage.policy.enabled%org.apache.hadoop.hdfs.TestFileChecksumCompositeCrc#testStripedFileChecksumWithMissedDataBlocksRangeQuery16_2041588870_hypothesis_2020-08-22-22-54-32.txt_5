reconf_parameter: dfs.storage.policy.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.storage.policy.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1709786166-172.17.0.3-1598136926577:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40612,DS-d0a25b89-8843-4c3d-8a1a-e3fb52da03ce,DISK], DatanodeInfoWithStorage[127.0.0.1:35271,DS-ee5d724d-5c65-4464-92c6-892cbecfc0d9,DISK], DatanodeInfoWithStorage[127.0.0.1:36027,DS-3dfcdb3e-dccf-4d9a-955a-2badb3b76cea,DISK], DatanodeInfoWithStorage[127.0.0.1:35666,DS-c1d94d97-7419-442d-8291-e7ede4ad9be5,DISK], DatanodeInfoWithStorage[127.0.0.1:43993,DS-7526ac4d-58f3-4c66-ba30-1f5e9c95dc1a,DISK], DatanodeInfoWithStorage[127.0.0.1:34597,DS-eda3b41a-7eb9-41b2-be02-cf891cc13ad1,DISK], DatanodeInfoWithStorage[127.0.0.1:44838,DS-5beec34c-4db9-4694-8ceb-b01c9cf9d830,DISK], DatanodeInfoWithStorage[127.0.0.1:38920,DS-3cc0f7f9-5982-4ec3-8eb3-9bd4c633c94a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1709786166-172.17.0.3-1598136926577:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40612,DS-d0a25b89-8843-4c3d-8a1a-e3fb52da03ce,DISK], DatanodeInfoWithStorage[127.0.0.1:35271,DS-ee5d724d-5c65-4464-92c6-892cbecfc0d9,DISK], DatanodeInfoWithStorage[127.0.0.1:36027,DS-3dfcdb3e-dccf-4d9a-955a-2badb3b76cea,DISK], DatanodeInfoWithStorage[127.0.0.1:35666,DS-c1d94d97-7419-442d-8291-e7ede4ad9be5,DISK], DatanodeInfoWithStorage[127.0.0.1:43993,DS-7526ac4d-58f3-4c66-ba30-1f5e9c95dc1a,DISK], DatanodeInfoWithStorage[127.0.0.1:34597,DS-eda3b41a-7eb9-41b2-be02-cf891cc13ad1,DISK], DatanodeInfoWithStorage[127.0.0.1:44838,DS-5beec34c-4db9-4694-8ceb-b01c9cf9d830,DISK], DatanodeInfoWithStorage[127.0.0.1:38920,DS-3cc0f7f9-5982-4ec3-8eb3-9bd4c633c94a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.storage.policy.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1420776063-172.17.0.3-1598137145119:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40488,DS-f68b012a-4ccb-4379-a49a-a5dd64d51d93,DISK], DatanodeInfoWithStorage[127.0.0.1:33586,DS-63a334c5-40b2-4141-a08b-d085815652b8,DISK], DatanodeInfoWithStorage[127.0.0.1:35683,DS-d5409730-333d-4707-988f-e9b7f646e7b3,DISK], DatanodeInfoWithStorage[127.0.0.1:39172,DS-c598166e-f32b-4d47-a559-90a017de2bd0,DISK], DatanodeInfoWithStorage[127.0.0.1:41567,DS-48774f14-a3fd-4221-be8e-08d88f7364d1,DISK], DatanodeInfoWithStorage[127.0.0.1:38303,DS-e5ab4af1-af50-4a72-a936-e8c97211efb9,DISK], DatanodeInfoWithStorage[127.0.0.1:37165,DS-333f222a-166d-407e-8d31-e9a45e658e45,DISK], DatanodeInfoWithStorage[127.0.0.1:39449,DS-33064514-b303-49c6-803c-17e2db858a22,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1420776063-172.17.0.3-1598137145119:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40488,DS-f68b012a-4ccb-4379-a49a-a5dd64d51d93,DISK], DatanodeInfoWithStorage[127.0.0.1:33586,DS-63a334c5-40b2-4141-a08b-d085815652b8,DISK], DatanodeInfoWithStorage[127.0.0.1:35683,DS-d5409730-333d-4707-988f-e9b7f646e7b3,DISK], DatanodeInfoWithStorage[127.0.0.1:39172,DS-c598166e-f32b-4d47-a559-90a017de2bd0,DISK], DatanodeInfoWithStorage[127.0.0.1:41567,DS-48774f14-a3fd-4221-be8e-08d88f7364d1,DISK], DatanodeInfoWithStorage[127.0.0.1:38303,DS-e5ab4af1-af50-4a72-a936-e8c97211efb9,DISK], DatanodeInfoWithStorage[127.0.0.1:37165,DS-333f222a-166d-407e-8d31-e9a45e658e45,DISK], DatanodeInfoWithStorage[127.0.0.1:39449,DS-33064514-b303-49c6-803c-17e2db858a22,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.storage.policy.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-178377185-172.17.0.3-1598137219978:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35533,DS-7dd3cb2d-4e2e-4169-880f-d81e4cfbe97e,DISK], DatanodeInfoWithStorage[127.0.0.1:40459,DS-e49ecd95-8879-41b3-8d6f-53de865f43f9,DISK], DatanodeInfoWithStorage[127.0.0.1:38856,DS-c9793d24-297c-407b-9abf-f938d4ac66ff,DISK], DatanodeInfoWithStorage[127.0.0.1:35651,DS-7406963f-7c00-4440-81a6-8d8b7749968b,DISK], DatanodeInfoWithStorage[127.0.0.1:45178,DS-ba09ba7b-bc4a-406e-ad80-c3a2e1b020cd,DISK], DatanodeInfoWithStorage[127.0.0.1:43399,DS-283c049d-5df8-48ec-8731-1b08ee699717,DISK], DatanodeInfoWithStorage[127.0.0.1:46803,DS-82e29dd0-f8c8-436a-a5fd-ef3b3c7696d7,DISK], DatanodeInfoWithStorage[127.0.0.1:46184,DS-b9fd56bd-6299-4bab-a5c5-b527692256b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-178377185-172.17.0.3-1598137219978:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35533,DS-7dd3cb2d-4e2e-4169-880f-d81e4cfbe97e,DISK], DatanodeInfoWithStorage[127.0.0.1:40459,DS-e49ecd95-8879-41b3-8d6f-53de865f43f9,DISK], DatanodeInfoWithStorage[127.0.0.1:38856,DS-c9793d24-297c-407b-9abf-f938d4ac66ff,DISK], DatanodeInfoWithStorage[127.0.0.1:35651,DS-7406963f-7c00-4440-81a6-8d8b7749968b,DISK], DatanodeInfoWithStorage[127.0.0.1:45178,DS-ba09ba7b-bc4a-406e-ad80-c3a2e1b020cd,DISK], DatanodeInfoWithStorage[127.0.0.1:43399,DS-283c049d-5df8-48ec-8731-1b08ee699717,DISK], DatanodeInfoWithStorage[127.0.0.1:46803,DS-82e29dd0-f8c8-436a-a5fd-ef3b3c7696d7,DISK], DatanodeInfoWithStorage[127.0.0.1:46184,DS-b9fd56bd-6299-4bab-a5c5-b527692256b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.storage.policy.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1942750748-172.17.0.3-1598137502325:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38336,DS-ded3550a-8a26-4027-8549-b8804e2946a2,DISK], DatanodeInfoWithStorage[127.0.0.1:43616,DS-db3de268-39cb-4df6-beb2-124e4123da8c,DISK], DatanodeInfoWithStorage[127.0.0.1:37900,DS-59847b24-43bd-40fa-8f34-a80ff930d697,DISK], DatanodeInfoWithStorage[127.0.0.1:36368,DS-1b58c84e-c352-4b30-854f-67b8f3f36686,DISK], DatanodeInfoWithStorage[127.0.0.1:40144,DS-6e3b84bf-eca1-4a0f-917a-bbc0297f327b,DISK], DatanodeInfoWithStorage[127.0.0.1:37201,DS-23ccd928-6c8c-4594-ad66-922bb260b2ce,DISK], DatanodeInfoWithStorage[127.0.0.1:33406,DS-2c86da42-cea0-49b6-90bf-0b2200bdc2b9,DISK], DatanodeInfoWithStorage[127.0.0.1:35165,DS-e45dd556-ab8c-4962-bc58-6c26f7b331fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1942750748-172.17.0.3-1598137502325:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38336,DS-ded3550a-8a26-4027-8549-b8804e2946a2,DISK], DatanodeInfoWithStorage[127.0.0.1:43616,DS-db3de268-39cb-4df6-beb2-124e4123da8c,DISK], DatanodeInfoWithStorage[127.0.0.1:37900,DS-59847b24-43bd-40fa-8f34-a80ff930d697,DISK], DatanodeInfoWithStorage[127.0.0.1:36368,DS-1b58c84e-c352-4b30-854f-67b8f3f36686,DISK], DatanodeInfoWithStorage[127.0.0.1:40144,DS-6e3b84bf-eca1-4a0f-917a-bbc0297f327b,DISK], DatanodeInfoWithStorage[127.0.0.1:37201,DS-23ccd928-6c8c-4594-ad66-922bb260b2ce,DISK], DatanodeInfoWithStorage[127.0.0.1:33406,DS-2c86da42-cea0-49b6-90bf-0b2200bdc2b9,DISK], DatanodeInfoWithStorage[127.0.0.1:35165,DS-e45dd556-ab8c-4962-bc58-6c26f7b331fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.storage.policy.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1521725358-172.17.0.3-1598137712228:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36948,DS-c06f79ce-ac83-408c-8473-5a509f776f53,DISK], DatanodeInfoWithStorage[127.0.0.1:44062,DS-fc19c355-c106-4a1d-8ac8-041135be5299,DISK], DatanodeInfoWithStorage[127.0.0.1:36411,DS-4f2c3f7d-1df9-4325-a99d-4c077d24bb34,DISK], DatanodeInfoWithStorage[127.0.0.1:33985,DS-d2d06546-2c30-42b6-ba3b-1e9032745432,DISK], DatanodeInfoWithStorage[127.0.0.1:43275,DS-c1131993-dbb2-4da5-8328-57aa71bab3b3,DISK], DatanodeInfoWithStorage[127.0.0.1:45537,DS-537588f3-3cc3-4ec0-a788-12b067304f60,DISK], DatanodeInfoWithStorage[127.0.0.1:34572,DS-ed060d9f-8072-4b25-a5a9-6126bcd9d440,DISK], DatanodeInfoWithStorage[127.0.0.1:45052,DS-9fba4394-4db8-47eb-9af4-c01c92ecf3b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1521725358-172.17.0.3-1598137712228:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36948,DS-c06f79ce-ac83-408c-8473-5a509f776f53,DISK], DatanodeInfoWithStorage[127.0.0.1:44062,DS-fc19c355-c106-4a1d-8ac8-041135be5299,DISK], DatanodeInfoWithStorage[127.0.0.1:36411,DS-4f2c3f7d-1df9-4325-a99d-4c077d24bb34,DISK], DatanodeInfoWithStorage[127.0.0.1:33985,DS-d2d06546-2c30-42b6-ba3b-1e9032745432,DISK], DatanodeInfoWithStorage[127.0.0.1:43275,DS-c1131993-dbb2-4da5-8328-57aa71bab3b3,DISK], DatanodeInfoWithStorage[127.0.0.1:45537,DS-537588f3-3cc3-4ec0-a788-12b067304f60,DISK], DatanodeInfoWithStorage[127.0.0.1:34572,DS-ed060d9f-8072-4b25-a5a9-6126bcd9d440,DISK], DatanodeInfoWithStorage[127.0.0.1:45052,DS-9fba4394-4db8-47eb-9af4-c01c92ecf3b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.storage.policy.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1190290905-172.17.0.3-1598138378114:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38014,DS-bcf378d7-b803-49cb-b652-967a1ad05b98,DISK], DatanodeInfoWithStorage[127.0.0.1:40220,DS-254e8d59-ebe5-466b-bf10-a369ad43e4ad,DISK], DatanodeInfoWithStorage[127.0.0.1:41720,DS-d1e82d2c-f238-407d-8821-d6b7d93c7f04,DISK], DatanodeInfoWithStorage[127.0.0.1:40639,DS-ed0a12a2-97b7-4eab-bfe9-7e0cc28f9b4d,DISK], DatanodeInfoWithStorage[127.0.0.1:36027,DS-8da7eb0d-feae-4058-b5bd-87858fc3cbaa,DISK], DatanodeInfoWithStorage[127.0.0.1:43153,DS-882b99e1-0426-4c7d-bf01-e054cf1e4320,DISK], DatanodeInfoWithStorage[127.0.0.1:46718,DS-7a676536-ff42-4ca1-a4bc-4ec87d842027,DISK], DatanodeInfoWithStorage[127.0.0.1:41308,DS-ee20d37e-e6e5-48e4-9cce-d6926a186e27,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1190290905-172.17.0.3-1598138378114:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38014,DS-bcf378d7-b803-49cb-b652-967a1ad05b98,DISK], DatanodeInfoWithStorage[127.0.0.1:40220,DS-254e8d59-ebe5-466b-bf10-a369ad43e4ad,DISK], DatanodeInfoWithStorage[127.0.0.1:41720,DS-d1e82d2c-f238-407d-8821-d6b7d93c7f04,DISK], DatanodeInfoWithStorage[127.0.0.1:40639,DS-ed0a12a2-97b7-4eab-bfe9-7e0cc28f9b4d,DISK], DatanodeInfoWithStorage[127.0.0.1:36027,DS-8da7eb0d-feae-4058-b5bd-87858fc3cbaa,DISK], DatanodeInfoWithStorage[127.0.0.1:43153,DS-882b99e1-0426-4c7d-bf01-e054cf1e4320,DISK], DatanodeInfoWithStorage[127.0.0.1:46718,DS-7a676536-ff42-4ca1-a4bc-4ec87d842027,DISK], DatanodeInfoWithStorage[127.0.0.1:41308,DS-ee20d37e-e6e5-48e4-9cce-d6926a186e27,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.storage.policy.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-873904406-172.17.0.3-1598138483173:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41641,DS-22da86d9-0931-4809-8ded-f9c1a7458306,DISK], DatanodeInfoWithStorage[127.0.0.1:34798,DS-602ce5be-6d19-444d-a5a9-f0a2aa53fc3f,DISK], DatanodeInfoWithStorage[127.0.0.1:46742,DS-e9da3569-0deb-433a-8290-a870c73a36ad,DISK], DatanodeInfoWithStorage[127.0.0.1:33592,DS-25a0463f-2bd5-4a6c-9023-93e84dc1f94e,DISK], DatanodeInfoWithStorage[127.0.0.1:36924,DS-3ed9d74b-1421-4e11-8e0e-c878988ee577,DISK], DatanodeInfoWithStorage[127.0.0.1:42999,DS-2eb91b7b-432f-4f1a-98a3-5fa828458d3e,DISK], DatanodeInfoWithStorage[127.0.0.1:45689,DS-c5a57465-487a-44b0-bd23-bdbaf7a52df0,DISK], DatanodeInfoWithStorage[127.0.0.1:42422,DS-ce7a398d-360a-4150-9390-d9a480fe9d6f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-873904406-172.17.0.3-1598138483173:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41641,DS-22da86d9-0931-4809-8ded-f9c1a7458306,DISK], DatanodeInfoWithStorage[127.0.0.1:34798,DS-602ce5be-6d19-444d-a5a9-f0a2aa53fc3f,DISK], DatanodeInfoWithStorage[127.0.0.1:46742,DS-e9da3569-0deb-433a-8290-a870c73a36ad,DISK], DatanodeInfoWithStorage[127.0.0.1:33592,DS-25a0463f-2bd5-4a6c-9023-93e84dc1f94e,DISK], DatanodeInfoWithStorage[127.0.0.1:36924,DS-3ed9d74b-1421-4e11-8e0e-c878988ee577,DISK], DatanodeInfoWithStorage[127.0.0.1:42999,DS-2eb91b7b-432f-4f1a-98a3-5fa828458d3e,DISK], DatanodeInfoWithStorage[127.0.0.1:45689,DS-c5a57465-487a-44b0-bd23-bdbaf7a52df0,DISK], DatanodeInfoWithStorage[127.0.0.1:42422,DS-ce7a398d-360a-4150-9390-d9a480fe9d6f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.storage.policy.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1354771727-172.17.0.3-1598138515580:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45117,DS-3c6e64de-d3a6-4835-aac5-356ce1a4ce40,DISK], DatanodeInfoWithStorage[127.0.0.1:42003,DS-2c253f77-a56c-4de5-8da1-f9577bb5f082,DISK], DatanodeInfoWithStorage[127.0.0.1:35576,DS-a566b10e-e338-4bd9-875d-88b6e12894ce,DISK], DatanodeInfoWithStorage[127.0.0.1:44758,DS-abcdec78-8729-4633-967c-1aa1aae7bf35,DISK], DatanodeInfoWithStorage[127.0.0.1:32771,DS-31e302cc-f922-4c21-a243-1f95ce61fd76,DISK], DatanodeInfoWithStorage[127.0.0.1:46150,DS-2eb7d474-91e1-4cb8-b7e2-da67120ba039,DISK], DatanodeInfoWithStorage[127.0.0.1:38602,DS-6ba408ca-17c6-4938-9302-61f3b3808ef3,DISK], DatanodeInfoWithStorage[127.0.0.1:39596,DS-e574528b-39ca-4dc8-bd92-2af2c0690783,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1354771727-172.17.0.3-1598138515580:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45117,DS-3c6e64de-d3a6-4835-aac5-356ce1a4ce40,DISK], DatanodeInfoWithStorage[127.0.0.1:42003,DS-2c253f77-a56c-4de5-8da1-f9577bb5f082,DISK], DatanodeInfoWithStorage[127.0.0.1:35576,DS-a566b10e-e338-4bd9-875d-88b6e12894ce,DISK], DatanodeInfoWithStorage[127.0.0.1:44758,DS-abcdec78-8729-4633-967c-1aa1aae7bf35,DISK], DatanodeInfoWithStorage[127.0.0.1:32771,DS-31e302cc-f922-4c21-a243-1f95ce61fd76,DISK], DatanodeInfoWithStorage[127.0.0.1:46150,DS-2eb7d474-91e1-4cb8-b7e2-da67120ba039,DISK], DatanodeInfoWithStorage[127.0.0.1:38602,DS-6ba408ca-17c6-4938-9302-61f3b3808ef3,DISK], DatanodeInfoWithStorage[127.0.0.1:39596,DS-e574528b-39ca-4dc8-bd92-2af2c0690783,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.storage.policy.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1965455324-172.17.0.3-1598139137382:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40274,DS-4d887b50-8fca-4bb4-b216-99002c6b7c6b,DISK], DatanodeInfoWithStorage[127.0.0.1:36330,DS-0f385992-f0c1-423c-ac95-978262d5d6b5,DISK], DatanodeInfoWithStorage[127.0.0.1:39229,DS-faba904b-9e21-483e-b93f-f183a905c469,DISK], DatanodeInfoWithStorage[127.0.0.1:45894,DS-1d877b6d-11b2-4618-88b4-631a1ceb10e3,DISK], DatanodeInfoWithStorage[127.0.0.1:40207,DS-a8b3898f-2ff6-4e85-a448-1e3e9ed065cf,DISK], DatanodeInfoWithStorage[127.0.0.1:38300,DS-2c2c4d89-c0fe-4d1e-9441-636aa842a3d1,DISK], DatanodeInfoWithStorage[127.0.0.1:37374,DS-58cc0355-c207-48f7-9096-5921c6d429ad,DISK], DatanodeInfoWithStorage[127.0.0.1:37530,DS-65f96d92-24f8-47a4-af3f-608b4d1364c5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1965455324-172.17.0.3-1598139137382:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40274,DS-4d887b50-8fca-4bb4-b216-99002c6b7c6b,DISK], DatanodeInfoWithStorage[127.0.0.1:36330,DS-0f385992-f0c1-423c-ac95-978262d5d6b5,DISK], DatanodeInfoWithStorage[127.0.0.1:39229,DS-faba904b-9e21-483e-b93f-f183a905c469,DISK], DatanodeInfoWithStorage[127.0.0.1:45894,DS-1d877b6d-11b2-4618-88b4-631a1ceb10e3,DISK], DatanodeInfoWithStorage[127.0.0.1:40207,DS-a8b3898f-2ff6-4e85-a448-1e3e9ed065cf,DISK], DatanodeInfoWithStorage[127.0.0.1:38300,DS-2c2c4d89-c0fe-4d1e-9441-636aa842a3d1,DISK], DatanodeInfoWithStorage[127.0.0.1:37374,DS-58cc0355-c207-48f7-9096-5921c6d429ad,DISK], DatanodeInfoWithStorage[127.0.0.1:37530,DS-65f96d92-24f8-47a4-af3f-608b4d1364c5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.storage.policy.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2114969020-172.17.0.3-1598139923696:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38831,DS-79818c61-f0df-4ab2-9a9f-8d574392bea8,DISK], DatanodeInfoWithStorage[127.0.0.1:38105,DS-acf40456-aaf9-4268-9102-23d724f6cd45,DISK], DatanodeInfoWithStorage[127.0.0.1:42131,DS-e6f5811f-f632-4fae-a2ee-6655c4099141,DISK], DatanodeInfoWithStorage[127.0.0.1:33767,DS-c1c765ca-16be-4ba3-ba9a-de9118278b20,DISK], DatanodeInfoWithStorage[127.0.0.1:38450,DS-7ea465b0-e844-4f19-b10e-9aaacac72690,DISK], DatanodeInfoWithStorage[127.0.0.1:40919,DS-ad76c87e-c572-4b7e-b402-a5fbcc1dff14,DISK], DatanodeInfoWithStorage[127.0.0.1:43515,DS-49ad0c95-0374-4704-ad22-dfd4426d6c1b,DISK], DatanodeInfoWithStorage[127.0.0.1:44535,DS-34755bbc-0180-4363-a885-8ece5f23325b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2114969020-172.17.0.3-1598139923696:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38831,DS-79818c61-f0df-4ab2-9a9f-8d574392bea8,DISK], DatanodeInfoWithStorage[127.0.0.1:38105,DS-acf40456-aaf9-4268-9102-23d724f6cd45,DISK], DatanodeInfoWithStorage[127.0.0.1:42131,DS-e6f5811f-f632-4fae-a2ee-6655c4099141,DISK], DatanodeInfoWithStorage[127.0.0.1:33767,DS-c1c765ca-16be-4ba3-ba9a-de9118278b20,DISK], DatanodeInfoWithStorage[127.0.0.1:38450,DS-7ea465b0-e844-4f19-b10e-9aaacac72690,DISK], DatanodeInfoWithStorage[127.0.0.1:40919,DS-ad76c87e-c572-4b7e-b402-a5fbcc1dff14,DISK], DatanodeInfoWithStorage[127.0.0.1:43515,DS-49ad0c95-0374-4704-ad22-dfd4426d6c1b,DISK], DatanodeInfoWithStorage[127.0.0.1:44535,DS-34755bbc-0180-4363-a885-8ece5f23325b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.storage.policy.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-194805345-172.17.0.3-1598139951492:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44220,DS-5984d861-0304-4dec-ad62-0b88031eb1e9,DISK], DatanodeInfoWithStorage[127.0.0.1:40966,DS-7c5c7955-3c46-42b0-8079-44c224095f38,DISK], DatanodeInfoWithStorage[127.0.0.1:35141,DS-338889eb-18bd-4008-8233-0656076844fa,DISK], DatanodeInfoWithStorage[127.0.0.1:35673,DS-457858c3-96bd-42d4-bd7f-77b5d7b51a35,DISK], DatanodeInfoWithStorage[127.0.0.1:41441,DS-e8634373-7288-400c-8573-398b6df4b5ec,DISK], DatanodeInfoWithStorage[127.0.0.1:32821,DS-11938aa0-12b4-4ae9-b788-25d889a4a8ee,DISK], DatanodeInfoWithStorage[127.0.0.1:34775,DS-9d9eea9d-0fdc-478a-849e-6c5c19f930e3,DISK], DatanodeInfoWithStorage[127.0.0.1:33143,DS-206647ab-fa6a-4df7-aab4-3009352b793f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-194805345-172.17.0.3-1598139951492:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44220,DS-5984d861-0304-4dec-ad62-0b88031eb1e9,DISK], DatanodeInfoWithStorage[127.0.0.1:40966,DS-7c5c7955-3c46-42b0-8079-44c224095f38,DISK], DatanodeInfoWithStorage[127.0.0.1:35141,DS-338889eb-18bd-4008-8233-0656076844fa,DISK], DatanodeInfoWithStorage[127.0.0.1:35673,DS-457858c3-96bd-42d4-bd7f-77b5d7b51a35,DISK], DatanodeInfoWithStorage[127.0.0.1:41441,DS-e8634373-7288-400c-8573-398b6df4b5ec,DISK], DatanodeInfoWithStorage[127.0.0.1:32821,DS-11938aa0-12b4-4ae9-b788-25d889a4a8ee,DISK], DatanodeInfoWithStorage[127.0.0.1:34775,DS-9d9eea9d-0fdc-478a-849e-6c5c19f930e3,DISK], DatanodeInfoWithStorage[127.0.0.1:33143,DS-206647ab-fa6a-4df7-aab4-3009352b793f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.storage.policy.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-598296066-172.17.0.3-1598140221729:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43113,DS-0ec512a5-c1e7-46ee-bd24-9e57c09e7190,DISK], DatanodeInfoWithStorage[127.0.0.1:46452,DS-3e7bdec6-4068-4374-97d1-ba738ad75095,DISK], DatanodeInfoWithStorage[127.0.0.1:41654,DS-cea5283e-d073-45bc-91dd-5d53aea56db9,DISK], DatanodeInfoWithStorage[127.0.0.1:44415,DS-89903725-cc65-41f4-84ca-2235b5ff3753,DISK], DatanodeInfoWithStorage[127.0.0.1:36697,DS-522ff7ae-f485-4347-8f4a-2ca403ffcca5,DISK], DatanodeInfoWithStorage[127.0.0.1:37309,DS-402ff900-b5cd-4a9c-85a4-ff05953194d8,DISK], DatanodeInfoWithStorage[127.0.0.1:41863,DS-45487410-9998-442b-b7b9-24dd68dd6be4,DISK], DatanodeInfoWithStorage[127.0.0.1:41713,DS-89b6e7ab-493b-42d8-81bf-7d0a0485a350,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-598296066-172.17.0.3-1598140221729:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43113,DS-0ec512a5-c1e7-46ee-bd24-9e57c09e7190,DISK], DatanodeInfoWithStorage[127.0.0.1:46452,DS-3e7bdec6-4068-4374-97d1-ba738ad75095,DISK], DatanodeInfoWithStorage[127.0.0.1:41654,DS-cea5283e-d073-45bc-91dd-5d53aea56db9,DISK], DatanodeInfoWithStorage[127.0.0.1:44415,DS-89903725-cc65-41f4-84ca-2235b5ff3753,DISK], DatanodeInfoWithStorage[127.0.0.1:36697,DS-522ff7ae-f485-4347-8f4a-2ca403ffcca5,DISK], DatanodeInfoWithStorage[127.0.0.1:37309,DS-402ff900-b5cd-4a9c-85a4-ff05953194d8,DISK], DatanodeInfoWithStorage[127.0.0.1:41863,DS-45487410-9998-442b-b7b9-24dd68dd6be4,DISK], DatanodeInfoWithStorage[127.0.0.1:41713,DS-89b6e7ab-493b-42d8-81bf-7d0a0485a350,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.storage.policy.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1798193725-172.17.0.3-1598141200874:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39027,DS-6106e2b0-e70c-4770-b4ec-f19e59dc1db6,DISK], DatanodeInfoWithStorage[127.0.0.1:38759,DS-a0ad4152-e5fc-4d44-85a1-017411476beb,DISK], DatanodeInfoWithStorage[127.0.0.1:33761,DS-7591e178-ec3d-4117-8848-6d2992fc9567,DISK], DatanodeInfoWithStorage[127.0.0.1:38140,DS-2ddbbe63-1c14-4795-b3e5-42d19f806aa5,DISK], DatanodeInfoWithStorage[127.0.0.1:41277,DS-e7d98c5b-e7e9-4dcf-9e78-d6927e7da581,DISK], DatanodeInfoWithStorage[127.0.0.1:33630,DS-0ff2d69f-1721-44b6-b108-f55d1e54f262,DISK], DatanodeInfoWithStorage[127.0.0.1:43101,DS-f901243d-b358-4715-8022-155fa63c1845,DISK], DatanodeInfoWithStorage[127.0.0.1:34718,DS-c3570051-78fb-4437-abfe-c219fa5b336f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1798193725-172.17.0.3-1598141200874:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39027,DS-6106e2b0-e70c-4770-b4ec-f19e59dc1db6,DISK], DatanodeInfoWithStorage[127.0.0.1:38759,DS-a0ad4152-e5fc-4d44-85a1-017411476beb,DISK], DatanodeInfoWithStorage[127.0.0.1:33761,DS-7591e178-ec3d-4117-8848-6d2992fc9567,DISK], DatanodeInfoWithStorage[127.0.0.1:38140,DS-2ddbbe63-1c14-4795-b3e5-42d19f806aa5,DISK], DatanodeInfoWithStorage[127.0.0.1:41277,DS-e7d98c5b-e7e9-4dcf-9e78-d6927e7da581,DISK], DatanodeInfoWithStorage[127.0.0.1:33630,DS-0ff2d69f-1721-44b6-b108-f55d1e54f262,DISK], DatanodeInfoWithStorage[127.0.0.1:43101,DS-f901243d-b358-4715-8022-155fa63c1845,DISK], DatanodeInfoWithStorage[127.0.0.1:34718,DS-c3570051-78fb-4437-abfe-c219fa5b336f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.storage.policy.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-830080728-172.17.0.3-1598141646967:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39027,DS-2c179e69-dfba-43ae-93f9-62eedd5461da,DISK], DatanodeInfoWithStorage[127.0.0.1:39827,DS-1583a8f7-4969-4ad1-b346-0e17f8d4d9be,DISK], DatanodeInfoWithStorage[127.0.0.1:33103,DS-9ec41236-b754-48ea-8f8d-2eff35362f89,DISK], DatanodeInfoWithStorage[127.0.0.1:45508,DS-d572fa5f-fe75-404e-aa74-6917d35a5911,DISK], DatanodeInfoWithStorage[127.0.0.1:41622,DS-0a3fbc19-11c7-430c-82c1-040585f0b79f,DISK], DatanodeInfoWithStorage[127.0.0.1:38603,DS-cc7cad04-ca0e-47aa-a786-234db9c12e5d,DISK], DatanodeInfoWithStorage[127.0.0.1:40398,DS-10d586a2-bde9-4776-9ec7-c5c87396ac80,DISK], DatanodeInfoWithStorage[127.0.0.1:36411,DS-dca41378-5a25-4c32-bc1b-449795df4514,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-830080728-172.17.0.3-1598141646967:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39027,DS-2c179e69-dfba-43ae-93f9-62eedd5461da,DISK], DatanodeInfoWithStorage[127.0.0.1:39827,DS-1583a8f7-4969-4ad1-b346-0e17f8d4d9be,DISK], DatanodeInfoWithStorage[127.0.0.1:33103,DS-9ec41236-b754-48ea-8f8d-2eff35362f89,DISK], DatanodeInfoWithStorage[127.0.0.1:45508,DS-d572fa5f-fe75-404e-aa74-6917d35a5911,DISK], DatanodeInfoWithStorage[127.0.0.1:41622,DS-0a3fbc19-11c7-430c-82c1-040585f0b79f,DISK], DatanodeInfoWithStorage[127.0.0.1:38603,DS-cc7cad04-ca0e-47aa-a786-234db9c12e5d,DISK], DatanodeInfoWithStorage[127.0.0.1:40398,DS-10d586a2-bde9-4776-9ec7-c5c87396ac80,DISK], DatanodeInfoWithStorage[127.0.0.1:36411,DS-dca41378-5a25-4c32-bc1b-449795df4514,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.storage.policy.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1719861875-172.17.0.3-1598141786613:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46761,DS-9affcf7a-03c3-405d-8e16-b667b0d1be7c,DISK], DatanodeInfoWithStorage[127.0.0.1:34961,DS-9870b6ea-8cda-4644-aaec-dafc582dc6ed,DISK], DatanodeInfoWithStorage[127.0.0.1:36044,DS-d830db82-1340-4aa8-9da2-84d3a5527ec1,DISK], DatanodeInfoWithStorage[127.0.0.1:33308,DS-97f27aec-31c4-4486-9f63-bc1abdf7c863,DISK], DatanodeInfoWithStorage[127.0.0.1:37306,DS-b0ac48b1-d557-42b1-bd52-f1917ec0b8f9,DISK], DatanodeInfoWithStorage[127.0.0.1:34721,DS-21e7dcf1-2b14-4916-acbc-02ba679ad56b,DISK], DatanodeInfoWithStorage[127.0.0.1:36808,DS-5e4c048c-d0a4-4cc0-9388-44056eafeaee,DISK], DatanodeInfoWithStorage[127.0.0.1:43106,DS-3fa79493-25d2-4a37-89c9-e5559634d127,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1719861875-172.17.0.3-1598141786613:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46761,DS-9affcf7a-03c3-405d-8e16-b667b0d1be7c,DISK], DatanodeInfoWithStorage[127.0.0.1:34961,DS-9870b6ea-8cda-4644-aaec-dafc582dc6ed,DISK], DatanodeInfoWithStorage[127.0.0.1:36044,DS-d830db82-1340-4aa8-9da2-84d3a5527ec1,DISK], DatanodeInfoWithStorage[127.0.0.1:33308,DS-97f27aec-31c4-4486-9f63-bc1abdf7c863,DISK], DatanodeInfoWithStorage[127.0.0.1:37306,DS-b0ac48b1-d557-42b1-bd52-f1917ec0b8f9,DISK], DatanodeInfoWithStorage[127.0.0.1:34721,DS-21e7dcf1-2b14-4916-acbc-02ba679ad56b,DISK], DatanodeInfoWithStorage[127.0.0.1:36808,DS-5e4c048c-d0a4-4cc0-9388-44056eafeaee,DISK], DatanodeInfoWithStorage[127.0.0.1:43106,DS-3fa79493-25d2-4a37-89c9-e5559634d127,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.storage.policy.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-640204424-172.17.0.3-1598141967186:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46197,DS-13f83f43-2565-4dd7-bde2-4f43d9d7e629,DISK], DatanodeInfoWithStorage[127.0.0.1:39335,DS-1b0731ae-07a9-43f2-8de3-1caaa567910e,DISK], DatanodeInfoWithStorage[127.0.0.1:39794,DS-71b967b6-31d1-46b8-bd43-dbf5f195ce1a,DISK], DatanodeInfoWithStorage[127.0.0.1:44844,DS-74f1873a-f4b2-41c1-8cd2-ba06aa7cdcda,DISK], DatanodeInfoWithStorage[127.0.0.1:39110,DS-9ae9f079-089b-4ecf-8eec-aef3c0827560,DISK], DatanodeInfoWithStorage[127.0.0.1:35103,DS-e32ad152-7104-47f4-8d3b-825b72fac211,DISK], DatanodeInfoWithStorage[127.0.0.1:35727,DS-c46b39a0-3edb-4ff5-b2a0-3a5e3f054077,DISK], DatanodeInfoWithStorage[127.0.0.1:38798,DS-d64ef2de-5da8-4ee4-b5fb-6160d193ed99,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-640204424-172.17.0.3-1598141967186:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46197,DS-13f83f43-2565-4dd7-bde2-4f43d9d7e629,DISK], DatanodeInfoWithStorage[127.0.0.1:39335,DS-1b0731ae-07a9-43f2-8de3-1caaa567910e,DISK], DatanodeInfoWithStorage[127.0.0.1:39794,DS-71b967b6-31d1-46b8-bd43-dbf5f195ce1a,DISK], DatanodeInfoWithStorage[127.0.0.1:44844,DS-74f1873a-f4b2-41c1-8cd2-ba06aa7cdcda,DISK], DatanodeInfoWithStorage[127.0.0.1:39110,DS-9ae9f079-089b-4ecf-8eec-aef3c0827560,DISK], DatanodeInfoWithStorage[127.0.0.1:35103,DS-e32ad152-7104-47f4-8d3b-825b72fac211,DISK], DatanodeInfoWithStorage[127.0.0.1:35727,DS-c46b39a0-3edb-4ff5-b2a0-3a5e3f054077,DISK], DatanodeInfoWithStorage[127.0.0.1:38798,DS-d64ef2de-5da8-4ee4-b5fb-6160d193ed99,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.storage.policy.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1185100987-172.17.0.3-1598142030322:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40371,DS-316758a2-254c-4c0e-a5e4-8533576994db,DISK], DatanodeInfoWithStorage[127.0.0.1:40936,DS-3a5d2e3e-cf74-43d5-85cb-c17449f7aafb,DISK], DatanodeInfoWithStorage[127.0.0.1:38938,DS-8fe5b438-01eb-4d69-88fa-ee24aae1c117,DISK], DatanodeInfoWithStorage[127.0.0.1:39052,DS-d6dbe1f1-e53a-4996-bd88-7da3190deb39,DISK], DatanodeInfoWithStorage[127.0.0.1:45687,DS-2e6562d4-b633-4954-9445-32d123a2118a,DISK], DatanodeInfoWithStorage[127.0.0.1:37487,DS-e41e987a-0e73-43b7-a9e5-15a1ffb54e1b,DISK], DatanodeInfoWithStorage[127.0.0.1:36839,DS-9ff41672-ac07-4532-aa0a-cba409a3fd88,DISK], DatanodeInfoWithStorage[127.0.0.1:37008,DS-26648ecc-3386-4dec-ac6c-ab6146e0e3ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1185100987-172.17.0.3-1598142030322:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40371,DS-316758a2-254c-4c0e-a5e4-8533576994db,DISK], DatanodeInfoWithStorage[127.0.0.1:40936,DS-3a5d2e3e-cf74-43d5-85cb-c17449f7aafb,DISK], DatanodeInfoWithStorage[127.0.0.1:38938,DS-8fe5b438-01eb-4d69-88fa-ee24aae1c117,DISK], DatanodeInfoWithStorage[127.0.0.1:39052,DS-d6dbe1f1-e53a-4996-bd88-7da3190deb39,DISK], DatanodeInfoWithStorage[127.0.0.1:45687,DS-2e6562d4-b633-4954-9445-32d123a2118a,DISK], DatanodeInfoWithStorage[127.0.0.1:37487,DS-e41e987a-0e73-43b7-a9e5-15a1ffb54e1b,DISK], DatanodeInfoWithStorage[127.0.0.1:36839,DS-9ff41672-ac07-4532-aa0a-cba409a3fd88,DISK], DatanodeInfoWithStorage[127.0.0.1:37008,DS-26648ecc-3386-4dec-ac6c-ab6146e0e3ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5216
