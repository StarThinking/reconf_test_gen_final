reconf_parameter: dfs.namenode.avoid.write.stale.datanode
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.avoid.write.stale.datanode
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-323309059-172.17.0.13-1598124404526:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46849,DS-7e4f0bb8-a7e2-4d17-911d-0f0ac50377ed,DISK], DatanodeInfoWithStorage[127.0.0.1:36834,DS-de4d7ca2-7e23-4683-8185-8b281d5a2cfc,DISK], DatanodeInfoWithStorage[127.0.0.1:37323,DS-1d793f8e-8640-495e-aa5f-697d952d6cf6,DISK], DatanodeInfoWithStorage[127.0.0.1:35172,DS-df40ab26-b255-4715-9d4d-dd46b41ca74b,DISK], DatanodeInfoWithStorage[127.0.0.1:39523,DS-6f99babd-cb5a-4225-8271-84ed8b099964,DISK], DatanodeInfoWithStorage[127.0.0.1:34990,DS-1cc6832a-2897-400a-b932-62fed29bdf7c,DISK], DatanodeInfoWithStorage[127.0.0.1:36496,DS-a6fefea3-287a-47fe-935e-d4af275b24f2,DISK], DatanodeInfoWithStorage[127.0.0.1:43065,DS-170e855f-d841-4f67-85d2-49aaf442b2fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-323309059-172.17.0.13-1598124404526:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46849,DS-7e4f0bb8-a7e2-4d17-911d-0f0ac50377ed,DISK], DatanodeInfoWithStorage[127.0.0.1:36834,DS-de4d7ca2-7e23-4683-8185-8b281d5a2cfc,DISK], DatanodeInfoWithStorage[127.0.0.1:37323,DS-1d793f8e-8640-495e-aa5f-697d952d6cf6,DISK], DatanodeInfoWithStorage[127.0.0.1:35172,DS-df40ab26-b255-4715-9d4d-dd46b41ca74b,DISK], DatanodeInfoWithStorage[127.0.0.1:39523,DS-6f99babd-cb5a-4225-8271-84ed8b099964,DISK], DatanodeInfoWithStorage[127.0.0.1:34990,DS-1cc6832a-2897-400a-b932-62fed29bdf7c,DISK], DatanodeInfoWithStorage[127.0.0.1:36496,DS-a6fefea3-287a-47fe-935e-d4af275b24f2,DISK], DatanodeInfoWithStorage[127.0.0.1:43065,DS-170e855f-d841-4f67-85d2-49aaf442b2fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.avoid.write.stale.datanode
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-337586643-172.17.0.13-1598124836516:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32776,DS-d77bead1-20d0-4fd6-be33-e54d2d501d63,DISK], DatanodeInfoWithStorage[127.0.0.1:44500,DS-c7eb756e-ef52-4595-b871-2ac9ff027d0c,DISK], DatanodeInfoWithStorage[127.0.0.1:42210,DS-e5a030cb-054b-48b0-ac8f-0184cf4ccf4a,DISK], DatanodeInfoWithStorage[127.0.0.1:36833,DS-3960d678-829b-4c70-af50-31f41b124a35,DISK], DatanodeInfoWithStorage[127.0.0.1:39433,DS-5aadb1ad-bc2b-404e-bd5e-db923a467b7b,DISK], DatanodeInfoWithStorage[127.0.0.1:37356,DS-01766e43-df56-45d7-a45a-8e7d53b3fe74,DISK], DatanodeInfoWithStorage[127.0.0.1:36894,DS-3026b485-cce0-463a-98d1-aa63106a2a7b,DISK], DatanodeInfoWithStorage[127.0.0.1:38840,DS-50e2cd06-0c6c-46db-8ae9-9157b044d934,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-337586643-172.17.0.13-1598124836516:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32776,DS-d77bead1-20d0-4fd6-be33-e54d2d501d63,DISK], DatanodeInfoWithStorage[127.0.0.1:44500,DS-c7eb756e-ef52-4595-b871-2ac9ff027d0c,DISK], DatanodeInfoWithStorage[127.0.0.1:42210,DS-e5a030cb-054b-48b0-ac8f-0184cf4ccf4a,DISK], DatanodeInfoWithStorage[127.0.0.1:36833,DS-3960d678-829b-4c70-af50-31f41b124a35,DISK], DatanodeInfoWithStorage[127.0.0.1:39433,DS-5aadb1ad-bc2b-404e-bd5e-db923a467b7b,DISK], DatanodeInfoWithStorage[127.0.0.1:37356,DS-01766e43-df56-45d7-a45a-8e7d53b3fe74,DISK], DatanodeInfoWithStorage[127.0.0.1:36894,DS-3026b485-cce0-463a-98d1-aa63106a2a7b,DISK], DatanodeInfoWithStorage[127.0.0.1:38840,DS-50e2cd06-0c6c-46db-8ae9-9157b044d934,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.avoid.write.stale.datanode
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-382492831-172.17.0.13-1598124873537:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34441,DS-48e5c206-2c20-4714-b4e4-e91d726ee94b,DISK], DatanodeInfoWithStorage[127.0.0.1:33476,DS-be43548c-d989-4fe5-a7c7-8bbc6e36892a,DISK], DatanodeInfoWithStorage[127.0.0.1:38210,DS-d3b90d2b-c845-413b-8131-37f707dfdfd6,DISK], DatanodeInfoWithStorage[127.0.0.1:46684,DS-19e2b01f-6cf5-4f45-9df4-90e94bba3032,DISK], DatanodeInfoWithStorage[127.0.0.1:42170,DS-96989091-8814-437f-9c46-e0a07754b321,DISK], DatanodeInfoWithStorage[127.0.0.1:34520,DS-48ac6500-39de-4bea-85db-18bc3e38f6a1,DISK], DatanodeInfoWithStorage[127.0.0.1:45045,DS-856a7694-2366-4157-82ac-7d2f06c9f483,DISK], DatanodeInfoWithStorage[127.0.0.1:42093,DS-26338ade-782f-41e0-aa10-d7443d0e1219,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-382492831-172.17.0.13-1598124873537:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34441,DS-48e5c206-2c20-4714-b4e4-e91d726ee94b,DISK], DatanodeInfoWithStorage[127.0.0.1:33476,DS-be43548c-d989-4fe5-a7c7-8bbc6e36892a,DISK], DatanodeInfoWithStorage[127.0.0.1:38210,DS-d3b90d2b-c845-413b-8131-37f707dfdfd6,DISK], DatanodeInfoWithStorage[127.0.0.1:46684,DS-19e2b01f-6cf5-4f45-9df4-90e94bba3032,DISK], DatanodeInfoWithStorage[127.0.0.1:42170,DS-96989091-8814-437f-9c46-e0a07754b321,DISK], DatanodeInfoWithStorage[127.0.0.1:34520,DS-48ac6500-39de-4bea-85db-18bc3e38f6a1,DISK], DatanodeInfoWithStorage[127.0.0.1:45045,DS-856a7694-2366-4157-82ac-7d2f06c9f483,DISK], DatanodeInfoWithStorage[127.0.0.1:42093,DS-26338ade-782f-41e0-aa10-d7443d0e1219,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.avoid.write.stale.datanode
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-620845631-172.17.0.13-1598124982125:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44674,DS-c570937f-3893-4d97-9ae6-7d9ecca8d422,DISK], DatanodeInfoWithStorage[127.0.0.1:46061,DS-f3379d25-4f0a-4200-8e58-c69aa4842d23,DISK], DatanodeInfoWithStorage[127.0.0.1:43293,DS-30c3dcd1-eec2-4662-a9ae-ca5410071483,DISK], DatanodeInfoWithStorage[127.0.0.1:38624,DS-38b09f0d-58f7-4fdf-93e6-2e1c2f212426,DISK], DatanodeInfoWithStorage[127.0.0.1:38562,DS-54c86b95-1655-4c8c-8836-494446e3454b,DISK], DatanodeInfoWithStorage[127.0.0.1:40777,DS-bbe0a9da-4bf4-4c77-a36b-487b2d223a8e,DISK], DatanodeInfoWithStorage[127.0.0.1:35787,DS-281be0e6-f0a8-4fc8-b313-6351529681f7,DISK], DatanodeInfoWithStorage[127.0.0.1:44663,DS-e45bb205-dbe6-485b-9776-094d7d34c3eb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-620845631-172.17.0.13-1598124982125:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44674,DS-c570937f-3893-4d97-9ae6-7d9ecca8d422,DISK], DatanodeInfoWithStorage[127.0.0.1:46061,DS-f3379d25-4f0a-4200-8e58-c69aa4842d23,DISK], DatanodeInfoWithStorage[127.0.0.1:43293,DS-30c3dcd1-eec2-4662-a9ae-ca5410071483,DISK], DatanodeInfoWithStorage[127.0.0.1:38624,DS-38b09f0d-58f7-4fdf-93e6-2e1c2f212426,DISK], DatanodeInfoWithStorage[127.0.0.1:38562,DS-54c86b95-1655-4c8c-8836-494446e3454b,DISK], DatanodeInfoWithStorage[127.0.0.1:40777,DS-bbe0a9da-4bf4-4c77-a36b-487b2d223a8e,DISK], DatanodeInfoWithStorage[127.0.0.1:35787,DS-281be0e6-f0a8-4fc8-b313-6351529681f7,DISK], DatanodeInfoWithStorage[127.0.0.1:44663,DS-e45bb205-dbe6-485b-9776-094d7d34c3eb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.avoid.write.stale.datanode
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-782968087-172.17.0.13-1598125059135:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40281,DS-7ad26bc4-54f5-41e5-89c5-436e2ef672be,DISK], DatanodeInfoWithStorage[127.0.0.1:41632,DS-61661e2d-d22a-4658-94c7-754653c1fa6b,DISK], DatanodeInfoWithStorage[127.0.0.1:45638,DS-5103db7f-3d5e-464d-b324-0e570324e9dd,DISK], DatanodeInfoWithStorage[127.0.0.1:42814,DS-101808aa-1f57-4bd8-8504-5d7fd282ffe0,DISK], DatanodeInfoWithStorage[127.0.0.1:36532,DS-1c4e4dd3-92e5-406a-a53a-c3a7c9dd8f2e,DISK], DatanodeInfoWithStorage[127.0.0.1:36579,DS-245034ac-7c31-4633-858f-f8a08beb5f57,DISK], DatanodeInfoWithStorage[127.0.0.1:32775,DS-67afe5df-ed1d-4be3-93ba-9e901df6ed60,DISK], DatanodeInfoWithStorage[127.0.0.1:40311,DS-1a4766ea-6483-4b40-9559-27842ddac278,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-782968087-172.17.0.13-1598125059135:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40281,DS-7ad26bc4-54f5-41e5-89c5-436e2ef672be,DISK], DatanodeInfoWithStorage[127.0.0.1:41632,DS-61661e2d-d22a-4658-94c7-754653c1fa6b,DISK], DatanodeInfoWithStorage[127.0.0.1:45638,DS-5103db7f-3d5e-464d-b324-0e570324e9dd,DISK], DatanodeInfoWithStorage[127.0.0.1:42814,DS-101808aa-1f57-4bd8-8504-5d7fd282ffe0,DISK], DatanodeInfoWithStorage[127.0.0.1:36532,DS-1c4e4dd3-92e5-406a-a53a-c3a7c9dd8f2e,DISK], DatanodeInfoWithStorage[127.0.0.1:36579,DS-245034ac-7c31-4633-858f-f8a08beb5f57,DISK], DatanodeInfoWithStorage[127.0.0.1:32775,DS-67afe5df-ed1d-4be3-93ba-9e901df6ed60,DISK], DatanodeInfoWithStorage[127.0.0.1:40311,DS-1a4766ea-6483-4b40-9559-27842ddac278,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.avoid.write.stale.datanode
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-516177470-172.17.0.13-1598125369421:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36841,DS-28741d0e-5b20-4e08-a80a-2296ab138ccd,DISK], DatanodeInfoWithStorage[127.0.0.1:39680,DS-cede4c16-b0d4-4eee-b839-3bd979de5190,DISK], DatanodeInfoWithStorage[127.0.0.1:43327,DS-6f80330b-cfc1-47ef-8d90-474e27b40067,DISK], DatanodeInfoWithStorage[127.0.0.1:42777,DS-92863874-a5a6-4341-a090-885599ce521e,DISK], DatanodeInfoWithStorage[127.0.0.1:42347,DS-8dce52bd-02e7-4a5f-a7bf-83b3be53ff5c,DISK], DatanodeInfoWithStorage[127.0.0.1:35043,DS-d44bf1fd-5e86-4ead-b69f-a6b6a2c81c94,DISK], DatanodeInfoWithStorage[127.0.0.1:44152,DS-f0134ac1-2635-4acc-a63c-cb624bce452a,DISK], DatanodeInfoWithStorage[127.0.0.1:42928,DS-8f1bd403-62bd-4322-aaae-385f238b7e56,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-516177470-172.17.0.13-1598125369421:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36841,DS-28741d0e-5b20-4e08-a80a-2296ab138ccd,DISK], DatanodeInfoWithStorage[127.0.0.1:39680,DS-cede4c16-b0d4-4eee-b839-3bd979de5190,DISK], DatanodeInfoWithStorage[127.0.0.1:43327,DS-6f80330b-cfc1-47ef-8d90-474e27b40067,DISK], DatanodeInfoWithStorage[127.0.0.1:42777,DS-92863874-a5a6-4341-a090-885599ce521e,DISK], DatanodeInfoWithStorage[127.0.0.1:42347,DS-8dce52bd-02e7-4a5f-a7bf-83b3be53ff5c,DISK], DatanodeInfoWithStorage[127.0.0.1:35043,DS-d44bf1fd-5e86-4ead-b69f-a6b6a2c81c94,DISK], DatanodeInfoWithStorage[127.0.0.1:44152,DS-f0134ac1-2635-4acc-a63c-cb624bce452a,DISK], DatanodeInfoWithStorage[127.0.0.1:42928,DS-8f1bd403-62bd-4322-aaae-385f238b7e56,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.avoid.write.stale.datanode
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1683717151-172.17.0.13-1598125503977:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41505,DS-e02fbdbe-bf5a-4cd1-8b76-20bb7a4d60bc,DISK], DatanodeInfoWithStorage[127.0.0.1:45183,DS-3fedae27-bd46-40e5-82bb-1089b192fcaa,DISK], DatanodeInfoWithStorage[127.0.0.1:43984,DS-aad8d316-5691-4e7a-9adc-9e0656121e14,DISK], DatanodeInfoWithStorage[127.0.0.1:37698,DS-3f6dc829-5ece-4bd9-b63f-efa87170f99b,DISK], DatanodeInfoWithStorage[127.0.0.1:42790,DS-d19e20e4-45fe-4c9c-85d6-4038b2b2527b,DISK], DatanodeInfoWithStorage[127.0.0.1:34893,DS-8e3ef51e-ab6e-4d7c-91b4-fe0f666c0404,DISK], DatanodeInfoWithStorage[127.0.0.1:40886,DS-112e6376-2104-4872-9444-43b6e172142b,DISK], DatanodeInfoWithStorage[127.0.0.1:33937,DS-7cc3f1ef-1a94-4d21-baeb-893ef0756e52,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1683717151-172.17.0.13-1598125503977:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41505,DS-e02fbdbe-bf5a-4cd1-8b76-20bb7a4d60bc,DISK], DatanodeInfoWithStorage[127.0.0.1:45183,DS-3fedae27-bd46-40e5-82bb-1089b192fcaa,DISK], DatanodeInfoWithStorage[127.0.0.1:43984,DS-aad8d316-5691-4e7a-9adc-9e0656121e14,DISK], DatanodeInfoWithStorage[127.0.0.1:37698,DS-3f6dc829-5ece-4bd9-b63f-efa87170f99b,DISK], DatanodeInfoWithStorage[127.0.0.1:42790,DS-d19e20e4-45fe-4c9c-85d6-4038b2b2527b,DISK], DatanodeInfoWithStorage[127.0.0.1:34893,DS-8e3ef51e-ab6e-4d7c-91b4-fe0f666c0404,DISK], DatanodeInfoWithStorage[127.0.0.1:40886,DS-112e6376-2104-4872-9444-43b6e172142b,DISK], DatanodeInfoWithStorage[127.0.0.1:33937,DS-7cc3f1ef-1a94-4d21-baeb-893ef0756e52,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.avoid.write.stale.datanode
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2037036419-172.17.0.13-1598125616746:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44202,DS-264f4187-6fb5-4130-9501-314cb8660739,DISK], DatanodeInfoWithStorage[127.0.0.1:45589,DS-7764fd2c-a970-4259-af81-3f2118c853a7,DISK], DatanodeInfoWithStorage[127.0.0.1:36220,DS-a07d5f74-71dc-4efe-8f7e-666953f2c7e8,DISK], DatanodeInfoWithStorage[127.0.0.1:40510,DS-7645f539-4678-4175-86a1-5b351b784574,DISK], DatanodeInfoWithStorage[127.0.0.1:45455,DS-a406e52a-a885-4b34-bd34-430453895ad0,DISK], DatanodeInfoWithStorage[127.0.0.1:39185,DS-40d2c8f8-0adf-46c9-bbdb-39098b03413e,DISK], DatanodeInfoWithStorage[127.0.0.1:39584,DS-8345320b-7564-4f83-a6a0-d2d6b87d5239,DISK], DatanodeInfoWithStorage[127.0.0.1:41899,DS-b887d10f-a836-47ea-be1f-95db71fd12d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2037036419-172.17.0.13-1598125616746:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44202,DS-264f4187-6fb5-4130-9501-314cb8660739,DISK], DatanodeInfoWithStorage[127.0.0.1:45589,DS-7764fd2c-a970-4259-af81-3f2118c853a7,DISK], DatanodeInfoWithStorage[127.0.0.1:36220,DS-a07d5f74-71dc-4efe-8f7e-666953f2c7e8,DISK], DatanodeInfoWithStorage[127.0.0.1:40510,DS-7645f539-4678-4175-86a1-5b351b784574,DISK], DatanodeInfoWithStorage[127.0.0.1:45455,DS-a406e52a-a885-4b34-bd34-430453895ad0,DISK], DatanodeInfoWithStorage[127.0.0.1:39185,DS-40d2c8f8-0adf-46c9-bbdb-39098b03413e,DISK], DatanodeInfoWithStorage[127.0.0.1:39584,DS-8345320b-7564-4f83-a6a0-d2d6b87d5239,DISK], DatanodeInfoWithStorage[127.0.0.1:41899,DS-b887d10f-a836-47ea-be1f-95db71fd12d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.avoid.write.stale.datanode
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-17894360-172.17.0.13-1598125788665:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42959,DS-78a31521-a600-422f-8394-2e804ccd5bd6,DISK], DatanodeInfoWithStorage[127.0.0.1:34430,DS-77cfa136-bcd2-4e3a-a247-cf64e2019586,DISK], DatanodeInfoWithStorage[127.0.0.1:45392,DS-3d111358-29ed-4ab9-ae5f-f5be84ab20f6,DISK], DatanodeInfoWithStorage[127.0.0.1:43795,DS-3cd49d2c-d402-4db3-84b0-85dde8b7ecb1,DISK], DatanodeInfoWithStorage[127.0.0.1:34725,DS-c889b426-1b57-48bd-9917-73e3f91fd334,DISK], DatanodeInfoWithStorage[127.0.0.1:44176,DS-ed4f0b3f-f880-400c-b935-7650e5434b67,DISK], DatanodeInfoWithStorage[127.0.0.1:42447,DS-5f480565-bb49-4436-bd87-b5e7edfd2c00,DISK], DatanodeInfoWithStorage[127.0.0.1:36357,DS-bdf7f0d0-84ea-4ffa-a08d-6d26f4562592,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-17894360-172.17.0.13-1598125788665:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42959,DS-78a31521-a600-422f-8394-2e804ccd5bd6,DISK], DatanodeInfoWithStorage[127.0.0.1:34430,DS-77cfa136-bcd2-4e3a-a247-cf64e2019586,DISK], DatanodeInfoWithStorage[127.0.0.1:45392,DS-3d111358-29ed-4ab9-ae5f-f5be84ab20f6,DISK], DatanodeInfoWithStorage[127.0.0.1:43795,DS-3cd49d2c-d402-4db3-84b0-85dde8b7ecb1,DISK], DatanodeInfoWithStorage[127.0.0.1:34725,DS-c889b426-1b57-48bd-9917-73e3f91fd334,DISK], DatanodeInfoWithStorage[127.0.0.1:44176,DS-ed4f0b3f-f880-400c-b935-7650e5434b67,DISK], DatanodeInfoWithStorage[127.0.0.1:42447,DS-5f480565-bb49-4436-bd87-b5e7edfd2c00,DISK], DatanodeInfoWithStorage[127.0.0.1:36357,DS-bdf7f0d0-84ea-4ffa-a08d-6d26f4562592,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.avoid.write.stale.datanode
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2021337997-172.17.0.13-1598126034563:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36334,DS-8f829bfb-e7bc-4d5b-9ea5-d40d2adbb1e2,DISK], DatanodeInfoWithStorage[127.0.0.1:34541,DS-fb108551-29ab-45c7-996d-d3d1cb95f0b5,DISK], DatanodeInfoWithStorage[127.0.0.1:46260,DS-62d55811-ead2-45eb-bd3a-e38d29a060bc,DISK], DatanodeInfoWithStorage[127.0.0.1:37025,DS-a35fa63c-bc35-4ece-85a0-4077b96ac97f,DISK], DatanodeInfoWithStorage[127.0.0.1:39632,DS-d046a06a-013c-4539-9bc5-3764ab60addc,DISK], DatanodeInfoWithStorage[127.0.0.1:37003,DS-9f435f04-929a-41f3-b7c6-1ef8c16dbf90,DISK], DatanodeInfoWithStorage[127.0.0.1:40778,DS-a93daedc-4d3f-46a5-8065-5c94d7a25834,DISK], DatanodeInfoWithStorage[127.0.0.1:38120,DS-f9c8aa54-df3b-4a81-b981-7b664b4ffbc3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2021337997-172.17.0.13-1598126034563:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36334,DS-8f829bfb-e7bc-4d5b-9ea5-d40d2adbb1e2,DISK], DatanodeInfoWithStorage[127.0.0.1:34541,DS-fb108551-29ab-45c7-996d-d3d1cb95f0b5,DISK], DatanodeInfoWithStorage[127.0.0.1:46260,DS-62d55811-ead2-45eb-bd3a-e38d29a060bc,DISK], DatanodeInfoWithStorage[127.0.0.1:37025,DS-a35fa63c-bc35-4ece-85a0-4077b96ac97f,DISK], DatanodeInfoWithStorage[127.0.0.1:39632,DS-d046a06a-013c-4539-9bc5-3764ab60addc,DISK], DatanodeInfoWithStorage[127.0.0.1:37003,DS-9f435f04-929a-41f3-b7c6-1ef8c16dbf90,DISK], DatanodeInfoWithStorage[127.0.0.1:40778,DS-a93daedc-4d3f-46a5-8065-5c94d7a25834,DISK], DatanodeInfoWithStorage[127.0.0.1:38120,DS-f9c8aa54-df3b-4a81-b981-7b664b4ffbc3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.avoid.write.stale.datanode
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-202038834-172.17.0.13-1598126196708:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46721,DS-1953667c-3b04-4ee3-acf9-9ad57bf29829,DISK], DatanodeInfoWithStorage[127.0.0.1:34729,DS-da054b82-76f2-45d0-9232-c36cba36dec4,DISK], DatanodeInfoWithStorage[127.0.0.1:43273,DS-8038e4d6-7a9e-4bc8-a631-9556ce0d6805,DISK], DatanodeInfoWithStorage[127.0.0.1:35938,DS-865d76bd-1651-4f1c-8106-ce5b9400763d,DISK], DatanodeInfoWithStorage[127.0.0.1:44871,DS-14fa4f94-2540-4658-a892-b2b3f0a0966d,DISK], DatanodeInfoWithStorage[127.0.0.1:36244,DS-54f224d8-b4f2-4157-ab17-9511ff73e333,DISK], DatanodeInfoWithStorage[127.0.0.1:43597,DS-b85ef0e4-50a2-41c1-a687-c26f32dd3758,DISK], DatanodeInfoWithStorage[127.0.0.1:37496,DS-efd1362e-4658-443c-95b0-da47036ded30,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-202038834-172.17.0.13-1598126196708:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46721,DS-1953667c-3b04-4ee3-acf9-9ad57bf29829,DISK], DatanodeInfoWithStorage[127.0.0.1:34729,DS-da054b82-76f2-45d0-9232-c36cba36dec4,DISK], DatanodeInfoWithStorage[127.0.0.1:43273,DS-8038e4d6-7a9e-4bc8-a631-9556ce0d6805,DISK], DatanodeInfoWithStorage[127.0.0.1:35938,DS-865d76bd-1651-4f1c-8106-ce5b9400763d,DISK], DatanodeInfoWithStorage[127.0.0.1:44871,DS-14fa4f94-2540-4658-a892-b2b3f0a0966d,DISK], DatanodeInfoWithStorage[127.0.0.1:36244,DS-54f224d8-b4f2-4157-ab17-9511ff73e333,DISK], DatanodeInfoWithStorage[127.0.0.1:43597,DS-b85ef0e4-50a2-41c1-a687-c26f32dd3758,DISK], DatanodeInfoWithStorage[127.0.0.1:37496,DS-efd1362e-4658-443c-95b0-da47036ded30,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.avoid.write.stale.datanode
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1541608709-172.17.0.13-1598126336479:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39775,DS-1a79541d-a02b-4b5e-8e48-3ed4126905e5,DISK], DatanodeInfoWithStorage[127.0.0.1:40548,DS-ad4cf3b3-1a10-4fc6-a351-d4e75f691c67,DISK], DatanodeInfoWithStorage[127.0.0.1:38358,DS-c2e82392-774c-4079-9747-ea8c330b1a42,DISK], DatanodeInfoWithStorage[127.0.0.1:34843,DS-3413192b-8303-46cc-aa7c-b62106826b87,DISK], DatanodeInfoWithStorage[127.0.0.1:36370,DS-da33acc4-08fd-4240-b4b8-2f97ac4f3bec,DISK], DatanodeInfoWithStorage[127.0.0.1:45806,DS-d7c70694-6a12-46fa-a542-ff5937f7d5a7,DISK], DatanodeInfoWithStorage[127.0.0.1:41659,DS-d70ca55a-1d99-4dc8-a640-52de0f7336ff,DISK], DatanodeInfoWithStorage[127.0.0.1:46687,DS-f496fabc-d82a-4a5d-9aaf-5a9f4a910459,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1541608709-172.17.0.13-1598126336479:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39775,DS-1a79541d-a02b-4b5e-8e48-3ed4126905e5,DISK], DatanodeInfoWithStorage[127.0.0.1:40548,DS-ad4cf3b3-1a10-4fc6-a351-d4e75f691c67,DISK], DatanodeInfoWithStorage[127.0.0.1:38358,DS-c2e82392-774c-4079-9747-ea8c330b1a42,DISK], DatanodeInfoWithStorage[127.0.0.1:34843,DS-3413192b-8303-46cc-aa7c-b62106826b87,DISK], DatanodeInfoWithStorage[127.0.0.1:36370,DS-da33acc4-08fd-4240-b4b8-2f97ac4f3bec,DISK], DatanodeInfoWithStorage[127.0.0.1:45806,DS-d7c70694-6a12-46fa-a542-ff5937f7d5a7,DISK], DatanodeInfoWithStorage[127.0.0.1:41659,DS-d70ca55a-1d99-4dc8-a640-52de0f7336ff,DISK], DatanodeInfoWithStorage[127.0.0.1:46687,DS-f496fabc-d82a-4a5d-9aaf-5a9f4a910459,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.avoid.write.stale.datanode
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-421682990-172.17.0.13-1598127298251:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37275,DS-f12e49c1-fea1-441b-8bc6-7e6073805762,DISK], DatanodeInfoWithStorage[127.0.0.1:44932,DS-9490fbe1-be05-4efe-b672-3399af562515,DISK], DatanodeInfoWithStorage[127.0.0.1:38310,DS-b3eaf921-d4b7-47bd-8ca0-a0f48586f220,DISK], DatanodeInfoWithStorage[127.0.0.1:41052,DS-9e59cb1a-3403-4b73-86f6-13cd3b7ee805,DISK], DatanodeInfoWithStorage[127.0.0.1:35358,DS-2e6fe2ae-4321-492f-99f0-0b67840cb964,DISK], DatanodeInfoWithStorage[127.0.0.1:44515,DS-f26db178-78e1-4dee-a6e6-29cddfb2ec4a,DISK], DatanodeInfoWithStorage[127.0.0.1:46236,DS-055edca3-6b11-4141-8523-5915a39b0f34,DISK], DatanodeInfoWithStorage[127.0.0.1:36739,DS-bf27d617-a565-4da0-88b8-c12aed686260,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-421682990-172.17.0.13-1598127298251:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37275,DS-f12e49c1-fea1-441b-8bc6-7e6073805762,DISK], DatanodeInfoWithStorage[127.0.0.1:44932,DS-9490fbe1-be05-4efe-b672-3399af562515,DISK], DatanodeInfoWithStorage[127.0.0.1:38310,DS-b3eaf921-d4b7-47bd-8ca0-a0f48586f220,DISK], DatanodeInfoWithStorage[127.0.0.1:41052,DS-9e59cb1a-3403-4b73-86f6-13cd3b7ee805,DISK], DatanodeInfoWithStorage[127.0.0.1:35358,DS-2e6fe2ae-4321-492f-99f0-0b67840cb964,DISK], DatanodeInfoWithStorage[127.0.0.1:44515,DS-f26db178-78e1-4dee-a6e6-29cddfb2ec4a,DISK], DatanodeInfoWithStorage[127.0.0.1:46236,DS-055edca3-6b11-4141-8523-5915a39b0f34,DISK], DatanodeInfoWithStorage[127.0.0.1:36739,DS-bf27d617-a565-4da0-88b8-c12aed686260,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.avoid.write.stale.datanode
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1758443050-172.17.0.13-1598127494637:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42214,DS-0d4a6077-fe27-4070-9f36-1e0da87ba4e4,DISK], DatanodeInfoWithStorage[127.0.0.1:37212,DS-659d76e7-035f-47d6-9a94-c76b51b186ce,DISK], DatanodeInfoWithStorage[127.0.0.1:46326,DS-2cdd7730-1cce-4109-922a-b798f22cba7e,DISK], DatanodeInfoWithStorage[127.0.0.1:42910,DS-3cb8e31c-171b-408b-b76a-b69d0d8ddad3,DISK], DatanodeInfoWithStorage[127.0.0.1:41223,DS-dfcb1abb-ca6b-40d1-a168-91872f94a84a,DISK], DatanodeInfoWithStorage[127.0.0.1:38732,DS-f0391f13-b8fe-4609-8ab0-4f578e0781ae,DISK], DatanodeInfoWithStorage[127.0.0.1:39287,DS-a3b5028f-0808-44f9-9281-1c44f1765fc3,DISK], DatanodeInfoWithStorage[127.0.0.1:45980,DS-2fe96e0f-0424-43d6-bd85-ae563b923901,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1758443050-172.17.0.13-1598127494637:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42214,DS-0d4a6077-fe27-4070-9f36-1e0da87ba4e4,DISK], DatanodeInfoWithStorage[127.0.0.1:37212,DS-659d76e7-035f-47d6-9a94-c76b51b186ce,DISK], DatanodeInfoWithStorage[127.0.0.1:46326,DS-2cdd7730-1cce-4109-922a-b798f22cba7e,DISK], DatanodeInfoWithStorage[127.0.0.1:42910,DS-3cb8e31c-171b-408b-b76a-b69d0d8ddad3,DISK], DatanodeInfoWithStorage[127.0.0.1:41223,DS-dfcb1abb-ca6b-40d1-a168-91872f94a84a,DISK], DatanodeInfoWithStorage[127.0.0.1:38732,DS-f0391f13-b8fe-4609-8ab0-4f578e0781ae,DISK], DatanodeInfoWithStorage[127.0.0.1:39287,DS-a3b5028f-0808-44f9-9281-1c44f1765fc3,DISK], DatanodeInfoWithStorage[127.0.0.1:45980,DS-2fe96e0f-0424-43d6-bd85-ae563b923901,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.avoid.write.stale.datanode
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-663593723-172.17.0.13-1598127770522:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35995,DS-ac67e3e3-47ac-4a14-92e3-8d52541b01fc,DISK], DatanodeInfoWithStorage[127.0.0.1:33365,DS-d9e5ad41-002d-491b-bb18-75332e3dabf2,DISK], DatanodeInfoWithStorage[127.0.0.1:37034,DS-4696990e-1358-4c5f-a975-d7af3b860541,DISK], DatanodeInfoWithStorage[127.0.0.1:38628,DS-e94bceff-1f85-4cf5-991e-0ec6be068e06,DISK], DatanodeInfoWithStorage[127.0.0.1:36409,DS-fbbb19da-03a7-4c75-b34f-b9c0f200f848,DISK], DatanodeInfoWithStorage[127.0.0.1:35179,DS-3bce4cfb-8492-4ba9-8afa-462fe01a3a37,DISK], DatanodeInfoWithStorage[127.0.0.1:37724,DS-4722c681-3bdf-42f0-9a06-e2334ebc2337,DISK], DatanodeInfoWithStorage[127.0.0.1:41921,DS-1d676a4f-12a1-4444-a1d2-a270ea49181f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-663593723-172.17.0.13-1598127770522:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35995,DS-ac67e3e3-47ac-4a14-92e3-8d52541b01fc,DISK], DatanodeInfoWithStorage[127.0.0.1:33365,DS-d9e5ad41-002d-491b-bb18-75332e3dabf2,DISK], DatanodeInfoWithStorage[127.0.0.1:37034,DS-4696990e-1358-4c5f-a975-d7af3b860541,DISK], DatanodeInfoWithStorage[127.0.0.1:38628,DS-e94bceff-1f85-4cf5-991e-0ec6be068e06,DISK], DatanodeInfoWithStorage[127.0.0.1:36409,DS-fbbb19da-03a7-4c75-b34f-b9c0f200f848,DISK], DatanodeInfoWithStorage[127.0.0.1:35179,DS-3bce4cfb-8492-4ba9-8afa-462fe01a3a37,DISK], DatanodeInfoWithStorage[127.0.0.1:37724,DS-4722c681-3bdf-42f0-9a06-e2334ebc2337,DISK], DatanodeInfoWithStorage[127.0.0.1:41921,DS-1d676a4f-12a1-4444-a1d2-a270ea49181f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.avoid.write.stale.datanode
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1845694293-172.17.0.13-1598127905633:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40275,DS-61604b33-34a7-45f4-863d-7b1101646802,DISK], DatanodeInfoWithStorage[127.0.0.1:44489,DS-2257bf2b-5f9b-4096-ad52-808e0529a40f,DISK], DatanodeInfoWithStorage[127.0.0.1:41497,DS-1c8c8854-b5ea-4748-a2a4-ee6b2013509a,DISK], DatanodeInfoWithStorage[127.0.0.1:37904,DS-0d4f7b1e-10ff-448a-945e-3ca8354d8653,DISK], DatanodeInfoWithStorage[127.0.0.1:39896,DS-9a6370e2-878a-4c35-be6b-9459ad370c1a,DISK], DatanodeInfoWithStorage[127.0.0.1:42812,DS-462074b6-d92d-42e7-bf97-03d12bfad63c,DISK], DatanodeInfoWithStorage[127.0.0.1:38454,DS-5bee6442-7033-49d9-94a7-58c317f7b7bd,DISK], DatanodeInfoWithStorage[127.0.0.1:45497,DS-e2777d74-ea02-4e49-b80e-2998191124a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1845694293-172.17.0.13-1598127905633:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40275,DS-61604b33-34a7-45f4-863d-7b1101646802,DISK], DatanodeInfoWithStorage[127.0.0.1:44489,DS-2257bf2b-5f9b-4096-ad52-808e0529a40f,DISK], DatanodeInfoWithStorage[127.0.0.1:41497,DS-1c8c8854-b5ea-4748-a2a4-ee6b2013509a,DISK], DatanodeInfoWithStorage[127.0.0.1:37904,DS-0d4f7b1e-10ff-448a-945e-3ca8354d8653,DISK], DatanodeInfoWithStorage[127.0.0.1:39896,DS-9a6370e2-878a-4c35-be6b-9459ad370c1a,DISK], DatanodeInfoWithStorage[127.0.0.1:42812,DS-462074b6-d92d-42e7-bf97-03d12bfad63c,DISK], DatanodeInfoWithStorage[127.0.0.1:38454,DS-5bee6442-7033-49d9-94a7-58c317f7b7bd,DISK], DatanodeInfoWithStorage[127.0.0.1:45497,DS-e2777d74-ea02-4e49-b80e-2998191124a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.avoid.write.stale.datanode
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-816829528-172.17.0.13-1598128105066:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36237,DS-00df7543-c1d5-4ecd-9474-2491ea106852,DISK], DatanodeInfoWithStorage[127.0.0.1:43549,DS-128618bf-763e-43be-8cb7-9985ce63b18e,DISK], DatanodeInfoWithStorage[127.0.0.1:40510,DS-79fa6f26-f37a-46a7-928e-e85ad3e7a1c0,DISK], DatanodeInfoWithStorage[127.0.0.1:37974,DS-0b28b3e2-f4b5-49c1-b1bd-817d6271b246,DISK], DatanodeInfoWithStorage[127.0.0.1:38078,DS-463957fe-bd70-4ae9-8c36-7c0cdaeb99d4,DISK], DatanodeInfoWithStorage[127.0.0.1:35337,DS-1b1b4117-0b69-459d-9525-26a99ab5ba68,DISK], DatanodeInfoWithStorage[127.0.0.1:46034,DS-2e0524e6-f813-4c09-b19b-2966f79e8513,DISK], DatanodeInfoWithStorage[127.0.0.1:35198,DS-3215ab7f-1a52-4fff-b97c-e325fc3d1778,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-816829528-172.17.0.13-1598128105066:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36237,DS-00df7543-c1d5-4ecd-9474-2491ea106852,DISK], DatanodeInfoWithStorage[127.0.0.1:43549,DS-128618bf-763e-43be-8cb7-9985ce63b18e,DISK], DatanodeInfoWithStorage[127.0.0.1:40510,DS-79fa6f26-f37a-46a7-928e-e85ad3e7a1c0,DISK], DatanodeInfoWithStorage[127.0.0.1:37974,DS-0b28b3e2-f4b5-49c1-b1bd-817d6271b246,DISK], DatanodeInfoWithStorage[127.0.0.1:38078,DS-463957fe-bd70-4ae9-8c36-7c0cdaeb99d4,DISK], DatanodeInfoWithStorage[127.0.0.1:35337,DS-1b1b4117-0b69-459d-9525-26a99ab5ba68,DISK], DatanodeInfoWithStorage[127.0.0.1:46034,DS-2e0524e6-f813-4c09-b19b-2966f79e8513,DISK], DatanodeInfoWithStorage[127.0.0.1:35198,DS-3215ab7f-1a52-4fff-b97c-e325fc3d1778,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.avoid.write.stale.datanode
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-373347974-172.17.0.13-1598128621995:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39313,DS-d00ce18c-24c7-4cd0-bf65-0cc1091d2810,DISK], DatanodeInfoWithStorage[127.0.0.1:43467,DS-d758b5e2-6ab1-435d-b365-f4b798eff0bd,DISK], DatanodeInfoWithStorage[127.0.0.1:34386,DS-0fd4f9cf-9735-47d5-860d-334644e0ba69,DISK], DatanodeInfoWithStorage[127.0.0.1:45335,DS-fec54a55-f385-40e5-a4d5-ae1917a893bf,DISK], DatanodeInfoWithStorage[127.0.0.1:38902,DS-e353d806-5f88-4f04-b380-627532ba1a31,DISK], DatanodeInfoWithStorage[127.0.0.1:39057,DS-a6e3e590-c821-47b1-b9f4-24df008bdfac,DISK], DatanodeInfoWithStorage[127.0.0.1:44692,DS-17aaedd6-8e02-4ce3-a895-a503185404fd,DISK], DatanodeInfoWithStorage[127.0.0.1:37294,DS-38428c7c-3f05-4411-92b2-04d978dc64e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-373347974-172.17.0.13-1598128621995:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39313,DS-d00ce18c-24c7-4cd0-bf65-0cc1091d2810,DISK], DatanodeInfoWithStorage[127.0.0.1:43467,DS-d758b5e2-6ab1-435d-b365-f4b798eff0bd,DISK], DatanodeInfoWithStorage[127.0.0.1:34386,DS-0fd4f9cf-9735-47d5-860d-334644e0ba69,DISK], DatanodeInfoWithStorage[127.0.0.1:45335,DS-fec54a55-f385-40e5-a4d5-ae1917a893bf,DISK], DatanodeInfoWithStorage[127.0.0.1:38902,DS-e353d806-5f88-4f04-b380-627532ba1a31,DISK], DatanodeInfoWithStorage[127.0.0.1:39057,DS-a6e3e590-c821-47b1-b9f4-24df008bdfac,DISK], DatanodeInfoWithStorage[127.0.0.1:44692,DS-17aaedd6-8e02-4ce3-a895-a503185404fd,DISK], DatanodeInfoWithStorage[127.0.0.1:37294,DS-38428c7c-3f05-4411-92b2-04d978dc64e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.avoid.write.stale.datanode
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1448027013-172.17.0.13-1598128689286:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40521,DS-e944d24b-c6a0-4bd9-91eb-366d71255c01,DISK], DatanodeInfoWithStorage[127.0.0.1:42095,DS-faef3bc8-5d41-4d4c-89a7-1915e918d15b,DISK], DatanodeInfoWithStorage[127.0.0.1:35683,DS-49cf8e1d-2cf1-4178-933f-fdf30fae29d3,DISK], DatanodeInfoWithStorage[127.0.0.1:43428,DS-d2a96eaf-9357-4f0e-a725-a5f057a78180,DISK], DatanodeInfoWithStorage[127.0.0.1:43664,DS-892ba556-1b8a-47d6-9212-f9e461829bb9,DISK], DatanodeInfoWithStorage[127.0.0.1:45807,DS-cca909f2-feb2-477e-b5f1-0b265077637d,DISK], DatanodeInfoWithStorage[127.0.0.1:44727,DS-7777278a-aa3a-48d5-b0ac-3e94fd4e6eac,DISK], DatanodeInfoWithStorage[127.0.0.1:37787,DS-8ac3bcce-66d4-4f27-a7b5-669d5dacebf1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1448027013-172.17.0.13-1598128689286:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40521,DS-e944d24b-c6a0-4bd9-91eb-366d71255c01,DISK], DatanodeInfoWithStorage[127.0.0.1:42095,DS-faef3bc8-5d41-4d4c-89a7-1915e918d15b,DISK], DatanodeInfoWithStorage[127.0.0.1:35683,DS-49cf8e1d-2cf1-4178-933f-fdf30fae29d3,DISK], DatanodeInfoWithStorage[127.0.0.1:43428,DS-d2a96eaf-9357-4f0e-a725-a5f057a78180,DISK], DatanodeInfoWithStorage[127.0.0.1:43664,DS-892ba556-1b8a-47d6-9212-f9e461829bb9,DISK], DatanodeInfoWithStorage[127.0.0.1:45807,DS-cca909f2-feb2-477e-b5f1-0b265077637d,DISK], DatanodeInfoWithStorage[127.0.0.1:44727,DS-7777278a-aa3a-48d5-b0ac-3e94fd4e6eac,DISK], DatanodeInfoWithStorage[127.0.0.1:37787,DS-8ac3bcce-66d4-4f27-a7b5-669d5dacebf1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.avoid.write.stale.datanode
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-436507955-172.17.0.13-1598129131578:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46816,DS-bdb2a542-2bbd-4954-aed3-36b58d21a382,DISK], DatanodeInfoWithStorage[127.0.0.1:45040,DS-200e06cf-0744-4597-89ef-74dfc328fc77,DISK], DatanodeInfoWithStorage[127.0.0.1:33774,DS-2d9d33f8-22b7-488a-953e-8ee4d0720255,DISK], DatanodeInfoWithStorage[127.0.0.1:44626,DS-587cb643-5f46-408a-8d2d-4a1c4cdabd25,DISK], DatanodeInfoWithStorage[127.0.0.1:32912,DS-a9e6c494-ea9e-42ea-a922-c3b1d9bfe24e,DISK], DatanodeInfoWithStorage[127.0.0.1:41491,DS-c12d674b-d797-44b4-98f5-4fc2bfb9db18,DISK], DatanodeInfoWithStorage[127.0.0.1:45072,DS-b6066d08-3b4d-489c-8ad5-d005184eb892,DISK], DatanodeInfoWithStorage[127.0.0.1:37817,DS-c578979c-6a89-4d58-ab04-7e11ae25a2f9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-436507955-172.17.0.13-1598129131578:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46816,DS-bdb2a542-2bbd-4954-aed3-36b58d21a382,DISK], DatanodeInfoWithStorage[127.0.0.1:45040,DS-200e06cf-0744-4597-89ef-74dfc328fc77,DISK], DatanodeInfoWithStorage[127.0.0.1:33774,DS-2d9d33f8-22b7-488a-953e-8ee4d0720255,DISK], DatanodeInfoWithStorage[127.0.0.1:44626,DS-587cb643-5f46-408a-8d2d-4a1c4cdabd25,DISK], DatanodeInfoWithStorage[127.0.0.1:32912,DS-a9e6c494-ea9e-42ea-a922-c3b1d9bfe24e,DISK], DatanodeInfoWithStorage[127.0.0.1:41491,DS-c12d674b-d797-44b4-98f5-4fc2bfb9db18,DISK], DatanodeInfoWithStorage[127.0.0.1:45072,DS-b6066d08-3b4d-489c-8ad5-d005184eb892,DISK], DatanodeInfoWithStorage[127.0.0.1:37817,DS-c578979c-6a89-4d58-ab04-7e11ae25a2f9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.avoid.write.stale.datanode
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1082458372-172.17.0.13-1598129172998:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40235,DS-bdbca9cb-1809-4901-8e06-e0fb81152d95,DISK], DatanodeInfoWithStorage[127.0.0.1:39635,DS-2f6e6622-bf2b-44f7-a545-ac3a864d0ac4,DISK], DatanodeInfoWithStorage[127.0.0.1:38873,DS-2c9266fd-1ac1-4754-82ff-ffef069e99dd,DISK], DatanodeInfoWithStorage[127.0.0.1:40619,DS-a1d52f59-2d6a-4097-8c70-e12cff6354f3,DISK], DatanodeInfoWithStorage[127.0.0.1:45381,DS-3a68daea-e084-450f-b14c-ff775b6fbc1a,DISK], DatanodeInfoWithStorage[127.0.0.1:42650,DS-07b352b5-b397-45df-95ba-208ca25d018e,DISK], DatanodeInfoWithStorage[127.0.0.1:43304,DS-2d453eca-2dc3-4a59-994a-91d817f9b857,DISK], DatanodeInfoWithStorage[127.0.0.1:41068,DS-fc780bae-8856-4dc0-b38f-cadb753d6341,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1082458372-172.17.0.13-1598129172998:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40235,DS-bdbca9cb-1809-4901-8e06-e0fb81152d95,DISK], DatanodeInfoWithStorage[127.0.0.1:39635,DS-2f6e6622-bf2b-44f7-a545-ac3a864d0ac4,DISK], DatanodeInfoWithStorage[127.0.0.1:38873,DS-2c9266fd-1ac1-4754-82ff-ffef069e99dd,DISK], DatanodeInfoWithStorage[127.0.0.1:40619,DS-a1d52f59-2d6a-4097-8c70-e12cff6354f3,DISK], DatanodeInfoWithStorage[127.0.0.1:45381,DS-3a68daea-e084-450f-b14c-ff775b6fbc1a,DISK], DatanodeInfoWithStorage[127.0.0.1:42650,DS-07b352b5-b397-45df-95ba-208ca25d018e,DISK], DatanodeInfoWithStorage[127.0.0.1:43304,DS-2d453eca-2dc3-4a59-994a-91d817f9b857,DISK], DatanodeInfoWithStorage[127.0.0.1:41068,DS-fc780bae-8856-4dc0-b38f-cadb753d6341,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.avoid.write.stale.datanode
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1885963269-172.17.0.13-1598129269117:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35245,DS-ee02e2ec-1535-4657-a4ab-06d15b4e68cc,DISK], DatanodeInfoWithStorage[127.0.0.1:42915,DS-8927b600-c344-4aec-9e4d-e11d48e06408,DISK], DatanodeInfoWithStorage[127.0.0.1:42874,DS-a2df7722-d18c-48da-9fce-6f5661b70e98,DISK], DatanodeInfoWithStorage[127.0.0.1:37780,DS-8195215d-ffcf-4ce0-acab-000415a5a67c,DISK], DatanodeInfoWithStorage[127.0.0.1:36100,DS-68fc6aea-89ba-49fd-bfda-90c452315f28,DISK], DatanodeInfoWithStorage[127.0.0.1:35928,DS-1b0c1612-703e-4c2f-956e-ca9f94985b00,DISK], DatanodeInfoWithStorage[127.0.0.1:42394,DS-7d68a04d-4333-449e-88b1-72cfb3f5e9db,DISK], DatanodeInfoWithStorage[127.0.0.1:39860,DS-441d1877-84ae-405e-9655-dc81cb79299b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1885963269-172.17.0.13-1598129269117:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35245,DS-ee02e2ec-1535-4657-a4ab-06d15b4e68cc,DISK], DatanodeInfoWithStorage[127.0.0.1:42915,DS-8927b600-c344-4aec-9e4d-e11d48e06408,DISK], DatanodeInfoWithStorage[127.0.0.1:42874,DS-a2df7722-d18c-48da-9fce-6f5661b70e98,DISK], DatanodeInfoWithStorage[127.0.0.1:37780,DS-8195215d-ffcf-4ce0-acab-000415a5a67c,DISK], DatanodeInfoWithStorage[127.0.0.1:36100,DS-68fc6aea-89ba-49fd-bfda-90c452315f28,DISK], DatanodeInfoWithStorage[127.0.0.1:35928,DS-1b0c1612-703e-4c2f-956e-ca9f94985b00,DISK], DatanodeInfoWithStorage[127.0.0.1:42394,DS-7d68a04d-4333-449e-88b1-72cfb3f5e9db,DISK], DatanodeInfoWithStorage[127.0.0.1:39860,DS-441d1877-84ae-405e-9655-dc81cb79299b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.avoid.write.stale.datanode
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1031533770-172.17.0.13-1598129460952:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39992,DS-46c099b6-21b2-4f85-b07d-5f06d6143ab5,DISK], DatanodeInfoWithStorage[127.0.0.1:40825,DS-a7df9abb-5b50-49bc-997f-be1b06f58750,DISK], DatanodeInfoWithStorage[127.0.0.1:36192,DS-0410e317-6db6-49de-8724-4a0c71fd424c,DISK], DatanodeInfoWithStorage[127.0.0.1:45072,DS-61f59c79-2dce-46f7-9d0b-ff121ab06056,DISK], DatanodeInfoWithStorage[127.0.0.1:40468,DS-42a60fa2-d238-4fb3-a73b-a180c8d10074,DISK], DatanodeInfoWithStorage[127.0.0.1:42002,DS-1acaa472-8390-41a9-b083-85a79c380afa,DISK], DatanodeInfoWithStorage[127.0.0.1:38281,DS-b4aef009-7727-42ba-9d56-71b01e489226,DISK], DatanodeInfoWithStorage[127.0.0.1:35728,DS-cfc96dca-24cb-484b-9736-170a8fd85f16,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1031533770-172.17.0.13-1598129460952:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39992,DS-46c099b6-21b2-4f85-b07d-5f06d6143ab5,DISK], DatanodeInfoWithStorage[127.0.0.1:40825,DS-a7df9abb-5b50-49bc-997f-be1b06f58750,DISK], DatanodeInfoWithStorage[127.0.0.1:36192,DS-0410e317-6db6-49de-8724-4a0c71fd424c,DISK], DatanodeInfoWithStorage[127.0.0.1:45072,DS-61f59c79-2dce-46f7-9d0b-ff121ab06056,DISK], DatanodeInfoWithStorage[127.0.0.1:40468,DS-42a60fa2-d238-4fb3-a73b-a180c8d10074,DISK], DatanodeInfoWithStorage[127.0.0.1:42002,DS-1acaa472-8390-41a9-b083-85a79c380afa,DISK], DatanodeInfoWithStorage[127.0.0.1:38281,DS-b4aef009-7727-42ba-9d56-71b01e489226,DISK], DatanodeInfoWithStorage[127.0.0.1:35728,DS-cfc96dca-24cb-484b-9736-170a8fd85f16,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 11 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5194
