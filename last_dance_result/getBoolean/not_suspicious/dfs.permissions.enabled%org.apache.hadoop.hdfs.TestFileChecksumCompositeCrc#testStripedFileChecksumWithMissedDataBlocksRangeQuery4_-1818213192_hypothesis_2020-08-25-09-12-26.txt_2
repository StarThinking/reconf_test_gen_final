reconf_parameter: dfs.permissions.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1681778494-172.17.0.14-1598347403212:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33659,DS-2fd93d4b-f907-42b0-b8ce-11024649ac22,DISK], DatanodeInfoWithStorage[127.0.0.1:43614,DS-44b0cd6d-3557-450f-8fa1-b9842c0e3de6,DISK], DatanodeInfoWithStorage[127.0.0.1:40056,DS-075015cd-8172-476f-9c04-7933d4453656,DISK], DatanodeInfoWithStorage[127.0.0.1:34084,DS-be1a9736-9edc-44c8-a507-2a7e7dff4c6a,DISK], DatanodeInfoWithStorage[127.0.0.1:43340,DS-4d468466-5682-484d-a637-4949b0bcf1f3,DISK], DatanodeInfoWithStorage[127.0.0.1:46053,DS-d7f4adda-0f2a-4366-8b45-d16871d398a8,DISK], DatanodeInfoWithStorage[127.0.0.1:42174,DS-fab2de0f-9a8c-4279-b2d2-3186890b3b46,DISK], DatanodeInfoWithStorage[127.0.0.1:43957,DS-5aaf766b-99b1-4696-8090-81705349cec1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1681778494-172.17.0.14-1598347403212:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33659,DS-2fd93d4b-f907-42b0-b8ce-11024649ac22,DISK], DatanodeInfoWithStorage[127.0.0.1:43614,DS-44b0cd6d-3557-450f-8fa1-b9842c0e3de6,DISK], DatanodeInfoWithStorage[127.0.0.1:40056,DS-075015cd-8172-476f-9c04-7933d4453656,DISK], DatanodeInfoWithStorage[127.0.0.1:34084,DS-be1a9736-9edc-44c8-a507-2a7e7dff4c6a,DISK], DatanodeInfoWithStorage[127.0.0.1:43340,DS-4d468466-5682-484d-a637-4949b0bcf1f3,DISK], DatanodeInfoWithStorage[127.0.0.1:46053,DS-d7f4adda-0f2a-4366-8b45-d16871d398a8,DISK], DatanodeInfoWithStorage[127.0.0.1:42174,DS-fab2de0f-9a8c-4279-b2d2-3186890b3b46,DISK], DatanodeInfoWithStorage[127.0.0.1:43957,DS-5aaf766b-99b1-4696-8090-81705349cec1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2047941175-172.17.0.14-1598347506093:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35181,DS-6925ce0b-71f5-400e-a16d-aac98250cd0d,DISK], DatanodeInfoWithStorage[127.0.0.1:41004,DS-3f32c8c2-c2a4-4854-b88a-9fcc4ebb59fd,DISK], DatanodeInfoWithStorage[127.0.0.1:40648,DS-64b80935-2cd2-49d6-80ee-ae7bcd2a801a,DISK], DatanodeInfoWithStorage[127.0.0.1:42102,DS-f2556adf-014a-40ed-90f8-974f2655278c,DISK], DatanodeInfoWithStorage[127.0.0.1:36121,DS-342234bf-87ea-4fd8-b8e1-13130ebb9141,DISK], DatanodeInfoWithStorage[127.0.0.1:46184,DS-bb3fe411-d06b-476b-ae96-8f5e510c3069,DISK], DatanodeInfoWithStorage[127.0.0.1:44488,DS-a7603312-534f-45c3-9251-04079aeb1ce1,DISK], DatanodeInfoWithStorage[127.0.0.1:46858,DS-8321d91c-437b-48d8-9da8-19dae20fd18c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2047941175-172.17.0.14-1598347506093:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35181,DS-6925ce0b-71f5-400e-a16d-aac98250cd0d,DISK], DatanodeInfoWithStorage[127.0.0.1:41004,DS-3f32c8c2-c2a4-4854-b88a-9fcc4ebb59fd,DISK], DatanodeInfoWithStorage[127.0.0.1:40648,DS-64b80935-2cd2-49d6-80ee-ae7bcd2a801a,DISK], DatanodeInfoWithStorage[127.0.0.1:42102,DS-f2556adf-014a-40ed-90f8-974f2655278c,DISK], DatanodeInfoWithStorage[127.0.0.1:36121,DS-342234bf-87ea-4fd8-b8e1-13130ebb9141,DISK], DatanodeInfoWithStorage[127.0.0.1:46184,DS-bb3fe411-d06b-476b-ae96-8f5e510c3069,DISK], DatanodeInfoWithStorage[127.0.0.1:44488,DS-a7603312-534f-45c3-9251-04079aeb1ce1,DISK], DatanodeInfoWithStorage[127.0.0.1:46858,DS-8321d91c-437b-48d8-9da8-19dae20fd18c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1823589385-172.17.0.14-1598347959427:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35053,DS-13e545b9-ab39-4c18-840b-d0a21e1b20a5,DISK], DatanodeInfoWithStorage[127.0.0.1:44281,DS-a08e02e8-4b21-4305-82af-f079857e87ba,DISK], DatanodeInfoWithStorage[127.0.0.1:43224,DS-33111357-a90e-4fa4-9b32-a76916fd851b,DISK], DatanodeInfoWithStorage[127.0.0.1:41066,DS-b7e5c441-befa-437c-9343-e2a99483433e,DISK], DatanodeInfoWithStorage[127.0.0.1:39448,DS-404a38c6-d256-4556-aa21-0500b4c79524,DISK], DatanodeInfoWithStorage[127.0.0.1:34515,DS-2ca9221e-2438-4c2d-9d6c-358156b66bab,DISK], DatanodeInfoWithStorage[127.0.0.1:32867,DS-67272f3d-e81d-40e9-9d75-bc518158a9cb,DISK], DatanodeInfoWithStorage[127.0.0.1:36299,DS-16e8a3fe-43b0-4915-a61d-444a25f16308,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1823589385-172.17.0.14-1598347959427:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35053,DS-13e545b9-ab39-4c18-840b-d0a21e1b20a5,DISK], DatanodeInfoWithStorage[127.0.0.1:44281,DS-a08e02e8-4b21-4305-82af-f079857e87ba,DISK], DatanodeInfoWithStorage[127.0.0.1:43224,DS-33111357-a90e-4fa4-9b32-a76916fd851b,DISK], DatanodeInfoWithStorage[127.0.0.1:41066,DS-b7e5c441-befa-437c-9343-e2a99483433e,DISK], DatanodeInfoWithStorage[127.0.0.1:39448,DS-404a38c6-d256-4556-aa21-0500b4c79524,DISK], DatanodeInfoWithStorage[127.0.0.1:34515,DS-2ca9221e-2438-4c2d-9d6c-358156b66bab,DISK], DatanodeInfoWithStorage[127.0.0.1:32867,DS-67272f3d-e81d-40e9-9d75-bc518158a9cb,DISK], DatanodeInfoWithStorage[127.0.0.1:36299,DS-16e8a3fe-43b0-4915-a61d-444a25f16308,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-204130256-172.17.0.14-1598348284184:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37513,DS-5d972d77-11d1-4f08-9bbc-addb27b930df,DISK], DatanodeInfoWithStorage[127.0.0.1:46258,DS-aa83eeb9-cfca-4cea-9a0d-637b14d36bd4,DISK], DatanodeInfoWithStorage[127.0.0.1:36998,DS-9e790280-cadb-44f3-9ae3-ab2b5a04db1b,DISK], DatanodeInfoWithStorage[127.0.0.1:42539,DS-e0b3636d-faef-4131-b85f-9ea9918a8545,DISK], DatanodeInfoWithStorage[127.0.0.1:34313,DS-91a9858c-4c29-47d4-aaee-1339c6a6dad5,DISK], DatanodeInfoWithStorage[127.0.0.1:38751,DS-1ed15ba2-0661-486b-bb09-e1f038a2b344,DISK], DatanodeInfoWithStorage[127.0.0.1:38711,DS-5d42c96c-2586-4c06-ac20-0c08df2b8d8e,DISK], DatanodeInfoWithStorage[127.0.0.1:45520,DS-c5a2032e-c22d-488f-b010-8dd2539855eb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-204130256-172.17.0.14-1598348284184:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37513,DS-5d972d77-11d1-4f08-9bbc-addb27b930df,DISK], DatanodeInfoWithStorage[127.0.0.1:46258,DS-aa83eeb9-cfca-4cea-9a0d-637b14d36bd4,DISK], DatanodeInfoWithStorage[127.0.0.1:36998,DS-9e790280-cadb-44f3-9ae3-ab2b5a04db1b,DISK], DatanodeInfoWithStorage[127.0.0.1:42539,DS-e0b3636d-faef-4131-b85f-9ea9918a8545,DISK], DatanodeInfoWithStorage[127.0.0.1:34313,DS-91a9858c-4c29-47d4-aaee-1339c6a6dad5,DISK], DatanodeInfoWithStorage[127.0.0.1:38751,DS-1ed15ba2-0661-486b-bb09-e1f038a2b344,DISK], DatanodeInfoWithStorage[127.0.0.1:38711,DS-5d42c96c-2586-4c06-ac20-0c08df2b8d8e,DISK], DatanodeInfoWithStorage[127.0.0.1:45520,DS-c5a2032e-c22d-488f-b010-8dd2539855eb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1918245370-172.17.0.14-1598348751477:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43125,DS-c4ea64d5-e257-400b-8011-a9d1acf5414b,DISK], DatanodeInfoWithStorage[127.0.0.1:41052,DS-137da329-3c1c-43e3-bdd4-d014951adb81,DISK], DatanodeInfoWithStorage[127.0.0.1:45110,DS-1fdc987d-e6bc-4487-8b84-d7965e50de4e,DISK], DatanodeInfoWithStorage[127.0.0.1:36366,DS-9cf5ad5e-8a92-4908-a8b2-e31807392427,DISK], DatanodeInfoWithStorage[127.0.0.1:41479,DS-5953629e-f8a1-4672-a1c7-4bfc03c55286,DISK], DatanodeInfoWithStorage[127.0.0.1:35412,DS-123cf18a-dba6-4fac-9ef0-660085918428,DISK], DatanodeInfoWithStorage[127.0.0.1:38001,DS-0b40dc3e-14e0-4e9a-8191-3a8b70c18838,DISK], DatanodeInfoWithStorage[127.0.0.1:41947,DS-59e0b96b-3e2a-4162-adf4-df73f89726ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1918245370-172.17.0.14-1598348751477:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43125,DS-c4ea64d5-e257-400b-8011-a9d1acf5414b,DISK], DatanodeInfoWithStorage[127.0.0.1:41052,DS-137da329-3c1c-43e3-bdd4-d014951adb81,DISK], DatanodeInfoWithStorage[127.0.0.1:45110,DS-1fdc987d-e6bc-4487-8b84-d7965e50de4e,DISK], DatanodeInfoWithStorage[127.0.0.1:36366,DS-9cf5ad5e-8a92-4908-a8b2-e31807392427,DISK], DatanodeInfoWithStorage[127.0.0.1:41479,DS-5953629e-f8a1-4672-a1c7-4bfc03c55286,DISK], DatanodeInfoWithStorage[127.0.0.1:35412,DS-123cf18a-dba6-4fac-9ef0-660085918428,DISK], DatanodeInfoWithStorage[127.0.0.1:38001,DS-0b40dc3e-14e0-4e9a-8191-3a8b70c18838,DISK], DatanodeInfoWithStorage[127.0.0.1:41947,DS-59e0b96b-3e2a-4162-adf4-df73f89726ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-907796228-172.17.0.14-1598348823452:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37845,DS-41ec9f68-53c7-4d09-a99b-c925e20d7e46,DISK], DatanodeInfoWithStorage[127.0.0.1:38930,DS-3dee7b92-a51f-45f2-9ece-4b515a4fc54f,DISK], DatanodeInfoWithStorage[127.0.0.1:32847,DS-5461d20e-98c4-4ef8-a52b-30323b898fd4,DISK], DatanodeInfoWithStorage[127.0.0.1:36906,DS-74be8ee4-a022-446c-a335-46afba31a25c,DISK], DatanodeInfoWithStorage[127.0.0.1:40517,DS-fd106119-71ce-4330-8224-dd9e630a6b67,DISK], DatanodeInfoWithStorage[127.0.0.1:46455,DS-ffeb6596-5345-40cf-93b3-61a1afbb0362,DISK], DatanodeInfoWithStorage[127.0.0.1:42882,DS-4d663870-d2a9-4af8-a89c-09bb5bb78eea,DISK], DatanodeInfoWithStorage[127.0.0.1:42129,DS-93443b22-11a9-48ec-8bcb-7c14ecde545f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-907796228-172.17.0.14-1598348823452:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37845,DS-41ec9f68-53c7-4d09-a99b-c925e20d7e46,DISK], DatanodeInfoWithStorage[127.0.0.1:38930,DS-3dee7b92-a51f-45f2-9ece-4b515a4fc54f,DISK], DatanodeInfoWithStorage[127.0.0.1:32847,DS-5461d20e-98c4-4ef8-a52b-30323b898fd4,DISK], DatanodeInfoWithStorage[127.0.0.1:36906,DS-74be8ee4-a022-446c-a335-46afba31a25c,DISK], DatanodeInfoWithStorage[127.0.0.1:40517,DS-fd106119-71ce-4330-8224-dd9e630a6b67,DISK], DatanodeInfoWithStorage[127.0.0.1:46455,DS-ffeb6596-5345-40cf-93b3-61a1afbb0362,DISK], DatanodeInfoWithStorage[127.0.0.1:42882,DS-4d663870-d2a9-4af8-a89c-09bb5bb78eea,DISK], DatanodeInfoWithStorage[127.0.0.1:42129,DS-93443b22-11a9-48ec-8bcb-7c14ecde545f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-388628284-172.17.0.14-1598348860088:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38997,DS-a9491688-e028-4f9c-a149-1a04375a96dd,DISK], DatanodeInfoWithStorage[127.0.0.1:44155,DS-f148909f-2411-435a-9152-f8265f424ac9,DISK], DatanodeInfoWithStorage[127.0.0.1:42581,DS-afa08ab4-7ed3-4610-8183-0aa77a6e07ed,DISK], DatanodeInfoWithStorage[127.0.0.1:44631,DS-89520bdf-484a-4f1e-b62b-17e3af785b2e,DISK], DatanodeInfoWithStorage[127.0.0.1:36115,DS-48968c1e-5b79-420b-9eac-dda56b5b8cc8,DISK], DatanodeInfoWithStorage[127.0.0.1:44040,DS-34da3b47-a252-43a9-9967-e52d7b515ae0,DISK], DatanodeInfoWithStorage[127.0.0.1:38907,DS-a54f8db1-39ff-4db7-9689-6d8ba1f1d00d,DISK], DatanodeInfoWithStorage[127.0.0.1:42148,DS-70c313b3-38a2-4cc8-9049-eaa0b962cd53,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-388628284-172.17.0.14-1598348860088:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38997,DS-a9491688-e028-4f9c-a149-1a04375a96dd,DISK], DatanodeInfoWithStorage[127.0.0.1:44155,DS-f148909f-2411-435a-9152-f8265f424ac9,DISK], DatanodeInfoWithStorage[127.0.0.1:42581,DS-afa08ab4-7ed3-4610-8183-0aa77a6e07ed,DISK], DatanodeInfoWithStorage[127.0.0.1:44631,DS-89520bdf-484a-4f1e-b62b-17e3af785b2e,DISK], DatanodeInfoWithStorage[127.0.0.1:36115,DS-48968c1e-5b79-420b-9eac-dda56b5b8cc8,DISK], DatanodeInfoWithStorage[127.0.0.1:44040,DS-34da3b47-a252-43a9-9967-e52d7b515ae0,DISK], DatanodeInfoWithStorage[127.0.0.1:38907,DS-a54f8db1-39ff-4db7-9689-6d8ba1f1d00d,DISK], DatanodeInfoWithStorage[127.0.0.1:42148,DS-70c313b3-38a2-4cc8-9049-eaa0b962cd53,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-153622210-172.17.0.14-1598349217370:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41202,DS-f38061a4-342e-4f71-bd06-3d9aed2bc701,DISK], DatanodeInfoWithStorage[127.0.0.1:36499,DS-b4666397-2e14-425d-96fc-5dda547d929d,DISK], DatanodeInfoWithStorage[127.0.0.1:34922,DS-115a1f65-bbf5-41b1-92f1-076b82b9bcfc,DISK], DatanodeInfoWithStorage[127.0.0.1:41877,DS-08270711-a451-4a61-91da-7fe5cf9b4827,DISK], DatanodeInfoWithStorage[127.0.0.1:33076,DS-7a522b97-bf33-4fe0-8093-d96b79f47701,DISK], DatanodeInfoWithStorage[127.0.0.1:34061,DS-e39392e1-f888-4e22-967e-d5de25c8ab91,DISK], DatanodeInfoWithStorage[127.0.0.1:45182,DS-af150a65-37c0-434b-94bf-5a50fbea08e8,DISK], DatanodeInfoWithStorage[127.0.0.1:38854,DS-5de117e7-a00f-4eeb-b88b-36a7830b43a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-153622210-172.17.0.14-1598349217370:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41202,DS-f38061a4-342e-4f71-bd06-3d9aed2bc701,DISK], DatanodeInfoWithStorage[127.0.0.1:36499,DS-b4666397-2e14-425d-96fc-5dda547d929d,DISK], DatanodeInfoWithStorage[127.0.0.1:34922,DS-115a1f65-bbf5-41b1-92f1-076b82b9bcfc,DISK], DatanodeInfoWithStorage[127.0.0.1:41877,DS-08270711-a451-4a61-91da-7fe5cf9b4827,DISK], DatanodeInfoWithStorage[127.0.0.1:33076,DS-7a522b97-bf33-4fe0-8093-d96b79f47701,DISK], DatanodeInfoWithStorage[127.0.0.1:34061,DS-e39392e1-f888-4e22-967e-d5de25c8ab91,DISK], DatanodeInfoWithStorage[127.0.0.1:45182,DS-af150a65-37c0-434b-94bf-5a50fbea08e8,DISK], DatanodeInfoWithStorage[127.0.0.1:38854,DS-5de117e7-a00f-4eeb-b88b-36a7830b43a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-477950279-172.17.0.14-1598349328475:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43613,DS-1105c01a-59ce-4a2c-95de-8be12b258c66,DISK], DatanodeInfoWithStorage[127.0.0.1:40316,DS-f423b5b5-2550-42eb-882f-7c6bb908b5c4,DISK], DatanodeInfoWithStorage[127.0.0.1:36193,DS-3d9b9e1f-cdc1-4819-816c-25bd793447d8,DISK], DatanodeInfoWithStorage[127.0.0.1:42992,DS-be4ded4c-7ae3-422a-8c48-f7a62d242931,DISK], DatanodeInfoWithStorage[127.0.0.1:37794,DS-bcaa8259-4655-4516-961d-9d9c9aee7935,DISK], DatanodeInfoWithStorage[127.0.0.1:40518,DS-d59c4e19-8df0-4d4b-b6b7-4f8d3a2839b0,DISK], DatanodeInfoWithStorage[127.0.0.1:44147,DS-67b714dc-3484-4fbb-a1b5-0839d2057f32,DISK], DatanodeInfoWithStorage[127.0.0.1:33414,DS-7fef769d-5077-4c22-b7fe-2b7d3874dba9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-477950279-172.17.0.14-1598349328475:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43613,DS-1105c01a-59ce-4a2c-95de-8be12b258c66,DISK], DatanodeInfoWithStorage[127.0.0.1:40316,DS-f423b5b5-2550-42eb-882f-7c6bb908b5c4,DISK], DatanodeInfoWithStorage[127.0.0.1:36193,DS-3d9b9e1f-cdc1-4819-816c-25bd793447d8,DISK], DatanodeInfoWithStorage[127.0.0.1:42992,DS-be4ded4c-7ae3-422a-8c48-f7a62d242931,DISK], DatanodeInfoWithStorage[127.0.0.1:37794,DS-bcaa8259-4655-4516-961d-9d9c9aee7935,DISK], DatanodeInfoWithStorage[127.0.0.1:40518,DS-d59c4e19-8df0-4d4b-b6b7-4f8d3a2839b0,DISK], DatanodeInfoWithStorage[127.0.0.1:44147,DS-67b714dc-3484-4fbb-a1b5-0839d2057f32,DISK], DatanodeInfoWithStorage[127.0.0.1:33414,DS-7fef769d-5077-4c22-b7fe-2b7d3874dba9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1518076983-172.17.0.14-1598349645690:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34778,DS-b7b945c6-dea8-4364-976f-5e9e55748362,DISK], DatanodeInfoWithStorage[127.0.0.1:40957,DS-bf299dd7-772d-4ab4-90f5-61a6299778f8,DISK], DatanodeInfoWithStorage[127.0.0.1:46320,DS-1d24c931-262a-4279-99da-c186d66d6f2d,DISK], DatanodeInfoWithStorage[127.0.0.1:33209,DS-451dcfd0-9f31-4fbe-87d6-991643794cc0,DISK], DatanodeInfoWithStorage[127.0.0.1:45455,DS-796fa671-b01f-4ebd-8bf3-a3efde4b94ef,DISK], DatanodeInfoWithStorage[127.0.0.1:33965,DS-51b03162-023f-42ea-be6a-99588639d199,DISK], DatanodeInfoWithStorage[127.0.0.1:41479,DS-b49e3ced-bcaf-46b6-bfb2-24dfbc8f0a2d,DISK], DatanodeInfoWithStorage[127.0.0.1:46163,DS-d3aed12e-96ae-41e4-8e38-7f8589eac827,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1518076983-172.17.0.14-1598349645690:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34778,DS-b7b945c6-dea8-4364-976f-5e9e55748362,DISK], DatanodeInfoWithStorage[127.0.0.1:40957,DS-bf299dd7-772d-4ab4-90f5-61a6299778f8,DISK], DatanodeInfoWithStorage[127.0.0.1:46320,DS-1d24c931-262a-4279-99da-c186d66d6f2d,DISK], DatanodeInfoWithStorage[127.0.0.1:33209,DS-451dcfd0-9f31-4fbe-87d6-991643794cc0,DISK], DatanodeInfoWithStorage[127.0.0.1:45455,DS-796fa671-b01f-4ebd-8bf3-a3efde4b94ef,DISK], DatanodeInfoWithStorage[127.0.0.1:33965,DS-51b03162-023f-42ea-be6a-99588639d199,DISK], DatanodeInfoWithStorage[127.0.0.1:41479,DS-b49e3ced-bcaf-46b6-bfb2-24dfbc8f0a2d,DISK], DatanodeInfoWithStorage[127.0.0.1:46163,DS-d3aed12e-96ae-41e4-8e38-7f8589eac827,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-251084111-172.17.0.14-1598350229702:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43838,DS-69d5f15c-ad59-4d9b-9b16-4069a0453e49,DISK], DatanodeInfoWithStorage[127.0.0.1:36067,DS-2e4d104c-a8f8-4356-89ed-c4fc71d9c167,DISK], DatanodeInfoWithStorage[127.0.0.1:40718,DS-b1ab9a7c-2ad0-4083-9854-f8942df528ab,DISK], DatanodeInfoWithStorage[127.0.0.1:46585,DS-1c3e2d56-48b2-4144-99f6-47757db32792,DISK], DatanodeInfoWithStorage[127.0.0.1:40877,DS-316cff71-656a-4362-81af-792031786e0b,DISK], DatanodeInfoWithStorage[127.0.0.1:36478,DS-239608fb-7ed6-4a2c-a9a1-9e6b9d6c2935,DISK], DatanodeInfoWithStorage[127.0.0.1:33613,DS-66b517aa-5b2e-48c2-b900-7f6ed78de7ad,DISK], DatanodeInfoWithStorage[127.0.0.1:38307,DS-5fd19f49-f14b-4994-a4fa-1a77568b4d80,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-251084111-172.17.0.14-1598350229702:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43838,DS-69d5f15c-ad59-4d9b-9b16-4069a0453e49,DISK], DatanodeInfoWithStorage[127.0.0.1:36067,DS-2e4d104c-a8f8-4356-89ed-c4fc71d9c167,DISK], DatanodeInfoWithStorage[127.0.0.1:40718,DS-b1ab9a7c-2ad0-4083-9854-f8942df528ab,DISK], DatanodeInfoWithStorage[127.0.0.1:46585,DS-1c3e2d56-48b2-4144-99f6-47757db32792,DISK], DatanodeInfoWithStorage[127.0.0.1:40877,DS-316cff71-656a-4362-81af-792031786e0b,DISK], DatanodeInfoWithStorage[127.0.0.1:36478,DS-239608fb-7ed6-4a2c-a9a1-9e6b9d6c2935,DISK], DatanodeInfoWithStorage[127.0.0.1:33613,DS-66b517aa-5b2e-48c2-b900-7f6ed78de7ad,DISK], DatanodeInfoWithStorage[127.0.0.1:38307,DS-5fd19f49-f14b-4994-a4fa-1a77568b4d80,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1600027903-172.17.0.14-1598350493011:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38114,DS-b0d45f36-242c-459e-82e2-819fce3ad4da,DISK], DatanodeInfoWithStorage[127.0.0.1:41218,DS-f1507da4-c38f-46d7-8efd-f5f67fe12562,DISK], DatanodeInfoWithStorage[127.0.0.1:38375,DS-1b981788-c25b-4cb5-9c13-8dfa5f1d8142,DISK], DatanodeInfoWithStorage[127.0.0.1:41250,DS-feb57ea3-50ac-4ec9-8771-87ec5c379131,DISK], DatanodeInfoWithStorage[127.0.0.1:45936,DS-8fa34596-721e-4a9e-b46f-054c66ed7467,DISK], DatanodeInfoWithStorage[127.0.0.1:36708,DS-2f6925b5-2997-4011-8c52-b0a893e66341,DISK], DatanodeInfoWithStorage[127.0.0.1:34280,DS-ac95caa0-8700-4361-899f-4b335011b0f7,DISK], DatanodeInfoWithStorage[127.0.0.1:37472,DS-4bf67e0f-5f09-4a03-969a-2a7958e1a8c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1600027903-172.17.0.14-1598350493011:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38114,DS-b0d45f36-242c-459e-82e2-819fce3ad4da,DISK], DatanodeInfoWithStorage[127.0.0.1:41218,DS-f1507da4-c38f-46d7-8efd-f5f67fe12562,DISK], DatanodeInfoWithStorage[127.0.0.1:38375,DS-1b981788-c25b-4cb5-9c13-8dfa5f1d8142,DISK], DatanodeInfoWithStorage[127.0.0.1:41250,DS-feb57ea3-50ac-4ec9-8771-87ec5c379131,DISK], DatanodeInfoWithStorage[127.0.0.1:45936,DS-8fa34596-721e-4a9e-b46f-054c66ed7467,DISK], DatanodeInfoWithStorage[127.0.0.1:36708,DS-2f6925b5-2997-4011-8c52-b0a893e66341,DISK], DatanodeInfoWithStorage[127.0.0.1:34280,DS-ac95caa0-8700-4361-899f-4b335011b0f7,DISK], DatanodeInfoWithStorage[127.0.0.1:37472,DS-4bf67e0f-5f09-4a03-969a-2a7958e1a8c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1487283297-172.17.0.14-1598350599740:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33589,DS-0f5f8141-aa26-4fd9-8230-69a158a291e3,DISK], DatanodeInfoWithStorage[127.0.0.1:43281,DS-f14352ac-bfe9-422e-838f-42bf6a9b0a26,DISK], DatanodeInfoWithStorage[127.0.0.1:46733,DS-79bf549f-fed1-4fec-a01d-c2e36528f8a2,DISK], DatanodeInfoWithStorage[127.0.0.1:41377,DS-76dc53ab-9ca7-4cf4-b2c5-05192ea30d0f,DISK], DatanodeInfoWithStorage[127.0.0.1:46182,DS-3f60f420-e043-49db-81fc-1ec9470a8f87,DISK], DatanodeInfoWithStorage[127.0.0.1:36670,DS-71067623-4549-429a-a70f-89cee29a289b,DISK], DatanodeInfoWithStorage[127.0.0.1:36535,DS-47cf4d84-2d0e-4587-be13-b22c9e5e9528,DISK], DatanodeInfoWithStorage[127.0.0.1:39923,DS-a213cb8b-177d-4cef-a771-caba08b5939b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1487283297-172.17.0.14-1598350599740:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33589,DS-0f5f8141-aa26-4fd9-8230-69a158a291e3,DISK], DatanodeInfoWithStorage[127.0.0.1:43281,DS-f14352ac-bfe9-422e-838f-42bf6a9b0a26,DISK], DatanodeInfoWithStorage[127.0.0.1:46733,DS-79bf549f-fed1-4fec-a01d-c2e36528f8a2,DISK], DatanodeInfoWithStorage[127.0.0.1:41377,DS-76dc53ab-9ca7-4cf4-b2c5-05192ea30d0f,DISK], DatanodeInfoWithStorage[127.0.0.1:46182,DS-3f60f420-e043-49db-81fc-1ec9470a8f87,DISK], DatanodeInfoWithStorage[127.0.0.1:36670,DS-71067623-4549-429a-a70f-89cee29a289b,DISK], DatanodeInfoWithStorage[127.0.0.1:36535,DS-47cf4d84-2d0e-4587-be13-b22c9e5e9528,DISK], DatanodeInfoWithStorage[127.0.0.1:39923,DS-a213cb8b-177d-4cef-a771-caba08b5939b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1791519685-172.17.0.14-1598350938805:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40873,DS-dd356544-499e-4e97-a0c4-cdd000a3450c,DISK], DatanodeInfoWithStorage[127.0.0.1:38127,DS-2f5f48da-fb30-4e6a-9688-6fcd1705c340,DISK], DatanodeInfoWithStorage[127.0.0.1:34314,DS-a7bc71f8-6562-484d-acdd-694e3239c34f,DISK], DatanodeInfoWithStorage[127.0.0.1:35401,DS-7559c86e-c388-4576-b8a2-5f54734b4bc3,DISK], DatanodeInfoWithStorage[127.0.0.1:35387,DS-6d5d72f8-cff8-486b-a091-399b21b1653b,DISK], DatanodeInfoWithStorage[127.0.0.1:34534,DS-0294d8e1-6416-4358-8368-b25dd88a9567,DISK], DatanodeInfoWithStorage[127.0.0.1:42991,DS-c9af2604-68dd-4d3a-ade6-12719cf5eacb,DISK], DatanodeInfoWithStorage[127.0.0.1:33055,DS-130e20de-414c-4b0d-9ff2-3f43f5a35960,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1791519685-172.17.0.14-1598350938805:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40873,DS-dd356544-499e-4e97-a0c4-cdd000a3450c,DISK], DatanodeInfoWithStorage[127.0.0.1:38127,DS-2f5f48da-fb30-4e6a-9688-6fcd1705c340,DISK], DatanodeInfoWithStorage[127.0.0.1:34314,DS-a7bc71f8-6562-484d-acdd-694e3239c34f,DISK], DatanodeInfoWithStorage[127.0.0.1:35401,DS-7559c86e-c388-4576-b8a2-5f54734b4bc3,DISK], DatanodeInfoWithStorage[127.0.0.1:35387,DS-6d5d72f8-cff8-486b-a091-399b21b1653b,DISK], DatanodeInfoWithStorage[127.0.0.1:34534,DS-0294d8e1-6416-4358-8368-b25dd88a9567,DISK], DatanodeInfoWithStorage[127.0.0.1:42991,DS-c9af2604-68dd-4d3a-ade6-12719cf5eacb,DISK], DatanodeInfoWithStorage[127.0.0.1:33055,DS-130e20de-414c-4b0d-9ff2-3f43f5a35960,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-950177886-172.17.0.14-1598351594184:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44748,DS-bb0e98ce-d7f0-452b-87b0-02ec1a7b7880,DISK], DatanodeInfoWithStorage[127.0.0.1:45278,DS-419b39dd-7935-4c16-992e-01e89dd40dd0,DISK], DatanodeInfoWithStorage[127.0.0.1:38534,DS-b83f67a1-2f20-485e-aa8f-1a4830009400,DISK], DatanodeInfoWithStorage[127.0.0.1:33456,DS-44af9e37-85bb-4eae-9ae5-52425b18f920,DISK], DatanodeInfoWithStorage[127.0.0.1:41769,DS-ccb44716-08a9-49e0-a1d2-8005d405ff4a,DISK], DatanodeInfoWithStorage[127.0.0.1:45386,DS-7e922e30-8b6b-4de0-82e5-a614f8d52557,DISK], DatanodeInfoWithStorage[127.0.0.1:46038,DS-e9374ee6-cf36-4e77-9552-b05eaee135d8,DISK], DatanodeInfoWithStorage[127.0.0.1:38616,DS-50da3e59-f998-4965-9459-a8d74bb07774,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-950177886-172.17.0.14-1598351594184:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44748,DS-bb0e98ce-d7f0-452b-87b0-02ec1a7b7880,DISK], DatanodeInfoWithStorage[127.0.0.1:45278,DS-419b39dd-7935-4c16-992e-01e89dd40dd0,DISK], DatanodeInfoWithStorage[127.0.0.1:38534,DS-b83f67a1-2f20-485e-aa8f-1a4830009400,DISK], DatanodeInfoWithStorage[127.0.0.1:33456,DS-44af9e37-85bb-4eae-9ae5-52425b18f920,DISK], DatanodeInfoWithStorage[127.0.0.1:41769,DS-ccb44716-08a9-49e0-a1d2-8005d405ff4a,DISK], DatanodeInfoWithStorage[127.0.0.1:45386,DS-7e922e30-8b6b-4de0-82e5-a614f8d52557,DISK], DatanodeInfoWithStorage[127.0.0.1:46038,DS-e9374ee6-cf36-4e77-9552-b05eaee135d8,DISK], DatanodeInfoWithStorage[127.0.0.1:38616,DS-50da3e59-f998-4965-9459-a8d74bb07774,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1805606070-172.17.0.14-1598351780368:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45085,DS-95b4c70c-051d-49b5-8141-99cf6b192041,DISK], DatanodeInfoWithStorage[127.0.0.1:33703,DS-aed0ce5b-e9d5-41c8-bdfb-f94a643d5c32,DISK], DatanodeInfoWithStorage[127.0.0.1:40189,DS-72702092-1e8c-4eb9-967f-ec87e07b694c,DISK], DatanodeInfoWithStorage[127.0.0.1:38948,DS-b3259da1-f1aa-47ec-b5f3-df48a5bc8d18,DISK], DatanodeInfoWithStorage[127.0.0.1:46842,DS-4fe769f7-de12-4308-9929-50140d3195af,DISK], DatanodeInfoWithStorage[127.0.0.1:33717,DS-453719fe-2197-49d3-be56-ede9d15da945,DISK], DatanodeInfoWithStorage[127.0.0.1:40378,DS-f7091652-f75b-4814-bb0e-67ecd449badc,DISK], DatanodeInfoWithStorage[127.0.0.1:39777,DS-1369b486-aa9c-412a-ba66-dd2af4776332,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1805606070-172.17.0.14-1598351780368:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45085,DS-95b4c70c-051d-49b5-8141-99cf6b192041,DISK], DatanodeInfoWithStorage[127.0.0.1:33703,DS-aed0ce5b-e9d5-41c8-bdfb-f94a643d5c32,DISK], DatanodeInfoWithStorage[127.0.0.1:40189,DS-72702092-1e8c-4eb9-967f-ec87e07b694c,DISK], DatanodeInfoWithStorage[127.0.0.1:38948,DS-b3259da1-f1aa-47ec-b5f3-df48a5bc8d18,DISK], DatanodeInfoWithStorage[127.0.0.1:46842,DS-4fe769f7-de12-4308-9929-50140d3195af,DISK], DatanodeInfoWithStorage[127.0.0.1:33717,DS-453719fe-2197-49d3-be56-ede9d15da945,DISK], DatanodeInfoWithStorage[127.0.0.1:40378,DS-f7091652-f75b-4814-bb0e-67ecd449badc,DISK], DatanodeInfoWithStorage[127.0.0.1:39777,DS-1369b486-aa9c-412a-ba66-dd2af4776332,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2135615748-172.17.0.14-1598351855540:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45807,DS-f3156d23-a4d9-4579-8ea9-d733fe67f646,DISK], DatanodeInfoWithStorage[127.0.0.1:38117,DS-bd774fb8-6940-49c3-8739-8d3e91267caa,DISK], DatanodeInfoWithStorage[127.0.0.1:44330,DS-fc234169-fe6c-48a5-88bd-c7b2a5059ff7,DISK], DatanodeInfoWithStorage[127.0.0.1:39708,DS-94e1dbf1-4736-47a7-9996-7c9dc257aea8,DISK], DatanodeInfoWithStorage[127.0.0.1:33072,DS-1561f3f4-e789-474f-892e-25bb93b3cdbf,DISK], DatanodeInfoWithStorage[127.0.0.1:46683,DS-2bb206df-b42d-4d6a-9920-f10343449d66,DISK], DatanodeInfoWithStorage[127.0.0.1:35559,DS-1a54a421-0917-42ef-845a-ef3b3078e427,DISK], DatanodeInfoWithStorage[127.0.0.1:44098,DS-82b9e848-6a83-46a4-a5d2-713153ba707a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2135615748-172.17.0.14-1598351855540:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45807,DS-f3156d23-a4d9-4579-8ea9-d733fe67f646,DISK], DatanodeInfoWithStorage[127.0.0.1:38117,DS-bd774fb8-6940-49c3-8739-8d3e91267caa,DISK], DatanodeInfoWithStorage[127.0.0.1:44330,DS-fc234169-fe6c-48a5-88bd-c7b2a5059ff7,DISK], DatanodeInfoWithStorage[127.0.0.1:39708,DS-94e1dbf1-4736-47a7-9996-7c9dc257aea8,DISK], DatanodeInfoWithStorage[127.0.0.1:33072,DS-1561f3f4-e789-474f-892e-25bb93b3cdbf,DISK], DatanodeInfoWithStorage[127.0.0.1:46683,DS-2bb206df-b42d-4d6a-9920-f10343449d66,DISK], DatanodeInfoWithStorage[127.0.0.1:35559,DS-1a54a421-0917-42ef-845a-ef3b3078e427,DISK], DatanodeInfoWithStorage[127.0.0.1:44098,DS-82b9e848-6a83-46a4-a5d2-713153ba707a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5504
