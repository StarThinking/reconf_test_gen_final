reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1131447786-172.17.0.13-1598121903904:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37827,DS-d593e482-a387-45e1-bc4c-c56e89d99692,DISK], DatanodeInfoWithStorage[127.0.0.1:37257,DS-6d09acdd-e3e6-4bb0-958f-ae18b405b860,DISK], DatanodeInfoWithStorage[127.0.0.1:45949,DS-0fbdc978-4260-4ef9-ad81-a382a6debbd6,DISK], DatanodeInfoWithStorage[127.0.0.1:37795,DS-6ba6ce18-943d-4085-ba62-9a3b0bc610fc,DISK], DatanodeInfoWithStorage[127.0.0.1:46477,DS-4990dc1e-4249-48ec-a369-216435ac0175,DISK], DatanodeInfoWithStorage[127.0.0.1:45083,DS-36c2c6c7-2e22-428a-89db-356a0a540826,DISK], DatanodeInfoWithStorage[127.0.0.1:34159,DS-9f3ecabe-31a6-4a38-978d-c4f61469c948,DISK], DatanodeInfoWithStorage[127.0.0.1:46498,DS-acc581d0-843f-4847-9129-cec59e5114b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1131447786-172.17.0.13-1598121903904:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37827,DS-d593e482-a387-45e1-bc4c-c56e89d99692,DISK], DatanodeInfoWithStorage[127.0.0.1:37257,DS-6d09acdd-e3e6-4bb0-958f-ae18b405b860,DISK], DatanodeInfoWithStorage[127.0.0.1:45949,DS-0fbdc978-4260-4ef9-ad81-a382a6debbd6,DISK], DatanodeInfoWithStorage[127.0.0.1:37795,DS-6ba6ce18-943d-4085-ba62-9a3b0bc610fc,DISK], DatanodeInfoWithStorage[127.0.0.1:46477,DS-4990dc1e-4249-48ec-a369-216435ac0175,DISK], DatanodeInfoWithStorage[127.0.0.1:45083,DS-36c2c6c7-2e22-428a-89db-356a0a540826,DISK], DatanodeInfoWithStorage[127.0.0.1:34159,DS-9f3ecabe-31a6-4a38-978d-c4f61469c948,DISK], DatanodeInfoWithStorage[127.0.0.1:46498,DS-acc581d0-843f-4847-9129-cec59e5114b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1036303158-172.17.0.13-1598121944133:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39599,DS-bc10525a-8a5a-4604-93ac-f2791991c3a6,DISK], DatanodeInfoWithStorage[127.0.0.1:39136,DS-efde43d8-3bce-415d-a567-a5c4a44d440f,DISK], DatanodeInfoWithStorage[127.0.0.1:40069,DS-8dff17bf-40cc-4d37-9887-50fef9b3b2ba,DISK], DatanodeInfoWithStorage[127.0.0.1:40780,DS-2ade0326-3804-4bd0-a225-5d6ea2b23244,DISK], DatanodeInfoWithStorage[127.0.0.1:45578,DS-5986e14c-1987-42ac-8a19-7dcbdc4d0ef5,DISK], DatanodeInfoWithStorage[127.0.0.1:45527,DS-e648241c-e665-4e97-9ef3-b9975e246200,DISK], DatanodeInfoWithStorage[127.0.0.1:39357,DS-39f8d53a-2c56-4447-bed5-e437dfdd8d0c,DISK], DatanodeInfoWithStorage[127.0.0.1:43238,DS-b5cabfb2-281d-4e3b-b32b-2839fdac9a80,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1036303158-172.17.0.13-1598121944133:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39599,DS-bc10525a-8a5a-4604-93ac-f2791991c3a6,DISK], DatanodeInfoWithStorage[127.0.0.1:39136,DS-efde43d8-3bce-415d-a567-a5c4a44d440f,DISK], DatanodeInfoWithStorage[127.0.0.1:40069,DS-8dff17bf-40cc-4d37-9887-50fef9b3b2ba,DISK], DatanodeInfoWithStorage[127.0.0.1:40780,DS-2ade0326-3804-4bd0-a225-5d6ea2b23244,DISK], DatanodeInfoWithStorage[127.0.0.1:45578,DS-5986e14c-1987-42ac-8a19-7dcbdc4d0ef5,DISK], DatanodeInfoWithStorage[127.0.0.1:45527,DS-e648241c-e665-4e97-9ef3-b9975e246200,DISK], DatanodeInfoWithStorage[127.0.0.1:39357,DS-39f8d53a-2c56-4447-bed5-e437dfdd8d0c,DISK], DatanodeInfoWithStorage[127.0.0.1:43238,DS-b5cabfb2-281d-4e3b-b32b-2839fdac9a80,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1286782599-172.17.0.13-1598122300621:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35876,DS-ebb78465-b61b-4c97-a595-7afd1da31121,DISK], DatanodeInfoWithStorage[127.0.0.1:35433,DS-13966904-1802-4c93-9ae3-3bc1a99ab27b,DISK], DatanodeInfoWithStorage[127.0.0.1:42278,DS-6b7c041f-a5c4-4b85-b3b0-66d04c2bee25,DISK], DatanodeInfoWithStorage[127.0.0.1:43974,DS-f5014a44-81eb-4851-a239-a6753022e8b0,DISK], DatanodeInfoWithStorage[127.0.0.1:45789,DS-2a87e8f1-bdfa-4f1b-b589-99b774150a91,DISK], DatanodeInfoWithStorage[127.0.0.1:34788,DS-a43c262d-5bff-48df-bcad-d411df50a53e,DISK], DatanodeInfoWithStorage[127.0.0.1:44610,DS-122e36e8-f09c-4c4f-9f4e-76b2581cb76f,DISK], DatanodeInfoWithStorage[127.0.0.1:33210,DS-234297fd-2357-4da8-ae6c-e7a6f2f17a29,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1286782599-172.17.0.13-1598122300621:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35876,DS-ebb78465-b61b-4c97-a595-7afd1da31121,DISK], DatanodeInfoWithStorage[127.0.0.1:35433,DS-13966904-1802-4c93-9ae3-3bc1a99ab27b,DISK], DatanodeInfoWithStorage[127.0.0.1:42278,DS-6b7c041f-a5c4-4b85-b3b0-66d04c2bee25,DISK], DatanodeInfoWithStorage[127.0.0.1:43974,DS-f5014a44-81eb-4851-a239-a6753022e8b0,DISK], DatanodeInfoWithStorage[127.0.0.1:45789,DS-2a87e8f1-bdfa-4f1b-b589-99b774150a91,DISK], DatanodeInfoWithStorage[127.0.0.1:34788,DS-a43c262d-5bff-48df-bcad-d411df50a53e,DISK], DatanodeInfoWithStorage[127.0.0.1:44610,DS-122e36e8-f09c-4c4f-9f4e-76b2581cb76f,DISK], DatanodeInfoWithStorage[127.0.0.1:33210,DS-234297fd-2357-4da8-ae6c-e7a6f2f17a29,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1930333166-172.17.0.13-1598122470327:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37013,DS-3a135c1d-9acc-450b-a136-e08b1043ecd7,DISK], DatanodeInfoWithStorage[127.0.0.1:42735,DS-4a0ca5ac-b6db-4d0b-a642-7124742bc455,DISK], DatanodeInfoWithStorage[127.0.0.1:42184,DS-7ef05209-5321-41ce-bfb3-74066ba590a1,DISK], DatanodeInfoWithStorage[127.0.0.1:38409,DS-fb4081a6-9773-4721-adaf-f13d7576a540,DISK], DatanodeInfoWithStorage[127.0.0.1:33451,DS-f13742cc-4eaf-4c4b-bdfd-c6447519e06c,DISK], DatanodeInfoWithStorage[127.0.0.1:46678,DS-a0d65065-9971-4613-9603-d0ddcc7aff2f,DISK], DatanodeInfoWithStorage[127.0.0.1:46149,DS-b8965c14-6cc1-4f09-b925-7382c8ad42a4,DISK], DatanodeInfoWithStorage[127.0.0.1:37302,DS-f39ba48b-7d3e-4025-b37b-008715cf7b1e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1930333166-172.17.0.13-1598122470327:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37013,DS-3a135c1d-9acc-450b-a136-e08b1043ecd7,DISK], DatanodeInfoWithStorage[127.0.0.1:42735,DS-4a0ca5ac-b6db-4d0b-a642-7124742bc455,DISK], DatanodeInfoWithStorage[127.0.0.1:42184,DS-7ef05209-5321-41ce-bfb3-74066ba590a1,DISK], DatanodeInfoWithStorage[127.0.0.1:38409,DS-fb4081a6-9773-4721-adaf-f13d7576a540,DISK], DatanodeInfoWithStorage[127.0.0.1:33451,DS-f13742cc-4eaf-4c4b-bdfd-c6447519e06c,DISK], DatanodeInfoWithStorage[127.0.0.1:46678,DS-a0d65065-9971-4613-9603-d0ddcc7aff2f,DISK], DatanodeInfoWithStorage[127.0.0.1:46149,DS-b8965c14-6cc1-4f09-b925-7382c8ad42a4,DISK], DatanodeInfoWithStorage[127.0.0.1:37302,DS-f39ba48b-7d3e-4025-b37b-008715cf7b1e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1181056155-172.17.0.13-1598122576008:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46863,DS-3819644c-e151-4479-9f7c-2173188e9d3c,DISK], DatanodeInfoWithStorage[127.0.0.1:40779,DS-f37907ab-8290-4321-ab9d-b80264564003,DISK], DatanodeInfoWithStorage[127.0.0.1:34538,DS-386015ee-918e-4335-91a1-d2804cd42cf1,DISK], DatanodeInfoWithStorage[127.0.0.1:43310,DS-c1f84c7b-1c37-44ce-acba-06276f98c974,DISK], DatanodeInfoWithStorage[127.0.0.1:34354,DS-0dff668e-3705-4406-97e8-44d075997fc4,DISK], DatanodeInfoWithStorage[127.0.0.1:37740,DS-dda514da-167d-44d7-8cb8-01f3eac3b3b4,DISK], DatanodeInfoWithStorage[127.0.0.1:33611,DS-20361933-3f8b-40fb-929b-6ceccb859d10,DISK], DatanodeInfoWithStorage[127.0.0.1:35476,DS-56fd9108-7043-4857-a425-ed40396bace9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1181056155-172.17.0.13-1598122576008:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46863,DS-3819644c-e151-4479-9f7c-2173188e9d3c,DISK], DatanodeInfoWithStorage[127.0.0.1:40779,DS-f37907ab-8290-4321-ab9d-b80264564003,DISK], DatanodeInfoWithStorage[127.0.0.1:34538,DS-386015ee-918e-4335-91a1-d2804cd42cf1,DISK], DatanodeInfoWithStorage[127.0.0.1:43310,DS-c1f84c7b-1c37-44ce-acba-06276f98c974,DISK], DatanodeInfoWithStorage[127.0.0.1:34354,DS-0dff668e-3705-4406-97e8-44d075997fc4,DISK], DatanodeInfoWithStorage[127.0.0.1:37740,DS-dda514da-167d-44d7-8cb8-01f3eac3b3b4,DISK], DatanodeInfoWithStorage[127.0.0.1:33611,DS-20361933-3f8b-40fb-929b-6ceccb859d10,DISK], DatanodeInfoWithStorage[127.0.0.1:35476,DS-56fd9108-7043-4857-a425-ed40396bace9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-516487581-172.17.0.13-1598123165965:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44614,DS-b56c3156-11da-4ab6-8127-13c92b7439b2,DISK], DatanodeInfoWithStorage[127.0.0.1:40728,DS-af06f13c-d581-403f-af44-08d8dd5fc421,DISK], DatanodeInfoWithStorage[127.0.0.1:40035,DS-04a10fec-44f8-4d09-bcd8-c885fc2eb1f7,DISK], DatanodeInfoWithStorage[127.0.0.1:46806,DS-6735fd09-718a-4b16-be3a-746c8cfb6478,DISK], DatanodeInfoWithStorage[127.0.0.1:45647,DS-febc0d2c-bb0e-4423-9896-f50f0fc1f220,DISK], DatanodeInfoWithStorage[127.0.0.1:42079,DS-2fe29577-a2e2-4c62-9ee3-e2989eee8584,DISK], DatanodeInfoWithStorage[127.0.0.1:42033,DS-5d7e0225-df4a-4067-b417-322995fd208c,DISK], DatanodeInfoWithStorage[127.0.0.1:37899,DS-750a5e16-e92b-4420-b410-ec3c078e3a51,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-516487581-172.17.0.13-1598123165965:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44614,DS-b56c3156-11da-4ab6-8127-13c92b7439b2,DISK], DatanodeInfoWithStorage[127.0.0.1:40728,DS-af06f13c-d581-403f-af44-08d8dd5fc421,DISK], DatanodeInfoWithStorage[127.0.0.1:40035,DS-04a10fec-44f8-4d09-bcd8-c885fc2eb1f7,DISK], DatanodeInfoWithStorage[127.0.0.1:46806,DS-6735fd09-718a-4b16-be3a-746c8cfb6478,DISK], DatanodeInfoWithStorage[127.0.0.1:45647,DS-febc0d2c-bb0e-4423-9896-f50f0fc1f220,DISK], DatanodeInfoWithStorage[127.0.0.1:42079,DS-2fe29577-a2e2-4c62-9ee3-e2989eee8584,DISK], DatanodeInfoWithStorage[127.0.0.1:42033,DS-5d7e0225-df4a-4067-b417-322995fd208c,DISK], DatanodeInfoWithStorage[127.0.0.1:37899,DS-750a5e16-e92b-4420-b410-ec3c078e3a51,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-800541281-172.17.0.13-1598123330814:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35597,DS-f69f69a7-28a5-49d6-8088-57a52a63ff37,DISK], DatanodeInfoWithStorage[127.0.0.1:44468,DS-0a103f46-1db3-4031-b426-1fcb76f1fa92,DISK], DatanodeInfoWithStorage[127.0.0.1:35169,DS-2c507c4f-a975-4175-802d-02194cab1014,DISK], DatanodeInfoWithStorage[127.0.0.1:38957,DS-4af1acb2-f58f-4b11-a554-6e7275ef2895,DISK], DatanodeInfoWithStorage[127.0.0.1:35680,DS-9b52823d-c331-4f8d-850d-5fb8713b20e8,DISK], DatanodeInfoWithStorage[127.0.0.1:42778,DS-71aa6fac-61ac-4031-a135-6c3f9fc75fbd,DISK], DatanodeInfoWithStorage[127.0.0.1:34299,DS-05335f03-bd01-4f05-a764-2a75b49c94d3,DISK], DatanodeInfoWithStorage[127.0.0.1:41486,DS-7d6fc0db-d243-47cc-96f8-121afbb29700,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-800541281-172.17.0.13-1598123330814:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35597,DS-f69f69a7-28a5-49d6-8088-57a52a63ff37,DISK], DatanodeInfoWithStorage[127.0.0.1:44468,DS-0a103f46-1db3-4031-b426-1fcb76f1fa92,DISK], DatanodeInfoWithStorage[127.0.0.1:35169,DS-2c507c4f-a975-4175-802d-02194cab1014,DISK], DatanodeInfoWithStorage[127.0.0.1:38957,DS-4af1acb2-f58f-4b11-a554-6e7275ef2895,DISK], DatanodeInfoWithStorage[127.0.0.1:35680,DS-9b52823d-c331-4f8d-850d-5fb8713b20e8,DISK], DatanodeInfoWithStorage[127.0.0.1:42778,DS-71aa6fac-61ac-4031-a135-6c3f9fc75fbd,DISK], DatanodeInfoWithStorage[127.0.0.1:34299,DS-05335f03-bd01-4f05-a764-2a75b49c94d3,DISK], DatanodeInfoWithStorage[127.0.0.1:41486,DS-7d6fc0db-d243-47cc-96f8-121afbb29700,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1277408219-172.17.0.13-1598123870661:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37528,DS-840de00e-1394-4433-a9c1-44cc6139e265,DISK], DatanodeInfoWithStorage[127.0.0.1:45292,DS-7ab5ffb1-0ceb-4f43-93b9-591ba79b4921,DISK], DatanodeInfoWithStorage[127.0.0.1:35243,DS-c86be9c9-700d-44f0-a601-8f341cc33a66,DISK], DatanodeInfoWithStorage[127.0.0.1:44473,DS-465165ae-26d8-4635-82f1-f782f4dea2b9,DISK], DatanodeInfoWithStorage[127.0.0.1:38082,DS-098acae2-4008-4204-ab49-837c3d1c8863,DISK], DatanodeInfoWithStorage[127.0.0.1:35079,DS-54213d06-6ff7-48dc-aeaf-f17b3d5534d0,DISK], DatanodeInfoWithStorage[127.0.0.1:41317,DS-bd2da559-8756-429b-83e2-9d5e56377dd8,DISK], DatanodeInfoWithStorage[127.0.0.1:35085,DS-8a8bb335-8e69-4d76-b5d3-a049e9232164,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1277408219-172.17.0.13-1598123870661:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37528,DS-840de00e-1394-4433-a9c1-44cc6139e265,DISK], DatanodeInfoWithStorage[127.0.0.1:45292,DS-7ab5ffb1-0ceb-4f43-93b9-591ba79b4921,DISK], DatanodeInfoWithStorage[127.0.0.1:35243,DS-c86be9c9-700d-44f0-a601-8f341cc33a66,DISK], DatanodeInfoWithStorage[127.0.0.1:44473,DS-465165ae-26d8-4635-82f1-f782f4dea2b9,DISK], DatanodeInfoWithStorage[127.0.0.1:38082,DS-098acae2-4008-4204-ab49-837c3d1c8863,DISK], DatanodeInfoWithStorage[127.0.0.1:35079,DS-54213d06-6ff7-48dc-aeaf-f17b3d5534d0,DISK], DatanodeInfoWithStorage[127.0.0.1:41317,DS-bd2da559-8756-429b-83e2-9d5e56377dd8,DISK], DatanodeInfoWithStorage[127.0.0.1:35085,DS-8a8bb335-8e69-4d76-b5d3-a049e9232164,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-606368431-172.17.0.13-1598123903901:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46372,DS-582204ef-4f38-4015-b40f-8d9b668702cc,DISK], DatanodeInfoWithStorage[127.0.0.1:44630,DS-4ad90e12-21be-49d6-818a-68d2eb4a10d8,DISK], DatanodeInfoWithStorage[127.0.0.1:46440,DS-3f693169-aa05-4b4c-aad9-15d81a78948e,DISK], DatanodeInfoWithStorage[127.0.0.1:35557,DS-d66371a9-b5c6-4205-b318-ef8559e28713,DISK], DatanodeInfoWithStorage[127.0.0.1:34830,DS-57e79c46-090c-4d2d-988e-e1d477b011f6,DISK], DatanodeInfoWithStorage[127.0.0.1:44979,DS-a0fdfbc1-8a0e-4b17-ac67-a1c9548fb5a9,DISK], DatanodeInfoWithStorage[127.0.0.1:36137,DS-15f834cb-a1a1-45e7-a961-62caf311ad62,DISK], DatanodeInfoWithStorage[127.0.0.1:42834,DS-339cc062-cf80-47a1-a5c7-5f4815df099d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-606368431-172.17.0.13-1598123903901:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46372,DS-582204ef-4f38-4015-b40f-8d9b668702cc,DISK], DatanodeInfoWithStorage[127.0.0.1:44630,DS-4ad90e12-21be-49d6-818a-68d2eb4a10d8,DISK], DatanodeInfoWithStorage[127.0.0.1:46440,DS-3f693169-aa05-4b4c-aad9-15d81a78948e,DISK], DatanodeInfoWithStorage[127.0.0.1:35557,DS-d66371a9-b5c6-4205-b318-ef8559e28713,DISK], DatanodeInfoWithStorage[127.0.0.1:34830,DS-57e79c46-090c-4d2d-988e-e1d477b011f6,DISK], DatanodeInfoWithStorage[127.0.0.1:44979,DS-a0fdfbc1-8a0e-4b17-ac67-a1c9548fb5a9,DISK], DatanodeInfoWithStorage[127.0.0.1:36137,DS-15f834cb-a1a1-45e7-a961-62caf311ad62,DISK], DatanodeInfoWithStorage[127.0.0.1:42834,DS-339cc062-cf80-47a1-a5c7-5f4815df099d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1716091050-172.17.0.13-1598124478306:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43269,DS-0d6586e7-ba33-49d7-ac75-0e1efbe1a0e4,DISK], DatanodeInfoWithStorage[127.0.0.1:42735,DS-4601eefb-e684-4f48-90fc-aaf4c2da8832,DISK], DatanodeInfoWithStorage[127.0.0.1:46444,DS-d7a6e179-6d10-4124-8a70-156f390c2866,DISK], DatanodeInfoWithStorage[127.0.0.1:40833,DS-cd051f90-2214-4875-976f-2ab64de51f71,DISK], DatanodeInfoWithStorage[127.0.0.1:45905,DS-b7482b8b-f481-4539-9af1-ef7a82a7c906,DISK], DatanodeInfoWithStorage[127.0.0.1:35305,DS-328aed68-422c-40f5-ba18-145fd40de3ea,DISK], DatanodeInfoWithStorage[127.0.0.1:44617,DS-c8f6b751-39c7-4119-b8fa-1d91a2b3188e,DISK], DatanodeInfoWithStorage[127.0.0.1:46536,DS-a404aa04-f446-488e-9dae-7d18f927ee26,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1716091050-172.17.0.13-1598124478306:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43269,DS-0d6586e7-ba33-49d7-ac75-0e1efbe1a0e4,DISK], DatanodeInfoWithStorage[127.0.0.1:42735,DS-4601eefb-e684-4f48-90fc-aaf4c2da8832,DISK], DatanodeInfoWithStorage[127.0.0.1:46444,DS-d7a6e179-6d10-4124-8a70-156f390c2866,DISK], DatanodeInfoWithStorage[127.0.0.1:40833,DS-cd051f90-2214-4875-976f-2ab64de51f71,DISK], DatanodeInfoWithStorage[127.0.0.1:45905,DS-b7482b8b-f481-4539-9af1-ef7a82a7c906,DISK], DatanodeInfoWithStorage[127.0.0.1:35305,DS-328aed68-422c-40f5-ba18-145fd40de3ea,DISK], DatanodeInfoWithStorage[127.0.0.1:44617,DS-c8f6b751-39c7-4119-b8fa-1d91a2b3188e,DISK], DatanodeInfoWithStorage[127.0.0.1:46536,DS-a404aa04-f446-488e-9dae-7d18f927ee26,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1462869716-172.17.0.13-1598124661469:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33426,DS-633c1922-8ab2-45f2-a59b-d183a6cd7079,DISK], DatanodeInfoWithStorage[127.0.0.1:46399,DS-6a852f49-1ca1-4619-8543-10dff87b74d3,DISK], DatanodeInfoWithStorage[127.0.0.1:45672,DS-8d15c4aa-b0cf-4453-95a0-3fc6b55afad8,DISK], DatanodeInfoWithStorage[127.0.0.1:44813,DS-d9f9a7be-9a25-468a-a18e-59c36f1e1a2d,DISK], DatanodeInfoWithStorage[127.0.0.1:38772,DS-0eda60b9-ac48-4a46-b2f2-e477cdb4ab1b,DISK], DatanodeInfoWithStorage[127.0.0.1:37091,DS-657eeb05-155f-4377-a374-8fa24b60c667,DISK], DatanodeInfoWithStorage[127.0.0.1:42181,DS-1eb53be7-ffce-417c-8bc5-2c6062761f73,DISK], DatanodeInfoWithStorage[127.0.0.1:44144,DS-0744ac88-ea70-490a-9420-ff157ce573c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1462869716-172.17.0.13-1598124661469:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33426,DS-633c1922-8ab2-45f2-a59b-d183a6cd7079,DISK], DatanodeInfoWithStorage[127.0.0.1:46399,DS-6a852f49-1ca1-4619-8543-10dff87b74d3,DISK], DatanodeInfoWithStorage[127.0.0.1:45672,DS-8d15c4aa-b0cf-4453-95a0-3fc6b55afad8,DISK], DatanodeInfoWithStorage[127.0.0.1:44813,DS-d9f9a7be-9a25-468a-a18e-59c36f1e1a2d,DISK], DatanodeInfoWithStorage[127.0.0.1:38772,DS-0eda60b9-ac48-4a46-b2f2-e477cdb4ab1b,DISK], DatanodeInfoWithStorage[127.0.0.1:37091,DS-657eeb05-155f-4377-a374-8fa24b60c667,DISK], DatanodeInfoWithStorage[127.0.0.1:42181,DS-1eb53be7-ffce-417c-8bc5-2c6062761f73,DISK], DatanodeInfoWithStorage[127.0.0.1:44144,DS-0744ac88-ea70-490a-9420-ff157ce573c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1687954339-172.17.0.13-1598124851674:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36287,DS-013b3853-6872-4fed-9bad-35d62e39caa4,DISK], DatanodeInfoWithStorage[127.0.0.1:46496,DS-4707e827-34d8-47ad-9c80-d70ed3027d79,DISK], DatanodeInfoWithStorage[127.0.0.1:43826,DS-c0654560-fb2c-4dcb-923e-8ace4e18bdb2,DISK], DatanodeInfoWithStorage[127.0.0.1:42100,DS-736bc405-9477-49b3-8534-940a0ff9e6cf,DISK], DatanodeInfoWithStorage[127.0.0.1:33635,DS-aaeea5e6-800d-473f-977e-5f7312b40c59,DISK], DatanodeInfoWithStorage[127.0.0.1:43511,DS-551d20b0-2d86-42e8-92a7-8732d418ec6f,DISK], DatanodeInfoWithStorage[127.0.0.1:39844,DS-a90224c1-1965-492b-bbc8-cf889116a806,DISK], DatanodeInfoWithStorage[127.0.0.1:43713,DS-183d26e8-d1af-45a1-83b4-28c73ca19725,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1687954339-172.17.0.13-1598124851674:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36287,DS-013b3853-6872-4fed-9bad-35d62e39caa4,DISK], DatanodeInfoWithStorage[127.0.0.1:46496,DS-4707e827-34d8-47ad-9c80-d70ed3027d79,DISK], DatanodeInfoWithStorage[127.0.0.1:43826,DS-c0654560-fb2c-4dcb-923e-8ace4e18bdb2,DISK], DatanodeInfoWithStorage[127.0.0.1:42100,DS-736bc405-9477-49b3-8534-940a0ff9e6cf,DISK], DatanodeInfoWithStorage[127.0.0.1:33635,DS-aaeea5e6-800d-473f-977e-5f7312b40c59,DISK], DatanodeInfoWithStorage[127.0.0.1:43511,DS-551d20b0-2d86-42e8-92a7-8732d418ec6f,DISK], DatanodeInfoWithStorage[127.0.0.1:39844,DS-a90224c1-1965-492b-bbc8-cf889116a806,DISK], DatanodeInfoWithStorage[127.0.0.1:43713,DS-183d26e8-d1af-45a1-83b4-28c73ca19725,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1672138884-172.17.0.13-1598125023395:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38437,DS-9274770d-b537-4403-a33f-27357d2ff274,DISK], DatanodeInfoWithStorage[127.0.0.1:36904,DS-58551ac7-903a-490f-8263-042fb2026e6d,DISK], DatanodeInfoWithStorage[127.0.0.1:38945,DS-ea891d43-4602-4582-86fd-9cc1b4db284e,DISK], DatanodeInfoWithStorage[127.0.0.1:33042,DS-1e09714f-b6a6-4e0f-b385-0330a1b7b16b,DISK], DatanodeInfoWithStorage[127.0.0.1:43610,DS-060f97e1-b001-46fe-8421-69ca0700302e,DISK], DatanodeInfoWithStorage[127.0.0.1:43870,DS-9d58647a-9de5-46a8-b43e-691cfddc11fb,DISK], DatanodeInfoWithStorage[127.0.0.1:46199,DS-2a15c24b-3ae7-447d-9930-4fe14f7f2bd1,DISK], DatanodeInfoWithStorage[127.0.0.1:41878,DS-32b43061-65a3-4b5e-b420-0f908e944501,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1672138884-172.17.0.13-1598125023395:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38437,DS-9274770d-b537-4403-a33f-27357d2ff274,DISK], DatanodeInfoWithStorage[127.0.0.1:36904,DS-58551ac7-903a-490f-8263-042fb2026e6d,DISK], DatanodeInfoWithStorage[127.0.0.1:38945,DS-ea891d43-4602-4582-86fd-9cc1b4db284e,DISK], DatanodeInfoWithStorage[127.0.0.1:33042,DS-1e09714f-b6a6-4e0f-b385-0330a1b7b16b,DISK], DatanodeInfoWithStorage[127.0.0.1:43610,DS-060f97e1-b001-46fe-8421-69ca0700302e,DISK], DatanodeInfoWithStorage[127.0.0.1:43870,DS-9d58647a-9de5-46a8-b43e-691cfddc11fb,DISK], DatanodeInfoWithStorage[127.0.0.1:46199,DS-2a15c24b-3ae7-447d-9930-4fe14f7f2bd1,DISK], DatanodeInfoWithStorage[127.0.0.1:41878,DS-32b43061-65a3-4b5e-b420-0f908e944501,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-584616518-172.17.0.13-1598125247825:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44807,DS-f3599de5-8e84-4925-84cb-32fbf3dcf3f9,DISK], DatanodeInfoWithStorage[127.0.0.1:33435,DS-1d19396a-d396-4f37-aa63-b575ed3e43e2,DISK], DatanodeInfoWithStorage[127.0.0.1:35250,DS-aab0c10b-5db0-4c3f-9453-ba37c7448945,DISK], DatanodeInfoWithStorage[127.0.0.1:44532,DS-5b77106c-af78-42a3-9151-b9a9ef0441af,DISK], DatanodeInfoWithStorage[127.0.0.1:41606,DS-304cb127-48ee-4e50-8f61-0e35e04efbaa,DISK], DatanodeInfoWithStorage[127.0.0.1:44172,DS-0c368f77-5b1a-4178-bf4e-584d9138e819,DISK], DatanodeInfoWithStorage[127.0.0.1:40150,DS-bf58bea1-6cee-4684-bc35-3c333f9cd815,DISK], DatanodeInfoWithStorage[127.0.0.1:33551,DS-a78b64cc-949a-4a28-937a-e658e3d8949f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-584616518-172.17.0.13-1598125247825:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44807,DS-f3599de5-8e84-4925-84cb-32fbf3dcf3f9,DISK], DatanodeInfoWithStorage[127.0.0.1:33435,DS-1d19396a-d396-4f37-aa63-b575ed3e43e2,DISK], DatanodeInfoWithStorage[127.0.0.1:35250,DS-aab0c10b-5db0-4c3f-9453-ba37c7448945,DISK], DatanodeInfoWithStorage[127.0.0.1:44532,DS-5b77106c-af78-42a3-9151-b9a9ef0441af,DISK], DatanodeInfoWithStorage[127.0.0.1:41606,DS-304cb127-48ee-4e50-8f61-0e35e04efbaa,DISK], DatanodeInfoWithStorage[127.0.0.1:44172,DS-0c368f77-5b1a-4178-bf4e-584d9138e819,DISK], DatanodeInfoWithStorage[127.0.0.1:40150,DS-bf58bea1-6cee-4684-bc35-3c333f9cd815,DISK], DatanodeInfoWithStorage[127.0.0.1:33551,DS-a78b64cc-949a-4a28-937a-e658e3d8949f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1473250896-172.17.0.13-1598125384266:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32916,DS-72018060-4e1e-4a7b-8e24-29ede2a9163f,DISK], DatanodeInfoWithStorage[127.0.0.1:35393,DS-facc2086-d2f0-482e-8197-aa2fb8558a49,DISK], DatanodeInfoWithStorage[127.0.0.1:40517,DS-e7b93cc8-20da-4098-a4c6-327ccb5ba29f,DISK], DatanodeInfoWithStorage[127.0.0.1:42160,DS-6ca4e20f-d3df-4c89-9522-4e436df4f3e1,DISK], DatanodeInfoWithStorage[127.0.0.1:39314,DS-a49549a5-261b-4029-bc81-007bbad77e35,DISK], DatanodeInfoWithStorage[127.0.0.1:36405,DS-2a4f39e5-e39d-422c-b463-442e5453e43f,DISK], DatanodeInfoWithStorage[127.0.0.1:42773,DS-5b60275f-dc8c-43a5-865f-1fbc280f058d,DISK], DatanodeInfoWithStorage[127.0.0.1:42246,DS-f8db522e-aaf2-4435-b5d1-f116509500eb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1473250896-172.17.0.13-1598125384266:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32916,DS-72018060-4e1e-4a7b-8e24-29ede2a9163f,DISK], DatanodeInfoWithStorage[127.0.0.1:35393,DS-facc2086-d2f0-482e-8197-aa2fb8558a49,DISK], DatanodeInfoWithStorage[127.0.0.1:40517,DS-e7b93cc8-20da-4098-a4c6-327ccb5ba29f,DISK], DatanodeInfoWithStorage[127.0.0.1:42160,DS-6ca4e20f-d3df-4c89-9522-4e436df4f3e1,DISK], DatanodeInfoWithStorage[127.0.0.1:39314,DS-a49549a5-261b-4029-bc81-007bbad77e35,DISK], DatanodeInfoWithStorage[127.0.0.1:36405,DS-2a4f39e5-e39d-422c-b463-442e5453e43f,DISK], DatanodeInfoWithStorage[127.0.0.1:42773,DS-5b60275f-dc8c-43a5-865f-1fbc280f058d,DISK], DatanodeInfoWithStorage[127.0.0.1:42246,DS-f8db522e-aaf2-4435-b5d1-f116509500eb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1496363426-172.17.0.13-1598125456575:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34569,DS-b940b5a5-48be-452f-b28d-f24f36e3785e,DISK], DatanodeInfoWithStorage[127.0.0.1:36220,DS-a57c4224-4484-43d3-a177-f21680cda564,DISK], DatanodeInfoWithStorage[127.0.0.1:44165,DS-6bf8709b-fff4-46f5-a6d4-99821c0f7eb6,DISK], DatanodeInfoWithStorage[127.0.0.1:38060,DS-3ea86ad2-6927-4420-ab4b-f7b4680d0557,DISK], DatanodeInfoWithStorage[127.0.0.1:36527,DS-e2308173-b300-445b-bbf3-d6e14ae5b859,DISK], DatanodeInfoWithStorage[127.0.0.1:40215,DS-cfbe36d9-9fb9-450a-b2b2-0089acb94ec7,DISK], DatanodeInfoWithStorage[127.0.0.1:34267,DS-31f1d074-b07a-4a0e-91a1-c2701f3844b6,DISK], DatanodeInfoWithStorage[127.0.0.1:40931,DS-37907138-2e59-4cb4-8733-9be3dda0eaf2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1496363426-172.17.0.13-1598125456575:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34569,DS-b940b5a5-48be-452f-b28d-f24f36e3785e,DISK], DatanodeInfoWithStorage[127.0.0.1:36220,DS-a57c4224-4484-43d3-a177-f21680cda564,DISK], DatanodeInfoWithStorage[127.0.0.1:44165,DS-6bf8709b-fff4-46f5-a6d4-99821c0f7eb6,DISK], DatanodeInfoWithStorage[127.0.0.1:38060,DS-3ea86ad2-6927-4420-ab4b-f7b4680d0557,DISK], DatanodeInfoWithStorage[127.0.0.1:36527,DS-e2308173-b300-445b-bbf3-d6e14ae5b859,DISK], DatanodeInfoWithStorage[127.0.0.1:40215,DS-cfbe36d9-9fb9-450a-b2b2-0089acb94ec7,DISK], DatanodeInfoWithStorage[127.0.0.1:34267,DS-31f1d074-b07a-4a0e-91a1-c2701f3844b6,DISK], DatanodeInfoWithStorage[127.0.0.1:40931,DS-37907138-2e59-4cb4-8733-9be3dda0eaf2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1412157592-172.17.0.13-1598125862076:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35921,DS-15dcb09e-4aeb-4828-ad58-84f96b4f3183,DISK], DatanodeInfoWithStorage[127.0.0.1:43377,DS-573d3d1c-b69d-4a97-a1d4-0f82d17cda15,DISK], DatanodeInfoWithStorage[127.0.0.1:44706,DS-1688a6fe-6bc9-4476-b03b-f05f40615608,DISK], DatanodeInfoWithStorage[127.0.0.1:35966,DS-5558cf34-769f-45bb-813e-5edbd0cb07cf,DISK], DatanodeInfoWithStorage[127.0.0.1:45962,DS-f124d403-fba8-45f6-a818-e5b6f0c0ea07,DISK], DatanodeInfoWithStorage[127.0.0.1:34787,DS-aeae5691-3efa-41c4-b045-b422d5af3d24,DISK], DatanodeInfoWithStorage[127.0.0.1:43356,DS-10cf912a-2d88-4220-ae56-9cab3c45ba33,DISK], DatanodeInfoWithStorage[127.0.0.1:32865,DS-2d18a5a2-33e9-4111-aafd-cb1d69380995,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1412157592-172.17.0.13-1598125862076:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35921,DS-15dcb09e-4aeb-4828-ad58-84f96b4f3183,DISK], DatanodeInfoWithStorage[127.0.0.1:43377,DS-573d3d1c-b69d-4a97-a1d4-0f82d17cda15,DISK], DatanodeInfoWithStorage[127.0.0.1:44706,DS-1688a6fe-6bc9-4476-b03b-f05f40615608,DISK], DatanodeInfoWithStorage[127.0.0.1:35966,DS-5558cf34-769f-45bb-813e-5edbd0cb07cf,DISK], DatanodeInfoWithStorage[127.0.0.1:45962,DS-f124d403-fba8-45f6-a818-e5b6f0c0ea07,DISK], DatanodeInfoWithStorage[127.0.0.1:34787,DS-aeae5691-3efa-41c4-b045-b422d5af3d24,DISK], DatanodeInfoWithStorage[127.0.0.1:43356,DS-10cf912a-2d88-4220-ae56-9cab3c45ba33,DISK], DatanodeInfoWithStorage[127.0.0.1:32865,DS-2d18a5a2-33e9-4111-aafd-cb1d69380995,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-989683997-172.17.0.13-1598126236059:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41976,DS-14853936-f8dd-4712-9812-84be3aa8b2f5,DISK], DatanodeInfoWithStorage[127.0.0.1:40188,DS-ac8793bd-e1a2-40f7-be9e-97b9fd02bde6,DISK], DatanodeInfoWithStorage[127.0.0.1:33289,DS-43dad043-d6d7-4b2b-9bed-7dbd8e3cd789,DISK], DatanodeInfoWithStorage[127.0.0.1:42912,DS-f7bd1fce-d979-4b99-b8df-01f3e26a3d35,DISK], DatanodeInfoWithStorage[127.0.0.1:34320,DS-37948a63-dac0-4f4a-85fe-fceddc57c471,DISK], DatanodeInfoWithStorage[127.0.0.1:41806,DS-aa1eb7b5-e293-46ec-97fa-1a2fd9ba92aa,DISK], DatanodeInfoWithStorage[127.0.0.1:37129,DS-1264a913-3652-45fc-b3b6-b91d68ad7793,DISK], DatanodeInfoWithStorage[127.0.0.1:38241,DS-bb8ccf14-ada4-4f63-9892-12027841b16c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-989683997-172.17.0.13-1598126236059:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41976,DS-14853936-f8dd-4712-9812-84be3aa8b2f5,DISK], DatanodeInfoWithStorage[127.0.0.1:40188,DS-ac8793bd-e1a2-40f7-be9e-97b9fd02bde6,DISK], DatanodeInfoWithStorage[127.0.0.1:33289,DS-43dad043-d6d7-4b2b-9bed-7dbd8e3cd789,DISK], DatanodeInfoWithStorage[127.0.0.1:42912,DS-f7bd1fce-d979-4b99-b8df-01f3e26a3d35,DISK], DatanodeInfoWithStorage[127.0.0.1:34320,DS-37948a63-dac0-4f4a-85fe-fceddc57c471,DISK], DatanodeInfoWithStorage[127.0.0.1:41806,DS-aa1eb7b5-e293-46ec-97fa-1a2fd9ba92aa,DISK], DatanodeInfoWithStorage[127.0.0.1:37129,DS-1264a913-3652-45fc-b3b6-b91d68ad7793,DISK], DatanodeInfoWithStorage[127.0.0.1:38241,DS-bb8ccf14-ada4-4f63-9892-12027841b16c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1277351651-172.17.0.13-1598126828931:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40447,DS-0fa61a70-4008-4b3a-9764-3e9cb1b51355,DISK], DatanodeInfoWithStorage[127.0.0.1:44178,DS-174b4276-c7eb-4a1a-ae1c-79ea73e1572b,DISK], DatanodeInfoWithStorage[127.0.0.1:42640,DS-71df8715-bc61-4086-a636-9bebfda1439e,DISK], DatanodeInfoWithStorage[127.0.0.1:45024,DS-d05b8b75-681c-452e-a6f4-9b9a71a22be3,DISK], DatanodeInfoWithStorage[127.0.0.1:40689,DS-304de5f6-1857-4739-b563-99033cbe578a,DISK], DatanodeInfoWithStorage[127.0.0.1:41368,DS-0720d0f9-94bf-41d6-a2e8-4636b9ee287e,DISK], DatanodeInfoWithStorage[127.0.0.1:42371,DS-63e91694-227b-4a13-95cf-742e39fc7d93,DISK], DatanodeInfoWithStorage[127.0.0.1:46045,DS-a2e4b150-35f8-42eb-b796-f783de6a8383,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1277351651-172.17.0.13-1598126828931:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40447,DS-0fa61a70-4008-4b3a-9764-3e9cb1b51355,DISK], DatanodeInfoWithStorage[127.0.0.1:44178,DS-174b4276-c7eb-4a1a-ae1c-79ea73e1572b,DISK], DatanodeInfoWithStorage[127.0.0.1:42640,DS-71df8715-bc61-4086-a636-9bebfda1439e,DISK], DatanodeInfoWithStorage[127.0.0.1:45024,DS-d05b8b75-681c-452e-a6f4-9b9a71a22be3,DISK], DatanodeInfoWithStorage[127.0.0.1:40689,DS-304de5f6-1857-4739-b563-99033cbe578a,DISK], DatanodeInfoWithStorage[127.0.0.1:41368,DS-0720d0f9-94bf-41d6-a2e8-4636b9ee287e,DISK], DatanodeInfoWithStorage[127.0.0.1:42371,DS-63e91694-227b-4a13-95cf-742e39fc7d93,DISK], DatanodeInfoWithStorage[127.0.0.1:46045,DS-a2e4b150-35f8-42eb-b796-f783de6a8383,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1919734073-172.17.0.13-1598126863639:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35843,DS-fc938213-5c41-43f1-ae42-3c0373b5c405,DISK], DatanodeInfoWithStorage[127.0.0.1:43548,DS-b02a0459-5431-4374-b845-96e11af636e4,DISK], DatanodeInfoWithStorage[127.0.0.1:40559,DS-307378bb-6335-4faa-85e0-5e1468e512c5,DISK], DatanodeInfoWithStorage[127.0.0.1:42592,DS-52f7589d-358a-4b32-8cb3-fd505d7feb88,DISK], DatanodeInfoWithStorage[127.0.0.1:41872,DS-e3a0a17b-b0de-4815-96c1-acb66817992c,DISK], DatanodeInfoWithStorage[127.0.0.1:33126,DS-a5f3affc-5bad-4ed4-9193-2400f2202ee5,DISK], DatanodeInfoWithStorage[127.0.0.1:42214,DS-712dc505-66e7-479e-a340-eae5cad8cf6e,DISK], DatanodeInfoWithStorage[127.0.0.1:44581,DS-6e9dc220-f4fd-41fa-872f-d123cc6d570b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1919734073-172.17.0.13-1598126863639:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35843,DS-fc938213-5c41-43f1-ae42-3c0373b5c405,DISK], DatanodeInfoWithStorage[127.0.0.1:43548,DS-b02a0459-5431-4374-b845-96e11af636e4,DISK], DatanodeInfoWithStorage[127.0.0.1:40559,DS-307378bb-6335-4faa-85e0-5e1468e512c5,DISK], DatanodeInfoWithStorage[127.0.0.1:42592,DS-52f7589d-358a-4b32-8cb3-fd505d7feb88,DISK], DatanodeInfoWithStorage[127.0.0.1:41872,DS-e3a0a17b-b0de-4815-96c1-acb66817992c,DISK], DatanodeInfoWithStorage[127.0.0.1:33126,DS-a5f3affc-5bad-4ed4-9193-2400f2202ee5,DISK], DatanodeInfoWithStorage[127.0.0.1:42214,DS-712dc505-66e7-479e-a340-eae5cad8cf6e,DISK], DatanodeInfoWithStorage[127.0.0.1:44581,DS-6e9dc220-f4fd-41fa-872f-d123cc6d570b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5254
