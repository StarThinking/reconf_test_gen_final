reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2025953859-172.17.0.19-1598090527715:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34956,DS-a3d57430-141e-4888-a631-b6fa20a8f418,DISK], DatanodeInfoWithStorage[127.0.0.1:43385,DS-33742d55-41cf-46a5-969c-c8e05a6d02e6,DISK], DatanodeInfoWithStorage[127.0.0.1:39631,DS-6935d6d8-b269-4d6e-b635-f5d0429d8c22,DISK], DatanodeInfoWithStorage[127.0.0.1:39297,DS-37d4cd50-c097-44df-a634-c0baecd78ed6,DISK], DatanodeInfoWithStorage[127.0.0.1:46244,DS-112c726d-1465-406c-a738-aa9b028bb61b,DISK], DatanodeInfoWithStorage[127.0.0.1:34415,DS-1ec42f4e-b9e7-4e76-aa61-3a6b4cb28589,DISK], DatanodeInfoWithStorage[127.0.0.1:46658,DS-f28b8a7e-4e2c-44d4-ac74-8180b23a2543,DISK], DatanodeInfoWithStorage[127.0.0.1:35590,DS-9c8be9cb-65e2-4759-b7b9-51387c4478de,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2025953859-172.17.0.19-1598090527715:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34956,DS-a3d57430-141e-4888-a631-b6fa20a8f418,DISK], DatanodeInfoWithStorage[127.0.0.1:43385,DS-33742d55-41cf-46a5-969c-c8e05a6d02e6,DISK], DatanodeInfoWithStorage[127.0.0.1:39631,DS-6935d6d8-b269-4d6e-b635-f5d0429d8c22,DISK], DatanodeInfoWithStorage[127.0.0.1:39297,DS-37d4cd50-c097-44df-a634-c0baecd78ed6,DISK], DatanodeInfoWithStorage[127.0.0.1:46244,DS-112c726d-1465-406c-a738-aa9b028bb61b,DISK], DatanodeInfoWithStorage[127.0.0.1:34415,DS-1ec42f4e-b9e7-4e76-aa61-3a6b4cb28589,DISK], DatanodeInfoWithStorage[127.0.0.1:46658,DS-f28b8a7e-4e2c-44d4-ac74-8180b23a2543,DISK], DatanodeInfoWithStorage[127.0.0.1:35590,DS-9c8be9cb-65e2-4759-b7b9-51387c4478de,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1023063868-172.17.0.19-1598090602199:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40746,DS-02ac93ff-72dc-4cd0-bcb3-5a0a1e79eed3,DISK], DatanodeInfoWithStorage[127.0.0.1:37605,DS-c2273d7d-2782-4266-9197-8d0c98969b2a,DISK], DatanodeInfoWithStorage[127.0.0.1:43473,DS-914ef692-ecdd-40a6-a721-d010c924351d,DISK], DatanodeInfoWithStorage[127.0.0.1:39218,DS-b14ea0fa-3def-4a1d-8613-bb172025d6e6,DISK], DatanodeInfoWithStorage[127.0.0.1:39508,DS-3b9c8841-0828-4653-b427-1dcc2f39db55,DISK], DatanodeInfoWithStorage[127.0.0.1:35664,DS-471972b9-5909-44c1-87c3-60d5f5a3fb81,DISK], DatanodeInfoWithStorage[127.0.0.1:38412,DS-5ac40a7e-1099-470c-9d13-075511b8ef51,DISK], DatanodeInfoWithStorage[127.0.0.1:35301,DS-8108882a-e572-4362-9813-3be0db0014d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1023063868-172.17.0.19-1598090602199:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40746,DS-02ac93ff-72dc-4cd0-bcb3-5a0a1e79eed3,DISK], DatanodeInfoWithStorage[127.0.0.1:37605,DS-c2273d7d-2782-4266-9197-8d0c98969b2a,DISK], DatanodeInfoWithStorage[127.0.0.1:43473,DS-914ef692-ecdd-40a6-a721-d010c924351d,DISK], DatanodeInfoWithStorage[127.0.0.1:39218,DS-b14ea0fa-3def-4a1d-8613-bb172025d6e6,DISK], DatanodeInfoWithStorage[127.0.0.1:39508,DS-3b9c8841-0828-4653-b427-1dcc2f39db55,DISK], DatanodeInfoWithStorage[127.0.0.1:35664,DS-471972b9-5909-44c1-87c3-60d5f5a3fb81,DISK], DatanodeInfoWithStorage[127.0.0.1:38412,DS-5ac40a7e-1099-470c-9d13-075511b8ef51,DISK], DatanodeInfoWithStorage[127.0.0.1:35301,DS-8108882a-e572-4362-9813-3be0db0014d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-833155993-172.17.0.19-1598090828809:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35205,DS-568d8554-888a-42f6-b3b1-ded3a05517cb,DISK], DatanodeInfoWithStorage[127.0.0.1:33425,DS-47685c12-e265-4b88-b0f2-8ad9c8cbabc3,DISK], DatanodeInfoWithStorage[127.0.0.1:37520,DS-49f936ad-3646-45c0-a916-c43f68904511,DISK], DatanodeInfoWithStorage[127.0.0.1:35598,DS-fd9fab71-8d52-4371-ae8d-9b6289563675,DISK], DatanodeInfoWithStorage[127.0.0.1:41344,DS-71cbce8f-993b-4a2c-baa8-7dcc596ec879,DISK], DatanodeInfoWithStorage[127.0.0.1:35882,DS-38505034-c0ba-4ed1-8ee6-43e2c82a5818,DISK], DatanodeInfoWithStorage[127.0.0.1:41050,DS-3351c703-5572-470d-960f-ea57eb7dfb6a,DISK], DatanodeInfoWithStorage[127.0.0.1:39695,DS-a042551f-4953-4b2f-964b-69533f5fbcde,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-833155993-172.17.0.19-1598090828809:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35205,DS-568d8554-888a-42f6-b3b1-ded3a05517cb,DISK], DatanodeInfoWithStorage[127.0.0.1:33425,DS-47685c12-e265-4b88-b0f2-8ad9c8cbabc3,DISK], DatanodeInfoWithStorage[127.0.0.1:37520,DS-49f936ad-3646-45c0-a916-c43f68904511,DISK], DatanodeInfoWithStorage[127.0.0.1:35598,DS-fd9fab71-8d52-4371-ae8d-9b6289563675,DISK], DatanodeInfoWithStorage[127.0.0.1:41344,DS-71cbce8f-993b-4a2c-baa8-7dcc596ec879,DISK], DatanodeInfoWithStorage[127.0.0.1:35882,DS-38505034-c0ba-4ed1-8ee6-43e2c82a5818,DISK], DatanodeInfoWithStorage[127.0.0.1:41050,DS-3351c703-5572-470d-960f-ea57eb7dfb6a,DISK], DatanodeInfoWithStorage[127.0.0.1:39695,DS-a042551f-4953-4b2f-964b-69533f5fbcde,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-918958073-172.17.0.19-1598090978429:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34917,DS-9d5d4d90-cab2-40b3-a5f8-409456cb2a34,DISK], DatanodeInfoWithStorage[127.0.0.1:44785,DS-076c54a1-0cf0-4d45-96c8-b1006c12cf89,DISK], DatanodeInfoWithStorage[127.0.0.1:46420,DS-cbb3c7ca-52c2-4386-af78-835bfe2a865b,DISK], DatanodeInfoWithStorage[127.0.0.1:46202,DS-d1c9db1c-b869-41a3-b70a-5fd3de01a421,DISK], DatanodeInfoWithStorage[127.0.0.1:38224,DS-abc763f5-3c71-4708-9235-186537d2278a,DISK], DatanodeInfoWithStorage[127.0.0.1:34383,DS-9852ac0e-c309-4952-9342-c188db002500,DISK], DatanodeInfoWithStorage[127.0.0.1:38679,DS-b910e784-1cd6-4ef2-aaf9-918c0dd9ef5d,DISK], DatanodeInfoWithStorage[127.0.0.1:35373,DS-bf7a3fb9-b861-437d-bf8e-2645e8e5f3af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-918958073-172.17.0.19-1598090978429:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34917,DS-9d5d4d90-cab2-40b3-a5f8-409456cb2a34,DISK], DatanodeInfoWithStorage[127.0.0.1:44785,DS-076c54a1-0cf0-4d45-96c8-b1006c12cf89,DISK], DatanodeInfoWithStorage[127.0.0.1:46420,DS-cbb3c7ca-52c2-4386-af78-835bfe2a865b,DISK], DatanodeInfoWithStorage[127.0.0.1:46202,DS-d1c9db1c-b869-41a3-b70a-5fd3de01a421,DISK], DatanodeInfoWithStorage[127.0.0.1:38224,DS-abc763f5-3c71-4708-9235-186537d2278a,DISK], DatanodeInfoWithStorage[127.0.0.1:34383,DS-9852ac0e-c309-4952-9342-c188db002500,DISK], DatanodeInfoWithStorage[127.0.0.1:38679,DS-b910e784-1cd6-4ef2-aaf9-918c0dd9ef5d,DISK], DatanodeInfoWithStorage[127.0.0.1:35373,DS-bf7a3fb9-b861-437d-bf8e-2645e8e5f3af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1219713499-172.17.0.19-1598091132777:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37351,DS-92604e18-093b-41f8-8bfa-45c35a03700a,DISK], DatanodeInfoWithStorage[127.0.0.1:46524,DS-990bbf7a-d7b0-4efa-b4f3-0315ce95be5d,DISK], DatanodeInfoWithStorage[127.0.0.1:34349,DS-04f1eab2-ecc7-4bbc-9fea-2de660dc099b,DISK], DatanodeInfoWithStorage[127.0.0.1:42767,DS-5e2829fa-fb43-4a60-b8fc-46100c366f9b,DISK], DatanodeInfoWithStorage[127.0.0.1:42744,DS-0e658424-7c29-46d1-9636-7160143ff445,DISK], DatanodeInfoWithStorage[127.0.0.1:35812,DS-ee30291e-f08e-4291-ad0c-74c89a4675ba,DISK], DatanodeInfoWithStorage[127.0.0.1:37516,DS-2bde9c07-122a-4923-ba5a-8c0506fc4571,DISK], DatanodeInfoWithStorage[127.0.0.1:44901,DS-a23faa7c-07ba-4e27-acf7-bf527c6dd944,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1219713499-172.17.0.19-1598091132777:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37351,DS-92604e18-093b-41f8-8bfa-45c35a03700a,DISK], DatanodeInfoWithStorage[127.0.0.1:46524,DS-990bbf7a-d7b0-4efa-b4f3-0315ce95be5d,DISK], DatanodeInfoWithStorage[127.0.0.1:34349,DS-04f1eab2-ecc7-4bbc-9fea-2de660dc099b,DISK], DatanodeInfoWithStorage[127.0.0.1:42767,DS-5e2829fa-fb43-4a60-b8fc-46100c366f9b,DISK], DatanodeInfoWithStorage[127.0.0.1:42744,DS-0e658424-7c29-46d1-9636-7160143ff445,DISK], DatanodeInfoWithStorage[127.0.0.1:35812,DS-ee30291e-f08e-4291-ad0c-74c89a4675ba,DISK], DatanodeInfoWithStorage[127.0.0.1:37516,DS-2bde9c07-122a-4923-ba5a-8c0506fc4571,DISK], DatanodeInfoWithStorage[127.0.0.1:44901,DS-a23faa7c-07ba-4e27-acf7-bf527c6dd944,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-738701455-172.17.0.19-1598091407057:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41543,DS-83c3ae35-3ecd-4321-a86e-5ee8b9c45cce,DISK], DatanodeInfoWithStorage[127.0.0.1:44617,DS-3d7e9049-4286-4501-a813-c4b001dd2d42,DISK], DatanodeInfoWithStorage[127.0.0.1:38216,DS-81db04e2-3275-4e48-bce8-5b17baf40380,DISK], DatanodeInfoWithStorage[127.0.0.1:35256,DS-43308903-0f2c-480f-a5bf-4f5b4e6184ae,DISK], DatanodeInfoWithStorage[127.0.0.1:43572,DS-db82c61a-7308-470e-a611-c3a6bf6aec69,DISK], DatanodeInfoWithStorage[127.0.0.1:33970,DS-98f2964e-ae73-4a7f-809d-c7f316364d75,DISK], DatanodeInfoWithStorage[127.0.0.1:35984,DS-734f363b-7426-47f1-8c03-48a238979d0b,DISK], DatanodeInfoWithStorage[127.0.0.1:36866,DS-d1804aec-ad7e-4597-959f-5f4df3d49727,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-738701455-172.17.0.19-1598091407057:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41543,DS-83c3ae35-3ecd-4321-a86e-5ee8b9c45cce,DISK], DatanodeInfoWithStorage[127.0.0.1:44617,DS-3d7e9049-4286-4501-a813-c4b001dd2d42,DISK], DatanodeInfoWithStorage[127.0.0.1:38216,DS-81db04e2-3275-4e48-bce8-5b17baf40380,DISK], DatanodeInfoWithStorage[127.0.0.1:35256,DS-43308903-0f2c-480f-a5bf-4f5b4e6184ae,DISK], DatanodeInfoWithStorage[127.0.0.1:43572,DS-db82c61a-7308-470e-a611-c3a6bf6aec69,DISK], DatanodeInfoWithStorage[127.0.0.1:33970,DS-98f2964e-ae73-4a7f-809d-c7f316364d75,DISK], DatanodeInfoWithStorage[127.0.0.1:35984,DS-734f363b-7426-47f1-8c03-48a238979d0b,DISK], DatanodeInfoWithStorage[127.0.0.1:36866,DS-d1804aec-ad7e-4597-959f-5f4df3d49727,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1266641761-172.17.0.19-1598091796370:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35871,DS-d8671bef-6f99-4726-999b-89b28056fb5a,DISK], DatanodeInfoWithStorage[127.0.0.1:42113,DS-1048416d-58af-4c16-b44b-33fcfe02b4e1,DISK], DatanodeInfoWithStorage[127.0.0.1:45188,DS-abc3bbbd-26c9-4de5-b3c9-0d1bf6a8f9ff,DISK], DatanodeInfoWithStorage[127.0.0.1:40700,DS-1cd3f7df-c26e-4f14-96b3-df2e54974c11,DISK], DatanodeInfoWithStorage[127.0.0.1:34434,DS-ff630cc5-9fd3-454c-9ede-0d607a285c8e,DISK], DatanodeInfoWithStorage[127.0.0.1:38444,DS-17b91e86-5bef-489e-ae74-f612ef36c788,DISK], DatanodeInfoWithStorage[127.0.0.1:45983,DS-2834d57a-9658-410c-b965-975f19c474df,DISK], DatanodeInfoWithStorage[127.0.0.1:40059,DS-5aee9c69-8889-4df4-87c5-68ca57e3521e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1266641761-172.17.0.19-1598091796370:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35871,DS-d8671bef-6f99-4726-999b-89b28056fb5a,DISK], DatanodeInfoWithStorage[127.0.0.1:42113,DS-1048416d-58af-4c16-b44b-33fcfe02b4e1,DISK], DatanodeInfoWithStorage[127.0.0.1:45188,DS-abc3bbbd-26c9-4de5-b3c9-0d1bf6a8f9ff,DISK], DatanodeInfoWithStorage[127.0.0.1:40700,DS-1cd3f7df-c26e-4f14-96b3-df2e54974c11,DISK], DatanodeInfoWithStorage[127.0.0.1:34434,DS-ff630cc5-9fd3-454c-9ede-0d607a285c8e,DISK], DatanodeInfoWithStorage[127.0.0.1:38444,DS-17b91e86-5bef-489e-ae74-f612ef36c788,DISK], DatanodeInfoWithStorage[127.0.0.1:45983,DS-2834d57a-9658-410c-b965-975f19c474df,DISK], DatanodeInfoWithStorage[127.0.0.1:40059,DS-5aee9c69-8889-4df4-87c5-68ca57e3521e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1365815962-172.17.0.19-1598091986790:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39239,DS-fa83c549-7680-4ce5-b411-49270b7cbcfb,DISK], DatanodeInfoWithStorage[127.0.0.1:33784,DS-d931076d-fefc-4c4b-94cc-9656e78b5d0d,DISK], DatanodeInfoWithStorage[127.0.0.1:43514,DS-38cafb30-ea3c-4b0a-8dd6-0c5f7ac5711a,DISK], DatanodeInfoWithStorage[127.0.0.1:34229,DS-943a9b1e-7af5-452b-b56e-7c9a3e1be236,DISK], DatanodeInfoWithStorage[127.0.0.1:38903,DS-bafa6a93-dea1-4bb3-8ca1-822f6936cfcc,DISK], DatanodeInfoWithStorage[127.0.0.1:36340,DS-5bc527d2-16e6-44df-9d09-ba8ce49daf96,DISK], DatanodeInfoWithStorage[127.0.0.1:45776,DS-2bcadc56-d965-4eca-a29a-a9f6a2a10abe,DISK], DatanodeInfoWithStorage[127.0.0.1:37256,DS-2d2feeba-c44a-4959-b45f-e95f97cb0c58,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1365815962-172.17.0.19-1598091986790:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39239,DS-fa83c549-7680-4ce5-b411-49270b7cbcfb,DISK], DatanodeInfoWithStorage[127.0.0.1:33784,DS-d931076d-fefc-4c4b-94cc-9656e78b5d0d,DISK], DatanodeInfoWithStorage[127.0.0.1:43514,DS-38cafb30-ea3c-4b0a-8dd6-0c5f7ac5711a,DISK], DatanodeInfoWithStorage[127.0.0.1:34229,DS-943a9b1e-7af5-452b-b56e-7c9a3e1be236,DISK], DatanodeInfoWithStorage[127.0.0.1:38903,DS-bafa6a93-dea1-4bb3-8ca1-822f6936cfcc,DISK], DatanodeInfoWithStorage[127.0.0.1:36340,DS-5bc527d2-16e6-44df-9d09-ba8ce49daf96,DISK], DatanodeInfoWithStorage[127.0.0.1:45776,DS-2bcadc56-d965-4eca-a29a-a9f6a2a10abe,DISK], DatanodeInfoWithStorage[127.0.0.1:37256,DS-2d2feeba-c44a-4959-b45f-e95f97cb0c58,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-855457768-172.17.0.19-1598093066468:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37113,DS-845db024-500d-46ab-bd2d-b7902e387b3c,DISK], DatanodeInfoWithStorage[127.0.0.1:39622,DS-d1eaca16-9f3d-4f32-b4f1-e856bfe3c97b,DISK], DatanodeInfoWithStorage[127.0.0.1:38457,DS-d368b439-9757-4170-9af6-186ebe82df4d,DISK], DatanodeInfoWithStorage[127.0.0.1:42435,DS-0b3c3625-40f4-4566-9548-eb1e29b3a8a4,DISK], DatanodeInfoWithStorage[127.0.0.1:34982,DS-9d97047d-c770-4041-9eb3-f6a1afc07474,DISK], DatanodeInfoWithStorage[127.0.0.1:40779,DS-9b3e367b-8b08-4b83-b22e-6ea7d0323635,DISK], DatanodeInfoWithStorage[127.0.0.1:36699,DS-80f732d3-46d1-437a-b50a-04ac41346725,DISK], DatanodeInfoWithStorage[127.0.0.1:39437,DS-4f324ec1-c3af-445a-ac3b-201611d07155,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-855457768-172.17.0.19-1598093066468:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37113,DS-845db024-500d-46ab-bd2d-b7902e387b3c,DISK], DatanodeInfoWithStorage[127.0.0.1:39622,DS-d1eaca16-9f3d-4f32-b4f1-e856bfe3c97b,DISK], DatanodeInfoWithStorage[127.0.0.1:38457,DS-d368b439-9757-4170-9af6-186ebe82df4d,DISK], DatanodeInfoWithStorage[127.0.0.1:42435,DS-0b3c3625-40f4-4566-9548-eb1e29b3a8a4,DISK], DatanodeInfoWithStorage[127.0.0.1:34982,DS-9d97047d-c770-4041-9eb3-f6a1afc07474,DISK], DatanodeInfoWithStorage[127.0.0.1:40779,DS-9b3e367b-8b08-4b83-b22e-6ea7d0323635,DISK], DatanodeInfoWithStorage[127.0.0.1:36699,DS-80f732d3-46d1-437a-b50a-04ac41346725,DISK], DatanodeInfoWithStorage[127.0.0.1:39437,DS-4f324ec1-c3af-445a-ac3b-201611d07155,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1346716966-172.17.0.19-1598093215799:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40627,DS-29d568cb-c190-42e7-a2b7-0fa526dc5530,DISK], DatanodeInfoWithStorage[127.0.0.1:35638,DS-dd0dc706-e6af-4bbd-a23c-de3c8ebee824,DISK], DatanodeInfoWithStorage[127.0.0.1:38271,DS-04bb9e8a-19db-4f45-baf6-4b31544be377,DISK], DatanodeInfoWithStorage[127.0.0.1:40890,DS-65a67efb-5374-4555-9655-399ed3816429,DISK], DatanodeInfoWithStorage[127.0.0.1:41240,DS-707a38ef-4f1c-4baa-9b97-814f7cd8d419,DISK], DatanodeInfoWithStorage[127.0.0.1:36702,DS-ee5818a2-ad75-41dd-a3e7-4b687181342c,DISK], DatanodeInfoWithStorage[127.0.0.1:38399,DS-6db1588b-1acd-4793-846a-9fe70687543c,DISK], DatanodeInfoWithStorage[127.0.0.1:36903,DS-968d0668-e7ae-4884-b49f-2a0dfa0a6ac7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1346716966-172.17.0.19-1598093215799:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40627,DS-29d568cb-c190-42e7-a2b7-0fa526dc5530,DISK], DatanodeInfoWithStorage[127.0.0.1:35638,DS-dd0dc706-e6af-4bbd-a23c-de3c8ebee824,DISK], DatanodeInfoWithStorage[127.0.0.1:38271,DS-04bb9e8a-19db-4f45-baf6-4b31544be377,DISK], DatanodeInfoWithStorage[127.0.0.1:40890,DS-65a67efb-5374-4555-9655-399ed3816429,DISK], DatanodeInfoWithStorage[127.0.0.1:41240,DS-707a38ef-4f1c-4baa-9b97-814f7cd8d419,DISK], DatanodeInfoWithStorage[127.0.0.1:36702,DS-ee5818a2-ad75-41dd-a3e7-4b687181342c,DISK], DatanodeInfoWithStorage[127.0.0.1:38399,DS-6db1588b-1acd-4793-846a-9fe70687543c,DISK], DatanodeInfoWithStorage[127.0.0.1:36903,DS-968d0668-e7ae-4884-b49f-2a0dfa0a6ac7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1799382133-172.17.0.19-1598093331579:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45634,DS-e9c1e552-97e6-48e4-b1e7-3969ffea9129,DISK], DatanodeInfoWithStorage[127.0.0.1:43745,DS-a13b3d84-9610-49dd-a8dc-adc8f3853cfd,DISK], DatanodeInfoWithStorage[127.0.0.1:35454,DS-b7396a96-e942-42fe-b575-9024783a39ef,DISK], DatanodeInfoWithStorage[127.0.0.1:44339,DS-591c30fe-46a3-42b1-8b2c-cd0c0d9c32f7,DISK], DatanodeInfoWithStorage[127.0.0.1:41703,DS-afef00b2-c714-418e-a652-42eb36e8ef95,DISK], DatanodeInfoWithStorage[127.0.0.1:37820,DS-0a0b50a2-81b4-492b-b530-83fd453884d2,DISK], DatanodeInfoWithStorage[127.0.0.1:42870,DS-16ea71c5-e052-439d-8e8f-b7cdea6e7302,DISK], DatanodeInfoWithStorage[127.0.0.1:37534,DS-dcdccd98-c484-4323-a24b-5cac335bd305,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1799382133-172.17.0.19-1598093331579:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45634,DS-e9c1e552-97e6-48e4-b1e7-3969ffea9129,DISK], DatanodeInfoWithStorage[127.0.0.1:43745,DS-a13b3d84-9610-49dd-a8dc-adc8f3853cfd,DISK], DatanodeInfoWithStorage[127.0.0.1:35454,DS-b7396a96-e942-42fe-b575-9024783a39ef,DISK], DatanodeInfoWithStorage[127.0.0.1:44339,DS-591c30fe-46a3-42b1-8b2c-cd0c0d9c32f7,DISK], DatanodeInfoWithStorage[127.0.0.1:41703,DS-afef00b2-c714-418e-a652-42eb36e8ef95,DISK], DatanodeInfoWithStorage[127.0.0.1:37820,DS-0a0b50a2-81b4-492b-b530-83fd453884d2,DISK], DatanodeInfoWithStorage[127.0.0.1:42870,DS-16ea71c5-e052-439d-8e8f-b7cdea6e7302,DISK], DatanodeInfoWithStorage[127.0.0.1:37534,DS-dcdccd98-c484-4323-a24b-5cac335bd305,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-727656405-172.17.0.19-1598093679847:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44859,DS-27c2bd82-3c6a-4e02-8360-0f1b02feb202,DISK], DatanodeInfoWithStorage[127.0.0.1:37700,DS-e68b0b38-fccd-4804-928f-3d8dbaac6d7e,DISK], DatanodeInfoWithStorage[127.0.0.1:46506,DS-3d345a9c-9f61-4c6b-9996-018b24705350,DISK], DatanodeInfoWithStorage[127.0.0.1:42640,DS-03b2abe7-a90d-484f-93bb-2198ffaec97c,DISK], DatanodeInfoWithStorage[127.0.0.1:43996,DS-c1227cb4-84a9-442f-8853-1883b2331394,DISK], DatanodeInfoWithStorage[127.0.0.1:42273,DS-1da01af9-c5e8-48ce-9513-b5f1abf2aef8,DISK], DatanodeInfoWithStorage[127.0.0.1:41394,DS-4054e33f-824b-434e-aed1-84ce4a91a32b,DISK], DatanodeInfoWithStorage[127.0.0.1:40614,DS-505c2943-f061-4159-8e9f-4d544d638a0e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-727656405-172.17.0.19-1598093679847:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44859,DS-27c2bd82-3c6a-4e02-8360-0f1b02feb202,DISK], DatanodeInfoWithStorage[127.0.0.1:37700,DS-e68b0b38-fccd-4804-928f-3d8dbaac6d7e,DISK], DatanodeInfoWithStorage[127.0.0.1:46506,DS-3d345a9c-9f61-4c6b-9996-018b24705350,DISK], DatanodeInfoWithStorage[127.0.0.1:42640,DS-03b2abe7-a90d-484f-93bb-2198ffaec97c,DISK], DatanodeInfoWithStorage[127.0.0.1:43996,DS-c1227cb4-84a9-442f-8853-1883b2331394,DISK], DatanodeInfoWithStorage[127.0.0.1:42273,DS-1da01af9-c5e8-48ce-9513-b5f1abf2aef8,DISK], DatanodeInfoWithStorage[127.0.0.1:41394,DS-4054e33f-824b-434e-aed1-84ce4a91a32b,DISK], DatanodeInfoWithStorage[127.0.0.1:40614,DS-505c2943-f061-4159-8e9f-4d544d638a0e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1338772079-172.17.0.19-1598093814425:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38867,DS-de737585-64c3-4b6c-bdc8-b1d4bb378887,DISK], DatanodeInfoWithStorage[127.0.0.1:38296,DS-432e5930-2cb0-4813-8513-488c3b53e6a5,DISK], DatanodeInfoWithStorage[127.0.0.1:45134,DS-445492bd-ddcf-4c36-9bda-e5824e67cbf6,DISK], DatanodeInfoWithStorage[127.0.0.1:38639,DS-5c88541f-a458-449c-afb2-a9325238234e,DISK], DatanodeInfoWithStorage[127.0.0.1:39279,DS-abffdc3e-422f-4c23-97c6-b62ae8e7e853,DISK], DatanodeInfoWithStorage[127.0.0.1:36694,DS-98e04ce0-ec42-4eca-bb55-f1f6f512cad2,DISK], DatanodeInfoWithStorage[127.0.0.1:36473,DS-ab84356f-3fde-49ba-825d-f665636be615,DISK], DatanodeInfoWithStorage[127.0.0.1:44274,DS-796ae7ab-d25d-409a-964e-e0ea17126961,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1338772079-172.17.0.19-1598093814425:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38867,DS-de737585-64c3-4b6c-bdc8-b1d4bb378887,DISK], DatanodeInfoWithStorage[127.0.0.1:38296,DS-432e5930-2cb0-4813-8513-488c3b53e6a5,DISK], DatanodeInfoWithStorage[127.0.0.1:45134,DS-445492bd-ddcf-4c36-9bda-e5824e67cbf6,DISK], DatanodeInfoWithStorage[127.0.0.1:38639,DS-5c88541f-a458-449c-afb2-a9325238234e,DISK], DatanodeInfoWithStorage[127.0.0.1:39279,DS-abffdc3e-422f-4c23-97c6-b62ae8e7e853,DISK], DatanodeInfoWithStorage[127.0.0.1:36694,DS-98e04ce0-ec42-4eca-bb55-f1f6f512cad2,DISK], DatanodeInfoWithStorage[127.0.0.1:36473,DS-ab84356f-3fde-49ba-825d-f665636be615,DISK], DatanodeInfoWithStorage[127.0.0.1:44274,DS-796ae7ab-d25d-409a-964e-e0ea17126961,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-20951786-172.17.0.19-1598094316311:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36202,DS-f0601a97-70c2-4dbc-bc69-72fe6ac6bd00,DISK], DatanodeInfoWithStorage[127.0.0.1:42644,DS-413679d8-e87c-4b0c-b620-c6b2f267d295,DISK], DatanodeInfoWithStorage[127.0.0.1:37032,DS-bb1c2ce5-1495-4353-940b-98c3ec7ed492,DISK], DatanodeInfoWithStorage[127.0.0.1:34335,DS-f3652c98-1ff0-4254-95d3-53b958f2f56a,DISK], DatanodeInfoWithStorage[127.0.0.1:35310,DS-d005ae38-fbea-47d4-af15-26c50f3d1d1b,DISK], DatanodeInfoWithStorage[127.0.0.1:35278,DS-e2ab1d28-eb2a-45d4-afbe-8b69c8a4e931,DISK], DatanodeInfoWithStorage[127.0.0.1:42065,DS-ca2a1d39-1adf-4410-909d-fff21a1d2006,DISK], DatanodeInfoWithStorage[127.0.0.1:41188,DS-388d235f-f743-48ff-91cd-47d30b2f6894,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-20951786-172.17.0.19-1598094316311:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36202,DS-f0601a97-70c2-4dbc-bc69-72fe6ac6bd00,DISK], DatanodeInfoWithStorage[127.0.0.1:42644,DS-413679d8-e87c-4b0c-b620-c6b2f267d295,DISK], DatanodeInfoWithStorage[127.0.0.1:37032,DS-bb1c2ce5-1495-4353-940b-98c3ec7ed492,DISK], DatanodeInfoWithStorage[127.0.0.1:34335,DS-f3652c98-1ff0-4254-95d3-53b958f2f56a,DISK], DatanodeInfoWithStorage[127.0.0.1:35310,DS-d005ae38-fbea-47d4-af15-26c50f3d1d1b,DISK], DatanodeInfoWithStorage[127.0.0.1:35278,DS-e2ab1d28-eb2a-45d4-afbe-8b69c8a4e931,DISK], DatanodeInfoWithStorage[127.0.0.1:42065,DS-ca2a1d39-1adf-4410-909d-fff21a1d2006,DISK], DatanodeInfoWithStorage[127.0.0.1:41188,DS-388d235f-f743-48ff-91cd-47d30b2f6894,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1458974912-172.17.0.19-1598094681146:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41295,DS-ce305220-ba8a-47c6-91bd-6ce5eaf2304b,DISK], DatanodeInfoWithStorage[127.0.0.1:36015,DS-4dfbc0e9-9d12-4889-a980-a6d47b534e2c,DISK], DatanodeInfoWithStorage[127.0.0.1:39151,DS-3b974f12-a1e3-41e7-abf9-6d950a4b4dd1,DISK], DatanodeInfoWithStorage[127.0.0.1:45443,DS-bf9a853c-6007-4288-a980-b764caa0d0a3,DISK], DatanodeInfoWithStorage[127.0.0.1:46611,DS-54f711c0-123f-43cd-a724-2175607c70ba,DISK], DatanodeInfoWithStorage[127.0.0.1:34236,DS-50155afc-6cff-4f14-9090-74b827a810eb,DISK], DatanodeInfoWithStorage[127.0.0.1:34545,DS-13b0a741-4bde-4a85-bb7b-645848e23edd,DISK], DatanodeInfoWithStorage[127.0.0.1:39626,DS-634a7f2b-f2c3-4db5-b8ad-0551616ad77f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1458974912-172.17.0.19-1598094681146:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41295,DS-ce305220-ba8a-47c6-91bd-6ce5eaf2304b,DISK], DatanodeInfoWithStorage[127.0.0.1:36015,DS-4dfbc0e9-9d12-4889-a980-a6d47b534e2c,DISK], DatanodeInfoWithStorage[127.0.0.1:39151,DS-3b974f12-a1e3-41e7-abf9-6d950a4b4dd1,DISK], DatanodeInfoWithStorage[127.0.0.1:45443,DS-bf9a853c-6007-4288-a980-b764caa0d0a3,DISK], DatanodeInfoWithStorage[127.0.0.1:46611,DS-54f711c0-123f-43cd-a724-2175607c70ba,DISK], DatanodeInfoWithStorage[127.0.0.1:34236,DS-50155afc-6cff-4f14-9090-74b827a810eb,DISK], DatanodeInfoWithStorage[127.0.0.1:34545,DS-13b0a741-4bde-4a85-bb7b-645848e23edd,DISK], DatanodeInfoWithStorage[127.0.0.1:39626,DS-634a7f2b-f2c3-4db5-b8ad-0551616ad77f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1955463608-172.17.0.19-1598095102577:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40842,DS-31aa3415-2732-43cc-b682-9a9509ba713f,DISK], DatanodeInfoWithStorage[127.0.0.1:33317,DS-9e93a605-8c89-435c-a79c-ca3dee62c3c9,DISK], DatanodeInfoWithStorage[127.0.0.1:35117,DS-367ed5da-3de7-4435-8833-681c7456861f,DISK], DatanodeInfoWithStorage[127.0.0.1:37904,DS-cce571e3-d748-4131-82ad-02a3269fed8d,DISK], DatanodeInfoWithStorage[127.0.0.1:33299,DS-0ba37c5c-2405-460a-b5ac-14df5fe0bc06,DISK], DatanodeInfoWithStorage[127.0.0.1:33636,DS-c13f3f6a-70b0-4fe3-a462-65b6c4316e01,DISK], DatanodeInfoWithStorage[127.0.0.1:34782,DS-ed01cba8-0e24-449f-ad46-c5016c72161a,DISK], DatanodeInfoWithStorage[127.0.0.1:38902,DS-e171d99a-b7a3-4b90-a358-0b69c1096b1b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1955463608-172.17.0.19-1598095102577:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40842,DS-31aa3415-2732-43cc-b682-9a9509ba713f,DISK], DatanodeInfoWithStorage[127.0.0.1:33317,DS-9e93a605-8c89-435c-a79c-ca3dee62c3c9,DISK], DatanodeInfoWithStorage[127.0.0.1:35117,DS-367ed5da-3de7-4435-8833-681c7456861f,DISK], DatanodeInfoWithStorage[127.0.0.1:37904,DS-cce571e3-d748-4131-82ad-02a3269fed8d,DISK], DatanodeInfoWithStorage[127.0.0.1:33299,DS-0ba37c5c-2405-460a-b5ac-14df5fe0bc06,DISK], DatanodeInfoWithStorage[127.0.0.1:33636,DS-c13f3f6a-70b0-4fe3-a462-65b6c4316e01,DISK], DatanodeInfoWithStorage[127.0.0.1:34782,DS-ed01cba8-0e24-449f-ad46-c5016c72161a,DISK], DatanodeInfoWithStorage[127.0.0.1:38902,DS-e171d99a-b7a3-4b90-a358-0b69c1096b1b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-644585965-172.17.0.19-1598095695495:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34125,DS-ee01a05e-7679-48ea-81d3-4729131b7a1d,DISK], DatanodeInfoWithStorage[127.0.0.1:46056,DS-c257996d-7382-4795-b65d-8226ca5c07d5,DISK], DatanodeInfoWithStorage[127.0.0.1:43995,DS-325fd9b5-2e52-4a3e-a6d9-d749684ac4e1,DISK], DatanodeInfoWithStorage[127.0.0.1:43222,DS-ca5f0492-efdf-4e11-827a-f3995d0d6eb1,DISK], DatanodeInfoWithStorage[127.0.0.1:37761,DS-9fe560ed-f282-4e11-83e4-9e6bb0ca4c7d,DISK], DatanodeInfoWithStorage[127.0.0.1:33117,DS-82194163-81b0-4b18-870f-ee4e921f7e8b,DISK], DatanodeInfoWithStorage[127.0.0.1:45665,DS-4861f6ed-9a2b-4fd8-86fe-466a31101b1b,DISK], DatanodeInfoWithStorage[127.0.0.1:43064,DS-00b7fb84-d2ee-4aa0-a236-b8e937163502,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-644585965-172.17.0.19-1598095695495:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34125,DS-ee01a05e-7679-48ea-81d3-4729131b7a1d,DISK], DatanodeInfoWithStorage[127.0.0.1:46056,DS-c257996d-7382-4795-b65d-8226ca5c07d5,DISK], DatanodeInfoWithStorage[127.0.0.1:43995,DS-325fd9b5-2e52-4a3e-a6d9-d749684ac4e1,DISK], DatanodeInfoWithStorage[127.0.0.1:43222,DS-ca5f0492-efdf-4e11-827a-f3995d0d6eb1,DISK], DatanodeInfoWithStorage[127.0.0.1:37761,DS-9fe560ed-f282-4e11-83e4-9e6bb0ca4c7d,DISK], DatanodeInfoWithStorage[127.0.0.1:33117,DS-82194163-81b0-4b18-870f-ee4e921f7e8b,DISK], DatanodeInfoWithStorage[127.0.0.1:45665,DS-4861f6ed-9a2b-4fd8-86fe-466a31101b1b,DISK], DatanodeInfoWithStorage[127.0.0.1:43064,DS-00b7fb84-d2ee-4aa0-a236-b8e937163502,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-207539484-172.17.0.19-1598095816888:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35411,DS-0fbdf94c-975f-4566-8c88-e82e9b1f7c15,DISK], DatanodeInfoWithStorage[127.0.0.1:40733,DS-3f8a8186-6bbe-44d1-bbb6-43b4350e6038,DISK], DatanodeInfoWithStorage[127.0.0.1:39018,DS-75aae0dd-4099-441c-9cd9-a84990980c96,DISK], DatanodeInfoWithStorage[127.0.0.1:46258,DS-2cb3d3b6-bebe-45c6-a453-f72fd38205ec,DISK], DatanodeInfoWithStorage[127.0.0.1:43421,DS-912fb030-e551-436f-b491-d43828286ba4,DISK], DatanodeInfoWithStorage[127.0.0.1:42795,DS-6f89811b-d693-4f3f-b2b3-8b78ec1afb69,DISK], DatanodeInfoWithStorage[127.0.0.1:35047,DS-9bb4214d-6579-4d4f-ab78-b3ff2060a077,DISK], DatanodeInfoWithStorage[127.0.0.1:43404,DS-38aad277-95e8-49d8-ae37-927d3e21e8e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-207539484-172.17.0.19-1598095816888:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35411,DS-0fbdf94c-975f-4566-8c88-e82e9b1f7c15,DISK], DatanodeInfoWithStorage[127.0.0.1:40733,DS-3f8a8186-6bbe-44d1-bbb6-43b4350e6038,DISK], DatanodeInfoWithStorage[127.0.0.1:39018,DS-75aae0dd-4099-441c-9cd9-a84990980c96,DISK], DatanodeInfoWithStorage[127.0.0.1:46258,DS-2cb3d3b6-bebe-45c6-a453-f72fd38205ec,DISK], DatanodeInfoWithStorage[127.0.0.1:43421,DS-912fb030-e551-436f-b491-d43828286ba4,DISK], DatanodeInfoWithStorage[127.0.0.1:42795,DS-6f89811b-d693-4f3f-b2b3-8b78ec1afb69,DISK], DatanodeInfoWithStorage[127.0.0.1:35047,DS-9bb4214d-6579-4d4f-ab78-b3ff2060a077,DISK], DatanodeInfoWithStorage[127.0.0.1:43404,DS-38aad277-95e8-49d8-ae37-927d3e21e8e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5963
