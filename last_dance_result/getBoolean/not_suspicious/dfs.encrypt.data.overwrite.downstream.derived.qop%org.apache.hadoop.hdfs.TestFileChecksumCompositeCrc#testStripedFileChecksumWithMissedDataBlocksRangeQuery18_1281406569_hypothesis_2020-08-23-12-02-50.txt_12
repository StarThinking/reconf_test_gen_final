reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2087003901-172.17.0.16-1598184358267:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38701,DS-263bed87-d359-4a59-a3fc-a4b3e580ee3d,DISK], DatanodeInfoWithStorage[127.0.0.1:42871,DS-17082279-a944-48c3-96e6-385a50fd178e,DISK], DatanodeInfoWithStorage[127.0.0.1:35813,DS-b9fdccda-ae8d-4e12-b201-34455fa63e34,DISK], DatanodeInfoWithStorage[127.0.0.1:42009,DS-eb382152-9dff-4695-b2bd-fcc887e61c8a,DISK], DatanodeInfoWithStorage[127.0.0.1:40785,DS-3e7fd544-f453-4bf9-b852-959fcaa46683,DISK], DatanodeInfoWithStorage[127.0.0.1:37055,DS-815efc52-09dc-439b-8d96-f720601a3dc1,DISK], DatanodeInfoWithStorage[127.0.0.1:40335,DS-821dd689-eb00-44d6-b00e-a75aaef5b8d8,DISK], DatanodeInfoWithStorage[127.0.0.1:39599,DS-cfa8b860-f9f4-4966-9f2e-c75ce7e21162,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2087003901-172.17.0.16-1598184358267:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38701,DS-263bed87-d359-4a59-a3fc-a4b3e580ee3d,DISK], DatanodeInfoWithStorage[127.0.0.1:42871,DS-17082279-a944-48c3-96e6-385a50fd178e,DISK], DatanodeInfoWithStorage[127.0.0.1:35813,DS-b9fdccda-ae8d-4e12-b201-34455fa63e34,DISK], DatanodeInfoWithStorage[127.0.0.1:42009,DS-eb382152-9dff-4695-b2bd-fcc887e61c8a,DISK], DatanodeInfoWithStorage[127.0.0.1:40785,DS-3e7fd544-f453-4bf9-b852-959fcaa46683,DISK], DatanodeInfoWithStorage[127.0.0.1:37055,DS-815efc52-09dc-439b-8d96-f720601a3dc1,DISK], DatanodeInfoWithStorage[127.0.0.1:40335,DS-821dd689-eb00-44d6-b00e-a75aaef5b8d8,DISK], DatanodeInfoWithStorage[127.0.0.1:39599,DS-cfa8b860-f9f4-4966-9f2e-c75ce7e21162,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2018515324-172.17.0.16-1598184692020:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41782,DS-b4e9cf97-2898-4686-b74d-2e29ed8e1a5c,DISK], DatanodeInfoWithStorage[127.0.0.1:41702,DS-8744ad15-08ba-4acf-8126-f55c823b84ee,DISK], DatanodeInfoWithStorage[127.0.0.1:37640,DS-9586f2bc-9743-4c49-b398-f33305e1a4d5,DISK], DatanodeInfoWithStorage[127.0.0.1:36417,DS-33be08b2-4df3-4d5a-b43a-67d36ce100ce,DISK], DatanodeInfoWithStorage[127.0.0.1:38382,DS-c82501a6-0ed5-4d70-af92-0d674327474c,DISK], DatanodeInfoWithStorage[127.0.0.1:44569,DS-77831e7d-fc8f-4e96-af1d-c2690d7a7192,DISK], DatanodeInfoWithStorage[127.0.0.1:44295,DS-2f0b454c-791b-4252-a3c4-44a79cf4cea5,DISK], DatanodeInfoWithStorage[127.0.0.1:45019,DS-453705e4-e9de-4a9e-a34f-858b764a61d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2018515324-172.17.0.16-1598184692020:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41782,DS-b4e9cf97-2898-4686-b74d-2e29ed8e1a5c,DISK], DatanodeInfoWithStorage[127.0.0.1:41702,DS-8744ad15-08ba-4acf-8126-f55c823b84ee,DISK], DatanodeInfoWithStorage[127.0.0.1:37640,DS-9586f2bc-9743-4c49-b398-f33305e1a4d5,DISK], DatanodeInfoWithStorage[127.0.0.1:36417,DS-33be08b2-4df3-4d5a-b43a-67d36ce100ce,DISK], DatanodeInfoWithStorage[127.0.0.1:38382,DS-c82501a6-0ed5-4d70-af92-0d674327474c,DISK], DatanodeInfoWithStorage[127.0.0.1:44569,DS-77831e7d-fc8f-4e96-af1d-c2690d7a7192,DISK], DatanodeInfoWithStorage[127.0.0.1:44295,DS-2f0b454c-791b-4252-a3c4-44a79cf4cea5,DISK], DatanodeInfoWithStorage[127.0.0.1:45019,DS-453705e4-e9de-4a9e-a34f-858b764a61d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-667669530-172.17.0.16-1598185575018:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38824,DS-385ba8d5-b536-47cc-82eb-8769e9c86879,DISK], DatanodeInfoWithStorage[127.0.0.1:41004,DS-4077c582-d27f-47f1-b1ae-b1fe24e82b7b,DISK], DatanodeInfoWithStorage[127.0.0.1:40685,DS-cf31695f-f2ca-4dde-bd4d-31f34cdc3ff1,DISK], DatanodeInfoWithStorage[127.0.0.1:37664,DS-1e8acf3a-11b6-475c-9e92-4e4002d7a6ec,DISK], DatanodeInfoWithStorage[127.0.0.1:33303,DS-185c5179-1674-45cd-97a1-5f29fa01d643,DISK], DatanodeInfoWithStorage[127.0.0.1:44356,DS-d5d80720-797a-4283-8747-c3327c983952,DISK], DatanodeInfoWithStorage[127.0.0.1:45042,DS-f6af7395-1ae7-4a55-8710-b57c320dbb39,DISK], DatanodeInfoWithStorage[127.0.0.1:39550,DS-a3947cab-9ee9-427a-9611-856833c99655,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-667669530-172.17.0.16-1598185575018:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38824,DS-385ba8d5-b536-47cc-82eb-8769e9c86879,DISK], DatanodeInfoWithStorage[127.0.0.1:41004,DS-4077c582-d27f-47f1-b1ae-b1fe24e82b7b,DISK], DatanodeInfoWithStorage[127.0.0.1:40685,DS-cf31695f-f2ca-4dde-bd4d-31f34cdc3ff1,DISK], DatanodeInfoWithStorage[127.0.0.1:37664,DS-1e8acf3a-11b6-475c-9e92-4e4002d7a6ec,DISK], DatanodeInfoWithStorage[127.0.0.1:33303,DS-185c5179-1674-45cd-97a1-5f29fa01d643,DISK], DatanodeInfoWithStorage[127.0.0.1:44356,DS-d5d80720-797a-4283-8747-c3327c983952,DISK], DatanodeInfoWithStorage[127.0.0.1:45042,DS-f6af7395-1ae7-4a55-8710-b57c320dbb39,DISK], DatanodeInfoWithStorage[127.0.0.1:39550,DS-a3947cab-9ee9-427a-9611-856833c99655,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1124013479-172.17.0.16-1598185821867:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34594,DS-8609f9a6-5104-42ee-8f11-de0f0195237f,DISK], DatanodeInfoWithStorage[127.0.0.1:41709,DS-11020614-e935-4cc1-967c-d7aa3bc3faf3,DISK], DatanodeInfoWithStorage[127.0.0.1:35556,DS-215fab9e-f84f-4824-af3f-9ef0f5f32033,DISK], DatanodeInfoWithStorage[127.0.0.1:33814,DS-e2de894f-00b9-4d33-a850-a0008b8aaed9,DISK], DatanodeInfoWithStorage[127.0.0.1:42105,DS-c093b323-63b7-4b64-824f-db82c4fd766f,DISK], DatanodeInfoWithStorage[127.0.0.1:36087,DS-0a9a7e5f-c8a5-4e04-bb6c-ea14a62fdbac,DISK], DatanodeInfoWithStorage[127.0.0.1:45793,DS-34283984-85ae-45cd-9155-acfe1df259dc,DISK], DatanodeInfoWithStorage[127.0.0.1:40855,DS-4f7192df-fd2e-4f80-ba5a-26e5c1e6ff10,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1124013479-172.17.0.16-1598185821867:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34594,DS-8609f9a6-5104-42ee-8f11-de0f0195237f,DISK], DatanodeInfoWithStorage[127.0.0.1:41709,DS-11020614-e935-4cc1-967c-d7aa3bc3faf3,DISK], DatanodeInfoWithStorage[127.0.0.1:35556,DS-215fab9e-f84f-4824-af3f-9ef0f5f32033,DISK], DatanodeInfoWithStorage[127.0.0.1:33814,DS-e2de894f-00b9-4d33-a850-a0008b8aaed9,DISK], DatanodeInfoWithStorage[127.0.0.1:42105,DS-c093b323-63b7-4b64-824f-db82c4fd766f,DISK], DatanodeInfoWithStorage[127.0.0.1:36087,DS-0a9a7e5f-c8a5-4e04-bb6c-ea14a62fdbac,DISK], DatanodeInfoWithStorage[127.0.0.1:45793,DS-34283984-85ae-45cd-9155-acfe1df259dc,DISK], DatanodeInfoWithStorage[127.0.0.1:40855,DS-4f7192df-fd2e-4f80-ba5a-26e5c1e6ff10,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-299116042-172.17.0.16-1598186191969:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44535,DS-9121f77f-9f09-4807-985e-8148f6f076be,DISK], DatanodeInfoWithStorage[127.0.0.1:35670,DS-7a1d341a-4773-44e0-8579-88e9a839a263,DISK], DatanodeInfoWithStorage[127.0.0.1:43911,DS-f9a7bfbf-c650-4a0d-b422-9b84a8a5f964,DISK], DatanodeInfoWithStorage[127.0.0.1:45017,DS-a41034c5-65ce-475d-8032-52ce881d79cb,DISK], DatanodeInfoWithStorage[127.0.0.1:35404,DS-26ebd69d-7b66-4f30-a852-057e039ab108,DISK], DatanodeInfoWithStorage[127.0.0.1:40976,DS-a823384a-da54-4597-ab8a-4502c0461d45,DISK], DatanodeInfoWithStorage[127.0.0.1:35981,DS-b5f73130-e1b3-4a36-932e-f05ee1d3d2ea,DISK], DatanodeInfoWithStorage[127.0.0.1:36157,DS-6fa5e8ad-957e-4c04-91cf-87e0084c6638,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-299116042-172.17.0.16-1598186191969:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44535,DS-9121f77f-9f09-4807-985e-8148f6f076be,DISK], DatanodeInfoWithStorage[127.0.0.1:35670,DS-7a1d341a-4773-44e0-8579-88e9a839a263,DISK], DatanodeInfoWithStorage[127.0.0.1:43911,DS-f9a7bfbf-c650-4a0d-b422-9b84a8a5f964,DISK], DatanodeInfoWithStorage[127.0.0.1:45017,DS-a41034c5-65ce-475d-8032-52ce881d79cb,DISK], DatanodeInfoWithStorage[127.0.0.1:35404,DS-26ebd69d-7b66-4f30-a852-057e039ab108,DISK], DatanodeInfoWithStorage[127.0.0.1:40976,DS-a823384a-da54-4597-ab8a-4502c0461d45,DISK], DatanodeInfoWithStorage[127.0.0.1:35981,DS-b5f73130-e1b3-4a36-932e-f05ee1d3d2ea,DISK], DatanodeInfoWithStorage[127.0.0.1:36157,DS-6fa5e8ad-957e-4c04-91cf-87e0084c6638,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-76380353-172.17.0.16-1598186506574:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43568,DS-86992cf4-57b2-4f34-af11-d36ab8bd6c43,DISK], DatanodeInfoWithStorage[127.0.0.1:35718,DS-e182209f-be54-4297-9eba-b2c085b380ad,DISK], DatanodeInfoWithStorage[127.0.0.1:34568,DS-9cef3c00-ce45-4d93-be59-2f3288d5309a,DISK], DatanodeInfoWithStorage[127.0.0.1:41941,DS-6c1693aa-6968-4a18-829d-76ab0aff9702,DISK], DatanodeInfoWithStorage[127.0.0.1:43970,DS-b8758544-443b-401d-b1f1-a02736578354,DISK], DatanodeInfoWithStorage[127.0.0.1:35179,DS-a72ce4ef-f8c8-4636-9315-adcebad7b798,DISK], DatanodeInfoWithStorage[127.0.0.1:38531,DS-cb160fd5-14ac-4e08-8f10-b588cff6573f,DISK], DatanodeInfoWithStorage[127.0.0.1:45826,DS-204142df-cd22-4402-bd65-599da7ee4174,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-76380353-172.17.0.16-1598186506574:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43568,DS-86992cf4-57b2-4f34-af11-d36ab8bd6c43,DISK], DatanodeInfoWithStorage[127.0.0.1:35718,DS-e182209f-be54-4297-9eba-b2c085b380ad,DISK], DatanodeInfoWithStorage[127.0.0.1:34568,DS-9cef3c00-ce45-4d93-be59-2f3288d5309a,DISK], DatanodeInfoWithStorage[127.0.0.1:41941,DS-6c1693aa-6968-4a18-829d-76ab0aff9702,DISK], DatanodeInfoWithStorage[127.0.0.1:43970,DS-b8758544-443b-401d-b1f1-a02736578354,DISK], DatanodeInfoWithStorage[127.0.0.1:35179,DS-a72ce4ef-f8c8-4636-9315-adcebad7b798,DISK], DatanodeInfoWithStorage[127.0.0.1:38531,DS-cb160fd5-14ac-4e08-8f10-b588cff6573f,DISK], DatanodeInfoWithStorage[127.0.0.1:45826,DS-204142df-cd22-4402-bd65-599da7ee4174,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-344369764-172.17.0.16-1598186695750:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41366,DS-40e489c3-819b-4b74-81fe-4eec0758553e,DISK], DatanodeInfoWithStorage[127.0.0.1:35952,DS-c097b9b2-a03a-458b-ae9a-3e4d3a33015b,DISK], DatanodeInfoWithStorage[127.0.0.1:40490,DS-9abe667e-43a6-44f7-b493-de21135bf9de,DISK], DatanodeInfoWithStorage[127.0.0.1:43248,DS-1bba7a25-534a-4932-917f-d34f83ec4364,DISK], DatanodeInfoWithStorage[127.0.0.1:45499,DS-4d070888-b9d9-4aa4-9b0b-418e12f6ca69,DISK], DatanodeInfoWithStorage[127.0.0.1:35478,DS-1213e15a-6bb4-4964-835d-628c1c4f5514,DISK], DatanodeInfoWithStorage[127.0.0.1:41551,DS-40daeaf4-f2c8-483f-be8f-d7a4a4348294,DISK], DatanodeInfoWithStorage[127.0.0.1:40698,DS-ce729cc7-cdd9-4322-85a1-ae63ec6096c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-344369764-172.17.0.16-1598186695750:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41366,DS-40e489c3-819b-4b74-81fe-4eec0758553e,DISK], DatanodeInfoWithStorage[127.0.0.1:35952,DS-c097b9b2-a03a-458b-ae9a-3e4d3a33015b,DISK], DatanodeInfoWithStorage[127.0.0.1:40490,DS-9abe667e-43a6-44f7-b493-de21135bf9de,DISK], DatanodeInfoWithStorage[127.0.0.1:43248,DS-1bba7a25-534a-4932-917f-d34f83ec4364,DISK], DatanodeInfoWithStorage[127.0.0.1:45499,DS-4d070888-b9d9-4aa4-9b0b-418e12f6ca69,DISK], DatanodeInfoWithStorage[127.0.0.1:35478,DS-1213e15a-6bb4-4964-835d-628c1c4f5514,DISK], DatanodeInfoWithStorage[127.0.0.1:41551,DS-40daeaf4-f2c8-483f-be8f-d7a4a4348294,DISK], DatanodeInfoWithStorage[127.0.0.1:40698,DS-ce729cc7-cdd9-4322-85a1-ae63ec6096c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-328119277-172.17.0.16-1598186832895:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44580,DS-3b565241-fddc-4389-ad91-7ee24fff3ac5,DISK], DatanodeInfoWithStorage[127.0.0.1:44765,DS-5adfded4-6512-4f5b-be64-5e78d31c4b62,DISK], DatanodeInfoWithStorage[127.0.0.1:41446,DS-ebd2fdb3-ed37-43aa-9cca-e3d794f9b05c,DISK], DatanodeInfoWithStorage[127.0.0.1:43132,DS-26f28d96-52b4-41de-972f-97acbbc6925d,DISK], DatanodeInfoWithStorage[127.0.0.1:36077,DS-a637567e-8eee-4beb-8d04-e53cde8fb94c,DISK], DatanodeInfoWithStorage[127.0.0.1:39670,DS-b1ae4717-4a0e-4636-9ffe-8f9d556f0d90,DISK], DatanodeInfoWithStorage[127.0.0.1:34831,DS-f8f7212f-0b5d-4bb3-92af-f771ffda9263,DISK], DatanodeInfoWithStorage[127.0.0.1:35997,DS-6ee6ab05-6293-4e78-880d-399653be2677,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-328119277-172.17.0.16-1598186832895:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44580,DS-3b565241-fddc-4389-ad91-7ee24fff3ac5,DISK], DatanodeInfoWithStorage[127.0.0.1:44765,DS-5adfded4-6512-4f5b-be64-5e78d31c4b62,DISK], DatanodeInfoWithStorage[127.0.0.1:41446,DS-ebd2fdb3-ed37-43aa-9cca-e3d794f9b05c,DISK], DatanodeInfoWithStorage[127.0.0.1:43132,DS-26f28d96-52b4-41de-972f-97acbbc6925d,DISK], DatanodeInfoWithStorage[127.0.0.1:36077,DS-a637567e-8eee-4beb-8d04-e53cde8fb94c,DISK], DatanodeInfoWithStorage[127.0.0.1:39670,DS-b1ae4717-4a0e-4636-9ffe-8f9d556f0d90,DISK], DatanodeInfoWithStorage[127.0.0.1:34831,DS-f8f7212f-0b5d-4bb3-92af-f771ffda9263,DISK], DatanodeInfoWithStorage[127.0.0.1:35997,DS-6ee6ab05-6293-4e78-880d-399653be2677,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1726662318-172.17.0.16-1598187219278:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44042,DS-a11b9b82-ac09-4889-9e55-bab058870aef,DISK], DatanodeInfoWithStorage[127.0.0.1:35834,DS-2b6e7c40-a3eb-4d28-b01f-fc2fc37dd6ca,DISK], DatanodeInfoWithStorage[127.0.0.1:46752,DS-83173dca-f500-411a-9170-c0729107570c,DISK], DatanodeInfoWithStorage[127.0.0.1:41437,DS-2d956865-e07f-4688-881f-6f4c277abf2d,DISK], DatanodeInfoWithStorage[127.0.0.1:40961,DS-bd232a38-83fd-4bb2-80bb-c04f4fa811ce,DISK], DatanodeInfoWithStorage[127.0.0.1:44536,DS-5f3777f6-70b9-4b7d-a46b-aa7219ac90f5,DISK], DatanodeInfoWithStorage[127.0.0.1:38849,DS-5485f48a-e597-42ce-8f59-6afc4698c400,DISK], DatanodeInfoWithStorage[127.0.0.1:36797,DS-c9ddf47b-8d45-4017-b572-77f7ff431431,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1726662318-172.17.0.16-1598187219278:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44042,DS-a11b9b82-ac09-4889-9e55-bab058870aef,DISK], DatanodeInfoWithStorage[127.0.0.1:35834,DS-2b6e7c40-a3eb-4d28-b01f-fc2fc37dd6ca,DISK], DatanodeInfoWithStorage[127.0.0.1:46752,DS-83173dca-f500-411a-9170-c0729107570c,DISK], DatanodeInfoWithStorage[127.0.0.1:41437,DS-2d956865-e07f-4688-881f-6f4c277abf2d,DISK], DatanodeInfoWithStorage[127.0.0.1:40961,DS-bd232a38-83fd-4bb2-80bb-c04f4fa811ce,DISK], DatanodeInfoWithStorage[127.0.0.1:44536,DS-5f3777f6-70b9-4b7d-a46b-aa7219ac90f5,DISK], DatanodeInfoWithStorage[127.0.0.1:38849,DS-5485f48a-e597-42ce-8f59-6afc4698c400,DISK], DatanodeInfoWithStorage[127.0.0.1:36797,DS-c9ddf47b-8d45-4017-b572-77f7ff431431,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-461119377-172.17.0.16-1598187291123:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38690,DS-826a4848-45e9-4dea-b07d-fbe91c8cebd5,DISK], DatanodeInfoWithStorage[127.0.0.1:40732,DS-9cdb9337-2bc0-4f4d-8c59-8d28baeda7d2,DISK], DatanodeInfoWithStorage[127.0.0.1:40086,DS-148eb0f0-e513-45a1-b1f9-5b5469b3107f,DISK], DatanodeInfoWithStorage[127.0.0.1:37770,DS-88432b44-3022-4c7a-b402-1ef7aa2a0683,DISK], DatanodeInfoWithStorage[127.0.0.1:34394,DS-0174554a-f21e-4702-ad99-ae9e03addf80,DISK], DatanodeInfoWithStorage[127.0.0.1:45734,DS-48dd23ab-2fb1-4dd2-8f4a-b2ad26872227,DISK], DatanodeInfoWithStorage[127.0.0.1:37162,DS-5463db88-6614-4168-8899-b940c94205bd,DISK], DatanodeInfoWithStorage[127.0.0.1:34595,DS-9e9d5071-d8ef-4dfb-860f-bc7ac2717dd6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-461119377-172.17.0.16-1598187291123:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38690,DS-826a4848-45e9-4dea-b07d-fbe91c8cebd5,DISK], DatanodeInfoWithStorage[127.0.0.1:40732,DS-9cdb9337-2bc0-4f4d-8c59-8d28baeda7d2,DISK], DatanodeInfoWithStorage[127.0.0.1:40086,DS-148eb0f0-e513-45a1-b1f9-5b5469b3107f,DISK], DatanodeInfoWithStorage[127.0.0.1:37770,DS-88432b44-3022-4c7a-b402-1ef7aa2a0683,DISK], DatanodeInfoWithStorage[127.0.0.1:34394,DS-0174554a-f21e-4702-ad99-ae9e03addf80,DISK], DatanodeInfoWithStorage[127.0.0.1:45734,DS-48dd23ab-2fb1-4dd2-8f4a-b2ad26872227,DISK], DatanodeInfoWithStorage[127.0.0.1:37162,DS-5463db88-6614-4168-8899-b940c94205bd,DISK], DatanodeInfoWithStorage[127.0.0.1:34595,DS-9e9d5071-d8ef-4dfb-860f-bc7ac2717dd6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-117022214-172.17.0.16-1598187825386:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40476,DS-317adf4c-6753-4731-856c-43a8b12caef2,DISK], DatanodeInfoWithStorage[127.0.0.1:36889,DS-b153cdca-4481-4899-8e14-4867be91e837,DISK], DatanodeInfoWithStorage[127.0.0.1:43000,DS-f96f0580-6963-4b6e-bc45-931f947ac4a3,DISK], DatanodeInfoWithStorage[127.0.0.1:39198,DS-48d2b5b2-195d-4a4a-a6d7-07da0c17d0c7,DISK], DatanodeInfoWithStorage[127.0.0.1:40610,DS-44966b78-9697-4b80-a758-6b9574a06fef,DISK], DatanodeInfoWithStorage[127.0.0.1:46756,DS-25f64496-30f3-4e6c-bfef-bca3fee23bf6,DISK], DatanodeInfoWithStorage[127.0.0.1:43299,DS-cd6f23bb-69c0-4903-bf31-0abf17f96b14,DISK], DatanodeInfoWithStorage[127.0.0.1:42275,DS-aee1c2e9-128c-49d8-9ed9-ff620aae81d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-117022214-172.17.0.16-1598187825386:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40476,DS-317adf4c-6753-4731-856c-43a8b12caef2,DISK], DatanodeInfoWithStorage[127.0.0.1:36889,DS-b153cdca-4481-4899-8e14-4867be91e837,DISK], DatanodeInfoWithStorage[127.0.0.1:43000,DS-f96f0580-6963-4b6e-bc45-931f947ac4a3,DISK], DatanodeInfoWithStorage[127.0.0.1:39198,DS-48d2b5b2-195d-4a4a-a6d7-07da0c17d0c7,DISK], DatanodeInfoWithStorage[127.0.0.1:40610,DS-44966b78-9697-4b80-a758-6b9574a06fef,DISK], DatanodeInfoWithStorage[127.0.0.1:46756,DS-25f64496-30f3-4e6c-bfef-bca3fee23bf6,DISK], DatanodeInfoWithStorage[127.0.0.1:43299,DS-cd6f23bb-69c0-4903-bf31-0abf17f96b14,DISK], DatanodeInfoWithStorage[127.0.0.1:42275,DS-aee1c2e9-128c-49d8-9ed9-ff620aae81d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1884028511-172.17.0.16-1598187887699:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41510,DS-489bacac-96f7-4848-876b-98ae7f93abba,DISK], DatanodeInfoWithStorage[127.0.0.1:34371,DS-3f654bca-3f8f-412a-aaea-74857dbc94c6,DISK], DatanodeInfoWithStorage[127.0.0.1:35315,DS-45c48a16-f60d-4bee-abf0-32406b664ba6,DISK], DatanodeInfoWithStorage[127.0.0.1:37931,DS-e3c94d42-62d4-4834-a4da-9634f7eb5475,DISK], DatanodeInfoWithStorage[127.0.0.1:44970,DS-41e4d9cb-1ae0-4cce-b686-e0120e99eb19,DISK], DatanodeInfoWithStorage[127.0.0.1:36364,DS-9d802d00-682e-4dd2-af31-a9d96254c439,DISK], DatanodeInfoWithStorage[127.0.0.1:40261,DS-47c05867-e448-4312-bd67-d1d9ccb3bc3d,DISK], DatanodeInfoWithStorage[127.0.0.1:42860,DS-58d1b175-7aa5-4ee5-bbee-a28c609ced7c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1884028511-172.17.0.16-1598187887699:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41510,DS-489bacac-96f7-4848-876b-98ae7f93abba,DISK], DatanodeInfoWithStorage[127.0.0.1:34371,DS-3f654bca-3f8f-412a-aaea-74857dbc94c6,DISK], DatanodeInfoWithStorage[127.0.0.1:35315,DS-45c48a16-f60d-4bee-abf0-32406b664ba6,DISK], DatanodeInfoWithStorage[127.0.0.1:37931,DS-e3c94d42-62d4-4834-a4da-9634f7eb5475,DISK], DatanodeInfoWithStorage[127.0.0.1:44970,DS-41e4d9cb-1ae0-4cce-b686-e0120e99eb19,DISK], DatanodeInfoWithStorage[127.0.0.1:36364,DS-9d802d00-682e-4dd2-af31-a9d96254c439,DISK], DatanodeInfoWithStorage[127.0.0.1:40261,DS-47c05867-e448-4312-bd67-d1d9ccb3bc3d,DISK], DatanodeInfoWithStorage[127.0.0.1:42860,DS-58d1b175-7aa5-4ee5-bbee-a28c609ced7c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1397901422-172.17.0.16-1598188070909:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45524,DS-adaae55a-768b-46d3-8753-7e201a881fa2,DISK], DatanodeInfoWithStorage[127.0.0.1:43833,DS-8ce4c8d9-3594-4c4f-ad57-c78696f2c9bd,DISK], DatanodeInfoWithStorage[127.0.0.1:36329,DS-d6cb5bfe-6bff-404d-8ce8-eaf1be70b7cd,DISK], DatanodeInfoWithStorage[127.0.0.1:33409,DS-f61d80e1-b9fe-45c4-9e62-35903d1bea95,DISK], DatanodeInfoWithStorage[127.0.0.1:39231,DS-d701e40c-3484-49bd-8995-30ade44508bf,DISK], DatanodeInfoWithStorage[127.0.0.1:42932,DS-85cae95d-25d9-487c-8e34-3ff7318a2a77,DISK], DatanodeInfoWithStorage[127.0.0.1:41161,DS-0061e3db-d248-4a0f-906c-c022ba674f4c,DISK], DatanodeInfoWithStorage[127.0.0.1:35656,DS-a8817f0f-7c4e-463b-a85a-d9a1619f23fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1397901422-172.17.0.16-1598188070909:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45524,DS-adaae55a-768b-46d3-8753-7e201a881fa2,DISK], DatanodeInfoWithStorage[127.0.0.1:43833,DS-8ce4c8d9-3594-4c4f-ad57-c78696f2c9bd,DISK], DatanodeInfoWithStorage[127.0.0.1:36329,DS-d6cb5bfe-6bff-404d-8ce8-eaf1be70b7cd,DISK], DatanodeInfoWithStorage[127.0.0.1:33409,DS-f61d80e1-b9fe-45c4-9e62-35903d1bea95,DISK], DatanodeInfoWithStorage[127.0.0.1:39231,DS-d701e40c-3484-49bd-8995-30ade44508bf,DISK], DatanodeInfoWithStorage[127.0.0.1:42932,DS-85cae95d-25d9-487c-8e34-3ff7318a2a77,DISK], DatanodeInfoWithStorage[127.0.0.1:41161,DS-0061e3db-d248-4a0f-906c-c022ba674f4c,DISK], DatanodeInfoWithStorage[127.0.0.1:35656,DS-a8817f0f-7c4e-463b-a85a-d9a1619f23fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-820505372-172.17.0.16-1598188424703:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35986,DS-72b34d7e-f9a3-46c1-b0d0-61933f43e3f9,DISK], DatanodeInfoWithStorage[127.0.0.1:46132,DS-e1ae66da-5017-461c-924a-a2d57e2eea5e,DISK], DatanodeInfoWithStorage[127.0.0.1:44897,DS-43862d9e-9cb3-4d8f-b524-dd1340f5ffe5,DISK], DatanodeInfoWithStorage[127.0.0.1:45559,DS-1e199d24-4c86-4778-bdfb-58b8f425c6ba,DISK], DatanodeInfoWithStorage[127.0.0.1:35675,DS-ee22c8ba-af5d-4473-8d06-33b65116bcd4,DISK], DatanodeInfoWithStorage[127.0.0.1:44075,DS-36d848c4-a5da-4d9a-b55d-8669987ec8cb,DISK], DatanodeInfoWithStorage[127.0.0.1:35523,DS-4c291fca-82ef-4615-81a0-872ae96d5271,DISK], DatanodeInfoWithStorage[127.0.0.1:36027,DS-b2b750e8-285c-41c1-8538-4a501d1bb5cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-820505372-172.17.0.16-1598188424703:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35986,DS-72b34d7e-f9a3-46c1-b0d0-61933f43e3f9,DISK], DatanodeInfoWithStorage[127.0.0.1:46132,DS-e1ae66da-5017-461c-924a-a2d57e2eea5e,DISK], DatanodeInfoWithStorage[127.0.0.1:44897,DS-43862d9e-9cb3-4d8f-b524-dd1340f5ffe5,DISK], DatanodeInfoWithStorage[127.0.0.1:45559,DS-1e199d24-4c86-4778-bdfb-58b8f425c6ba,DISK], DatanodeInfoWithStorage[127.0.0.1:35675,DS-ee22c8ba-af5d-4473-8d06-33b65116bcd4,DISK], DatanodeInfoWithStorage[127.0.0.1:44075,DS-36d848c4-a5da-4d9a-b55d-8669987ec8cb,DISK], DatanodeInfoWithStorage[127.0.0.1:35523,DS-4c291fca-82ef-4615-81a0-872ae96d5271,DISK], DatanodeInfoWithStorage[127.0.0.1:36027,DS-b2b750e8-285c-41c1-8538-4a501d1bb5cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1332851889-172.17.0.16-1598188453106:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33662,DS-7c528190-ac6c-40ce-a573-9b29ebb99381,DISK], DatanodeInfoWithStorage[127.0.0.1:35585,DS-6ae82426-2448-432f-ad34-b3f8f619d256,DISK], DatanodeInfoWithStorage[127.0.0.1:43704,DS-a80629da-19f1-4ca9-ba1d-ec341cf1cc7d,DISK], DatanodeInfoWithStorage[127.0.0.1:37926,DS-f9d610aa-0486-4c8b-9a9f-db0314ba9d16,DISK], DatanodeInfoWithStorage[127.0.0.1:39391,DS-cfe784cd-70f7-44ba-9da9-e8147bd60723,DISK], DatanodeInfoWithStorage[127.0.0.1:36423,DS-c41e4ef0-becf-46b2-ad1f-b83ffb1ee932,DISK], DatanodeInfoWithStorage[127.0.0.1:46078,DS-bbe65865-a9b2-4c1e-9ca1-98532b05ef66,DISK], DatanodeInfoWithStorage[127.0.0.1:40180,DS-0ad31f4a-1cea-4545-826d-1667f363fd6e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1332851889-172.17.0.16-1598188453106:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33662,DS-7c528190-ac6c-40ce-a573-9b29ebb99381,DISK], DatanodeInfoWithStorage[127.0.0.1:35585,DS-6ae82426-2448-432f-ad34-b3f8f619d256,DISK], DatanodeInfoWithStorage[127.0.0.1:43704,DS-a80629da-19f1-4ca9-ba1d-ec341cf1cc7d,DISK], DatanodeInfoWithStorage[127.0.0.1:37926,DS-f9d610aa-0486-4c8b-9a9f-db0314ba9d16,DISK], DatanodeInfoWithStorage[127.0.0.1:39391,DS-cfe784cd-70f7-44ba-9da9-e8147bd60723,DISK], DatanodeInfoWithStorage[127.0.0.1:36423,DS-c41e4ef0-becf-46b2-ad1f-b83ffb1ee932,DISK], DatanodeInfoWithStorage[127.0.0.1:46078,DS-bbe65865-a9b2-4c1e-9ca1-98532b05ef66,DISK], DatanodeInfoWithStorage[127.0.0.1:40180,DS-0ad31f4a-1cea-4545-826d-1667f363fd6e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-427760521-172.17.0.16-1598189121037:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34507,DS-a9a806f6-6651-47e2-a599-f566c27690de,DISK], DatanodeInfoWithStorage[127.0.0.1:44761,DS-d7e9758f-aa32-40df-942c-5f0d024d736f,DISK], DatanodeInfoWithStorage[127.0.0.1:40056,DS-1af9a61a-9a5a-461d-8727-f9874a62c7c7,DISK], DatanodeInfoWithStorage[127.0.0.1:45523,DS-5784c6a7-2b19-4e8c-abdf-1d7e5000b5e0,DISK], DatanodeInfoWithStorage[127.0.0.1:41771,DS-e86dc9b3-134e-419f-8d99-518c50797fcd,DISK], DatanodeInfoWithStorage[127.0.0.1:33104,DS-5425a4a0-13c4-482e-994f-a6fb411a75a9,DISK], DatanodeInfoWithStorage[127.0.0.1:38280,DS-11fd4bfb-c7c3-4390-9388-c702d2bc2686,DISK], DatanodeInfoWithStorage[127.0.0.1:34205,DS-aaf6edb0-888e-46c6-83a0-54be6330b3dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-427760521-172.17.0.16-1598189121037:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34507,DS-a9a806f6-6651-47e2-a599-f566c27690de,DISK], DatanodeInfoWithStorage[127.0.0.1:44761,DS-d7e9758f-aa32-40df-942c-5f0d024d736f,DISK], DatanodeInfoWithStorage[127.0.0.1:40056,DS-1af9a61a-9a5a-461d-8727-f9874a62c7c7,DISK], DatanodeInfoWithStorage[127.0.0.1:45523,DS-5784c6a7-2b19-4e8c-abdf-1d7e5000b5e0,DISK], DatanodeInfoWithStorage[127.0.0.1:41771,DS-e86dc9b3-134e-419f-8d99-518c50797fcd,DISK], DatanodeInfoWithStorage[127.0.0.1:33104,DS-5425a4a0-13c4-482e-994f-a6fb411a75a9,DISK], DatanodeInfoWithStorage[127.0.0.1:38280,DS-11fd4bfb-c7c3-4390-9388-c702d2bc2686,DISK], DatanodeInfoWithStorage[127.0.0.1:34205,DS-aaf6edb0-888e-46c6-83a0-54be6330b3dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1913966348-172.17.0.16-1598189156069:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37434,DS-62079865-c45c-4de4-a8a2-7a6e114a7031,DISK], DatanodeInfoWithStorage[127.0.0.1:38901,DS-4435c1af-1c42-4480-9296-55ac1c961da4,DISK], DatanodeInfoWithStorage[127.0.0.1:35516,DS-a0fb32eb-05d9-4fab-8c57-20cebe30da02,DISK], DatanodeInfoWithStorage[127.0.0.1:43177,DS-f9ec1ea9-aa50-4ec5-8d84-a34275394904,DISK], DatanodeInfoWithStorage[127.0.0.1:45665,DS-8830757b-1da0-4e5a-aded-6d79a4ef05bb,DISK], DatanodeInfoWithStorage[127.0.0.1:36600,DS-c2d84b9f-5ab5-4e53-9d1d-2a40d18fccb3,DISK], DatanodeInfoWithStorage[127.0.0.1:33556,DS-98c00e18-5aa8-4882-91bd-64f41e91ea46,DISK], DatanodeInfoWithStorage[127.0.0.1:37419,DS-cf44b9b0-78a3-413e-b099-65d309073dc5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1913966348-172.17.0.16-1598189156069:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37434,DS-62079865-c45c-4de4-a8a2-7a6e114a7031,DISK], DatanodeInfoWithStorage[127.0.0.1:38901,DS-4435c1af-1c42-4480-9296-55ac1c961da4,DISK], DatanodeInfoWithStorage[127.0.0.1:35516,DS-a0fb32eb-05d9-4fab-8c57-20cebe30da02,DISK], DatanodeInfoWithStorage[127.0.0.1:43177,DS-f9ec1ea9-aa50-4ec5-8d84-a34275394904,DISK], DatanodeInfoWithStorage[127.0.0.1:45665,DS-8830757b-1da0-4e5a-aded-6d79a4ef05bb,DISK], DatanodeInfoWithStorage[127.0.0.1:36600,DS-c2d84b9f-5ab5-4e53-9d1d-2a40d18fccb3,DISK], DatanodeInfoWithStorage[127.0.0.1:33556,DS-98c00e18-5aa8-4882-91bd-64f41e91ea46,DISK], DatanodeInfoWithStorage[127.0.0.1:37419,DS-cf44b9b0-78a3-413e-b099-65d309073dc5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5144
