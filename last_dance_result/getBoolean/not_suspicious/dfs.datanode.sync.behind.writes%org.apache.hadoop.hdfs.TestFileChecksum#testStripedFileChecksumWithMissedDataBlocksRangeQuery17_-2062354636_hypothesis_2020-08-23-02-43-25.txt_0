reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1552002443-172.17.0.5-1598150646829:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42710,DS-098429af-c6f7-4f80-b425-995ad6c0f34d,DISK], DatanodeInfoWithStorage[127.0.0.1:44367,DS-b101a2a2-af03-4980-a25e-34fe6e57359a,DISK], DatanodeInfoWithStorage[127.0.0.1:35708,DS-a4eb24d6-48c1-4aa6-abd8-d95d57d92cae,DISK], DatanodeInfoWithStorage[127.0.0.1:38833,DS-8107963f-44fa-4ffa-9efc-e08377c01128,DISK], DatanodeInfoWithStorage[127.0.0.1:40578,DS-ca344c3c-db08-449b-a40b-77a245518c3d,DISK], DatanodeInfoWithStorage[127.0.0.1:42037,DS-5bc149aa-6226-4d96-8b12-00f1414ee3ea,DISK], DatanodeInfoWithStorage[127.0.0.1:42333,DS-838ebcd7-489d-43d6-86d8-58c48a75af03,DISK], DatanodeInfoWithStorage[127.0.0.1:43416,DS-ff624038-41fa-4629-a957-67c387c116b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1552002443-172.17.0.5-1598150646829:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42710,DS-098429af-c6f7-4f80-b425-995ad6c0f34d,DISK], DatanodeInfoWithStorage[127.0.0.1:44367,DS-b101a2a2-af03-4980-a25e-34fe6e57359a,DISK], DatanodeInfoWithStorage[127.0.0.1:35708,DS-a4eb24d6-48c1-4aa6-abd8-d95d57d92cae,DISK], DatanodeInfoWithStorage[127.0.0.1:38833,DS-8107963f-44fa-4ffa-9efc-e08377c01128,DISK], DatanodeInfoWithStorage[127.0.0.1:40578,DS-ca344c3c-db08-449b-a40b-77a245518c3d,DISK], DatanodeInfoWithStorage[127.0.0.1:42037,DS-5bc149aa-6226-4d96-8b12-00f1414ee3ea,DISK], DatanodeInfoWithStorage[127.0.0.1:42333,DS-838ebcd7-489d-43d6-86d8-58c48a75af03,DISK], DatanodeInfoWithStorage[127.0.0.1:43416,DS-ff624038-41fa-4629-a957-67c387c116b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1063978868-172.17.0.5-1598150809463:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40980,DS-93a53096-52ad-4f87-92d4-57df90c61aa7,DISK], DatanodeInfoWithStorage[127.0.0.1:42987,DS-1e7f6cc6-ea38-4f6f-b602-ef2285a231f1,DISK], DatanodeInfoWithStorage[127.0.0.1:39316,DS-1739572f-ff8f-4d1d-87c2-1033f0b44490,DISK], DatanodeInfoWithStorage[127.0.0.1:33230,DS-0f9231cd-23fa-40eb-9c3a-56dd03340de3,DISK], DatanodeInfoWithStorage[127.0.0.1:37545,DS-76b4cd50-9d5f-4463-b26a-77eabb20393d,DISK], DatanodeInfoWithStorage[127.0.0.1:37309,DS-786b4dd7-2654-4db1-870a-85f3ea064fe6,DISK], DatanodeInfoWithStorage[127.0.0.1:39208,DS-d0ca7677-c044-407a-b8d4-fe8c625e6d16,DISK], DatanodeInfoWithStorage[127.0.0.1:41533,DS-0d189bd6-1d8a-4189-82fa-b166a95d7b5b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1063978868-172.17.0.5-1598150809463:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40980,DS-93a53096-52ad-4f87-92d4-57df90c61aa7,DISK], DatanodeInfoWithStorage[127.0.0.1:42987,DS-1e7f6cc6-ea38-4f6f-b602-ef2285a231f1,DISK], DatanodeInfoWithStorage[127.0.0.1:39316,DS-1739572f-ff8f-4d1d-87c2-1033f0b44490,DISK], DatanodeInfoWithStorage[127.0.0.1:33230,DS-0f9231cd-23fa-40eb-9c3a-56dd03340de3,DISK], DatanodeInfoWithStorage[127.0.0.1:37545,DS-76b4cd50-9d5f-4463-b26a-77eabb20393d,DISK], DatanodeInfoWithStorage[127.0.0.1:37309,DS-786b4dd7-2654-4db1-870a-85f3ea064fe6,DISK], DatanodeInfoWithStorage[127.0.0.1:39208,DS-d0ca7677-c044-407a-b8d4-fe8c625e6d16,DISK], DatanodeInfoWithStorage[127.0.0.1:41533,DS-0d189bd6-1d8a-4189-82fa-b166a95d7b5b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2426646-172.17.0.5-1598150905268:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43846,DS-51181f8f-0019-4a08-a298-c946634efd04,DISK], DatanodeInfoWithStorage[127.0.0.1:33654,DS-b07bd280-f975-49d6-abbf-a5e75875fe15,DISK], DatanodeInfoWithStorage[127.0.0.1:39807,DS-de314d71-1b0c-47d4-a2b3-d91701f434e3,DISK], DatanodeInfoWithStorage[127.0.0.1:37548,DS-4cd4547d-a880-472e-923c-66129dac2368,DISK], DatanodeInfoWithStorage[127.0.0.1:36982,DS-1625617a-70f4-4ca1-9d96-71f9d06c2f11,DISK], DatanodeInfoWithStorage[127.0.0.1:37661,DS-daf486e6-2eec-47d3-b268-8f571a9cb57f,DISK], DatanodeInfoWithStorage[127.0.0.1:36740,DS-efb924e3-37d5-4ee1-bfbd-c5673e0b9389,DISK], DatanodeInfoWithStorage[127.0.0.1:33663,DS-666e843c-f862-4521-b47b-bcd18f2d86a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2426646-172.17.0.5-1598150905268:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43846,DS-51181f8f-0019-4a08-a298-c946634efd04,DISK], DatanodeInfoWithStorage[127.0.0.1:33654,DS-b07bd280-f975-49d6-abbf-a5e75875fe15,DISK], DatanodeInfoWithStorage[127.0.0.1:39807,DS-de314d71-1b0c-47d4-a2b3-d91701f434e3,DISK], DatanodeInfoWithStorage[127.0.0.1:37548,DS-4cd4547d-a880-472e-923c-66129dac2368,DISK], DatanodeInfoWithStorage[127.0.0.1:36982,DS-1625617a-70f4-4ca1-9d96-71f9d06c2f11,DISK], DatanodeInfoWithStorage[127.0.0.1:37661,DS-daf486e6-2eec-47d3-b268-8f571a9cb57f,DISK], DatanodeInfoWithStorage[127.0.0.1:36740,DS-efb924e3-37d5-4ee1-bfbd-c5673e0b9389,DISK], DatanodeInfoWithStorage[127.0.0.1:33663,DS-666e843c-f862-4521-b47b-bcd18f2d86a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1219566834-172.17.0.5-1598151070041:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39194,DS-dfd52179-dff9-4223-8746-dcd530529748,DISK], DatanodeInfoWithStorage[127.0.0.1:41969,DS-ffc56be7-7ec6-4b45-ab0f-292fb7304d69,DISK], DatanodeInfoWithStorage[127.0.0.1:35782,DS-80168333-4ba0-4a81-a4a4-5100adbad30c,DISK], DatanodeInfoWithStorage[127.0.0.1:42929,DS-89d9ca43-d4ea-4011-a471-a33ce23202a2,DISK], DatanodeInfoWithStorage[127.0.0.1:36066,DS-9b4ef9c3-3a05-4304-8444-0bccc1946bf0,DISK], DatanodeInfoWithStorage[127.0.0.1:45838,DS-d4156089-e6ec-43b7-a4b4-e83fee846755,DISK], DatanodeInfoWithStorage[127.0.0.1:42203,DS-794b75f3-f597-4d7b-8868-873453a78360,DISK], DatanodeInfoWithStorage[127.0.0.1:43274,DS-cf5e5664-920f-4d27-bb30-19f5872390c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1219566834-172.17.0.5-1598151070041:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39194,DS-dfd52179-dff9-4223-8746-dcd530529748,DISK], DatanodeInfoWithStorage[127.0.0.1:41969,DS-ffc56be7-7ec6-4b45-ab0f-292fb7304d69,DISK], DatanodeInfoWithStorage[127.0.0.1:35782,DS-80168333-4ba0-4a81-a4a4-5100adbad30c,DISK], DatanodeInfoWithStorage[127.0.0.1:42929,DS-89d9ca43-d4ea-4011-a471-a33ce23202a2,DISK], DatanodeInfoWithStorage[127.0.0.1:36066,DS-9b4ef9c3-3a05-4304-8444-0bccc1946bf0,DISK], DatanodeInfoWithStorage[127.0.0.1:45838,DS-d4156089-e6ec-43b7-a4b4-e83fee846755,DISK], DatanodeInfoWithStorage[127.0.0.1:42203,DS-794b75f3-f597-4d7b-8868-873453a78360,DISK], DatanodeInfoWithStorage[127.0.0.1:43274,DS-cf5e5664-920f-4d27-bb30-19f5872390c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-888640192-172.17.0.5-1598151390973:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38782,DS-736cfe11-8433-4cc8-b8af-b07f5de19e21,DISK], DatanodeInfoWithStorage[127.0.0.1:38161,DS-ceb90c31-75d9-40d1-9f81-fac2735b7ea1,DISK], DatanodeInfoWithStorage[127.0.0.1:40168,DS-ffc8fb07-ee7e-4eff-b002-aa45ba4c31b5,DISK], DatanodeInfoWithStorage[127.0.0.1:45049,DS-7e1de5e1-eada-48ad-bd58-caed737e26f0,DISK], DatanodeInfoWithStorage[127.0.0.1:36324,DS-7c7fb123-a474-42d9-9760-cb819751e3a7,DISK], DatanodeInfoWithStorage[127.0.0.1:34740,DS-9c6c732d-35fd-485b-b80d-5044646cd366,DISK], DatanodeInfoWithStorage[127.0.0.1:42014,DS-d4913b1e-2efd-4cc1-b25d-9a5efb4be6dd,DISK], DatanodeInfoWithStorage[127.0.0.1:40146,DS-fe3b49f3-3b77-4381-8b3a-4b5526b490b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-888640192-172.17.0.5-1598151390973:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38782,DS-736cfe11-8433-4cc8-b8af-b07f5de19e21,DISK], DatanodeInfoWithStorage[127.0.0.1:38161,DS-ceb90c31-75d9-40d1-9f81-fac2735b7ea1,DISK], DatanodeInfoWithStorage[127.0.0.1:40168,DS-ffc8fb07-ee7e-4eff-b002-aa45ba4c31b5,DISK], DatanodeInfoWithStorage[127.0.0.1:45049,DS-7e1de5e1-eada-48ad-bd58-caed737e26f0,DISK], DatanodeInfoWithStorage[127.0.0.1:36324,DS-7c7fb123-a474-42d9-9760-cb819751e3a7,DISK], DatanodeInfoWithStorage[127.0.0.1:34740,DS-9c6c732d-35fd-485b-b80d-5044646cd366,DISK], DatanodeInfoWithStorage[127.0.0.1:42014,DS-d4913b1e-2efd-4cc1-b25d-9a5efb4be6dd,DISK], DatanodeInfoWithStorage[127.0.0.1:40146,DS-fe3b49f3-3b77-4381-8b3a-4b5526b490b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-812181399-172.17.0.5-1598151584714:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40593,DS-02ac4abd-a39a-4777-bd5d-71eb8436fa76,DISK], DatanodeInfoWithStorage[127.0.0.1:45514,DS-786af6ac-fe98-4e7b-b0f6-8d84813a2b78,DISK], DatanodeInfoWithStorage[127.0.0.1:40858,DS-511dc26f-91d3-4739-b837-3226a4ec2b32,DISK], DatanodeInfoWithStorage[127.0.0.1:39284,DS-f6538120-6ade-437b-988a-6b70129e7ea5,DISK], DatanodeInfoWithStorage[127.0.0.1:46348,DS-f2ff3d5c-8975-473c-a054-974a347fa5ac,DISK], DatanodeInfoWithStorage[127.0.0.1:42675,DS-260b7b21-7482-483f-a666-4ccef27c2355,DISK], DatanodeInfoWithStorage[127.0.0.1:46581,DS-25a332e1-599e-4ca0-9a98-681731c15533,DISK], DatanodeInfoWithStorage[127.0.0.1:37056,DS-4735b3df-8333-4890-847c-c57672cbf78f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-812181399-172.17.0.5-1598151584714:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40593,DS-02ac4abd-a39a-4777-bd5d-71eb8436fa76,DISK], DatanodeInfoWithStorage[127.0.0.1:45514,DS-786af6ac-fe98-4e7b-b0f6-8d84813a2b78,DISK], DatanodeInfoWithStorage[127.0.0.1:40858,DS-511dc26f-91d3-4739-b837-3226a4ec2b32,DISK], DatanodeInfoWithStorage[127.0.0.1:39284,DS-f6538120-6ade-437b-988a-6b70129e7ea5,DISK], DatanodeInfoWithStorage[127.0.0.1:46348,DS-f2ff3d5c-8975-473c-a054-974a347fa5ac,DISK], DatanodeInfoWithStorage[127.0.0.1:42675,DS-260b7b21-7482-483f-a666-4ccef27c2355,DISK], DatanodeInfoWithStorage[127.0.0.1:46581,DS-25a332e1-599e-4ca0-9a98-681731c15533,DISK], DatanodeInfoWithStorage[127.0.0.1:37056,DS-4735b3df-8333-4890-847c-c57672cbf78f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1419484094-172.17.0.5-1598151620727:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41447,DS-e7a7251f-9a1e-4208-a260-5c20b5ea94b0,DISK], DatanodeInfoWithStorage[127.0.0.1:42982,DS-5ce21099-22db-434e-baec-d99675f57025,DISK], DatanodeInfoWithStorage[127.0.0.1:39355,DS-a7efb3dd-b31e-47db-910d-86b5550a87a5,DISK], DatanodeInfoWithStorage[127.0.0.1:33255,DS-3cf38a3a-eeed-43ae-b8cb-86d189378eea,DISK], DatanodeInfoWithStorage[127.0.0.1:38496,DS-35b534a9-f0f4-4e42-a72d-53bfafd3adc1,DISK], DatanodeInfoWithStorage[127.0.0.1:37712,DS-2c4b4520-559c-45b3-a223-87eda9514e59,DISK], DatanodeInfoWithStorage[127.0.0.1:33882,DS-20c5da96-949b-4d57-a227-3c53edf26305,DISK], DatanodeInfoWithStorage[127.0.0.1:43602,DS-7b4ed445-9a1d-478c-819e-0b0cd2f52fe8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1419484094-172.17.0.5-1598151620727:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41447,DS-e7a7251f-9a1e-4208-a260-5c20b5ea94b0,DISK], DatanodeInfoWithStorage[127.0.0.1:42982,DS-5ce21099-22db-434e-baec-d99675f57025,DISK], DatanodeInfoWithStorage[127.0.0.1:39355,DS-a7efb3dd-b31e-47db-910d-86b5550a87a5,DISK], DatanodeInfoWithStorage[127.0.0.1:33255,DS-3cf38a3a-eeed-43ae-b8cb-86d189378eea,DISK], DatanodeInfoWithStorage[127.0.0.1:38496,DS-35b534a9-f0f4-4e42-a72d-53bfafd3adc1,DISK], DatanodeInfoWithStorage[127.0.0.1:37712,DS-2c4b4520-559c-45b3-a223-87eda9514e59,DISK], DatanodeInfoWithStorage[127.0.0.1:33882,DS-20c5da96-949b-4d57-a227-3c53edf26305,DISK], DatanodeInfoWithStorage[127.0.0.1:43602,DS-7b4ed445-9a1d-478c-819e-0b0cd2f52fe8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1166494859-172.17.0.5-1598151697782:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45322,DS-cff46455-4cd4-471d-a99e-c09f60fa0e5d,DISK], DatanodeInfoWithStorage[127.0.0.1:45389,DS-edfb0988-5436-4ac3-83eb-eb22f2637b32,DISK], DatanodeInfoWithStorage[127.0.0.1:45379,DS-c6903b06-3572-4e10-8571-7da227fdc413,DISK], DatanodeInfoWithStorage[127.0.0.1:41464,DS-b067db59-4e32-432b-a930-b920fe203a1b,DISK], DatanodeInfoWithStorage[127.0.0.1:44691,DS-9a1a443f-59bd-4c16-8a02-069e87dd3a36,DISK], DatanodeInfoWithStorage[127.0.0.1:35088,DS-1b42bba3-4790-4dcb-956a-8b51c74151ca,DISK], DatanodeInfoWithStorage[127.0.0.1:34887,DS-e657448b-bebd-43fa-ac2c-1ea91c7c1559,DISK], DatanodeInfoWithStorage[127.0.0.1:45973,DS-c800c6c6-b0b9-406c-afe1-7bf02ced75d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1166494859-172.17.0.5-1598151697782:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45322,DS-cff46455-4cd4-471d-a99e-c09f60fa0e5d,DISK], DatanodeInfoWithStorage[127.0.0.1:45389,DS-edfb0988-5436-4ac3-83eb-eb22f2637b32,DISK], DatanodeInfoWithStorage[127.0.0.1:45379,DS-c6903b06-3572-4e10-8571-7da227fdc413,DISK], DatanodeInfoWithStorage[127.0.0.1:41464,DS-b067db59-4e32-432b-a930-b920fe203a1b,DISK], DatanodeInfoWithStorage[127.0.0.1:44691,DS-9a1a443f-59bd-4c16-8a02-069e87dd3a36,DISK], DatanodeInfoWithStorage[127.0.0.1:35088,DS-1b42bba3-4790-4dcb-956a-8b51c74151ca,DISK], DatanodeInfoWithStorage[127.0.0.1:34887,DS-e657448b-bebd-43fa-ac2c-1ea91c7c1559,DISK], DatanodeInfoWithStorage[127.0.0.1:45973,DS-c800c6c6-b0b9-406c-afe1-7bf02ced75d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-611802350-172.17.0.5-1598151938053:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36828,DS-254cf7b7-edce-42b6-b381-aef2675dcdac,DISK], DatanodeInfoWithStorage[127.0.0.1:39348,DS-1e636056-1bf4-431a-9d2b-561c1af00f9a,DISK], DatanodeInfoWithStorage[127.0.0.1:37679,DS-173d8a64-1d02-4a6f-a276-cd261eb22562,DISK], DatanodeInfoWithStorage[127.0.0.1:46532,DS-b402750b-55f1-4427-996d-5b32cdd5d536,DISK], DatanodeInfoWithStorage[127.0.0.1:33070,DS-64101c30-484e-4651-a5db-b475498d97f3,DISK], DatanodeInfoWithStorage[127.0.0.1:40131,DS-41950212-5a9f-4fd4-a243-5f782b0ec0fa,DISK], DatanodeInfoWithStorage[127.0.0.1:37012,DS-3cae98bc-bd68-4f4c-ae1b-622e96170c66,DISK], DatanodeInfoWithStorage[127.0.0.1:32952,DS-d89342c5-a6d7-4ec9-a6e2-812fed30e47a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-611802350-172.17.0.5-1598151938053:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36828,DS-254cf7b7-edce-42b6-b381-aef2675dcdac,DISK], DatanodeInfoWithStorage[127.0.0.1:39348,DS-1e636056-1bf4-431a-9d2b-561c1af00f9a,DISK], DatanodeInfoWithStorage[127.0.0.1:37679,DS-173d8a64-1d02-4a6f-a276-cd261eb22562,DISK], DatanodeInfoWithStorage[127.0.0.1:46532,DS-b402750b-55f1-4427-996d-5b32cdd5d536,DISK], DatanodeInfoWithStorage[127.0.0.1:33070,DS-64101c30-484e-4651-a5db-b475498d97f3,DISK], DatanodeInfoWithStorage[127.0.0.1:40131,DS-41950212-5a9f-4fd4-a243-5f782b0ec0fa,DISK], DatanodeInfoWithStorage[127.0.0.1:37012,DS-3cae98bc-bd68-4f4c-ae1b-622e96170c66,DISK], DatanodeInfoWithStorage[127.0.0.1:32952,DS-d89342c5-a6d7-4ec9-a6e2-812fed30e47a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1614853916-172.17.0.5-1598152471447:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40673,DS-e4b791ac-1fcd-47a3-8271-5bee0356e739,DISK], DatanodeInfoWithStorage[127.0.0.1:37691,DS-823228c2-eec8-461d-88c1-60a4df20b9e0,DISK], DatanodeInfoWithStorage[127.0.0.1:45523,DS-4516b4cd-b0dc-4644-b409-cd3055ad295b,DISK], DatanodeInfoWithStorage[127.0.0.1:43679,DS-4aea0482-7e65-470c-8216-3fc8a8bb6055,DISK], DatanodeInfoWithStorage[127.0.0.1:44770,DS-6b370471-868c-44cc-af1b-7d70f426a6cd,DISK], DatanodeInfoWithStorage[127.0.0.1:34909,DS-3774aad0-6136-41ae-b282-9127d741f648,DISK], DatanodeInfoWithStorage[127.0.0.1:41766,DS-d957a95a-5ef1-4c84-9732-398cb697ec3f,DISK], DatanodeInfoWithStorage[127.0.0.1:38223,DS-2625f0eb-2aa2-4a75-9f14-1cce15ec700e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1614853916-172.17.0.5-1598152471447:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40673,DS-e4b791ac-1fcd-47a3-8271-5bee0356e739,DISK], DatanodeInfoWithStorage[127.0.0.1:37691,DS-823228c2-eec8-461d-88c1-60a4df20b9e0,DISK], DatanodeInfoWithStorage[127.0.0.1:45523,DS-4516b4cd-b0dc-4644-b409-cd3055ad295b,DISK], DatanodeInfoWithStorage[127.0.0.1:43679,DS-4aea0482-7e65-470c-8216-3fc8a8bb6055,DISK], DatanodeInfoWithStorage[127.0.0.1:44770,DS-6b370471-868c-44cc-af1b-7d70f426a6cd,DISK], DatanodeInfoWithStorage[127.0.0.1:34909,DS-3774aad0-6136-41ae-b282-9127d741f648,DISK], DatanodeInfoWithStorage[127.0.0.1:41766,DS-d957a95a-5ef1-4c84-9732-398cb697ec3f,DISK], DatanodeInfoWithStorage[127.0.0.1:38223,DS-2625f0eb-2aa2-4a75-9f14-1cce15ec700e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-795420115-172.17.0.5-1598152622744:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41318,DS-81fe90e9-b981-435f-a966-1fe8ea6ee52d,DISK], DatanodeInfoWithStorage[127.0.0.1:45007,DS-1b6bc967-16ea-452e-ba49-2eaec8d3787c,DISK], DatanodeInfoWithStorage[127.0.0.1:42325,DS-1e2146d8-d07c-47a8-a2e4-f1785d8fb543,DISK], DatanodeInfoWithStorage[127.0.0.1:33265,DS-8de6f76c-33ae-41df-aeca-8cdd626ca7e8,DISK], DatanodeInfoWithStorage[127.0.0.1:42362,DS-1d450acd-9612-43b0-af8f-725fc142c286,DISK], DatanodeInfoWithStorage[127.0.0.1:38038,DS-3cf30eed-a7ed-46ea-8216-0088ed45ec73,DISK], DatanodeInfoWithStorage[127.0.0.1:36294,DS-86fd3949-677e-4848-975b-133b422e4ec1,DISK], DatanodeInfoWithStorage[127.0.0.1:42259,DS-8ad5214f-9d4e-4314-8447-0f3ae97e8281,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-795420115-172.17.0.5-1598152622744:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41318,DS-81fe90e9-b981-435f-a966-1fe8ea6ee52d,DISK], DatanodeInfoWithStorage[127.0.0.1:45007,DS-1b6bc967-16ea-452e-ba49-2eaec8d3787c,DISK], DatanodeInfoWithStorage[127.0.0.1:42325,DS-1e2146d8-d07c-47a8-a2e4-f1785d8fb543,DISK], DatanodeInfoWithStorage[127.0.0.1:33265,DS-8de6f76c-33ae-41df-aeca-8cdd626ca7e8,DISK], DatanodeInfoWithStorage[127.0.0.1:42362,DS-1d450acd-9612-43b0-af8f-725fc142c286,DISK], DatanodeInfoWithStorage[127.0.0.1:38038,DS-3cf30eed-a7ed-46ea-8216-0088ed45ec73,DISK], DatanodeInfoWithStorage[127.0.0.1:36294,DS-86fd3949-677e-4848-975b-133b422e4ec1,DISK], DatanodeInfoWithStorage[127.0.0.1:42259,DS-8ad5214f-9d4e-4314-8447-0f3ae97e8281,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1995539545-172.17.0.5-1598152804172:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45369,DS-71dd34ae-602b-4f44-a260-f44805062c82,DISK], DatanodeInfoWithStorage[127.0.0.1:43112,DS-674da0dc-7ea9-4e0f-8d6d-736630cc39d0,DISK], DatanodeInfoWithStorage[127.0.0.1:34244,DS-40fa85ba-20bd-4fa1-b2ba-33002313b626,DISK], DatanodeInfoWithStorage[127.0.0.1:40343,DS-d6c2a6d2-30c9-4671-b8b0-4e21922ec63d,DISK], DatanodeInfoWithStorage[127.0.0.1:34123,DS-05515109-1baa-4fba-88de-dbb980971516,DISK], DatanodeInfoWithStorage[127.0.0.1:46263,DS-5f396de7-ec71-4d7c-aa9a-60d9a26c86da,DISK], DatanodeInfoWithStorage[127.0.0.1:44301,DS-0c048ecb-e414-4135-89c9-f62729345c48,DISK], DatanodeInfoWithStorage[127.0.0.1:46707,DS-8a830792-f57f-42a4-8c95-0868d31a7cce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1995539545-172.17.0.5-1598152804172:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45369,DS-71dd34ae-602b-4f44-a260-f44805062c82,DISK], DatanodeInfoWithStorage[127.0.0.1:43112,DS-674da0dc-7ea9-4e0f-8d6d-736630cc39d0,DISK], DatanodeInfoWithStorage[127.0.0.1:34244,DS-40fa85ba-20bd-4fa1-b2ba-33002313b626,DISK], DatanodeInfoWithStorage[127.0.0.1:40343,DS-d6c2a6d2-30c9-4671-b8b0-4e21922ec63d,DISK], DatanodeInfoWithStorage[127.0.0.1:34123,DS-05515109-1baa-4fba-88de-dbb980971516,DISK], DatanodeInfoWithStorage[127.0.0.1:46263,DS-5f396de7-ec71-4d7c-aa9a-60d9a26c86da,DISK], DatanodeInfoWithStorage[127.0.0.1:44301,DS-0c048ecb-e414-4135-89c9-f62729345c48,DISK], DatanodeInfoWithStorage[127.0.0.1:46707,DS-8a830792-f57f-42a4-8c95-0868d31a7cce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2139823098-172.17.0.5-1598152914697:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42579,DS-8eea7682-bf5e-437f-aa19-099c9fcaab68,DISK], DatanodeInfoWithStorage[127.0.0.1:38671,DS-c975780e-ccdc-4a8a-83bb-a9d4809f80a1,DISK], DatanodeInfoWithStorage[127.0.0.1:43256,DS-272f8270-d8a0-4084-b84a-b70c57089722,DISK], DatanodeInfoWithStorage[127.0.0.1:34898,DS-8bdde3ca-72ba-4c49-bb48-0bb67a619943,DISK], DatanodeInfoWithStorage[127.0.0.1:41604,DS-56f482f8-fdcf-4c14-a4ae-2162abed6a08,DISK], DatanodeInfoWithStorage[127.0.0.1:45115,DS-d79249a9-8ba2-41ad-8b98-4fc34c18e7a2,DISK], DatanodeInfoWithStorage[127.0.0.1:38490,DS-e0424ae9-0de6-4c95-aa58-d063c72d37ec,DISK], DatanodeInfoWithStorage[127.0.0.1:37662,DS-cc7c197f-ec61-4207-9ece-de8aee6288fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2139823098-172.17.0.5-1598152914697:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42579,DS-8eea7682-bf5e-437f-aa19-099c9fcaab68,DISK], DatanodeInfoWithStorage[127.0.0.1:38671,DS-c975780e-ccdc-4a8a-83bb-a9d4809f80a1,DISK], DatanodeInfoWithStorage[127.0.0.1:43256,DS-272f8270-d8a0-4084-b84a-b70c57089722,DISK], DatanodeInfoWithStorage[127.0.0.1:34898,DS-8bdde3ca-72ba-4c49-bb48-0bb67a619943,DISK], DatanodeInfoWithStorage[127.0.0.1:41604,DS-56f482f8-fdcf-4c14-a4ae-2162abed6a08,DISK], DatanodeInfoWithStorage[127.0.0.1:45115,DS-d79249a9-8ba2-41ad-8b98-4fc34c18e7a2,DISK], DatanodeInfoWithStorage[127.0.0.1:38490,DS-e0424ae9-0de6-4c95-aa58-d063c72d37ec,DISK], DatanodeInfoWithStorage[127.0.0.1:37662,DS-cc7c197f-ec61-4207-9ece-de8aee6288fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2017696673-172.17.0.5-1598152953233:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34808,DS-d5930006-04c5-4b43-b97d-e01ab5879aad,DISK], DatanodeInfoWithStorage[127.0.0.1:35634,DS-c921dfa6-f075-49e9-be2c-d4fe44a9c4cb,DISK], DatanodeInfoWithStorage[127.0.0.1:42002,DS-662ed6de-363b-4c6d-b7e0-e3d1fc688921,DISK], DatanodeInfoWithStorage[127.0.0.1:44778,DS-026dc4f0-b0d7-4099-9f2b-ac5e365214d5,DISK], DatanodeInfoWithStorage[127.0.0.1:43033,DS-09781aff-a2e9-4277-945e-8de35396db57,DISK], DatanodeInfoWithStorage[127.0.0.1:38014,DS-3c4186b0-a9c0-4b60-a32b-b288e26441fc,DISK], DatanodeInfoWithStorage[127.0.0.1:43294,DS-29c1e405-1e03-4c4f-a99c-969f6ff4a735,DISK], DatanodeInfoWithStorage[127.0.0.1:38938,DS-3857bfa6-b402-4c24-b6bf-0e09db8419d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2017696673-172.17.0.5-1598152953233:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34808,DS-d5930006-04c5-4b43-b97d-e01ab5879aad,DISK], DatanodeInfoWithStorage[127.0.0.1:35634,DS-c921dfa6-f075-49e9-be2c-d4fe44a9c4cb,DISK], DatanodeInfoWithStorage[127.0.0.1:42002,DS-662ed6de-363b-4c6d-b7e0-e3d1fc688921,DISK], DatanodeInfoWithStorage[127.0.0.1:44778,DS-026dc4f0-b0d7-4099-9f2b-ac5e365214d5,DISK], DatanodeInfoWithStorage[127.0.0.1:43033,DS-09781aff-a2e9-4277-945e-8de35396db57,DISK], DatanodeInfoWithStorage[127.0.0.1:38014,DS-3c4186b0-a9c0-4b60-a32b-b288e26441fc,DISK], DatanodeInfoWithStorage[127.0.0.1:43294,DS-29c1e405-1e03-4c4f-a99c-969f6ff4a735,DISK], DatanodeInfoWithStorage[127.0.0.1:38938,DS-3857bfa6-b402-4c24-b6bf-0e09db8419d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1077986997-172.17.0.5-1598153278288:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37957,DS-91c54136-e231-4c0f-a308-b32d9b651fc9,DISK], DatanodeInfoWithStorage[127.0.0.1:33193,DS-0faa67dd-8b52-46ee-9261-2577cfadb54d,DISK], DatanodeInfoWithStorage[127.0.0.1:35720,DS-cd79a5bc-b3a0-48c6-9248-97af30ae5c81,DISK], DatanodeInfoWithStorage[127.0.0.1:39908,DS-d76d5884-19e2-406f-8632-e5af6cde7e9a,DISK], DatanodeInfoWithStorage[127.0.0.1:44761,DS-e11c7f28-a519-4713-89ad-f52701c0fba5,DISK], DatanodeInfoWithStorage[127.0.0.1:43044,DS-f6c41297-e8ac-41e9-ae2f-c985026cecae,DISK], DatanodeInfoWithStorage[127.0.0.1:43929,DS-f8c5001a-33ba-4db5-b976-be3114083da0,DISK], DatanodeInfoWithStorage[127.0.0.1:46119,DS-1bd8f26d-98a8-47cf-a7bf-88e516b61a6d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1077986997-172.17.0.5-1598153278288:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37957,DS-91c54136-e231-4c0f-a308-b32d9b651fc9,DISK], DatanodeInfoWithStorage[127.0.0.1:33193,DS-0faa67dd-8b52-46ee-9261-2577cfadb54d,DISK], DatanodeInfoWithStorage[127.0.0.1:35720,DS-cd79a5bc-b3a0-48c6-9248-97af30ae5c81,DISK], DatanodeInfoWithStorage[127.0.0.1:39908,DS-d76d5884-19e2-406f-8632-e5af6cde7e9a,DISK], DatanodeInfoWithStorage[127.0.0.1:44761,DS-e11c7f28-a519-4713-89ad-f52701c0fba5,DISK], DatanodeInfoWithStorage[127.0.0.1:43044,DS-f6c41297-e8ac-41e9-ae2f-c985026cecae,DISK], DatanodeInfoWithStorage[127.0.0.1:43929,DS-f8c5001a-33ba-4db5-b976-be3114083da0,DISK], DatanodeInfoWithStorage[127.0.0.1:46119,DS-1bd8f26d-98a8-47cf-a7bf-88e516b61a6d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-233306224-172.17.0.5-1598153344124:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37001,DS-fdfbeb71-081a-4221-9139-a8917cc2c5e8,DISK], DatanodeInfoWithStorage[127.0.0.1:35239,DS-ec508d05-c84e-42ad-8e3b-6c83974723f3,DISK], DatanodeInfoWithStorage[127.0.0.1:39950,DS-ec184a24-29a1-409d-b4ab-aacc9347d72b,DISK], DatanodeInfoWithStorage[127.0.0.1:46739,DS-9a9c057c-85b4-48bf-92cb-72b50384b787,DISK], DatanodeInfoWithStorage[127.0.0.1:33521,DS-abeb5e50-33c8-4fd1-b01e-8115fc411980,DISK], DatanodeInfoWithStorage[127.0.0.1:43241,DS-9095e8cd-3c4d-45d5-8f9c-00e9e1bfa3ed,DISK], DatanodeInfoWithStorage[127.0.0.1:42949,DS-476aaad8-e36c-463b-ad0b-e11ef4fccc61,DISK], DatanodeInfoWithStorage[127.0.0.1:35823,DS-8ccfec92-a890-4a3a-a3d8-42eca553a0ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-233306224-172.17.0.5-1598153344124:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37001,DS-fdfbeb71-081a-4221-9139-a8917cc2c5e8,DISK], DatanodeInfoWithStorage[127.0.0.1:35239,DS-ec508d05-c84e-42ad-8e3b-6c83974723f3,DISK], DatanodeInfoWithStorage[127.0.0.1:39950,DS-ec184a24-29a1-409d-b4ab-aacc9347d72b,DISK], DatanodeInfoWithStorage[127.0.0.1:46739,DS-9a9c057c-85b4-48bf-92cb-72b50384b787,DISK], DatanodeInfoWithStorage[127.0.0.1:33521,DS-abeb5e50-33c8-4fd1-b01e-8115fc411980,DISK], DatanodeInfoWithStorage[127.0.0.1:43241,DS-9095e8cd-3c4d-45d5-8f9c-00e9e1bfa3ed,DISK], DatanodeInfoWithStorage[127.0.0.1:42949,DS-476aaad8-e36c-463b-ad0b-e11ef4fccc61,DISK], DatanodeInfoWithStorage[127.0.0.1:35823,DS-8ccfec92-a890-4a3a-a3d8-42eca553a0ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-232626998-172.17.0.5-1598153484942:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46007,DS-547e7fe2-1ea2-49e7-b252-c7c0b7e79fed,DISK], DatanodeInfoWithStorage[127.0.0.1:41803,DS-39a78a9a-4e91-4e47-a02d-db4f48314050,DISK], DatanodeInfoWithStorage[127.0.0.1:38661,DS-1b6bb477-d784-4521-b879-de400277c3fb,DISK], DatanodeInfoWithStorage[127.0.0.1:40943,DS-0b780c31-5b6d-4e19-85ae-ea797428d9d4,DISK], DatanodeInfoWithStorage[127.0.0.1:41802,DS-4ee456e3-ec21-4244-bafa-d8b4383c54ba,DISK], DatanodeInfoWithStorage[127.0.0.1:36335,DS-9c8dd6c7-8a1c-425c-8478-17bd292d4cfa,DISK], DatanodeInfoWithStorage[127.0.0.1:42051,DS-057c1fd8-8535-4bdc-8f38-81094bd9f3d8,DISK], DatanodeInfoWithStorage[127.0.0.1:44912,DS-cc894e17-160b-4441-b909-7f0e1092103a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-232626998-172.17.0.5-1598153484942:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46007,DS-547e7fe2-1ea2-49e7-b252-c7c0b7e79fed,DISK], DatanodeInfoWithStorage[127.0.0.1:41803,DS-39a78a9a-4e91-4e47-a02d-db4f48314050,DISK], DatanodeInfoWithStorage[127.0.0.1:38661,DS-1b6bb477-d784-4521-b879-de400277c3fb,DISK], DatanodeInfoWithStorage[127.0.0.1:40943,DS-0b780c31-5b6d-4e19-85ae-ea797428d9d4,DISK], DatanodeInfoWithStorage[127.0.0.1:41802,DS-4ee456e3-ec21-4244-bafa-d8b4383c54ba,DISK], DatanodeInfoWithStorage[127.0.0.1:36335,DS-9c8dd6c7-8a1c-425c-8478-17bd292d4cfa,DISK], DatanodeInfoWithStorage[127.0.0.1:42051,DS-057c1fd8-8535-4bdc-8f38-81094bd9f3d8,DISK], DatanodeInfoWithStorage[127.0.0.1:44912,DS-cc894e17-160b-4441-b909-7f0e1092103a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1390483824-172.17.0.5-1598153593903:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40617,DS-3ebb617b-9a45-4c77-8916-2000c50bae4a,DISK], DatanodeInfoWithStorage[127.0.0.1:46302,DS-a042a121-c1a0-4c69-9362-9c4f6612a2cb,DISK], DatanodeInfoWithStorage[127.0.0.1:41450,DS-0c172175-1b2a-4b72-addd-c9e41eb0e3b9,DISK], DatanodeInfoWithStorage[127.0.0.1:42296,DS-5659a0a2-39af-49fa-9b5a-88ea53cd0ba6,DISK], DatanodeInfoWithStorage[127.0.0.1:33169,DS-d829a530-30b1-4713-9bba-0c13dc16a8f0,DISK], DatanodeInfoWithStorage[127.0.0.1:44743,DS-38172c3b-06b7-4299-939d-1f96d0dcb22d,DISK], DatanodeInfoWithStorage[127.0.0.1:34232,DS-25172a32-b04a-417c-b449-94f2923a9be4,DISK], DatanodeInfoWithStorage[127.0.0.1:37714,DS-25faf595-4d45-4877-b329-f38c0e8fedf9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1390483824-172.17.0.5-1598153593903:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40617,DS-3ebb617b-9a45-4c77-8916-2000c50bae4a,DISK], DatanodeInfoWithStorage[127.0.0.1:46302,DS-a042a121-c1a0-4c69-9362-9c4f6612a2cb,DISK], DatanodeInfoWithStorage[127.0.0.1:41450,DS-0c172175-1b2a-4b72-addd-c9e41eb0e3b9,DISK], DatanodeInfoWithStorage[127.0.0.1:42296,DS-5659a0a2-39af-49fa-9b5a-88ea53cd0ba6,DISK], DatanodeInfoWithStorage[127.0.0.1:33169,DS-d829a530-30b1-4713-9bba-0c13dc16a8f0,DISK], DatanodeInfoWithStorage[127.0.0.1:44743,DS-38172c3b-06b7-4299-939d-1f96d0dcb22d,DISK], DatanodeInfoWithStorage[127.0.0.1:34232,DS-25172a32-b04a-417c-b449-94f2923a9be4,DISK], DatanodeInfoWithStorage[127.0.0.1:37714,DS-25faf595-4d45-4877-b329-f38c0e8fedf9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-420660260-172.17.0.5-1598153699790:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37277,DS-776fb41b-c37f-4120-92d3-f7b6a1d5342d,DISK], DatanodeInfoWithStorage[127.0.0.1:34871,DS-28561cb0-c59b-4b88-a33e-45363548db80,DISK], DatanodeInfoWithStorage[127.0.0.1:40009,DS-3d3bb0c6-fff5-473d-9b27-5e19d58e130e,DISK], DatanodeInfoWithStorage[127.0.0.1:33438,DS-c17033a5-67e3-4eee-8cb3-524f4c88dbb2,DISK], DatanodeInfoWithStorage[127.0.0.1:41020,DS-dd59d323-0074-49ea-8f7d-2d8527b26d1a,DISK], DatanodeInfoWithStorage[127.0.0.1:32945,DS-2feb9cf7-7851-48a5-8115-49e7c4941f03,DISK], DatanodeInfoWithStorage[127.0.0.1:42520,DS-f9c4b095-2b83-4e22-b474-67697da9cfbc,DISK], DatanodeInfoWithStorage[127.0.0.1:33928,DS-eea51185-8bf7-4197-8269-120aef7b33d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-420660260-172.17.0.5-1598153699790:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37277,DS-776fb41b-c37f-4120-92d3-f7b6a1d5342d,DISK], DatanodeInfoWithStorage[127.0.0.1:34871,DS-28561cb0-c59b-4b88-a33e-45363548db80,DISK], DatanodeInfoWithStorage[127.0.0.1:40009,DS-3d3bb0c6-fff5-473d-9b27-5e19d58e130e,DISK], DatanodeInfoWithStorage[127.0.0.1:33438,DS-c17033a5-67e3-4eee-8cb3-524f4c88dbb2,DISK], DatanodeInfoWithStorage[127.0.0.1:41020,DS-dd59d323-0074-49ea-8f7d-2d8527b26d1a,DISK], DatanodeInfoWithStorage[127.0.0.1:32945,DS-2feb9cf7-7851-48a5-8115-49e7c4941f03,DISK], DatanodeInfoWithStorage[127.0.0.1:42520,DS-f9c4b095-2b83-4e22-b474-67697da9cfbc,DISK], DatanodeInfoWithStorage[127.0.0.1:33928,DS-eea51185-8bf7-4197-8269-120aef7b33d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1480915568-172.17.0.5-1598153845683:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39258,DS-000c47cc-f9e1-423f-b8c4-2aaad26e4b9e,DISK], DatanodeInfoWithStorage[127.0.0.1:45686,DS-3122f807-41d3-4c70-a058-47ca7a5b044b,DISK], DatanodeInfoWithStorage[127.0.0.1:37286,DS-fbcdc3f5-76cd-4b57-b9a5-1c7fcf7382ac,DISK], DatanodeInfoWithStorage[127.0.0.1:40555,DS-2908c5f9-2b80-46bf-a977-cc186853738d,DISK], DatanodeInfoWithStorage[127.0.0.1:34969,DS-c59bf8c8-b811-4efd-9716-f7898d13c867,DISK], DatanodeInfoWithStorage[127.0.0.1:42791,DS-fee16249-dbe5-455a-9f1c-6795b37cbca0,DISK], DatanodeInfoWithStorage[127.0.0.1:33040,DS-bade6671-259b-4fa9-b028-30307a3f392d,DISK], DatanodeInfoWithStorage[127.0.0.1:45145,DS-6ac50d58-aa0b-40ef-adbf-f7ca927961a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1480915568-172.17.0.5-1598153845683:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39258,DS-000c47cc-f9e1-423f-b8c4-2aaad26e4b9e,DISK], DatanodeInfoWithStorage[127.0.0.1:45686,DS-3122f807-41d3-4c70-a058-47ca7a5b044b,DISK], DatanodeInfoWithStorage[127.0.0.1:37286,DS-fbcdc3f5-76cd-4b57-b9a5-1c7fcf7382ac,DISK], DatanodeInfoWithStorage[127.0.0.1:40555,DS-2908c5f9-2b80-46bf-a977-cc186853738d,DISK], DatanodeInfoWithStorage[127.0.0.1:34969,DS-c59bf8c8-b811-4efd-9716-f7898d13c867,DISK], DatanodeInfoWithStorage[127.0.0.1:42791,DS-fee16249-dbe5-455a-9f1c-6795b37cbca0,DISK], DatanodeInfoWithStorage[127.0.0.1:33040,DS-bade6671-259b-4fa9-b028-30307a3f392d,DISK], DatanodeInfoWithStorage[127.0.0.1:45145,DS-6ac50d58-aa0b-40ef-adbf-f7ca927961a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1816546480-172.17.0.5-1598154567064:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37814,DS-ac98be80-1357-4ff9-94ca-07be16d4f652,DISK], DatanodeInfoWithStorage[127.0.0.1:33452,DS-ffb97a81-71f7-44cd-aaeb-54c8c01e928b,DISK], DatanodeInfoWithStorage[127.0.0.1:36227,DS-1b22badc-f153-4e53-939d-9c2c347c4260,DISK], DatanodeInfoWithStorage[127.0.0.1:45110,DS-2c0789a7-b07b-4671-a6d3-c59c2ad53ac4,DISK], DatanodeInfoWithStorage[127.0.0.1:39439,DS-9f71f079-4c18-48db-b006-7aaf3e88050d,DISK], DatanodeInfoWithStorage[127.0.0.1:45507,DS-6d42220f-ada5-4dd0-863b-e5e49aae1a10,DISK], DatanodeInfoWithStorage[127.0.0.1:33051,DS-0ad22348-0851-41dd-b590-ddba74953bfb,DISK], DatanodeInfoWithStorage[127.0.0.1:45133,DS-99e1d393-a35f-48c7-8d03-8707ed6f575c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1816546480-172.17.0.5-1598154567064:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37814,DS-ac98be80-1357-4ff9-94ca-07be16d4f652,DISK], DatanodeInfoWithStorage[127.0.0.1:33452,DS-ffb97a81-71f7-44cd-aaeb-54c8c01e928b,DISK], DatanodeInfoWithStorage[127.0.0.1:36227,DS-1b22badc-f153-4e53-939d-9c2c347c4260,DISK], DatanodeInfoWithStorage[127.0.0.1:45110,DS-2c0789a7-b07b-4671-a6d3-c59c2ad53ac4,DISK], DatanodeInfoWithStorage[127.0.0.1:39439,DS-9f71f079-4c18-48db-b006-7aaf3e88050d,DISK], DatanodeInfoWithStorage[127.0.0.1:45507,DS-6d42220f-ada5-4dd0-863b-e5e49aae1a10,DISK], DatanodeInfoWithStorage[127.0.0.1:33051,DS-0ad22348-0851-41dd-b590-ddba74953bfb,DISK], DatanodeInfoWithStorage[127.0.0.1:45133,DS-99e1d393-a35f-48c7-8d03-8707ed6f575c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-390896592-172.17.0.5-1598155244212:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43419,DS-b53c5c9a-9121-478a-b0ea-e30d9024ba3b,DISK], DatanodeInfoWithStorage[127.0.0.1:45192,DS-faabe5b0-0ca8-49e7-84f2-c5f2f1127fbf,DISK], DatanodeInfoWithStorage[127.0.0.1:45755,DS-17ddfd4d-f09f-40d8-977e-02a9745d5f11,DISK], DatanodeInfoWithStorage[127.0.0.1:45102,DS-838b6f4c-347f-43ba-9148-304fe8702e49,DISK], DatanodeInfoWithStorage[127.0.0.1:34500,DS-3b7c456e-04a5-42e1-9e46-9fb42a959519,DISK], DatanodeInfoWithStorage[127.0.0.1:45639,DS-15f64fec-d2cf-4eff-a7cc-edd90fe42bdf,DISK], DatanodeInfoWithStorage[127.0.0.1:37644,DS-93ce802d-4407-4cfc-83cc-c7dee08683bb,DISK], DatanodeInfoWithStorage[127.0.0.1:33136,DS-6b4be189-5db4-4de7-8643-72f0337813c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-390896592-172.17.0.5-1598155244212:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43419,DS-b53c5c9a-9121-478a-b0ea-e30d9024ba3b,DISK], DatanodeInfoWithStorage[127.0.0.1:45192,DS-faabe5b0-0ca8-49e7-84f2-c5f2f1127fbf,DISK], DatanodeInfoWithStorage[127.0.0.1:45755,DS-17ddfd4d-f09f-40d8-977e-02a9745d5f11,DISK], DatanodeInfoWithStorage[127.0.0.1:45102,DS-838b6f4c-347f-43ba-9148-304fe8702e49,DISK], DatanodeInfoWithStorage[127.0.0.1:34500,DS-3b7c456e-04a5-42e1-9e46-9fb42a959519,DISK], DatanodeInfoWithStorage[127.0.0.1:45639,DS-15f64fec-d2cf-4eff-a7cc-edd90fe42bdf,DISK], DatanodeInfoWithStorage[127.0.0.1:37644,DS-93ce802d-4407-4cfc-83cc-c7dee08683bb,DISK], DatanodeInfoWithStorage[127.0.0.1:33136,DS-6b4be189-5db4-4de7-8643-72f0337813c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2021705774-172.17.0.5-1598155277726:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37944,DS-d035e109-bfbf-4ccd-aa88-c191b8fa05ad,DISK], DatanodeInfoWithStorage[127.0.0.1:46193,DS-0651415e-02ab-4555-938f-b5d8fb99e14c,DISK], DatanodeInfoWithStorage[127.0.0.1:41559,DS-25cf926f-f2b1-4b1a-a030-bf372ccfe5c1,DISK], DatanodeInfoWithStorage[127.0.0.1:40165,DS-37596ab2-13a9-4a6d-b8d5-2d399c03cce3,DISK], DatanodeInfoWithStorage[127.0.0.1:38093,DS-27abd3af-db82-4bae-a88f-c5b1aac180b7,DISK], DatanodeInfoWithStorage[127.0.0.1:46171,DS-b148fd3e-0d21-43f9-b6fd-d35da4b703ba,DISK], DatanodeInfoWithStorage[127.0.0.1:43397,DS-421f58be-4aca-49e7-bc86-0f0cd503b0a6,DISK], DatanodeInfoWithStorage[127.0.0.1:37206,DS-3185471c-132c-40ef-be7a-e2c11953e2b7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2021705774-172.17.0.5-1598155277726:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37944,DS-d035e109-bfbf-4ccd-aa88-c191b8fa05ad,DISK], DatanodeInfoWithStorage[127.0.0.1:46193,DS-0651415e-02ab-4555-938f-b5d8fb99e14c,DISK], DatanodeInfoWithStorage[127.0.0.1:41559,DS-25cf926f-f2b1-4b1a-a030-bf372ccfe5c1,DISK], DatanodeInfoWithStorage[127.0.0.1:40165,DS-37596ab2-13a9-4a6d-b8d5-2d399c03cce3,DISK], DatanodeInfoWithStorage[127.0.0.1:38093,DS-27abd3af-db82-4bae-a88f-c5b1aac180b7,DISK], DatanodeInfoWithStorage[127.0.0.1:46171,DS-b148fd3e-0d21-43f9-b6fd-d35da4b703ba,DISK], DatanodeInfoWithStorage[127.0.0.1:43397,DS-421f58be-4aca-49e7-bc86-0f0cd503b0a6,DISK], DatanodeInfoWithStorage[127.0.0.1:37206,DS-3185471c-132c-40ef-be7a-e2c11953e2b7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-778850410-172.17.0.5-1598155656778:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33760,DS-fc004bfa-e14a-4c0a-ae77-880b4074ec58,DISK], DatanodeInfoWithStorage[127.0.0.1:34424,DS-de031642-3c2c-4cbe-a2a9-baf92b6a6bbe,DISK], DatanodeInfoWithStorage[127.0.0.1:43788,DS-ae4711b9-63e3-4c6d-9390-5deda9ed96a2,DISK], DatanodeInfoWithStorage[127.0.0.1:34400,DS-7aacf2ca-c922-4bd7-980c-e64b542feb8d,DISK], DatanodeInfoWithStorage[127.0.0.1:43482,DS-700a5d4d-69b5-4a6b-94f9-d7bf222e7b99,DISK], DatanodeInfoWithStorage[127.0.0.1:42351,DS-7ac7a97c-1c9d-40e9-8a06-395d034c87b1,DISK], DatanodeInfoWithStorage[127.0.0.1:37415,DS-3434f8a5-4521-4077-ae5a-4d632f4fd400,DISK], DatanodeInfoWithStorage[127.0.0.1:37400,DS-39f4b78d-daf2-4759-8cec-938640739ad4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-778850410-172.17.0.5-1598155656778:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33760,DS-fc004bfa-e14a-4c0a-ae77-880b4074ec58,DISK], DatanodeInfoWithStorage[127.0.0.1:34424,DS-de031642-3c2c-4cbe-a2a9-baf92b6a6bbe,DISK], DatanodeInfoWithStorage[127.0.0.1:43788,DS-ae4711b9-63e3-4c6d-9390-5deda9ed96a2,DISK], DatanodeInfoWithStorage[127.0.0.1:34400,DS-7aacf2ca-c922-4bd7-980c-e64b542feb8d,DISK], DatanodeInfoWithStorage[127.0.0.1:43482,DS-700a5d4d-69b5-4a6b-94f9-d7bf222e7b99,DISK], DatanodeInfoWithStorage[127.0.0.1:42351,DS-7ac7a97c-1c9d-40e9-8a06-395d034c87b1,DISK], DatanodeInfoWithStorage[127.0.0.1:37415,DS-3434f8a5-4521-4077-ae5a-4d632f4fd400,DISK], DatanodeInfoWithStorage[127.0.0.1:37400,DS-39f4b78d-daf2-4759-8cec-938640739ad4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 10 out of 50
v1v1v2v2 failed with probability 14 out of 50
result: false positive !!!
Total execution time in seconds : 5274
