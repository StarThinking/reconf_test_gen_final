reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1290941896-172.17.0.7-1598134520100:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34427,DS-407053ae-2ff0-42d1-aa17-463231240e56,DISK], DatanodeInfoWithStorage[127.0.0.1:45717,DS-6a9868c6-943c-47d3-9330-0d84e87a66e8,DISK], DatanodeInfoWithStorage[127.0.0.1:32921,DS-c3829924-955e-494d-b597-25144dc5d4fa,DISK], DatanodeInfoWithStorage[127.0.0.1:37075,DS-2ddedfdd-1b89-429c-a6e5-06352def40f2,DISK], DatanodeInfoWithStorage[127.0.0.1:38799,DS-c4ab12af-832b-4124-af86-ccaf65472f1a,DISK], DatanodeInfoWithStorage[127.0.0.1:37604,DS-7d16b40b-2f22-4d39-b632-c31405945883,DISK], DatanodeInfoWithStorage[127.0.0.1:46595,DS-c0556e2d-a270-40bd-8202-f9bfa2af2c69,DISK], DatanodeInfoWithStorage[127.0.0.1:43583,DS-7035dc3e-8d64-48b6-be8a-5485e07cf21c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1290941896-172.17.0.7-1598134520100:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34427,DS-407053ae-2ff0-42d1-aa17-463231240e56,DISK], DatanodeInfoWithStorage[127.0.0.1:45717,DS-6a9868c6-943c-47d3-9330-0d84e87a66e8,DISK], DatanodeInfoWithStorage[127.0.0.1:32921,DS-c3829924-955e-494d-b597-25144dc5d4fa,DISK], DatanodeInfoWithStorage[127.0.0.1:37075,DS-2ddedfdd-1b89-429c-a6e5-06352def40f2,DISK], DatanodeInfoWithStorage[127.0.0.1:38799,DS-c4ab12af-832b-4124-af86-ccaf65472f1a,DISK], DatanodeInfoWithStorage[127.0.0.1:37604,DS-7d16b40b-2f22-4d39-b632-c31405945883,DISK], DatanodeInfoWithStorage[127.0.0.1:46595,DS-c0556e2d-a270-40bd-8202-f9bfa2af2c69,DISK], DatanodeInfoWithStorage[127.0.0.1:43583,DS-7035dc3e-8d64-48b6-be8a-5485e07cf21c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-101707171-172.17.0.7-1598134583065:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40809,DS-81677d67-0910-4599-8750-d1beb37cb9cb,DISK], DatanodeInfoWithStorage[127.0.0.1:46466,DS-6f7cd022-516a-4bf3-9d8b-69a97ec6a225,DISK], DatanodeInfoWithStorage[127.0.0.1:42709,DS-5aaaf13d-3b79-44b9-96a9-ad542bf37dbd,DISK], DatanodeInfoWithStorage[127.0.0.1:38513,DS-1ae54be2-3ab8-4fad-91e2-83ea8184e220,DISK], DatanodeInfoWithStorage[127.0.0.1:32969,DS-e3c9fb42-e570-4889-99a3-b924f3964c87,DISK], DatanodeInfoWithStorage[127.0.0.1:36795,DS-cce6bcd6-dab1-45ed-a8e8-52f3be3a069b,DISK], DatanodeInfoWithStorage[127.0.0.1:44293,DS-534c04ff-da10-4f35-a4ac-9f4db0a3692d,DISK], DatanodeInfoWithStorage[127.0.0.1:42630,DS-61e12c01-5150-4dbd-a64c-677b19834c75,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-101707171-172.17.0.7-1598134583065:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40809,DS-81677d67-0910-4599-8750-d1beb37cb9cb,DISK], DatanodeInfoWithStorage[127.0.0.1:46466,DS-6f7cd022-516a-4bf3-9d8b-69a97ec6a225,DISK], DatanodeInfoWithStorage[127.0.0.1:42709,DS-5aaaf13d-3b79-44b9-96a9-ad542bf37dbd,DISK], DatanodeInfoWithStorage[127.0.0.1:38513,DS-1ae54be2-3ab8-4fad-91e2-83ea8184e220,DISK], DatanodeInfoWithStorage[127.0.0.1:32969,DS-e3c9fb42-e570-4889-99a3-b924f3964c87,DISK], DatanodeInfoWithStorage[127.0.0.1:36795,DS-cce6bcd6-dab1-45ed-a8e8-52f3be3a069b,DISK], DatanodeInfoWithStorage[127.0.0.1:44293,DS-534c04ff-da10-4f35-a4ac-9f4db0a3692d,DISK], DatanodeInfoWithStorage[127.0.0.1:42630,DS-61e12c01-5150-4dbd-a64c-677b19834c75,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-803648280-172.17.0.7-1598134726316:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42548,DS-b1a059b6-4996-4bd6-923e-236129d090bb,DISK], DatanodeInfoWithStorage[127.0.0.1:45911,DS-36d370e3-dd89-46a5-8b4a-d4449ba46336,DISK], DatanodeInfoWithStorage[127.0.0.1:37410,DS-d9ca26c5-b3ef-4b47-8ae0-34bf5ca7dcc9,DISK], DatanodeInfoWithStorage[127.0.0.1:38014,DS-47ee407e-ba77-4fdf-8df7-3fd221ffe510,DISK], DatanodeInfoWithStorage[127.0.0.1:35119,DS-343f9504-c0a9-484e-8a8d-cde9116f87d7,DISK], DatanodeInfoWithStorage[127.0.0.1:41944,DS-2e9cdf3f-be49-4b2c-89ba-959c01be774e,DISK], DatanodeInfoWithStorage[127.0.0.1:46031,DS-83e9b911-e223-4c4e-92d6-c1b7aea5ce54,DISK], DatanodeInfoWithStorage[127.0.0.1:39157,DS-d81c3f51-3a9d-4861-b592-d65ca7e47658,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-803648280-172.17.0.7-1598134726316:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42548,DS-b1a059b6-4996-4bd6-923e-236129d090bb,DISK], DatanodeInfoWithStorage[127.0.0.1:45911,DS-36d370e3-dd89-46a5-8b4a-d4449ba46336,DISK], DatanodeInfoWithStorage[127.0.0.1:37410,DS-d9ca26c5-b3ef-4b47-8ae0-34bf5ca7dcc9,DISK], DatanodeInfoWithStorage[127.0.0.1:38014,DS-47ee407e-ba77-4fdf-8df7-3fd221ffe510,DISK], DatanodeInfoWithStorage[127.0.0.1:35119,DS-343f9504-c0a9-484e-8a8d-cde9116f87d7,DISK], DatanodeInfoWithStorage[127.0.0.1:41944,DS-2e9cdf3f-be49-4b2c-89ba-959c01be774e,DISK], DatanodeInfoWithStorage[127.0.0.1:46031,DS-83e9b911-e223-4c4e-92d6-c1b7aea5ce54,DISK], DatanodeInfoWithStorage[127.0.0.1:39157,DS-d81c3f51-3a9d-4861-b592-d65ca7e47658,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1319633488-172.17.0.7-1598135165901:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45399,DS-9b791044-c8c3-4ce6-98b0-b2e70e267839,DISK], DatanodeInfoWithStorage[127.0.0.1:43378,DS-1dca6f3f-5c78-433c-a68c-d576eaeff0b4,DISK], DatanodeInfoWithStorage[127.0.0.1:43196,DS-518f5404-d7d0-4179-a777-06f642d8e75c,DISK], DatanodeInfoWithStorage[127.0.0.1:40676,DS-1cf5fc51-29a8-45da-9708-6449d4f898f6,DISK], DatanodeInfoWithStorage[127.0.0.1:42057,DS-eeaaa154-a83b-4409-8786-419ffeed38eb,DISK], DatanodeInfoWithStorage[127.0.0.1:35747,DS-1bebbe78-fcf2-4f9d-9d70-efbcd66c36bc,DISK], DatanodeInfoWithStorage[127.0.0.1:35419,DS-ea94e7d1-f36c-4826-9e0d-a0973346c8ad,DISK], DatanodeInfoWithStorage[127.0.0.1:44249,DS-3c21eccf-0b59-46ba-b245-37b5ec31e25d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1319633488-172.17.0.7-1598135165901:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45399,DS-9b791044-c8c3-4ce6-98b0-b2e70e267839,DISK], DatanodeInfoWithStorage[127.0.0.1:43378,DS-1dca6f3f-5c78-433c-a68c-d576eaeff0b4,DISK], DatanodeInfoWithStorage[127.0.0.1:43196,DS-518f5404-d7d0-4179-a777-06f642d8e75c,DISK], DatanodeInfoWithStorage[127.0.0.1:40676,DS-1cf5fc51-29a8-45da-9708-6449d4f898f6,DISK], DatanodeInfoWithStorage[127.0.0.1:42057,DS-eeaaa154-a83b-4409-8786-419ffeed38eb,DISK], DatanodeInfoWithStorage[127.0.0.1:35747,DS-1bebbe78-fcf2-4f9d-9d70-efbcd66c36bc,DISK], DatanodeInfoWithStorage[127.0.0.1:35419,DS-ea94e7d1-f36c-4826-9e0d-a0973346c8ad,DISK], DatanodeInfoWithStorage[127.0.0.1:44249,DS-3c21eccf-0b59-46ba-b245-37b5ec31e25d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1036700404-172.17.0.7-1598135343634:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40729,DS-3a8f6e54-4e12-4006-8c38-ddd41a3adc86,DISK], DatanodeInfoWithStorage[127.0.0.1:43327,DS-c75bc459-8383-4ef1-882a-1603361d84f5,DISK], DatanodeInfoWithStorage[127.0.0.1:41123,DS-e3d31fb7-e371-4003-840e-fee07d8825fb,DISK], DatanodeInfoWithStorage[127.0.0.1:33591,DS-e7243b95-59b2-4b4e-99d0-35c7cae59700,DISK], DatanodeInfoWithStorage[127.0.0.1:37588,DS-c3a80f84-ffe6-4656-8eea-543fee7f47bb,DISK], DatanodeInfoWithStorage[127.0.0.1:43006,DS-eb3f58f9-6ef3-4176-835b-b87f7ad6f488,DISK], DatanodeInfoWithStorage[127.0.0.1:34709,DS-455461b1-caa2-4ccf-b8b3-1c9bb736d157,DISK], DatanodeInfoWithStorage[127.0.0.1:42858,DS-b9c08850-2caf-4141-8e38-61cedd74309d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1036700404-172.17.0.7-1598135343634:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40729,DS-3a8f6e54-4e12-4006-8c38-ddd41a3adc86,DISK], DatanodeInfoWithStorage[127.0.0.1:43327,DS-c75bc459-8383-4ef1-882a-1603361d84f5,DISK], DatanodeInfoWithStorage[127.0.0.1:41123,DS-e3d31fb7-e371-4003-840e-fee07d8825fb,DISK], DatanodeInfoWithStorage[127.0.0.1:33591,DS-e7243b95-59b2-4b4e-99d0-35c7cae59700,DISK], DatanodeInfoWithStorage[127.0.0.1:37588,DS-c3a80f84-ffe6-4656-8eea-543fee7f47bb,DISK], DatanodeInfoWithStorage[127.0.0.1:43006,DS-eb3f58f9-6ef3-4176-835b-b87f7ad6f488,DISK], DatanodeInfoWithStorage[127.0.0.1:34709,DS-455461b1-caa2-4ccf-b8b3-1c9bb736d157,DISK], DatanodeInfoWithStorage[127.0.0.1:42858,DS-b9c08850-2caf-4141-8e38-61cedd74309d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1158284645-172.17.0.7-1598135380954:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40773,DS-1c141d36-c6f4-4acd-936e-3ebc1ea9bbc6,DISK], DatanodeInfoWithStorage[127.0.0.1:39487,DS-51cf8446-f8ec-446b-8a6f-80585339fea3,DISK], DatanodeInfoWithStorage[127.0.0.1:45470,DS-c6108efc-31d4-4953-ad86-d71480f26081,DISK], DatanodeInfoWithStorage[127.0.0.1:46190,DS-0cc7b905-bb8c-47e1-b531-4aaf1f2948cb,DISK], DatanodeInfoWithStorage[127.0.0.1:40078,DS-26360017-d818-49cb-acb5-829fc382b31c,DISK], DatanodeInfoWithStorage[127.0.0.1:43853,DS-210f17f6-f25f-4e70-95d4-832f2597bcaf,DISK], DatanodeInfoWithStorage[127.0.0.1:41112,DS-a3ab0784-2c6d-4a9e-9c59-23c2259b511e,DISK], DatanodeInfoWithStorage[127.0.0.1:42916,DS-340c08be-3e8c-41ec-b353-cdb341c2a7a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1158284645-172.17.0.7-1598135380954:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40773,DS-1c141d36-c6f4-4acd-936e-3ebc1ea9bbc6,DISK], DatanodeInfoWithStorage[127.0.0.1:39487,DS-51cf8446-f8ec-446b-8a6f-80585339fea3,DISK], DatanodeInfoWithStorage[127.0.0.1:45470,DS-c6108efc-31d4-4953-ad86-d71480f26081,DISK], DatanodeInfoWithStorage[127.0.0.1:46190,DS-0cc7b905-bb8c-47e1-b531-4aaf1f2948cb,DISK], DatanodeInfoWithStorage[127.0.0.1:40078,DS-26360017-d818-49cb-acb5-829fc382b31c,DISK], DatanodeInfoWithStorage[127.0.0.1:43853,DS-210f17f6-f25f-4e70-95d4-832f2597bcaf,DISK], DatanodeInfoWithStorage[127.0.0.1:41112,DS-a3ab0784-2c6d-4a9e-9c59-23c2259b511e,DISK], DatanodeInfoWithStorage[127.0.0.1:42916,DS-340c08be-3e8c-41ec-b353-cdb341c2a7a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1812909735-172.17.0.7-1598135700054:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40867,DS-1d03f3c5-e0a4-4646-a14c-80281ff2991b,DISK], DatanodeInfoWithStorage[127.0.0.1:32861,DS-1a4a4f21-9b60-465d-94fc-e33cb58bda54,DISK], DatanodeInfoWithStorage[127.0.0.1:44076,DS-240d1302-80a1-484d-b168-d141dc6199b2,DISK], DatanodeInfoWithStorage[127.0.0.1:39523,DS-0f954f6f-f58d-4502-af9e-28ac61eff214,DISK], DatanodeInfoWithStorage[127.0.0.1:34503,DS-901a5a54-322b-44d6-ada6-7b8a46932089,DISK], DatanodeInfoWithStorage[127.0.0.1:36308,DS-16c63dd9-3921-4c8a-96f3-a6f4b496696d,DISK], DatanodeInfoWithStorage[127.0.0.1:44425,DS-ef972c8f-96b8-45ba-8005-1b0a49a57564,DISK], DatanodeInfoWithStorage[127.0.0.1:39316,DS-d0f1ceb3-23a0-4b67-9adc-0428feca903e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1812909735-172.17.0.7-1598135700054:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40867,DS-1d03f3c5-e0a4-4646-a14c-80281ff2991b,DISK], DatanodeInfoWithStorage[127.0.0.1:32861,DS-1a4a4f21-9b60-465d-94fc-e33cb58bda54,DISK], DatanodeInfoWithStorage[127.0.0.1:44076,DS-240d1302-80a1-484d-b168-d141dc6199b2,DISK], DatanodeInfoWithStorage[127.0.0.1:39523,DS-0f954f6f-f58d-4502-af9e-28ac61eff214,DISK], DatanodeInfoWithStorage[127.0.0.1:34503,DS-901a5a54-322b-44d6-ada6-7b8a46932089,DISK], DatanodeInfoWithStorage[127.0.0.1:36308,DS-16c63dd9-3921-4c8a-96f3-a6f4b496696d,DISK], DatanodeInfoWithStorage[127.0.0.1:44425,DS-ef972c8f-96b8-45ba-8005-1b0a49a57564,DISK], DatanodeInfoWithStorage[127.0.0.1:39316,DS-d0f1ceb3-23a0-4b67-9adc-0428feca903e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-58065607-172.17.0.7-1598136230129:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37112,DS-4d799057-9022-4c30-83c8-aeb12c6da70e,DISK], DatanodeInfoWithStorage[127.0.0.1:34040,DS-4597f589-4d15-412e-92a5-5ea0bd6a96af,DISK], DatanodeInfoWithStorage[127.0.0.1:37405,DS-b9942414-b7af-4bae-abfc-d2f5118af1cc,DISK], DatanodeInfoWithStorage[127.0.0.1:37976,DS-c437fd74-5662-45db-a2e0-33d6a73606af,DISK], DatanodeInfoWithStorage[127.0.0.1:45906,DS-68510ec6-b246-4f9f-9bcb-784731fdcbdc,DISK], DatanodeInfoWithStorage[127.0.0.1:36763,DS-51ec34c5-6cb9-443d-94dc-33b9f261d23e,DISK], DatanodeInfoWithStorage[127.0.0.1:36618,DS-79abe380-0dc7-4e77-a9da-6ebf67d066ba,DISK], DatanodeInfoWithStorage[127.0.0.1:43160,DS-c0b9bfb0-1963-4184-97d6-f9032074a74f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-58065607-172.17.0.7-1598136230129:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37112,DS-4d799057-9022-4c30-83c8-aeb12c6da70e,DISK], DatanodeInfoWithStorage[127.0.0.1:34040,DS-4597f589-4d15-412e-92a5-5ea0bd6a96af,DISK], DatanodeInfoWithStorage[127.0.0.1:37405,DS-b9942414-b7af-4bae-abfc-d2f5118af1cc,DISK], DatanodeInfoWithStorage[127.0.0.1:37976,DS-c437fd74-5662-45db-a2e0-33d6a73606af,DISK], DatanodeInfoWithStorage[127.0.0.1:45906,DS-68510ec6-b246-4f9f-9bcb-784731fdcbdc,DISK], DatanodeInfoWithStorage[127.0.0.1:36763,DS-51ec34c5-6cb9-443d-94dc-33b9f261d23e,DISK], DatanodeInfoWithStorage[127.0.0.1:36618,DS-79abe380-0dc7-4e77-a9da-6ebf67d066ba,DISK], DatanodeInfoWithStorage[127.0.0.1:43160,DS-c0b9bfb0-1963-4184-97d6-f9032074a74f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1195134021-172.17.0.7-1598136580103:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36303,DS-6e86c271-1fb3-4dcb-9c66-d98cd2bb3e40,DISK], DatanodeInfoWithStorage[127.0.0.1:34004,DS-bf9fd58c-ec87-40d4-85e7-8818f6ecdc26,DISK], DatanodeInfoWithStorage[127.0.0.1:35109,DS-39ff659c-c904-4a65-b588-1d9127aa2e79,DISK], DatanodeInfoWithStorage[127.0.0.1:33664,DS-86bf2761-5253-45b4-8fba-67209d6271b1,DISK], DatanodeInfoWithStorage[127.0.0.1:33253,DS-03446934-5611-4dfd-8ff5-5600d2448a88,DISK], DatanodeInfoWithStorage[127.0.0.1:39248,DS-961d1d2b-4dd3-41f2-8fdd-f3bfb05d52c7,DISK], DatanodeInfoWithStorage[127.0.0.1:43146,DS-aab46b7b-0212-48fa-8a40-8487ff4cc3d6,DISK], DatanodeInfoWithStorage[127.0.0.1:33076,DS-6b44ac43-dc95-43f3-9433-6944a0974c6b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1195134021-172.17.0.7-1598136580103:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36303,DS-6e86c271-1fb3-4dcb-9c66-d98cd2bb3e40,DISK], DatanodeInfoWithStorage[127.0.0.1:34004,DS-bf9fd58c-ec87-40d4-85e7-8818f6ecdc26,DISK], DatanodeInfoWithStorage[127.0.0.1:35109,DS-39ff659c-c904-4a65-b588-1d9127aa2e79,DISK], DatanodeInfoWithStorage[127.0.0.1:33664,DS-86bf2761-5253-45b4-8fba-67209d6271b1,DISK], DatanodeInfoWithStorage[127.0.0.1:33253,DS-03446934-5611-4dfd-8ff5-5600d2448a88,DISK], DatanodeInfoWithStorage[127.0.0.1:39248,DS-961d1d2b-4dd3-41f2-8fdd-f3bfb05d52c7,DISK], DatanodeInfoWithStorage[127.0.0.1:43146,DS-aab46b7b-0212-48fa-8a40-8487ff4cc3d6,DISK], DatanodeInfoWithStorage[127.0.0.1:33076,DS-6b44ac43-dc95-43f3-9433-6944a0974c6b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-577306167-172.17.0.7-1598136738486:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43281,DS-05601fa4-ba81-4aa1-ab3d-47dae8205228,DISK], DatanodeInfoWithStorage[127.0.0.1:45500,DS-d0ae6ca0-c002-4b1d-9084-7cb4c3cd9803,DISK], DatanodeInfoWithStorage[127.0.0.1:45423,DS-b51f96b3-cfbb-46fe-a12b-4f8c93377884,DISK], DatanodeInfoWithStorage[127.0.0.1:38905,DS-f5754bf3-f0ec-455c-99e7-4770db5e2f59,DISK], DatanodeInfoWithStorage[127.0.0.1:41999,DS-2b7a8d5c-a24f-41fc-bae7-f0fdabd0b721,DISK], DatanodeInfoWithStorage[127.0.0.1:42135,DS-490a8879-0564-4564-9374-1d71478530cd,DISK], DatanodeInfoWithStorage[127.0.0.1:43462,DS-c16b3172-8904-44d5-a6f5-270a5af2840f,DISK], DatanodeInfoWithStorage[127.0.0.1:43310,DS-57c1ef81-1cd7-49a8-9d28-f7a3218902be,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-577306167-172.17.0.7-1598136738486:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43281,DS-05601fa4-ba81-4aa1-ab3d-47dae8205228,DISK], DatanodeInfoWithStorage[127.0.0.1:45500,DS-d0ae6ca0-c002-4b1d-9084-7cb4c3cd9803,DISK], DatanodeInfoWithStorage[127.0.0.1:45423,DS-b51f96b3-cfbb-46fe-a12b-4f8c93377884,DISK], DatanodeInfoWithStorage[127.0.0.1:38905,DS-f5754bf3-f0ec-455c-99e7-4770db5e2f59,DISK], DatanodeInfoWithStorage[127.0.0.1:41999,DS-2b7a8d5c-a24f-41fc-bae7-f0fdabd0b721,DISK], DatanodeInfoWithStorage[127.0.0.1:42135,DS-490a8879-0564-4564-9374-1d71478530cd,DISK], DatanodeInfoWithStorage[127.0.0.1:43462,DS-c16b3172-8904-44d5-a6f5-270a5af2840f,DISK], DatanodeInfoWithStorage[127.0.0.1:43310,DS-57c1ef81-1cd7-49a8-9d28-f7a3218902be,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-966546439-172.17.0.7-1598137147357:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46870,DS-806da3b6-c253-4bc4-931a-64dbfcf60de7,DISK], DatanodeInfoWithStorage[127.0.0.1:41614,DS-c5faed93-4f30-4fd1-8ae7-b5e43ff8cb12,DISK], DatanodeInfoWithStorage[127.0.0.1:34069,DS-ca09a943-f18a-41c9-a9f8-357ddc274b02,DISK], DatanodeInfoWithStorage[127.0.0.1:33915,DS-46061ae8-6d3c-4086-be5f-70a8624673dc,DISK], DatanodeInfoWithStorage[127.0.0.1:41107,DS-26b33557-0208-4762-9a32-11c50d308d5c,DISK], DatanodeInfoWithStorage[127.0.0.1:40656,DS-a981583a-59c1-46c5-824e-600f5b00e3ad,DISK], DatanodeInfoWithStorage[127.0.0.1:34577,DS-f656ad16-2c1a-4766-9c23-90925980ac4e,DISK], DatanodeInfoWithStorage[127.0.0.1:33320,DS-34fdc6b3-446b-431b-be50-9eb959576491,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-966546439-172.17.0.7-1598137147357:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46870,DS-806da3b6-c253-4bc4-931a-64dbfcf60de7,DISK], DatanodeInfoWithStorage[127.0.0.1:41614,DS-c5faed93-4f30-4fd1-8ae7-b5e43ff8cb12,DISK], DatanodeInfoWithStorage[127.0.0.1:34069,DS-ca09a943-f18a-41c9-a9f8-357ddc274b02,DISK], DatanodeInfoWithStorage[127.0.0.1:33915,DS-46061ae8-6d3c-4086-be5f-70a8624673dc,DISK], DatanodeInfoWithStorage[127.0.0.1:41107,DS-26b33557-0208-4762-9a32-11c50d308d5c,DISK], DatanodeInfoWithStorage[127.0.0.1:40656,DS-a981583a-59c1-46c5-824e-600f5b00e3ad,DISK], DatanodeInfoWithStorage[127.0.0.1:34577,DS-f656ad16-2c1a-4766-9c23-90925980ac4e,DISK], DatanodeInfoWithStorage[127.0.0.1:33320,DS-34fdc6b3-446b-431b-be50-9eb959576491,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1888507177-172.17.0.7-1598137422190:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41241,DS-220d124d-6aec-4d02-bcc9-622e5cda26fa,DISK], DatanodeInfoWithStorage[127.0.0.1:39105,DS-b4170549-7987-4827-a7bb-a0186ebc4bf8,DISK], DatanodeInfoWithStorage[127.0.0.1:45642,DS-bb052fb9-c5be-4fa3-a250-c4744190f9f2,DISK], DatanodeInfoWithStorage[127.0.0.1:46735,DS-d2842adb-8c67-44e6-ba89-70b94ec5ab19,DISK], DatanodeInfoWithStorage[127.0.0.1:43516,DS-1df014b2-5440-4272-9eea-55b40d27f0c5,DISK], DatanodeInfoWithStorage[127.0.0.1:35546,DS-cd033ef8-fa83-4dff-b0c9-b89e931c0f40,DISK], DatanodeInfoWithStorage[127.0.0.1:42196,DS-cfd55320-8af1-4ec5-b049-b2bd75c919b2,DISK], DatanodeInfoWithStorage[127.0.0.1:33282,DS-b494f097-014c-42f1-94cf-7e4664ae954e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1888507177-172.17.0.7-1598137422190:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41241,DS-220d124d-6aec-4d02-bcc9-622e5cda26fa,DISK], DatanodeInfoWithStorage[127.0.0.1:39105,DS-b4170549-7987-4827-a7bb-a0186ebc4bf8,DISK], DatanodeInfoWithStorage[127.0.0.1:45642,DS-bb052fb9-c5be-4fa3-a250-c4744190f9f2,DISK], DatanodeInfoWithStorage[127.0.0.1:46735,DS-d2842adb-8c67-44e6-ba89-70b94ec5ab19,DISK], DatanodeInfoWithStorage[127.0.0.1:43516,DS-1df014b2-5440-4272-9eea-55b40d27f0c5,DISK], DatanodeInfoWithStorage[127.0.0.1:35546,DS-cd033ef8-fa83-4dff-b0c9-b89e931c0f40,DISK], DatanodeInfoWithStorage[127.0.0.1:42196,DS-cfd55320-8af1-4ec5-b049-b2bd75c919b2,DISK], DatanodeInfoWithStorage[127.0.0.1:33282,DS-b494f097-014c-42f1-94cf-7e4664ae954e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1469017659-172.17.0.7-1598138311082:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40856,DS-008c8f63-abfe-4c83-bb4f-ad330c99e31e,DISK], DatanodeInfoWithStorage[127.0.0.1:44920,DS-33db7419-e467-444a-8e41-19b3c2294aa5,DISK], DatanodeInfoWithStorage[127.0.0.1:38297,DS-e3c7fd7f-18ec-4e27-814e-d9dd62dfc0c7,DISK], DatanodeInfoWithStorage[127.0.0.1:41177,DS-a2e5103a-b3be-41a3-a735-88afb6b92f97,DISK], DatanodeInfoWithStorage[127.0.0.1:34552,DS-53084420-00ab-4d67-8ddc-cbfc0dfd09ab,DISK], DatanodeInfoWithStorage[127.0.0.1:34976,DS-7362b46d-332f-4321-affd-d3090db0b689,DISK], DatanodeInfoWithStorage[127.0.0.1:43047,DS-b2bd1e1d-ec44-490b-8011-797e0b1b4e87,DISK], DatanodeInfoWithStorage[127.0.0.1:45286,DS-525d8f65-ff6f-4640-b31e-2a0b6d9e06a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1469017659-172.17.0.7-1598138311082:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40856,DS-008c8f63-abfe-4c83-bb4f-ad330c99e31e,DISK], DatanodeInfoWithStorage[127.0.0.1:44920,DS-33db7419-e467-444a-8e41-19b3c2294aa5,DISK], DatanodeInfoWithStorage[127.0.0.1:38297,DS-e3c7fd7f-18ec-4e27-814e-d9dd62dfc0c7,DISK], DatanodeInfoWithStorage[127.0.0.1:41177,DS-a2e5103a-b3be-41a3-a735-88afb6b92f97,DISK], DatanodeInfoWithStorage[127.0.0.1:34552,DS-53084420-00ab-4d67-8ddc-cbfc0dfd09ab,DISK], DatanodeInfoWithStorage[127.0.0.1:34976,DS-7362b46d-332f-4321-affd-d3090db0b689,DISK], DatanodeInfoWithStorage[127.0.0.1:43047,DS-b2bd1e1d-ec44-490b-8011-797e0b1b4e87,DISK], DatanodeInfoWithStorage[127.0.0.1:45286,DS-525d8f65-ff6f-4640-b31e-2a0b6d9e06a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-410980045-172.17.0.7-1598138491478:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42502,DS-4ccd5782-f7ac-4104-b9cc-fb0123f5201f,DISK], DatanodeInfoWithStorage[127.0.0.1:46209,DS-ad2e4ea0-a83d-4a63-95b3-a65142f7649e,DISK], DatanodeInfoWithStorage[127.0.0.1:43916,DS-8df3166d-213d-44fa-9fc3-37a6b7ae0065,DISK], DatanodeInfoWithStorage[127.0.0.1:34391,DS-203389de-a848-490c-88ac-810cf8c3cfee,DISK], DatanodeInfoWithStorage[127.0.0.1:44398,DS-cc9dc1b7-eabf-4634-9770-9124f938a311,DISK], DatanodeInfoWithStorage[127.0.0.1:33929,DS-1fa02581-ae96-4d5b-a618-f2704ea242a3,DISK], DatanodeInfoWithStorage[127.0.0.1:33213,DS-b297101c-4b41-48fc-81e9-0f5c1a761aef,DISK], DatanodeInfoWithStorage[127.0.0.1:34051,DS-0107da6f-c572-4454-9399-17567de83777,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-410980045-172.17.0.7-1598138491478:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42502,DS-4ccd5782-f7ac-4104-b9cc-fb0123f5201f,DISK], DatanodeInfoWithStorage[127.0.0.1:46209,DS-ad2e4ea0-a83d-4a63-95b3-a65142f7649e,DISK], DatanodeInfoWithStorage[127.0.0.1:43916,DS-8df3166d-213d-44fa-9fc3-37a6b7ae0065,DISK], DatanodeInfoWithStorage[127.0.0.1:34391,DS-203389de-a848-490c-88ac-810cf8c3cfee,DISK], DatanodeInfoWithStorage[127.0.0.1:44398,DS-cc9dc1b7-eabf-4634-9770-9124f938a311,DISK], DatanodeInfoWithStorage[127.0.0.1:33929,DS-1fa02581-ae96-4d5b-a618-f2704ea242a3,DISK], DatanodeInfoWithStorage[127.0.0.1:33213,DS-b297101c-4b41-48fc-81e9-0f5c1a761aef,DISK], DatanodeInfoWithStorage[127.0.0.1:34051,DS-0107da6f-c572-4454-9399-17567de83777,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-140487845-172.17.0.7-1598138728765:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41771,DS-94deeb59-5708-46f2-97cb-307d627e2c04,DISK], DatanodeInfoWithStorage[127.0.0.1:39073,DS-b3f451ef-a855-4c60-8276-c573f33c6a51,DISK], DatanodeInfoWithStorage[127.0.0.1:39959,DS-58c7fb03-91fd-41c7-8f89-0543dcc0c2dc,DISK], DatanodeInfoWithStorage[127.0.0.1:45121,DS-27a08805-2936-44d7-b1e1-1f07320e3cab,DISK], DatanodeInfoWithStorage[127.0.0.1:40542,DS-df74d22d-9b20-4a8e-9262-4768ce0b6914,DISK], DatanodeInfoWithStorage[127.0.0.1:39069,DS-67212762-182e-4c02-aea4-1ca3d9e87429,DISK], DatanodeInfoWithStorage[127.0.0.1:38724,DS-4d2430b2-7212-4ee3-aa6a-51e52c3e0b82,DISK], DatanodeInfoWithStorage[127.0.0.1:35687,DS-2e7de880-deb1-4d21-bafa-ef1de880f7f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-140487845-172.17.0.7-1598138728765:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41771,DS-94deeb59-5708-46f2-97cb-307d627e2c04,DISK], DatanodeInfoWithStorage[127.0.0.1:39073,DS-b3f451ef-a855-4c60-8276-c573f33c6a51,DISK], DatanodeInfoWithStorage[127.0.0.1:39959,DS-58c7fb03-91fd-41c7-8f89-0543dcc0c2dc,DISK], DatanodeInfoWithStorage[127.0.0.1:45121,DS-27a08805-2936-44d7-b1e1-1f07320e3cab,DISK], DatanodeInfoWithStorage[127.0.0.1:40542,DS-df74d22d-9b20-4a8e-9262-4768ce0b6914,DISK], DatanodeInfoWithStorage[127.0.0.1:39069,DS-67212762-182e-4c02-aea4-1ca3d9e87429,DISK], DatanodeInfoWithStorage[127.0.0.1:38724,DS-4d2430b2-7212-4ee3-aa6a-51e52c3e0b82,DISK], DatanodeInfoWithStorage[127.0.0.1:35687,DS-2e7de880-deb1-4d21-bafa-ef1de880f7f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-367375586-172.17.0.7-1598138965201:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43865,DS-5912af24-ee4e-4edb-a775-02c0420b1b6a,DISK], DatanodeInfoWithStorage[127.0.0.1:39522,DS-7bd748b8-d91e-4a5b-bb65-45720c7d6855,DISK], DatanodeInfoWithStorage[127.0.0.1:36225,DS-ccc0516c-5bdc-430d-90f7-ce0f5218f089,DISK], DatanodeInfoWithStorage[127.0.0.1:43366,DS-6262b423-6d6f-4b5b-a573-69a57ea27732,DISK], DatanodeInfoWithStorage[127.0.0.1:41288,DS-bc8120e7-b931-4d79-b286-00cb37769048,DISK], DatanodeInfoWithStorage[127.0.0.1:45814,DS-ed9c738c-d9ee-4c8a-8509-936d35caa438,DISK], DatanodeInfoWithStorage[127.0.0.1:46122,DS-d8043536-61d6-4761-9881-931617aa0076,DISK], DatanodeInfoWithStorage[127.0.0.1:42224,DS-6f066e4d-0614-4384-a98b-3faf077727e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-367375586-172.17.0.7-1598138965201:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43865,DS-5912af24-ee4e-4edb-a775-02c0420b1b6a,DISK], DatanodeInfoWithStorage[127.0.0.1:39522,DS-7bd748b8-d91e-4a5b-bb65-45720c7d6855,DISK], DatanodeInfoWithStorage[127.0.0.1:36225,DS-ccc0516c-5bdc-430d-90f7-ce0f5218f089,DISK], DatanodeInfoWithStorage[127.0.0.1:43366,DS-6262b423-6d6f-4b5b-a573-69a57ea27732,DISK], DatanodeInfoWithStorage[127.0.0.1:41288,DS-bc8120e7-b931-4d79-b286-00cb37769048,DISK], DatanodeInfoWithStorage[127.0.0.1:45814,DS-ed9c738c-d9ee-4c8a-8509-936d35caa438,DISK], DatanodeInfoWithStorage[127.0.0.1:46122,DS-d8043536-61d6-4761-9881-931617aa0076,DISK], DatanodeInfoWithStorage[127.0.0.1:42224,DS-6f066e4d-0614-4384-a98b-3faf077727e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-268628049-172.17.0.7-1598139385301:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40203,DS-7b800e34-f21a-4467-98a2-855362805d96,DISK], DatanodeInfoWithStorage[127.0.0.1:40582,DS-beda73f1-23d7-4f77-a087-cc21a774baa5,DISK], DatanodeInfoWithStorage[127.0.0.1:32876,DS-221a2faa-e922-4490-8fbf-b0e1afa4dec7,DISK], DatanodeInfoWithStorage[127.0.0.1:40529,DS-3166edad-2e06-4afe-9dae-69e460f97ee1,DISK], DatanodeInfoWithStorage[127.0.0.1:40822,DS-2ef5ccda-f1f9-4744-ab98-7c4506c34ed6,DISK], DatanodeInfoWithStorage[127.0.0.1:46566,DS-bd062f47-b763-40b0-b9eb-af601e06ef4c,DISK], DatanodeInfoWithStorage[127.0.0.1:37141,DS-d27a6976-1604-4ebb-afc0-7e3eb09e5879,DISK], DatanodeInfoWithStorage[127.0.0.1:44399,DS-339dd2a7-eac0-4f7a-94f6-70f52a71ff40,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-268628049-172.17.0.7-1598139385301:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40203,DS-7b800e34-f21a-4467-98a2-855362805d96,DISK], DatanodeInfoWithStorage[127.0.0.1:40582,DS-beda73f1-23d7-4f77-a087-cc21a774baa5,DISK], DatanodeInfoWithStorage[127.0.0.1:32876,DS-221a2faa-e922-4490-8fbf-b0e1afa4dec7,DISK], DatanodeInfoWithStorage[127.0.0.1:40529,DS-3166edad-2e06-4afe-9dae-69e460f97ee1,DISK], DatanodeInfoWithStorage[127.0.0.1:40822,DS-2ef5ccda-f1f9-4744-ab98-7c4506c34ed6,DISK], DatanodeInfoWithStorage[127.0.0.1:46566,DS-bd062f47-b763-40b0-b9eb-af601e06ef4c,DISK], DatanodeInfoWithStorage[127.0.0.1:37141,DS-d27a6976-1604-4ebb-afc0-7e3eb09e5879,DISK], DatanodeInfoWithStorage[127.0.0.1:44399,DS-339dd2a7-eac0-4f7a-94f6-70f52a71ff40,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5185
