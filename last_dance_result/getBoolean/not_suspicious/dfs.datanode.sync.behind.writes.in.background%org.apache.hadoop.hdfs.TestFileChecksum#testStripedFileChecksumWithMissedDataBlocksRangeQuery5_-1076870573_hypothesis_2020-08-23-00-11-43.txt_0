reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-968149377-172.17.0.11-1598141668474:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45046,DS-22060184-aee5-4a48-95dc-0290df7790c1,DISK], DatanodeInfoWithStorage[127.0.0.1:38174,DS-ecbc7452-7457-4d85-80b6-f719b76e4155,DISK], DatanodeInfoWithStorage[127.0.0.1:38383,DS-4545d0ac-19c5-494f-a821-0b5ec83c0942,DISK], DatanodeInfoWithStorage[127.0.0.1:43640,DS-c1f30d66-731c-46c3-b8ca-c6e75245950a,DISK], DatanodeInfoWithStorage[127.0.0.1:36232,DS-615237d5-52a8-487b-baa5-d4b38f79e4b7,DISK], DatanodeInfoWithStorage[127.0.0.1:34172,DS-3ad44d0b-9b6d-4d35-b822-290bc5ef4e7d,DISK], DatanodeInfoWithStorage[127.0.0.1:38212,DS-4195a6d6-8dc3-4420-95ac-48f714eef2cf,DISK], DatanodeInfoWithStorage[127.0.0.1:38238,DS-ff68c347-a139-4deb-9773-f6710d5bff2f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-968149377-172.17.0.11-1598141668474:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45046,DS-22060184-aee5-4a48-95dc-0290df7790c1,DISK], DatanodeInfoWithStorage[127.0.0.1:38174,DS-ecbc7452-7457-4d85-80b6-f719b76e4155,DISK], DatanodeInfoWithStorage[127.0.0.1:38383,DS-4545d0ac-19c5-494f-a821-0b5ec83c0942,DISK], DatanodeInfoWithStorage[127.0.0.1:43640,DS-c1f30d66-731c-46c3-b8ca-c6e75245950a,DISK], DatanodeInfoWithStorage[127.0.0.1:36232,DS-615237d5-52a8-487b-baa5-d4b38f79e4b7,DISK], DatanodeInfoWithStorage[127.0.0.1:34172,DS-3ad44d0b-9b6d-4d35-b822-290bc5ef4e7d,DISK], DatanodeInfoWithStorage[127.0.0.1:38212,DS-4195a6d6-8dc3-4420-95ac-48f714eef2cf,DISK], DatanodeInfoWithStorage[127.0.0.1:38238,DS-ff68c347-a139-4deb-9773-f6710d5bff2f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-862676301-172.17.0.11-1598142436965:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35942,DS-c44d9c15-6645-4c83-9689-7d1cb283e125,DISK], DatanodeInfoWithStorage[127.0.0.1:34295,DS-5f624bc0-1faf-4c23-977c-cef36730a6cb,DISK], DatanodeInfoWithStorage[127.0.0.1:40479,DS-7be9d279-3526-415b-a455-cdb8bb424331,DISK], DatanodeInfoWithStorage[127.0.0.1:35510,DS-4a31cb51-043a-48b5-8cb9-a602980a71c1,DISK], DatanodeInfoWithStorage[127.0.0.1:34424,DS-c69da112-9aab-4dc7-90c2-67bd04d88097,DISK], DatanodeInfoWithStorage[127.0.0.1:34599,DS-32738a33-1535-4871-af2c-2c479f247f73,DISK], DatanodeInfoWithStorage[127.0.0.1:35696,DS-19aa51df-bb6c-4fad-8628-6747665ef241,DISK], DatanodeInfoWithStorage[127.0.0.1:45387,DS-8d2f620d-74d4-4438-a954-00bd70a8e7ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-862676301-172.17.0.11-1598142436965:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35942,DS-c44d9c15-6645-4c83-9689-7d1cb283e125,DISK], DatanodeInfoWithStorage[127.0.0.1:34295,DS-5f624bc0-1faf-4c23-977c-cef36730a6cb,DISK], DatanodeInfoWithStorage[127.0.0.1:40479,DS-7be9d279-3526-415b-a455-cdb8bb424331,DISK], DatanodeInfoWithStorage[127.0.0.1:35510,DS-4a31cb51-043a-48b5-8cb9-a602980a71c1,DISK], DatanodeInfoWithStorage[127.0.0.1:34424,DS-c69da112-9aab-4dc7-90c2-67bd04d88097,DISK], DatanodeInfoWithStorage[127.0.0.1:34599,DS-32738a33-1535-4871-af2c-2c479f247f73,DISK], DatanodeInfoWithStorage[127.0.0.1:35696,DS-19aa51df-bb6c-4fad-8628-6747665ef241,DISK], DatanodeInfoWithStorage[127.0.0.1:45387,DS-8d2f620d-74d4-4438-a954-00bd70a8e7ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-102916021-172.17.0.11-1598142552274:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37792,DS-867ab7ec-4718-4145-a9ec-45322340ac2d,DISK], DatanodeInfoWithStorage[127.0.0.1:42137,DS-9d8388ad-dc08-4e9c-b5e6-f9c9202899fc,DISK], DatanodeInfoWithStorage[127.0.0.1:44016,DS-578d5a6b-8638-4999-8435-37053fcc92d9,DISK], DatanodeInfoWithStorage[127.0.0.1:37227,DS-3f939b37-d522-4157-b67c-83e634fe3c18,DISK], DatanodeInfoWithStorage[127.0.0.1:33273,DS-acce55e7-f727-415a-950e-36be8d847f3f,DISK], DatanodeInfoWithStorage[127.0.0.1:38508,DS-234f35fe-2b49-4f5d-a83d-6a13791023ab,DISK], DatanodeInfoWithStorage[127.0.0.1:36418,DS-5c0bd226-a47c-4ba6-8092-678a859a43ba,DISK], DatanodeInfoWithStorage[127.0.0.1:38582,DS-db1510a0-cebb-4263-9a8e-7f3f7d222491,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-102916021-172.17.0.11-1598142552274:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37792,DS-867ab7ec-4718-4145-a9ec-45322340ac2d,DISK], DatanodeInfoWithStorage[127.0.0.1:42137,DS-9d8388ad-dc08-4e9c-b5e6-f9c9202899fc,DISK], DatanodeInfoWithStorage[127.0.0.1:44016,DS-578d5a6b-8638-4999-8435-37053fcc92d9,DISK], DatanodeInfoWithStorage[127.0.0.1:37227,DS-3f939b37-d522-4157-b67c-83e634fe3c18,DISK], DatanodeInfoWithStorage[127.0.0.1:33273,DS-acce55e7-f727-415a-950e-36be8d847f3f,DISK], DatanodeInfoWithStorage[127.0.0.1:38508,DS-234f35fe-2b49-4f5d-a83d-6a13791023ab,DISK], DatanodeInfoWithStorage[127.0.0.1:36418,DS-5c0bd226-a47c-4ba6-8092-678a859a43ba,DISK], DatanodeInfoWithStorage[127.0.0.1:38582,DS-db1510a0-cebb-4263-9a8e-7f3f7d222491,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1501247299-172.17.0.11-1598142705684:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38661,DS-90ae45e2-4b22-4497-a153-e78cad5b3fe1,DISK], DatanodeInfoWithStorage[127.0.0.1:36445,DS-a24043a7-13fa-4920-84db-4fd33c69b278,DISK], DatanodeInfoWithStorage[127.0.0.1:46620,DS-51e37024-5cd4-4829-9b79-280ab508aee4,DISK], DatanodeInfoWithStorage[127.0.0.1:37277,DS-abf7a812-3687-4a72-b2cd-923269a08849,DISK], DatanodeInfoWithStorage[127.0.0.1:35798,DS-906dca32-9b2a-469e-8bdb-8e2a3d7c812b,DISK], DatanodeInfoWithStorage[127.0.0.1:38271,DS-f9b34e02-a00c-4e3d-9e17-6b5f8d281354,DISK], DatanodeInfoWithStorage[127.0.0.1:32938,DS-7c8785d8-5707-4456-a84d-d29ec792ead4,DISK], DatanodeInfoWithStorage[127.0.0.1:43483,DS-90f994b1-c0c3-4588-9fd4-edf19c8a7b3a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1501247299-172.17.0.11-1598142705684:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38661,DS-90ae45e2-4b22-4497-a153-e78cad5b3fe1,DISK], DatanodeInfoWithStorage[127.0.0.1:36445,DS-a24043a7-13fa-4920-84db-4fd33c69b278,DISK], DatanodeInfoWithStorage[127.0.0.1:46620,DS-51e37024-5cd4-4829-9b79-280ab508aee4,DISK], DatanodeInfoWithStorage[127.0.0.1:37277,DS-abf7a812-3687-4a72-b2cd-923269a08849,DISK], DatanodeInfoWithStorage[127.0.0.1:35798,DS-906dca32-9b2a-469e-8bdb-8e2a3d7c812b,DISK], DatanodeInfoWithStorage[127.0.0.1:38271,DS-f9b34e02-a00c-4e3d-9e17-6b5f8d281354,DISK], DatanodeInfoWithStorage[127.0.0.1:32938,DS-7c8785d8-5707-4456-a84d-d29ec792ead4,DISK], DatanodeInfoWithStorage[127.0.0.1:43483,DS-90f994b1-c0c3-4588-9fd4-edf19c8a7b3a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1951006226-172.17.0.11-1598143112372:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39658,DS-6f463039-343c-4f5b-aaa9-ec8765fb2624,DISK], DatanodeInfoWithStorage[127.0.0.1:36575,DS-c02719d5-11dd-4bf9-b3d5-e0906aeaf7c1,DISK], DatanodeInfoWithStorage[127.0.0.1:34304,DS-c4ba49de-802a-4472-bf29-815541767520,DISK], DatanodeInfoWithStorage[127.0.0.1:39597,DS-c68ce33c-6c95-4232-8863-7264be9691ee,DISK], DatanodeInfoWithStorage[127.0.0.1:37232,DS-5e6008f5-e033-4cb0-806e-1b4ad601bdf9,DISK], DatanodeInfoWithStorage[127.0.0.1:42326,DS-ab19d77f-dcde-4571-a107-192d2573f062,DISK], DatanodeInfoWithStorage[127.0.0.1:44931,DS-c76a635c-8843-4771-b35d-1f60a52e9ced,DISK], DatanodeInfoWithStorage[127.0.0.1:33355,DS-7d6a0d2f-d8c4-4292-bdc6-40c40c3e022f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1951006226-172.17.0.11-1598143112372:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39658,DS-6f463039-343c-4f5b-aaa9-ec8765fb2624,DISK], DatanodeInfoWithStorage[127.0.0.1:36575,DS-c02719d5-11dd-4bf9-b3d5-e0906aeaf7c1,DISK], DatanodeInfoWithStorage[127.0.0.1:34304,DS-c4ba49de-802a-4472-bf29-815541767520,DISK], DatanodeInfoWithStorage[127.0.0.1:39597,DS-c68ce33c-6c95-4232-8863-7264be9691ee,DISK], DatanodeInfoWithStorage[127.0.0.1:37232,DS-5e6008f5-e033-4cb0-806e-1b4ad601bdf9,DISK], DatanodeInfoWithStorage[127.0.0.1:42326,DS-ab19d77f-dcde-4571-a107-192d2573f062,DISK], DatanodeInfoWithStorage[127.0.0.1:44931,DS-c76a635c-8843-4771-b35d-1f60a52e9ced,DISK], DatanodeInfoWithStorage[127.0.0.1:33355,DS-7d6a0d2f-d8c4-4292-bdc6-40c40c3e022f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1835819256-172.17.0.11-1598143298772:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45320,DS-81476d77-2cf5-42e1-9f97-41306f402cdd,DISK], DatanodeInfoWithStorage[127.0.0.1:35141,DS-6638ef87-88e9-4479-aff8-32bea302e496,DISK], DatanodeInfoWithStorage[127.0.0.1:36611,DS-0d1096d9-3142-4436-8986-389fe932a791,DISK], DatanodeInfoWithStorage[127.0.0.1:43342,DS-197082ae-60b7-433c-b8c7-fb16ea939e80,DISK], DatanodeInfoWithStorage[127.0.0.1:45590,DS-936dcc72-7dce-4b0c-af37-b5b361852706,DISK], DatanodeInfoWithStorage[127.0.0.1:35326,DS-1160d8db-754a-4992-8127-b6fd52c17e64,DISK], DatanodeInfoWithStorage[127.0.0.1:33793,DS-c6ef0e16-ea47-4cad-b974-9ac60d97f3c5,DISK], DatanodeInfoWithStorage[127.0.0.1:38921,DS-cc0bc001-9a3d-4129-afee-241248a1f51e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1835819256-172.17.0.11-1598143298772:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45320,DS-81476d77-2cf5-42e1-9f97-41306f402cdd,DISK], DatanodeInfoWithStorage[127.0.0.1:35141,DS-6638ef87-88e9-4479-aff8-32bea302e496,DISK], DatanodeInfoWithStorage[127.0.0.1:36611,DS-0d1096d9-3142-4436-8986-389fe932a791,DISK], DatanodeInfoWithStorage[127.0.0.1:43342,DS-197082ae-60b7-433c-b8c7-fb16ea939e80,DISK], DatanodeInfoWithStorage[127.0.0.1:45590,DS-936dcc72-7dce-4b0c-af37-b5b361852706,DISK], DatanodeInfoWithStorage[127.0.0.1:35326,DS-1160d8db-754a-4992-8127-b6fd52c17e64,DISK], DatanodeInfoWithStorage[127.0.0.1:33793,DS-c6ef0e16-ea47-4cad-b974-9ac60d97f3c5,DISK], DatanodeInfoWithStorage[127.0.0.1:38921,DS-cc0bc001-9a3d-4129-afee-241248a1f51e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1027305963-172.17.0.11-1598143561588:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34853,DS-d225e778-4258-4dd3-a359-452baaef3616,DISK], DatanodeInfoWithStorage[127.0.0.1:35342,DS-02d4edfa-195a-4820-bad4-7aac0e272746,DISK], DatanodeInfoWithStorage[127.0.0.1:45461,DS-dd3e9b7f-6944-462f-87e0-b64a33f9ecf8,DISK], DatanodeInfoWithStorage[127.0.0.1:42319,DS-6d5c6873-6f5d-43c4-80d1-933c5ebb2359,DISK], DatanodeInfoWithStorage[127.0.0.1:32858,DS-a964e355-5308-4b81-81a5-083189e40bf2,DISK], DatanodeInfoWithStorage[127.0.0.1:34572,DS-134301d2-c6c0-42e6-8549-c1dee44f60d1,DISK], DatanodeInfoWithStorage[127.0.0.1:33460,DS-902dba29-787a-4041-8639-ab4066a5daf5,DISK], DatanodeInfoWithStorage[127.0.0.1:42586,DS-e95630f4-9d47-4a56-8d24-ae2fafb4959d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1027305963-172.17.0.11-1598143561588:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34853,DS-d225e778-4258-4dd3-a359-452baaef3616,DISK], DatanodeInfoWithStorage[127.0.0.1:35342,DS-02d4edfa-195a-4820-bad4-7aac0e272746,DISK], DatanodeInfoWithStorage[127.0.0.1:45461,DS-dd3e9b7f-6944-462f-87e0-b64a33f9ecf8,DISK], DatanodeInfoWithStorage[127.0.0.1:42319,DS-6d5c6873-6f5d-43c4-80d1-933c5ebb2359,DISK], DatanodeInfoWithStorage[127.0.0.1:32858,DS-a964e355-5308-4b81-81a5-083189e40bf2,DISK], DatanodeInfoWithStorage[127.0.0.1:34572,DS-134301d2-c6c0-42e6-8549-c1dee44f60d1,DISK], DatanodeInfoWithStorage[127.0.0.1:33460,DS-902dba29-787a-4041-8639-ab4066a5daf5,DISK], DatanodeInfoWithStorage[127.0.0.1:42586,DS-e95630f4-9d47-4a56-8d24-ae2fafb4959d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1704467083-172.17.0.11-1598143633694:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43573,DS-dfbb3767-e821-4a93-b106-204fcb9bed1e,DISK], DatanodeInfoWithStorage[127.0.0.1:43111,DS-110c1794-bbbc-4fe1-ac52-15ed9f1afde1,DISK], DatanodeInfoWithStorage[127.0.0.1:39834,DS-a89b2ad6-064f-4953-ae0b-13d1ae51fcaf,DISK], DatanodeInfoWithStorage[127.0.0.1:39873,DS-5e4d18c1-116f-4089-8822-c69bf9c78b9f,DISK], DatanodeInfoWithStorage[127.0.0.1:45138,DS-90347888-26c7-43a9-8c83-b98395b6b4ae,DISK], DatanodeInfoWithStorage[127.0.0.1:34681,DS-5bcce315-bdad-4e4d-8de0-13b69fcd4c66,DISK], DatanodeInfoWithStorage[127.0.0.1:33260,DS-ae7c26bd-99d0-43f4-861a-9931fb98da8e,DISK], DatanodeInfoWithStorage[127.0.0.1:36356,DS-289bf367-54f4-4ab5-982a-e0786f5f5865,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1704467083-172.17.0.11-1598143633694:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43573,DS-dfbb3767-e821-4a93-b106-204fcb9bed1e,DISK], DatanodeInfoWithStorage[127.0.0.1:43111,DS-110c1794-bbbc-4fe1-ac52-15ed9f1afde1,DISK], DatanodeInfoWithStorage[127.0.0.1:39834,DS-a89b2ad6-064f-4953-ae0b-13d1ae51fcaf,DISK], DatanodeInfoWithStorage[127.0.0.1:39873,DS-5e4d18c1-116f-4089-8822-c69bf9c78b9f,DISK], DatanodeInfoWithStorage[127.0.0.1:45138,DS-90347888-26c7-43a9-8c83-b98395b6b4ae,DISK], DatanodeInfoWithStorage[127.0.0.1:34681,DS-5bcce315-bdad-4e4d-8de0-13b69fcd4c66,DISK], DatanodeInfoWithStorage[127.0.0.1:33260,DS-ae7c26bd-99d0-43f4-861a-9931fb98da8e,DISK], DatanodeInfoWithStorage[127.0.0.1:36356,DS-289bf367-54f4-4ab5-982a-e0786f5f5865,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-54124085-172.17.0.11-1598143919687:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35399,DS-c66cb6af-f6d0-411b-94a4-567a89a1e1a3,DISK], DatanodeInfoWithStorage[127.0.0.1:38914,DS-c3664e5f-b4a2-4c7b-9add-cba7447face1,DISK], DatanodeInfoWithStorage[127.0.0.1:36460,DS-3742a37f-beae-4578-b4c0-354c9551dd33,DISK], DatanodeInfoWithStorage[127.0.0.1:33241,DS-bee1f5a5-2b42-4379-bf37-d21c3f6a2b78,DISK], DatanodeInfoWithStorage[127.0.0.1:33683,DS-eb64fa02-6d42-42ef-90ba-f281885dc69e,DISK], DatanodeInfoWithStorage[127.0.0.1:37982,DS-485ad672-5637-4100-9706-16fe2affb0e6,DISK], DatanodeInfoWithStorage[127.0.0.1:36757,DS-a1765d7f-e3b0-4d2c-a8f6-54ef9ca64b8f,DISK], DatanodeInfoWithStorage[127.0.0.1:39918,DS-adf53884-97f1-4701-89eb-e794e8789521,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-54124085-172.17.0.11-1598143919687:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35399,DS-c66cb6af-f6d0-411b-94a4-567a89a1e1a3,DISK], DatanodeInfoWithStorage[127.0.0.1:38914,DS-c3664e5f-b4a2-4c7b-9add-cba7447face1,DISK], DatanodeInfoWithStorage[127.0.0.1:36460,DS-3742a37f-beae-4578-b4c0-354c9551dd33,DISK], DatanodeInfoWithStorage[127.0.0.1:33241,DS-bee1f5a5-2b42-4379-bf37-d21c3f6a2b78,DISK], DatanodeInfoWithStorage[127.0.0.1:33683,DS-eb64fa02-6d42-42ef-90ba-f281885dc69e,DISK], DatanodeInfoWithStorage[127.0.0.1:37982,DS-485ad672-5637-4100-9706-16fe2affb0e6,DISK], DatanodeInfoWithStorage[127.0.0.1:36757,DS-a1765d7f-e3b0-4d2c-a8f6-54ef9ca64b8f,DISK], DatanodeInfoWithStorage[127.0.0.1:39918,DS-adf53884-97f1-4701-89eb-e794e8789521,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-4095784-172.17.0.11-1598144135206:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37395,DS-f1afbf30-d99f-4935-8986-359d1590b0f1,DISK], DatanodeInfoWithStorage[127.0.0.1:33560,DS-9ffb00cf-87cf-497b-b3cc-567ef585f038,DISK], DatanodeInfoWithStorage[127.0.0.1:37846,DS-50b9ae07-cc50-4e51-a9e7-a66363d790a1,DISK], DatanodeInfoWithStorage[127.0.0.1:35582,DS-3ab33ed0-1635-4d20-b5dd-1322f27601ee,DISK], DatanodeInfoWithStorage[127.0.0.1:33405,DS-274ae405-6bfd-4618-b245-ba6fa066bb3c,DISK], DatanodeInfoWithStorage[127.0.0.1:44837,DS-0bdb9a0c-23c6-41f5-a916-10c6ca46a025,DISK], DatanodeInfoWithStorage[127.0.0.1:36084,DS-372fb7bb-ddd5-4daa-a9bd-de65843c4204,DISK], DatanodeInfoWithStorage[127.0.0.1:43842,DS-7bb59d55-fef7-4622-9931-e286d6d92f4c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-4095784-172.17.0.11-1598144135206:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37395,DS-f1afbf30-d99f-4935-8986-359d1590b0f1,DISK], DatanodeInfoWithStorage[127.0.0.1:33560,DS-9ffb00cf-87cf-497b-b3cc-567ef585f038,DISK], DatanodeInfoWithStorage[127.0.0.1:37846,DS-50b9ae07-cc50-4e51-a9e7-a66363d790a1,DISK], DatanodeInfoWithStorage[127.0.0.1:35582,DS-3ab33ed0-1635-4d20-b5dd-1322f27601ee,DISK], DatanodeInfoWithStorage[127.0.0.1:33405,DS-274ae405-6bfd-4618-b245-ba6fa066bb3c,DISK], DatanodeInfoWithStorage[127.0.0.1:44837,DS-0bdb9a0c-23c6-41f5-a916-10c6ca46a025,DISK], DatanodeInfoWithStorage[127.0.0.1:36084,DS-372fb7bb-ddd5-4daa-a9bd-de65843c4204,DISK], DatanodeInfoWithStorage[127.0.0.1:43842,DS-7bb59d55-fef7-4622-9931-e286d6d92f4c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-459197768-172.17.0.11-1598144462188:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45306,DS-4c5d7342-3121-4263-8bb7-fda8b12b2f24,DISK], DatanodeInfoWithStorage[127.0.0.1:43758,DS-ede58b8d-2daf-4e80-8fbc-c09ff0d35047,DISK], DatanodeInfoWithStorage[127.0.0.1:35172,DS-63faf643-4cc8-4cbf-b9a4-3eb4eed39ead,DISK], DatanodeInfoWithStorage[127.0.0.1:43564,DS-15817b24-ee10-4d78-9f2b-95f93933a55f,DISK], DatanodeInfoWithStorage[127.0.0.1:45813,DS-2c56aaf4-cdf5-4427-a045-466ced5f1188,DISK], DatanodeInfoWithStorage[127.0.0.1:42436,DS-e07abd14-bb63-4a62-b481-07fa97c26be7,DISK], DatanodeInfoWithStorage[127.0.0.1:34259,DS-b67226f0-6ea3-40ef-b1a1-c47f28f21b1b,DISK], DatanodeInfoWithStorage[127.0.0.1:42489,DS-94b1cf16-b789-47ba-b77f-9f3a32711f02,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-459197768-172.17.0.11-1598144462188:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45306,DS-4c5d7342-3121-4263-8bb7-fda8b12b2f24,DISK], DatanodeInfoWithStorage[127.0.0.1:43758,DS-ede58b8d-2daf-4e80-8fbc-c09ff0d35047,DISK], DatanodeInfoWithStorage[127.0.0.1:35172,DS-63faf643-4cc8-4cbf-b9a4-3eb4eed39ead,DISK], DatanodeInfoWithStorage[127.0.0.1:43564,DS-15817b24-ee10-4d78-9f2b-95f93933a55f,DISK], DatanodeInfoWithStorage[127.0.0.1:45813,DS-2c56aaf4-cdf5-4427-a045-466ced5f1188,DISK], DatanodeInfoWithStorage[127.0.0.1:42436,DS-e07abd14-bb63-4a62-b481-07fa97c26be7,DISK], DatanodeInfoWithStorage[127.0.0.1:34259,DS-b67226f0-6ea3-40ef-b1a1-c47f28f21b1b,DISK], DatanodeInfoWithStorage[127.0.0.1:42489,DS-94b1cf16-b789-47ba-b77f-9f3a32711f02,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1237957075-172.17.0.11-1598144534464:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35590,DS-6df651bc-0938-4309-98ec-7f4015af1a5b,DISK], DatanodeInfoWithStorage[127.0.0.1:43227,DS-57b7fef6-7835-4e2e-8c7b-3c5aeb81f468,DISK], DatanodeInfoWithStorage[127.0.0.1:37627,DS-3e10d995-f956-49a6-b2dc-0065732c5801,DISK], DatanodeInfoWithStorage[127.0.0.1:40085,DS-297ff0a8-f35a-45a4-8e10-d6a40008a435,DISK], DatanodeInfoWithStorage[127.0.0.1:46532,DS-c672fc41-f3e0-4bfe-8fe5-f2d546da9a7a,DISK], DatanodeInfoWithStorage[127.0.0.1:43965,DS-258e4d31-6959-41ad-9a42-f5dd20d936cc,DISK], DatanodeInfoWithStorage[127.0.0.1:40514,DS-a288543b-e80f-4002-9e35-e84169752f7c,DISK], DatanodeInfoWithStorage[127.0.0.1:44062,DS-45b8fe08-3435-43c0-97c4-8560f2c11e23,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1237957075-172.17.0.11-1598144534464:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35590,DS-6df651bc-0938-4309-98ec-7f4015af1a5b,DISK], DatanodeInfoWithStorage[127.0.0.1:43227,DS-57b7fef6-7835-4e2e-8c7b-3c5aeb81f468,DISK], DatanodeInfoWithStorage[127.0.0.1:37627,DS-3e10d995-f956-49a6-b2dc-0065732c5801,DISK], DatanodeInfoWithStorage[127.0.0.1:40085,DS-297ff0a8-f35a-45a4-8e10-d6a40008a435,DISK], DatanodeInfoWithStorage[127.0.0.1:46532,DS-c672fc41-f3e0-4bfe-8fe5-f2d546da9a7a,DISK], DatanodeInfoWithStorage[127.0.0.1:43965,DS-258e4d31-6959-41ad-9a42-f5dd20d936cc,DISK], DatanodeInfoWithStorage[127.0.0.1:40514,DS-a288543b-e80f-4002-9e35-e84169752f7c,DISK], DatanodeInfoWithStorage[127.0.0.1:44062,DS-45b8fe08-3435-43c0-97c4-8560f2c11e23,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-519999901-172.17.0.11-1598144741066:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41621,DS-ba05eea6-8eff-4d6b-bc01-ef82b7e566a7,DISK], DatanodeInfoWithStorage[127.0.0.1:43008,DS-64bba820-4717-40ea-a034-1d17a3d10621,DISK], DatanodeInfoWithStorage[127.0.0.1:40154,DS-f5680409-575f-4df3-847a-80dbfc6f92b2,DISK], DatanodeInfoWithStorage[127.0.0.1:41616,DS-2aba2f72-6150-4e20-8b10-22f5d1de6f89,DISK], DatanodeInfoWithStorage[127.0.0.1:43884,DS-f23c667b-f24e-460a-8fba-aff75765b844,DISK], DatanodeInfoWithStorage[127.0.0.1:43722,DS-2d5e6de0-0199-496a-a844-3c8b5dcf7837,DISK], DatanodeInfoWithStorage[127.0.0.1:37707,DS-3de167ac-41bc-4885-bf0f-ff48ca8a2a32,DISK], DatanodeInfoWithStorage[127.0.0.1:35908,DS-2fe2f18f-0b34-4eee-98b7-ffb8d3475e16,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-519999901-172.17.0.11-1598144741066:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41621,DS-ba05eea6-8eff-4d6b-bc01-ef82b7e566a7,DISK], DatanodeInfoWithStorage[127.0.0.1:43008,DS-64bba820-4717-40ea-a034-1d17a3d10621,DISK], DatanodeInfoWithStorage[127.0.0.1:40154,DS-f5680409-575f-4df3-847a-80dbfc6f92b2,DISK], DatanodeInfoWithStorage[127.0.0.1:41616,DS-2aba2f72-6150-4e20-8b10-22f5d1de6f89,DISK], DatanodeInfoWithStorage[127.0.0.1:43884,DS-f23c667b-f24e-460a-8fba-aff75765b844,DISK], DatanodeInfoWithStorage[127.0.0.1:43722,DS-2d5e6de0-0199-496a-a844-3c8b5dcf7837,DISK], DatanodeInfoWithStorage[127.0.0.1:37707,DS-3de167ac-41bc-4885-bf0f-ff48ca8a2a32,DISK], DatanodeInfoWithStorage[127.0.0.1:35908,DS-2fe2f18f-0b34-4eee-98b7-ffb8d3475e16,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-360498237-172.17.0.11-1598144780832:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34717,DS-448aa256-5239-4f7b-b17f-9024e08027b3,DISK], DatanodeInfoWithStorage[127.0.0.1:33684,DS-1aa908fe-4bfa-48c1-acf8-80521b8ff820,DISK], DatanodeInfoWithStorage[127.0.0.1:35416,DS-72a9641b-da50-4fe8-87b3-01ed507220d9,DISK], DatanodeInfoWithStorage[127.0.0.1:36283,DS-9e79a803-5bf4-4466-a818-cbc4cf8483e5,DISK], DatanodeInfoWithStorage[127.0.0.1:34409,DS-c76676b6-d00d-4c07-bb15-2885925875c4,DISK], DatanodeInfoWithStorage[127.0.0.1:35627,DS-4db25c8d-078a-4bc0-93ae-1ec43ce607f7,DISK], DatanodeInfoWithStorage[127.0.0.1:34537,DS-fa83e93e-cbb9-4697-80a5-dcac905f01bf,DISK], DatanodeInfoWithStorage[127.0.0.1:44447,DS-e97492b0-df47-4ea8-b088-997a458c35f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-360498237-172.17.0.11-1598144780832:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34717,DS-448aa256-5239-4f7b-b17f-9024e08027b3,DISK], DatanodeInfoWithStorage[127.0.0.1:33684,DS-1aa908fe-4bfa-48c1-acf8-80521b8ff820,DISK], DatanodeInfoWithStorage[127.0.0.1:35416,DS-72a9641b-da50-4fe8-87b3-01ed507220d9,DISK], DatanodeInfoWithStorage[127.0.0.1:36283,DS-9e79a803-5bf4-4466-a818-cbc4cf8483e5,DISK], DatanodeInfoWithStorage[127.0.0.1:34409,DS-c76676b6-d00d-4c07-bb15-2885925875c4,DISK], DatanodeInfoWithStorage[127.0.0.1:35627,DS-4db25c8d-078a-4bc0-93ae-1ec43ce607f7,DISK], DatanodeInfoWithStorage[127.0.0.1:34537,DS-fa83e93e-cbb9-4697-80a5-dcac905f01bf,DISK], DatanodeInfoWithStorage[127.0.0.1:44447,DS-e97492b0-df47-4ea8-b088-997a458c35f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1045895924-172.17.0.11-1598144966131:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44739,DS-fd9748cc-c604-4d77-bf9a-eb271c8716c1,DISK], DatanodeInfoWithStorage[127.0.0.1:35241,DS-814eba08-71aa-42bb-8c90-88ef59e8da7e,DISK], DatanodeInfoWithStorage[127.0.0.1:43691,DS-1979a81b-14c3-480b-809e-f26860778d48,DISK], DatanodeInfoWithStorage[127.0.0.1:37435,DS-f87c9141-3308-4712-a5ff-592c73baa228,DISK], DatanodeInfoWithStorage[127.0.0.1:38481,DS-bc4a178b-19c4-4d7f-b82a-bbe5be189783,DISK], DatanodeInfoWithStorage[127.0.0.1:41298,DS-79f3b108-88a1-4797-aaab-a939ae4199f6,DISK], DatanodeInfoWithStorage[127.0.0.1:44198,DS-15d239c7-1401-4c9a-8488-591daa283cbd,DISK], DatanodeInfoWithStorage[127.0.0.1:36029,DS-e0981aa6-0089-4df9-93c4-1d723bdbe084,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1045895924-172.17.0.11-1598144966131:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44739,DS-fd9748cc-c604-4d77-bf9a-eb271c8716c1,DISK], DatanodeInfoWithStorage[127.0.0.1:35241,DS-814eba08-71aa-42bb-8c90-88ef59e8da7e,DISK], DatanodeInfoWithStorage[127.0.0.1:43691,DS-1979a81b-14c3-480b-809e-f26860778d48,DISK], DatanodeInfoWithStorage[127.0.0.1:37435,DS-f87c9141-3308-4712-a5ff-592c73baa228,DISK], DatanodeInfoWithStorage[127.0.0.1:38481,DS-bc4a178b-19c4-4d7f-b82a-bbe5be189783,DISK], DatanodeInfoWithStorage[127.0.0.1:41298,DS-79f3b108-88a1-4797-aaab-a939ae4199f6,DISK], DatanodeInfoWithStorage[127.0.0.1:44198,DS-15d239c7-1401-4c9a-8488-591daa283cbd,DISK], DatanodeInfoWithStorage[127.0.0.1:36029,DS-e0981aa6-0089-4df9-93c4-1d723bdbe084,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1711867488-172.17.0.11-1598145035714:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42593,DS-f5f7a1a9-6a7f-4b7b-9ff2-6ff90c9bce04,DISK], DatanodeInfoWithStorage[127.0.0.1:39898,DS-5b8fb1b6-21d2-44b3-b8cd-1ad94a877696,DISK], DatanodeInfoWithStorage[127.0.0.1:43337,DS-8993a0a8-2453-4cbe-a628-2f82bd821611,DISK], DatanodeInfoWithStorage[127.0.0.1:42021,DS-5e5ec93e-ffcf-4d5c-8232-61a956532460,DISK], DatanodeInfoWithStorage[127.0.0.1:36129,DS-35ea7236-9d8a-4899-8d74-2088007fe211,DISK], DatanodeInfoWithStorage[127.0.0.1:35032,DS-c38240ac-502e-4ac1-b72e-54e9b24b476a,DISK], DatanodeInfoWithStorage[127.0.0.1:37737,DS-68c8fefe-e955-431a-be54-dd6d16f47f04,DISK], DatanodeInfoWithStorage[127.0.0.1:33363,DS-3e41eb1d-57df-4811-9251-4854f39f2e7e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1711867488-172.17.0.11-1598145035714:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42593,DS-f5f7a1a9-6a7f-4b7b-9ff2-6ff90c9bce04,DISK], DatanodeInfoWithStorage[127.0.0.1:39898,DS-5b8fb1b6-21d2-44b3-b8cd-1ad94a877696,DISK], DatanodeInfoWithStorage[127.0.0.1:43337,DS-8993a0a8-2453-4cbe-a628-2f82bd821611,DISK], DatanodeInfoWithStorage[127.0.0.1:42021,DS-5e5ec93e-ffcf-4d5c-8232-61a956532460,DISK], DatanodeInfoWithStorage[127.0.0.1:36129,DS-35ea7236-9d8a-4899-8d74-2088007fe211,DISK], DatanodeInfoWithStorage[127.0.0.1:35032,DS-c38240ac-502e-4ac1-b72e-54e9b24b476a,DISK], DatanodeInfoWithStorage[127.0.0.1:37737,DS-68c8fefe-e955-431a-be54-dd6d16f47f04,DISK], DatanodeInfoWithStorage[127.0.0.1:33363,DS-3e41eb1d-57df-4811-9251-4854f39f2e7e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1851690421-172.17.0.11-1598145070052:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41349,DS-26c44a6f-a312-44c8-8cda-be050df82e92,DISK], DatanodeInfoWithStorage[127.0.0.1:37978,DS-465c560a-d656-4ab9-b361-8cbae4cc1031,DISK], DatanodeInfoWithStorage[127.0.0.1:35343,DS-0818d7d5-be2a-4c75-aa76-0a02e29b8b2c,DISK], DatanodeInfoWithStorage[127.0.0.1:42583,DS-082b3943-c9a4-426d-9d9b-19865ffda4d5,DISK], DatanodeInfoWithStorage[127.0.0.1:38092,DS-379eafba-4157-47f1-88de-f4fd858ecbd0,DISK], DatanodeInfoWithStorage[127.0.0.1:36979,DS-0673082f-c333-40b4-81bf-c334f7f1fa68,DISK], DatanodeInfoWithStorage[127.0.0.1:44425,DS-ef0fa60b-e338-4e61-9fb7-6afeec0dbf9d,DISK], DatanodeInfoWithStorage[127.0.0.1:45689,DS-f5c096d8-9f7b-44ff-924e-5b7b619b6b00,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1851690421-172.17.0.11-1598145070052:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41349,DS-26c44a6f-a312-44c8-8cda-be050df82e92,DISK], DatanodeInfoWithStorage[127.0.0.1:37978,DS-465c560a-d656-4ab9-b361-8cbae4cc1031,DISK], DatanodeInfoWithStorage[127.0.0.1:35343,DS-0818d7d5-be2a-4c75-aa76-0a02e29b8b2c,DISK], DatanodeInfoWithStorage[127.0.0.1:42583,DS-082b3943-c9a4-426d-9d9b-19865ffda4d5,DISK], DatanodeInfoWithStorage[127.0.0.1:38092,DS-379eafba-4157-47f1-88de-f4fd858ecbd0,DISK], DatanodeInfoWithStorage[127.0.0.1:36979,DS-0673082f-c333-40b4-81bf-c334f7f1fa68,DISK], DatanodeInfoWithStorage[127.0.0.1:44425,DS-ef0fa60b-e338-4e61-9fb7-6afeec0dbf9d,DISK], DatanodeInfoWithStorage[127.0.0.1:45689,DS-f5c096d8-9f7b-44ff-924e-5b7b619b6b00,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-929748580-172.17.0.11-1598146242833:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41461,DS-4dc7b5bf-ce28-4630-a188-fff7bac54b59,DISK], DatanodeInfoWithStorage[127.0.0.1:46439,DS-292b47b7-025e-4317-b821-941c269205ef,DISK], DatanodeInfoWithStorage[127.0.0.1:38952,DS-478d76ad-e7ac-490b-ba76-9bb6834df49c,DISK], DatanodeInfoWithStorage[127.0.0.1:39478,DS-2c563cd6-6351-451e-aa8a-eca627b934eb,DISK], DatanodeInfoWithStorage[127.0.0.1:44802,DS-d7460653-be58-471f-99db-d9fec4953532,DISK], DatanodeInfoWithStorage[127.0.0.1:42258,DS-fb853923-e2cf-4512-a8b9-46aa71c2d8d1,DISK], DatanodeInfoWithStorage[127.0.0.1:45111,DS-31391743-53df-433f-b784-ec28ed32f5c6,DISK], DatanodeInfoWithStorage[127.0.0.1:40055,DS-12d0cde1-e9a6-4b01-8ae0-d5e2982c1f13,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-929748580-172.17.0.11-1598146242833:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41461,DS-4dc7b5bf-ce28-4630-a188-fff7bac54b59,DISK], DatanodeInfoWithStorage[127.0.0.1:46439,DS-292b47b7-025e-4317-b821-941c269205ef,DISK], DatanodeInfoWithStorage[127.0.0.1:38952,DS-478d76ad-e7ac-490b-ba76-9bb6834df49c,DISK], DatanodeInfoWithStorage[127.0.0.1:39478,DS-2c563cd6-6351-451e-aa8a-eca627b934eb,DISK], DatanodeInfoWithStorage[127.0.0.1:44802,DS-d7460653-be58-471f-99db-d9fec4953532,DISK], DatanodeInfoWithStorage[127.0.0.1:42258,DS-fb853923-e2cf-4512-a8b9-46aa71c2d8d1,DISK], DatanodeInfoWithStorage[127.0.0.1:45111,DS-31391743-53df-433f-b784-ec28ed32f5c6,DISK], DatanodeInfoWithStorage[127.0.0.1:40055,DS-12d0cde1-e9a6-4b01-8ae0-d5e2982c1f13,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1476500662-172.17.0.11-1598146575207:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44202,DS-3500d059-1797-49af-806e-2e8955890d56,DISK], DatanodeInfoWithStorage[127.0.0.1:33480,DS-5e5f7dfd-9f89-4615-8139-5ca885c149b8,DISK], DatanodeInfoWithStorage[127.0.0.1:44472,DS-7d48344f-7749-4773-8a9d-468cfbcb4371,DISK], DatanodeInfoWithStorage[127.0.0.1:36687,DS-b80f955d-2710-4d75-8feb-174d359dbd32,DISK], DatanodeInfoWithStorage[127.0.0.1:39406,DS-2fe644c3-2f0a-4353-b3db-66c92a6dc312,DISK], DatanodeInfoWithStorage[127.0.0.1:40359,DS-5a96da2d-6820-4032-a67f-ea3ab0bc2c67,DISK], DatanodeInfoWithStorage[127.0.0.1:44969,DS-ddfd1a17-518b-4ad3-8e26-c7055abaa92e,DISK], DatanodeInfoWithStorage[127.0.0.1:35239,DS-9b6acd91-a237-48b7-97de-079c358a7672,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1476500662-172.17.0.11-1598146575207:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44202,DS-3500d059-1797-49af-806e-2e8955890d56,DISK], DatanodeInfoWithStorage[127.0.0.1:33480,DS-5e5f7dfd-9f89-4615-8139-5ca885c149b8,DISK], DatanodeInfoWithStorage[127.0.0.1:44472,DS-7d48344f-7749-4773-8a9d-468cfbcb4371,DISK], DatanodeInfoWithStorage[127.0.0.1:36687,DS-b80f955d-2710-4d75-8feb-174d359dbd32,DISK], DatanodeInfoWithStorage[127.0.0.1:39406,DS-2fe644c3-2f0a-4353-b3db-66c92a6dc312,DISK], DatanodeInfoWithStorage[127.0.0.1:40359,DS-5a96da2d-6820-4032-a67f-ea3ab0bc2c67,DISK], DatanodeInfoWithStorage[127.0.0.1:44969,DS-ddfd1a17-518b-4ad3-8e26-c7055abaa92e,DISK], DatanodeInfoWithStorage[127.0.0.1:35239,DS-9b6acd91-a237-48b7-97de-079c358a7672,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-381996045-172.17.0.11-1598146835591:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45049,DS-c70f519e-d7ad-4545-9db4-6aba6e56a685,DISK], DatanodeInfoWithStorage[127.0.0.1:40864,DS-b04f838c-3046-4326-9b14-15b9f28ef19f,DISK], DatanodeInfoWithStorage[127.0.0.1:35758,DS-2ec7ecc4-aff8-4086-a211-b1e067a6cb11,DISK], DatanodeInfoWithStorage[127.0.0.1:32904,DS-2d551660-7d0f-4edc-ab1a-633defc21a50,DISK], DatanodeInfoWithStorage[127.0.0.1:33033,DS-74fffed1-35f8-42c7-9bd7-3913e5bd9522,DISK], DatanodeInfoWithStorage[127.0.0.1:46063,DS-398778d2-ca9b-49d6-bfda-53b7cdb53b0f,DISK], DatanodeInfoWithStorage[127.0.0.1:38188,DS-aa781050-8ad3-4567-b6cc-a92ab2f0f5c6,DISK], DatanodeInfoWithStorage[127.0.0.1:36544,DS-67cb161a-4708-4072-9e20-d049a3d00280,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-381996045-172.17.0.11-1598146835591:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45049,DS-c70f519e-d7ad-4545-9db4-6aba6e56a685,DISK], DatanodeInfoWithStorage[127.0.0.1:40864,DS-b04f838c-3046-4326-9b14-15b9f28ef19f,DISK], DatanodeInfoWithStorage[127.0.0.1:35758,DS-2ec7ecc4-aff8-4086-a211-b1e067a6cb11,DISK], DatanodeInfoWithStorage[127.0.0.1:32904,DS-2d551660-7d0f-4edc-ab1a-633defc21a50,DISK], DatanodeInfoWithStorage[127.0.0.1:33033,DS-74fffed1-35f8-42c7-9bd7-3913e5bd9522,DISK], DatanodeInfoWithStorage[127.0.0.1:46063,DS-398778d2-ca9b-49d6-bfda-53b7cdb53b0f,DISK], DatanodeInfoWithStorage[127.0.0.1:38188,DS-aa781050-8ad3-4567-b6cc-a92ab2f0f5c6,DISK], DatanodeInfoWithStorage[127.0.0.1:36544,DS-67cb161a-4708-4072-9e20-d049a3d00280,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 5427
