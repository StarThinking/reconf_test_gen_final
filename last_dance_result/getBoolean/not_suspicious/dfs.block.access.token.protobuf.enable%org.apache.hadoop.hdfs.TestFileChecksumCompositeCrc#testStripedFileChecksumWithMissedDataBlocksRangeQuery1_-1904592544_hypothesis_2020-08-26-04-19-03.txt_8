reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-585980332-172.17.0.13-1598416069257:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39260,DS-09ee2cb6-0d80-43cd-ab11-ebe88ca750f5,DISK], DatanodeInfoWithStorage[127.0.0.1:40036,DS-51b7ac19-2886-46b2-b0c5-9a2ffc86ef05,DISK], DatanodeInfoWithStorage[127.0.0.1:40043,DS-e77e9c31-1110-4431-a229-1bedd2e3fc2e,DISK], DatanodeInfoWithStorage[127.0.0.1:36059,DS-7e40028b-e72d-4820-8791-a4e5ac03e5fd,DISK], DatanodeInfoWithStorage[127.0.0.1:45980,DS-5628933e-832f-4584-8af4-509b83d816e3,DISK], DatanodeInfoWithStorage[127.0.0.1:44083,DS-125331d7-06a1-42bc-a0f5-6c5b9b37e05b,DISK], DatanodeInfoWithStorage[127.0.0.1:35549,DS-0f5cf4f3-fb96-40a0-807d-45d1e320791b,DISK], DatanodeInfoWithStorage[127.0.0.1:42024,DS-3fa3a9a5-c1f5-45f5-b0ce-3c46c66c2c99,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-585980332-172.17.0.13-1598416069257:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39260,DS-09ee2cb6-0d80-43cd-ab11-ebe88ca750f5,DISK], DatanodeInfoWithStorage[127.0.0.1:40036,DS-51b7ac19-2886-46b2-b0c5-9a2ffc86ef05,DISK], DatanodeInfoWithStorage[127.0.0.1:40043,DS-e77e9c31-1110-4431-a229-1bedd2e3fc2e,DISK], DatanodeInfoWithStorage[127.0.0.1:36059,DS-7e40028b-e72d-4820-8791-a4e5ac03e5fd,DISK], DatanodeInfoWithStorage[127.0.0.1:45980,DS-5628933e-832f-4584-8af4-509b83d816e3,DISK], DatanodeInfoWithStorage[127.0.0.1:44083,DS-125331d7-06a1-42bc-a0f5-6c5b9b37e05b,DISK], DatanodeInfoWithStorage[127.0.0.1:35549,DS-0f5cf4f3-fb96-40a0-807d-45d1e320791b,DISK], DatanodeInfoWithStorage[127.0.0.1:42024,DS-3fa3a9a5-c1f5-45f5-b0ce-3c46c66c2c99,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1134419068-172.17.0.13-1598416410642:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46789,DS-b4d74e2c-8187-4e07-bbef-37740fe69c00,DISK], DatanodeInfoWithStorage[127.0.0.1:33836,DS-8d303951-8cc0-4f8a-9df2-1ec3557ca536,DISK], DatanodeInfoWithStorage[127.0.0.1:44827,DS-39bd756b-4dea-488d-9e74-720b1699d8d8,DISK], DatanodeInfoWithStorage[127.0.0.1:38981,DS-9d97a386-9a47-41e3-afc5-c219e151048c,DISK], DatanodeInfoWithStorage[127.0.0.1:38096,DS-7a4a385d-d08d-4f53-b5a0-fc1e882ae8b1,DISK], DatanodeInfoWithStorage[127.0.0.1:45380,DS-8051f23d-9210-45ec-b292-ff0bd0b78e44,DISK], DatanodeInfoWithStorage[127.0.0.1:40253,DS-0af7f398-d2b3-418e-895a-e475a203c579,DISK], DatanodeInfoWithStorage[127.0.0.1:34124,DS-a3ffbc0d-ca60-418c-af30-a871941ae093,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1134419068-172.17.0.13-1598416410642:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46789,DS-b4d74e2c-8187-4e07-bbef-37740fe69c00,DISK], DatanodeInfoWithStorage[127.0.0.1:33836,DS-8d303951-8cc0-4f8a-9df2-1ec3557ca536,DISK], DatanodeInfoWithStorage[127.0.0.1:44827,DS-39bd756b-4dea-488d-9e74-720b1699d8d8,DISK], DatanodeInfoWithStorage[127.0.0.1:38981,DS-9d97a386-9a47-41e3-afc5-c219e151048c,DISK], DatanodeInfoWithStorage[127.0.0.1:38096,DS-7a4a385d-d08d-4f53-b5a0-fc1e882ae8b1,DISK], DatanodeInfoWithStorage[127.0.0.1:45380,DS-8051f23d-9210-45ec-b292-ff0bd0b78e44,DISK], DatanodeInfoWithStorage[127.0.0.1:40253,DS-0af7f398-d2b3-418e-895a-e475a203c579,DISK], DatanodeInfoWithStorage[127.0.0.1:34124,DS-a3ffbc0d-ca60-418c-af30-a871941ae093,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-772266071-172.17.0.13-1598416605566:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34484,DS-6a5fba80-0bab-4629-9a19-d48af8bcb1bf,DISK], DatanodeInfoWithStorage[127.0.0.1:34458,DS-7f6b7a43-a25b-4a21-8214-40aaac12abf3,DISK], DatanodeInfoWithStorage[127.0.0.1:41234,DS-186dfc97-efea-4403-bdb4-6fbf40ddaf62,DISK], DatanodeInfoWithStorage[127.0.0.1:36939,DS-4ef4eb4c-9bc0-42c2-b081-c520e9bc4618,DISK], DatanodeInfoWithStorage[127.0.0.1:32852,DS-f2706108-74f9-4ae7-8493-f374c984963c,DISK], DatanodeInfoWithStorage[127.0.0.1:34793,DS-27e29b06-105e-4057-b565-fdf73d189e83,DISK], DatanodeInfoWithStorage[127.0.0.1:45228,DS-931fb371-6275-422b-839a-ad08ebfce187,DISK], DatanodeInfoWithStorage[127.0.0.1:34583,DS-023a30d7-3d80-4608-ba9b-417b0466f3fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-772266071-172.17.0.13-1598416605566:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34484,DS-6a5fba80-0bab-4629-9a19-d48af8bcb1bf,DISK], DatanodeInfoWithStorage[127.0.0.1:34458,DS-7f6b7a43-a25b-4a21-8214-40aaac12abf3,DISK], DatanodeInfoWithStorage[127.0.0.1:41234,DS-186dfc97-efea-4403-bdb4-6fbf40ddaf62,DISK], DatanodeInfoWithStorage[127.0.0.1:36939,DS-4ef4eb4c-9bc0-42c2-b081-c520e9bc4618,DISK], DatanodeInfoWithStorage[127.0.0.1:32852,DS-f2706108-74f9-4ae7-8493-f374c984963c,DISK], DatanodeInfoWithStorage[127.0.0.1:34793,DS-27e29b06-105e-4057-b565-fdf73d189e83,DISK], DatanodeInfoWithStorage[127.0.0.1:45228,DS-931fb371-6275-422b-839a-ad08ebfce187,DISK], DatanodeInfoWithStorage[127.0.0.1:34583,DS-023a30d7-3d80-4608-ba9b-417b0466f3fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-155250183-172.17.0.13-1598416840058:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43319,DS-c61d4ecc-ec87-4fb7-985c-7817f107aed8,DISK], DatanodeInfoWithStorage[127.0.0.1:42147,DS-b137cbc6-18db-40a3-aa97-18c7615867ab,DISK], DatanodeInfoWithStorage[127.0.0.1:38024,DS-5a9b884a-78d1-4149-8fcb-fa6bd933b61f,DISK], DatanodeInfoWithStorage[127.0.0.1:40998,DS-dc5e955c-eee3-4235-9310-5cd67696adf8,DISK], DatanodeInfoWithStorage[127.0.0.1:45699,DS-74bee947-f0fc-43a9-8aa0-8cfcb6c8f029,DISK], DatanodeInfoWithStorage[127.0.0.1:38686,DS-38c6ecba-85b7-49ad-ac9b-d91039c7ce1a,DISK], DatanodeInfoWithStorage[127.0.0.1:40757,DS-b18de887-3539-49b8-9e87-aec94a8d94a7,DISK], DatanodeInfoWithStorage[127.0.0.1:42357,DS-f79c9692-4d38-4bc4-a660-8b260715a4b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-155250183-172.17.0.13-1598416840058:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43319,DS-c61d4ecc-ec87-4fb7-985c-7817f107aed8,DISK], DatanodeInfoWithStorage[127.0.0.1:42147,DS-b137cbc6-18db-40a3-aa97-18c7615867ab,DISK], DatanodeInfoWithStorage[127.0.0.1:38024,DS-5a9b884a-78d1-4149-8fcb-fa6bd933b61f,DISK], DatanodeInfoWithStorage[127.0.0.1:40998,DS-dc5e955c-eee3-4235-9310-5cd67696adf8,DISK], DatanodeInfoWithStorage[127.0.0.1:45699,DS-74bee947-f0fc-43a9-8aa0-8cfcb6c8f029,DISK], DatanodeInfoWithStorage[127.0.0.1:38686,DS-38c6ecba-85b7-49ad-ac9b-d91039c7ce1a,DISK], DatanodeInfoWithStorage[127.0.0.1:40757,DS-b18de887-3539-49b8-9e87-aec94a8d94a7,DISK], DatanodeInfoWithStorage[127.0.0.1:42357,DS-f79c9692-4d38-4bc4-a660-8b260715a4b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-38791711-172.17.0.13-1598417816243:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40617,DS-7f9573a1-727c-4a5f-a2f7-c120309bff9f,DISK], DatanodeInfoWithStorage[127.0.0.1:39364,DS-cfa6e7fc-9683-4e82-9722-6dfd61226357,DISK], DatanodeInfoWithStorage[127.0.0.1:32942,DS-46754459-5c43-45c3-8160-e8e8e9cfd7f5,DISK], DatanodeInfoWithStorage[127.0.0.1:39006,DS-3b23b11b-a8cd-4120-b693-f853a955a066,DISK], DatanodeInfoWithStorage[127.0.0.1:36019,DS-7b2b5d73-76a9-4ca9-8f47-d9f31edd2e82,DISK], DatanodeInfoWithStorage[127.0.0.1:39726,DS-20f97631-ee5d-48df-8204-9908acc7d382,DISK], DatanodeInfoWithStorage[127.0.0.1:40889,DS-5ed1c5c5-c1e2-4132-9646-2d38aac58db0,DISK], DatanodeInfoWithStorage[127.0.0.1:39272,DS-ea649caf-05d8-46ea-ae39-2f7fbb72baf5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-38791711-172.17.0.13-1598417816243:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40617,DS-7f9573a1-727c-4a5f-a2f7-c120309bff9f,DISK], DatanodeInfoWithStorage[127.0.0.1:39364,DS-cfa6e7fc-9683-4e82-9722-6dfd61226357,DISK], DatanodeInfoWithStorage[127.0.0.1:32942,DS-46754459-5c43-45c3-8160-e8e8e9cfd7f5,DISK], DatanodeInfoWithStorage[127.0.0.1:39006,DS-3b23b11b-a8cd-4120-b693-f853a955a066,DISK], DatanodeInfoWithStorage[127.0.0.1:36019,DS-7b2b5d73-76a9-4ca9-8f47-d9f31edd2e82,DISK], DatanodeInfoWithStorage[127.0.0.1:39726,DS-20f97631-ee5d-48df-8204-9908acc7d382,DISK], DatanodeInfoWithStorage[127.0.0.1:40889,DS-5ed1c5c5-c1e2-4132-9646-2d38aac58db0,DISK], DatanodeInfoWithStorage[127.0.0.1:39272,DS-ea649caf-05d8-46ea-ae39-2f7fbb72baf5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1406570776-172.17.0.13-1598417930646:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42184,DS-766d176d-e20d-44e6-97eb-22de9bbd4c63,DISK], DatanodeInfoWithStorage[127.0.0.1:43279,DS-77d456dc-7aab-4121-a3ac-7e7450109c92,DISK], DatanodeInfoWithStorage[127.0.0.1:43048,DS-27b13eb6-9fbb-411a-ac3a-bc30ec02a584,DISK], DatanodeInfoWithStorage[127.0.0.1:39537,DS-8141fbcf-b696-417d-a58d-47f69acbb29b,DISK], DatanodeInfoWithStorage[127.0.0.1:46610,DS-a02d223d-5075-4780-9901-c19709aae876,DISK], DatanodeInfoWithStorage[127.0.0.1:39548,DS-2170567f-7a8c-4400-9281-494b2c70c09c,DISK], DatanodeInfoWithStorage[127.0.0.1:36941,DS-795825de-f00f-437e-92ce-b8518e625405,DISK], DatanodeInfoWithStorage[127.0.0.1:37552,DS-2c820b69-2fd4-455b-9edc-a912b6aa9f7f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1406570776-172.17.0.13-1598417930646:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42184,DS-766d176d-e20d-44e6-97eb-22de9bbd4c63,DISK], DatanodeInfoWithStorage[127.0.0.1:43279,DS-77d456dc-7aab-4121-a3ac-7e7450109c92,DISK], DatanodeInfoWithStorage[127.0.0.1:43048,DS-27b13eb6-9fbb-411a-ac3a-bc30ec02a584,DISK], DatanodeInfoWithStorage[127.0.0.1:39537,DS-8141fbcf-b696-417d-a58d-47f69acbb29b,DISK], DatanodeInfoWithStorage[127.0.0.1:46610,DS-a02d223d-5075-4780-9901-c19709aae876,DISK], DatanodeInfoWithStorage[127.0.0.1:39548,DS-2170567f-7a8c-4400-9281-494b2c70c09c,DISK], DatanodeInfoWithStorage[127.0.0.1:36941,DS-795825de-f00f-437e-92ce-b8518e625405,DISK], DatanodeInfoWithStorage[127.0.0.1:37552,DS-2c820b69-2fd4-455b-9edc-a912b6aa9f7f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-336947690-172.17.0.13-1598418436805:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34974,DS-7c8731b7-9c5c-401c-9bef-d1109b1d5245,DISK], DatanodeInfoWithStorage[127.0.0.1:34452,DS-c09956a8-9127-4bd6-aea5-87d2577b6b3c,DISK], DatanodeInfoWithStorage[127.0.0.1:35513,DS-7a99e5dd-8f87-4418-bf86-238dbf330c7a,DISK], DatanodeInfoWithStorage[127.0.0.1:33924,DS-607835b3-ddf7-4452-a29f-7fbb8ba8f46d,DISK], DatanodeInfoWithStorage[127.0.0.1:38799,DS-e9ccece7-530b-42fc-9a06-a287dca26515,DISK], DatanodeInfoWithStorage[127.0.0.1:46568,DS-233dd5b2-0283-4e27-aafc-33f2e1bd1d44,DISK], DatanodeInfoWithStorage[127.0.0.1:39839,DS-e45c74cf-8a68-4d5a-8a35-58429f4a51c9,DISK], DatanodeInfoWithStorage[127.0.0.1:39371,DS-f5e03512-19ce-432b-ab63-30a8763b6d8c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-336947690-172.17.0.13-1598418436805:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34974,DS-7c8731b7-9c5c-401c-9bef-d1109b1d5245,DISK], DatanodeInfoWithStorage[127.0.0.1:34452,DS-c09956a8-9127-4bd6-aea5-87d2577b6b3c,DISK], DatanodeInfoWithStorage[127.0.0.1:35513,DS-7a99e5dd-8f87-4418-bf86-238dbf330c7a,DISK], DatanodeInfoWithStorage[127.0.0.1:33924,DS-607835b3-ddf7-4452-a29f-7fbb8ba8f46d,DISK], DatanodeInfoWithStorage[127.0.0.1:38799,DS-e9ccece7-530b-42fc-9a06-a287dca26515,DISK], DatanodeInfoWithStorage[127.0.0.1:46568,DS-233dd5b2-0283-4e27-aafc-33f2e1bd1d44,DISK], DatanodeInfoWithStorage[127.0.0.1:39839,DS-e45c74cf-8a68-4d5a-8a35-58429f4a51c9,DISK], DatanodeInfoWithStorage[127.0.0.1:39371,DS-f5e03512-19ce-432b-ab63-30a8763b6d8c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2029895533-172.17.0.13-1598418572381:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40378,DS-d2a5f34c-972e-4d76-ae7a-65d96c1eb249,DISK], DatanodeInfoWithStorage[127.0.0.1:43160,DS-245f1d3c-b346-436c-a603-b1eee4a020cf,DISK], DatanodeInfoWithStorage[127.0.0.1:37229,DS-90a694ab-d113-4983-bc51-f5e8f2b62fe8,DISK], DatanodeInfoWithStorage[127.0.0.1:41228,DS-16b4ae7a-6332-42cb-9ac2-88bacf0137ec,DISK], DatanodeInfoWithStorage[127.0.0.1:35806,DS-0d6874cf-6576-47b2-9cf1-1e4387d718b3,DISK], DatanodeInfoWithStorage[127.0.0.1:38725,DS-5a682152-a287-4810-946b-bfb419099b0d,DISK], DatanodeInfoWithStorage[127.0.0.1:46567,DS-63038545-9c17-40c2-8b20-abb504b9de84,DISK], DatanodeInfoWithStorage[127.0.0.1:34929,DS-71734cea-62e3-4092-a386-3478f1493889,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2029895533-172.17.0.13-1598418572381:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40378,DS-d2a5f34c-972e-4d76-ae7a-65d96c1eb249,DISK], DatanodeInfoWithStorage[127.0.0.1:43160,DS-245f1d3c-b346-436c-a603-b1eee4a020cf,DISK], DatanodeInfoWithStorage[127.0.0.1:37229,DS-90a694ab-d113-4983-bc51-f5e8f2b62fe8,DISK], DatanodeInfoWithStorage[127.0.0.1:41228,DS-16b4ae7a-6332-42cb-9ac2-88bacf0137ec,DISK], DatanodeInfoWithStorage[127.0.0.1:35806,DS-0d6874cf-6576-47b2-9cf1-1e4387d718b3,DISK], DatanodeInfoWithStorage[127.0.0.1:38725,DS-5a682152-a287-4810-946b-bfb419099b0d,DISK], DatanodeInfoWithStorage[127.0.0.1:46567,DS-63038545-9c17-40c2-8b20-abb504b9de84,DISK], DatanodeInfoWithStorage[127.0.0.1:34929,DS-71734cea-62e3-4092-a386-3478f1493889,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1781797938-172.17.0.13-1598418786794:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46712,DS-b6101c42-ad6c-43c0-8361-fe00b68e097e,DISK], DatanodeInfoWithStorage[127.0.0.1:34163,DS-ea4f0b57-95b9-477d-b09b-da5532de8cfe,DISK], DatanodeInfoWithStorage[127.0.0.1:42492,DS-f02422f7-e797-40f0-82ec-146e6b1049f4,DISK], DatanodeInfoWithStorage[127.0.0.1:44278,DS-d8703750-1c4e-49ad-82ba-a6b6bef7ec95,DISK], DatanodeInfoWithStorage[127.0.0.1:34015,DS-a13abca4-cf81-494c-a000-98b6480587a3,DISK], DatanodeInfoWithStorage[127.0.0.1:35720,DS-070b1bc6-db42-4aab-aa6c-ba4b591dc11d,DISK], DatanodeInfoWithStorage[127.0.0.1:39672,DS-58b1cfb2-852e-40ef-8650-6703ffb90e04,DISK], DatanodeInfoWithStorage[127.0.0.1:40986,DS-7c91b2c2-51e6-491c-a004-b46bbe21e7c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1781797938-172.17.0.13-1598418786794:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46712,DS-b6101c42-ad6c-43c0-8361-fe00b68e097e,DISK], DatanodeInfoWithStorage[127.0.0.1:34163,DS-ea4f0b57-95b9-477d-b09b-da5532de8cfe,DISK], DatanodeInfoWithStorage[127.0.0.1:42492,DS-f02422f7-e797-40f0-82ec-146e6b1049f4,DISK], DatanodeInfoWithStorage[127.0.0.1:44278,DS-d8703750-1c4e-49ad-82ba-a6b6bef7ec95,DISK], DatanodeInfoWithStorage[127.0.0.1:34015,DS-a13abca4-cf81-494c-a000-98b6480587a3,DISK], DatanodeInfoWithStorage[127.0.0.1:35720,DS-070b1bc6-db42-4aab-aa6c-ba4b591dc11d,DISK], DatanodeInfoWithStorage[127.0.0.1:39672,DS-58b1cfb2-852e-40ef-8650-6703ffb90e04,DISK], DatanodeInfoWithStorage[127.0.0.1:40986,DS-7c91b2c2-51e6-491c-a004-b46bbe21e7c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1252558792-172.17.0.13-1598419092956:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34009,DS-b609f00b-f2a1-4200-9c68-384e7a624fb6,DISK], DatanodeInfoWithStorage[127.0.0.1:35998,DS-66b07724-53db-40ad-b6a8-c6e2709065a8,DISK], DatanodeInfoWithStorage[127.0.0.1:39312,DS-f03b4eb7-e2c9-43ee-8a7d-b8f3b03fee25,DISK], DatanodeInfoWithStorage[127.0.0.1:44417,DS-22bd954f-3e36-4e1a-b9d5-d02afb4c6941,DISK], DatanodeInfoWithStorage[127.0.0.1:44461,DS-5282c978-b4a9-4ed5-ae6b-46baee4aa791,DISK], DatanodeInfoWithStorage[127.0.0.1:42206,DS-57a1d12c-cad9-4f86-b359-1204771dfe9e,DISK], DatanodeInfoWithStorage[127.0.0.1:43748,DS-3569f8cf-ae29-4620-bf96-2e7fa2670aa4,DISK], DatanodeInfoWithStorage[127.0.0.1:39531,DS-7d3e8d27-a740-4fee-90a4-ffdc772281ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1252558792-172.17.0.13-1598419092956:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34009,DS-b609f00b-f2a1-4200-9c68-384e7a624fb6,DISK], DatanodeInfoWithStorage[127.0.0.1:35998,DS-66b07724-53db-40ad-b6a8-c6e2709065a8,DISK], DatanodeInfoWithStorage[127.0.0.1:39312,DS-f03b4eb7-e2c9-43ee-8a7d-b8f3b03fee25,DISK], DatanodeInfoWithStorage[127.0.0.1:44417,DS-22bd954f-3e36-4e1a-b9d5-d02afb4c6941,DISK], DatanodeInfoWithStorage[127.0.0.1:44461,DS-5282c978-b4a9-4ed5-ae6b-46baee4aa791,DISK], DatanodeInfoWithStorage[127.0.0.1:42206,DS-57a1d12c-cad9-4f86-b359-1204771dfe9e,DISK], DatanodeInfoWithStorage[127.0.0.1:43748,DS-3569f8cf-ae29-4620-bf96-2e7fa2670aa4,DISK], DatanodeInfoWithStorage[127.0.0.1:39531,DS-7d3e8d27-a740-4fee-90a4-ffdc772281ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-619808381-172.17.0.13-1598419194810:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39243,DS-d8efceed-058a-4d17-9e03-964885d0f4d0,DISK], DatanodeInfoWithStorage[127.0.0.1:41200,DS-cfb92287-343a-4057-9462-1883b46cb281,DISK], DatanodeInfoWithStorage[127.0.0.1:34113,DS-c6a7449b-ebab-4d45-ba8f-4520ea96a4b7,DISK], DatanodeInfoWithStorage[127.0.0.1:37100,DS-2cfac80d-30a9-454c-a8ae-26f522b8cdb7,DISK], DatanodeInfoWithStorage[127.0.0.1:44037,DS-26165fe2-d0d6-416d-838f-c5ce8e45ad15,DISK], DatanodeInfoWithStorage[127.0.0.1:35427,DS-9587e6ca-6393-4dda-aeb1-be88ea23a5a1,DISK], DatanodeInfoWithStorage[127.0.0.1:34924,DS-ab147cc4-164f-4ccf-baed-09a58f24d60c,DISK], DatanodeInfoWithStorage[127.0.0.1:42481,DS-fc6c4ece-ea69-4309-aee3-85fa823541ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-619808381-172.17.0.13-1598419194810:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39243,DS-d8efceed-058a-4d17-9e03-964885d0f4d0,DISK], DatanodeInfoWithStorage[127.0.0.1:41200,DS-cfb92287-343a-4057-9462-1883b46cb281,DISK], DatanodeInfoWithStorage[127.0.0.1:34113,DS-c6a7449b-ebab-4d45-ba8f-4520ea96a4b7,DISK], DatanodeInfoWithStorage[127.0.0.1:37100,DS-2cfac80d-30a9-454c-a8ae-26f522b8cdb7,DISK], DatanodeInfoWithStorage[127.0.0.1:44037,DS-26165fe2-d0d6-416d-838f-c5ce8e45ad15,DISK], DatanodeInfoWithStorage[127.0.0.1:35427,DS-9587e6ca-6393-4dda-aeb1-be88ea23a5a1,DISK], DatanodeInfoWithStorage[127.0.0.1:34924,DS-ab147cc4-164f-4ccf-baed-09a58f24d60c,DISK], DatanodeInfoWithStorage[127.0.0.1:42481,DS-fc6c4ece-ea69-4309-aee3-85fa823541ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1172124819-172.17.0.13-1598419744422:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38057,DS-9cb16559-2e82-4b04-9bfe-dee0f3db1744,DISK], DatanodeInfoWithStorage[127.0.0.1:40645,DS-884bd88e-9ad5-45e2-ab5e-2092aef73cf1,DISK], DatanodeInfoWithStorage[127.0.0.1:37096,DS-3361c09d-ad0f-469b-971c-e11ddfc7d836,DISK], DatanodeInfoWithStorage[127.0.0.1:43001,DS-539129d5-3643-4dbb-9fe1-aa72f1d83c81,DISK], DatanodeInfoWithStorage[127.0.0.1:46766,DS-53a8d716-6d7e-4a74-9c30-db55db168822,DISK], DatanodeInfoWithStorage[127.0.0.1:44413,DS-fd4e84bb-591d-4863-817e-6ca3b9ebc594,DISK], DatanodeInfoWithStorage[127.0.0.1:35788,DS-e87651f1-68f0-4d29-ad37-11f13402a7a1,DISK], DatanodeInfoWithStorage[127.0.0.1:45851,DS-adf98797-ee50-4825-aa4b-03ebdb8341b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1172124819-172.17.0.13-1598419744422:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38057,DS-9cb16559-2e82-4b04-9bfe-dee0f3db1744,DISK], DatanodeInfoWithStorage[127.0.0.1:40645,DS-884bd88e-9ad5-45e2-ab5e-2092aef73cf1,DISK], DatanodeInfoWithStorage[127.0.0.1:37096,DS-3361c09d-ad0f-469b-971c-e11ddfc7d836,DISK], DatanodeInfoWithStorage[127.0.0.1:43001,DS-539129d5-3643-4dbb-9fe1-aa72f1d83c81,DISK], DatanodeInfoWithStorage[127.0.0.1:46766,DS-53a8d716-6d7e-4a74-9c30-db55db168822,DISK], DatanodeInfoWithStorage[127.0.0.1:44413,DS-fd4e84bb-591d-4863-817e-6ca3b9ebc594,DISK], DatanodeInfoWithStorage[127.0.0.1:35788,DS-e87651f1-68f0-4d29-ad37-11f13402a7a1,DISK], DatanodeInfoWithStorage[127.0.0.1:45851,DS-adf98797-ee50-4825-aa4b-03ebdb8341b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-672566330-172.17.0.13-1598419915869:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40473,DS-fb46f68c-e360-4bca-941a-d9062c332756,DISK], DatanodeInfoWithStorage[127.0.0.1:43436,DS-e66c1265-bfef-4ae2-8b32-570aec725784,DISK], DatanodeInfoWithStorage[127.0.0.1:41287,DS-da086c84-6723-4f21-8c02-0d3f603572fb,DISK], DatanodeInfoWithStorage[127.0.0.1:42598,DS-0099c17f-2b9d-4205-8214-b5f320c70e5e,DISK], DatanodeInfoWithStorage[127.0.0.1:35183,DS-738dc3c6-2fb8-4954-bd1f-43ea2aecc4e2,DISK], DatanodeInfoWithStorage[127.0.0.1:45581,DS-3c3e0c5b-9c56-4349-8208-8e56da6ee76a,DISK], DatanodeInfoWithStorage[127.0.0.1:34642,DS-99df8321-fd8b-4bbc-b41d-3c14440a1a19,DISK], DatanodeInfoWithStorage[127.0.0.1:39175,DS-0cf5c850-6ea3-4b9c-b52e-758b52bba22e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-672566330-172.17.0.13-1598419915869:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40473,DS-fb46f68c-e360-4bca-941a-d9062c332756,DISK], DatanodeInfoWithStorage[127.0.0.1:43436,DS-e66c1265-bfef-4ae2-8b32-570aec725784,DISK], DatanodeInfoWithStorage[127.0.0.1:41287,DS-da086c84-6723-4f21-8c02-0d3f603572fb,DISK], DatanodeInfoWithStorage[127.0.0.1:42598,DS-0099c17f-2b9d-4205-8214-b5f320c70e5e,DISK], DatanodeInfoWithStorage[127.0.0.1:35183,DS-738dc3c6-2fb8-4954-bd1f-43ea2aecc4e2,DISK], DatanodeInfoWithStorage[127.0.0.1:45581,DS-3c3e0c5b-9c56-4349-8208-8e56da6ee76a,DISK], DatanodeInfoWithStorage[127.0.0.1:34642,DS-99df8321-fd8b-4bbc-b41d-3c14440a1a19,DISK], DatanodeInfoWithStorage[127.0.0.1:39175,DS-0cf5c850-6ea3-4b9c-b52e-758b52bba22e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1884671033-172.17.0.13-1598420029318:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32869,DS-2765e3c1-6301-4343-b3c5-c0ba31423f54,DISK], DatanodeInfoWithStorage[127.0.0.1:40400,DS-136af98a-0b63-40cb-8542-eab46550c316,DISK], DatanodeInfoWithStorage[127.0.0.1:44375,DS-01b34255-2729-49dc-bcfc-4371d31e6be1,DISK], DatanodeInfoWithStorage[127.0.0.1:46233,DS-e1d5d283-5ac9-4a0d-9a1f-a160be091ad8,DISK], DatanodeInfoWithStorage[127.0.0.1:39838,DS-656befb9-71f1-4fe2-a7cb-b151bed08ead,DISK], DatanodeInfoWithStorage[127.0.0.1:33968,DS-115f1f0d-7bda-4764-8dea-ba28642d3a34,DISK], DatanodeInfoWithStorage[127.0.0.1:41422,DS-16683ba5-ebdc-42cd-9769-f4d210cc94c8,DISK], DatanodeInfoWithStorage[127.0.0.1:37114,DS-905ccd97-f486-4004-beaa-9e78b0090633,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1884671033-172.17.0.13-1598420029318:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32869,DS-2765e3c1-6301-4343-b3c5-c0ba31423f54,DISK], DatanodeInfoWithStorage[127.0.0.1:40400,DS-136af98a-0b63-40cb-8542-eab46550c316,DISK], DatanodeInfoWithStorage[127.0.0.1:44375,DS-01b34255-2729-49dc-bcfc-4371d31e6be1,DISK], DatanodeInfoWithStorage[127.0.0.1:46233,DS-e1d5d283-5ac9-4a0d-9a1f-a160be091ad8,DISK], DatanodeInfoWithStorage[127.0.0.1:39838,DS-656befb9-71f1-4fe2-a7cb-b151bed08ead,DISK], DatanodeInfoWithStorage[127.0.0.1:33968,DS-115f1f0d-7bda-4764-8dea-ba28642d3a34,DISK], DatanodeInfoWithStorage[127.0.0.1:41422,DS-16683ba5-ebdc-42cd-9769-f4d210cc94c8,DISK], DatanodeInfoWithStorage[127.0.0.1:37114,DS-905ccd97-f486-4004-beaa-9e78b0090633,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-64139401-172.17.0.13-1598420252128:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43315,DS-952910ec-55e7-4800-a0db-abef50f8193e,DISK], DatanodeInfoWithStorage[127.0.0.1:37418,DS-204adb0f-9752-45b3-a50a-08a471714142,DISK], DatanodeInfoWithStorage[127.0.0.1:43593,DS-161959c9-09f6-4ccd-aa77-fb106e699971,DISK], DatanodeInfoWithStorage[127.0.0.1:45092,DS-6875760d-eef3-4a84-88fa-d5b924e0843e,DISK], DatanodeInfoWithStorage[127.0.0.1:42353,DS-8f7ff47c-66aa-410d-b206-072b1827aef9,DISK], DatanodeInfoWithStorage[127.0.0.1:36797,DS-79c1c8b6-7b6a-4522-a05b-20495ec85cd5,DISK], DatanodeInfoWithStorage[127.0.0.1:44818,DS-adb41515-644a-426c-9acd-956f232fdef8,DISK], DatanodeInfoWithStorage[127.0.0.1:33524,DS-6fb434db-b559-41a1-ba11-a4503dc49f0f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-64139401-172.17.0.13-1598420252128:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43315,DS-952910ec-55e7-4800-a0db-abef50f8193e,DISK], DatanodeInfoWithStorage[127.0.0.1:37418,DS-204adb0f-9752-45b3-a50a-08a471714142,DISK], DatanodeInfoWithStorage[127.0.0.1:43593,DS-161959c9-09f6-4ccd-aa77-fb106e699971,DISK], DatanodeInfoWithStorage[127.0.0.1:45092,DS-6875760d-eef3-4a84-88fa-d5b924e0843e,DISK], DatanodeInfoWithStorage[127.0.0.1:42353,DS-8f7ff47c-66aa-410d-b206-072b1827aef9,DISK], DatanodeInfoWithStorage[127.0.0.1:36797,DS-79c1c8b6-7b6a-4522-a05b-20495ec85cd5,DISK], DatanodeInfoWithStorage[127.0.0.1:44818,DS-adb41515-644a-426c-9acd-956f232fdef8,DISK], DatanodeInfoWithStorage[127.0.0.1:33524,DS-6fb434db-b559-41a1-ba11-a4503dc49f0f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1676979575-172.17.0.13-1598420412936:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40222,DS-9713e5b1-bc45-4b31-9bbe-2f352fa3ffb0,DISK], DatanodeInfoWithStorage[127.0.0.1:40173,DS-a7c3ce2f-2fba-4f9e-b476-f13c87f36906,DISK], DatanodeInfoWithStorage[127.0.0.1:41401,DS-3ae165d8-a8ca-4d11-a406-6f1007452658,DISK], DatanodeInfoWithStorage[127.0.0.1:45829,DS-c02abdd8-09cd-466a-b9e2-43951ea40314,DISK], DatanodeInfoWithStorage[127.0.0.1:38260,DS-89f44b91-e4e3-49a0-affb-64cdfba73adb,DISK], DatanodeInfoWithStorage[127.0.0.1:35336,DS-3583bbee-7946-4384-987c-a8346fbd8c63,DISK], DatanodeInfoWithStorage[127.0.0.1:41804,DS-a7cd2e57-7cc1-4f0e-8d9c-0d7ecc57d8aa,DISK], DatanodeInfoWithStorage[127.0.0.1:34035,DS-23e067ce-8864-4218-9da2-0cfce4ad8ea2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1676979575-172.17.0.13-1598420412936:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40222,DS-9713e5b1-bc45-4b31-9bbe-2f352fa3ffb0,DISK], DatanodeInfoWithStorage[127.0.0.1:40173,DS-a7c3ce2f-2fba-4f9e-b476-f13c87f36906,DISK], DatanodeInfoWithStorage[127.0.0.1:41401,DS-3ae165d8-a8ca-4d11-a406-6f1007452658,DISK], DatanodeInfoWithStorage[127.0.0.1:45829,DS-c02abdd8-09cd-466a-b9e2-43951ea40314,DISK], DatanodeInfoWithStorage[127.0.0.1:38260,DS-89f44b91-e4e3-49a0-affb-64cdfba73adb,DISK], DatanodeInfoWithStorage[127.0.0.1:35336,DS-3583bbee-7946-4384-987c-a8346fbd8c63,DISK], DatanodeInfoWithStorage[127.0.0.1:41804,DS-a7cd2e57-7cc1-4f0e-8d9c-0d7ecc57d8aa,DISK], DatanodeInfoWithStorage[127.0.0.1:34035,DS-23e067ce-8864-4218-9da2-0cfce4ad8ea2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-22673613-172.17.0.13-1598420694597:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43609,DS-ef4afd4a-d307-4d28-8990-6adc1ddd7c5d,DISK], DatanodeInfoWithStorage[127.0.0.1:42471,DS-e410a68f-2750-4457-8461-99928ef7ba37,DISK], DatanodeInfoWithStorage[127.0.0.1:34934,DS-6863c28b-e074-4e14-8802-b8b31d99e157,DISK], DatanodeInfoWithStorage[127.0.0.1:37977,DS-fd807838-b837-4aff-a889-9c31e12d66b8,DISK], DatanodeInfoWithStorage[127.0.0.1:38037,DS-9cb3024f-8048-43e8-a42f-3c02e1fc0a89,DISK], DatanodeInfoWithStorage[127.0.0.1:36448,DS-ab6a8a1b-a51b-4414-886d-1f92e78bf181,DISK], DatanodeInfoWithStorage[127.0.0.1:39090,DS-77c196d1-9e5a-4b6b-8734-73966bbcaf90,DISK], DatanodeInfoWithStorage[127.0.0.1:38602,DS-c153b875-345f-4f50-a9f0-83aa35d05c75,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-22673613-172.17.0.13-1598420694597:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43609,DS-ef4afd4a-d307-4d28-8990-6adc1ddd7c5d,DISK], DatanodeInfoWithStorage[127.0.0.1:42471,DS-e410a68f-2750-4457-8461-99928ef7ba37,DISK], DatanodeInfoWithStorage[127.0.0.1:34934,DS-6863c28b-e074-4e14-8802-b8b31d99e157,DISK], DatanodeInfoWithStorage[127.0.0.1:37977,DS-fd807838-b837-4aff-a889-9c31e12d66b8,DISK], DatanodeInfoWithStorage[127.0.0.1:38037,DS-9cb3024f-8048-43e8-a42f-3c02e1fc0a89,DISK], DatanodeInfoWithStorage[127.0.0.1:36448,DS-ab6a8a1b-a51b-4414-886d-1f92e78bf181,DISK], DatanodeInfoWithStorage[127.0.0.1:39090,DS-77c196d1-9e5a-4b6b-8734-73966bbcaf90,DISK], DatanodeInfoWithStorage[127.0.0.1:38602,DS-c153b875-345f-4f50-a9f0-83aa35d05c75,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 5423
