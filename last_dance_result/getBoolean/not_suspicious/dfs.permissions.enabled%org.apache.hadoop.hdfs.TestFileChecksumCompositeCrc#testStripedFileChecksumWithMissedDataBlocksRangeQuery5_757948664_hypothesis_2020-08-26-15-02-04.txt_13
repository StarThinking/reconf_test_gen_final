reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1535656369-172.17.0.15-1598454283842:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43351,DS-d6aafee9-3585-4517-93ab-af9cdb3bac74,DISK], DatanodeInfoWithStorage[127.0.0.1:45220,DS-03815436-eb1c-4b0b-a5e7-89af4fa42ea3,DISK], DatanodeInfoWithStorage[127.0.0.1:44491,DS-48514df7-027b-43a0-b94c-8e857bd9b382,DISK], DatanodeInfoWithStorage[127.0.0.1:32944,DS-992fff2e-c0cc-465e-bcde-109e0b827133,DISK], DatanodeInfoWithStorage[127.0.0.1:43876,DS-2f425445-83fd-4636-9771-753b697e2378,DISK], DatanodeInfoWithStorage[127.0.0.1:36407,DS-8dfa794a-e20e-4f5c-a4b3-0ef867a86985,DISK], DatanodeInfoWithStorage[127.0.0.1:45962,DS-dc5bd8d2-93a8-442b-89d4-7bbdbafcad25,DISK], DatanodeInfoWithStorage[127.0.0.1:46774,DS-6b1da09f-4085-4873-8fb8-42bed6c53e4d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1535656369-172.17.0.15-1598454283842:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43351,DS-d6aafee9-3585-4517-93ab-af9cdb3bac74,DISK], DatanodeInfoWithStorage[127.0.0.1:45220,DS-03815436-eb1c-4b0b-a5e7-89af4fa42ea3,DISK], DatanodeInfoWithStorage[127.0.0.1:44491,DS-48514df7-027b-43a0-b94c-8e857bd9b382,DISK], DatanodeInfoWithStorage[127.0.0.1:32944,DS-992fff2e-c0cc-465e-bcde-109e0b827133,DISK], DatanodeInfoWithStorage[127.0.0.1:43876,DS-2f425445-83fd-4636-9771-753b697e2378,DISK], DatanodeInfoWithStorage[127.0.0.1:36407,DS-8dfa794a-e20e-4f5c-a4b3-0ef867a86985,DISK], DatanodeInfoWithStorage[127.0.0.1:45962,DS-dc5bd8d2-93a8-442b-89d4-7bbdbafcad25,DISK], DatanodeInfoWithStorage[127.0.0.1:46774,DS-6b1da09f-4085-4873-8fb8-42bed6c53e4d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1633200680-172.17.0.15-1598454557162:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39109,DS-303586b1-4f25-42bc-9adf-2d30d8862c87,DISK], DatanodeInfoWithStorage[127.0.0.1:44862,DS-0b67d768-85f4-4363-82b0-014a18d46b65,DISK], DatanodeInfoWithStorage[127.0.0.1:34909,DS-9edfa9b2-444c-4780-be6b-0cfc65f3138f,DISK], DatanodeInfoWithStorage[127.0.0.1:41711,DS-adc5bef1-a96b-4bda-911e-1af0bcc17afa,DISK], DatanodeInfoWithStorage[127.0.0.1:36619,DS-5f930f37-fc8a-4067-b283-dea1fcb9a616,DISK], DatanodeInfoWithStorage[127.0.0.1:41481,DS-f8d8bb3f-349f-4d0c-b683-4a18adef0bf8,DISK], DatanodeInfoWithStorage[127.0.0.1:43641,DS-d9d856c2-4ef1-41cc-802c-e9fca9855ad2,DISK], DatanodeInfoWithStorage[127.0.0.1:34362,DS-65b2f681-e17a-421a-a9db-25e1022dd481,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1633200680-172.17.0.15-1598454557162:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39109,DS-303586b1-4f25-42bc-9adf-2d30d8862c87,DISK], DatanodeInfoWithStorage[127.0.0.1:44862,DS-0b67d768-85f4-4363-82b0-014a18d46b65,DISK], DatanodeInfoWithStorage[127.0.0.1:34909,DS-9edfa9b2-444c-4780-be6b-0cfc65f3138f,DISK], DatanodeInfoWithStorage[127.0.0.1:41711,DS-adc5bef1-a96b-4bda-911e-1af0bcc17afa,DISK], DatanodeInfoWithStorage[127.0.0.1:36619,DS-5f930f37-fc8a-4067-b283-dea1fcb9a616,DISK], DatanodeInfoWithStorage[127.0.0.1:41481,DS-f8d8bb3f-349f-4d0c-b683-4a18adef0bf8,DISK], DatanodeInfoWithStorage[127.0.0.1:43641,DS-d9d856c2-4ef1-41cc-802c-e9fca9855ad2,DISK], DatanodeInfoWithStorage[127.0.0.1:34362,DS-65b2f681-e17a-421a-a9db-25e1022dd481,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-396608269-172.17.0.15-1598454910093:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42026,DS-35ff50bd-2d1c-4272-8842-27e274088bea,DISK], DatanodeInfoWithStorage[127.0.0.1:34215,DS-fe87fb71-dfea-490f-adf4-84f5166b9967,DISK], DatanodeInfoWithStorage[127.0.0.1:33691,DS-df2ee37d-5e25-487b-90b0-b5cd092daba8,DISK], DatanodeInfoWithStorage[127.0.0.1:46529,DS-2139669d-da66-4c4e-be74-ed2695ac5e03,DISK], DatanodeInfoWithStorage[127.0.0.1:33046,DS-957ea832-bbae-4c4a-8cee-07a621651ef9,DISK], DatanodeInfoWithStorage[127.0.0.1:36629,DS-dc0e1b6f-230f-4a21-ae2d-5e0b4b5fbb01,DISK], DatanodeInfoWithStorage[127.0.0.1:38652,DS-4d024184-8baa-4935-9f7b-1f54b972157f,DISK], DatanodeInfoWithStorage[127.0.0.1:38910,DS-d8cdd823-74f1-4ebf-b6d2-63ec3e343bcb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-396608269-172.17.0.15-1598454910093:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42026,DS-35ff50bd-2d1c-4272-8842-27e274088bea,DISK], DatanodeInfoWithStorage[127.0.0.1:34215,DS-fe87fb71-dfea-490f-adf4-84f5166b9967,DISK], DatanodeInfoWithStorage[127.0.0.1:33691,DS-df2ee37d-5e25-487b-90b0-b5cd092daba8,DISK], DatanodeInfoWithStorage[127.0.0.1:46529,DS-2139669d-da66-4c4e-be74-ed2695ac5e03,DISK], DatanodeInfoWithStorage[127.0.0.1:33046,DS-957ea832-bbae-4c4a-8cee-07a621651ef9,DISK], DatanodeInfoWithStorage[127.0.0.1:36629,DS-dc0e1b6f-230f-4a21-ae2d-5e0b4b5fbb01,DISK], DatanodeInfoWithStorage[127.0.0.1:38652,DS-4d024184-8baa-4935-9f7b-1f54b972157f,DISK], DatanodeInfoWithStorage[127.0.0.1:38910,DS-d8cdd823-74f1-4ebf-b6d2-63ec3e343bcb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1286767771-172.17.0.15-1598455208516:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38435,DS-6633644d-51e5-413b-aae2-51cd40e1d24d,DISK], DatanodeInfoWithStorage[127.0.0.1:45584,DS-f1265e23-8356-4a17-befa-1dcaac7402eb,DISK], DatanodeInfoWithStorage[127.0.0.1:46663,DS-5d520a9c-67c6-4a03-824e-b4320e6a1ab1,DISK], DatanodeInfoWithStorage[127.0.0.1:32849,DS-28ef1c9d-17a2-4e46-9bd6-00683013f30d,DISK], DatanodeInfoWithStorage[127.0.0.1:39179,DS-d4744e32-a1f5-4dd1-99d7-568dd5b240d2,DISK], DatanodeInfoWithStorage[127.0.0.1:44700,DS-2481f167-188e-4459-b3e0-55dbbce4916a,DISK], DatanodeInfoWithStorage[127.0.0.1:41223,DS-c4ca15dd-1643-4f41-945d-e594d02f89bf,DISK], DatanodeInfoWithStorage[127.0.0.1:41375,DS-63c5f84b-1c9e-4c2a-a64f-8e06d328c185,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1286767771-172.17.0.15-1598455208516:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38435,DS-6633644d-51e5-413b-aae2-51cd40e1d24d,DISK], DatanodeInfoWithStorage[127.0.0.1:45584,DS-f1265e23-8356-4a17-befa-1dcaac7402eb,DISK], DatanodeInfoWithStorage[127.0.0.1:46663,DS-5d520a9c-67c6-4a03-824e-b4320e6a1ab1,DISK], DatanodeInfoWithStorage[127.0.0.1:32849,DS-28ef1c9d-17a2-4e46-9bd6-00683013f30d,DISK], DatanodeInfoWithStorage[127.0.0.1:39179,DS-d4744e32-a1f5-4dd1-99d7-568dd5b240d2,DISK], DatanodeInfoWithStorage[127.0.0.1:44700,DS-2481f167-188e-4459-b3e0-55dbbce4916a,DISK], DatanodeInfoWithStorage[127.0.0.1:41223,DS-c4ca15dd-1643-4f41-945d-e594d02f89bf,DISK], DatanodeInfoWithStorage[127.0.0.1:41375,DS-63c5f84b-1c9e-4c2a-a64f-8e06d328c185,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-654592878-172.17.0.15-1598455531259:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37585,DS-1e82484e-661a-4e2d-8b41-7f33909cdfdc,DISK], DatanodeInfoWithStorage[127.0.0.1:42143,DS-7b8e93e5-fca5-4925-89f8-835aaf0fa40d,DISK], DatanodeInfoWithStorage[127.0.0.1:45658,DS-9e6e0811-855b-4d10-892c-0dccdacb08ca,DISK], DatanodeInfoWithStorage[127.0.0.1:40769,DS-b925b44e-0789-4bb3-9bd7-1f311ef0c1aa,DISK], DatanodeInfoWithStorage[127.0.0.1:44385,DS-379afa3d-7bbb-4abc-a0e2-cdebd1412f7b,DISK], DatanodeInfoWithStorage[127.0.0.1:37276,DS-aa36a5fb-c4d1-4a1a-af02-3f3ba4dd3f4c,DISK], DatanodeInfoWithStorage[127.0.0.1:36043,DS-7de48fa3-0c24-4b17-870a-73d990e05899,DISK], DatanodeInfoWithStorage[127.0.0.1:37026,DS-190c831b-4e35-48c0-8841-5f619cea8518,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-654592878-172.17.0.15-1598455531259:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37585,DS-1e82484e-661a-4e2d-8b41-7f33909cdfdc,DISK], DatanodeInfoWithStorage[127.0.0.1:42143,DS-7b8e93e5-fca5-4925-89f8-835aaf0fa40d,DISK], DatanodeInfoWithStorage[127.0.0.1:45658,DS-9e6e0811-855b-4d10-892c-0dccdacb08ca,DISK], DatanodeInfoWithStorage[127.0.0.1:40769,DS-b925b44e-0789-4bb3-9bd7-1f311ef0c1aa,DISK], DatanodeInfoWithStorage[127.0.0.1:44385,DS-379afa3d-7bbb-4abc-a0e2-cdebd1412f7b,DISK], DatanodeInfoWithStorage[127.0.0.1:37276,DS-aa36a5fb-c4d1-4a1a-af02-3f3ba4dd3f4c,DISK], DatanodeInfoWithStorage[127.0.0.1:36043,DS-7de48fa3-0c24-4b17-870a-73d990e05899,DISK], DatanodeInfoWithStorage[127.0.0.1:37026,DS-190c831b-4e35-48c0-8841-5f619cea8518,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-442634605-172.17.0.15-1598455663683:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41849,DS-97912f5f-3921-426d-b220-bb487bb2517a,DISK], DatanodeInfoWithStorage[127.0.0.1:42228,DS-b6156e09-0ec1-4ab0-bba4-41b08aa04033,DISK], DatanodeInfoWithStorage[127.0.0.1:34969,DS-cfd580de-edb8-4aa0-87b6-f19dc7fb1ece,DISK], DatanodeInfoWithStorage[127.0.0.1:33836,DS-906c2817-8525-4f82-8b31-5f44507709a9,DISK], DatanodeInfoWithStorage[127.0.0.1:39289,DS-abe80b5c-bfde-408f-a357-4d0fd3319c82,DISK], DatanodeInfoWithStorage[127.0.0.1:32895,DS-0abc3603-5644-46ac-ac50-0c7921c0a56c,DISK], DatanodeInfoWithStorage[127.0.0.1:45979,DS-8da42224-c994-456a-97c5-b79b1aa75806,DISK], DatanodeInfoWithStorage[127.0.0.1:42884,DS-c5fdb1ad-1ed1-4093-9ff6-20cf3c8940e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-442634605-172.17.0.15-1598455663683:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41849,DS-97912f5f-3921-426d-b220-bb487bb2517a,DISK], DatanodeInfoWithStorage[127.0.0.1:42228,DS-b6156e09-0ec1-4ab0-bba4-41b08aa04033,DISK], DatanodeInfoWithStorage[127.0.0.1:34969,DS-cfd580de-edb8-4aa0-87b6-f19dc7fb1ece,DISK], DatanodeInfoWithStorage[127.0.0.1:33836,DS-906c2817-8525-4f82-8b31-5f44507709a9,DISK], DatanodeInfoWithStorage[127.0.0.1:39289,DS-abe80b5c-bfde-408f-a357-4d0fd3319c82,DISK], DatanodeInfoWithStorage[127.0.0.1:32895,DS-0abc3603-5644-46ac-ac50-0c7921c0a56c,DISK], DatanodeInfoWithStorage[127.0.0.1:45979,DS-8da42224-c994-456a-97c5-b79b1aa75806,DISK], DatanodeInfoWithStorage[127.0.0.1:42884,DS-c5fdb1ad-1ed1-4093-9ff6-20cf3c8940e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1620881034-172.17.0.15-1598455768111:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44323,DS-b2a52de1-a55a-4298-88df-711b5dd547da,DISK], DatanodeInfoWithStorage[127.0.0.1:43804,DS-7c92df26-470a-4939-8815-3852a495a9f2,DISK], DatanodeInfoWithStorage[127.0.0.1:40070,DS-ba343b81-fb74-4656-8c6a-ea62020021db,DISK], DatanodeInfoWithStorage[127.0.0.1:38518,DS-a6cbd248-b6d8-4d10-b4c2-cacb5d5f78eb,DISK], DatanodeInfoWithStorage[127.0.0.1:40833,DS-60565e06-f05b-4c04-b824-49f7443198d0,DISK], DatanodeInfoWithStorage[127.0.0.1:39405,DS-dcae0b0c-c63c-4c39-bc86-0dd7753957b5,DISK], DatanodeInfoWithStorage[127.0.0.1:43086,DS-5d92bd44-337c-45e6-a366-b749e31fd9f6,DISK], DatanodeInfoWithStorage[127.0.0.1:44554,DS-7bf96670-f635-46fc-b905-3f33cf3afc64,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1620881034-172.17.0.15-1598455768111:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44323,DS-b2a52de1-a55a-4298-88df-711b5dd547da,DISK], DatanodeInfoWithStorage[127.0.0.1:43804,DS-7c92df26-470a-4939-8815-3852a495a9f2,DISK], DatanodeInfoWithStorage[127.0.0.1:40070,DS-ba343b81-fb74-4656-8c6a-ea62020021db,DISK], DatanodeInfoWithStorage[127.0.0.1:38518,DS-a6cbd248-b6d8-4d10-b4c2-cacb5d5f78eb,DISK], DatanodeInfoWithStorage[127.0.0.1:40833,DS-60565e06-f05b-4c04-b824-49f7443198d0,DISK], DatanodeInfoWithStorage[127.0.0.1:39405,DS-dcae0b0c-c63c-4c39-bc86-0dd7753957b5,DISK], DatanodeInfoWithStorage[127.0.0.1:43086,DS-5d92bd44-337c-45e6-a366-b749e31fd9f6,DISK], DatanodeInfoWithStorage[127.0.0.1:44554,DS-7bf96670-f635-46fc-b905-3f33cf3afc64,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1192240774-172.17.0.15-1598455937884:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46459,DS-b3360dab-a0bc-4dd4-a50e-3ca962425ce2,DISK], DatanodeInfoWithStorage[127.0.0.1:34259,DS-0e072190-e78c-4c06-87a1-bd37effc5176,DISK], DatanodeInfoWithStorage[127.0.0.1:34774,DS-ce95d041-ff72-4fc6-aec2-280f0f8ccd49,DISK], DatanodeInfoWithStorage[127.0.0.1:44377,DS-b42ec9b2-771b-4688-88ed-14738c07205b,DISK], DatanodeInfoWithStorage[127.0.0.1:40284,DS-3e40ac14-ee3b-4a7d-8897-c6e5ea9348ff,DISK], DatanodeInfoWithStorage[127.0.0.1:39689,DS-a03fa693-8473-4581-946f-605d4c1bec86,DISK], DatanodeInfoWithStorage[127.0.0.1:42705,DS-abac94c4-5d7e-4eda-b8a9-60e636160f5b,DISK], DatanodeInfoWithStorage[127.0.0.1:32921,DS-0a5dfb52-0290-48d7-a3be-896ea9ddc624,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1192240774-172.17.0.15-1598455937884:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46459,DS-b3360dab-a0bc-4dd4-a50e-3ca962425ce2,DISK], DatanodeInfoWithStorage[127.0.0.1:34259,DS-0e072190-e78c-4c06-87a1-bd37effc5176,DISK], DatanodeInfoWithStorage[127.0.0.1:34774,DS-ce95d041-ff72-4fc6-aec2-280f0f8ccd49,DISK], DatanodeInfoWithStorage[127.0.0.1:44377,DS-b42ec9b2-771b-4688-88ed-14738c07205b,DISK], DatanodeInfoWithStorage[127.0.0.1:40284,DS-3e40ac14-ee3b-4a7d-8897-c6e5ea9348ff,DISK], DatanodeInfoWithStorage[127.0.0.1:39689,DS-a03fa693-8473-4581-946f-605d4c1bec86,DISK], DatanodeInfoWithStorage[127.0.0.1:42705,DS-abac94c4-5d7e-4eda-b8a9-60e636160f5b,DISK], DatanodeInfoWithStorage[127.0.0.1:32921,DS-0a5dfb52-0290-48d7-a3be-896ea9ddc624,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1523740019-172.17.0.15-1598456058262:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35395,DS-943456c0-bcfb-45f7-9c6f-2ac5d9df4583,DISK], DatanodeInfoWithStorage[127.0.0.1:39970,DS-b7587d04-0e5d-4e8b-acc5-779cdf511ee7,DISK], DatanodeInfoWithStorage[127.0.0.1:44921,DS-349147aa-572e-4bb0-89e3-70460762b7e3,DISK], DatanodeInfoWithStorage[127.0.0.1:38785,DS-3aaaa28f-1e6a-43f2-b67d-0aef17e51579,DISK], DatanodeInfoWithStorage[127.0.0.1:35171,DS-3cbc15d2-2e36-40f0-965b-c2f407e47c50,DISK], DatanodeInfoWithStorage[127.0.0.1:42092,DS-87371bd7-445c-4580-9059-948b7508e662,DISK], DatanodeInfoWithStorage[127.0.0.1:37377,DS-b5fab7e2-a5ce-449c-8f4e-496acfab5008,DISK], DatanodeInfoWithStorage[127.0.0.1:46428,DS-ef8d01b7-bfe7-476c-be30-da38b08380b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1523740019-172.17.0.15-1598456058262:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35395,DS-943456c0-bcfb-45f7-9c6f-2ac5d9df4583,DISK], DatanodeInfoWithStorage[127.0.0.1:39970,DS-b7587d04-0e5d-4e8b-acc5-779cdf511ee7,DISK], DatanodeInfoWithStorage[127.0.0.1:44921,DS-349147aa-572e-4bb0-89e3-70460762b7e3,DISK], DatanodeInfoWithStorage[127.0.0.1:38785,DS-3aaaa28f-1e6a-43f2-b67d-0aef17e51579,DISK], DatanodeInfoWithStorage[127.0.0.1:35171,DS-3cbc15d2-2e36-40f0-965b-c2f407e47c50,DISK], DatanodeInfoWithStorage[127.0.0.1:42092,DS-87371bd7-445c-4580-9059-948b7508e662,DISK], DatanodeInfoWithStorage[127.0.0.1:37377,DS-b5fab7e2-a5ce-449c-8f4e-496acfab5008,DISK], DatanodeInfoWithStorage[127.0.0.1:46428,DS-ef8d01b7-bfe7-476c-be30-da38b08380b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1258173408-172.17.0.15-1598456361748:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33708,DS-a97c6b20-2168-4289-bd75-bff06d9f82b7,DISK], DatanodeInfoWithStorage[127.0.0.1:42796,DS-12dbcc9a-e3c5-42ae-a830-02211c778b34,DISK], DatanodeInfoWithStorage[127.0.0.1:43235,DS-935e86ba-c296-4916-b32e-d55e4c94b2ea,DISK], DatanodeInfoWithStorage[127.0.0.1:36841,DS-13aa23b1-e639-4b77-8e37-6c0b7bc55b47,DISK], DatanodeInfoWithStorage[127.0.0.1:33815,DS-7ae55ee0-2a1b-4f70-98aa-7ff2a8d6f57a,DISK], DatanodeInfoWithStorage[127.0.0.1:46648,DS-1f4ce98a-3d87-4842-95b8-330b37011d4e,DISK], DatanodeInfoWithStorage[127.0.0.1:34969,DS-bd2cf202-2fa4-49fc-bacc-3fc6fb9cb710,DISK], DatanodeInfoWithStorage[127.0.0.1:43377,DS-158f31cc-dd21-43f1-bf57-016676b0a362,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1258173408-172.17.0.15-1598456361748:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33708,DS-a97c6b20-2168-4289-bd75-bff06d9f82b7,DISK], DatanodeInfoWithStorage[127.0.0.1:42796,DS-12dbcc9a-e3c5-42ae-a830-02211c778b34,DISK], DatanodeInfoWithStorage[127.0.0.1:43235,DS-935e86ba-c296-4916-b32e-d55e4c94b2ea,DISK], DatanodeInfoWithStorage[127.0.0.1:36841,DS-13aa23b1-e639-4b77-8e37-6c0b7bc55b47,DISK], DatanodeInfoWithStorage[127.0.0.1:33815,DS-7ae55ee0-2a1b-4f70-98aa-7ff2a8d6f57a,DISK], DatanodeInfoWithStorage[127.0.0.1:46648,DS-1f4ce98a-3d87-4842-95b8-330b37011d4e,DISK], DatanodeInfoWithStorage[127.0.0.1:34969,DS-bd2cf202-2fa4-49fc-bacc-3fc6fb9cb710,DISK], DatanodeInfoWithStorage[127.0.0.1:43377,DS-158f31cc-dd21-43f1-bf57-016676b0a362,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1642691556-172.17.0.15-1598457320768:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34420,DS-12f5ab86-b870-44cc-8c9c-b3ea93c6b333,DISK], DatanodeInfoWithStorage[127.0.0.1:42831,DS-8b0b6a11-353e-4063-8b9d-205eb6b46107,DISK], DatanodeInfoWithStorage[127.0.0.1:35860,DS-d55ac129-10c3-46a7-95bb-de5ce7b69aab,DISK], DatanodeInfoWithStorage[127.0.0.1:43693,DS-7e79c3d2-b9f2-4500-8460-3dfdc11ed755,DISK], DatanodeInfoWithStorage[127.0.0.1:43415,DS-5820bab1-8d6f-4618-8ebb-c3d7db51a1ef,DISK], DatanodeInfoWithStorage[127.0.0.1:39451,DS-c2969e33-45e0-437f-a405-9316a6b4ecd0,DISK], DatanodeInfoWithStorage[127.0.0.1:42804,DS-d3b3b0dd-4e68-467c-bf2e-6a0c6685e1cb,DISK], DatanodeInfoWithStorage[127.0.0.1:35742,DS-3f05973f-8a2b-4b92-a892-d4067c2ab348,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1642691556-172.17.0.15-1598457320768:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34420,DS-12f5ab86-b870-44cc-8c9c-b3ea93c6b333,DISK], DatanodeInfoWithStorage[127.0.0.1:42831,DS-8b0b6a11-353e-4063-8b9d-205eb6b46107,DISK], DatanodeInfoWithStorage[127.0.0.1:35860,DS-d55ac129-10c3-46a7-95bb-de5ce7b69aab,DISK], DatanodeInfoWithStorage[127.0.0.1:43693,DS-7e79c3d2-b9f2-4500-8460-3dfdc11ed755,DISK], DatanodeInfoWithStorage[127.0.0.1:43415,DS-5820bab1-8d6f-4618-8ebb-c3d7db51a1ef,DISK], DatanodeInfoWithStorage[127.0.0.1:39451,DS-c2969e33-45e0-437f-a405-9316a6b4ecd0,DISK], DatanodeInfoWithStorage[127.0.0.1:42804,DS-d3b3b0dd-4e68-467c-bf2e-6a0c6685e1cb,DISK], DatanodeInfoWithStorage[127.0.0.1:35742,DS-3f05973f-8a2b-4b92-a892-d4067c2ab348,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-761222597-172.17.0.15-1598457881292:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41711,DS-1f25df46-7f68-4b76-9872-1ad22644bc6f,DISK], DatanodeInfoWithStorage[127.0.0.1:35308,DS-cc21926c-134d-4a29-a7eb-0b7a32f24294,DISK], DatanodeInfoWithStorage[127.0.0.1:43409,DS-2f0bccee-98a4-400e-989b-70dc54bd0b6e,DISK], DatanodeInfoWithStorage[127.0.0.1:41583,DS-385ef8cf-ffac-482c-8313-839c0fc4986d,DISK], DatanodeInfoWithStorage[127.0.0.1:35217,DS-463ded2c-a4fb-4e12-85ce-50b512aeb01e,DISK], DatanodeInfoWithStorage[127.0.0.1:39514,DS-b7395b12-69e9-43e2-abce-ede67991fdcc,DISK], DatanodeInfoWithStorage[127.0.0.1:40242,DS-f8dcea95-57a7-4eef-96ea-3d76411135c4,DISK], DatanodeInfoWithStorage[127.0.0.1:45865,DS-db2748aa-ab71-4877-9ccc-365ff690d7ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-761222597-172.17.0.15-1598457881292:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41711,DS-1f25df46-7f68-4b76-9872-1ad22644bc6f,DISK], DatanodeInfoWithStorage[127.0.0.1:35308,DS-cc21926c-134d-4a29-a7eb-0b7a32f24294,DISK], DatanodeInfoWithStorage[127.0.0.1:43409,DS-2f0bccee-98a4-400e-989b-70dc54bd0b6e,DISK], DatanodeInfoWithStorage[127.0.0.1:41583,DS-385ef8cf-ffac-482c-8313-839c0fc4986d,DISK], DatanodeInfoWithStorage[127.0.0.1:35217,DS-463ded2c-a4fb-4e12-85ce-50b512aeb01e,DISK], DatanodeInfoWithStorage[127.0.0.1:39514,DS-b7395b12-69e9-43e2-abce-ede67991fdcc,DISK], DatanodeInfoWithStorage[127.0.0.1:40242,DS-f8dcea95-57a7-4eef-96ea-3d76411135c4,DISK], DatanodeInfoWithStorage[127.0.0.1:45865,DS-db2748aa-ab71-4877-9ccc-365ff690d7ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1997953195-172.17.0.15-1598458901077:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34601,DS-3af67d05-6f13-4396-88e5-ac2fa276305a,DISK], DatanodeInfoWithStorage[127.0.0.1:37161,DS-260414d7-2eb4-4aa4-b619-490895b8001c,DISK], DatanodeInfoWithStorage[127.0.0.1:46198,DS-5a778ba0-5cad-4e2c-a988-065923440a15,DISK], DatanodeInfoWithStorage[127.0.0.1:39622,DS-3b777dda-4d74-4bbd-b527-54d1ee9c8a5e,DISK], DatanodeInfoWithStorage[127.0.0.1:45796,DS-0328a3e7-cd88-4410-8c8d-a224b09b315b,DISK], DatanodeInfoWithStorage[127.0.0.1:33958,DS-708dc40a-98ca-4781-8bd4-77f274cc8d70,DISK], DatanodeInfoWithStorage[127.0.0.1:43365,DS-56a8a2ad-925d-4389-9297-a4381375f54c,DISK], DatanodeInfoWithStorage[127.0.0.1:33663,DS-c05a0997-c67e-41aa-8b83-b5ebbb1e8b37,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1997953195-172.17.0.15-1598458901077:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34601,DS-3af67d05-6f13-4396-88e5-ac2fa276305a,DISK], DatanodeInfoWithStorage[127.0.0.1:37161,DS-260414d7-2eb4-4aa4-b619-490895b8001c,DISK], DatanodeInfoWithStorage[127.0.0.1:46198,DS-5a778ba0-5cad-4e2c-a988-065923440a15,DISK], DatanodeInfoWithStorage[127.0.0.1:39622,DS-3b777dda-4d74-4bbd-b527-54d1ee9c8a5e,DISK], DatanodeInfoWithStorage[127.0.0.1:45796,DS-0328a3e7-cd88-4410-8c8d-a224b09b315b,DISK], DatanodeInfoWithStorage[127.0.0.1:33958,DS-708dc40a-98ca-4781-8bd4-77f274cc8d70,DISK], DatanodeInfoWithStorage[127.0.0.1:43365,DS-56a8a2ad-925d-4389-9297-a4381375f54c,DISK], DatanodeInfoWithStorage[127.0.0.1:33663,DS-c05a0997-c67e-41aa-8b83-b5ebbb1e8b37,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-289953173-172.17.0.15-1598459330498:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43110,DS-3bb3231d-f04b-4892-85d5-1b820c080d77,DISK], DatanodeInfoWithStorage[127.0.0.1:45303,DS-fc9a3a65-1d67-47d1-b0b2-c64f1a1203b4,DISK], DatanodeInfoWithStorage[127.0.0.1:46728,DS-8c3f1d4a-c0a3-4ee4-af7a-f84256e6f649,DISK], DatanodeInfoWithStorage[127.0.0.1:38221,DS-93675fd7-a488-4934-920f-ab572a338407,DISK], DatanodeInfoWithStorage[127.0.0.1:45936,DS-0959494f-36b7-4d56-99c0-d3e1e89b6815,DISK], DatanodeInfoWithStorage[127.0.0.1:38545,DS-aa2bf8f8-43fb-445e-82ef-be2f8b689af8,DISK], DatanodeInfoWithStorage[127.0.0.1:33801,DS-11ae04d9-6a7a-4b51-9718-2cc29aab938d,DISK], DatanodeInfoWithStorage[127.0.0.1:33307,DS-b25808b2-5ff4-43f7-95ca-3e53596224d9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-289953173-172.17.0.15-1598459330498:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43110,DS-3bb3231d-f04b-4892-85d5-1b820c080d77,DISK], DatanodeInfoWithStorage[127.0.0.1:45303,DS-fc9a3a65-1d67-47d1-b0b2-c64f1a1203b4,DISK], DatanodeInfoWithStorage[127.0.0.1:46728,DS-8c3f1d4a-c0a3-4ee4-af7a-f84256e6f649,DISK], DatanodeInfoWithStorage[127.0.0.1:38221,DS-93675fd7-a488-4934-920f-ab572a338407,DISK], DatanodeInfoWithStorage[127.0.0.1:45936,DS-0959494f-36b7-4d56-99c0-d3e1e89b6815,DISK], DatanodeInfoWithStorage[127.0.0.1:38545,DS-aa2bf8f8-43fb-445e-82ef-be2f8b689af8,DISK], DatanodeInfoWithStorage[127.0.0.1:33801,DS-11ae04d9-6a7a-4b51-9718-2cc29aab938d,DISK], DatanodeInfoWithStorage[127.0.0.1:33307,DS-b25808b2-5ff4-43f7-95ca-3e53596224d9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-314227898-172.17.0.15-1598459369930:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45825,DS-ad6a198a-d9da-48f8-97a8-db52a2c232c4,DISK], DatanodeInfoWithStorage[127.0.0.1:34021,DS-eaa03e94-9227-43c4-a637-d06ab61b4373,DISK], DatanodeInfoWithStorage[127.0.0.1:37062,DS-6900b325-b167-4f78-863b-c942d667dc90,DISK], DatanodeInfoWithStorage[127.0.0.1:36499,DS-ca2dc592-5d14-47e8-833b-bed28bb26b16,DISK], DatanodeInfoWithStorage[127.0.0.1:39028,DS-af1cfe05-2c39-4cd8-9187-3e6bf4fada2e,DISK], DatanodeInfoWithStorage[127.0.0.1:39903,DS-3090e9b0-f0cb-4601-aa1a-01c654be71b4,DISK], DatanodeInfoWithStorage[127.0.0.1:33987,DS-185da8fc-0b71-4d04-9399-bcb13125040b,DISK], DatanodeInfoWithStorage[127.0.0.1:37380,DS-c8e1e936-47c7-4bf3-8e17-a413d41bea79,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-314227898-172.17.0.15-1598459369930:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45825,DS-ad6a198a-d9da-48f8-97a8-db52a2c232c4,DISK], DatanodeInfoWithStorage[127.0.0.1:34021,DS-eaa03e94-9227-43c4-a637-d06ab61b4373,DISK], DatanodeInfoWithStorage[127.0.0.1:37062,DS-6900b325-b167-4f78-863b-c942d667dc90,DISK], DatanodeInfoWithStorage[127.0.0.1:36499,DS-ca2dc592-5d14-47e8-833b-bed28bb26b16,DISK], DatanodeInfoWithStorage[127.0.0.1:39028,DS-af1cfe05-2c39-4cd8-9187-3e6bf4fada2e,DISK], DatanodeInfoWithStorage[127.0.0.1:39903,DS-3090e9b0-f0cb-4601-aa1a-01c654be71b4,DISK], DatanodeInfoWithStorage[127.0.0.1:33987,DS-185da8fc-0b71-4d04-9399-bcb13125040b,DISK], DatanodeInfoWithStorage[127.0.0.1:37380,DS-c8e1e936-47c7-4bf3-8e17-a413d41bea79,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5344
