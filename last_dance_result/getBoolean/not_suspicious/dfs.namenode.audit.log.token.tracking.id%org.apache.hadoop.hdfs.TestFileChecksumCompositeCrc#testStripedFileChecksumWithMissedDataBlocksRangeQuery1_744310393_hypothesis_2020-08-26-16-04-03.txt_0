reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-99860881-172.17.0.4-1598458444768:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41055,DS-a9da15e1-1633-4d0e-9435-4204b4f49060,DISK], DatanodeInfoWithStorage[127.0.0.1:32788,DS-79f66569-2e57-4095-87ed-ac8c187fdbad,DISK], DatanodeInfoWithStorage[127.0.0.1:40164,DS-c1c2e901-5bcc-47e5-bd87-d7cc004d1c55,DISK], DatanodeInfoWithStorage[127.0.0.1:46204,DS-a9e45f35-fc64-4169-9950-40b9e9e707e2,DISK], DatanodeInfoWithStorage[127.0.0.1:42375,DS-c3b1f431-bb30-43ed-b87e-5a0ea4d2581c,DISK], DatanodeInfoWithStorage[127.0.0.1:37205,DS-0c139c76-c0c2-4c65-bf50-509105b6e861,DISK], DatanodeInfoWithStorage[127.0.0.1:42780,DS-9636157b-14ad-4ca8-b4e6-87a2f77f2bcf,DISK], DatanodeInfoWithStorage[127.0.0.1:37267,DS-8ba142fd-e060-4166-b30b-45a8068e4090,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-99860881-172.17.0.4-1598458444768:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41055,DS-a9da15e1-1633-4d0e-9435-4204b4f49060,DISK], DatanodeInfoWithStorage[127.0.0.1:32788,DS-79f66569-2e57-4095-87ed-ac8c187fdbad,DISK], DatanodeInfoWithStorage[127.0.0.1:40164,DS-c1c2e901-5bcc-47e5-bd87-d7cc004d1c55,DISK], DatanodeInfoWithStorage[127.0.0.1:46204,DS-a9e45f35-fc64-4169-9950-40b9e9e707e2,DISK], DatanodeInfoWithStorage[127.0.0.1:42375,DS-c3b1f431-bb30-43ed-b87e-5a0ea4d2581c,DISK], DatanodeInfoWithStorage[127.0.0.1:37205,DS-0c139c76-c0c2-4c65-bf50-509105b6e861,DISK], DatanodeInfoWithStorage[127.0.0.1:42780,DS-9636157b-14ad-4ca8-b4e6-87a2f77f2bcf,DISK], DatanodeInfoWithStorage[127.0.0.1:37267,DS-8ba142fd-e060-4166-b30b-45a8068e4090,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1383516702-172.17.0.4-1598458477119:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37413,DS-93aa5f6a-3deb-4ae7-9b96-e25b962a8b4b,DISK], DatanodeInfoWithStorage[127.0.0.1:40446,DS-a7805942-98c1-4302-be43-57d669a6bcce,DISK], DatanodeInfoWithStorage[127.0.0.1:43795,DS-0dce7cc9-e62b-490f-9bae-b08c490a72bf,DISK], DatanodeInfoWithStorage[127.0.0.1:40596,DS-ae3a4f18-3890-40db-83fb-47a5da310c5b,DISK], DatanodeInfoWithStorage[127.0.0.1:43339,DS-ec00885c-0afd-4363-9fea-50beb7eed03a,DISK], DatanodeInfoWithStorage[127.0.0.1:33781,DS-d7b88d86-e3bb-4d58-9342-5b86cd5ff551,DISK], DatanodeInfoWithStorage[127.0.0.1:42874,DS-b82ed055-371a-4d30-b326-bc52ccce0ec7,DISK], DatanodeInfoWithStorage[127.0.0.1:45273,DS-1235a2fa-47b3-403b-a3e6-9274e4006aca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1383516702-172.17.0.4-1598458477119:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37413,DS-93aa5f6a-3deb-4ae7-9b96-e25b962a8b4b,DISK], DatanodeInfoWithStorage[127.0.0.1:40446,DS-a7805942-98c1-4302-be43-57d669a6bcce,DISK], DatanodeInfoWithStorage[127.0.0.1:43795,DS-0dce7cc9-e62b-490f-9bae-b08c490a72bf,DISK], DatanodeInfoWithStorage[127.0.0.1:40596,DS-ae3a4f18-3890-40db-83fb-47a5da310c5b,DISK], DatanodeInfoWithStorage[127.0.0.1:43339,DS-ec00885c-0afd-4363-9fea-50beb7eed03a,DISK], DatanodeInfoWithStorage[127.0.0.1:33781,DS-d7b88d86-e3bb-4d58-9342-5b86cd5ff551,DISK], DatanodeInfoWithStorage[127.0.0.1:42874,DS-b82ed055-371a-4d30-b326-bc52ccce0ec7,DISK], DatanodeInfoWithStorage[127.0.0.1:45273,DS-1235a2fa-47b3-403b-a3e6-9274e4006aca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1718403157-172.17.0.4-1598458545617:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33625,DS-52ec58d3-ad50-4b36-89d1-07484adc004e,DISK], DatanodeInfoWithStorage[127.0.0.1:41799,DS-692088d8-22a4-4896-9fe8-42947b8fc49a,DISK], DatanodeInfoWithStorage[127.0.0.1:35950,DS-f60ec4d5-9c6f-490e-a97b-bc2cd3f64377,DISK], DatanodeInfoWithStorage[127.0.0.1:40145,DS-ba0a4855-7c8e-4dc7-941b-6e6e7baf88d8,DISK], DatanodeInfoWithStorage[127.0.0.1:40026,DS-dd7e59f7-f408-4bb5-a4e5-c0a48a87b284,DISK], DatanodeInfoWithStorage[127.0.0.1:36254,DS-9b557eb6-2a89-4eb4-8dc7-7928253ff533,DISK], DatanodeInfoWithStorage[127.0.0.1:45214,DS-835c037b-7dd1-4075-974f-b7df6aad57da,DISK], DatanodeInfoWithStorage[127.0.0.1:46399,DS-432c487f-5a98-40c5-baf6-d8547729a69d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1718403157-172.17.0.4-1598458545617:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33625,DS-52ec58d3-ad50-4b36-89d1-07484adc004e,DISK], DatanodeInfoWithStorage[127.0.0.1:41799,DS-692088d8-22a4-4896-9fe8-42947b8fc49a,DISK], DatanodeInfoWithStorage[127.0.0.1:35950,DS-f60ec4d5-9c6f-490e-a97b-bc2cd3f64377,DISK], DatanodeInfoWithStorage[127.0.0.1:40145,DS-ba0a4855-7c8e-4dc7-941b-6e6e7baf88d8,DISK], DatanodeInfoWithStorage[127.0.0.1:40026,DS-dd7e59f7-f408-4bb5-a4e5-c0a48a87b284,DISK], DatanodeInfoWithStorage[127.0.0.1:36254,DS-9b557eb6-2a89-4eb4-8dc7-7928253ff533,DISK], DatanodeInfoWithStorage[127.0.0.1:45214,DS-835c037b-7dd1-4075-974f-b7df6aad57da,DISK], DatanodeInfoWithStorage[127.0.0.1:46399,DS-432c487f-5a98-40c5-baf6-d8547729a69d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2008014894-172.17.0.4-1598458616968:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44944,DS-7eee57a9-e56e-450a-bd26-e975dccbd0ad,DISK], DatanodeInfoWithStorage[127.0.0.1:40226,DS-47e678cf-69ef-4118-817c-6960989f45dd,DISK], DatanodeInfoWithStorage[127.0.0.1:33344,DS-e39fea5b-b7cc-4b05-bc23-defb48631c1e,DISK], DatanodeInfoWithStorage[127.0.0.1:43341,DS-31d6e031-ae07-4e5c-8a5c-22c2dbcbafe4,DISK], DatanodeInfoWithStorage[127.0.0.1:40870,DS-9fa3d72b-0d88-4ad6-8bd7-6f98718eaabb,DISK], DatanodeInfoWithStorage[127.0.0.1:40904,DS-08efaff2-ba37-4993-8699-30f17e93b2dd,DISK], DatanodeInfoWithStorage[127.0.0.1:45411,DS-5652c3be-51b7-4689-acb7-911e6ca0eaee,DISK], DatanodeInfoWithStorage[127.0.0.1:42212,DS-abd60574-6742-4948-b4f2-8091af554504,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2008014894-172.17.0.4-1598458616968:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44944,DS-7eee57a9-e56e-450a-bd26-e975dccbd0ad,DISK], DatanodeInfoWithStorage[127.0.0.1:40226,DS-47e678cf-69ef-4118-817c-6960989f45dd,DISK], DatanodeInfoWithStorage[127.0.0.1:33344,DS-e39fea5b-b7cc-4b05-bc23-defb48631c1e,DISK], DatanodeInfoWithStorage[127.0.0.1:43341,DS-31d6e031-ae07-4e5c-8a5c-22c2dbcbafe4,DISK], DatanodeInfoWithStorage[127.0.0.1:40870,DS-9fa3d72b-0d88-4ad6-8bd7-6f98718eaabb,DISK], DatanodeInfoWithStorage[127.0.0.1:40904,DS-08efaff2-ba37-4993-8699-30f17e93b2dd,DISK], DatanodeInfoWithStorage[127.0.0.1:45411,DS-5652c3be-51b7-4689-acb7-911e6ca0eaee,DISK], DatanodeInfoWithStorage[127.0.0.1:42212,DS-abd60574-6742-4948-b4f2-8091af554504,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1096049512-172.17.0.4-1598458654042:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42240,DS-3f36d358-cf67-43cc-9943-1a46da29cceb,DISK], DatanodeInfoWithStorage[127.0.0.1:39147,DS-e704887d-dd19-4ecd-90ee-1fabfcf3778c,DISK], DatanodeInfoWithStorage[127.0.0.1:45794,DS-07c10b53-7794-483e-9edb-c8eca690e898,DISK], DatanodeInfoWithStorage[127.0.0.1:38006,DS-f21a8a84-6d33-47dc-a921-0f3feaf55246,DISK], DatanodeInfoWithStorage[127.0.0.1:34139,DS-4cb57ef0-2f6b-4bb9-ade0-c5518d457b9b,DISK], DatanodeInfoWithStorage[127.0.0.1:43582,DS-b4ab2d0e-ec37-4782-9846-2d030bf21288,DISK], DatanodeInfoWithStorage[127.0.0.1:44628,DS-a0760605-4d22-4a47-aaaa-6bfce9968cd6,DISK], DatanodeInfoWithStorage[127.0.0.1:36812,DS-320b964d-89df-4050-b9f0-45d5940b8363,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1096049512-172.17.0.4-1598458654042:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42240,DS-3f36d358-cf67-43cc-9943-1a46da29cceb,DISK], DatanodeInfoWithStorage[127.0.0.1:39147,DS-e704887d-dd19-4ecd-90ee-1fabfcf3778c,DISK], DatanodeInfoWithStorage[127.0.0.1:45794,DS-07c10b53-7794-483e-9edb-c8eca690e898,DISK], DatanodeInfoWithStorage[127.0.0.1:38006,DS-f21a8a84-6d33-47dc-a921-0f3feaf55246,DISK], DatanodeInfoWithStorage[127.0.0.1:34139,DS-4cb57ef0-2f6b-4bb9-ade0-c5518d457b9b,DISK], DatanodeInfoWithStorage[127.0.0.1:43582,DS-b4ab2d0e-ec37-4782-9846-2d030bf21288,DISK], DatanodeInfoWithStorage[127.0.0.1:44628,DS-a0760605-4d22-4a47-aaaa-6bfce9968cd6,DISK], DatanodeInfoWithStorage[127.0.0.1:36812,DS-320b964d-89df-4050-b9f0-45d5940b8363,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-413493710-172.17.0.4-1598458948985:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39566,DS-ad971cf0-d5ea-4b06-8649-0fd53b443251,DISK], DatanodeInfoWithStorage[127.0.0.1:45731,DS-ba341611-09ec-4c34-8872-fb7ab9972d41,DISK], DatanodeInfoWithStorage[127.0.0.1:39941,DS-0a85e26f-ff9f-4d6b-9ab7-55d832c1cc5e,DISK], DatanodeInfoWithStorage[127.0.0.1:44275,DS-2aeac137-04b8-4c0f-8bc1-71958c45461c,DISK], DatanodeInfoWithStorage[127.0.0.1:32782,DS-de9e58e0-d63c-40f6-a89f-1651b94bc2cc,DISK], DatanodeInfoWithStorage[127.0.0.1:37005,DS-8b01499f-e2e3-4a4f-b5d1-19409747e463,DISK], DatanodeInfoWithStorage[127.0.0.1:35001,DS-cc3b328b-6f84-4efe-b277-e70117907297,DISK], DatanodeInfoWithStorage[127.0.0.1:33572,DS-1e5ad793-4e0b-4bb1-ac35-e5fc7fea9935,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-413493710-172.17.0.4-1598458948985:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39566,DS-ad971cf0-d5ea-4b06-8649-0fd53b443251,DISK], DatanodeInfoWithStorage[127.0.0.1:45731,DS-ba341611-09ec-4c34-8872-fb7ab9972d41,DISK], DatanodeInfoWithStorage[127.0.0.1:39941,DS-0a85e26f-ff9f-4d6b-9ab7-55d832c1cc5e,DISK], DatanodeInfoWithStorage[127.0.0.1:44275,DS-2aeac137-04b8-4c0f-8bc1-71958c45461c,DISK], DatanodeInfoWithStorage[127.0.0.1:32782,DS-de9e58e0-d63c-40f6-a89f-1651b94bc2cc,DISK], DatanodeInfoWithStorage[127.0.0.1:37005,DS-8b01499f-e2e3-4a4f-b5d1-19409747e463,DISK], DatanodeInfoWithStorage[127.0.0.1:35001,DS-cc3b328b-6f84-4efe-b277-e70117907297,DISK], DatanodeInfoWithStorage[127.0.0.1:33572,DS-1e5ad793-4e0b-4bb1-ac35-e5fc7fea9935,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1469030980-172.17.0.4-1598459057448:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46392,DS-4a8859f8-1bbc-4edd-95ef-be1b4e957333,DISK], DatanodeInfoWithStorage[127.0.0.1:36572,DS-9b805f2c-03d0-471f-9d2c-2fb3ecebed1a,DISK], DatanodeInfoWithStorage[127.0.0.1:36328,DS-b9d4d315-ab55-4a79-a30d-a41b073b113f,DISK], DatanodeInfoWithStorage[127.0.0.1:44727,DS-912802ca-65fc-4019-8929-8522451d4920,DISK], DatanodeInfoWithStorage[127.0.0.1:35162,DS-59d40d6e-04d8-416f-93bc-22731c603f91,DISK], DatanodeInfoWithStorage[127.0.0.1:43176,DS-0daa3c68-12a6-4d3c-8533-599d42bb7f26,DISK], DatanodeInfoWithStorage[127.0.0.1:40779,DS-7c7f441b-1c3c-43f5-9004-4fcf0f3a1c51,DISK], DatanodeInfoWithStorage[127.0.0.1:44230,DS-625a7365-8340-4faf-94ba-1a0102f77460,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1469030980-172.17.0.4-1598459057448:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46392,DS-4a8859f8-1bbc-4edd-95ef-be1b4e957333,DISK], DatanodeInfoWithStorage[127.0.0.1:36572,DS-9b805f2c-03d0-471f-9d2c-2fb3ecebed1a,DISK], DatanodeInfoWithStorage[127.0.0.1:36328,DS-b9d4d315-ab55-4a79-a30d-a41b073b113f,DISK], DatanodeInfoWithStorage[127.0.0.1:44727,DS-912802ca-65fc-4019-8929-8522451d4920,DISK], DatanodeInfoWithStorage[127.0.0.1:35162,DS-59d40d6e-04d8-416f-93bc-22731c603f91,DISK], DatanodeInfoWithStorage[127.0.0.1:43176,DS-0daa3c68-12a6-4d3c-8533-599d42bb7f26,DISK], DatanodeInfoWithStorage[127.0.0.1:40779,DS-7c7f441b-1c3c-43f5-9004-4fcf0f3a1c51,DISK], DatanodeInfoWithStorage[127.0.0.1:44230,DS-625a7365-8340-4faf-94ba-1a0102f77460,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-626033593-172.17.0.4-1598459230170:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33788,DS-c136413c-c8f2-49fc-8cd1-16fb33ad0dd6,DISK], DatanodeInfoWithStorage[127.0.0.1:42502,DS-5c9e81bc-c5f7-40a2-8bb8-89c2c0048da1,DISK], DatanodeInfoWithStorage[127.0.0.1:38974,DS-f4845872-a143-461e-a448-9c8323f31542,DISK], DatanodeInfoWithStorage[127.0.0.1:39942,DS-20aea22d-a104-47dd-b76f-517a054ce7c3,DISK], DatanodeInfoWithStorage[127.0.0.1:42253,DS-31f86793-7420-4dbf-ab00-780501d1e301,DISK], DatanodeInfoWithStorage[127.0.0.1:45363,DS-286eba7f-0e92-4255-b911-d1622a1db134,DISK], DatanodeInfoWithStorage[127.0.0.1:36090,DS-ab2e2a48-c045-4f6b-8952-4530f53c7ced,DISK], DatanodeInfoWithStorage[127.0.0.1:43175,DS-cf0dd94d-53b8-4397-9946-5ce6433a3c91,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-626033593-172.17.0.4-1598459230170:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33788,DS-c136413c-c8f2-49fc-8cd1-16fb33ad0dd6,DISK], DatanodeInfoWithStorage[127.0.0.1:42502,DS-5c9e81bc-c5f7-40a2-8bb8-89c2c0048da1,DISK], DatanodeInfoWithStorage[127.0.0.1:38974,DS-f4845872-a143-461e-a448-9c8323f31542,DISK], DatanodeInfoWithStorage[127.0.0.1:39942,DS-20aea22d-a104-47dd-b76f-517a054ce7c3,DISK], DatanodeInfoWithStorage[127.0.0.1:42253,DS-31f86793-7420-4dbf-ab00-780501d1e301,DISK], DatanodeInfoWithStorage[127.0.0.1:45363,DS-286eba7f-0e92-4255-b911-d1622a1db134,DISK], DatanodeInfoWithStorage[127.0.0.1:36090,DS-ab2e2a48-c045-4f6b-8952-4530f53c7ced,DISK], DatanodeInfoWithStorage[127.0.0.1:43175,DS-cf0dd94d-53b8-4397-9946-5ce6433a3c91,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-885548716-172.17.0.4-1598459461457:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37433,DS-66258be4-6f65-44a8-b989-c91acc4b6917,DISK], DatanodeInfoWithStorage[127.0.0.1:42923,DS-c189d16b-ee71-4719-9997-30eec75e8584,DISK], DatanodeInfoWithStorage[127.0.0.1:38400,DS-d937fb15-09ff-4cd7-8dde-7ce0f69564e2,DISK], DatanodeInfoWithStorage[127.0.0.1:46836,DS-decb4795-84e1-4fac-b83a-d56786d4ba36,DISK], DatanodeInfoWithStorage[127.0.0.1:44666,DS-b4744be7-a7b6-47a8-b7c7-0a80728391b1,DISK], DatanodeInfoWithStorage[127.0.0.1:46431,DS-e204b863-e4b4-44bc-a08e-54276c9122aa,DISK], DatanodeInfoWithStorage[127.0.0.1:41337,DS-6af49ca0-f6f6-43d2-bb99-1db7774b843a,DISK], DatanodeInfoWithStorage[127.0.0.1:43817,DS-da508e38-7e9e-4302-9b34-8c9f76d7a522,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-885548716-172.17.0.4-1598459461457:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37433,DS-66258be4-6f65-44a8-b989-c91acc4b6917,DISK], DatanodeInfoWithStorage[127.0.0.1:42923,DS-c189d16b-ee71-4719-9997-30eec75e8584,DISK], DatanodeInfoWithStorage[127.0.0.1:38400,DS-d937fb15-09ff-4cd7-8dde-7ce0f69564e2,DISK], DatanodeInfoWithStorage[127.0.0.1:46836,DS-decb4795-84e1-4fac-b83a-d56786d4ba36,DISK], DatanodeInfoWithStorage[127.0.0.1:44666,DS-b4744be7-a7b6-47a8-b7c7-0a80728391b1,DISK], DatanodeInfoWithStorage[127.0.0.1:46431,DS-e204b863-e4b4-44bc-a08e-54276c9122aa,DISK], DatanodeInfoWithStorage[127.0.0.1:41337,DS-6af49ca0-f6f6-43d2-bb99-1db7774b843a,DISK], DatanodeInfoWithStorage[127.0.0.1:43817,DS-da508e38-7e9e-4302-9b34-8c9f76d7a522,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-796496713-172.17.0.4-1598460340863:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33203,DS-b914c043-7622-417b-a491-d040dd839f05,DISK], DatanodeInfoWithStorage[127.0.0.1:37811,DS-c6234b30-cd11-48d5-9793-6fa6da23d387,DISK], DatanodeInfoWithStorage[127.0.0.1:46678,DS-2ad5587f-1d81-4c53-82ad-3e62d689dcda,DISK], DatanodeInfoWithStorage[127.0.0.1:42985,DS-82ea0aba-d462-4355-a198-57f41b0c9d95,DISK], DatanodeInfoWithStorage[127.0.0.1:38757,DS-87fb32ad-60ea-4404-a993-597eab775262,DISK], DatanodeInfoWithStorage[127.0.0.1:35668,DS-39a8b1ed-1e9e-444a-8518-0e17d2e806d5,DISK], DatanodeInfoWithStorage[127.0.0.1:45086,DS-b25ef1a5-5d39-458e-9288-09a3e2f95002,DISK], DatanodeInfoWithStorage[127.0.0.1:41370,DS-e6fccb03-c16e-4b94-89bf-fc51417100c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-796496713-172.17.0.4-1598460340863:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33203,DS-b914c043-7622-417b-a491-d040dd839f05,DISK], DatanodeInfoWithStorage[127.0.0.1:37811,DS-c6234b30-cd11-48d5-9793-6fa6da23d387,DISK], DatanodeInfoWithStorage[127.0.0.1:46678,DS-2ad5587f-1d81-4c53-82ad-3e62d689dcda,DISK], DatanodeInfoWithStorage[127.0.0.1:42985,DS-82ea0aba-d462-4355-a198-57f41b0c9d95,DISK], DatanodeInfoWithStorage[127.0.0.1:38757,DS-87fb32ad-60ea-4404-a993-597eab775262,DISK], DatanodeInfoWithStorage[127.0.0.1:35668,DS-39a8b1ed-1e9e-444a-8518-0e17d2e806d5,DISK], DatanodeInfoWithStorage[127.0.0.1:45086,DS-b25ef1a5-5d39-458e-9288-09a3e2f95002,DISK], DatanodeInfoWithStorage[127.0.0.1:41370,DS-e6fccb03-c16e-4b94-89bf-fc51417100c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1271216717-172.17.0.4-1598460708341:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35452,DS-89fcd9ab-73ed-4783-b31c-b28c1917c871,DISK], DatanodeInfoWithStorage[127.0.0.1:45866,DS-5a6feec4-460a-4e84-8ab7-70203c9a19a3,DISK], DatanodeInfoWithStorage[127.0.0.1:37222,DS-e1f975cf-579b-4dee-ab3f-fdd3089f2227,DISK], DatanodeInfoWithStorage[127.0.0.1:40932,DS-ce80cda4-263e-461c-b64e-24de185a37bc,DISK], DatanodeInfoWithStorage[127.0.0.1:44459,DS-45f4ac9b-1e46-4ff8-b5e5-3c4c7d87b653,DISK], DatanodeInfoWithStorage[127.0.0.1:37670,DS-0fc164dc-9a11-4797-94ad-0623d8f66bdc,DISK], DatanodeInfoWithStorage[127.0.0.1:42448,DS-303d359e-387f-423d-9ae3-9affd4187c62,DISK], DatanodeInfoWithStorage[127.0.0.1:40884,DS-a461e797-e9ee-4b6b-9bcc-5ed2850df2f8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1271216717-172.17.0.4-1598460708341:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35452,DS-89fcd9ab-73ed-4783-b31c-b28c1917c871,DISK], DatanodeInfoWithStorage[127.0.0.1:45866,DS-5a6feec4-460a-4e84-8ab7-70203c9a19a3,DISK], DatanodeInfoWithStorage[127.0.0.1:37222,DS-e1f975cf-579b-4dee-ab3f-fdd3089f2227,DISK], DatanodeInfoWithStorage[127.0.0.1:40932,DS-ce80cda4-263e-461c-b64e-24de185a37bc,DISK], DatanodeInfoWithStorage[127.0.0.1:44459,DS-45f4ac9b-1e46-4ff8-b5e5-3c4c7d87b653,DISK], DatanodeInfoWithStorage[127.0.0.1:37670,DS-0fc164dc-9a11-4797-94ad-0623d8f66bdc,DISK], DatanodeInfoWithStorage[127.0.0.1:42448,DS-303d359e-387f-423d-9ae3-9affd4187c62,DISK], DatanodeInfoWithStorage[127.0.0.1:40884,DS-a461e797-e9ee-4b6b-9bcc-5ed2850df2f8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1906950590-172.17.0.4-1598461191287:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43028,DS-63f4bf53-1efe-4887-9685-c1c988762ff7,DISK], DatanodeInfoWithStorage[127.0.0.1:38460,DS-d515af55-10d5-456c-9c1e-2d0f252ad07c,DISK], DatanodeInfoWithStorage[127.0.0.1:42171,DS-13bbcdf4-1379-4ac1-86b1-854403a776d0,DISK], DatanodeInfoWithStorage[127.0.0.1:38507,DS-728ed363-0d7c-4fee-9813-c1daff7aa157,DISK], DatanodeInfoWithStorage[127.0.0.1:38560,DS-191a87f8-4319-46d4-a220-a364f503e560,DISK], DatanodeInfoWithStorage[127.0.0.1:43332,DS-1a9b93fb-27b0-4f34-96c9-59bcd4bd193c,DISK], DatanodeInfoWithStorage[127.0.0.1:33628,DS-6021f1d3-ae1b-43a5-9837-b6a24ff467d8,DISK], DatanodeInfoWithStorage[127.0.0.1:39512,DS-12117f88-9ed0-45e2-aba4-b598cfe4cd5b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1906950590-172.17.0.4-1598461191287:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43028,DS-63f4bf53-1efe-4887-9685-c1c988762ff7,DISK], DatanodeInfoWithStorage[127.0.0.1:38460,DS-d515af55-10d5-456c-9c1e-2d0f252ad07c,DISK], DatanodeInfoWithStorage[127.0.0.1:42171,DS-13bbcdf4-1379-4ac1-86b1-854403a776d0,DISK], DatanodeInfoWithStorage[127.0.0.1:38507,DS-728ed363-0d7c-4fee-9813-c1daff7aa157,DISK], DatanodeInfoWithStorage[127.0.0.1:38560,DS-191a87f8-4319-46d4-a220-a364f503e560,DISK], DatanodeInfoWithStorage[127.0.0.1:43332,DS-1a9b93fb-27b0-4f34-96c9-59bcd4bd193c,DISK], DatanodeInfoWithStorage[127.0.0.1:33628,DS-6021f1d3-ae1b-43a5-9837-b6a24ff467d8,DISK], DatanodeInfoWithStorage[127.0.0.1:39512,DS-12117f88-9ed0-45e2-aba4-b598cfe4cd5b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1656252726-172.17.0.4-1598461226796:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34441,DS-eb645c6c-f10e-492e-9cff-ba763a9f9488,DISK], DatanodeInfoWithStorage[127.0.0.1:46395,DS-e68cd73f-3cba-4f13-928e-d3c23da1abb9,DISK], DatanodeInfoWithStorage[127.0.0.1:32948,DS-c1719bf7-48d2-4081-9006-5d440c5573b7,DISK], DatanodeInfoWithStorage[127.0.0.1:38197,DS-dd2e6d86-7917-404c-90ae-1986174d1d7f,DISK], DatanodeInfoWithStorage[127.0.0.1:39515,DS-c7d8c34a-a9f8-4832-8fad-c89f624ea625,DISK], DatanodeInfoWithStorage[127.0.0.1:46466,DS-fca532a1-5b20-405f-97b5-0b63cd309b79,DISK], DatanodeInfoWithStorage[127.0.0.1:41612,DS-0d8866be-1edb-4fa3-a0f9-0dc1f1d5ca2e,DISK], DatanodeInfoWithStorage[127.0.0.1:43040,DS-42f34bf3-9eb4-46b7-a811-672ab011a4ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1656252726-172.17.0.4-1598461226796:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34441,DS-eb645c6c-f10e-492e-9cff-ba763a9f9488,DISK], DatanodeInfoWithStorage[127.0.0.1:46395,DS-e68cd73f-3cba-4f13-928e-d3c23da1abb9,DISK], DatanodeInfoWithStorage[127.0.0.1:32948,DS-c1719bf7-48d2-4081-9006-5d440c5573b7,DISK], DatanodeInfoWithStorage[127.0.0.1:38197,DS-dd2e6d86-7917-404c-90ae-1986174d1d7f,DISK], DatanodeInfoWithStorage[127.0.0.1:39515,DS-c7d8c34a-a9f8-4832-8fad-c89f624ea625,DISK], DatanodeInfoWithStorage[127.0.0.1:46466,DS-fca532a1-5b20-405f-97b5-0b63cd309b79,DISK], DatanodeInfoWithStorage[127.0.0.1:41612,DS-0d8866be-1edb-4fa3-a0f9-0dc1f1d5ca2e,DISK], DatanodeInfoWithStorage[127.0.0.1:43040,DS-42f34bf3-9eb4-46b7-a811-672ab011a4ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1279672386-172.17.0.4-1598461616008:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41284,DS-72604410-a5fc-45d1-8485-da8f72e8fa03,DISK], DatanodeInfoWithStorage[127.0.0.1:35254,DS-02a4cdf5-ece4-4d36-bc9d-1b3af0488623,DISK], DatanodeInfoWithStorage[127.0.0.1:38982,DS-daa5992e-fa9e-473d-a8c8-5cd4d2d586c0,DISK], DatanodeInfoWithStorage[127.0.0.1:41276,DS-49b09ec3-ad9c-44ce-8b2d-74f9bbf63137,DISK], DatanodeInfoWithStorage[127.0.0.1:33545,DS-b7826b88-74c2-4892-9352-30a0338848c7,DISK], DatanodeInfoWithStorage[127.0.0.1:42385,DS-b6f570c0-3d79-47c4-b7f8-2a3e14048ffa,DISK], DatanodeInfoWithStorage[127.0.0.1:38291,DS-91664d66-4d37-4cb0-a27f-7b75cba8ad8f,DISK], DatanodeInfoWithStorage[127.0.0.1:44043,DS-fe67fb11-88a1-47e0-bb24-032a8b14f82b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1279672386-172.17.0.4-1598461616008:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41284,DS-72604410-a5fc-45d1-8485-da8f72e8fa03,DISK], DatanodeInfoWithStorage[127.0.0.1:35254,DS-02a4cdf5-ece4-4d36-bc9d-1b3af0488623,DISK], DatanodeInfoWithStorage[127.0.0.1:38982,DS-daa5992e-fa9e-473d-a8c8-5cd4d2d586c0,DISK], DatanodeInfoWithStorage[127.0.0.1:41276,DS-49b09ec3-ad9c-44ce-8b2d-74f9bbf63137,DISK], DatanodeInfoWithStorage[127.0.0.1:33545,DS-b7826b88-74c2-4892-9352-30a0338848c7,DISK], DatanodeInfoWithStorage[127.0.0.1:42385,DS-b6f570c0-3d79-47c4-b7f8-2a3e14048ffa,DISK], DatanodeInfoWithStorage[127.0.0.1:38291,DS-91664d66-4d37-4cb0-a27f-7b75cba8ad8f,DISK], DatanodeInfoWithStorage[127.0.0.1:44043,DS-fe67fb11-88a1-47e0-bb24-032a8b14f82b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1959160099-172.17.0.4-1598462008866:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35830,DS-0a9a8e83-d754-4239-a959-c4f8ad0f0196,DISK], DatanodeInfoWithStorage[127.0.0.1:42592,DS-41a87478-e376-4a7f-be37-52572ce7c325,DISK], DatanodeInfoWithStorage[127.0.0.1:33332,DS-25f0e39c-62fd-4822-8872-86064f5fa127,DISK], DatanodeInfoWithStorage[127.0.0.1:38594,DS-feff0e21-3852-4b6a-bf2a-43bc9ee1711b,DISK], DatanodeInfoWithStorage[127.0.0.1:33710,DS-bb4cf2df-f80b-4bd1-a6c2-0e75641bef7b,DISK], DatanodeInfoWithStorage[127.0.0.1:34349,DS-f94da191-9174-436e-9dfc-070f7e6f4d41,DISK], DatanodeInfoWithStorage[127.0.0.1:36139,DS-1232c35e-8210-4a8d-9b79-5a674f9e550a,DISK], DatanodeInfoWithStorage[127.0.0.1:41618,DS-77560dd4-8c3e-40ff-a304-1cb1bb5c1e52,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1959160099-172.17.0.4-1598462008866:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35830,DS-0a9a8e83-d754-4239-a959-c4f8ad0f0196,DISK], DatanodeInfoWithStorage[127.0.0.1:42592,DS-41a87478-e376-4a7f-be37-52572ce7c325,DISK], DatanodeInfoWithStorage[127.0.0.1:33332,DS-25f0e39c-62fd-4822-8872-86064f5fa127,DISK], DatanodeInfoWithStorage[127.0.0.1:38594,DS-feff0e21-3852-4b6a-bf2a-43bc9ee1711b,DISK], DatanodeInfoWithStorage[127.0.0.1:33710,DS-bb4cf2df-f80b-4bd1-a6c2-0e75641bef7b,DISK], DatanodeInfoWithStorage[127.0.0.1:34349,DS-f94da191-9174-436e-9dfc-070f7e6f4d41,DISK], DatanodeInfoWithStorage[127.0.0.1:36139,DS-1232c35e-8210-4a8d-9b79-5a674f9e550a,DISK], DatanodeInfoWithStorage[127.0.0.1:41618,DS-77560dd4-8c3e-40ff-a304-1cb1bb5c1e52,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1360039648-172.17.0.4-1598462263839:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36176,DS-d2e9ff84-83b3-4218-87f7-93a00a4295b0,DISK], DatanodeInfoWithStorage[127.0.0.1:35397,DS-23870cb9-b68c-4bac-b0fc-fd670a279cb8,DISK], DatanodeInfoWithStorage[127.0.0.1:32970,DS-581013b1-7f1f-4af6-a87a-99f54c15fa13,DISK], DatanodeInfoWithStorage[127.0.0.1:38036,DS-46ee7c0b-9019-4972-96e6-138fc69efdb7,DISK], DatanodeInfoWithStorage[127.0.0.1:41043,DS-5ada1db1-8cd8-4b7b-982d-0206dbc197c8,DISK], DatanodeInfoWithStorage[127.0.0.1:42424,DS-c5eccf6f-4035-4608-8c00-6273e2e58935,DISK], DatanodeInfoWithStorage[127.0.0.1:36139,DS-4a2fe5f3-8749-4f82-b600-82f937c96422,DISK], DatanodeInfoWithStorage[127.0.0.1:43782,DS-baaafebe-6849-4976-97ee-5d87197bee20,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1360039648-172.17.0.4-1598462263839:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36176,DS-d2e9ff84-83b3-4218-87f7-93a00a4295b0,DISK], DatanodeInfoWithStorage[127.0.0.1:35397,DS-23870cb9-b68c-4bac-b0fc-fd670a279cb8,DISK], DatanodeInfoWithStorage[127.0.0.1:32970,DS-581013b1-7f1f-4af6-a87a-99f54c15fa13,DISK], DatanodeInfoWithStorage[127.0.0.1:38036,DS-46ee7c0b-9019-4972-96e6-138fc69efdb7,DISK], DatanodeInfoWithStorage[127.0.0.1:41043,DS-5ada1db1-8cd8-4b7b-982d-0206dbc197c8,DISK], DatanodeInfoWithStorage[127.0.0.1:42424,DS-c5eccf6f-4035-4608-8c00-6273e2e58935,DISK], DatanodeInfoWithStorage[127.0.0.1:36139,DS-4a2fe5f3-8749-4f82-b600-82f937c96422,DISK], DatanodeInfoWithStorage[127.0.0.1:43782,DS-baaafebe-6849-4976-97ee-5d87197bee20,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1251766263-172.17.0.4-1598462803884:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33216,DS-16426fa9-8b8f-4989-931b-97fe93952320,DISK], DatanodeInfoWithStorage[127.0.0.1:45741,DS-6b46f05a-97a9-44bb-8349-e260d3ebb44e,DISK], DatanodeInfoWithStorage[127.0.0.1:45768,DS-dede3110-036a-4d7f-bcd0-62c4fdc1e826,DISK], DatanodeInfoWithStorage[127.0.0.1:34577,DS-2ed65787-eb7b-4d56-8e46-0cae2dacca88,DISK], DatanodeInfoWithStorage[127.0.0.1:41798,DS-433dccea-4e06-4282-9096-baac1835d6b7,DISK], DatanodeInfoWithStorage[127.0.0.1:33980,DS-8d754323-9b23-486a-b314-dbc32cc21a44,DISK], DatanodeInfoWithStorage[127.0.0.1:38451,DS-bc9c8cb1-d985-48bc-95a8-cb05e661c564,DISK], DatanodeInfoWithStorage[127.0.0.1:41643,DS-beb70c6c-4d97-4572-ab9f-9cc591722e22,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1251766263-172.17.0.4-1598462803884:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33216,DS-16426fa9-8b8f-4989-931b-97fe93952320,DISK], DatanodeInfoWithStorage[127.0.0.1:45741,DS-6b46f05a-97a9-44bb-8349-e260d3ebb44e,DISK], DatanodeInfoWithStorage[127.0.0.1:45768,DS-dede3110-036a-4d7f-bcd0-62c4fdc1e826,DISK], DatanodeInfoWithStorage[127.0.0.1:34577,DS-2ed65787-eb7b-4d56-8e46-0cae2dacca88,DISK], DatanodeInfoWithStorage[127.0.0.1:41798,DS-433dccea-4e06-4282-9096-baac1835d6b7,DISK], DatanodeInfoWithStorage[127.0.0.1:33980,DS-8d754323-9b23-486a-b314-dbc32cc21a44,DISK], DatanodeInfoWithStorage[127.0.0.1:38451,DS-bc9c8cb1-d985-48bc-95a8-cb05e661c564,DISK], DatanodeInfoWithStorage[127.0.0.1:41643,DS-beb70c6c-4d97-4572-ab9f-9cc591722e22,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5255
