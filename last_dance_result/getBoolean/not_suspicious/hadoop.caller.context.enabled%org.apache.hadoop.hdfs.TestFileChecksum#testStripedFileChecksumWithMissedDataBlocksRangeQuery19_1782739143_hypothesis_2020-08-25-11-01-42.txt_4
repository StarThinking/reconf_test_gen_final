reconf_parameter: hadoop.caller.context.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-448565819-172.17.0.20-1598353794307:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42461,DS-4890556c-129f-4515-9e09-2f2317d81560,DISK], DatanodeInfoWithStorage[127.0.0.1:37982,DS-b87fe099-655d-44cb-92ac-96516ff78240,DISK], DatanodeInfoWithStorage[127.0.0.1:38040,DS-dc5a57fb-dbac-4600-9240-358f0c4c19f2,DISK], DatanodeInfoWithStorage[127.0.0.1:41926,DS-51b3a1ef-d4b7-4f81-8efd-b3c3ffb0d2ab,DISK], DatanodeInfoWithStorage[127.0.0.1:46585,DS-e9140b1b-f4ce-47ba-a962-977b1a4a1f82,DISK], DatanodeInfoWithStorage[127.0.0.1:42836,DS-d858eae6-abe5-4af7-97f8-233676cf39dd,DISK], DatanodeInfoWithStorage[127.0.0.1:39748,DS-f6fa4fef-3fc3-4da4-bc6d-aa9949117bc8,DISK], DatanodeInfoWithStorage[127.0.0.1:44115,DS-c222f1a2-6e5b-4593-96f4-a39fa2b1cfc7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-448565819-172.17.0.20-1598353794307:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42461,DS-4890556c-129f-4515-9e09-2f2317d81560,DISK], DatanodeInfoWithStorage[127.0.0.1:37982,DS-b87fe099-655d-44cb-92ac-96516ff78240,DISK], DatanodeInfoWithStorage[127.0.0.1:38040,DS-dc5a57fb-dbac-4600-9240-358f0c4c19f2,DISK], DatanodeInfoWithStorage[127.0.0.1:41926,DS-51b3a1ef-d4b7-4f81-8efd-b3c3ffb0d2ab,DISK], DatanodeInfoWithStorage[127.0.0.1:46585,DS-e9140b1b-f4ce-47ba-a962-977b1a4a1f82,DISK], DatanodeInfoWithStorage[127.0.0.1:42836,DS-d858eae6-abe5-4af7-97f8-233676cf39dd,DISK], DatanodeInfoWithStorage[127.0.0.1:39748,DS-f6fa4fef-3fc3-4da4-bc6d-aa9949117bc8,DISK], DatanodeInfoWithStorage[127.0.0.1:44115,DS-c222f1a2-6e5b-4593-96f4-a39fa2b1cfc7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1230769133-172.17.0.20-1598353899143:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34011,DS-1f1a975b-5897-4856-ac95-347016d3e0a5,DISK], DatanodeInfoWithStorage[127.0.0.1:33060,DS-780ea528-6cb8-4355-b525-eb240138be30,DISK], DatanodeInfoWithStorage[127.0.0.1:35692,DS-4a58e27b-22e6-45b0-8873-de79bc6a48d8,DISK], DatanodeInfoWithStorage[127.0.0.1:38682,DS-f8e5b67e-fed4-48e6-9f83-4723654a9efe,DISK], DatanodeInfoWithStorage[127.0.0.1:41419,DS-a9aa9633-735f-47bf-9df1-80b6aae97e83,DISK], DatanodeInfoWithStorage[127.0.0.1:45358,DS-eee62239-bde0-44a3-b317-a028b800ce87,DISK], DatanodeInfoWithStorage[127.0.0.1:44913,DS-16611126-a908-402f-bdb9-ee927f6cce53,DISK], DatanodeInfoWithStorage[127.0.0.1:43758,DS-cecd08f2-e85c-4fec-be82-d88465a621f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1230769133-172.17.0.20-1598353899143:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34011,DS-1f1a975b-5897-4856-ac95-347016d3e0a5,DISK], DatanodeInfoWithStorage[127.0.0.1:33060,DS-780ea528-6cb8-4355-b525-eb240138be30,DISK], DatanodeInfoWithStorage[127.0.0.1:35692,DS-4a58e27b-22e6-45b0-8873-de79bc6a48d8,DISK], DatanodeInfoWithStorage[127.0.0.1:38682,DS-f8e5b67e-fed4-48e6-9f83-4723654a9efe,DISK], DatanodeInfoWithStorage[127.0.0.1:41419,DS-a9aa9633-735f-47bf-9df1-80b6aae97e83,DISK], DatanodeInfoWithStorage[127.0.0.1:45358,DS-eee62239-bde0-44a3-b317-a028b800ce87,DISK], DatanodeInfoWithStorage[127.0.0.1:44913,DS-16611126-a908-402f-bdb9-ee927f6cce53,DISK], DatanodeInfoWithStorage[127.0.0.1:43758,DS-cecd08f2-e85c-4fec-be82-d88465a621f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.caller.context.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-617134777-172.17.0.20-1598353933694:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39002,DS-414c6b37-a444-4d15-a6cd-8cfdc0b8f21d,DISK], DatanodeInfoWithStorage[127.0.0.1:39170,DS-502b5266-3f7a-4f6a-b50a-e5e449401d8b,DISK], DatanodeInfoWithStorage[127.0.0.1:39526,DS-5a2f5684-b6a1-46ac-8092-8628b95feb31,DISK], DatanodeInfoWithStorage[127.0.0.1:43199,DS-2a54adb8-8e30-4881-92f6-c47c385990c6,DISK], DatanodeInfoWithStorage[127.0.0.1:45200,DS-b7e8f9ee-06f4-49d7-afd4-a2ae37554f92,DISK], DatanodeInfoWithStorage[127.0.0.1:43476,DS-482d3576-4e17-41f5-a5dc-fb614d1b630c,DISK], DatanodeInfoWithStorage[127.0.0.1:40745,DS-7e49fd2b-7695-4789-8bdd-13b344b8822b,DISK], DatanodeInfoWithStorage[127.0.0.1:34621,DS-991cce45-d304-4719-99e4-629b120cba6b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-617134777-172.17.0.20-1598353933694:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39002,DS-414c6b37-a444-4d15-a6cd-8cfdc0b8f21d,DISK], DatanodeInfoWithStorage[127.0.0.1:39170,DS-502b5266-3f7a-4f6a-b50a-e5e449401d8b,DISK], DatanodeInfoWithStorage[127.0.0.1:39526,DS-5a2f5684-b6a1-46ac-8092-8628b95feb31,DISK], DatanodeInfoWithStorage[127.0.0.1:43199,DS-2a54adb8-8e30-4881-92f6-c47c385990c6,DISK], DatanodeInfoWithStorage[127.0.0.1:45200,DS-b7e8f9ee-06f4-49d7-afd4-a2ae37554f92,DISK], DatanodeInfoWithStorage[127.0.0.1:43476,DS-482d3576-4e17-41f5-a5dc-fb614d1b630c,DISK], DatanodeInfoWithStorage[127.0.0.1:40745,DS-7e49fd2b-7695-4789-8bdd-13b344b8822b,DISK], DatanodeInfoWithStorage[127.0.0.1:34621,DS-991cce45-d304-4719-99e4-629b120cba6b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.caller.context.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1693986967-172.17.0.20-1598354135295:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43392,DS-398331e5-6292-4068-a374-0dc5fe02a3af,DISK], DatanodeInfoWithStorage[127.0.0.1:32852,DS-f81da331-c678-4bdd-81af-329e9b541625,DISK], DatanodeInfoWithStorage[127.0.0.1:42660,DS-924bc43f-e535-41ea-8192-8c20163b54d6,DISK], DatanodeInfoWithStorage[127.0.0.1:44434,DS-970218fb-3fe8-479f-8aeb-f992e9456062,DISK], DatanodeInfoWithStorage[127.0.0.1:36391,DS-826e3c73-20ea-4523-a46f-032df6c8c78a,DISK], DatanodeInfoWithStorage[127.0.0.1:34378,DS-3d97f849-427e-4bdf-9351-259c67b1baf3,DISK], DatanodeInfoWithStorage[127.0.0.1:35494,DS-75abb143-c747-4961-98bc-a39b914a7338,DISK], DatanodeInfoWithStorage[127.0.0.1:37016,DS-5e2c2ac4-1dd1-4fb2-9337-e0f8897101b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1693986967-172.17.0.20-1598354135295:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43392,DS-398331e5-6292-4068-a374-0dc5fe02a3af,DISK], DatanodeInfoWithStorage[127.0.0.1:32852,DS-f81da331-c678-4bdd-81af-329e9b541625,DISK], DatanodeInfoWithStorage[127.0.0.1:42660,DS-924bc43f-e535-41ea-8192-8c20163b54d6,DISK], DatanodeInfoWithStorage[127.0.0.1:44434,DS-970218fb-3fe8-479f-8aeb-f992e9456062,DISK], DatanodeInfoWithStorage[127.0.0.1:36391,DS-826e3c73-20ea-4523-a46f-032df6c8c78a,DISK], DatanodeInfoWithStorage[127.0.0.1:34378,DS-3d97f849-427e-4bdf-9351-259c67b1baf3,DISK], DatanodeInfoWithStorage[127.0.0.1:35494,DS-75abb143-c747-4961-98bc-a39b914a7338,DISK], DatanodeInfoWithStorage[127.0.0.1:37016,DS-5e2c2ac4-1dd1-4fb2-9337-e0f8897101b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1418593353-172.17.0.20-1598354402798:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37935,DS-dd08592a-2d82-4c97-ae4e-43f82fadec4b,DISK], DatanodeInfoWithStorage[127.0.0.1:41395,DS-9870f306-9eef-4c7d-a3b9-55d6ad2e186a,DISK], DatanodeInfoWithStorage[127.0.0.1:36705,DS-9c5985c1-2dcd-4274-be99-078558a38b74,DISK], DatanodeInfoWithStorage[127.0.0.1:43615,DS-c910655c-6222-4082-9942-bf06b303dc14,DISK], DatanodeInfoWithStorage[127.0.0.1:38985,DS-7a20eb0f-2043-4ce8-ac02-168e46d3fb0e,DISK], DatanodeInfoWithStorage[127.0.0.1:34363,DS-92d38a3a-a9d8-4e09-9104-02db10fcbf07,DISK], DatanodeInfoWithStorage[127.0.0.1:38521,DS-6f573f8b-68a0-4c2a-aae9-0cae95697abb,DISK], DatanodeInfoWithStorage[127.0.0.1:46560,DS-1c0f4a86-1b90-4fdf-9c3f-bbe13170cb7b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1418593353-172.17.0.20-1598354402798:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37935,DS-dd08592a-2d82-4c97-ae4e-43f82fadec4b,DISK], DatanodeInfoWithStorage[127.0.0.1:41395,DS-9870f306-9eef-4c7d-a3b9-55d6ad2e186a,DISK], DatanodeInfoWithStorage[127.0.0.1:36705,DS-9c5985c1-2dcd-4274-be99-078558a38b74,DISK], DatanodeInfoWithStorage[127.0.0.1:43615,DS-c910655c-6222-4082-9942-bf06b303dc14,DISK], DatanodeInfoWithStorage[127.0.0.1:38985,DS-7a20eb0f-2043-4ce8-ac02-168e46d3fb0e,DISK], DatanodeInfoWithStorage[127.0.0.1:34363,DS-92d38a3a-a9d8-4e09-9104-02db10fcbf07,DISK], DatanodeInfoWithStorage[127.0.0.1:38521,DS-6f573f8b-68a0-4c2a-aae9-0cae95697abb,DISK], DatanodeInfoWithStorage[127.0.0.1:46560,DS-1c0f4a86-1b90-4fdf-9c3f-bbe13170cb7b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1881973617-172.17.0.20-1598355078780:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34893,DS-761a7855-8976-471f-9498-1905b6798717,DISK], DatanodeInfoWithStorage[127.0.0.1:33764,DS-dc6abd0e-5673-45d4-a598-b9c7a6ae31b2,DISK], DatanodeInfoWithStorage[127.0.0.1:45065,DS-d1d73ded-e6ab-47de-8cc1-bab294472a42,DISK], DatanodeInfoWithStorage[127.0.0.1:38664,DS-656dddd7-cc1c-4600-81df-98f9c9b3855f,DISK], DatanodeInfoWithStorage[127.0.0.1:40613,DS-274b4817-ddaf-426a-931e-cd1bce8ee63c,DISK], DatanodeInfoWithStorage[127.0.0.1:37442,DS-fb7c5e0d-8821-460d-b176-c56981e2b75d,DISK], DatanodeInfoWithStorage[127.0.0.1:33501,DS-3a2f46de-5495-449b-81df-201aa9770862,DISK], DatanodeInfoWithStorage[127.0.0.1:36766,DS-5067a6ef-02c8-4e2c-ba20-e3cdb6e9f329,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1881973617-172.17.0.20-1598355078780:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34893,DS-761a7855-8976-471f-9498-1905b6798717,DISK], DatanodeInfoWithStorage[127.0.0.1:33764,DS-dc6abd0e-5673-45d4-a598-b9c7a6ae31b2,DISK], DatanodeInfoWithStorage[127.0.0.1:45065,DS-d1d73ded-e6ab-47de-8cc1-bab294472a42,DISK], DatanodeInfoWithStorage[127.0.0.1:38664,DS-656dddd7-cc1c-4600-81df-98f9c9b3855f,DISK], DatanodeInfoWithStorage[127.0.0.1:40613,DS-274b4817-ddaf-426a-931e-cd1bce8ee63c,DISK], DatanodeInfoWithStorage[127.0.0.1:37442,DS-fb7c5e0d-8821-460d-b176-c56981e2b75d,DISK], DatanodeInfoWithStorage[127.0.0.1:33501,DS-3a2f46de-5495-449b-81df-201aa9770862,DISK], DatanodeInfoWithStorage[127.0.0.1:36766,DS-5067a6ef-02c8-4e2c-ba20-e3cdb6e9f329,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-115460407-172.17.0.20-1598356041488:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36745,DS-6aa02c0f-872e-4f7a-a181-df8eb4327f13,DISK], DatanodeInfoWithStorage[127.0.0.1:43010,DS-f39aef14-f7e1-485c-a304-dc9c56e7895c,DISK], DatanodeInfoWithStorage[127.0.0.1:33858,DS-67432c7c-5545-4a28-8b4e-1889b671020d,DISK], DatanodeInfoWithStorage[127.0.0.1:42957,DS-d368110d-2a87-4d20-87bc-ff76441cce89,DISK], DatanodeInfoWithStorage[127.0.0.1:34291,DS-74d2b648-509d-4238-9166-1dc0c3ee8064,DISK], DatanodeInfoWithStorage[127.0.0.1:43407,DS-6bb0253d-5033-4142-ac67-7e4f176ebc5a,DISK], DatanodeInfoWithStorage[127.0.0.1:44805,DS-347efeb5-1673-4234-b2b2-3cfaf4badd84,DISK], DatanodeInfoWithStorage[127.0.0.1:43959,DS-b4ef9e55-0ba0-4dbb-bd36-8b0b800e3675,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-115460407-172.17.0.20-1598356041488:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36745,DS-6aa02c0f-872e-4f7a-a181-df8eb4327f13,DISK], DatanodeInfoWithStorage[127.0.0.1:43010,DS-f39aef14-f7e1-485c-a304-dc9c56e7895c,DISK], DatanodeInfoWithStorage[127.0.0.1:33858,DS-67432c7c-5545-4a28-8b4e-1889b671020d,DISK], DatanodeInfoWithStorage[127.0.0.1:42957,DS-d368110d-2a87-4d20-87bc-ff76441cce89,DISK], DatanodeInfoWithStorage[127.0.0.1:34291,DS-74d2b648-509d-4238-9166-1dc0c3ee8064,DISK], DatanodeInfoWithStorage[127.0.0.1:43407,DS-6bb0253d-5033-4142-ac67-7e4f176ebc5a,DISK], DatanodeInfoWithStorage[127.0.0.1:44805,DS-347efeb5-1673-4234-b2b2-3cfaf4badd84,DISK], DatanodeInfoWithStorage[127.0.0.1:43959,DS-b4ef9e55-0ba0-4dbb-bd36-8b0b800e3675,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1447152012-172.17.0.20-1598356223683:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44668,DS-6fa2c0a0-47f0-4e83-927c-8dcf2e8e072b,DISK], DatanodeInfoWithStorage[127.0.0.1:34509,DS-4acd012a-42f6-49b3-bbea-28e18895243e,DISK], DatanodeInfoWithStorage[127.0.0.1:46622,DS-d5a64c0f-44ef-4eaf-8659-4766212073db,DISK], DatanodeInfoWithStorage[127.0.0.1:39460,DS-1ea08add-35f7-4add-887c-eb11db6c720e,DISK], DatanodeInfoWithStorage[127.0.0.1:40994,DS-6ca02a2d-81a9-4998-b2aa-1dc832919590,DISK], DatanodeInfoWithStorage[127.0.0.1:38636,DS-b86515b3-ae5f-4515-a97e-2f1a634c0fc5,DISK], DatanodeInfoWithStorage[127.0.0.1:35708,DS-9def70c9-fb30-4ff3-8c41-7083bd105e20,DISK], DatanodeInfoWithStorage[127.0.0.1:40169,DS-04677893-6f66-47a4-aed6-acd136fee479,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1447152012-172.17.0.20-1598356223683:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44668,DS-6fa2c0a0-47f0-4e83-927c-8dcf2e8e072b,DISK], DatanodeInfoWithStorage[127.0.0.1:34509,DS-4acd012a-42f6-49b3-bbea-28e18895243e,DISK], DatanodeInfoWithStorage[127.0.0.1:46622,DS-d5a64c0f-44ef-4eaf-8659-4766212073db,DISK], DatanodeInfoWithStorage[127.0.0.1:39460,DS-1ea08add-35f7-4add-887c-eb11db6c720e,DISK], DatanodeInfoWithStorage[127.0.0.1:40994,DS-6ca02a2d-81a9-4998-b2aa-1dc832919590,DISK], DatanodeInfoWithStorage[127.0.0.1:38636,DS-b86515b3-ae5f-4515-a97e-2f1a634c0fc5,DISK], DatanodeInfoWithStorage[127.0.0.1:35708,DS-9def70c9-fb30-4ff3-8c41-7083bd105e20,DISK], DatanodeInfoWithStorage[127.0.0.1:40169,DS-04677893-6f66-47a4-aed6-acd136fee479,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1780239772-172.17.0.20-1598357573550:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38353,DS-aa53a698-cf32-4174-acbb-f8321f72dea8,DISK], DatanodeInfoWithStorage[127.0.0.1:44688,DS-c89af271-e8eb-4174-bec4-ff08cfd368c0,DISK], DatanodeInfoWithStorage[127.0.0.1:43498,DS-4bf3872f-568c-4389-bbfc-bfb2b40741a2,DISK], DatanodeInfoWithStorage[127.0.0.1:46678,DS-c0ad76c2-2aac-4504-933c-7d45568ec3b1,DISK], DatanodeInfoWithStorage[127.0.0.1:34038,DS-ab904437-d3d8-414e-bcb4-f76daa38838a,DISK], DatanodeInfoWithStorage[127.0.0.1:36527,DS-a7b56e11-5814-4c0b-a879-92533288b7a5,DISK], DatanodeInfoWithStorage[127.0.0.1:33165,DS-75ff56a2-f36d-438b-b50e-be10c05b0a92,DISK], DatanodeInfoWithStorage[127.0.0.1:41961,DS-004fc03c-fe75-4839-be06-db15348118b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1780239772-172.17.0.20-1598357573550:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38353,DS-aa53a698-cf32-4174-acbb-f8321f72dea8,DISK], DatanodeInfoWithStorage[127.0.0.1:44688,DS-c89af271-e8eb-4174-bec4-ff08cfd368c0,DISK], DatanodeInfoWithStorage[127.0.0.1:43498,DS-4bf3872f-568c-4389-bbfc-bfb2b40741a2,DISK], DatanodeInfoWithStorage[127.0.0.1:46678,DS-c0ad76c2-2aac-4504-933c-7d45568ec3b1,DISK], DatanodeInfoWithStorage[127.0.0.1:34038,DS-ab904437-d3d8-414e-bcb4-f76daa38838a,DISK], DatanodeInfoWithStorage[127.0.0.1:36527,DS-a7b56e11-5814-4c0b-a879-92533288b7a5,DISK], DatanodeInfoWithStorage[127.0.0.1:33165,DS-75ff56a2-f36d-438b-b50e-be10c05b0a92,DISK], DatanodeInfoWithStorage[127.0.0.1:41961,DS-004fc03c-fe75-4839-be06-db15348118b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-193230082-172.17.0.20-1598357918763:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44896,DS-2f602bbf-bc32-42a5-a8a8-17e4ca22fabc,DISK], DatanodeInfoWithStorage[127.0.0.1:42109,DS-2658bbbd-f1fd-4c21-a25a-e678574b5115,DISK], DatanodeInfoWithStorage[127.0.0.1:34066,DS-14873cbc-3030-4aaf-b495-93bfcdbb1850,DISK], DatanodeInfoWithStorage[127.0.0.1:44183,DS-a8ca2331-a63d-4a69-b862-c63444ab166c,DISK], DatanodeInfoWithStorage[127.0.0.1:36478,DS-4f6a588f-81c9-4573-ae1a-a3ea90f7ec6e,DISK], DatanodeInfoWithStorage[127.0.0.1:34953,DS-6d90cf3f-8ba9-4c72-9636-c773084cf0ee,DISK], DatanodeInfoWithStorage[127.0.0.1:42943,DS-f983dd3b-b298-4fcd-92b8-c6ce4f333c88,DISK], DatanodeInfoWithStorage[127.0.0.1:36418,DS-ec504ef4-5559-42de-9434-a55b7cf1eea7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-193230082-172.17.0.20-1598357918763:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44896,DS-2f602bbf-bc32-42a5-a8a8-17e4ca22fabc,DISK], DatanodeInfoWithStorage[127.0.0.1:42109,DS-2658bbbd-f1fd-4c21-a25a-e678574b5115,DISK], DatanodeInfoWithStorage[127.0.0.1:34066,DS-14873cbc-3030-4aaf-b495-93bfcdbb1850,DISK], DatanodeInfoWithStorage[127.0.0.1:44183,DS-a8ca2331-a63d-4a69-b862-c63444ab166c,DISK], DatanodeInfoWithStorage[127.0.0.1:36478,DS-4f6a588f-81c9-4573-ae1a-a3ea90f7ec6e,DISK], DatanodeInfoWithStorage[127.0.0.1:34953,DS-6d90cf3f-8ba9-4c72-9636-c773084cf0ee,DISK], DatanodeInfoWithStorage[127.0.0.1:42943,DS-f983dd3b-b298-4fcd-92b8-c6ce4f333c88,DISK], DatanodeInfoWithStorage[127.0.0.1:36418,DS-ec504ef4-5559-42de-9434-a55b7cf1eea7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-518805930-172.17.0.20-1598358313050:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37613,DS-13340517-7988-408a-a534-333e74c162af,DISK], DatanodeInfoWithStorage[127.0.0.1:36972,DS-fb6cb155-75c2-44d5-a9a1-868175ac41f1,DISK], DatanodeInfoWithStorage[127.0.0.1:44845,DS-708b6a52-00c8-418b-884f-d9cdaa0ba7b8,DISK], DatanodeInfoWithStorage[127.0.0.1:37810,DS-a4f8140d-1cc8-4b9e-9fd8-477627343b6d,DISK], DatanodeInfoWithStorage[127.0.0.1:45897,DS-3e0c3470-f8d5-463c-8d85-749651299d95,DISK], DatanodeInfoWithStorage[127.0.0.1:45756,DS-a392847d-4269-41e2-844c-14fa1a3921a7,DISK], DatanodeInfoWithStorage[127.0.0.1:33773,DS-44ecd454-943a-44aa-815d-fe76a54ba708,DISK], DatanodeInfoWithStorage[127.0.0.1:37242,DS-ca4e67da-6644-4b30-ac2f-b497b1470af5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-518805930-172.17.0.20-1598358313050:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37613,DS-13340517-7988-408a-a534-333e74c162af,DISK], DatanodeInfoWithStorage[127.0.0.1:36972,DS-fb6cb155-75c2-44d5-a9a1-868175ac41f1,DISK], DatanodeInfoWithStorage[127.0.0.1:44845,DS-708b6a52-00c8-418b-884f-d9cdaa0ba7b8,DISK], DatanodeInfoWithStorage[127.0.0.1:37810,DS-a4f8140d-1cc8-4b9e-9fd8-477627343b6d,DISK], DatanodeInfoWithStorage[127.0.0.1:45897,DS-3e0c3470-f8d5-463c-8d85-749651299d95,DISK], DatanodeInfoWithStorage[127.0.0.1:45756,DS-a392847d-4269-41e2-844c-14fa1a3921a7,DISK], DatanodeInfoWithStorage[127.0.0.1:33773,DS-44ecd454-943a-44aa-815d-fe76a54ba708,DISK], DatanodeInfoWithStorage[127.0.0.1:37242,DS-ca4e67da-6644-4b30-ac2f-b497b1470af5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: hadoop.caller.context.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-306367441-172.17.0.20-1598358339740:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45119,DS-bd2a40c4-b3e4-4ae4-8869-a0c22d478202,DISK], DatanodeInfoWithStorage[127.0.0.1:45880,DS-b3f1a49f-853d-48e0-87bb-a4dba85262b6,DISK], DatanodeInfoWithStorage[127.0.0.1:38235,DS-d90a9db3-2d1b-4d9f-aa36-f3f9900ee6b4,DISK], DatanodeInfoWithStorage[127.0.0.1:33989,DS-039da085-46cb-466b-bac9-4b102ca3a39a,DISK], DatanodeInfoWithStorage[127.0.0.1:44642,DS-1632032b-da57-4aac-a058-7b448a7bc1c7,DISK], DatanodeInfoWithStorage[127.0.0.1:45552,DS-f3c79613-0f51-4e89-ba0a-f8f3c53c7413,DISK], DatanodeInfoWithStorage[127.0.0.1:46672,DS-2a7621c7-9fbf-495a-8d30-beb8dddc0ad3,DISK], DatanodeInfoWithStorage[127.0.0.1:40445,DS-3554c442-13f9-47ca-91d9-f56213fa15d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-306367441-172.17.0.20-1598358339740:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45119,DS-bd2a40c4-b3e4-4ae4-8869-a0c22d478202,DISK], DatanodeInfoWithStorage[127.0.0.1:45880,DS-b3f1a49f-853d-48e0-87bb-a4dba85262b6,DISK], DatanodeInfoWithStorage[127.0.0.1:38235,DS-d90a9db3-2d1b-4d9f-aa36-f3f9900ee6b4,DISK], DatanodeInfoWithStorage[127.0.0.1:33989,DS-039da085-46cb-466b-bac9-4b102ca3a39a,DISK], DatanodeInfoWithStorage[127.0.0.1:44642,DS-1632032b-da57-4aac-a058-7b448a7bc1c7,DISK], DatanodeInfoWithStorage[127.0.0.1:45552,DS-f3c79613-0f51-4e89-ba0a-f8f3c53c7413,DISK], DatanodeInfoWithStorage[127.0.0.1:46672,DS-2a7621c7-9fbf-495a-8d30-beb8dddc0ad3,DISK], DatanodeInfoWithStorage[127.0.0.1:40445,DS-3554c442-13f9-47ca-91d9-f56213fa15d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 2 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5057
