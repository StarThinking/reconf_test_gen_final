reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-247789535-172.17.0.17-1598157490383:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46378,DS-2c4b7e79-7627-40fe-9b61-7c439b1c3a90,DISK], DatanodeInfoWithStorage[127.0.0.1:38443,DS-211a6f8d-a970-496d-b06d-84405f1b519e,DISK], DatanodeInfoWithStorage[127.0.0.1:43623,DS-179b50ba-6288-4dad-a5d9-10a65168a2ac,DISK], DatanodeInfoWithStorage[127.0.0.1:41425,DS-c31d145d-1a85-41f0-9714-5b4b0e4660fa,DISK], DatanodeInfoWithStorage[127.0.0.1:33144,DS-b048b1ea-5f19-4c8b-a85f-f56f7e4289d0,DISK], DatanodeInfoWithStorage[127.0.0.1:36998,DS-900b3f2a-ff3f-45c5-b4fd-bc6af6402e3d,DISK], DatanodeInfoWithStorage[127.0.0.1:41610,DS-b188e4fc-e21d-463b-8a0d-771c33df355a,DISK], DatanodeInfoWithStorage[127.0.0.1:46363,DS-daf3be10-1f13-4cad-99af-16f0438e63f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-247789535-172.17.0.17-1598157490383:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46378,DS-2c4b7e79-7627-40fe-9b61-7c439b1c3a90,DISK], DatanodeInfoWithStorage[127.0.0.1:38443,DS-211a6f8d-a970-496d-b06d-84405f1b519e,DISK], DatanodeInfoWithStorage[127.0.0.1:43623,DS-179b50ba-6288-4dad-a5d9-10a65168a2ac,DISK], DatanodeInfoWithStorage[127.0.0.1:41425,DS-c31d145d-1a85-41f0-9714-5b4b0e4660fa,DISK], DatanodeInfoWithStorage[127.0.0.1:33144,DS-b048b1ea-5f19-4c8b-a85f-f56f7e4289d0,DISK], DatanodeInfoWithStorage[127.0.0.1:36998,DS-900b3f2a-ff3f-45c5-b4fd-bc6af6402e3d,DISK], DatanodeInfoWithStorage[127.0.0.1:41610,DS-b188e4fc-e21d-463b-8a0d-771c33df355a,DISK], DatanodeInfoWithStorage[127.0.0.1:46363,DS-daf3be10-1f13-4cad-99af-16f0438e63f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-65691838-172.17.0.17-1598157525068:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45484,DS-9c2d8a68-ea14-4593-bd79-e905d69ac6b8,DISK], DatanodeInfoWithStorage[127.0.0.1:46330,DS-6a5993c1-8917-48e7-ba55-373069f6e3b5,DISK], DatanodeInfoWithStorage[127.0.0.1:41046,DS-2dbeedf2-c0fa-44f5-9de3-966f041f2691,DISK], DatanodeInfoWithStorage[127.0.0.1:37544,DS-a9317b22-5c0e-4283-aa47-6b9e037ea313,DISK], DatanodeInfoWithStorage[127.0.0.1:42657,DS-0a7cf501-b419-463b-b7dd-6f33b89bd7b3,DISK], DatanodeInfoWithStorage[127.0.0.1:38957,DS-da904971-a574-4e7b-9e90-ae71a84cb73e,DISK], DatanodeInfoWithStorage[127.0.0.1:38852,DS-f7ce403d-60e4-4d95-a748-ec1a9fa4574e,DISK], DatanodeInfoWithStorage[127.0.0.1:45372,DS-98eaf66a-f018-4e1b-9ffa-111167a5c37f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-65691838-172.17.0.17-1598157525068:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45484,DS-9c2d8a68-ea14-4593-bd79-e905d69ac6b8,DISK], DatanodeInfoWithStorage[127.0.0.1:46330,DS-6a5993c1-8917-48e7-ba55-373069f6e3b5,DISK], DatanodeInfoWithStorage[127.0.0.1:41046,DS-2dbeedf2-c0fa-44f5-9de3-966f041f2691,DISK], DatanodeInfoWithStorage[127.0.0.1:37544,DS-a9317b22-5c0e-4283-aa47-6b9e037ea313,DISK], DatanodeInfoWithStorage[127.0.0.1:42657,DS-0a7cf501-b419-463b-b7dd-6f33b89bd7b3,DISK], DatanodeInfoWithStorage[127.0.0.1:38957,DS-da904971-a574-4e7b-9e90-ae71a84cb73e,DISK], DatanodeInfoWithStorage[127.0.0.1:38852,DS-f7ce403d-60e4-4d95-a748-ec1a9fa4574e,DISK], DatanodeInfoWithStorage[127.0.0.1:45372,DS-98eaf66a-f018-4e1b-9ffa-111167a5c37f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-335356788-172.17.0.17-1598157565059:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33594,DS-ea786c24-fe67-4854-b43e-19b672c38ae7,DISK], DatanodeInfoWithStorage[127.0.0.1:33345,DS-252e4d2f-cef4-4fe4-aae3-cefda3c97d32,DISK], DatanodeInfoWithStorage[127.0.0.1:44511,DS-3a73e673-06ac-431a-93c1-0b86aa5efd99,DISK], DatanodeInfoWithStorage[127.0.0.1:35990,DS-c947d553-c238-40b8-8ea3-a55beffdb566,DISK], DatanodeInfoWithStorage[127.0.0.1:44834,DS-c98e1bb9-90c6-4ac8-a57d-ba2617133f85,DISK], DatanodeInfoWithStorage[127.0.0.1:41852,DS-9eb63e32-1d67-44f5-b37c-4d82f919e299,DISK], DatanodeInfoWithStorage[127.0.0.1:38535,DS-eabdef96-a33e-47a7-bb8e-3339fb6d8d16,DISK], DatanodeInfoWithStorage[127.0.0.1:35716,DS-7268d051-c803-44a2-a953-917430cd54df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-335356788-172.17.0.17-1598157565059:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33594,DS-ea786c24-fe67-4854-b43e-19b672c38ae7,DISK], DatanodeInfoWithStorage[127.0.0.1:33345,DS-252e4d2f-cef4-4fe4-aae3-cefda3c97d32,DISK], DatanodeInfoWithStorage[127.0.0.1:44511,DS-3a73e673-06ac-431a-93c1-0b86aa5efd99,DISK], DatanodeInfoWithStorage[127.0.0.1:35990,DS-c947d553-c238-40b8-8ea3-a55beffdb566,DISK], DatanodeInfoWithStorage[127.0.0.1:44834,DS-c98e1bb9-90c6-4ac8-a57d-ba2617133f85,DISK], DatanodeInfoWithStorage[127.0.0.1:41852,DS-9eb63e32-1d67-44f5-b37c-4d82f919e299,DISK], DatanodeInfoWithStorage[127.0.0.1:38535,DS-eabdef96-a33e-47a7-bb8e-3339fb6d8d16,DISK], DatanodeInfoWithStorage[127.0.0.1:35716,DS-7268d051-c803-44a2-a953-917430cd54df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2105423049-172.17.0.17-1598157727863:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34520,DS-28884ab4-c7e9-4a4d-9bfd-b2a0cc9136d8,DISK], DatanodeInfoWithStorage[127.0.0.1:36140,DS-4f438948-7d1f-49f5-9e45-f707f6139bbd,DISK], DatanodeInfoWithStorage[127.0.0.1:44164,DS-3460f813-8176-4b6a-8938-4fa0fc8220dd,DISK], DatanodeInfoWithStorage[127.0.0.1:34705,DS-564c60d7-12d8-4bd8-a55e-5925d059d748,DISK], DatanodeInfoWithStorage[127.0.0.1:46112,DS-b9b9c68d-3376-45b7-a436-4b7df946a25e,DISK], DatanodeInfoWithStorage[127.0.0.1:46475,DS-12501290-e1dd-4e77-b552-9e124d42dd85,DISK], DatanodeInfoWithStorage[127.0.0.1:33631,DS-024fd32e-c403-4f98-8c90-dd61e1b9e283,DISK], DatanodeInfoWithStorage[127.0.0.1:38082,DS-21322cfa-e2dd-4738-8a71-ad494af3d9c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2105423049-172.17.0.17-1598157727863:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34520,DS-28884ab4-c7e9-4a4d-9bfd-b2a0cc9136d8,DISK], DatanodeInfoWithStorage[127.0.0.1:36140,DS-4f438948-7d1f-49f5-9e45-f707f6139bbd,DISK], DatanodeInfoWithStorage[127.0.0.1:44164,DS-3460f813-8176-4b6a-8938-4fa0fc8220dd,DISK], DatanodeInfoWithStorage[127.0.0.1:34705,DS-564c60d7-12d8-4bd8-a55e-5925d059d748,DISK], DatanodeInfoWithStorage[127.0.0.1:46112,DS-b9b9c68d-3376-45b7-a436-4b7df946a25e,DISK], DatanodeInfoWithStorage[127.0.0.1:46475,DS-12501290-e1dd-4e77-b552-9e124d42dd85,DISK], DatanodeInfoWithStorage[127.0.0.1:33631,DS-024fd32e-c403-4f98-8c90-dd61e1b9e283,DISK], DatanodeInfoWithStorage[127.0.0.1:38082,DS-21322cfa-e2dd-4738-8a71-ad494af3d9c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1525074064-172.17.0.17-1598158037658:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33995,DS-1720be44-c184-446b-8abb-dbccbe601b42,DISK], DatanodeInfoWithStorage[127.0.0.1:39169,DS-9985e187-3b2e-4bbd-97ff-43945f05dfbf,DISK], DatanodeInfoWithStorage[127.0.0.1:45026,DS-3da8a63f-da5b-4107-b1cd-3c260e72f1cb,DISK], DatanodeInfoWithStorage[127.0.0.1:44630,DS-640c30cf-a614-488a-aaff-268e59b3c0c7,DISK], DatanodeInfoWithStorage[127.0.0.1:41853,DS-1b08d4e9-b41f-4103-af6b-8abf07dca442,DISK], DatanodeInfoWithStorage[127.0.0.1:37080,DS-5cc3162c-348f-4255-843d-2be635bcb53a,DISK], DatanodeInfoWithStorage[127.0.0.1:38676,DS-907e5417-8d27-4ee4-b965-7775d0fbb8c6,DISK], DatanodeInfoWithStorage[127.0.0.1:43307,DS-a04c022a-8535-43a3-b3aa-e066a77148a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1525074064-172.17.0.17-1598158037658:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33995,DS-1720be44-c184-446b-8abb-dbccbe601b42,DISK], DatanodeInfoWithStorage[127.0.0.1:39169,DS-9985e187-3b2e-4bbd-97ff-43945f05dfbf,DISK], DatanodeInfoWithStorage[127.0.0.1:45026,DS-3da8a63f-da5b-4107-b1cd-3c260e72f1cb,DISK], DatanodeInfoWithStorage[127.0.0.1:44630,DS-640c30cf-a614-488a-aaff-268e59b3c0c7,DISK], DatanodeInfoWithStorage[127.0.0.1:41853,DS-1b08d4e9-b41f-4103-af6b-8abf07dca442,DISK], DatanodeInfoWithStorage[127.0.0.1:37080,DS-5cc3162c-348f-4255-843d-2be635bcb53a,DISK], DatanodeInfoWithStorage[127.0.0.1:38676,DS-907e5417-8d27-4ee4-b965-7775d0fbb8c6,DISK], DatanodeInfoWithStorage[127.0.0.1:43307,DS-a04c022a-8535-43a3-b3aa-e066a77148a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-74976196-172.17.0.17-1598158065790:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44369,DS-c022cb77-e264-4d9d-a9e9-8c4585e51d73,DISK], DatanodeInfoWithStorage[127.0.0.1:45237,DS-dea792f3-3b72-443d-b24d-2536d9f2dbf7,DISK], DatanodeInfoWithStorage[127.0.0.1:40293,DS-e7227adc-e2d3-4a6f-a010-518ca3bad22c,DISK], DatanodeInfoWithStorage[127.0.0.1:43077,DS-900912b3-15ce-455b-813b-0fc24efe6960,DISK], DatanodeInfoWithStorage[127.0.0.1:42483,DS-5c10abab-7898-4790-86a5-19b06988dfcb,DISK], DatanodeInfoWithStorage[127.0.0.1:35010,DS-c3fdad37-02f7-4914-9e91-e69843fc4b8d,DISK], DatanodeInfoWithStorage[127.0.0.1:33110,DS-46309347-bbac-4f6c-8ddf-032e41a8633a,DISK], DatanodeInfoWithStorage[127.0.0.1:33008,DS-3f3b80a6-05da-43c6-a735-5ae43905b73f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-74976196-172.17.0.17-1598158065790:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44369,DS-c022cb77-e264-4d9d-a9e9-8c4585e51d73,DISK], DatanodeInfoWithStorage[127.0.0.1:45237,DS-dea792f3-3b72-443d-b24d-2536d9f2dbf7,DISK], DatanodeInfoWithStorage[127.0.0.1:40293,DS-e7227adc-e2d3-4a6f-a010-518ca3bad22c,DISK], DatanodeInfoWithStorage[127.0.0.1:43077,DS-900912b3-15ce-455b-813b-0fc24efe6960,DISK], DatanodeInfoWithStorage[127.0.0.1:42483,DS-5c10abab-7898-4790-86a5-19b06988dfcb,DISK], DatanodeInfoWithStorage[127.0.0.1:35010,DS-c3fdad37-02f7-4914-9e91-e69843fc4b8d,DISK], DatanodeInfoWithStorage[127.0.0.1:33110,DS-46309347-bbac-4f6c-8ddf-032e41a8633a,DISK], DatanodeInfoWithStorage[127.0.0.1:33008,DS-3f3b80a6-05da-43c6-a735-5ae43905b73f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1145334951-172.17.0.17-1598158294266:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41901,DS-ee032378-e3cd-4464-ae3d-2dd6deabc153,DISK], DatanodeInfoWithStorage[127.0.0.1:33234,DS-18d2e814-dd7e-4dd3-b42c-f674581adc49,DISK], DatanodeInfoWithStorage[127.0.0.1:37892,DS-e83e346d-e357-403c-8baf-7830324e649d,DISK], DatanodeInfoWithStorage[127.0.0.1:39777,DS-1d5ba5dd-2981-405b-99c2-9326701feac1,DISK], DatanodeInfoWithStorage[127.0.0.1:40079,DS-78f08034-b99a-4743-9c89-25925b3e9d8c,DISK], DatanodeInfoWithStorage[127.0.0.1:35949,DS-cbda0279-0b59-4d92-ae12-d5c1ea117e2d,DISK], DatanodeInfoWithStorage[127.0.0.1:46536,DS-2c04c78f-b695-48ad-996e-5002d18b0f92,DISK], DatanodeInfoWithStorage[127.0.0.1:35472,DS-7709e9df-c087-480b-8f1a-d397df508ee8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1145334951-172.17.0.17-1598158294266:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41901,DS-ee032378-e3cd-4464-ae3d-2dd6deabc153,DISK], DatanodeInfoWithStorage[127.0.0.1:33234,DS-18d2e814-dd7e-4dd3-b42c-f674581adc49,DISK], DatanodeInfoWithStorage[127.0.0.1:37892,DS-e83e346d-e357-403c-8baf-7830324e649d,DISK], DatanodeInfoWithStorage[127.0.0.1:39777,DS-1d5ba5dd-2981-405b-99c2-9326701feac1,DISK], DatanodeInfoWithStorage[127.0.0.1:40079,DS-78f08034-b99a-4743-9c89-25925b3e9d8c,DISK], DatanodeInfoWithStorage[127.0.0.1:35949,DS-cbda0279-0b59-4d92-ae12-d5c1ea117e2d,DISK], DatanodeInfoWithStorage[127.0.0.1:46536,DS-2c04c78f-b695-48ad-996e-5002d18b0f92,DISK], DatanodeInfoWithStorage[127.0.0.1:35472,DS-7709e9df-c087-480b-8f1a-d397df508ee8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1840799181-172.17.0.17-1598158568105:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34415,DS-61938e12-55ea-4d72-b0e9-c3a0cae96629,DISK], DatanodeInfoWithStorage[127.0.0.1:43093,DS-5ba39cd7-edc0-4d86-8b0e-d096287c584e,DISK], DatanodeInfoWithStorage[127.0.0.1:40893,DS-8ad8bd54-ce9c-4fd2-a78e-724fca19a402,DISK], DatanodeInfoWithStorage[127.0.0.1:35791,DS-e7fbbefb-4e2a-49af-9be8-0d5e124d2f21,DISK], DatanodeInfoWithStorage[127.0.0.1:38210,DS-03e10ae4-a043-495b-aab9-3df73466f967,DISK], DatanodeInfoWithStorage[127.0.0.1:40301,DS-9c86b820-9527-420e-9ecd-61115ae3ab2e,DISK], DatanodeInfoWithStorage[127.0.0.1:32818,DS-6dcdcc1f-10f7-4914-9916-e744b46cc6ae,DISK], DatanodeInfoWithStorage[127.0.0.1:41363,DS-d1d8a7dc-a871-44aa-a182-754968b83c20,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1840799181-172.17.0.17-1598158568105:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34415,DS-61938e12-55ea-4d72-b0e9-c3a0cae96629,DISK], DatanodeInfoWithStorage[127.0.0.1:43093,DS-5ba39cd7-edc0-4d86-8b0e-d096287c584e,DISK], DatanodeInfoWithStorage[127.0.0.1:40893,DS-8ad8bd54-ce9c-4fd2-a78e-724fca19a402,DISK], DatanodeInfoWithStorage[127.0.0.1:35791,DS-e7fbbefb-4e2a-49af-9be8-0d5e124d2f21,DISK], DatanodeInfoWithStorage[127.0.0.1:38210,DS-03e10ae4-a043-495b-aab9-3df73466f967,DISK], DatanodeInfoWithStorage[127.0.0.1:40301,DS-9c86b820-9527-420e-9ecd-61115ae3ab2e,DISK], DatanodeInfoWithStorage[127.0.0.1:32818,DS-6dcdcc1f-10f7-4914-9916-e744b46cc6ae,DISK], DatanodeInfoWithStorage[127.0.0.1:41363,DS-d1d8a7dc-a871-44aa-a182-754968b83c20,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1504966446-172.17.0.17-1598159026448:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34759,DS-7c3a5008-a2f8-4f14-a539-044b0d076745,DISK], DatanodeInfoWithStorage[127.0.0.1:35693,DS-39e13e5b-1953-4a1c-84d2-238068052814,DISK], DatanodeInfoWithStorage[127.0.0.1:42887,DS-bfe4292c-bde6-4687-a98e-42f932df57e6,DISK], DatanodeInfoWithStorage[127.0.0.1:41758,DS-48fdc7df-e6bd-4695-9a89-ac4c138512a5,DISK], DatanodeInfoWithStorage[127.0.0.1:36953,DS-328f82f7-df3c-4afa-8d31-2936972e2462,DISK], DatanodeInfoWithStorage[127.0.0.1:36377,DS-501f7742-52ad-40c4-8e73-d1c272adb282,DISK], DatanodeInfoWithStorage[127.0.0.1:34943,DS-ceb4d1ce-6a33-4cb5-af52-a5589dd5051b,DISK], DatanodeInfoWithStorage[127.0.0.1:38714,DS-ac257441-1d75-4d28-864c-9196839d62f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1504966446-172.17.0.17-1598159026448:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34759,DS-7c3a5008-a2f8-4f14-a539-044b0d076745,DISK], DatanodeInfoWithStorage[127.0.0.1:35693,DS-39e13e5b-1953-4a1c-84d2-238068052814,DISK], DatanodeInfoWithStorage[127.0.0.1:42887,DS-bfe4292c-bde6-4687-a98e-42f932df57e6,DISK], DatanodeInfoWithStorage[127.0.0.1:41758,DS-48fdc7df-e6bd-4695-9a89-ac4c138512a5,DISK], DatanodeInfoWithStorage[127.0.0.1:36953,DS-328f82f7-df3c-4afa-8d31-2936972e2462,DISK], DatanodeInfoWithStorage[127.0.0.1:36377,DS-501f7742-52ad-40c4-8e73-d1c272adb282,DISK], DatanodeInfoWithStorage[127.0.0.1:34943,DS-ceb4d1ce-6a33-4cb5-af52-a5589dd5051b,DISK], DatanodeInfoWithStorage[127.0.0.1:38714,DS-ac257441-1d75-4d28-864c-9196839d62f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1774224219-172.17.0.17-1598159828959:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41900,DS-54257eb1-6100-4dd3-a801-2fe10464eb66,DISK], DatanodeInfoWithStorage[127.0.0.1:46244,DS-6d6af36b-b1f0-456d-bcf1-74fcef45007b,DISK], DatanodeInfoWithStorage[127.0.0.1:39631,DS-a1268ba3-1a86-41e3-aaf9-dccb8d70b759,DISK], DatanodeInfoWithStorage[127.0.0.1:37878,DS-c8d4b420-9c04-4e39-abb7-ea6cd92d50f8,DISK], DatanodeInfoWithStorage[127.0.0.1:45623,DS-ca1a2f89-1b52-47c6-adce-0be9e3dc8da7,DISK], DatanodeInfoWithStorage[127.0.0.1:36733,DS-db328166-164f-4d04-9f27-e244b29dec64,DISK], DatanodeInfoWithStorage[127.0.0.1:43761,DS-5ad4e55d-799f-46a2-8610-7d36da646787,DISK], DatanodeInfoWithStorage[127.0.0.1:33952,DS-0702b573-8ea3-48b9-bdff-dff51371a6a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1774224219-172.17.0.17-1598159828959:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41900,DS-54257eb1-6100-4dd3-a801-2fe10464eb66,DISK], DatanodeInfoWithStorage[127.0.0.1:46244,DS-6d6af36b-b1f0-456d-bcf1-74fcef45007b,DISK], DatanodeInfoWithStorage[127.0.0.1:39631,DS-a1268ba3-1a86-41e3-aaf9-dccb8d70b759,DISK], DatanodeInfoWithStorage[127.0.0.1:37878,DS-c8d4b420-9c04-4e39-abb7-ea6cd92d50f8,DISK], DatanodeInfoWithStorage[127.0.0.1:45623,DS-ca1a2f89-1b52-47c6-adce-0be9e3dc8da7,DISK], DatanodeInfoWithStorage[127.0.0.1:36733,DS-db328166-164f-4d04-9f27-e244b29dec64,DISK], DatanodeInfoWithStorage[127.0.0.1:43761,DS-5ad4e55d-799f-46a2-8610-7d36da646787,DISK], DatanodeInfoWithStorage[127.0.0.1:33952,DS-0702b573-8ea3-48b9-bdff-dff51371a6a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1515739731-172.17.0.17-1598159962695:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39196,DS-17a97b1a-5581-4d8f-8d7c-c979a195ca1c,DISK], DatanodeInfoWithStorage[127.0.0.1:33180,DS-06a52331-cd44-424d-be1b-6a67ad3956a4,DISK], DatanodeInfoWithStorage[127.0.0.1:44089,DS-551c77cc-e636-46d3-a73d-a54fc75fbe55,DISK], DatanodeInfoWithStorage[127.0.0.1:37090,DS-34c4428e-1306-4f0b-a687-0606fd319231,DISK], DatanodeInfoWithStorage[127.0.0.1:38599,DS-4085bffd-00c6-46d7-bfc3-7e72835a8aaa,DISK], DatanodeInfoWithStorage[127.0.0.1:39784,DS-420752cc-0cd8-41e0-bf77-2209350241c0,DISK], DatanodeInfoWithStorage[127.0.0.1:36038,DS-ed5cf2d4-6dd9-4062-bca1-ffac0ffc6b58,DISK], DatanodeInfoWithStorage[127.0.0.1:40018,DS-337aaad5-6d02-464d-8ae3-9e98a3835826,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1515739731-172.17.0.17-1598159962695:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39196,DS-17a97b1a-5581-4d8f-8d7c-c979a195ca1c,DISK], DatanodeInfoWithStorage[127.0.0.1:33180,DS-06a52331-cd44-424d-be1b-6a67ad3956a4,DISK], DatanodeInfoWithStorage[127.0.0.1:44089,DS-551c77cc-e636-46d3-a73d-a54fc75fbe55,DISK], DatanodeInfoWithStorage[127.0.0.1:37090,DS-34c4428e-1306-4f0b-a687-0606fd319231,DISK], DatanodeInfoWithStorage[127.0.0.1:38599,DS-4085bffd-00c6-46d7-bfc3-7e72835a8aaa,DISK], DatanodeInfoWithStorage[127.0.0.1:39784,DS-420752cc-0cd8-41e0-bf77-2209350241c0,DISK], DatanodeInfoWithStorage[127.0.0.1:36038,DS-ed5cf2d4-6dd9-4062-bca1-ffac0ffc6b58,DISK], DatanodeInfoWithStorage[127.0.0.1:40018,DS-337aaad5-6d02-464d-8ae3-9e98a3835826,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1691507649-172.17.0.17-1598159993483:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36226,DS-87aba6ce-dcc4-4099-a5d6-6145643c3944,DISK], DatanodeInfoWithStorage[127.0.0.1:37794,DS-3e6da479-b2b4-44b1-a86c-12665b255dd6,DISK], DatanodeInfoWithStorage[127.0.0.1:40241,DS-8124c254-80d7-4d4f-acaa-c719613990c4,DISK], DatanodeInfoWithStorage[127.0.0.1:42414,DS-412cdef3-2419-469f-92a9-d300be282216,DISK], DatanodeInfoWithStorage[127.0.0.1:34956,DS-cf87d8ea-5ace-45b3-a311-24aa8586223e,DISK], DatanodeInfoWithStorage[127.0.0.1:36497,DS-29fe01c0-ca8b-4119-96af-cc63aff10a5a,DISK], DatanodeInfoWithStorage[127.0.0.1:41856,DS-bd42207f-0c16-4291-a019-5e3ac4c370a9,DISK], DatanodeInfoWithStorage[127.0.0.1:45554,DS-460dbb70-217c-4750-a480-89f188a4c889,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1691507649-172.17.0.17-1598159993483:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36226,DS-87aba6ce-dcc4-4099-a5d6-6145643c3944,DISK], DatanodeInfoWithStorage[127.0.0.1:37794,DS-3e6da479-b2b4-44b1-a86c-12665b255dd6,DISK], DatanodeInfoWithStorage[127.0.0.1:40241,DS-8124c254-80d7-4d4f-acaa-c719613990c4,DISK], DatanodeInfoWithStorage[127.0.0.1:42414,DS-412cdef3-2419-469f-92a9-d300be282216,DISK], DatanodeInfoWithStorage[127.0.0.1:34956,DS-cf87d8ea-5ace-45b3-a311-24aa8586223e,DISK], DatanodeInfoWithStorage[127.0.0.1:36497,DS-29fe01c0-ca8b-4119-96af-cc63aff10a5a,DISK], DatanodeInfoWithStorage[127.0.0.1:41856,DS-bd42207f-0c16-4291-a019-5e3ac4c370a9,DISK], DatanodeInfoWithStorage[127.0.0.1:45554,DS-460dbb70-217c-4750-a480-89f188a4c889,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-295627874-172.17.0.17-1598160474253:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41804,DS-35f00f72-4ac6-426e-8b72-9dc48da1284e,DISK], DatanodeInfoWithStorage[127.0.0.1:41181,DS-d95ba70a-a6b2-4b86-97bd-626456177aa9,DISK], DatanodeInfoWithStorage[127.0.0.1:44563,DS-ca6da246-76ba-48cc-85a3-e5efd97068af,DISK], DatanodeInfoWithStorage[127.0.0.1:33256,DS-0a997080-bda2-4d22-82bc-2b1e0a0c8869,DISK], DatanodeInfoWithStorage[127.0.0.1:41866,DS-d7fa10fc-0776-400a-9907-a24c987523d4,DISK], DatanodeInfoWithStorage[127.0.0.1:35699,DS-9eeb1cd8-692e-4bbd-ba99-a670f7f6e3d5,DISK], DatanodeInfoWithStorage[127.0.0.1:36975,DS-001fd5ef-cf87-4bb6-a918-799031afedb8,DISK], DatanodeInfoWithStorage[127.0.0.1:41764,DS-7b6783af-44b4-4649-87f3-01c63e6d3476,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-295627874-172.17.0.17-1598160474253:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41804,DS-35f00f72-4ac6-426e-8b72-9dc48da1284e,DISK], DatanodeInfoWithStorage[127.0.0.1:41181,DS-d95ba70a-a6b2-4b86-97bd-626456177aa9,DISK], DatanodeInfoWithStorage[127.0.0.1:44563,DS-ca6da246-76ba-48cc-85a3-e5efd97068af,DISK], DatanodeInfoWithStorage[127.0.0.1:33256,DS-0a997080-bda2-4d22-82bc-2b1e0a0c8869,DISK], DatanodeInfoWithStorage[127.0.0.1:41866,DS-d7fa10fc-0776-400a-9907-a24c987523d4,DISK], DatanodeInfoWithStorage[127.0.0.1:35699,DS-9eeb1cd8-692e-4bbd-ba99-a670f7f6e3d5,DISK], DatanodeInfoWithStorage[127.0.0.1:36975,DS-001fd5ef-cf87-4bb6-a918-799031afedb8,DISK], DatanodeInfoWithStorage[127.0.0.1:41764,DS-7b6783af-44b4-4649-87f3-01c63e6d3476,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-142250822-172.17.0.17-1598160538875:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34048,DS-54719c02-d5be-468e-8972-9738b498e4e9,DISK], DatanodeInfoWithStorage[127.0.0.1:33267,DS-299ed677-a29e-4a23-8700-d7a35b026900,DISK], DatanodeInfoWithStorage[127.0.0.1:39914,DS-7241d440-02bf-4181-8941-3d1bdddfeca2,DISK], DatanodeInfoWithStorage[127.0.0.1:32832,DS-ded24b36-3324-4594-8ed1-4ca8b9ffccc4,DISK], DatanodeInfoWithStorage[127.0.0.1:42788,DS-e0eff4ff-ca46-4b10-b5df-464b291fb53d,DISK], DatanodeInfoWithStorage[127.0.0.1:40893,DS-bb734029-626e-4d5b-8ca0-70a0decf3c18,DISK], DatanodeInfoWithStorage[127.0.0.1:43222,DS-c88b42c4-f4f8-4f5f-94b8-1a82f8f03620,DISK], DatanodeInfoWithStorage[127.0.0.1:39596,DS-3e21aaaf-d125-419f-88ee-f49fd1dc1f06,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-142250822-172.17.0.17-1598160538875:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34048,DS-54719c02-d5be-468e-8972-9738b498e4e9,DISK], DatanodeInfoWithStorage[127.0.0.1:33267,DS-299ed677-a29e-4a23-8700-d7a35b026900,DISK], DatanodeInfoWithStorage[127.0.0.1:39914,DS-7241d440-02bf-4181-8941-3d1bdddfeca2,DISK], DatanodeInfoWithStorage[127.0.0.1:32832,DS-ded24b36-3324-4594-8ed1-4ca8b9ffccc4,DISK], DatanodeInfoWithStorage[127.0.0.1:42788,DS-e0eff4ff-ca46-4b10-b5df-464b291fb53d,DISK], DatanodeInfoWithStorage[127.0.0.1:40893,DS-bb734029-626e-4d5b-8ca0-70a0decf3c18,DISK], DatanodeInfoWithStorage[127.0.0.1:43222,DS-c88b42c4-f4f8-4f5f-94b8-1a82f8f03620,DISK], DatanodeInfoWithStorage[127.0.0.1:39596,DS-3e21aaaf-d125-419f-88ee-f49fd1dc1f06,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-903989672-172.17.0.17-1598160879532:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39599,DS-70581d9b-a72e-4d2a-aad8-f588a0c7d06e,DISK], DatanodeInfoWithStorage[127.0.0.1:41473,DS-6b8f2f03-abf5-41ec-828e-d43419b86c53,DISK], DatanodeInfoWithStorage[127.0.0.1:44982,DS-37196def-c521-4d11-85db-6b3e5b9d7df8,DISK], DatanodeInfoWithStorage[127.0.0.1:37650,DS-ab4154f4-4d99-4688-afc8-3e918155c74e,DISK], DatanodeInfoWithStorage[127.0.0.1:33469,DS-c5b2a181-14c6-4c68-955c-4a4502c96802,DISK], DatanodeInfoWithStorage[127.0.0.1:42725,DS-3cdee75b-c71c-4336-a262-769a65c75dbf,DISK], DatanodeInfoWithStorage[127.0.0.1:38008,DS-5cccd175-5dce-44d2-b3a1-12bdf98b6563,DISK], DatanodeInfoWithStorage[127.0.0.1:43475,DS-ec4bde38-1a97-4a99-a569-74d8ce9ee288,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-903989672-172.17.0.17-1598160879532:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39599,DS-70581d9b-a72e-4d2a-aad8-f588a0c7d06e,DISK], DatanodeInfoWithStorage[127.0.0.1:41473,DS-6b8f2f03-abf5-41ec-828e-d43419b86c53,DISK], DatanodeInfoWithStorage[127.0.0.1:44982,DS-37196def-c521-4d11-85db-6b3e5b9d7df8,DISK], DatanodeInfoWithStorage[127.0.0.1:37650,DS-ab4154f4-4d99-4688-afc8-3e918155c74e,DISK], DatanodeInfoWithStorage[127.0.0.1:33469,DS-c5b2a181-14c6-4c68-955c-4a4502c96802,DISK], DatanodeInfoWithStorage[127.0.0.1:42725,DS-3cdee75b-c71c-4336-a262-769a65c75dbf,DISK], DatanodeInfoWithStorage[127.0.0.1:38008,DS-5cccd175-5dce-44d2-b3a1-12bdf98b6563,DISK], DatanodeInfoWithStorage[127.0.0.1:43475,DS-ec4bde38-1a97-4a99-a569-74d8ce9ee288,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1482276539-172.17.0.17-1598161359378:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43528,DS-03f441d9-d68f-4b5a-a865-80877884106f,DISK], DatanodeInfoWithStorage[127.0.0.1:35983,DS-1f74940e-600a-48d2-9c5e-711204d9f6a7,DISK], DatanodeInfoWithStorage[127.0.0.1:42551,DS-c9d6e6c8-bc1b-444f-89f5-312f6735d97a,DISK], DatanodeInfoWithStorage[127.0.0.1:39684,DS-fee68e7d-793d-4919-a9b5-42836a065356,DISK], DatanodeInfoWithStorage[127.0.0.1:43063,DS-4c287a10-e169-43de-bbea-65fdf2c64475,DISK], DatanodeInfoWithStorage[127.0.0.1:42943,DS-76b6e4a4-b61e-4129-8912-a61a996b4a37,DISK], DatanodeInfoWithStorage[127.0.0.1:41721,DS-23012b8f-5740-4741-ba10-7113f46cc11c,DISK], DatanodeInfoWithStorage[127.0.0.1:44714,DS-adb2c860-ffc8-47da-acfb-dd77b077d0c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1482276539-172.17.0.17-1598161359378:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43528,DS-03f441d9-d68f-4b5a-a865-80877884106f,DISK], DatanodeInfoWithStorage[127.0.0.1:35983,DS-1f74940e-600a-48d2-9c5e-711204d9f6a7,DISK], DatanodeInfoWithStorage[127.0.0.1:42551,DS-c9d6e6c8-bc1b-444f-89f5-312f6735d97a,DISK], DatanodeInfoWithStorage[127.0.0.1:39684,DS-fee68e7d-793d-4919-a9b5-42836a065356,DISK], DatanodeInfoWithStorage[127.0.0.1:43063,DS-4c287a10-e169-43de-bbea-65fdf2c64475,DISK], DatanodeInfoWithStorage[127.0.0.1:42943,DS-76b6e4a4-b61e-4129-8912-a61a996b4a37,DISK], DatanodeInfoWithStorage[127.0.0.1:41721,DS-23012b8f-5740-4741-ba10-7113f46cc11c,DISK], DatanodeInfoWithStorage[127.0.0.1:44714,DS-adb2c860-ffc8-47da-acfb-dd77b077d0c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1008139804-172.17.0.17-1598161465841:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34304,DS-4cafa780-c307-4c83-abc9-c25ad1806d64,DISK], DatanodeInfoWithStorage[127.0.0.1:46119,DS-338a2c41-ecca-4a86-b1b1-5446f740a5e2,DISK], DatanodeInfoWithStorage[127.0.0.1:33008,DS-7d11c749-1e7b-4d1e-8aac-473b0bb98cbf,DISK], DatanodeInfoWithStorage[127.0.0.1:46211,DS-86da0bab-5a86-4edd-a02e-67e5bcf48eed,DISK], DatanodeInfoWithStorage[127.0.0.1:38648,DS-b6c45e82-bf68-4713-9038-ca8a6b64a5c3,DISK], DatanodeInfoWithStorage[127.0.0.1:45767,DS-4b2083a1-e46b-4e34-a1ea-65dbc30bc1c6,DISK], DatanodeInfoWithStorage[127.0.0.1:39377,DS-7686c89c-7abd-4d8e-a427-451fc9946908,DISK], DatanodeInfoWithStorage[127.0.0.1:45813,DS-05413417-c539-4951-b309-81e854ab4ef0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1008139804-172.17.0.17-1598161465841:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34304,DS-4cafa780-c307-4c83-abc9-c25ad1806d64,DISK], DatanodeInfoWithStorage[127.0.0.1:46119,DS-338a2c41-ecca-4a86-b1b1-5446f740a5e2,DISK], DatanodeInfoWithStorage[127.0.0.1:33008,DS-7d11c749-1e7b-4d1e-8aac-473b0bb98cbf,DISK], DatanodeInfoWithStorage[127.0.0.1:46211,DS-86da0bab-5a86-4edd-a02e-67e5bcf48eed,DISK], DatanodeInfoWithStorage[127.0.0.1:38648,DS-b6c45e82-bf68-4713-9038-ca8a6b64a5c3,DISK], DatanodeInfoWithStorage[127.0.0.1:45767,DS-4b2083a1-e46b-4e34-a1ea-65dbc30bc1c6,DISK], DatanodeInfoWithStorage[127.0.0.1:39377,DS-7686c89c-7abd-4d8e-a427-451fc9946908,DISK], DatanodeInfoWithStorage[127.0.0.1:45813,DS-05413417-c539-4951-b309-81e854ab4ef0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-529665731-172.17.0.17-1598161621302:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36284,DS-396c0429-d2b6-42b7-8336-ecdbd182ffa1,DISK], DatanodeInfoWithStorage[127.0.0.1:46426,DS-d0954feb-c18b-4aa3-8d77-243d788c6cd9,DISK], DatanodeInfoWithStorage[127.0.0.1:43794,DS-09f693b7-cce9-4b94-865e-40b5b33ab980,DISK], DatanodeInfoWithStorage[127.0.0.1:46124,DS-8423b98b-e6de-4e4e-8297-512d8c19b32f,DISK], DatanodeInfoWithStorage[127.0.0.1:38567,DS-4cb6bc7b-02b4-4176-bc1f-0bf8b558e595,DISK], DatanodeInfoWithStorage[127.0.0.1:44653,DS-249706a3-914a-4f8e-b007-0f32f52448ac,DISK], DatanodeInfoWithStorage[127.0.0.1:37149,DS-5324ce91-8976-4a79-90b3-5b0a70d0dfe4,DISK], DatanodeInfoWithStorage[127.0.0.1:42393,DS-a3efec85-2663-4fbc-bfaa-32904752a5e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-529665731-172.17.0.17-1598161621302:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36284,DS-396c0429-d2b6-42b7-8336-ecdbd182ffa1,DISK], DatanodeInfoWithStorage[127.0.0.1:46426,DS-d0954feb-c18b-4aa3-8d77-243d788c6cd9,DISK], DatanodeInfoWithStorage[127.0.0.1:43794,DS-09f693b7-cce9-4b94-865e-40b5b33ab980,DISK], DatanodeInfoWithStorage[127.0.0.1:46124,DS-8423b98b-e6de-4e4e-8297-512d8c19b32f,DISK], DatanodeInfoWithStorage[127.0.0.1:38567,DS-4cb6bc7b-02b4-4176-bc1f-0bf8b558e595,DISK], DatanodeInfoWithStorage[127.0.0.1:44653,DS-249706a3-914a-4f8e-b007-0f32f52448ac,DISK], DatanodeInfoWithStorage[127.0.0.1:37149,DS-5324ce91-8976-4a79-90b3-5b0a70d0dfe4,DISK], DatanodeInfoWithStorage[127.0.0.1:42393,DS-a3efec85-2663-4fbc-bfaa-32904752a5e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1698654623-172.17.0.17-1598161744442:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43510,DS-bff9ef07-56e2-4f48-80f0-f14b850b046f,DISK], DatanodeInfoWithStorage[127.0.0.1:40457,DS-0d71056c-1919-4bbd-a229-3d9235959da0,DISK], DatanodeInfoWithStorage[127.0.0.1:45232,DS-bccaf544-33a3-4dc0-8dc5-1355ac257039,DISK], DatanodeInfoWithStorage[127.0.0.1:33541,DS-26bb7a8d-f9bd-4943-8dfa-bee5abb8ece3,DISK], DatanodeInfoWithStorage[127.0.0.1:35195,DS-fd868cc3-43cb-418e-85f6-d84ae75984c3,DISK], DatanodeInfoWithStorage[127.0.0.1:37057,DS-8120abe8-3808-468f-91cf-f3afce14fc22,DISK], DatanodeInfoWithStorage[127.0.0.1:43197,DS-8bcfadcc-affc-44cd-8b40-7ab33bd73108,DISK], DatanodeInfoWithStorage[127.0.0.1:46329,DS-4727bc38-4e84-4378-85a9-ab34ec0a9dfb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1698654623-172.17.0.17-1598161744442:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43510,DS-bff9ef07-56e2-4f48-80f0-f14b850b046f,DISK], DatanodeInfoWithStorage[127.0.0.1:40457,DS-0d71056c-1919-4bbd-a229-3d9235959da0,DISK], DatanodeInfoWithStorage[127.0.0.1:45232,DS-bccaf544-33a3-4dc0-8dc5-1355ac257039,DISK], DatanodeInfoWithStorage[127.0.0.1:33541,DS-26bb7a8d-f9bd-4943-8dfa-bee5abb8ece3,DISK], DatanodeInfoWithStorage[127.0.0.1:35195,DS-fd868cc3-43cb-418e-85f6-d84ae75984c3,DISK], DatanodeInfoWithStorage[127.0.0.1:37057,DS-8120abe8-3808-468f-91cf-f3afce14fc22,DISK], DatanodeInfoWithStorage[127.0.0.1:43197,DS-8bcfadcc-affc-44cd-8b40-7ab33bd73108,DISK], DatanodeInfoWithStorage[127.0.0.1:46329,DS-4727bc38-4e84-4378-85a9-ab34ec0a9dfb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-872432580-172.17.0.17-1598161813176:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45072,DS-2ac71f5d-8774-4c73-9acc-3b766175b213,DISK], DatanodeInfoWithStorage[127.0.0.1:43539,DS-5ae5695a-2511-4b25-ac09-3ff2a0654586,DISK], DatanodeInfoWithStorage[127.0.0.1:33488,DS-e02c322e-4d88-41fa-9162-9fce064bda19,DISK], DatanodeInfoWithStorage[127.0.0.1:39783,DS-560fb6d7-3795-458b-be47-18fbb817fd19,DISK], DatanodeInfoWithStorage[127.0.0.1:42719,DS-575608e0-7376-468b-9f39-e16ca96ae809,DISK], DatanodeInfoWithStorage[127.0.0.1:42818,DS-4c2b5af0-59fa-40dd-b55e-08000483a499,DISK], DatanodeInfoWithStorage[127.0.0.1:40027,DS-4d3487e8-829f-4183-9948-cece53c8e0f8,DISK], DatanodeInfoWithStorage[127.0.0.1:42614,DS-c5872f11-2bc3-47b5-8020-8425fc369ca5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-872432580-172.17.0.17-1598161813176:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45072,DS-2ac71f5d-8774-4c73-9acc-3b766175b213,DISK], DatanodeInfoWithStorage[127.0.0.1:43539,DS-5ae5695a-2511-4b25-ac09-3ff2a0654586,DISK], DatanodeInfoWithStorage[127.0.0.1:33488,DS-e02c322e-4d88-41fa-9162-9fce064bda19,DISK], DatanodeInfoWithStorage[127.0.0.1:39783,DS-560fb6d7-3795-458b-be47-18fbb817fd19,DISK], DatanodeInfoWithStorage[127.0.0.1:42719,DS-575608e0-7376-468b-9f39-e16ca96ae809,DISK], DatanodeInfoWithStorage[127.0.0.1:42818,DS-4c2b5af0-59fa-40dd-b55e-08000483a499,DISK], DatanodeInfoWithStorage[127.0.0.1:40027,DS-4d3487e8-829f-4183-9948-cece53c8e0f8,DISK], DatanodeInfoWithStorage[127.0.0.1:42614,DS-c5872f11-2bc3-47b5-8020-8425fc369ca5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1636641177-172.17.0.17-1598161984764:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46048,DS-8548821b-71c5-4bd6-b455-e9807be09343,DISK], DatanodeInfoWithStorage[127.0.0.1:40534,DS-3b3f8043-073f-4e54-93b9-aa725cefefc3,DISK], DatanodeInfoWithStorage[127.0.0.1:39866,DS-67285b51-8cbd-459b-9825-87fa4dd01d0d,DISK], DatanodeInfoWithStorage[127.0.0.1:42775,DS-3ce12196-74ff-4311-962d-3b2b29a2628a,DISK], DatanodeInfoWithStorage[127.0.0.1:40282,DS-8ed31255-9098-4d3d-9368-8aa59a8768fb,DISK], DatanodeInfoWithStorage[127.0.0.1:42638,DS-be90b5a9-d746-484e-ab8e-d1d1955e3174,DISK], DatanodeInfoWithStorage[127.0.0.1:33628,DS-1b019f7c-91c5-43cb-89a1-256d3d00304b,DISK], DatanodeInfoWithStorage[127.0.0.1:41316,DS-ca206ed6-d715-41f0-9be5-f755db671c71,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1636641177-172.17.0.17-1598161984764:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46048,DS-8548821b-71c5-4bd6-b455-e9807be09343,DISK], DatanodeInfoWithStorage[127.0.0.1:40534,DS-3b3f8043-073f-4e54-93b9-aa725cefefc3,DISK], DatanodeInfoWithStorage[127.0.0.1:39866,DS-67285b51-8cbd-459b-9825-87fa4dd01d0d,DISK], DatanodeInfoWithStorage[127.0.0.1:42775,DS-3ce12196-74ff-4311-962d-3b2b29a2628a,DISK], DatanodeInfoWithStorage[127.0.0.1:40282,DS-8ed31255-9098-4d3d-9368-8aa59a8768fb,DISK], DatanodeInfoWithStorage[127.0.0.1:42638,DS-be90b5a9-d746-484e-ab8e-d1d1955e3174,DISK], DatanodeInfoWithStorage[127.0.0.1:33628,DS-1b019f7c-91c5-43cb-89a1-256d3d00304b,DISK], DatanodeInfoWithStorage[127.0.0.1:41316,DS-ca206ed6-d715-41f0-9be5-f755db671c71,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 9 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 4975
