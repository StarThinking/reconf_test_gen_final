reconf_parameter: dfs.namenode.avoid.write.stale.datanode
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.avoid.write.stale.datanode
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-5912856-172.17.0.18-1598376517241:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45261,DS-e4ed7375-b1c3-4846-a366-57e5ba1c75d6,DISK], DatanodeInfoWithStorage[127.0.0.1:34654,DS-0d334fad-bea3-4191-8cc1-629082e8713c,DISK], DatanodeInfoWithStorage[127.0.0.1:39965,DS-c2335780-3ba2-4a56-8b1c-1899a9e52542,DISK], DatanodeInfoWithStorage[127.0.0.1:33104,DS-896506f3-1045-4aca-9845-4d249d36880f,DISK], DatanodeInfoWithStorage[127.0.0.1:45161,DS-bdf36991-6240-4022-9d9a-bf11b60dc7e9,DISK], DatanodeInfoWithStorage[127.0.0.1:37194,DS-58a524e0-4368-4d55-97a5-58f390fedd7c,DISK], DatanodeInfoWithStorage[127.0.0.1:43087,DS-1c012725-ab57-4d21-9bed-38aa3a80ff9f,DISK], DatanodeInfoWithStorage[127.0.0.1:46548,DS-2ec042f4-4860-4836-b46c-e65974585afc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-5912856-172.17.0.18-1598376517241:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45261,DS-e4ed7375-b1c3-4846-a366-57e5ba1c75d6,DISK], DatanodeInfoWithStorage[127.0.0.1:34654,DS-0d334fad-bea3-4191-8cc1-629082e8713c,DISK], DatanodeInfoWithStorage[127.0.0.1:39965,DS-c2335780-3ba2-4a56-8b1c-1899a9e52542,DISK], DatanodeInfoWithStorage[127.0.0.1:33104,DS-896506f3-1045-4aca-9845-4d249d36880f,DISK], DatanodeInfoWithStorage[127.0.0.1:45161,DS-bdf36991-6240-4022-9d9a-bf11b60dc7e9,DISK], DatanodeInfoWithStorage[127.0.0.1:37194,DS-58a524e0-4368-4d55-97a5-58f390fedd7c,DISK], DatanodeInfoWithStorage[127.0.0.1:43087,DS-1c012725-ab57-4d21-9bed-38aa3a80ff9f,DISK], DatanodeInfoWithStorage[127.0.0.1:46548,DS-2ec042f4-4860-4836-b46c-e65974585afc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.avoid.write.stale.datanode
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-567020443-172.17.0.18-1598376801171:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42689,DS-1f6ef54d-cbff-485d-bea3-10fb92614b60,DISK], DatanodeInfoWithStorage[127.0.0.1:37615,DS-e3db2587-fb7d-47ef-83f3-8c350d68d81b,DISK], DatanodeInfoWithStorage[127.0.0.1:42642,DS-3edfe888-e9be-46e9-9758-0d8479025ec8,DISK], DatanodeInfoWithStorage[127.0.0.1:36094,DS-c45b35bd-29b8-46d7-8c8d-6e6484e13ff2,DISK], DatanodeInfoWithStorage[127.0.0.1:43732,DS-b2943925-64e5-45aa-94ef-ff57e32e2705,DISK], DatanodeInfoWithStorage[127.0.0.1:36722,DS-fc64e7b2-99a2-488a-9eb4-75f3b27fd37c,DISK], DatanodeInfoWithStorage[127.0.0.1:34369,DS-ff69ad14-902e-4ec3-8fef-5477859335cb,DISK], DatanodeInfoWithStorage[127.0.0.1:35133,DS-f144e1cf-5015-4c9b-bae6-5c504ffe3ecb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-567020443-172.17.0.18-1598376801171:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42689,DS-1f6ef54d-cbff-485d-bea3-10fb92614b60,DISK], DatanodeInfoWithStorage[127.0.0.1:37615,DS-e3db2587-fb7d-47ef-83f3-8c350d68d81b,DISK], DatanodeInfoWithStorage[127.0.0.1:42642,DS-3edfe888-e9be-46e9-9758-0d8479025ec8,DISK], DatanodeInfoWithStorage[127.0.0.1:36094,DS-c45b35bd-29b8-46d7-8c8d-6e6484e13ff2,DISK], DatanodeInfoWithStorage[127.0.0.1:43732,DS-b2943925-64e5-45aa-94ef-ff57e32e2705,DISK], DatanodeInfoWithStorage[127.0.0.1:36722,DS-fc64e7b2-99a2-488a-9eb4-75f3b27fd37c,DISK], DatanodeInfoWithStorage[127.0.0.1:34369,DS-ff69ad14-902e-4ec3-8fef-5477859335cb,DISK], DatanodeInfoWithStorage[127.0.0.1:35133,DS-f144e1cf-5015-4c9b-bae6-5c504ffe3ecb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.avoid.write.stale.datanode
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1050416041-172.17.0.18-1598377559527:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39815,DS-a9026fe9-47c0-4d86-98c4-514dedbb72af,DISK], DatanodeInfoWithStorage[127.0.0.1:36954,DS-f567fdd9-101b-4da9-8d77-ce28fab56008,DISK], DatanodeInfoWithStorage[127.0.0.1:40441,DS-ca772b8b-becb-4443-ba06-5c1bcad5d3a2,DISK], DatanodeInfoWithStorage[127.0.0.1:45983,DS-c9f282f3-aebc-4d19-95fa-88560687610e,DISK], DatanodeInfoWithStorage[127.0.0.1:34402,DS-a9458613-c1f4-411b-ae02-302212d00179,DISK], DatanodeInfoWithStorage[127.0.0.1:40529,DS-5816c74b-27db-43dc-b6b5-9e110f8f6bad,DISK], DatanodeInfoWithStorage[127.0.0.1:36802,DS-d7312fbc-d2c3-459c-81d2-0073cc18df93,DISK], DatanodeInfoWithStorage[127.0.0.1:34780,DS-af8e4557-809e-411b-9d98-8ebb1d2fa9fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1050416041-172.17.0.18-1598377559527:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39815,DS-a9026fe9-47c0-4d86-98c4-514dedbb72af,DISK], DatanodeInfoWithStorage[127.0.0.1:36954,DS-f567fdd9-101b-4da9-8d77-ce28fab56008,DISK], DatanodeInfoWithStorage[127.0.0.1:40441,DS-ca772b8b-becb-4443-ba06-5c1bcad5d3a2,DISK], DatanodeInfoWithStorage[127.0.0.1:45983,DS-c9f282f3-aebc-4d19-95fa-88560687610e,DISK], DatanodeInfoWithStorage[127.0.0.1:34402,DS-a9458613-c1f4-411b-ae02-302212d00179,DISK], DatanodeInfoWithStorage[127.0.0.1:40529,DS-5816c74b-27db-43dc-b6b5-9e110f8f6bad,DISK], DatanodeInfoWithStorage[127.0.0.1:36802,DS-d7312fbc-d2c3-459c-81d2-0073cc18df93,DISK], DatanodeInfoWithStorage[127.0.0.1:34780,DS-af8e4557-809e-411b-9d98-8ebb1d2fa9fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.avoid.write.stale.datanode
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-760548937-172.17.0.18-1598377625737:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40766,DS-c35a08cc-8fcb-412e-b73c-38001608ac88,DISK], DatanodeInfoWithStorage[127.0.0.1:34795,DS-9994a56f-fc41-4e11-be55-08ba8359ee0a,DISK], DatanodeInfoWithStorage[127.0.0.1:40651,DS-ae62b82f-83d6-4394-9917-b5494f34008c,DISK], DatanodeInfoWithStorage[127.0.0.1:43231,DS-12910fed-2408-4111-991d-03e62da38bf7,DISK], DatanodeInfoWithStorage[127.0.0.1:39298,DS-71a72dd1-814b-4129-a5a6-8b63b777b4eb,DISK], DatanodeInfoWithStorage[127.0.0.1:44953,DS-f1c29a77-60e5-4ada-a796-2fd4f94c1ee8,DISK], DatanodeInfoWithStorage[127.0.0.1:46014,DS-48a5dcbb-5245-452e-83a7-318ba53475dd,DISK], DatanodeInfoWithStorage[127.0.0.1:34369,DS-4b1eb8dc-7eec-4d6e-8f59-95f677053cf9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-760548937-172.17.0.18-1598377625737:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40766,DS-c35a08cc-8fcb-412e-b73c-38001608ac88,DISK], DatanodeInfoWithStorage[127.0.0.1:34795,DS-9994a56f-fc41-4e11-be55-08ba8359ee0a,DISK], DatanodeInfoWithStorage[127.0.0.1:40651,DS-ae62b82f-83d6-4394-9917-b5494f34008c,DISK], DatanodeInfoWithStorage[127.0.0.1:43231,DS-12910fed-2408-4111-991d-03e62da38bf7,DISK], DatanodeInfoWithStorage[127.0.0.1:39298,DS-71a72dd1-814b-4129-a5a6-8b63b777b4eb,DISK], DatanodeInfoWithStorage[127.0.0.1:44953,DS-f1c29a77-60e5-4ada-a796-2fd4f94c1ee8,DISK], DatanodeInfoWithStorage[127.0.0.1:46014,DS-48a5dcbb-5245-452e-83a7-318ba53475dd,DISK], DatanodeInfoWithStorage[127.0.0.1:34369,DS-4b1eb8dc-7eec-4d6e-8f59-95f677053cf9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.avoid.write.stale.datanode
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-767320528-172.17.0.18-1598377805019:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42699,DS-016c959b-a8bc-42ac-84b0-6f50e01248fa,DISK], DatanodeInfoWithStorage[127.0.0.1:33793,DS-ad37477c-6636-43b6-9a11-2f4f2fc744c0,DISK], DatanodeInfoWithStorage[127.0.0.1:33490,DS-19606818-a11a-4a1f-848e-d8740efe1c55,DISK], DatanodeInfoWithStorage[127.0.0.1:40211,DS-69a0d390-4a73-4d7d-85ba-fd1e4963aa5d,DISK], DatanodeInfoWithStorage[127.0.0.1:39496,DS-d3ce7309-9740-4184-ae2a-d404c8c9c329,DISK], DatanodeInfoWithStorage[127.0.0.1:33680,DS-55542dc6-8e70-4568-80b7-581dd5843bbd,DISK], DatanodeInfoWithStorage[127.0.0.1:34107,DS-39958937-b2cc-4fb7-9dff-053207753aa3,DISK], DatanodeInfoWithStorage[127.0.0.1:36929,DS-a004f04d-578e-4e3b-9df9-2294845601da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-767320528-172.17.0.18-1598377805019:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42699,DS-016c959b-a8bc-42ac-84b0-6f50e01248fa,DISK], DatanodeInfoWithStorage[127.0.0.1:33793,DS-ad37477c-6636-43b6-9a11-2f4f2fc744c0,DISK], DatanodeInfoWithStorage[127.0.0.1:33490,DS-19606818-a11a-4a1f-848e-d8740efe1c55,DISK], DatanodeInfoWithStorage[127.0.0.1:40211,DS-69a0d390-4a73-4d7d-85ba-fd1e4963aa5d,DISK], DatanodeInfoWithStorage[127.0.0.1:39496,DS-d3ce7309-9740-4184-ae2a-d404c8c9c329,DISK], DatanodeInfoWithStorage[127.0.0.1:33680,DS-55542dc6-8e70-4568-80b7-581dd5843bbd,DISK], DatanodeInfoWithStorage[127.0.0.1:34107,DS-39958937-b2cc-4fb7-9dff-053207753aa3,DISK], DatanodeInfoWithStorage[127.0.0.1:36929,DS-a004f04d-578e-4e3b-9df9-2294845601da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.avoid.write.stale.datanode
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-605399130-172.17.0.18-1598377991692:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36260,DS-6ee03fcc-ebde-49ab-a19e-33bbc4df5623,DISK], DatanodeInfoWithStorage[127.0.0.1:33826,DS-eb6bd25a-41a4-4c6a-8b79-3d2cc20611dc,DISK], DatanodeInfoWithStorage[127.0.0.1:43190,DS-92dfcc75-394f-4f1f-add6-cde0eddcbac3,DISK], DatanodeInfoWithStorage[127.0.0.1:44097,DS-92fb68fc-4bcc-4bbd-a39d-ae5b42764db3,DISK], DatanodeInfoWithStorage[127.0.0.1:39971,DS-ef12089b-a486-4b94-8cd3-c2bf0582209e,DISK], DatanodeInfoWithStorage[127.0.0.1:33984,DS-eccc5b5c-45d3-4dc6-ba3e-a2f9e0f00a5f,DISK], DatanodeInfoWithStorage[127.0.0.1:40096,DS-21c34342-28d9-408b-b2a0-05e6f76155f7,DISK], DatanodeInfoWithStorage[127.0.0.1:36646,DS-7d93c629-2906-41cd-be2d-e1a2b4d19091,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-605399130-172.17.0.18-1598377991692:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36260,DS-6ee03fcc-ebde-49ab-a19e-33bbc4df5623,DISK], DatanodeInfoWithStorage[127.0.0.1:33826,DS-eb6bd25a-41a4-4c6a-8b79-3d2cc20611dc,DISK], DatanodeInfoWithStorage[127.0.0.1:43190,DS-92dfcc75-394f-4f1f-add6-cde0eddcbac3,DISK], DatanodeInfoWithStorage[127.0.0.1:44097,DS-92fb68fc-4bcc-4bbd-a39d-ae5b42764db3,DISK], DatanodeInfoWithStorage[127.0.0.1:39971,DS-ef12089b-a486-4b94-8cd3-c2bf0582209e,DISK], DatanodeInfoWithStorage[127.0.0.1:33984,DS-eccc5b5c-45d3-4dc6-ba3e-a2f9e0f00a5f,DISK], DatanodeInfoWithStorage[127.0.0.1:40096,DS-21c34342-28d9-408b-b2a0-05e6f76155f7,DISK], DatanodeInfoWithStorage[127.0.0.1:36646,DS-7d93c629-2906-41cd-be2d-e1a2b4d19091,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.avoid.write.stale.datanode
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1573421380-172.17.0.18-1598378025697:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36089,DS-5592bdd5-19ea-4f8c-bd6b-f929053e9b62,DISK], DatanodeInfoWithStorage[127.0.0.1:37516,DS-ee3d7f5d-1c98-45e6-824c-4f4384a7655c,DISK], DatanodeInfoWithStorage[127.0.0.1:46236,DS-df317da3-c564-435b-a43c-f312192ab411,DISK], DatanodeInfoWithStorage[127.0.0.1:45272,DS-9d9ec9f9-097f-43c3-87ac-c33084611a47,DISK], DatanodeInfoWithStorage[127.0.0.1:44045,DS-4415ed87-be04-406a-83bd-816440be6148,DISK], DatanodeInfoWithStorage[127.0.0.1:44107,DS-b8eecc66-54aa-4e9f-82e0-61ffce5fd6a3,DISK], DatanodeInfoWithStorage[127.0.0.1:42252,DS-a25ff1e2-8dc1-4402-9f8e-54f4a73a5b15,DISK], DatanodeInfoWithStorage[127.0.0.1:43271,DS-bd01dd8f-cc13-4244-8456-d4f570b03d08,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1573421380-172.17.0.18-1598378025697:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36089,DS-5592bdd5-19ea-4f8c-bd6b-f929053e9b62,DISK], DatanodeInfoWithStorage[127.0.0.1:37516,DS-ee3d7f5d-1c98-45e6-824c-4f4384a7655c,DISK], DatanodeInfoWithStorage[127.0.0.1:46236,DS-df317da3-c564-435b-a43c-f312192ab411,DISK], DatanodeInfoWithStorage[127.0.0.1:45272,DS-9d9ec9f9-097f-43c3-87ac-c33084611a47,DISK], DatanodeInfoWithStorage[127.0.0.1:44045,DS-4415ed87-be04-406a-83bd-816440be6148,DISK], DatanodeInfoWithStorage[127.0.0.1:44107,DS-b8eecc66-54aa-4e9f-82e0-61ffce5fd6a3,DISK], DatanodeInfoWithStorage[127.0.0.1:42252,DS-a25ff1e2-8dc1-4402-9f8e-54f4a73a5b15,DISK], DatanodeInfoWithStorage[127.0.0.1:43271,DS-bd01dd8f-cc13-4244-8456-d4f570b03d08,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.avoid.write.stale.datanode
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1688884260-172.17.0.18-1598378312467:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44028,DS-00731c16-dbfa-44eb-9b16-506312c0a687,DISK], DatanodeInfoWithStorage[127.0.0.1:41000,DS-7181104d-366f-4501-82c4-9205c1f27de9,DISK], DatanodeInfoWithStorage[127.0.0.1:33953,DS-e79e1ce1-e63e-4000-8367-92b73be62951,DISK], DatanodeInfoWithStorage[127.0.0.1:35256,DS-090bd35c-ad84-4d85-a47e-814282f5c52f,DISK], DatanodeInfoWithStorage[127.0.0.1:35398,DS-a64f5e0c-22f4-4459-8404-4e2b140514c1,DISK], DatanodeInfoWithStorage[127.0.0.1:45054,DS-f486a49f-3a79-4302-b306-a434a077a840,DISK], DatanodeInfoWithStorage[127.0.0.1:43798,DS-76727e13-15a3-4801-a845-3670b9fbcfc8,DISK], DatanodeInfoWithStorage[127.0.0.1:34556,DS-de27005d-2613-4994-80ce-9348847f6aec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1688884260-172.17.0.18-1598378312467:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44028,DS-00731c16-dbfa-44eb-9b16-506312c0a687,DISK], DatanodeInfoWithStorage[127.0.0.1:41000,DS-7181104d-366f-4501-82c4-9205c1f27de9,DISK], DatanodeInfoWithStorage[127.0.0.1:33953,DS-e79e1ce1-e63e-4000-8367-92b73be62951,DISK], DatanodeInfoWithStorage[127.0.0.1:35256,DS-090bd35c-ad84-4d85-a47e-814282f5c52f,DISK], DatanodeInfoWithStorage[127.0.0.1:35398,DS-a64f5e0c-22f4-4459-8404-4e2b140514c1,DISK], DatanodeInfoWithStorage[127.0.0.1:45054,DS-f486a49f-3a79-4302-b306-a434a077a840,DISK], DatanodeInfoWithStorage[127.0.0.1:43798,DS-76727e13-15a3-4801-a845-3670b9fbcfc8,DISK], DatanodeInfoWithStorage[127.0.0.1:34556,DS-de27005d-2613-4994-80ce-9348847f6aec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.avoid.write.stale.datanode
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-944107189-172.17.0.18-1598378508873:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41082,DS-04f34f7a-80b9-443e-9a9d-c33c2dacbf22,DISK], DatanodeInfoWithStorage[127.0.0.1:42576,DS-56114227-ba7a-4b38-95ab-faf63fba283f,DISK], DatanodeInfoWithStorage[127.0.0.1:45942,DS-05e6467a-356a-46e1-b44a-aca9ee2581f5,DISK], DatanodeInfoWithStorage[127.0.0.1:42895,DS-533c1437-0ea1-4607-9d35-8254bb7ea745,DISK], DatanodeInfoWithStorage[127.0.0.1:38431,DS-9e607f9b-e487-41a1-9ef7-d6df3a96bb47,DISK], DatanodeInfoWithStorage[127.0.0.1:44190,DS-9f7ad27d-f9ef-4e15-9f24-eb4c5001c4d8,DISK], DatanodeInfoWithStorage[127.0.0.1:41744,DS-5bac499e-8aa7-4b8d-b580-83c4c98bb46b,DISK], DatanodeInfoWithStorage[127.0.0.1:46291,DS-34ac02c0-9ae8-42e7-ab06-fbbe2863b3b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-944107189-172.17.0.18-1598378508873:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41082,DS-04f34f7a-80b9-443e-9a9d-c33c2dacbf22,DISK], DatanodeInfoWithStorage[127.0.0.1:42576,DS-56114227-ba7a-4b38-95ab-faf63fba283f,DISK], DatanodeInfoWithStorage[127.0.0.1:45942,DS-05e6467a-356a-46e1-b44a-aca9ee2581f5,DISK], DatanodeInfoWithStorage[127.0.0.1:42895,DS-533c1437-0ea1-4607-9d35-8254bb7ea745,DISK], DatanodeInfoWithStorage[127.0.0.1:38431,DS-9e607f9b-e487-41a1-9ef7-d6df3a96bb47,DISK], DatanodeInfoWithStorage[127.0.0.1:44190,DS-9f7ad27d-f9ef-4e15-9f24-eb4c5001c4d8,DISK], DatanodeInfoWithStorage[127.0.0.1:41744,DS-5bac499e-8aa7-4b8d-b580-83c4c98bb46b,DISK], DatanodeInfoWithStorage[127.0.0.1:46291,DS-34ac02c0-9ae8-42e7-ab06-fbbe2863b3b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.avoid.write.stale.datanode
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1060895288-172.17.0.18-1598378686984:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41730,DS-6c488136-c575-4960-b40b-7ff0616c766a,DISK], DatanodeInfoWithStorage[127.0.0.1:41651,DS-6c92e20b-8dd6-4fe9-99cc-8d03e6ae8ee7,DISK], DatanodeInfoWithStorage[127.0.0.1:44182,DS-743a2138-9497-4eba-a9ea-cc13ef20874c,DISK], DatanodeInfoWithStorage[127.0.0.1:37970,DS-15f1ccc5-20dd-406d-bb59-24556c09d95f,DISK], DatanodeInfoWithStorage[127.0.0.1:37295,DS-c7866e25-8526-487d-8d16-e1b8f5eb6f64,DISK], DatanodeInfoWithStorage[127.0.0.1:35411,DS-5dc128c7-8c42-4775-9722-542fe96b439c,DISK], DatanodeInfoWithStorage[127.0.0.1:39918,DS-d981d651-796c-449b-bd25-b9a9c56ec8ac,DISK], DatanodeInfoWithStorage[127.0.0.1:39531,DS-e0da5157-348b-4f70-8c66-277b50368db3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1060895288-172.17.0.18-1598378686984:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41730,DS-6c488136-c575-4960-b40b-7ff0616c766a,DISK], DatanodeInfoWithStorage[127.0.0.1:41651,DS-6c92e20b-8dd6-4fe9-99cc-8d03e6ae8ee7,DISK], DatanodeInfoWithStorage[127.0.0.1:44182,DS-743a2138-9497-4eba-a9ea-cc13ef20874c,DISK], DatanodeInfoWithStorage[127.0.0.1:37970,DS-15f1ccc5-20dd-406d-bb59-24556c09d95f,DISK], DatanodeInfoWithStorage[127.0.0.1:37295,DS-c7866e25-8526-487d-8d16-e1b8f5eb6f64,DISK], DatanodeInfoWithStorage[127.0.0.1:35411,DS-5dc128c7-8c42-4775-9722-542fe96b439c,DISK], DatanodeInfoWithStorage[127.0.0.1:39918,DS-d981d651-796c-449b-bd25-b9a9c56ec8ac,DISK], DatanodeInfoWithStorage[127.0.0.1:39531,DS-e0da5157-348b-4f70-8c66-277b50368db3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.avoid.write.stale.datanode
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-72773474-172.17.0.18-1598378977263:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36823,DS-96185368-42ea-466e-8746-b9265a6d061d,DISK], DatanodeInfoWithStorage[127.0.0.1:34281,DS-b3220e09-fe03-407f-8943-2a3cf899f6d8,DISK], DatanodeInfoWithStorage[127.0.0.1:35570,DS-dfe3c63f-8698-4d80-a9b1-cb8f7d33db89,DISK], DatanodeInfoWithStorage[127.0.0.1:38285,DS-0d70b43a-e8c4-4c9e-86dc-d4318455a517,DISK], DatanodeInfoWithStorage[127.0.0.1:46666,DS-22aea6d5-d10e-4fb1-983d-df7c04a868a1,DISK], DatanodeInfoWithStorage[127.0.0.1:36444,DS-d0ec0a4e-061d-4c03-8f3c-4aacfe9eb87a,DISK], DatanodeInfoWithStorage[127.0.0.1:38724,DS-9bece261-4644-49bd-86b2-29b65227fc39,DISK], DatanodeInfoWithStorage[127.0.0.1:34748,DS-b3c4d85f-d03d-434c-acbe-a6876b9db452,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-72773474-172.17.0.18-1598378977263:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36823,DS-96185368-42ea-466e-8746-b9265a6d061d,DISK], DatanodeInfoWithStorage[127.0.0.1:34281,DS-b3220e09-fe03-407f-8943-2a3cf899f6d8,DISK], DatanodeInfoWithStorage[127.0.0.1:35570,DS-dfe3c63f-8698-4d80-a9b1-cb8f7d33db89,DISK], DatanodeInfoWithStorage[127.0.0.1:38285,DS-0d70b43a-e8c4-4c9e-86dc-d4318455a517,DISK], DatanodeInfoWithStorage[127.0.0.1:46666,DS-22aea6d5-d10e-4fb1-983d-df7c04a868a1,DISK], DatanodeInfoWithStorage[127.0.0.1:36444,DS-d0ec0a4e-061d-4c03-8f3c-4aacfe9eb87a,DISK], DatanodeInfoWithStorage[127.0.0.1:38724,DS-9bece261-4644-49bd-86b2-29b65227fc39,DISK], DatanodeInfoWithStorage[127.0.0.1:34748,DS-b3c4d85f-d03d-434c-acbe-a6876b9db452,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.avoid.write.stale.datanode
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-16007123-172.17.0.18-1598379118266:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43583,DS-a450ecbc-9edf-4c95-bc0d-b223858f907a,DISK], DatanodeInfoWithStorage[127.0.0.1:44198,DS-37c5c53b-52fc-402c-bbb6-dcdc54dd821e,DISK], DatanodeInfoWithStorage[127.0.0.1:33085,DS-74c60cca-8ff7-4ccb-8781-141410c1f32a,DISK], DatanodeInfoWithStorage[127.0.0.1:44856,DS-b5b5329c-332a-4b66-aa38-09061b8cb6f7,DISK], DatanodeInfoWithStorage[127.0.0.1:44657,DS-1f26662b-c0de-4ecc-a511-4781e873429f,DISK], DatanodeInfoWithStorage[127.0.0.1:40797,DS-4175025e-4d18-44c0-80dc-c48fc267e5b0,DISK], DatanodeInfoWithStorage[127.0.0.1:39161,DS-f92862e7-26dd-42f9-b047-2a556fa4a919,DISK], DatanodeInfoWithStorage[127.0.0.1:36720,DS-c25f9bd5-7a0f-4e13-8c14-62edb0349233,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-16007123-172.17.0.18-1598379118266:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43583,DS-a450ecbc-9edf-4c95-bc0d-b223858f907a,DISK], DatanodeInfoWithStorage[127.0.0.1:44198,DS-37c5c53b-52fc-402c-bbb6-dcdc54dd821e,DISK], DatanodeInfoWithStorage[127.0.0.1:33085,DS-74c60cca-8ff7-4ccb-8781-141410c1f32a,DISK], DatanodeInfoWithStorage[127.0.0.1:44856,DS-b5b5329c-332a-4b66-aa38-09061b8cb6f7,DISK], DatanodeInfoWithStorage[127.0.0.1:44657,DS-1f26662b-c0de-4ecc-a511-4781e873429f,DISK], DatanodeInfoWithStorage[127.0.0.1:40797,DS-4175025e-4d18-44c0-80dc-c48fc267e5b0,DISK], DatanodeInfoWithStorage[127.0.0.1:39161,DS-f92862e7-26dd-42f9-b047-2a556fa4a919,DISK], DatanodeInfoWithStorage[127.0.0.1:36720,DS-c25f9bd5-7a0f-4e13-8c14-62edb0349233,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.avoid.write.stale.datanode
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1834963296-172.17.0.18-1598379477788:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38541,DS-37f0c90a-f001-474b-95c3-3922cfc80d82,DISK], DatanodeInfoWithStorage[127.0.0.1:45626,DS-c4e71038-5e40-494a-8d08-a59301b70a62,DISK], DatanodeInfoWithStorage[127.0.0.1:36331,DS-f65a5e12-f362-42da-9120-88376a12032e,DISK], DatanodeInfoWithStorage[127.0.0.1:37537,DS-04bac975-6279-402b-866a-830907881c5a,DISK], DatanodeInfoWithStorage[127.0.0.1:43177,DS-f9a3e0e5-83d7-4779-abab-ee5a756bf127,DISK], DatanodeInfoWithStorage[127.0.0.1:33729,DS-c9ebd148-8a3c-467c-9df5-4670867e24eb,DISK], DatanodeInfoWithStorage[127.0.0.1:38612,DS-ec51b59e-79b8-49bf-80b3-9a8e283061ca,DISK], DatanodeInfoWithStorage[127.0.0.1:37386,DS-ba568c8d-5927-4a4d-810a-a9d7c518ff5e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1834963296-172.17.0.18-1598379477788:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38541,DS-37f0c90a-f001-474b-95c3-3922cfc80d82,DISK], DatanodeInfoWithStorage[127.0.0.1:45626,DS-c4e71038-5e40-494a-8d08-a59301b70a62,DISK], DatanodeInfoWithStorage[127.0.0.1:36331,DS-f65a5e12-f362-42da-9120-88376a12032e,DISK], DatanodeInfoWithStorage[127.0.0.1:37537,DS-04bac975-6279-402b-866a-830907881c5a,DISK], DatanodeInfoWithStorage[127.0.0.1:43177,DS-f9a3e0e5-83d7-4779-abab-ee5a756bf127,DISK], DatanodeInfoWithStorage[127.0.0.1:33729,DS-c9ebd148-8a3c-467c-9df5-4670867e24eb,DISK], DatanodeInfoWithStorage[127.0.0.1:38612,DS-ec51b59e-79b8-49bf-80b3-9a8e283061ca,DISK], DatanodeInfoWithStorage[127.0.0.1:37386,DS-ba568c8d-5927-4a4d-810a-a9d7c518ff5e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.avoid.write.stale.datanode
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1147352191-172.17.0.18-1598379555173:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36752,DS-3a6bbdcb-1949-491b-a1de-0c11697ef1a1,DISK], DatanodeInfoWithStorage[127.0.0.1:44834,DS-5903675e-9ac9-434c-9fb6-5520c20bc3cd,DISK], DatanodeInfoWithStorage[127.0.0.1:39850,DS-0bdbdea1-6d3e-4fde-803d-1ad52eb75e9a,DISK], DatanodeInfoWithStorage[127.0.0.1:44515,DS-b29dda35-8bfd-4a35-bc2f-5d1261adca22,DISK], DatanodeInfoWithStorage[127.0.0.1:34577,DS-cc9ceffc-5677-4928-b98f-f06631c00b97,DISK], DatanodeInfoWithStorage[127.0.0.1:36337,DS-6bfad02d-5e35-4cc9-bc31-cac72c3a52c8,DISK], DatanodeInfoWithStorage[127.0.0.1:37084,DS-ecbf780c-0270-45c6-a621-e5d5caeee890,DISK], DatanodeInfoWithStorage[127.0.0.1:39284,DS-85879776-4025-4e11-8909-9780b2ac4cf3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1147352191-172.17.0.18-1598379555173:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36752,DS-3a6bbdcb-1949-491b-a1de-0c11697ef1a1,DISK], DatanodeInfoWithStorage[127.0.0.1:44834,DS-5903675e-9ac9-434c-9fb6-5520c20bc3cd,DISK], DatanodeInfoWithStorage[127.0.0.1:39850,DS-0bdbdea1-6d3e-4fde-803d-1ad52eb75e9a,DISK], DatanodeInfoWithStorage[127.0.0.1:44515,DS-b29dda35-8bfd-4a35-bc2f-5d1261adca22,DISK], DatanodeInfoWithStorage[127.0.0.1:34577,DS-cc9ceffc-5677-4928-b98f-f06631c00b97,DISK], DatanodeInfoWithStorage[127.0.0.1:36337,DS-6bfad02d-5e35-4cc9-bc31-cac72c3a52c8,DISK], DatanodeInfoWithStorage[127.0.0.1:37084,DS-ecbf780c-0270-45c6-a621-e5d5caeee890,DISK], DatanodeInfoWithStorage[127.0.0.1:39284,DS-85879776-4025-4e11-8909-9780b2ac4cf3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.avoid.write.stale.datanode
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-687356483-172.17.0.18-1598379592808:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45461,DS-7194dedf-f2cb-473c-826f-1569990a5f74,DISK], DatanodeInfoWithStorage[127.0.0.1:41959,DS-26f1c1db-0f2b-4ecc-b318-5a360568ed6e,DISK], DatanodeInfoWithStorage[127.0.0.1:42852,DS-26680497-3b2f-409f-bf17-1a645b5d2b86,DISK], DatanodeInfoWithStorage[127.0.0.1:46454,DS-89f2f8f2-ef00-42a2-8cfb-9104a01aeb0c,DISK], DatanodeInfoWithStorage[127.0.0.1:45499,DS-34eb83b6-6695-40ee-a7de-72aecdf9a22c,DISK], DatanodeInfoWithStorage[127.0.0.1:42264,DS-cf54bdbc-398c-435b-9d6d-767398350436,DISK], DatanodeInfoWithStorage[127.0.0.1:41784,DS-d2279a1e-77d1-44b1-95dc-4766e3016f7f,DISK], DatanodeInfoWithStorage[127.0.0.1:41912,DS-3c3c1f58-13f2-451a-b0fd-658a516a716d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-687356483-172.17.0.18-1598379592808:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45461,DS-7194dedf-f2cb-473c-826f-1569990a5f74,DISK], DatanodeInfoWithStorage[127.0.0.1:41959,DS-26f1c1db-0f2b-4ecc-b318-5a360568ed6e,DISK], DatanodeInfoWithStorage[127.0.0.1:42852,DS-26680497-3b2f-409f-bf17-1a645b5d2b86,DISK], DatanodeInfoWithStorage[127.0.0.1:46454,DS-89f2f8f2-ef00-42a2-8cfb-9104a01aeb0c,DISK], DatanodeInfoWithStorage[127.0.0.1:45499,DS-34eb83b6-6695-40ee-a7de-72aecdf9a22c,DISK], DatanodeInfoWithStorage[127.0.0.1:42264,DS-cf54bdbc-398c-435b-9d6d-767398350436,DISK], DatanodeInfoWithStorage[127.0.0.1:41784,DS-d2279a1e-77d1-44b1-95dc-4766e3016f7f,DISK], DatanodeInfoWithStorage[127.0.0.1:41912,DS-3c3c1f58-13f2-451a-b0fd-658a516a716d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.avoid.write.stale.datanode
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1250643114-172.17.0.18-1598380094872:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44218,DS-972b1312-aff5-4873-bfd0-97b2e41b2643,DISK], DatanodeInfoWithStorage[127.0.0.1:41767,DS-85748510-7506-4fa4-a820-b945a1f191f2,DISK], DatanodeInfoWithStorage[127.0.0.1:36820,DS-2788c4a5-d7f3-429d-ae4d-6d32fecec6bf,DISK], DatanodeInfoWithStorage[127.0.0.1:33132,DS-d64a2e9d-bab2-4c93-b9e8-4eb5ca5ea019,DISK], DatanodeInfoWithStorage[127.0.0.1:35656,DS-159704e9-6032-4cb7-9b38-fd4b0b7da98b,DISK], DatanodeInfoWithStorage[127.0.0.1:34853,DS-76c68357-c2ba-463a-8071-a2e3d0636200,DISK], DatanodeInfoWithStorage[127.0.0.1:41117,DS-559c80d5-97c4-4ab6-bfbc-d692ee2eb3b6,DISK], DatanodeInfoWithStorage[127.0.0.1:40858,DS-d0004562-c174-452f-9b6a-5daa138e428d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1250643114-172.17.0.18-1598380094872:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44218,DS-972b1312-aff5-4873-bfd0-97b2e41b2643,DISK], DatanodeInfoWithStorage[127.0.0.1:41767,DS-85748510-7506-4fa4-a820-b945a1f191f2,DISK], DatanodeInfoWithStorage[127.0.0.1:36820,DS-2788c4a5-d7f3-429d-ae4d-6d32fecec6bf,DISK], DatanodeInfoWithStorage[127.0.0.1:33132,DS-d64a2e9d-bab2-4c93-b9e8-4eb5ca5ea019,DISK], DatanodeInfoWithStorage[127.0.0.1:35656,DS-159704e9-6032-4cb7-9b38-fd4b0b7da98b,DISK], DatanodeInfoWithStorage[127.0.0.1:34853,DS-76c68357-c2ba-463a-8071-a2e3d0636200,DISK], DatanodeInfoWithStorage[127.0.0.1:41117,DS-559c80d5-97c4-4ab6-bfbc-d692ee2eb3b6,DISK], DatanodeInfoWithStorage[127.0.0.1:40858,DS-d0004562-c174-452f-9b6a-5daa138e428d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.avoid.write.stale.datanode
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-12414702-172.17.0.18-1598380326830:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42031,DS-e0c1e032-163e-4a64-b898-ca20383c8d58,DISK], DatanodeInfoWithStorage[127.0.0.1:41125,DS-666f6317-2a7c-4a73-836c-d1989f8afd67,DISK], DatanodeInfoWithStorage[127.0.0.1:37300,DS-549412cd-693d-42bc-a997-a0a5face63e9,DISK], DatanodeInfoWithStorage[127.0.0.1:44001,DS-2de50942-fee4-4ddc-9fe2-26de760ed1fd,DISK], DatanodeInfoWithStorage[127.0.0.1:46454,DS-38b7af4c-232a-470c-9fbb-4e0dc9a06151,DISK], DatanodeInfoWithStorage[127.0.0.1:44372,DS-471e51d8-03eb-41e7-8b1e-13806109f5f2,DISK], DatanodeInfoWithStorage[127.0.0.1:36961,DS-834c6b2d-55db-46f5-8bb5-1d8d7705faa3,DISK], DatanodeInfoWithStorage[127.0.0.1:45827,DS-6e5291ff-5fbe-40af-9c83-0cadf1457597,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-12414702-172.17.0.18-1598380326830:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42031,DS-e0c1e032-163e-4a64-b898-ca20383c8d58,DISK], DatanodeInfoWithStorage[127.0.0.1:41125,DS-666f6317-2a7c-4a73-836c-d1989f8afd67,DISK], DatanodeInfoWithStorage[127.0.0.1:37300,DS-549412cd-693d-42bc-a997-a0a5face63e9,DISK], DatanodeInfoWithStorage[127.0.0.1:44001,DS-2de50942-fee4-4ddc-9fe2-26de760ed1fd,DISK], DatanodeInfoWithStorage[127.0.0.1:46454,DS-38b7af4c-232a-470c-9fbb-4e0dc9a06151,DISK], DatanodeInfoWithStorage[127.0.0.1:44372,DS-471e51d8-03eb-41e7-8b1e-13806109f5f2,DISK], DatanodeInfoWithStorage[127.0.0.1:36961,DS-834c6b2d-55db-46f5-8bb5-1d8d7705faa3,DISK], DatanodeInfoWithStorage[127.0.0.1:45827,DS-6e5291ff-5fbe-40af-9c83-0cadf1457597,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.avoid.write.stale.datanode
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-44900869-172.17.0.18-1598381038002:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37479,DS-8c2effdd-1b40-4a63-9e8c-728b128d5b03,DISK], DatanodeInfoWithStorage[127.0.0.1:38036,DS-88d3fbce-1298-42a8-bb6c-4b67e9e8f33e,DISK], DatanodeInfoWithStorage[127.0.0.1:38630,DS-3f2e1b20-82d0-4cf3-9c82-f525fbaabd92,DISK], DatanodeInfoWithStorage[127.0.0.1:42996,DS-ca4689ca-9d1f-45e9-84ff-547ce6861d37,DISK], DatanodeInfoWithStorage[127.0.0.1:43783,DS-58f7ffd4-4e68-4a66-bf21-6b0d17d02268,DISK], DatanodeInfoWithStorage[127.0.0.1:36292,DS-2817d865-d7cd-4efe-92e5-31f615e73d8b,DISK], DatanodeInfoWithStorage[127.0.0.1:45583,DS-5c106222-51d9-46d6-8799-ec4ca9165e60,DISK], DatanodeInfoWithStorage[127.0.0.1:39061,DS-2cec3cc7-fafb-42ac-8548-3fe4022edc38,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-44900869-172.17.0.18-1598381038002:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37479,DS-8c2effdd-1b40-4a63-9e8c-728b128d5b03,DISK], DatanodeInfoWithStorage[127.0.0.1:38036,DS-88d3fbce-1298-42a8-bb6c-4b67e9e8f33e,DISK], DatanodeInfoWithStorage[127.0.0.1:38630,DS-3f2e1b20-82d0-4cf3-9c82-f525fbaabd92,DISK], DatanodeInfoWithStorage[127.0.0.1:42996,DS-ca4689ca-9d1f-45e9-84ff-547ce6861d37,DISK], DatanodeInfoWithStorage[127.0.0.1:43783,DS-58f7ffd4-4e68-4a66-bf21-6b0d17d02268,DISK], DatanodeInfoWithStorage[127.0.0.1:36292,DS-2817d865-d7cd-4efe-92e5-31f615e73d8b,DISK], DatanodeInfoWithStorage[127.0.0.1:45583,DS-5c106222-51d9-46d6-8799-ec4ca9165e60,DISK], DatanodeInfoWithStorage[127.0.0.1:39061,DS-2cec3cc7-fafb-42ac-8548-3fe4022edc38,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.avoid.write.stale.datanode
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-882830977-172.17.0.18-1598381105477:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35211,DS-f9542999-2725-473b-8c76-6b246abafa23,DISK], DatanodeInfoWithStorage[127.0.0.1:43665,DS-8c0449d4-5e47-42eb-9cc3-a00a95273800,DISK], DatanodeInfoWithStorage[127.0.0.1:41813,DS-17dccbfc-15c8-4a75-9026-26589a7e5b77,DISK], DatanodeInfoWithStorage[127.0.0.1:36394,DS-77337af7-953e-487f-a866-202565212908,DISK], DatanodeInfoWithStorage[127.0.0.1:44426,DS-22108393-1e05-4fe3-a978-3fc4e0c51e1e,DISK], DatanodeInfoWithStorage[127.0.0.1:40977,DS-a2b24c35-854e-4f83-87ab-9d03a1148834,DISK], DatanodeInfoWithStorage[127.0.0.1:44366,DS-f6d4f23f-1074-477e-9363-882670f55209,DISK], DatanodeInfoWithStorage[127.0.0.1:44678,DS-843bf0bd-3cc4-4ec2-ae87-2ae5988b69d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-882830977-172.17.0.18-1598381105477:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35211,DS-f9542999-2725-473b-8c76-6b246abafa23,DISK], DatanodeInfoWithStorage[127.0.0.1:43665,DS-8c0449d4-5e47-42eb-9cc3-a00a95273800,DISK], DatanodeInfoWithStorage[127.0.0.1:41813,DS-17dccbfc-15c8-4a75-9026-26589a7e5b77,DISK], DatanodeInfoWithStorage[127.0.0.1:36394,DS-77337af7-953e-487f-a866-202565212908,DISK], DatanodeInfoWithStorage[127.0.0.1:44426,DS-22108393-1e05-4fe3-a978-3fc4e0c51e1e,DISK], DatanodeInfoWithStorage[127.0.0.1:40977,DS-a2b24c35-854e-4f83-87ab-9d03a1148834,DISK], DatanodeInfoWithStorage[127.0.0.1:44366,DS-f6d4f23f-1074-477e-9363-882670f55209,DISK], DatanodeInfoWithStorage[127.0.0.1:44678,DS-843bf0bd-3cc4-4ec2-ae87-2ae5988b69d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5488
