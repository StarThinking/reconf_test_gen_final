reconf_parameter: dfs.namenode.block-placement-policy.default.prefer-local-node
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.block-placement-policy.default.prefer-local-node
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-740394953-172.17.0.15-1598166743055:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46567,DS-db600356-dd65-4aa5-883f-4d9488bf779f,DISK], DatanodeInfoWithStorage[127.0.0.1:37580,DS-0a5d06c7-ff63-46e3-b749-8f9d7642272f,DISK], DatanodeInfoWithStorage[127.0.0.1:36766,DS-417c592e-f8b8-4a3d-b4a4-8c682d9fdddb,DISK], DatanodeInfoWithStorage[127.0.0.1:39283,DS-8e3451f2-098f-48b0-863a-60064b7cbc6d,DISK], DatanodeInfoWithStorage[127.0.0.1:35719,DS-579dc3d8-89b4-4980-a41c-4bb87af8cf7e,DISK], DatanodeInfoWithStorage[127.0.0.1:45860,DS-dcfcc064-258c-43a4-bd48-20826d888cf7,DISK], DatanodeInfoWithStorage[127.0.0.1:41806,DS-62e1753b-70d8-4bad-89a7-2fefba658127,DISK], DatanodeInfoWithStorage[127.0.0.1:37571,DS-1b17987f-5229-4f77-a5e7-2770823c5a96,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-740394953-172.17.0.15-1598166743055:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46567,DS-db600356-dd65-4aa5-883f-4d9488bf779f,DISK], DatanodeInfoWithStorage[127.0.0.1:37580,DS-0a5d06c7-ff63-46e3-b749-8f9d7642272f,DISK], DatanodeInfoWithStorage[127.0.0.1:36766,DS-417c592e-f8b8-4a3d-b4a4-8c682d9fdddb,DISK], DatanodeInfoWithStorage[127.0.0.1:39283,DS-8e3451f2-098f-48b0-863a-60064b7cbc6d,DISK], DatanodeInfoWithStorage[127.0.0.1:35719,DS-579dc3d8-89b4-4980-a41c-4bb87af8cf7e,DISK], DatanodeInfoWithStorage[127.0.0.1:45860,DS-dcfcc064-258c-43a4-bd48-20826d888cf7,DISK], DatanodeInfoWithStorage[127.0.0.1:41806,DS-62e1753b-70d8-4bad-89a7-2fefba658127,DISK], DatanodeInfoWithStorage[127.0.0.1:37571,DS-1b17987f-5229-4f77-a5e7-2770823c5a96,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.block-placement-policy.default.prefer-local-node
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1352659105-172.17.0.15-1598166772536:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41458,DS-38983ed2-0240-41b4-b48c-37ef518915f1,DISK], DatanodeInfoWithStorage[127.0.0.1:39831,DS-f3a05ebe-f42e-436e-acc6-9e87087f1ed0,DISK], DatanodeInfoWithStorage[127.0.0.1:45895,DS-ebb38fea-7608-4eff-8888-56ae9c287d53,DISK], DatanodeInfoWithStorage[127.0.0.1:35516,DS-71aa0cab-58bf-440d-9f17-4a94fb2055f6,DISK], DatanodeInfoWithStorage[127.0.0.1:33542,DS-9e374c99-b8c7-4e6d-b848-14445285cc11,DISK], DatanodeInfoWithStorage[127.0.0.1:41155,DS-aba78366-39ef-4e73-ade2-6ee470fcd03a,DISK], DatanodeInfoWithStorage[127.0.0.1:34244,DS-685e0851-0a3d-4f9f-9164-0a3fa635d5e9,DISK], DatanodeInfoWithStorage[127.0.0.1:33926,DS-251e3cfa-dc8b-45d2-8fca-c497c5d67815,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1352659105-172.17.0.15-1598166772536:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41458,DS-38983ed2-0240-41b4-b48c-37ef518915f1,DISK], DatanodeInfoWithStorage[127.0.0.1:39831,DS-f3a05ebe-f42e-436e-acc6-9e87087f1ed0,DISK], DatanodeInfoWithStorage[127.0.0.1:45895,DS-ebb38fea-7608-4eff-8888-56ae9c287d53,DISK], DatanodeInfoWithStorage[127.0.0.1:35516,DS-71aa0cab-58bf-440d-9f17-4a94fb2055f6,DISK], DatanodeInfoWithStorage[127.0.0.1:33542,DS-9e374c99-b8c7-4e6d-b848-14445285cc11,DISK], DatanodeInfoWithStorage[127.0.0.1:41155,DS-aba78366-39ef-4e73-ade2-6ee470fcd03a,DISK], DatanodeInfoWithStorage[127.0.0.1:34244,DS-685e0851-0a3d-4f9f-9164-0a3fa635d5e9,DISK], DatanodeInfoWithStorage[127.0.0.1:33926,DS-251e3cfa-dc8b-45d2-8fca-c497c5d67815,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.block-placement-policy.default.prefer-local-node
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1539875689-172.17.0.15-1598167278561:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34651,DS-6ed80c4f-8615-4c68-b747-1eacc80e3e4b,DISK], DatanodeInfoWithStorage[127.0.0.1:39973,DS-b627df5a-68cd-4d01-9f75-670a362c5442,DISK], DatanodeInfoWithStorage[127.0.0.1:40100,DS-cfd361ce-bfde-4236-bb95-67c820238403,DISK], DatanodeInfoWithStorage[127.0.0.1:39660,DS-3ea7a3fa-a44e-4b31-9c51-66855df6e6fc,DISK], DatanodeInfoWithStorage[127.0.0.1:45340,DS-15e0d4fd-208a-46a0-a5ec-026e829d3955,DISK], DatanodeInfoWithStorage[127.0.0.1:32827,DS-f7fb43b4-2662-4383-9546-efdc3a4a280b,DISK], DatanodeInfoWithStorage[127.0.0.1:34031,DS-e9e933b6-c605-49c9-8aca-9aacf6e0eea2,DISK], DatanodeInfoWithStorage[127.0.0.1:37610,DS-302ef56f-0f9e-4f0a-ba8a-804020cf8b07,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1539875689-172.17.0.15-1598167278561:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34651,DS-6ed80c4f-8615-4c68-b747-1eacc80e3e4b,DISK], DatanodeInfoWithStorage[127.0.0.1:39973,DS-b627df5a-68cd-4d01-9f75-670a362c5442,DISK], DatanodeInfoWithStorage[127.0.0.1:40100,DS-cfd361ce-bfde-4236-bb95-67c820238403,DISK], DatanodeInfoWithStorage[127.0.0.1:39660,DS-3ea7a3fa-a44e-4b31-9c51-66855df6e6fc,DISK], DatanodeInfoWithStorage[127.0.0.1:45340,DS-15e0d4fd-208a-46a0-a5ec-026e829d3955,DISK], DatanodeInfoWithStorage[127.0.0.1:32827,DS-f7fb43b4-2662-4383-9546-efdc3a4a280b,DISK], DatanodeInfoWithStorage[127.0.0.1:34031,DS-e9e933b6-c605-49c9-8aca-9aacf6e0eea2,DISK], DatanodeInfoWithStorage[127.0.0.1:37610,DS-302ef56f-0f9e-4f0a-ba8a-804020cf8b07,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.block-placement-policy.default.prefer-local-node
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-413223187-172.17.0.15-1598167449692:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39560,DS-88b9d2c8-5972-4818-8f83-fbb076e9ab04,DISK], DatanodeInfoWithStorage[127.0.0.1:43899,DS-e3fd15f5-0b45-425b-8484-b321960ecc65,DISK], DatanodeInfoWithStorage[127.0.0.1:44630,DS-ec669ab7-6e6f-47dc-8cad-f45bc55b9833,DISK], DatanodeInfoWithStorage[127.0.0.1:44775,DS-8e5c9ccd-17db-471a-a4c9-563a79bc6f2b,DISK], DatanodeInfoWithStorage[127.0.0.1:41549,DS-c72c68db-3dcb-423d-b049-60a02538986c,DISK], DatanodeInfoWithStorage[127.0.0.1:39726,DS-19e58e94-0c20-4ef4-b249-ded605fdf457,DISK], DatanodeInfoWithStorage[127.0.0.1:35150,DS-c9485b92-09b0-4f41-a8be-5b0abc7232d8,DISK], DatanodeInfoWithStorage[127.0.0.1:40420,DS-77638b8c-76fb-46f8-a138-67f37256e770,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-413223187-172.17.0.15-1598167449692:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39560,DS-88b9d2c8-5972-4818-8f83-fbb076e9ab04,DISK], DatanodeInfoWithStorage[127.0.0.1:43899,DS-e3fd15f5-0b45-425b-8484-b321960ecc65,DISK], DatanodeInfoWithStorage[127.0.0.1:44630,DS-ec669ab7-6e6f-47dc-8cad-f45bc55b9833,DISK], DatanodeInfoWithStorage[127.0.0.1:44775,DS-8e5c9ccd-17db-471a-a4c9-563a79bc6f2b,DISK], DatanodeInfoWithStorage[127.0.0.1:41549,DS-c72c68db-3dcb-423d-b049-60a02538986c,DISK], DatanodeInfoWithStorage[127.0.0.1:39726,DS-19e58e94-0c20-4ef4-b249-ded605fdf457,DISK], DatanodeInfoWithStorage[127.0.0.1:35150,DS-c9485b92-09b0-4f41-a8be-5b0abc7232d8,DISK], DatanodeInfoWithStorage[127.0.0.1:40420,DS-77638b8c-76fb-46f8-a138-67f37256e770,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.block-placement-policy.default.prefer-local-node
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1962142330-172.17.0.15-1598167800458:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36204,DS-8d3fb20b-3e8e-47b6-bbc8-64b33af73605,DISK], DatanodeInfoWithStorage[127.0.0.1:46413,DS-05059005-f891-4f8d-b3cd-8fd603415c1c,DISK], DatanodeInfoWithStorage[127.0.0.1:40914,DS-91b0dcad-5aff-4047-ac42-907a0e3a1016,DISK], DatanodeInfoWithStorage[127.0.0.1:40397,DS-5a797ce8-c9b2-4225-952e-cc98329cbe96,DISK], DatanodeInfoWithStorage[127.0.0.1:37052,DS-051f1f48-a1c2-43ca-a989-908b7dfe1de2,DISK], DatanodeInfoWithStorage[127.0.0.1:35144,DS-816d3b32-6bd2-48da-be9b-b9215d2c6cbd,DISK], DatanodeInfoWithStorage[127.0.0.1:46234,DS-fc92b3cd-41b2-4f1b-80ee-e4f1c96aef6e,DISK], DatanodeInfoWithStorage[127.0.0.1:39077,DS-4536dc3e-b884-461d-8da5-3192f4355fac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1962142330-172.17.0.15-1598167800458:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36204,DS-8d3fb20b-3e8e-47b6-bbc8-64b33af73605,DISK], DatanodeInfoWithStorage[127.0.0.1:46413,DS-05059005-f891-4f8d-b3cd-8fd603415c1c,DISK], DatanodeInfoWithStorage[127.0.0.1:40914,DS-91b0dcad-5aff-4047-ac42-907a0e3a1016,DISK], DatanodeInfoWithStorage[127.0.0.1:40397,DS-5a797ce8-c9b2-4225-952e-cc98329cbe96,DISK], DatanodeInfoWithStorage[127.0.0.1:37052,DS-051f1f48-a1c2-43ca-a989-908b7dfe1de2,DISK], DatanodeInfoWithStorage[127.0.0.1:35144,DS-816d3b32-6bd2-48da-be9b-b9215d2c6cbd,DISK], DatanodeInfoWithStorage[127.0.0.1:46234,DS-fc92b3cd-41b2-4f1b-80ee-e4f1c96aef6e,DISK], DatanodeInfoWithStorage[127.0.0.1:39077,DS-4536dc3e-b884-461d-8da5-3192f4355fac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.block-placement-policy.default.prefer-local-node
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-656562904-172.17.0.15-1598168013179:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37782,DS-a3340a91-bea6-4908-bd2a-7fe32d2fa9b5,DISK], DatanodeInfoWithStorage[127.0.0.1:39676,DS-887804bb-ab7b-4884-a6bf-9ca840d72de4,DISK], DatanodeInfoWithStorage[127.0.0.1:34195,DS-1b41c961-397a-4959-825c-b6ed2fb426e4,DISK], DatanodeInfoWithStorage[127.0.0.1:39609,DS-dc448406-ffa3-44dd-940e-d8b0b3d7e256,DISK], DatanodeInfoWithStorage[127.0.0.1:33501,DS-5444b758-ece4-4581-93f8-ea859f4f16f3,DISK], DatanodeInfoWithStorage[127.0.0.1:45045,DS-f6c5a9a0-eeac-401e-9f74-013be1c15f26,DISK], DatanodeInfoWithStorage[127.0.0.1:34701,DS-b4a54dbf-9e32-47b4-ad54-a15268558248,DISK], DatanodeInfoWithStorage[127.0.0.1:43670,DS-033c512c-e6d5-4fbf-b6db-1d28304a5c6c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-656562904-172.17.0.15-1598168013179:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37782,DS-a3340a91-bea6-4908-bd2a-7fe32d2fa9b5,DISK], DatanodeInfoWithStorage[127.0.0.1:39676,DS-887804bb-ab7b-4884-a6bf-9ca840d72de4,DISK], DatanodeInfoWithStorage[127.0.0.1:34195,DS-1b41c961-397a-4959-825c-b6ed2fb426e4,DISK], DatanodeInfoWithStorage[127.0.0.1:39609,DS-dc448406-ffa3-44dd-940e-d8b0b3d7e256,DISK], DatanodeInfoWithStorage[127.0.0.1:33501,DS-5444b758-ece4-4581-93f8-ea859f4f16f3,DISK], DatanodeInfoWithStorage[127.0.0.1:45045,DS-f6c5a9a0-eeac-401e-9f74-013be1c15f26,DISK], DatanodeInfoWithStorage[127.0.0.1:34701,DS-b4a54dbf-9e32-47b4-ad54-a15268558248,DISK], DatanodeInfoWithStorage[127.0.0.1:43670,DS-033c512c-e6d5-4fbf-b6db-1d28304a5c6c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.block-placement-policy.default.prefer-local-node
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1413870366-172.17.0.15-1598168244290:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37414,DS-d23e15c0-5c7c-440a-87c7-bfde6213a259,DISK], DatanodeInfoWithStorage[127.0.0.1:46444,DS-f81a997d-2cbf-45b3-9470-ce023807e379,DISK], DatanodeInfoWithStorage[127.0.0.1:37184,DS-47b80ec4-197d-4745-9fce-ca2958f3456c,DISK], DatanodeInfoWithStorage[127.0.0.1:38225,DS-e5cab48f-29f3-4aa8-93ae-78dbc84a0b8d,DISK], DatanodeInfoWithStorage[127.0.0.1:35493,DS-01e58d1f-0154-4871-a149-7119d3aceac1,DISK], DatanodeInfoWithStorage[127.0.0.1:35737,DS-da36be3f-3cbf-49b8-b210-50f92fcd9d93,DISK], DatanodeInfoWithStorage[127.0.0.1:39093,DS-be7ce138-38a8-4c76-ab8f-11192e860d79,DISK], DatanodeInfoWithStorage[127.0.0.1:34982,DS-ff2a3042-a461-479c-9dab-016fb5f26f96,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1413870366-172.17.0.15-1598168244290:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37414,DS-d23e15c0-5c7c-440a-87c7-bfde6213a259,DISK], DatanodeInfoWithStorage[127.0.0.1:46444,DS-f81a997d-2cbf-45b3-9470-ce023807e379,DISK], DatanodeInfoWithStorage[127.0.0.1:37184,DS-47b80ec4-197d-4745-9fce-ca2958f3456c,DISK], DatanodeInfoWithStorage[127.0.0.1:38225,DS-e5cab48f-29f3-4aa8-93ae-78dbc84a0b8d,DISK], DatanodeInfoWithStorage[127.0.0.1:35493,DS-01e58d1f-0154-4871-a149-7119d3aceac1,DISK], DatanodeInfoWithStorage[127.0.0.1:35737,DS-da36be3f-3cbf-49b8-b210-50f92fcd9d93,DISK], DatanodeInfoWithStorage[127.0.0.1:39093,DS-be7ce138-38a8-4c76-ab8f-11192e860d79,DISK], DatanodeInfoWithStorage[127.0.0.1:34982,DS-ff2a3042-a461-479c-9dab-016fb5f26f96,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.block-placement-policy.default.prefer-local-node
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1086466050-172.17.0.15-1598168520672:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38043,DS-26c21b50-9a85-431b-b153-ce4c968d408c,DISK], DatanodeInfoWithStorage[127.0.0.1:46249,DS-754f9247-c52b-415c-a6d3-6f3875677051,DISK], DatanodeInfoWithStorage[127.0.0.1:46871,DS-e08067f3-1ffd-4afb-ba01-5bb494dd4404,DISK], DatanodeInfoWithStorage[127.0.0.1:41537,DS-5c7f76dc-8958-4dc2-b2a8-a078e0c01fd5,DISK], DatanodeInfoWithStorage[127.0.0.1:42864,DS-e120a8a3-5ed1-4691-a607-4dbe6f8bbe50,DISK], DatanodeInfoWithStorage[127.0.0.1:36150,DS-3bab19b9-33d7-436e-9a66-1611393cf512,DISK], DatanodeInfoWithStorage[127.0.0.1:46407,DS-f89206b3-414d-4efd-a15e-1b199c2a2b08,DISK], DatanodeInfoWithStorage[127.0.0.1:36241,DS-afbb434c-86e7-400e-9541-a3e71144e8e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1086466050-172.17.0.15-1598168520672:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38043,DS-26c21b50-9a85-431b-b153-ce4c968d408c,DISK], DatanodeInfoWithStorage[127.0.0.1:46249,DS-754f9247-c52b-415c-a6d3-6f3875677051,DISK], DatanodeInfoWithStorage[127.0.0.1:46871,DS-e08067f3-1ffd-4afb-ba01-5bb494dd4404,DISK], DatanodeInfoWithStorage[127.0.0.1:41537,DS-5c7f76dc-8958-4dc2-b2a8-a078e0c01fd5,DISK], DatanodeInfoWithStorage[127.0.0.1:42864,DS-e120a8a3-5ed1-4691-a607-4dbe6f8bbe50,DISK], DatanodeInfoWithStorage[127.0.0.1:36150,DS-3bab19b9-33d7-436e-9a66-1611393cf512,DISK], DatanodeInfoWithStorage[127.0.0.1:46407,DS-f89206b3-414d-4efd-a15e-1b199c2a2b08,DISK], DatanodeInfoWithStorage[127.0.0.1:36241,DS-afbb434c-86e7-400e-9541-a3e71144e8e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.block-placement-policy.default.prefer-local-node
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-405805254-172.17.0.15-1598168766534:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41372,DS-afbc0382-14a4-4daa-bd30-e414f7d94f23,DISK], DatanodeInfoWithStorage[127.0.0.1:45408,DS-66e57159-91fc-4432-b47d-e485594ef9ee,DISK], DatanodeInfoWithStorage[127.0.0.1:45703,DS-f461b6d9-6192-4b64-add7-19fe0ca8b740,DISK], DatanodeInfoWithStorage[127.0.0.1:42296,DS-2da2a657-474a-468f-8de8-92a61960ce31,DISK], DatanodeInfoWithStorage[127.0.0.1:45247,DS-966239b5-1d72-4e02-a397-b4178a412015,DISK], DatanodeInfoWithStorage[127.0.0.1:34518,DS-b55a3fa0-2cbf-4eef-a629-3c67ee9c6503,DISK], DatanodeInfoWithStorage[127.0.0.1:46603,DS-2f35c7ae-6ddc-4605-8d47-6bd3700fdc14,DISK], DatanodeInfoWithStorage[127.0.0.1:46544,DS-6499bbc7-6706-4402-8d1b-0280b4aadd22,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-405805254-172.17.0.15-1598168766534:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41372,DS-afbc0382-14a4-4daa-bd30-e414f7d94f23,DISK], DatanodeInfoWithStorage[127.0.0.1:45408,DS-66e57159-91fc-4432-b47d-e485594ef9ee,DISK], DatanodeInfoWithStorage[127.0.0.1:45703,DS-f461b6d9-6192-4b64-add7-19fe0ca8b740,DISK], DatanodeInfoWithStorage[127.0.0.1:42296,DS-2da2a657-474a-468f-8de8-92a61960ce31,DISK], DatanodeInfoWithStorage[127.0.0.1:45247,DS-966239b5-1d72-4e02-a397-b4178a412015,DISK], DatanodeInfoWithStorage[127.0.0.1:34518,DS-b55a3fa0-2cbf-4eef-a629-3c67ee9c6503,DISK], DatanodeInfoWithStorage[127.0.0.1:46603,DS-2f35c7ae-6ddc-4605-8d47-6bd3700fdc14,DISK], DatanodeInfoWithStorage[127.0.0.1:46544,DS-6499bbc7-6706-4402-8d1b-0280b4aadd22,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.block-placement-policy.default.prefer-local-node
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1150797393-172.17.0.15-1598168882268:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37414,DS-3d195960-d2a3-4c13-9059-24129f4a6bca,DISK], DatanodeInfoWithStorage[127.0.0.1:34890,DS-7c6503d3-7803-4fdc-a522-5472416f78cf,DISK], DatanodeInfoWithStorage[127.0.0.1:43861,DS-392b0ef4-58f4-43f0-8796-33334f77fc36,DISK], DatanodeInfoWithStorage[127.0.0.1:34902,DS-95e8ee90-1645-4bb7-b70d-f879bc9eb518,DISK], DatanodeInfoWithStorage[127.0.0.1:35603,DS-5c7669b5-214f-417f-a10a-040c91a02f5e,DISK], DatanodeInfoWithStorage[127.0.0.1:35732,DS-e1d78353-dc34-48bd-a0ba-c80f57e85964,DISK], DatanodeInfoWithStorage[127.0.0.1:33096,DS-66a289a7-84a7-4871-ab34-128c197fd8bb,DISK], DatanodeInfoWithStorage[127.0.0.1:43892,DS-987c221b-c9a3-494a-9c92-9256b8559742,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1150797393-172.17.0.15-1598168882268:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37414,DS-3d195960-d2a3-4c13-9059-24129f4a6bca,DISK], DatanodeInfoWithStorage[127.0.0.1:34890,DS-7c6503d3-7803-4fdc-a522-5472416f78cf,DISK], DatanodeInfoWithStorage[127.0.0.1:43861,DS-392b0ef4-58f4-43f0-8796-33334f77fc36,DISK], DatanodeInfoWithStorage[127.0.0.1:34902,DS-95e8ee90-1645-4bb7-b70d-f879bc9eb518,DISK], DatanodeInfoWithStorage[127.0.0.1:35603,DS-5c7669b5-214f-417f-a10a-040c91a02f5e,DISK], DatanodeInfoWithStorage[127.0.0.1:35732,DS-e1d78353-dc34-48bd-a0ba-c80f57e85964,DISK], DatanodeInfoWithStorage[127.0.0.1:33096,DS-66a289a7-84a7-4871-ab34-128c197fd8bb,DISK], DatanodeInfoWithStorage[127.0.0.1:43892,DS-987c221b-c9a3-494a-9c92-9256b8559742,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.block-placement-policy.default.prefer-local-node
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-40306416-172.17.0.15-1598169200206:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44643,DS-b5d50e10-0d80-4719-a8ae-c6e7ccaba7cd,DISK], DatanodeInfoWithStorage[127.0.0.1:38959,DS-29353fa0-0b61-4f13-9437-23d1262353eb,DISK], DatanodeInfoWithStorage[127.0.0.1:41154,DS-51e63e59-290c-4ab4-8b6d-b267954ad824,DISK], DatanodeInfoWithStorage[127.0.0.1:35658,DS-bac726df-fb21-489c-adde-84d030a12330,DISK], DatanodeInfoWithStorage[127.0.0.1:35249,DS-300d419d-f0f1-4a54-b464-6bafd2fd63ef,DISK], DatanodeInfoWithStorage[127.0.0.1:35236,DS-5d77ac82-d5f6-4bf6-adf3-4a79c6d94c27,DISK], DatanodeInfoWithStorage[127.0.0.1:36891,DS-c04e37a1-51c3-4704-a729-2fb3163a9ce1,DISK], DatanodeInfoWithStorage[127.0.0.1:35149,DS-67edcd98-a61f-4378-a133-2d2a01ce2236,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-40306416-172.17.0.15-1598169200206:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44643,DS-b5d50e10-0d80-4719-a8ae-c6e7ccaba7cd,DISK], DatanodeInfoWithStorage[127.0.0.1:38959,DS-29353fa0-0b61-4f13-9437-23d1262353eb,DISK], DatanodeInfoWithStorage[127.0.0.1:41154,DS-51e63e59-290c-4ab4-8b6d-b267954ad824,DISK], DatanodeInfoWithStorage[127.0.0.1:35658,DS-bac726df-fb21-489c-adde-84d030a12330,DISK], DatanodeInfoWithStorage[127.0.0.1:35249,DS-300d419d-f0f1-4a54-b464-6bafd2fd63ef,DISK], DatanodeInfoWithStorage[127.0.0.1:35236,DS-5d77ac82-d5f6-4bf6-adf3-4a79c6d94c27,DISK], DatanodeInfoWithStorage[127.0.0.1:36891,DS-c04e37a1-51c3-4704-a729-2fb3163a9ce1,DISK], DatanodeInfoWithStorage[127.0.0.1:35149,DS-67edcd98-a61f-4378-a133-2d2a01ce2236,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.block-placement-policy.default.prefer-local-node
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-494489026-172.17.0.15-1598169504416:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35613,DS-eb95e989-e960-4a90-bfac-087ac232e4d5,DISK], DatanodeInfoWithStorage[127.0.0.1:45684,DS-a8125caf-8ac7-4329-84c5-9a565af651f7,DISK], DatanodeInfoWithStorage[127.0.0.1:40035,DS-e83d91e6-2ff0-470e-aa23-aa4db43e3248,DISK], DatanodeInfoWithStorage[127.0.0.1:35719,DS-aeafe61c-c33f-448f-a654-aa36579897ab,DISK], DatanodeInfoWithStorage[127.0.0.1:45045,DS-14c5682f-055f-4b54-8d16-501651774f3b,DISK], DatanodeInfoWithStorage[127.0.0.1:34135,DS-25821f5f-8945-4197-a862-1c129bc7c198,DISK], DatanodeInfoWithStorage[127.0.0.1:43217,DS-46205b77-b40b-4f2d-ab1f-27a57bab7d15,DISK], DatanodeInfoWithStorage[127.0.0.1:38750,DS-efbe01e6-f16a-4f2f-a0dd-3f5d89c0e921,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-494489026-172.17.0.15-1598169504416:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35613,DS-eb95e989-e960-4a90-bfac-087ac232e4d5,DISK], DatanodeInfoWithStorage[127.0.0.1:45684,DS-a8125caf-8ac7-4329-84c5-9a565af651f7,DISK], DatanodeInfoWithStorage[127.0.0.1:40035,DS-e83d91e6-2ff0-470e-aa23-aa4db43e3248,DISK], DatanodeInfoWithStorage[127.0.0.1:35719,DS-aeafe61c-c33f-448f-a654-aa36579897ab,DISK], DatanodeInfoWithStorage[127.0.0.1:45045,DS-14c5682f-055f-4b54-8d16-501651774f3b,DISK], DatanodeInfoWithStorage[127.0.0.1:34135,DS-25821f5f-8945-4197-a862-1c129bc7c198,DISK], DatanodeInfoWithStorage[127.0.0.1:43217,DS-46205b77-b40b-4f2d-ab1f-27a57bab7d15,DISK], DatanodeInfoWithStorage[127.0.0.1:38750,DS-efbe01e6-f16a-4f2f-a0dd-3f5d89c0e921,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.block-placement-policy.default.prefer-local-node
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-218745116-172.17.0.15-1598170038673:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33450,DS-b55cbbb2-e059-409e-9af4-3b07ca781799,DISK], DatanodeInfoWithStorage[127.0.0.1:41882,DS-210e5d84-b135-44d2-9da2-c3e2c4575492,DISK], DatanodeInfoWithStorage[127.0.0.1:43598,DS-ef05548a-a219-4809-85ee-5f0bff2772a0,DISK], DatanodeInfoWithStorage[127.0.0.1:38149,DS-2d901e13-b152-4bc2-b944-7e171b279115,DISK], DatanodeInfoWithStorage[127.0.0.1:38357,DS-22bec2d9-60c5-4e1e-ba00-c0fbad45115f,DISK], DatanodeInfoWithStorage[127.0.0.1:42410,DS-b36d66ec-5120-4630-8f82-5dc39f44bd54,DISK], DatanodeInfoWithStorage[127.0.0.1:39816,DS-b1c87d49-82a1-4980-ab6d-10938d31ce9c,DISK], DatanodeInfoWithStorage[127.0.0.1:45834,DS-6b0052cd-57b6-4f15-adda-c3228e03ea53,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-218745116-172.17.0.15-1598170038673:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33450,DS-b55cbbb2-e059-409e-9af4-3b07ca781799,DISK], DatanodeInfoWithStorage[127.0.0.1:41882,DS-210e5d84-b135-44d2-9da2-c3e2c4575492,DISK], DatanodeInfoWithStorage[127.0.0.1:43598,DS-ef05548a-a219-4809-85ee-5f0bff2772a0,DISK], DatanodeInfoWithStorage[127.0.0.1:38149,DS-2d901e13-b152-4bc2-b944-7e171b279115,DISK], DatanodeInfoWithStorage[127.0.0.1:38357,DS-22bec2d9-60c5-4e1e-ba00-c0fbad45115f,DISK], DatanodeInfoWithStorage[127.0.0.1:42410,DS-b36d66ec-5120-4630-8f82-5dc39f44bd54,DISK], DatanodeInfoWithStorage[127.0.0.1:39816,DS-b1c87d49-82a1-4980-ab6d-10938d31ce9c,DISK], DatanodeInfoWithStorage[127.0.0.1:45834,DS-6b0052cd-57b6-4f15-adda-c3228e03ea53,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.block-placement-policy.default.prefer-local-node
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1110733012-172.17.0.15-1598170063919:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38223,DS-b5383289-6cea-4205-8f76-80e411d1c2ef,DISK], DatanodeInfoWithStorage[127.0.0.1:38298,DS-c0c36d6f-0dc0-417b-a14f-acbbf5afd17a,DISK], DatanodeInfoWithStorage[127.0.0.1:39719,DS-71ec3266-b7fb-4100-8f20-4a056c809996,DISK], DatanodeInfoWithStorage[127.0.0.1:41235,DS-faccd6bf-e94e-4a90-ad45-f7d0f869702d,DISK], DatanodeInfoWithStorage[127.0.0.1:41311,DS-78b72edf-e27c-46a7-a289-228d1c1b385b,DISK], DatanodeInfoWithStorage[127.0.0.1:40047,DS-1a974da8-77b3-4bc9-a15e-172ae573ed69,DISK], DatanodeInfoWithStorage[127.0.0.1:37686,DS-3df999cc-069a-49dd-b1aa-f60e6db0f998,DISK], DatanodeInfoWithStorage[127.0.0.1:40103,DS-b4d915f6-8fc1-4dbc-9bf7-bd3e3a66be77,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1110733012-172.17.0.15-1598170063919:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38223,DS-b5383289-6cea-4205-8f76-80e411d1c2ef,DISK], DatanodeInfoWithStorage[127.0.0.1:38298,DS-c0c36d6f-0dc0-417b-a14f-acbbf5afd17a,DISK], DatanodeInfoWithStorage[127.0.0.1:39719,DS-71ec3266-b7fb-4100-8f20-4a056c809996,DISK], DatanodeInfoWithStorage[127.0.0.1:41235,DS-faccd6bf-e94e-4a90-ad45-f7d0f869702d,DISK], DatanodeInfoWithStorage[127.0.0.1:41311,DS-78b72edf-e27c-46a7-a289-228d1c1b385b,DISK], DatanodeInfoWithStorage[127.0.0.1:40047,DS-1a974da8-77b3-4bc9-a15e-172ae573ed69,DISK], DatanodeInfoWithStorage[127.0.0.1:37686,DS-3df999cc-069a-49dd-b1aa-f60e6db0f998,DISK], DatanodeInfoWithStorage[127.0.0.1:40103,DS-b4d915f6-8fc1-4dbc-9bf7-bd3e3a66be77,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.block-placement-policy.default.prefer-local-node
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1894685032-172.17.0.15-1598170307814:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40068,DS-f3f3087b-6d69-4629-af86-40d1c552c7cf,DISK], DatanodeInfoWithStorage[127.0.0.1:33031,DS-3863b943-518b-47a9-923e-cfb858928975,DISK], DatanodeInfoWithStorage[127.0.0.1:37230,DS-bf03eeef-9679-4268-9682-5ea19615ab5e,DISK], DatanodeInfoWithStorage[127.0.0.1:32862,DS-205acd06-ebe3-4a5f-8b22-5c1bd95c0a95,DISK], DatanodeInfoWithStorage[127.0.0.1:41264,DS-7ac48d85-0cf7-4c85-8401-4595c54bd59e,DISK], DatanodeInfoWithStorage[127.0.0.1:41805,DS-0a83dfaf-7649-47ee-a3ab-73f003472fef,DISK], DatanodeInfoWithStorage[127.0.0.1:43414,DS-29799b84-6f1c-486e-bbba-444b4a642c38,DISK], DatanodeInfoWithStorage[127.0.0.1:40457,DS-c564338f-0a19-47cb-b5d7-1405b5e35415,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1894685032-172.17.0.15-1598170307814:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40068,DS-f3f3087b-6d69-4629-af86-40d1c552c7cf,DISK], DatanodeInfoWithStorage[127.0.0.1:33031,DS-3863b943-518b-47a9-923e-cfb858928975,DISK], DatanodeInfoWithStorage[127.0.0.1:37230,DS-bf03eeef-9679-4268-9682-5ea19615ab5e,DISK], DatanodeInfoWithStorage[127.0.0.1:32862,DS-205acd06-ebe3-4a5f-8b22-5c1bd95c0a95,DISK], DatanodeInfoWithStorage[127.0.0.1:41264,DS-7ac48d85-0cf7-4c85-8401-4595c54bd59e,DISK], DatanodeInfoWithStorage[127.0.0.1:41805,DS-0a83dfaf-7649-47ee-a3ab-73f003472fef,DISK], DatanodeInfoWithStorage[127.0.0.1:43414,DS-29799b84-6f1c-486e-bbba-444b4a642c38,DISK], DatanodeInfoWithStorage[127.0.0.1:40457,DS-c564338f-0a19-47cb-b5d7-1405b5e35415,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.block-placement-policy.default.prefer-local-node
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1334697142-172.17.0.15-1598171059177:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33153,DS-78a3267a-c144-4537-813b-712464d16b5f,DISK], DatanodeInfoWithStorage[127.0.0.1:45819,DS-1ec06b8c-31c9-4b02-8edc-eea9ac61aceb,DISK], DatanodeInfoWithStorage[127.0.0.1:39153,DS-8e320038-aa99-4c94-b0d3-6dcfd5f749f0,DISK], DatanodeInfoWithStorage[127.0.0.1:34076,DS-00311433-a05b-4044-bb3e-7fcf43c6d412,DISK], DatanodeInfoWithStorage[127.0.0.1:37539,DS-0a0d26ce-3796-4527-a7f7-14a9b85d3958,DISK], DatanodeInfoWithStorage[127.0.0.1:38952,DS-34c3a5b6-a517-4bcb-b51e-113ba92c5dfb,DISK], DatanodeInfoWithStorage[127.0.0.1:37462,DS-0a04bc87-9610-41d4-a921-9e8927d3ddd7,DISK], DatanodeInfoWithStorage[127.0.0.1:45255,DS-e5c0a819-2d6f-43b0-825e-ab86baa896b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1334697142-172.17.0.15-1598171059177:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33153,DS-78a3267a-c144-4537-813b-712464d16b5f,DISK], DatanodeInfoWithStorage[127.0.0.1:45819,DS-1ec06b8c-31c9-4b02-8edc-eea9ac61aceb,DISK], DatanodeInfoWithStorage[127.0.0.1:39153,DS-8e320038-aa99-4c94-b0d3-6dcfd5f749f0,DISK], DatanodeInfoWithStorage[127.0.0.1:34076,DS-00311433-a05b-4044-bb3e-7fcf43c6d412,DISK], DatanodeInfoWithStorage[127.0.0.1:37539,DS-0a0d26ce-3796-4527-a7f7-14a9b85d3958,DISK], DatanodeInfoWithStorage[127.0.0.1:38952,DS-34c3a5b6-a517-4bcb-b51e-113ba92c5dfb,DISK], DatanodeInfoWithStorage[127.0.0.1:37462,DS-0a04bc87-9610-41d4-a921-9e8927d3ddd7,DISK], DatanodeInfoWithStorage[127.0.0.1:45255,DS-e5c0a819-2d6f-43b0-825e-ab86baa896b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.block-placement-policy.default.prefer-local-node
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1129277629-172.17.0.15-1598171138080:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46817,DS-dc0aa5f5-e0da-4949-9dd1-337ff0871f8f,DISK], DatanodeInfoWithStorage[127.0.0.1:46366,DS-afdf29ee-4259-4372-8938-dc8b4ec4bb5c,DISK], DatanodeInfoWithStorage[127.0.0.1:37187,DS-efa2e5a5-3eb5-435d-9e5b-8d14684e0afe,DISK], DatanodeInfoWithStorage[127.0.0.1:39736,DS-5485466d-ae30-4747-8277-62d02cf9ccf4,DISK], DatanodeInfoWithStorage[127.0.0.1:39952,DS-169ba2c8-6b54-4c72-b23a-61964885c9a9,DISK], DatanodeInfoWithStorage[127.0.0.1:43786,DS-d0f764ec-01d5-446a-be3f-1a37a12536f4,DISK], DatanodeInfoWithStorage[127.0.0.1:37969,DS-dd640db2-39ae-4492-8b41-00e059db13f8,DISK], DatanodeInfoWithStorage[127.0.0.1:46197,DS-57b87a9e-3866-4616-9b4e-558c7a340bf3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1129277629-172.17.0.15-1598171138080:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46817,DS-dc0aa5f5-e0da-4949-9dd1-337ff0871f8f,DISK], DatanodeInfoWithStorage[127.0.0.1:46366,DS-afdf29ee-4259-4372-8938-dc8b4ec4bb5c,DISK], DatanodeInfoWithStorage[127.0.0.1:37187,DS-efa2e5a5-3eb5-435d-9e5b-8d14684e0afe,DISK], DatanodeInfoWithStorage[127.0.0.1:39736,DS-5485466d-ae30-4747-8277-62d02cf9ccf4,DISK], DatanodeInfoWithStorage[127.0.0.1:39952,DS-169ba2c8-6b54-4c72-b23a-61964885c9a9,DISK], DatanodeInfoWithStorage[127.0.0.1:43786,DS-d0f764ec-01d5-446a-be3f-1a37a12536f4,DISK], DatanodeInfoWithStorage[127.0.0.1:37969,DS-dd640db2-39ae-4492-8b41-00e059db13f8,DISK], DatanodeInfoWithStorage[127.0.0.1:46197,DS-57b87a9e-3866-4616-9b4e-558c7a340bf3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 5182
