reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-330400950-172.17.0.6-1598149689163:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44624,DS-949c16d8-f95b-4c7c-ae2b-45f4824c1a3c,DISK], DatanodeInfoWithStorage[127.0.0.1:36230,DS-ea0030e3-3c9f-419b-b415-bdde3cb55f0a,DISK], DatanodeInfoWithStorage[127.0.0.1:41141,DS-9ea9c517-bd95-47ab-8bdb-6c87f0cb7dd8,DISK], DatanodeInfoWithStorage[127.0.0.1:42453,DS-4486d4b0-3774-4fcc-9e1b-27ba57964df9,DISK], DatanodeInfoWithStorage[127.0.0.1:40888,DS-44a20733-85f6-4903-bee6-c2319b33fbd3,DISK], DatanodeInfoWithStorage[127.0.0.1:33955,DS-2c7c9bc0-f77c-4499-a93a-9b8b5c423955,DISK], DatanodeInfoWithStorage[127.0.0.1:42261,DS-4886759e-25c9-4a65-94bd-a3301bfd5f6b,DISK], DatanodeInfoWithStorage[127.0.0.1:46818,DS-865c47fb-6db1-4fff-b705-5ce3eee1b86f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-330400950-172.17.0.6-1598149689163:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44624,DS-949c16d8-f95b-4c7c-ae2b-45f4824c1a3c,DISK], DatanodeInfoWithStorage[127.0.0.1:36230,DS-ea0030e3-3c9f-419b-b415-bdde3cb55f0a,DISK], DatanodeInfoWithStorage[127.0.0.1:41141,DS-9ea9c517-bd95-47ab-8bdb-6c87f0cb7dd8,DISK], DatanodeInfoWithStorage[127.0.0.1:42453,DS-4486d4b0-3774-4fcc-9e1b-27ba57964df9,DISK], DatanodeInfoWithStorage[127.0.0.1:40888,DS-44a20733-85f6-4903-bee6-c2319b33fbd3,DISK], DatanodeInfoWithStorage[127.0.0.1:33955,DS-2c7c9bc0-f77c-4499-a93a-9b8b5c423955,DISK], DatanodeInfoWithStorage[127.0.0.1:42261,DS-4886759e-25c9-4a65-94bd-a3301bfd5f6b,DISK], DatanodeInfoWithStorage[127.0.0.1:46818,DS-865c47fb-6db1-4fff-b705-5ce3eee1b86f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-917841450-172.17.0.6-1598149760758:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38454,DS-88cc44fd-1128-472c-8e83-7ec54dd9702c,DISK], DatanodeInfoWithStorage[127.0.0.1:33315,DS-25a46e86-1172-417b-bae3-a109e35ea2ca,DISK], DatanodeInfoWithStorage[127.0.0.1:35074,DS-30c576b2-0339-45c0-a377-1bbba4817e53,DISK], DatanodeInfoWithStorage[127.0.0.1:41742,DS-379213d2-9222-415e-8cca-6f7e6e195be5,DISK], DatanodeInfoWithStorage[127.0.0.1:45175,DS-7fcd1ef4-a8b9-45fa-8eb0-54daedfecb86,DISK], DatanodeInfoWithStorage[127.0.0.1:37617,DS-570ca76f-cfd3-46e0-867d-a16b37061f97,DISK], DatanodeInfoWithStorage[127.0.0.1:33889,DS-53b9b557-c822-4fef-acf4-b4b38d6e42cf,DISK], DatanodeInfoWithStorage[127.0.0.1:37190,DS-c4fc38f2-d5f2-4fcf-b30d-cd5282a234b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-917841450-172.17.0.6-1598149760758:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38454,DS-88cc44fd-1128-472c-8e83-7ec54dd9702c,DISK], DatanodeInfoWithStorage[127.0.0.1:33315,DS-25a46e86-1172-417b-bae3-a109e35ea2ca,DISK], DatanodeInfoWithStorage[127.0.0.1:35074,DS-30c576b2-0339-45c0-a377-1bbba4817e53,DISK], DatanodeInfoWithStorage[127.0.0.1:41742,DS-379213d2-9222-415e-8cca-6f7e6e195be5,DISK], DatanodeInfoWithStorage[127.0.0.1:45175,DS-7fcd1ef4-a8b9-45fa-8eb0-54daedfecb86,DISK], DatanodeInfoWithStorage[127.0.0.1:37617,DS-570ca76f-cfd3-46e0-867d-a16b37061f97,DISK], DatanodeInfoWithStorage[127.0.0.1:33889,DS-53b9b557-c822-4fef-acf4-b4b38d6e42cf,DISK], DatanodeInfoWithStorage[127.0.0.1:37190,DS-c4fc38f2-d5f2-4fcf-b30d-cd5282a234b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-347027254-172.17.0.6-1598150139494:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34048,DS-76193609-a0a3-4be5-ba01-8752645065c3,DISK], DatanodeInfoWithStorage[127.0.0.1:35504,DS-8aed7dca-ce02-43d7-a4da-5819294f5691,DISK], DatanodeInfoWithStorage[127.0.0.1:34680,DS-040d45fe-2a21-43dd-8912-f9adf7346c42,DISK], DatanodeInfoWithStorage[127.0.0.1:42091,DS-239158ce-9e0d-4f40-afd0-3208cf135f92,DISK], DatanodeInfoWithStorage[127.0.0.1:33253,DS-38012194-d95d-4331-bab3-6bb9aca9b868,DISK], DatanodeInfoWithStorage[127.0.0.1:42169,DS-d3be785f-4f97-4c5c-8fc9-151de3a16aea,DISK], DatanodeInfoWithStorage[127.0.0.1:34157,DS-020a7d94-c640-43bc-9785-be7d866a9a64,DISK], DatanodeInfoWithStorage[127.0.0.1:38389,DS-f1d5d27c-6f08-4663-976d-3128f91ccde3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-347027254-172.17.0.6-1598150139494:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34048,DS-76193609-a0a3-4be5-ba01-8752645065c3,DISK], DatanodeInfoWithStorage[127.0.0.1:35504,DS-8aed7dca-ce02-43d7-a4da-5819294f5691,DISK], DatanodeInfoWithStorage[127.0.0.1:34680,DS-040d45fe-2a21-43dd-8912-f9adf7346c42,DISK], DatanodeInfoWithStorage[127.0.0.1:42091,DS-239158ce-9e0d-4f40-afd0-3208cf135f92,DISK], DatanodeInfoWithStorage[127.0.0.1:33253,DS-38012194-d95d-4331-bab3-6bb9aca9b868,DISK], DatanodeInfoWithStorage[127.0.0.1:42169,DS-d3be785f-4f97-4c5c-8fc9-151de3a16aea,DISK], DatanodeInfoWithStorage[127.0.0.1:34157,DS-020a7d94-c640-43bc-9785-be7d866a9a64,DISK], DatanodeInfoWithStorage[127.0.0.1:38389,DS-f1d5d27c-6f08-4663-976d-3128f91ccde3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-185576352-172.17.0.6-1598150208267:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44952,DS-f3ca869e-6b8f-4b75-961e-8f000a3d5a70,DISK], DatanodeInfoWithStorage[127.0.0.1:39374,DS-26353e0f-14e9-4c85-8ce3-42b6328d470d,DISK], DatanodeInfoWithStorage[127.0.0.1:37544,DS-5ebc6fbd-c4d4-49d9-b703-817848453f16,DISK], DatanodeInfoWithStorage[127.0.0.1:42808,DS-f4ac85cf-b984-41b4-9e79-669c236d4363,DISK], DatanodeInfoWithStorage[127.0.0.1:33277,DS-966fb0b4-585a-46ad-ba6f-f1c08c48e689,DISK], DatanodeInfoWithStorage[127.0.0.1:43137,DS-79e27886-352c-4b76-bd60-3da84a23a93f,DISK], DatanodeInfoWithStorage[127.0.0.1:37951,DS-1936af89-cfc6-4bd0-a254-a1580a83afe8,DISK], DatanodeInfoWithStorage[127.0.0.1:42227,DS-14056516-7522-4873-81b4-48dce283a189,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-185576352-172.17.0.6-1598150208267:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44952,DS-f3ca869e-6b8f-4b75-961e-8f000a3d5a70,DISK], DatanodeInfoWithStorage[127.0.0.1:39374,DS-26353e0f-14e9-4c85-8ce3-42b6328d470d,DISK], DatanodeInfoWithStorage[127.0.0.1:37544,DS-5ebc6fbd-c4d4-49d9-b703-817848453f16,DISK], DatanodeInfoWithStorage[127.0.0.1:42808,DS-f4ac85cf-b984-41b4-9e79-669c236d4363,DISK], DatanodeInfoWithStorage[127.0.0.1:33277,DS-966fb0b4-585a-46ad-ba6f-f1c08c48e689,DISK], DatanodeInfoWithStorage[127.0.0.1:43137,DS-79e27886-352c-4b76-bd60-3da84a23a93f,DISK], DatanodeInfoWithStorage[127.0.0.1:37951,DS-1936af89-cfc6-4bd0-a254-a1580a83afe8,DISK], DatanodeInfoWithStorage[127.0.0.1:42227,DS-14056516-7522-4873-81b4-48dce283a189,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1249788566-172.17.0.6-1598150538949:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40096,DS-84a7f021-af75-4b3b-98a6-c743d9f5a865,DISK], DatanodeInfoWithStorage[127.0.0.1:34191,DS-d768034c-b474-4ef8-8dc9-546a96ad6855,DISK], DatanodeInfoWithStorage[127.0.0.1:39699,DS-d505d405-acbd-4e85-aac6-e7e8ece3a2d9,DISK], DatanodeInfoWithStorage[127.0.0.1:35413,DS-1a38a356-f4f2-4813-ac20-f36e7a7262e2,DISK], DatanodeInfoWithStorage[127.0.0.1:46341,DS-572ba6f9-fd26-42a1-8508-0ea1bffa84d0,DISK], DatanodeInfoWithStorage[127.0.0.1:40831,DS-93933a74-1d7b-4cf6-8be9-a08f8612618b,DISK], DatanodeInfoWithStorage[127.0.0.1:42471,DS-0fe991e5-f5e1-4e50-a021-192db98892f4,DISK], DatanodeInfoWithStorage[127.0.0.1:41841,DS-64cc96ad-cebd-4d93-b382-dc9dfae7723a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1249788566-172.17.0.6-1598150538949:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40096,DS-84a7f021-af75-4b3b-98a6-c743d9f5a865,DISK], DatanodeInfoWithStorage[127.0.0.1:34191,DS-d768034c-b474-4ef8-8dc9-546a96ad6855,DISK], DatanodeInfoWithStorage[127.0.0.1:39699,DS-d505d405-acbd-4e85-aac6-e7e8ece3a2d9,DISK], DatanodeInfoWithStorage[127.0.0.1:35413,DS-1a38a356-f4f2-4813-ac20-f36e7a7262e2,DISK], DatanodeInfoWithStorage[127.0.0.1:46341,DS-572ba6f9-fd26-42a1-8508-0ea1bffa84d0,DISK], DatanodeInfoWithStorage[127.0.0.1:40831,DS-93933a74-1d7b-4cf6-8be9-a08f8612618b,DISK], DatanodeInfoWithStorage[127.0.0.1:42471,DS-0fe991e5-f5e1-4e50-a021-192db98892f4,DISK], DatanodeInfoWithStorage[127.0.0.1:41841,DS-64cc96ad-cebd-4d93-b382-dc9dfae7723a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-41571005-172.17.0.6-1598151023609:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37195,DS-8d618be6-0d55-47f9-803d-21de291129d3,DISK], DatanodeInfoWithStorage[127.0.0.1:40171,DS-cbd37fb0-b98a-4036-9539-6f30a7e33511,DISK], DatanodeInfoWithStorage[127.0.0.1:38740,DS-f78ef356-2a18-4bb0-b73f-0957e28fee53,DISK], DatanodeInfoWithStorage[127.0.0.1:37002,DS-0959802f-5bc9-4469-ad01-b72c954b93cd,DISK], DatanodeInfoWithStorage[127.0.0.1:34618,DS-cf9bebff-4e16-4ae5-ae8f-59e2a621cc1e,DISK], DatanodeInfoWithStorage[127.0.0.1:43185,DS-71897ac9-2123-4ae7-b0e3-47cd0759e7aa,DISK], DatanodeInfoWithStorage[127.0.0.1:40381,DS-2f13ab9f-f12b-4d2a-921f-fb6e78c3ad0d,DISK], DatanodeInfoWithStorage[127.0.0.1:35550,DS-b1394b27-7bff-4ad2-a70b-fae59aaa9981,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-41571005-172.17.0.6-1598151023609:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37195,DS-8d618be6-0d55-47f9-803d-21de291129d3,DISK], DatanodeInfoWithStorage[127.0.0.1:40171,DS-cbd37fb0-b98a-4036-9539-6f30a7e33511,DISK], DatanodeInfoWithStorage[127.0.0.1:38740,DS-f78ef356-2a18-4bb0-b73f-0957e28fee53,DISK], DatanodeInfoWithStorage[127.0.0.1:37002,DS-0959802f-5bc9-4469-ad01-b72c954b93cd,DISK], DatanodeInfoWithStorage[127.0.0.1:34618,DS-cf9bebff-4e16-4ae5-ae8f-59e2a621cc1e,DISK], DatanodeInfoWithStorage[127.0.0.1:43185,DS-71897ac9-2123-4ae7-b0e3-47cd0759e7aa,DISK], DatanodeInfoWithStorage[127.0.0.1:40381,DS-2f13ab9f-f12b-4d2a-921f-fb6e78c3ad0d,DISK], DatanodeInfoWithStorage[127.0.0.1:35550,DS-b1394b27-7bff-4ad2-a70b-fae59aaa9981,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1099440919-172.17.0.6-1598151205078:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46556,DS-110291ec-23a3-4ca2-8d02-3babcf3e3784,DISK], DatanodeInfoWithStorage[127.0.0.1:32989,DS-263554a1-83dd-47a9-b784-bba00e05b0c0,DISK], DatanodeInfoWithStorage[127.0.0.1:40295,DS-60c7130e-c340-4ac5-b31e-c34a2fd1a042,DISK], DatanodeInfoWithStorage[127.0.0.1:37537,DS-ea884918-859c-4d9f-a044-64402e7e2657,DISK], DatanodeInfoWithStorage[127.0.0.1:44172,DS-dfb6eb4b-4b32-446d-af1c-a3221401dcdb,DISK], DatanodeInfoWithStorage[127.0.0.1:37028,DS-bc2dd6c9-d5bd-45fd-ab67-a6df0e0e8594,DISK], DatanodeInfoWithStorage[127.0.0.1:34763,DS-ef5629f0-196c-453d-93d7-0b3fc4c8175b,DISK], DatanodeInfoWithStorage[127.0.0.1:42044,DS-39387e35-e5fd-457c-94a9-d7e642428046,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1099440919-172.17.0.6-1598151205078:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46556,DS-110291ec-23a3-4ca2-8d02-3babcf3e3784,DISK], DatanodeInfoWithStorage[127.0.0.1:32989,DS-263554a1-83dd-47a9-b784-bba00e05b0c0,DISK], DatanodeInfoWithStorage[127.0.0.1:40295,DS-60c7130e-c340-4ac5-b31e-c34a2fd1a042,DISK], DatanodeInfoWithStorage[127.0.0.1:37537,DS-ea884918-859c-4d9f-a044-64402e7e2657,DISK], DatanodeInfoWithStorage[127.0.0.1:44172,DS-dfb6eb4b-4b32-446d-af1c-a3221401dcdb,DISK], DatanodeInfoWithStorage[127.0.0.1:37028,DS-bc2dd6c9-d5bd-45fd-ab67-a6df0e0e8594,DISK], DatanodeInfoWithStorage[127.0.0.1:34763,DS-ef5629f0-196c-453d-93d7-0b3fc4c8175b,DISK], DatanodeInfoWithStorage[127.0.0.1:42044,DS-39387e35-e5fd-457c-94a9-d7e642428046,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1902084110-172.17.0.6-1598151496027:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36580,DS-b1109c24-0302-4fa8-84a0-694d340153c0,DISK], DatanodeInfoWithStorage[127.0.0.1:38448,DS-5108787d-e08c-4bf2-9a0b-145aaf0c1e28,DISK], DatanodeInfoWithStorage[127.0.0.1:35489,DS-c8cad293-f9e1-4873-8ecf-adc533293e0c,DISK], DatanodeInfoWithStorage[127.0.0.1:45061,DS-37bbe864-c4ab-4477-80d8-520eb14b8bbe,DISK], DatanodeInfoWithStorage[127.0.0.1:33768,DS-2b75c686-7081-4b5d-8f2f-cbad37d0d238,DISK], DatanodeInfoWithStorage[127.0.0.1:43485,DS-375e103b-1939-4fea-8dd8-e59af5df00ba,DISK], DatanodeInfoWithStorage[127.0.0.1:41390,DS-1c35ea85-b365-4b0f-a23c-3e25f56861c1,DISK], DatanodeInfoWithStorage[127.0.0.1:44664,DS-82075ca9-271f-4c69-9a4d-e8df59b78c44,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1902084110-172.17.0.6-1598151496027:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36580,DS-b1109c24-0302-4fa8-84a0-694d340153c0,DISK], DatanodeInfoWithStorage[127.0.0.1:38448,DS-5108787d-e08c-4bf2-9a0b-145aaf0c1e28,DISK], DatanodeInfoWithStorage[127.0.0.1:35489,DS-c8cad293-f9e1-4873-8ecf-adc533293e0c,DISK], DatanodeInfoWithStorage[127.0.0.1:45061,DS-37bbe864-c4ab-4477-80d8-520eb14b8bbe,DISK], DatanodeInfoWithStorage[127.0.0.1:33768,DS-2b75c686-7081-4b5d-8f2f-cbad37d0d238,DISK], DatanodeInfoWithStorage[127.0.0.1:43485,DS-375e103b-1939-4fea-8dd8-e59af5df00ba,DISK], DatanodeInfoWithStorage[127.0.0.1:41390,DS-1c35ea85-b365-4b0f-a23c-3e25f56861c1,DISK], DatanodeInfoWithStorage[127.0.0.1:44664,DS-82075ca9-271f-4c69-9a4d-e8df59b78c44,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-918110333-172.17.0.6-1598151889539:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41412,DS-b57ded36-253a-4661-bc35-9e619dd235b5,DISK], DatanodeInfoWithStorage[127.0.0.1:38309,DS-b164638a-ed3d-4358-a7bf-e05272722ea0,DISK], DatanodeInfoWithStorage[127.0.0.1:38591,DS-12473239-4bc6-4354-b3a3-3204cf95baa8,DISK], DatanodeInfoWithStorage[127.0.0.1:35430,DS-118308d3-023b-437a-94cb-9af0ffa57789,DISK], DatanodeInfoWithStorage[127.0.0.1:46687,DS-4b446191-88a8-4e66-a3e2-92a1d3da8489,DISK], DatanodeInfoWithStorage[127.0.0.1:34045,DS-03b77a7a-ffad-4fa9-b66e-b41a07eea9f8,DISK], DatanodeInfoWithStorage[127.0.0.1:40567,DS-d67fed7c-dabd-4c6a-9e9d-8af8dc28de43,DISK], DatanodeInfoWithStorage[127.0.0.1:38773,DS-8f384baa-4a4a-4b41-bdcb-fe01fa8629eb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-918110333-172.17.0.6-1598151889539:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41412,DS-b57ded36-253a-4661-bc35-9e619dd235b5,DISK], DatanodeInfoWithStorage[127.0.0.1:38309,DS-b164638a-ed3d-4358-a7bf-e05272722ea0,DISK], DatanodeInfoWithStorage[127.0.0.1:38591,DS-12473239-4bc6-4354-b3a3-3204cf95baa8,DISK], DatanodeInfoWithStorage[127.0.0.1:35430,DS-118308d3-023b-437a-94cb-9af0ffa57789,DISK], DatanodeInfoWithStorage[127.0.0.1:46687,DS-4b446191-88a8-4e66-a3e2-92a1d3da8489,DISK], DatanodeInfoWithStorage[127.0.0.1:34045,DS-03b77a7a-ffad-4fa9-b66e-b41a07eea9f8,DISK], DatanodeInfoWithStorage[127.0.0.1:40567,DS-d67fed7c-dabd-4c6a-9e9d-8af8dc28de43,DISK], DatanodeInfoWithStorage[127.0.0.1:38773,DS-8f384baa-4a4a-4b41-bdcb-fe01fa8629eb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-892842993-172.17.0.6-1598152003690:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37424,DS-59d2a2ba-b428-44f2-85a9-1b983ff58a29,DISK], DatanodeInfoWithStorage[127.0.0.1:34896,DS-b23a948d-4afd-43b3-892f-d2e3ebdcc470,DISK], DatanodeInfoWithStorage[127.0.0.1:45285,DS-9cdc5c5c-0822-4be6-b2b8-dac78acdcf34,DISK], DatanodeInfoWithStorage[127.0.0.1:39661,DS-4f394bb2-39a4-44a1-a381-07cd917065f3,DISK], DatanodeInfoWithStorage[127.0.0.1:36484,DS-2ece6cf6-6ada-4f1c-80d4-71fe8370b8ef,DISK], DatanodeInfoWithStorage[127.0.0.1:35362,DS-3456c89b-2243-4b76-b232-ee499ba4dece,DISK], DatanodeInfoWithStorage[127.0.0.1:33406,DS-3131c7bf-9f10-4c2a-9cc3-eb841e2666a4,DISK], DatanodeInfoWithStorage[127.0.0.1:46271,DS-ef04ba55-8355-4188-ac32-e8cb3cfd5be4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-892842993-172.17.0.6-1598152003690:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37424,DS-59d2a2ba-b428-44f2-85a9-1b983ff58a29,DISK], DatanodeInfoWithStorage[127.0.0.1:34896,DS-b23a948d-4afd-43b3-892f-d2e3ebdcc470,DISK], DatanodeInfoWithStorage[127.0.0.1:45285,DS-9cdc5c5c-0822-4be6-b2b8-dac78acdcf34,DISK], DatanodeInfoWithStorage[127.0.0.1:39661,DS-4f394bb2-39a4-44a1-a381-07cd917065f3,DISK], DatanodeInfoWithStorage[127.0.0.1:36484,DS-2ece6cf6-6ada-4f1c-80d4-71fe8370b8ef,DISK], DatanodeInfoWithStorage[127.0.0.1:35362,DS-3456c89b-2243-4b76-b232-ee499ba4dece,DISK], DatanodeInfoWithStorage[127.0.0.1:33406,DS-3131c7bf-9f10-4c2a-9cc3-eb841e2666a4,DISK], DatanodeInfoWithStorage[127.0.0.1:46271,DS-ef04ba55-8355-4188-ac32-e8cb3cfd5be4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1210981800-172.17.0.6-1598152109045:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37417,DS-d439be4f-0254-4744-80aa-e59e2968e3bf,DISK], DatanodeInfoWithStorage[127.0.0.1:39285,DS-547e7833-0d62-4948-ae58-01b433df1d4a,DISK], DatanodeInfoWithStorage[127.0.0.1:41586,DS-cf61f419-f5d1-4aa2-8687-885611222a89,DISK], DatanodeInfoWithStorage[127.0.0.1:44342,DS-36c63400-ceba-438e-b15d-c9564a9d6d96,DISK], DatanodeInfoWithStorage[127.0.0.1:44268,DS-dbdae42b-031d-4ca9-8816-b3fce1378c96,DISK], DatanodeInfoWithStorage[127.0.0.1:40593,DS-dd095470-c716-4071-bb75-eddd358acd88,DISK], DatanodeInfoWithStorage[127.0.0.1:42322,DS-f79fbdae-25ed-47f9-ae3f-1de9d50ff26b,DISK], DatanodeInfoWithStorage[127.0.0.1:46029,DS-6b0cb251-f132-4cac-9037-7d616faaa3cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1210981800-172.17.0.6-1598152109045:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37417,DS-d439be4f-0254-4744-80aa-e59e2968e3bf,DISK], DatanodeInfoWithStorage[127.0.0.1:39285,DS-547e7833-0d62-4948-ae58-01b433df1d4a,DISK], DatanodeInfoWithStorage[127.0.0.1:41586,DS-cf61f419-f5d1-4aa2-8687-885611222a89,DISK], DatanodeInfoWithStorage[127.0.0.1:44342,DS-36c63400-ceba-438e-b15d-c9564a9d6d96,DISK], DatanodeInfoWithStorage[127.0.0.1:44268,DS-dbdae42b-031d-4ca9-8816-b3fce1378c96,DISK], DatanodeInfoWithStorage[127.0.0.1:40593,DS-dd095470-c716-4071-bb75-eddd358acd88,DISK], DatanodeInfoWithStorage[127.0.0.1:42322,DS-f79fbdae-25ed-47f9-ae3f-1de9d50ff26b,DISK], DatanodeInfoWithStorage[127.0.0.1:46029,DS-6b0cb251-f132-4cac-9037-7d616faaa3cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-308850436-172.17.0.6-1598153468901:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36159,DS-cd417814-1db3-41e1-a718-43ffca505916,DISK], DatanodeInfoWithStorage[127.0.0.1:38053,DS-295bb2d2-ffca-48ed-8703-bf2381d12fa7,DISK], DatanodeInfoWithStorage[127.0.0.1:37188,DS-ccc1bfc9-ce47-4797-87d8-24aa39c76729,DISK], DatanodeInfoWithStorage[127.0.0.1:43687,DS-efc52a77-6717-47ef-b29f-2e5e3229ec1f,DISK], DatanodeInfoWithStorage[127.0.0.1:36869,DS-1dca6a8c-8d8c-45c8-b852-8d439d2e26a6,DISK], DatanodeInfoWithStorage[127.0.0.1:35683,DS-5800d0ee-4e53-4a64-9167-ac9eb99e76bc,DISK], DatanodeInfoWithStorage[127.0.0.1:34483,DS-589ad630-eac5-4d34-bea6-4ef4d94f85ad,DISK], DatanodeInfoWithStorage[127.0.0.1:42396,DS-e46ef68e-f48b-42a9-8249-f5237275912a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-308850436-172.17.0.6-1598153468901:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36159,DS-cd417814-1db3-41e1-a718-43ffca505916,DISK], DatanodeInfoWithStorage[127.0.0.1:38053,DS-295bb2d2-ffca-48ed-8703-bf2381d12fa7,DISK], DatanodeInfoWithStorage[127.0.0.1:37188,DS-ccc1bfc9-ce47-4797-87d8-24aa39c76729,DISK], DatanodeInfoWithStorage[127.0.0.1:43687,DS-efc52a77-6717-47ef-b29f-2e5e3229ec1f,DISK], DatanodeInfoWithStorage[127.0.0.1:36869,DS-1dca6a8c-8d8c-45c8-b852-8d439d2e26a6,DISK], DatanodeInfoWithStorage[127.0.0.1:35683,DS-5800d0ee-4e53-4a64-9167-ac9eb99e76bc,DISK], DatanodeInfoWithStorage[127.0.0.1:34483,DS-589ad630-eac5-4d34-bea6-4ef4d94f85ad,DISK], DatanodeInfoWithStorage[127.0.0.1:42396,DS-e46ef68e-f48b-42a9-8249-f5237275912a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-462478055-172.17.0.6-1598153703986:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40380,DS-d1a687b8-7f10-4b8a-a219-2b3b74108e8e,DISK], DatanodeInfoWithStorage[127.0.0.1:40499,DS-b16a2be5-daad-47f0-8b0f-c8353f4bba17,DISK], DatanodeInfoWithStorage[127.0.0.1:33610,DS-ac8e67d5-b28a-46c2-a6e7-8934a48cdfee,DISK], DatanodeInfoWithStorage[127.0.0.1:37344,DS-0ce660b7-768c-49d4-b9ff-465397772b03,DISK], DatanodeInfoWithStorage[127.0.0.1:44916,DS-cd309808-85ac-4b77-b079-d7e558352ec8,DISK], DatanodeInfoWithStorage[127.0.0.1:35363,DS-3a2a78ef-022e-4f73-8a3e-cc919ca5ffcd,DISK], DatanodeInfoWithStorage[127.0.0.1:37243,DS-35ea8d51-7ac6-4bda-89bc-a07edbcaea8e,DISK], DatanodeInfoWithStorage[127.0.0.1:37546,DS-a7b64a0a-cbc1-459f-be31-86f299df68f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-462478055-172.17.0.6-1598153703986:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40380,DS-d1a687b8-7f10-4b8a-a219-2b3b74108e8e,DISK], DatanodeInfoWithStorage[127.0.0.1:40499,DS-b16a2be5-daad-47f0-8b0f-c8353f4bba17,DISK], DatanodeInfoWithStorage[127.0.0.1:33610,DS-ac8e67d5-b28a-46c2-a6e7-8934a48cdfee,DISK], DatanodeInfoWithStorage[127.0.0.1:37344,DS-0ce660b7-768c-49d4-b9ff-465397772b03,DISK], DatanodeInfoWithStorage[127.0.0.1:44916,DS-cd309808-85ac-4b77-b079-d7e558352ec8,DISK], DatanodeInfoWithStorage[127.0.0.1:35363,DS-3a2a78ef-022e-4f73-8a3e-cc919ca5ffcd,DISK], DatanodeInfoWithStorage[127.0.0.1:37243,DS-35ea8d51-7ac6-4bda-89bc-a07edbcaea8e,DISK], DatanodeInfoWithStorage[127.0.0.1:37546,DS-a7b64a0a-cbc1-459f-be31-86f299df68f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5249
