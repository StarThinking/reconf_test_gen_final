reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2048150442-172.17.0.3-1598468414713:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46671,DS-fafe4949-b446-4ea1-9b7b-15ede0906c98,DISK], DatanodeInfoWithStorage[127.0.0.1:32863,DS-90656d81-7dd3-457d-bb08-1c0d06e2cffe,DISK], DatanodeInfoWithStorage[127.0.0.1:41526,DS-73a4a502-6aa1-4170-93bc-e793ddd54cca,DISK], DatanodeInfoWithStorage[127.0.0.1:43071,DS-8262b5ce-f1c6-4c0f-820f-3ce95688b67c,DISK], DatanodeInfoWithStorage[127.0.0.1:46028,DS-a682db49-220f-49ba-aad3-00a1adaf4b18,DISK], DatanodeInfoWithStorage[127.0.0.1:36382,DS-f4a15044-4d6f-47b8-a63a-5beeadda2361,DISK], DatanodeInfoWithStorage[127.0.0.1:34527,DS-ec60c57c-e75c-4d84-a559-95c5bf9bd58c,DISK], DatanodeInfoWithStorage[127.0.0.1:45116,DS-00007793-8098-44ea-b81f-f6b908cd20a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2048150442-172.17.0.3-1598468414713:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46671,DS-fafe4949-b446-4ea1-9b7b-15ede0906c98,DISK], DatanodeInfoWithStorage[127.0.0.1:32863,DS-90656d81-7dd3-457d-bb08-1c0d06e2cffe,DISK], DatanodeInfoWithStorage[127.0.0.1:41526,DS-73a4a502-6aa1-4170-93bc-e793ddd54cca,DISK], DatanodeInfoWithStorage[127.0.0.1:43071,DS-8262b5ce-f1c6-4c0f-820f-3ce95688b67c,DISK], DatanodeInfoWithStorage[127.0.0.1:46028,DS-a682db49-220f-49ba-aad3-00a1adaf4b18,DISK], DatanodeInfoWithStorage[127.0.0.1:36382,DS-f4a15044-4d6f-47b8-a63a-5beeadda2361,DISK], DatanodeInfoWithStorage[127.0.0.1:34527,DS-ec60c57c-e75c-4d84-a559-95c5bf9bd58c,DISK], DatanodeInfoWithStorage[127.0.0.1:45116,DS-00007793-8098-44ea-b81f-f6b908cd20a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-665330791-172.17.0.3-1598468811002:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46365,DS-903b660a-c63a-433a-abb4-11d49a676314,DISK], DatanodeInfoWithStorage[127.0.0.1:45962,DS-d4aa912d-6674-48e0-b39f-aafbccc9c48c,DISK], DatanodeInfoWithStorage[127.0.0.1:42908,DS-ef1b36a5-98fb-4c03-a4d4-82aeae3c7f43,DISK], DatanodeInfoWithStorage[127.0.0.1:43349,DS-51c1a44d-64ca-4ab6-932f-c754b264aa43,DISK], DatanodeInfoWithStorage[127.0.0.1:45143,DS-5cc12392-fdba-49c4-abcb-f6523abf965e,DISK], DatanodeInfoWithStorage[127.0.0.1:35087,DS-775be1da-8ad6-4e29-84cb-ea4358c97a1c,DISK], DatanodeInfoWithStorage[127.0.0.1:43142,DS-e083db09-b704-45f2-b53d-0412e025e094,DISK], DatanodeInfoWithStorage[127.0.0.1:35469,DS-168da0fa-751d-4a97-ae99-01c05979a5d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-665330791-172.17.0.3-1598468811002:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46365,DS-903b660a-c63a-433a-abb4-11d49a676314,DISK], DatanodeInfoWithStorage[127.0.0.1:45962,DS-d4aa912d-6674-48e0-b39f-aafbccc9c48c,DISK], DatanodeInfoWithStorage[127.0.0.1:42908,DS-ef1b36a5-98fb-4c03-a4d4-82aeae3c7f43,DISK], DatanodeInfoWithStorage[127.0.0.1:43349,DS-51c1a44d-64ca-4ab6-932f-c754b264aa43,DISK], DatanodeInfoWithStorage[127.0.0.1:45143,DS-5cc12392-fdba-49c4-abcb-f6523abf965e,DISK], DatanodeInfoWithStorage[127.0.0.1:35087,DS-775be1da-8ad6-4e29-84cb-ea4358c97a1c,DISK], DatanodeInfoWithStorage[127.0.0.1:43142,DS-e083db09-b704-45f2-b53d-0412e025e094,DISK], DatanodeInfoWithStorage[127.0.0.1:35469,DS-168da0fa-751d-4a97-ae99-01c05979a5d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1847514465-172.17.0.3-1598468957110:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42888,DS-b26a87e3-e7c2-439a-a153-3acc391d0724,DISK], DatanodeInfoWithStorage[127.0.0.1:39354,DS-ad8a758c-01bf-4c24-bd4f-f08ba13df28c,DISK], DatanodeInfoWithStorage[127.0.0.1:41094,DS-e8c76ca2-2a60-429b-a0c3-f0fdcf0acab9,DISK], DatanodeInfoWithStorage[127.0.0.1:46851,DS-2cc63067-d0d3-4383-b691-6495b63cc3c8,DISK], DatanodeInfoWithStorage[127.0.0.1:42923,DS-4a2cf983-f7c8-454e-8b43-20db8585376d,DISK], DatanodeInfoWithStorage[127.0.0.1:35613,DS-49f66e32-47c5-42c4-9e0f-6036b1965fe6,DISK], DatanodeInfoWithStorage[127.0.0.1:46254,DS-303bed82-da5b-4f49-8217-a093ae707875,DISK], DatanodeInfoWithStorage[127.0.0.1:45913,DS-7da08ee4-2879-4965-a7c7-57969bcd902c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1847514465-172.17.0.3-1598468957110:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42888,DS-b26a87e3-e7c2-439a-a153-3acc391d0724,DISK], DatanodeInfoWithStorage[127.0.0.1:39354,DS-ad8a758c-01bf-4c24-bd4f-f08ba13df28c,DISK], DatanodeInfoWithStorage[127.0.0.1:41094,DS-e8c76ca2-2a60-429b-a0c3-f0fdcf0acab9,DISK], DatanodeInfoWithStorage[127.0.0.1:46851,DS-2cc63067-d0d3-4383-b691-6495b63cc3c8,DISK], DatanodeInfoWithStorage[127.0.0.1:42923,DS-4a2cf983-f7c8-454e-8b43-20db8585376d,DISK], DatanodeInfoWithStorage[127.0.0.1:35613,DS-49f66e32-47c5-42c4-9e0f-6036b1965fe6,DISK], DatanodeInfoWithStorage[127.0.0.1:46254,DS-303bed82-da5b-4f49-8217-a093ae707875,DISK], DatanodeInfoWithStorage[127.0.0.1:45913,DS-7da08ee4-2879-4965-a7c7-57969bcd902c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2009216958-172.17.0.3-1598469239255:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44262,DS-088f85c8-2c87-4db7-a605-bed2b3b41ee6,DISK], DatanodeInfoWithStorage[127.0.0.1:37880,DS-02ccf4a1-b9ef-4e90-8d32-54aea5a8533a,DISK], DatanodeInfoWithStorage[127.0.0.1:37484,DS-cab500c6-5795-4148-92c5-763b2caef5fc,DISK], DatanodeInfoWithStorage[127.0.0.1:41197,DS-822947d3-1024-4c64-88d6-0b040ede2985,DISK], DatanodeInfoWithStorage[127.0.0.1:42900,DS-3278589b-7869-4436-9c9c-5da724b9edef,DISK], DatanodeInfoWithStorage[127.0.0.1:41660,DS-84944c6a-2f59-4117-a510-32bfecdd666f,DISK], DatanodeInfoWithStorage[127.0.0.1:35323,DS-ec1f7d2f-e625-46a9-acaf-1cb75a1c49c4,DISK], DatanodeInfoWithStorage[127.0.0.1:46473,DS-9ae6d793-262e-4d26-aaed-ca774fc01ce4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2009216958-172.17.0.3-1598469239255:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44262,DS-088f85c8-2c87-4db7-a605-bed2b3b41ee6,DISK], DatanodeInfoWithStorage[127.0.0.1:37880,DS-02ccf4a1-b9ef-4e90-8d32-54aea5a8533a,DISK], DatanodeInfoWithStorage[127.0.0.1:37484,DS-cab500c6-5795-4148-92c5-763b2caef5fc,DISK], DatanodeInfoWithStorage[127.0.0.1:41197,DS-822947d3-1024-4c64-88d6-0b040ede2985,DISK], DatanodeInfoWithStorage[127.0.0.1:42900,DS-3278589b-7869-4436-9c9c-5da724b9edef,DISK], DatanodeInfoWithStorage[127.0.0.1:41660,DS-84944c6a-2f59-4117-a510-32bfecdd666f,DISK], DatanodeInfoWithStorage[127.0.0.1:35323,DS-ec1f7d2f-e625-46a9-acaf-1cb75a1c49c4,DISK], DatanodeInfoWithStorage[127.0.0.1:46473,DS-9ae6d793-262e-4d26-aaed-ca774fc01ce4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-628427040-172.17.0.3-1598470140429:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33389,DS-1655bf8f-cce8-45a6-b22f-40f4da173d6a,DISK], DatanodeInfoWithStorage[127.0.0.1:46019,DS-2f980aee-9015-4477-84eb-949a6f71339e,DISK], DatanodeInfoWithStorage[127.0.0.1:38481,DS-59f2edc0-e705-4f38-93e0-5b6fcfb75f7e,DISK], DatanodeInfoWithStorage[127.0.0.1:36601,DS-14242e74-bf8c-4381-b7fb-4072fbcf000e,DISK], DatanodeInfoWithStorage[127.0.0.1:33701,DS-a7c878e8-ed09-4d90-8f77-e0146e352ea1,DISK], DatanodeInfoWithStorage[127.0.0.1:35416,DS-cbde969f-93c2-414b-8f1c-bda386f3fecf,DISK], DatanodeInfoWithStorage[127.0.0.1:45187,DS-db4a2f60-0348-4d4e-9cb1-1c7f77f746c1,DISK], DatanodeInfoWithStorage[127.0.0.1:36510,DS-5cd165a3-d4ac-414d-b635-8e3d09fea64d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-628427040-172.17.0.3-1598470140429:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33389,DS-1655bf8f-cce8-45a6-b22f-40f4da173d6a,DISK], DatanodeInfoWithStorage[127.0.0.1:46019,DS-2f980aee-9015-4477-84eb-949a6f71339e,DISK], DatanodeInfoWithStorage[127.0.0.1:38481,DS-59f2edc0-e705-4f38-93e0-5b6fcfb75f7e,DISK], DatanodeInfoWithStorage[127.0.0.1:36601,DS-14242e74-bf8c-4381-b7fb-4072fbcf000e,DISK], DatanodeInfoWithStorage[127.0.0.1:33701,DS-a7c878e8-ed09-4d90-8f77-e0146e352ea1,DISK], DatanodeInfoWithStorage[127.0.0.1:35416,DS-cbde969f-93c2-414b-8f1c-bda386f3fecf,DISK], DatanodeInfoWithStorage[127.0.0.1:45187,DS-db4a2f60-0348-4d4e-9cb1-1c7f77f746c1,DISK], DatanodeInfoWithStorage[127.0.0.1:36510,DS-5cd165a3-d4ac-414d-b635-8e3d09fea64d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2003542439-172.17.0.3-1598470637365:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36144,DS-bca7b12f-dabf-4cb6-abe6-f4f6f9c6726d,DISK], DatanodeInfoWithStorage[127.0.0.1:45979,DS-8f758870-2b81-4066-9eaf-5559f0f957b3,DISK], DatanodeInfoWithStorage[127.0.0.1:33627,DS-0980464c-17cc-4b83-b84e-257bb69f21da,DISK], DatanodeInfoWithStorage[127.0.0.1:41195,DS-51f6b1bf-5542-403b-9669-40ae9b304267,DISK], DatanodeInfoWithStorage[127.0.0.1:39492,DS-0fd2218a-c217-4fbf-b899-e3519901b1c7,DISK], DatanodeInfoWithStorage[127.0.0.1:39315,DS-9d6a9a6e-e90d-4a96-b999-c9d270ad5f0f,DISK], DatanodeInfoWithStorage[127.0.0.1:33398,DS-f14b9dd0-37e5-459a-9853-7909c777de6c,DISK], DatanodeInfoWithStorage[127.0.0.1:34545,DS-2369582c-8bb8-47c8-87d2-8bdce3b5c538,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2003542439-172.17.0.3-1598470637365:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36144,DS-bca7b12f-dabf-4cb6-abe6-f4f6f9c6726d,DISK], DatanodeInfoWithStorage[127.0.0.1:45979,DS-8f758870-2b81-4066-9eaf-5559f0f957b3,DISK], DatanodeInfoWithStorage[127.0.0.1:33627,DS-0980464c-17cc-4b83-b84e-257bb69f21da,DISK], DatanodeInfoWithStorage[127.0.0.1:41195,DS-51f6b1bf-5542-403b-9669-40ae9b304267,DISK], DatanodeInfoWithStorage[127.0.0.1:39492,DS-0fd2218a-c217-4fbf-b899-e3519901b1c7,DISK], DatanodeInfoWithStorage[127.0.0.1:39315,DS-9d6a9a6e-e90d-4a96-b999-c9d270ad5f0f,DISK], DatanodeInfoWithStorage[127.0.0.1:33398,DS-f14b9dd0-37e5-459a-9853-7909c777de6c,DISK], DatanodeInfoWithStorage[127.0.0.1:34545,DS-2369582c-8bb8-47c8-87d2-8bdce3b5c538,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1443238265-172.17.0.3-1598470732027:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42289,DS-71bf6e45-da04-46d9-bbdd-281a260f6318,DISK], DatanodeInfoWithStorage[127.0.0.1:42620,DS-cde5b1a3-77a9-4317-ae74-e2a9d3bd51b9,DISK], DatanodeInfoWithStorage[127.0.0.1:46389,DS-3337a125-7f90-4826-822a-16b950440679,DISK], DatanodeInfoWithStorage[127.0.0.1:36426,DS-616f0de8-95a6-437f-90f0-8a27bbb40be6,DISK], DatanodeInfoWithStorage[127.0.0.1:40349,DS-eb1188bc-d177-4b17-8c52-4529cccd964f,DISK], DatanodeInfoWithStorage[127.0.0.1:37303,DS-a15b63b0-7fc2-48d3-959c-53825137cd0c,DISK], DatanodeInfoWithStorage[127.0.0.1:38075,DS-6b0e3eb4-8ad4-4981-9f03-a3b3e79cf5d5,DISK], DatanodeInfoWithStorage[127.0.0.1:40237,DS-68a8548f-19e0-491d-863c-58146e915c58,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1443238265-172.17.0.3-1598470732027:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42289,DS-71bf6e45-da04-46d9-bbdd-281a260f6318,DISK], DatanodeInfoWithStorage[127.0.0.1:42620,DS-cde5b1a3-77a9-4317-ae74-e2a9d3bd51b9,DISK], DatanodeInfoWithStorage[127.0.0.1:46389,DS-3337a125-7f90-4826-822a-16b950440679,DISK], DatanodeInfoWithStorage[127.0.0.1:36426,DS-616f0de8-95a6-437f-90f0-8a27bbb40be6,DISK], DatanodeInfoWithStorage[127.0.0.1:40349,DS-eb1188bc-d177-4b17-8c52-4529cccd964f,DISK], DatanodeInfoWithStorage[127.0.0.1:37303,DS-a15b63b0-7fc2-48d3-959c-53825137cd0c,DISK], DatanodeInfoWithStorage[127.0.0.1:38075,DS-6b0e3eb4-8ad4-4981-9f03-a3b3e79cf5d5,DISK], DatanodeInfoWithStorage[127.0.0.1:40237,DS-68a8548f-19e0-491d-863c-58146e915c58,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1191361336-172.17.0.3-1598470834474:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45734,DS-d3088250-e829-4b68-902c-75d317101984,DISK], DatanodeInfoWithStorage[127.0.0.1:46333,DS-32d773f8-da7e-4576-af00-495312806da6,DISK], DatanodeInfoWithStorage[127.0.0.1:40296,DS-1f66bbb8-b99b-4b81-8607-6b58e76563e2,DISK], DatanodeInfoWithStorage[127.0.0.1:39071,DS-20fa0222-6bd2-417d-8503-88bce49fd1ca,DISK], DatanodeInfoWithStorage[127.0.0.1:33319,DS-3278cbef-836e-4779-9c18-fa0e076ca563,DISK], DatanodeInfoWithStorage[127.0.0.1:35537,DS-5355a6e3-fe5b-46b6-ac6a-b9a3ba222ee8,DISK], DatanodeInfoWithStorage[127.0.0.1:41016,DS-b1ecc7cf-7c19-4a5b-b8c3-88c1b63ba7f4,DISK], DatanodeInfoWithStorage[127.0.0.1:37227,DS-add011e2-f135-40dc-b81d-a6e91bd2989c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1191361336-172.17.0.3-1598470834474:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45734,DS-d3088250-e829-4b68-902c-75d317101984,DISK], DatanodeInfoWithStorage[127.0.0.1:46333,DS-32d773f8-da7e-4576-af00-495312806da6,DISK], DatanodeInfoWithStorage[127.0.0.1:40296,DS-1f66bbb8-b99b-4b81-8607-6b58e76563e2,DISK], DatanodeInfoWithStorage[127.0.0.1:39071,DS-20fa0222-6bd2-417d-8503-88bce49fd1ca,DISK], DatanodeInfoWithStorage[127.0.0.1:33319,DS-3278cbef-836e-4779-9c18-fa0e076ca563,DISK], DatanodeInfoWithStorage[127.0.0.1:35537,DS-5355a6e3-fe5b-46b6-ac6a-b9a3ba222ee8,DISK], DatanodeInfoWithStorage[127.0.0.1:41016,DS-b1ecc7cf-7c19-4a5b-b8c3-88c1b63ba7f4,DISK], DatanodeInfoWithStorage[127.0.0.1:37227,DS-add011e2-f135-40dc-b81d-a6e91bd2989c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-64078066-172.17.0.3-1598471742777:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34756,DS-4bd3cf99-2798-486e-b8d3-6c6822e3679c,DISK], DatanodeInfoWithStorage[127.0.0.1:41355,DS-e36f386e-8e71-498d-babc-790f64a924f2,DISK], DatanodeInfoWithStorage[127.0.0.1:37656,DS-9066c35d-713d-4417-823b-4f6794c987e1,DISK], DatanodeInfoWithStorage[127.0.0.1:45634,DS-c139df95-6458-4c27-9ac3-bea16c3c030d,DISK], DatanodeInfoWithStorage[127.0.0.1:38185,DS-0fd74e08-edfa-4026-94d6-c72a2e3a56b8,DISK], DatanodeInfoWithStorage[127.0.0.1:41367,DS-222d68d8-e2f5-4ed5-b233-653d8ab6d0a9,DISK], DatanodeInfoWithStorage[127.0.0.1:41782,DS-1016a957-7bd4-4d6a-aefc-3c805066b054,DISK], DatanodeInfoWithStorage[127.0.0.1:40488,DS-81bf60fb-bf6d-4f41-8ec9-85c05c801050,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-64078066-172.17.0.3-1598471742777:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34756,DS-4bd3cf99-2798-486e-b8d3-6c6822e3679c,DISK], DatanodeInfoWithStorage[127.0.0.1:41355,DS-e36f386e-8e71-498d-babc-790f64a924f2,DISK], DatanodeInfoWithStorage[127.0.0.1:37656,DS-9066c35d-713d-4417-823b-4f6794c987e1,DISK], DatanodeInfoWithStorage[127.0.0.1:45634,DS-c139df95-6458-4c27-9ac3-bea16c3c030d,DISK], DatanodeInfoWithStorage[127.0.0.1:38185,DS-0fd74e08-edfa-4026-94d6-c72a2e3a56b8,DISK], DatanodeInfoWithStorage[127.0.0.1:41367,DS-222d68d8-e2f5-4ed5-b233-653d8ab6d0a9,DISK], DatanodeInfoWithStorage[127.0.0.1:41782,DS-1016a957-7bd4-4d6a-aefc-3c805066b054,DISK], DatanodeInfoWithStorage[127.0.0.1:40488,DS-81bf60fb-bf6d-4f41-8ec9-85c05c801050,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1273681527-172.17.0.3-1598471832354:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45502,DS-6ec9e559-a8fd-4ccc-a1b9-bb69d9e9ea1b,DISK], DatanodeInfoWithStorage[127.0.0.1:37875,DS-51e8af64-9455-47e3-93f5-168aaaacde4f,DISK], DatanodeInfoWithStorage[127.0.0.1:44672,DS-e1bfd343-b060-4f21-9b06-73181287fade,DISK], DatanodeInfoWithStorage[127.0.0.1:36534,DS-51fafa83-f3af-4027-89cb-fa1a202e5533,DISK], DatanodeInfoWithStorage[127.0.0.1:44784,DS-d19f9b8e-1326-4b7c-8fb6-4b66f7325750,DISK], DatanodeInfoWithStorage[127.0.0.1:39477,DS-163f2ebb-e6a9-4ba4-ae58-e16faa862f66,DISK], DatanodeInfoWithStorage[127.0.0.1:46502,DS-4ffb2dd9-374b-4bde-83cd-b52025beef0d,DISK], DatanodeInfoWithStorage[127.0.0.1:39970,DS-aa1eb6c4-5487-4282-89bd-8caff8fbbdfd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1273681527-172.17.0.3-1598471832354:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45502,DS-6ec9e559-a8fd-4ccc-a1b9-bb69d9e9ea1b,DISK], DatanodeInfoWithStorage[127.0.0.1:37875,DS-51e8af64-9455-47e3-93f5-168aaaacde4f,DISK], DatanodeInfoWithStorage[127.0.0.1:44672,DS-e1bfd343-b060-4f21-9b06-73181287fade,DISK], DatanodeInfoWithStorage[127.0.0.1:36534,DS-51fafa83-f3af-4027-89cb-fa1a202e5533,DISK], DatanodeInfoWithStorage[127.0.0.1:44784,DS-d19f9b8e-1326-4b7c-8fb6-4b66f7325750,DISK], DatanodeInfoWithStorage[127.0.0.1:39477,DS-163f2ebb-e6a9-4ba4-ae58-e16faa862f66,DISK], DatanodeInfoWithStorage[127.0.0.1:46502,DS-4ffb2dd9-374b-4bde-83cd-b52025beef0d,DISK], DatanodeInfoWithStorage[127.0.0.1:39970,DS-aa1eb6c4-5487-4282-89bd-8caff8fbbdfd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-955036118-172.17.0.3-1598471931079:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35815,DS-df1d4498-c088-43ab-a966-57e017144207,DISK], DatanodeInfoWithStorage[127.0.0.1:45138,DS-0fbe7eb7-1b4d-4007-8759-177211a0ce76,DISK], DatanodeInfoWithStorage[127.0.0.1:35179,DS-4ca3304a-163f-434f-be12-1f16d37f94d7,DISK], DatanodeInfoWithStorage[127.0.0.1:34101,DS-2f41a36d-9b7e-4771-a2a9-a4fe299c2748,DISK], DatanodeInfoWithStorage[127.0.0.1:40854,DS-27c70433-102a-4a78-8d57-59f724dee56d,DISK], DatanodeInfoWithStorage[127.0.0.1:41610,DS-4c4d81c7-8277-4502-a3e6-052b8d5def7c,DISK], DatanodeInfoWithStorage[127.0.0.1:34091,DS-fe13b2c6-3ed0-49dc-a6ff-6625a87f4e84,DISK], DatanodeInfoWithStorage[127.0.0.1:44260,DS-91d62012-1cba-47a0-95b6-b7cd68ae3348,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-955036118-172.17.0.3-1598471931079:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35815,DS-df1d4498-c088-43ab-a966-57e017144207,DISK], DatanodeInfoWithStorage[127.0.0.1:45138,DS-0fbe7eb7-1b4d-4007-8759-177211a0ce76,DISK], DatanodeInfoWithStorage[127.0.0.1:35179,DS-4ca3304a-163f-434f-be12-1f16d37f94d7,DISK], DatanodeInfoWithStorage[127.0.0.1:34101,DS-2f41a36d-9b7e-4771-a2a9-a4fe299c2748,DISK], DatanodeInfoWithStorage[127.0.0.1:40854,DS-27c70433-102a-4a78-8d57-59f724dee56d,DISK], DatanodeInfoWithStorage[127.0.0.1:41610,DS-4c4d81c7-8277-4502-a3e6-052b8d5def7c,DISK], DatanodeInfoWithStorage[127.0.0.1:34091,DS-fe13b2c6-3ed0-49dc-a6ff-6625a87f4e84,DISK], DatanodeInfoWithStorage[127.0.0.1:44260,DS-91d62012-1cba-47a0-95b6-b7cd68ae3348,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1520216163-172.17.0.3-1598471966789:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46786,DS-e7f4941d-9958-4374-b431-8384c1125f39,DISK], DatanodeInfoWithStorage[127.0.0.1:46493,DS-03fc9db0-9b5e-487d-ac61-8c460d2268d7,DISK], DatanodeInfoWithStorage[127.0.0.1:33601,DS-0e27cda2-1484-4105-9246-cbc6cf6eb7c2,DISK], DatanodeInfoWithStorage[127.0.0.1:37953,DS-e10a715e-4866-426f-906a-513a9336b9c2,DISK], DatanodeInfoWithStorage[127.0.0.1:36387,DS-5ea00831-80d0-4a65-a473-2914944d10d6,DISK], DatanodeInfoWithStorage[127.0.0.1:32899,DS-7c35858a-609b-4be6-83ce-c74f124043d6,DISK], DatanodeInfoWithStorage[127.0.0.1:34158,DS-9fc135c7-410e-4977-ac03-2dcaab4a986e,DISK], DatanodeInfoWithStorage[127.0.0.1:43431,DS-034907d2-de10-440e-aed7-d68e9ef82462,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1520216163-172.17.0.3-1598471966789:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46786,DS-e7f4941d-9958-4374-b431-8384c1125f39,DISK], DatanodeInfoWithStorage[127.0.0.1:46493,DS-03fc9db0-9b5e-487d-ac61-8c460d2268d7,DISK], DatanodeInfoWithStorage[127.0.0.1:33601,DS-0e27cda2-1484-4105-9246-cbc6cf6eb7c2,DISK], DatanodeInfoWithStorage[127.0.0.1:37953,DS-e10a715e-4866-426f-906a-513a9336b9c2,DISK], DatanodeInfoWithStorage[127.0.0.1:36387,DS-5ea00831-80d0-4a65-a473-2914944d10d6,DISK], DatanodeInfoWithStorage[127.0.0.1:32899,DS-7c35858a-609b-4be6-83ce-c74f124043d6,DISK], DatanodeInfoWithStorage[127.0.0.1:34158,DS-9fc135c7-410e-4977-ac03-2dcaab4a986e,DISK], DatanodeInfoWithStorage[127.0.0.1:43431,DS-034907d2-de10-440e-aed7-d68e9ef82462,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1088688072-172.17.0.3-1598472154772:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44163,DS-278694f4-43b6-4dd0-98d9-65a5854d30b9,DISK], DatanodeInfoWithStorage[127.0.0.1:41167,DS-43ca6d75-bd2a-4976-9eaf-75f3faecb6b0,DISK], DatanodeInfoWithStorage[127.0.0.1:34055,DS-9c5fa7a9-1c22-4223-ac26-1b516c3cf49f,DISK], DatanodeInfoWithStorage[127.0.0.1:42507,DS-695d92b9-9ca3-4eff-a026-2d81dc989397,DISK], DatanodeInfoWithStorage[127.0.0.1:42991,DS-ea7dfa49-ea60-4e0d-a39e-f84d71f7e6b7,DISK], DatanodeInfoWithStorage[127.0.0.1:46504,DS-76c8b90e-9e6c-40ac-a344-ca75fa3d9f33,DISK], DatanodeInfoWithStorage[127.0.0.1:41401,DS-d156bbbf-ea0c-4744-b1c9-71b889bc282f,DISK], DatanodeInfoWithStorage[127.0.0.1:42593,DS-9b70e557-3cb3-4573-a59b-2c65d2abc6fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1088688072-172.17.0.3-1598472154772:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44163,DS-278694f4-43b6-4dd0-98d9-65a5854d30b9,DISK], DatanodeInfoWithStorage[127.0.0.1:41167,DS-43ca6d75-bd2a-4976-9eaf-75f3faecb6b0,DISK], DatanodeInfoWithStorage[127.0.0.1:34055,DS-9c5fa7a9-1c22-4223-ac26-1b516c3cf49f,DISK], DatanodeInfoWithStorage[127.0.0.1:42507,DS-695d92b9-9ca3-4eff-a026-2d81dc989397,DISK], DatanodeInfoWithStorage[127.0.0.1:42991,DS-ea7dfa49-ea60-4e0d-a39e-f84d71f7e6b7,DISK], DatanodeInfoWithStorage[127.0.0.1:46504,DS-76c8b90e-9e6c-40ac-a344-ca75fa3d9f33,DISK], DatanodeInfoWithStorage[127.0.0.1:41401,DS-d156bbbf-ea0c-4744-b1c9-71b889bc282f,DISK], DatanodeInfoWithStorage[127.0.0.1:42593,DS-9b70e557-3cb3-4573-a59b-2c65d2abc6fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-322629510-172.17.0.3-1598472779322:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39321,DS-628d41d3-d31f-4883-a1f5-a8286f8aee6d,DISK], DatanodeInfoWithStorage[127.0.0.1:46871,DS-98810af8-ae0d-427d-81b0-d41a64b48ced,DISK], DatanodeInfoWithStorage[127.0.0.1:34995,DS-4b6170b3-9b0c-45d2-b03b-7c28928ffc2b,DISK], DatanodeInfoWithStorage[127.0.0.1:36895,DS-10eea155-5878-4a55-9090-bbb10f093f16,DISK], DatanodeInfoWithStorage[127.0.0.1:40000,DS-6f2b0972-c1cb-4f32-baf0-12ceb9a403d0,DISK], DatanodeInfoWithStorage[127.0.0.1:43511,DS-1478565c-6f23-46bc-95c3-8527af6caf37,DISK], DatanodeInfoWithStorage[127.0.0.1:38160,DS-eab46567-0f7e-4176-ba56-c449bed2b9b0,DISK], DatanodeInfoWithStorage[127.0.0.1:36913,DS-6a90b88f-737d-4b80-bde9-923d6ea3310f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-322629510-172.17.0.3-1598472779322:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39321,DS-628d41d3-d31f-4883-a1f5-a8286f8aee6d,DISK], DatanodeInfoWithStorage[127.0.0.1:46871,DS-98810af8-ae0d-427d-81b0-d41a64b48ced,DISK], DatanodeInfoWithStorage[127.0.0.1:34995,DS-4b6170b3-9b0c-45d2-b03b-7c28928ffc2b,DISK], DatanodeInfoWithStorage[127.0.0.1:36895,DS-10eea155-5878-4a55-9090-bbb10f093f16,DISK], DatanodeInfoWithStorage[127.0.0.1:40000,DS-6f2b0972-c1cb-4f32-baf0-12ceb9a403d0,DISK], DatanodeInfoWithStorage[127.0.0.1:43511,DS-1478565c-6f23-46bc-95c3-8527af6caf37,DISK], DatanodeInfoWithStorage[127.0.0.1:38160,DS-eab46567-0f7e-4176-ba56-c449bed2b9b0,DISK], DatanodeInfoWithStorage[127.0.0.1:36913,DS-6a90b88f-737d-4b80-bde9-923d6ea3310f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 6 out of 50
result: might be true error
Total execution time in seconds : 4824
