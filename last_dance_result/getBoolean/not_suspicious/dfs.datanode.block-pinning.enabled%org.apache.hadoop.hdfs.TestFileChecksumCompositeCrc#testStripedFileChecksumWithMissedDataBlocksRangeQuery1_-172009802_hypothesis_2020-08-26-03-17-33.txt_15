reconf_parameter: dfs.datanode.block-pinning.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.block-pinning.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1587169597-172.17.0.12-1598412028577:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34112,DS-d9c31196-2317-45bd-9178-cd9ccac279a6,DISK], DatanodeInfoWithStorage[127.0.0.1:44433,DS-6e6cfae8-c604-4232-86ad-06002d836baa,DISK], DatanodeInfoWithStorage[127.0.0.1:36144,DS-2a1b46c3-c174-436f-8ad6-448b2bbe852a,DISK], DatanodeInfoWithStorage[127.0.0.1:34881,DS-cd203b16-bdb5-45e3-a8ea-92a9437a625b,DISK], DatanodeInfoWithStorage[127.0.0.1:42707,DS-6ebe5f2d-dffe-49b1-a9a9-3f810d3f54fe,DISK], DatanodeInfoWithStorage[127.0.0.1:38152,DS-af1fcee9-ea28-4b22-b371-92b60c3ed0c8,DISK], DatanodeInfoWithStorage[127.0.0.1:43297,DS-6ea218e8-e348-400f-943b-c8bbe7a58f45,DISK], DatanodeInfoWithStorage[127.0.0.1:34644,DS-dcdb764e-9ce1-41b8-bb93-8af4f0595eb5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1587169597-172.17.0.12-1598412028577:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34112,DS-d9c31196-2317-45bd-9178-cd9ccac279a6,DISK], DatanodeInfoWithStorage[127.0.0.1:44433,DS-6e6cfae8-c604-4232-86ad-06002d836baa,DISK], DatanodeInfoWithStorage[127.0.0.1:36144,DS-2a1b46c3-c174-436f-8ad6-448b2bbe852a,DISK], DatanodeInfoWithStorage[127.0.0.1:34881,DS-cd203b16-bdb5-45e3-a8ea-92a9437a625b,DISK], DatanodeInfoWithStorage[127.0.0.1:42707,DS-6ebe5f2d-dffe-49b1-a9a9-3f810d3f54fe,DISK], DatanodeInfoWithStorage[127.0.0.1:38152,DS-af1fcee9-ea28-4b22-b371-92b60c3ed0c8,DISK], DatanodeInfoWithStorage[127.0.0.1:43297,DS-6ea218e8-e348-400f-943b-c8bbe7a58f45,DISK], DatanodeInfoWithStorage[127.0.0.1:34644,DS-dcdb764e-9ce1-41b8-bb93-8af4f0595eb5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.block-pinning.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2048995406-172.17.0.12-1598412063282:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39852,DS-ec813a07-37f6-4d52-a48e-47845e42ba17,DISK], DatanodeInfoWithStorage[127.0.0.1:38976,DS-c090b31f-eafb-44ae-b094-e34052d3afe8,DISK], DatanodeInfoWithStorage[127.0.0.1:41057,DS-6bf23e59-b4c4-4348-a769-bdafb6b3173a,DISK], DatanodeInfoWithStorage[127.0.0.1:39291,DS-24acea80-ef40-4001-b98c-d52473216647,DISK], DatanodeInfoWithStorage[127.0.0.1:34570,DS-1d2dfeb6-7b5b-4048-ae62-dec673669fc8,DISK], DatanodeInfoWithStorage[127.0.0.1:37406,DS-fa352a2d-e8d6-443c-a34a-c1bcc929379c,DISK], DatanodeInfoWithStorage[127.0.0.1:46435,DS-b1a34b49-1f0b-4e5a-a295-0b43912bfae4,DISK], DatanodeInfoWithStorage[127.0.0.1:37588,DS-7b1da086-c7d0-40a2-baf1-a730fda73b03,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2048995406-172.17.0.12-1598412063282:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39852,DS-ec813a07-37f6-4d52-a48e-47845e42ba17,DISK], DatanodeInfoWithStorage[127.0.0.1:38976,DS-c090b31f-eafb-44ae-b094-e34052d3afe8,DISK], DatanodeInfoWithStorage[127.0.0.1:41057,DS-6bf23e59-b4c4-4348-a769-bdafb6b3173a,DISK], DatanodeInfoWithStorage[127.0.0.1:39291,DS-24acea80-ef40-4001-b98c-d52473216647,DISK], DatanodeInfoWithStorage[127.0.0.1:34570,DS-1d2dfeb6-7b5b-4048-ae62-dec673669fc8,DISK], DatanodeInfoWithStorage[127.0.0.1:37406,DS-fa352a2d-e8d6-443c-a34a-c1bcc929379c,DISK], DatanodeInfoWithStorage[127.0.0.1:46435,DS-b1a34b49-1f0b-4e5a-a295-0b43912bfae4,DISK], DatanodeInfoWithStorage[127.0.0.1:37588,DS-7b1da086-c7d0-40a2-baf1-a730fda73b03,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.block-pinning.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1596703492-172.17.0.12-1598412463634:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45890,DS-0e7ea9e5-0dc0-4991-a7b8-498f25f3681b,DISK], DatanodeInfoWithStorage[127.0.0.1:44490,DS-0ccc6d6f-a25b-415c-9586-a2a9f8c69789,DISK], DatanodeInfoWithStorage[127.0.0.1:39024,DS-100f37ec-1249-4421-b7fd-775240007638,DISK], DatanodeInfoWithStorage[127.0.0.1:39090,DS-113f3f80-ed91-4f0f-8a09-e7db65b9b010,DISK], DatanodeInfoWithStorage[127.0.0.1:36607,DS-27aeb775-fb56-44de-8d64-e32c50626a34,DISK], DatanodeInfoWithStorage[127.0.0.1:33800,DS-2607ffc7-3e14-4ea5-80dd-1c1af107855f,DISK], DatanodeInfoWithStorage[127.0.0.1:34598,DS-f1e4e301-af04-4c13-9f71-1c505fa775c1,DISK], DatanodeInfoWithStorage[127.0.0.1:42094,DS-25409538-1e5f-4c0f-8fda-5fce967a512b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1596703492-172.17.0.12-1598412463634:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45890,DS-0e7ea9e5-0dc0-4991-a7b8-498f25f3681b,DISK], DatanodeInfoWithStorage[127.0.0.1:44490,DS-0ccc6d6f-a25b-415c-9586-a2a9f8c69789,DISK], DatanodeInfoWithStorage[127.0.0.1:39024,DS-100f37ec-1249-4421-b7fd-775240007638,DISK], DatanodeInfoWithStorage[127.0.0.1:39090,DS-113f3f80-ed91-4f0f-8a09-e7db65b9b010,DISK], DatanodeInfoWithStorage[127.0.0.1:36607,DS-27aeb775-fb56-44de-8d64-e32c50626a34,DISK], DatanodeInfoWithStorage[127.0.0.1:33800,DS-2607ffc7-3e14-4ea5-80dd-1c1af107855f,DISK], DatanodeInfoWithStorage[127.0.0.1:34598,DS-f1e4e301-af04-4c13-9f71-1c505fa775c1,DISK], DatanodeInfoWithStorage[127.0.0.1:42094,DS-25409538-1e5f-4c0f-8fda-5fce967a512b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.block-pinning.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-468571291-172.17.0.12-1598413419072:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46597,DS-e62fac0d-b8ff-412c-9358-2bde9f71340d,DISK], DatanodeInfoWithStorage[127.0.0.1:42609,DS-cb02b122-0bac-4e50-a65c-e9556cec1521,DISK], DatanodeInfoWithStorage[127.0.0.1:44687,DS-83560a05-83d7-4680-8296-8317ac95e0fd,DISK], DatanodeInfoWithStorage[127.0.0.1:42273,DS-c5848647-56d9-4caf-8f87-2fabacf1f462,DISK], DatanodeInfoWithStorage[127.0.0.1:46410,DS-ca08a37c-15c1-4fd8-959f-f0a19bd63297,DISK], DatanodeInfoWithStorage[127.0.0.1:43166,DS-dd026cea-061a-4432-98cd-8ffec4c16c45,DISK], DatanodeInfoWithStorage[127.0.0.1:35827,DS-f9121d86-be34-49db-ae7b-37a2209c0039,DISK], DatanodeInfoWithStorage[127.0.0.1:46445,DS-4fbef904-4ce6-41b9-8c3a-c4f70e5a2b5b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-468571291-172.17.0.12-1598413419072:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46597,DS-e62fac0d-b8ff-412c-9358-2bde9f71340d,DISK], DatanodeInfoWithStorage[127.0.0.1:42609,DS-cb02b122-0bac-4e50-a65c-e9556cec1521,DISK], DatanodeInfoWithStorage[127.0.0.1:44687,DS-83560a05-83d7-4680-8296-8317ac95e0fd,DISK], DatanodeInfoWithStorage[127.0.0.1:42273,DS-c5848647-56d9-4caf-8f87-2fabacf1f462,DISK], DatanodeInfoWithStorage[127.0.0.1:46410,DS-ca08a37c-15c1-4fd8-959f-f0a19bd63297,DISK], DatanodeInfoWithStorage[127.0.0.1:43166,DS-dd026cea-061a-4432-98cd-8ffec4c16c45,DISK], DatanodeInfoWithStorage[127.0.0.1:35827,DS-f9121d86-be34-49db-ae7b-37a2209c0039,DISK], DatanodeInfoWithStorage[127.0.0.1:46445,DS-4fbef904-4ce6-41b9-8c3a-c4f70e5a2b5b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.block-pinning.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1493869472-172.17.0.12-1598413461398:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40754,DS-187f91e4-87b8-4e33-b469-28d01270c4fa,DISK], DatanodeInfoWithStorage[127.0.0.1:40084,DS-96b6f2b3-9ac6-4d67-b999-c760472ec8d4,DISK], DatanodeInfoWithStorage[127.0.0.1:33605,DS-8e16a6f5-f086-4b78-82bb-92b7ef7ee9db,DISK], DatanodeInfoWithStorage[127.0.0.1:43751,DS-15e37d59-d703-448d-9b70-d046178eeb2e,DISK], DatanodeInfoWithStorage[127.0.0.1:41064,DS-dd41fe41-03ea-487e-b06f-ef2ba40ec193,DISK], DatanodeInfoWithStorage[127.0.0.1:37307,DS-412641a6-e886-4c2a-b335-24dee0558346,DISK], DatanodeInfoWithStorage[127.0.0.1:33781,DS-f992bf5e-fd73-4c7d-b6b3-c1be45028fec,DISK], DatanodeInfoWithStorage[127.0.0.1:46153,DS-a971688f-82e2-4f41-8282-d74dd99a61d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1493869472-172.17.0.12-1598413461398:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40754,DS-187f91e4-87b8-4e33-b469-28d01270c4fa,DISK], DatanodeInfoWithStorage[127.0.0.1:40084,DS-96b6f2b3-9ac6-4d67-b999-c760472ec8d4,DISK], DatanodeInfoWithStorage[127.0.0.1:33605,DS-8e16a6f5-f086-4b78-82bb-92b7ef7ee9db,DISK], DatanodeInfoWithStorage[127.0.0.1:43751,DS-15e37d59-d703-448d-9b70-d046178eeb2e,DISK], DatanodeInfoWithStorage[127.0.0.1:41064,DS-dd41fe41-03ea-487e-b06f-ef2ba40ec193,DISK], DatanodeInfoWithStorage[127.0.0.1:37307,DS-412641a6-e886-4c2a-b335-24dee0558346,DISK], DatanodeInfoWithStorage[127.0.0.1:33781,DS-f992bf5e-fd73-4c7d-b6b3-c1be45028fec,DISK], DatanodeInfoWithStorage[127.0.0.1:46153,DS-a971688f-82e2-4f41-8282-d74dd99a61d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.block-pinning.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1556219315-172.17.0.12-1598413658670:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42063,DS-fd0e1b40-9b3a-4f08-9715-50acb74b525e,DISK], DatanodeInfoWithStorage[127.0.0.1:38996,DS-9dde575a-45fc-4b5d-ae31-50619aef94ea,DISK], DatanodeInfoWithStorage[127.0.0.1:33893,DS-30e34e4b-bfd6-4a97-ab29-30c3e33e8ee1,DISK], DatanodeInfoWithStorage[127.0.0.1:37163,DS-41a1fe51-9d54-4bd4-a70d-cc6b089b11f0,DISK], DatanodeInfoWithStorage[127.0.0.1:44060,DS-b95cc687-6b57-41d9-bcbe-b99cc855d72b,DISK], DatanodeInfoWithStorage[127.0.0.1:37815,DS-59b492ed-bf1f-40ea-bb17-9bcf06261c51,DISK], DatanodeInfoWithStorage[127.0.0.1:38000,DS-bb388bc4-5115-44dc-b9e2-e4da671e8602,DISK], DatanodeInfoWithStorage[127.0.0.1:39502,DS-f56cf1a4-8692-4c79-ba06-09632388299d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1556219315-172.17.0.12-1598413658670:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42063,DS-fd0e1b40-9b3a-4f08-9715-50acb74b525e,DISK], DatanodeInfoWithStorage[127.0.0.1:38996,DS-9dde575a-45fc-4b5d-ae31-50619aef94ea,DISK], DatanodeInfoWithStorage[127.0.0.1:33893,DS-30e34e4b-bfd6-4a97-ab29-30c3e33e8ee1,DISK], DatanodeInfoWithStorage[127.0.0.1:37163,DS-41a1fe51-9d54-4bd4-a70d-cc6b089b11f0,DISK], DatanodeInfoWithStorage[127.0.0.1:44060,DS-b95cc687-6b57-41d9-bcbe-b99cc855d72b,DISK], DatanodeInfoWithStorage[127.0.0.1:37815,DS-59b492ed-bf1f-40ea-bb17-9bcf06261c51,DISK], DatanodeInfoWithStorage[127.0.0.1:38000,DS-bb388bc4-5115-44dc-b9e2-e4da671e8602,DISK], DatanodeInfoWithStorage[127.0.0.1:39502,DS-f56cf1a4-8692-4c79-ba06-09632388299d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.block-pinning.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-467502472-172.17.0.12-1598413686424:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43552,DS-0cbb38d2-03b4-4767-90f0-a916a0596af9,DISK], DatanodeInfoWithStorage[127.0.0.1:35975,DS-628c9f9f-0b41-414e-b197-949592952980,DISK], DatanodeInfoWithStorage[127.0.0.1:44382,DS-de3545fc-3a3f-49dc-9241-95fd8b7813bc,DISK], DatanodeInfoWithStorage[127.0.0.1:38674,DS-69d6022c-3120-45e0-95af-ee6f4d26cafa,DISK], DatanodeInfoWithStorage[127.0.0.1:40520,DS-1102f955-79d0-47f9-9a07-6c2fa8b5a547,DISK], DatanodeInfoWithStorage[127.0.0.1:37925,DS-6195c94b-ae39-4bcc-8d8e-071d22542c32,DISK], DatanodeInfoWithStorage[127.0.0.1:35335,DS-6362a611-731c-4c73-9732-d326e8e687b0,DISK], DatanodeInfoWithStorage[127.0.0.1:44413,DS-f5e79278-ff8b-456d-92c4-da40e6473fb3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-467502472-172.17.0.12-1598413686424:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43552,DS-0cbb38d2-03b4-4767-90f0-a916a0596af9,DISK], DatanodeInfoWithStorage[127.0.0.1:35975,DS-628c9f9f-0b41-414e-b197-949592952980,DISK], DatanodeInfoWithStorage[127.0.0.1:44382,DS-de3545fc-3a3f-49dc-9241-95fd8b7813bc,DISK], DatanodeInfoWithStorage[127.0.0.1:38674,DS-69d6022c-3120-45e0-95af-ee6f4d26cafa,DISK], DatanodeInfoWithStorage[127.0.0.1:40520,DS-1102f955-79d0-47f9-9a07-6c2fa8b5a547,DISK], DatanodeInfoWithStorage[127.0.0.1:37925,DS-6195c94b-ae39-4bcc-8d8e-071d22542c32,DISK], DatanodeInfoWithStorage[127.0.0.1:35335,DS-6362a611-731c-4c73-9732-d326e8e687b0,DISK], DatanodeInfoWithStorage[127.0.0.1:44413,DS-f5e79278-ff8b-456d-92c4-da40e6473fb3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.block-pinning.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-135143781-172.17.0.12-1598413760993:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45921,DS-440ec504-2974-4602-b8e2-69d17cfd4375,DISK], DatanodeInfoWithStorage[127.0.0.1:34359,DS-62c07b76-111e-4a2d-8c20-a0610af185c1,DISK], DatanodeInfoWithStorage[127.0.0.1:46503,DS-433d50c8-9e4e-476d-934a-c9ca90da30ea,DISK], DatanodeInfoWithStorage[127.0.0.1:43986,DS-7da3c5eb-d95a-4cdd-9337-5dd36b1ca4e3,DISK], DatanodeInfoWithStorage[127.0.0.1:46011,DS-03f2cbf0-14a1-4020-9d07-7f7477153460,DISK], DatanodeInfoWithStorage[127.0.0.1:44487,DS-179c1ce1-41a7-4497-bea8-ee81669ad948,DISK], DatanodeInfoWithStorage[127.0.0.1:40750,DS-8781efbd-b0b9-43f4-8816-1f46bf94f050,DISK], DatanodeInfoWithStorage[127.0.0.1:42704,DS-2a4eaa02-a7e9-4bc0-b3be-bc22fc648779,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-135143781-172.17.0.12-1598413760993:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45921,DS-440ec504-2974-4602-b8e2-69d17cfd4375,DISK], DatanodeInfoWithStorage[127.0.0.1:34359,DS-62c07b76-111e-4a2d-8c20-a0610af185c1,DISK], DatanodeInfoWithStorage[127.0.0.1:46503,DS-433d50c8-9e4e-476d-934a-c9ca90da30ea,DISK], DatanodeInfoWithStorage[127.0.0.1:43986,DS-7da3c5eb-d95a-4cdd-9337-5dd36b1ca4e3,DISK], DatanodeInfoWithStorage[127.0.0.1:46011,DS-03f2cbf0-14a1-4020-9d07-7f7477153460,DISK], DatanodeInfoWithStorage[127.0.0.1:44487,DS-179c1ce1-41a7-4497-bea8-ee81669ad948,DISK], DatanodeInfoWithStorage[127.0.0.1:40750,DS-8781efbd-b0b9-43f4-8816-1f46bf94f050,DISK], DatanodeInfoWithStorage[127.0.0.1:42704,DS-2a4eaa02-a7e9-4bc0-b3be-bc22fc648779,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.block-pinning.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-733018479-172.17.0.12-1598414033104:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40466,DS-a2c5c214-797d-4799-8fe6-0eecd0cf944f,DISK], DatanodeInfoWithStorage[127.0.0.1:39494,DS-9881d4e4-f803-4bf0-a411-df7b32f362d0,DISK], DatanodeInfoWithStorage[127.0.0.1:46624,DS-e5227bd8-eefe-4543-83a6-8c96161e139b,DISK], DatanodeInfoWithStorage[127.0.0.1:46127,DS-81fc1ca4-e2c0-4cc7-9d75-4000f3367553,DISK], DatanodeInfoWithStorage[127.0.0.1:38575,DS-f2e2ca95-42a5-4221-93a4-c9faedf01aee,DISK], DatanodeInfoWithStorage[127.0.0.1:33059,DS-dbbf5d0f-4bc9-4ca7-980d-417b6dcd815b,DISK], DatanodeInfoWithStorage[127.0.0.1:41817,DS-0638012b-f51c-49dd-8011-edb91f4b61ff,DISK], DatanodeInfoWithStorage[127.0.0.1:33000,DS-1610f456-18bd-4fc0-afb5-9a5b3045d8b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-733018479-172.17.0.12-1598414033104:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40466,DS-a2c5c214-797d-4799-8fe6-0eecd0cf944f,DISK], DatanodeInfoWithStorage[127.0.0.1:39494,DS-9881d4e4-f803-4bf0-a411-df7b32f362d0,DISK], DatanodeInfoWithStorage[127.0.0.1:46624,DS-e5227bd8-eefe-4543-83a6-8c96161e139b,DISK], DatanodeInfoWithStorage[127.0.0.1:46127,DS-81fc1ca4-e2c0-4cc7-9d75-4000f3367553,DISK], DatanodeInfoWithStorage[127.0.0.1:38575,DS-f2e2ca95-42a5-4221-93a4-c9faedf01aee,DISK], DatanodeInfoWithStorage[127.0.0.1:33059,DS-dbbf5d0f-4bc9-4ca7-980d-417b6dcd815b,DISK], DatanodeInfoWithStorage[127.0.0.1:41817,DS-0638012b-f51c-49dd-8011-edb91f4b61ff,DISK], DatanodeInfoWithStorage[127.0.0.1:33000,DS-1610f456-18bd-4fc0-afb5-9a5b3045d8b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.block-pinning.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2143739934-172.17.0.12-1598414359132:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44988,DS-bfc98a2e-ea50-4fb4-adda-f6a7b4fe8778,DISK], DatanodeInfoWithStorage[127.0.0.1:37195,DS-e0a1f5ef-520c-44cd-b81c-d74de43691b5,DISK], DatanodeInfoWithStorage[127.0.0.1:33615,DS-a624ba8e-d997-4f5a-b93e-75284b677a68,DISK], DatanodeInfoWithStorage[127.0.0.1:34263,DS-dba34cfa-9304-4fbe-a15e-911aece76431,DISK], DatanodeInfoWithStorage[127.0.0.1:41706,DS-3b439032-ffe9-41c3-bc1d-047cd6c422c8,DISK], DatanodeInfoWithStorage[127.0.0.1:38006,DS-29027035-162e-4709-b5c6-326ffff1c2c6,DISK], DatanodeInfoWithStorage[127.0.0.1:37455,DS-20f9be3d-ade6-43ae-800c-9f758ecffea6,DISK], DatanodeInfoWithStorage[127.0.0.1:40804,DS-43994e2f-2c33-4e7e-89d5-0e18f07271c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2143739934-172.17.0.12-1598414359132:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44988,DS-bfc98a2e-ea50-4fb4-adda-f6a7b4fe8778,DISK], DatanodeInfoWithStorage[127.0.0.1:37195,DS-e0a1f5ef-520c-44cd-b81c-d74de43691b5,DISK], DatanodeInfoWithStorage[127.0.0.1:33615,DS-a624ba8e-d997-4f5a-b93e-75284b677a68,DISK], DatanodeInfoWithStorage[127.0.0.1:34263,DS-dba34cfa-9304-4fbe-a15e-911aece76431,DISK], DatanodeInfoWithStorage[127.0.0.1:41706,DS-3b439032-ffe9-41c3-bc1d-047cd6c422c8,DISK], DatanodeInfoWithStorage[127.0.0.1:38006,DS-29027035-162e-4709-b5c6-326ffff1c2c6,DISK], DatanodeInfoWithStorage[127.0.0.1:37455,DS-20f9be3d-ade6-43ae-800c-9f758ecffea6,DISK], DatanodeInfoWithStorage[127.0.0.1:40804,DS-43994e2f-2c33-4e7e-89d5-0e18f07271c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.block-pinning.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1322903984-172.17.0.12-1598414622243:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43746,DS-43799070-ad67-4546-a6ab-5425a175ea95,DISK], DatanodeInfoWithStorage[127.0.0.1:40599,DS-968b8458-f054-4300-958a-cf6f96080791,DISK], DatanodeInfoWithStorage[127.0.0.1:44414,DS-c45b5023-9ded-44b4-b113-1e35dcd1483c,DISK], DatanodeInfoWithStorage[127.0.0.1:46440,DS-c89b6402-e32b-47c6-95cc-84125aba32d9,DISK], DatanodeInfoWithStorage[127.0.0.1:44234,DS-be34c17d-4c0a-4c33-a169-c3eb435b265b,DISK], DatanodeInfoWithStorage[127.0.0.1:37120,DS-e2349a93-6f8e-43e4-b2e3-f5f5582d8831,DISK], DatanodeInfoWithStorage[127.0.0.1:44513,DS-394052ad-bc6a-4ba1-85a1-f16979b1c0c9,DISK], DatanodeInfoWithStorage[127.0.0.1:43318,DS-25e56243-643f-412f-bb7a-02441c2b61d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1322903984-172.17.0.12-1598414622243:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43746,DS-43799070-ad67-4546-a6ab-5425a175ea95,DISK], DatanodeInfoWithStorage[127.0.0.1:40599,DS-968b8458-f054-4300-958a-cf6f96080791,DISK], DatanodeInfoWithStorage[127.0.0.1:44414,DS-c45b5023-9ded-44b4-b113-1e35dcd1483c,DISK], DatanodeInfoWithStorage[127.0.0.1:46440,DS-c89b6402-e32b-47c6-95cc-84125aba32d9,DISK], DatanodeInfoWithStorage[127.0.0.1:44234,DS-be34c17d-4c0a-4c33-a169-c3eb435b265b,DISK], DatanodeInfoWithStorage[127.0.0.1:37120,DS-e2349a93-6f8e-43e4-b2e3-f5f5582d8831,DISK], DatanodeInfoWithStorage[127.0.0.1:44513,DS-394052ad-bc6a-4ba1-85a1-f16979b1c0c9,DISK], DatanodeInfoWithStorage[127.0.0.1:43318,DS-25e56243-643f-412f-bb7a-02441c2b61d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.block-pinning.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1052158967-172.17.0.12-1598414884946:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41314,DS-1a7ad6eb-968e-4b85-9636-717cb2d8c8b1,DISK], DatanodeInfoWithStorage[127.0.0.1:34331,DS-6ef76617-b555-4f73-b818-a5b0d9e04817,DISK], DatanodeInfoWithStorage[127.0.0.1:33734,DS-e7a9683f-5e04-4565-9409-178c0bf050c9,DISK], DatanodeInfoWithStorage[127.0.0.1:36630,DS-6b3c9037-870a-4bb0-bc87-81f6b5ac768c,DISK], DatanodeInfoWithStorage[127.0.0.1:43664,DS-b189f2b1-b940-466a-aa92-2098169f2ecc,DISK], DatanodeInfoWithStorage[127.0.0.1:45213,DS-378f9c9a-8542-4afd-90b5-ecc7eb957dd1,DISK], DatanodeInfoWithStorage[127.0.0.1:42108,DS-d89bf0ac-5948-4053-980d-dc77483fc85d,DISK], DatanodeInfoWithStorage[127.0.0.1:42565,DS-252794e4-5a9f-4020-9e58-ae68e0e124c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1052158967-172.17.0.12-1598414884946:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41314,DS-1a7ad6eb-968e-4b85-9636-717cb2d8c8b1,DISK], DatanodeInfoWithStorage[127.0.0.1:34331,DS-6ef76617-b555-4f73-b818-a5b0d9e04817,DISK], DatanodeInfoWithStorage[127.0.0.1:33734,DS-e7a9683f-5e04-4565-9409-178c0bf050c9,DISK], DatanodeInfoWithStorage[127.0.0.1:36630,DS-6b3c9037-870a-4bb0-bc87-81f6b5ac768c,DISK], DatanodeInfoWithStorage[127.0.0.1:43664,DS-b189f2b1-b940-466a-aa92-2098169f2ecc,DISK], DatanodeInfoWithStorage[127.0.0.1:45213,DS-378f9c9a-8542-4afd-90b5-ecc7eb957dd1,DISK], DatanodeInfoWithStorage[127.0.0.1:42108,DS-d89bf0ac-5948-4053-980d-dc77483fc85d,DISK], DatanodeInfoWithStorage[127.0.0.1:42565,DS-252794e4-5a9f-4020-9e58-ae68e0e124c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.block-pinning.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1510985658-172.17.0.12-1598415351270:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46226,DS-55271256-396a-4803-be33-d8545a55d7e2,DISK], DatanodeInfoWithStorage[127.0.0.1:41339,DS-01d04f6b-7557-4d40-8cd5-b3bd4ea637a9,DISK], DatanodeInfoWithStorage[127.0.0.1:45966,DS-db1fb992-8c0a-4307-b732-ff5868e3dc1d,DISK], DatanodeInfoWithStorage[127.0.0.1:33947,DS-ab2ddf2b-cd29-4efe-b584-9fddfe927321,DISK], DatanodeInfoWithStorage[127.0.0.1:43211,DS-35f5affb-6ac8-48d1-b52f-371e9f7ad856,DISK], DatanodeInfoWithStorage[127.0.0.1:34570,DS-18231010-78fe-4ec0-b294-8c20c56bafca,DISK], DatanodeInfoWithStorage[127.0.0.1:40111,DS-b8e3c444-fc59-43af-b0a3-903b7596e5e9,DISK], DatanodeInfoWithStorage[127.0.0.1:41722,DS-c0857253-7eef-45ec-9a6e-6f69fea9fd68,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1510985658-172.17.0.12-1598415351270:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46226,DS-55271256-396a-4803-be33-d8545a55d7e2,DISK], DatanodeInfoWithStorage[127.0.0.1:41339,DS-01d04f6b-7557-4d40-8cd5-b3bd4ea637a9,DISK], DatanodeInfoWithStorage[127.0.0.1:45966,DS-db1fb992-8c0a-4307-b732-ff5868e3dc1d,DISK], DatanodeInfoWithStorage[127.0.0.1:33947,DS-ab2ddf2b-cd29-4efe-b584-9fddfe927321,DISK], DatanodeInfoWithStorage[127.0.0.1:43211,DS-35f5affb-6ac8-48d1-b52f-371e9f7ad856,DISK], DatanodeInfoWithStorage[127.0.0.1:34570,DS-18231010-78fe-4ec0-b294-8c20c56bafca,DISK], DatanodeInfoWithStorage[127.0.0.1:40111,DS-b8e3c444-fc59-43af-b0a3-903b7596e5e9,DISK], DatanodeInfoWithStorage[127.0.0.1:41722,DS-c0857253-7eef-45ec-9a6e-6f69fea9fd68,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.block-pinning.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-656597765-172.17.0.12-1598415576107:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38974,DS-8290810a-8143-4985-bcfd-1ca3d2678e8e,DISK], DatanodeInfoWithStorage[127.0.0.1:43577,DS-8a9a8685-0fa5-44d5-a528-465bd4fbf635,DISK], DatanodeInfoWithStorage[127.0.0.1:39090,DS-0beca6ce-1ea7-4f29-bb45-d956d50ffa50,DISK], DatanodeInfoWithStorage[127.0.0.1:34957,DS-bf71bab8-28b7-4b1e-86ec-293d507597ba,DISK], DatanodeInfoWithStorage[127.0.0.1:35962,DS-58047bfb-d781-46cf-a18e-8af2c420d3db,DISK], DatanodeInfoWithStorage[127.0.0.1:36427,DS-f4b983f7-e8b8-413b-8954-0f303463993a,DISK], DatanodeInfoWithStorage[127.0.0.1:40542,DS-3948dcdb-c2b2-4935-8b01-63d1eec70f89,DISK], DatanodeInfoWithStorage[127.0.0.1:36385,DS-5daebc5a-9056-4ab8-913e-651c04dba854,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-656597765-172.17.0.12-1598415576107:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38974,DS-8290810a-8143-4985-bcfd-1ca3d2678e8e,DISK], DatanodeInfoWithStorage[127.0.0.1:43577,DS-8a9a8685-0fa5-44d5-a528-465bd4fbf635,DISK], DatanodeInfoWithStorage[127.0.0.1:39090,DS-0beca6ce-1ea7-4f29-bb45-d956d50ffa50,DISK], DatanodeInfoWithStorage[127.0.0.1:34957,DS-bf71bab8-28b7-4b1e-86ec-293d507597ba,DISK], DatanodeInfoWithStorage[127.0.0.1:35962,DS-58047bfb-d781-46cf-a18e-8af2c420d3db,DISK], DatanodeInfoWithStorage[127.0.0.1:36427,DS-f4b983f7-e8b8-413b-8954-0f303463993a,DISK], DatanodeInfoWithStorage[127.0.0.1:40542,DS-3948dcdb-c2b2-4935-8b01-63d1eec70f89,DISK], DatanodeInfoWithStorage[127.0.0.1:36385,DS-5daebc5a-9056-4ab8-913e-651c04dba854,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.block-pinning.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-828604904-172.17.0.12-1598416087189:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33274,DS-9bc884c8-f19c-41b4-9b39-a44b9cdccadb,DISK], DatanodeInfoWithStorage[127.0.0.1:34699,DS-3f411527-eae6-450a-8ca2-2e185a58bdce,DISK], DatanodeInfoWithStorage[127.0.0.1:43144,DS-dfcca72f-412c-4f70-aa3a-8a88c2f1c098,DISK], DatanodeInfoWithStorage[127.0.0.1:34460,DS-c6886875-7d2d-48ab-b87f-7a7536cc3285,DISK], DatanodeInfoWithStorage[127.0.0.1:40301,DS-65491c25-9899-4a3a-aa1a-c0e5ee5b6901,DISK], DatanodeInfoWithStorage[127.0.0.1:33027,DS-5ef78828-3498-47c4-b2c4-ab50ae47a02c,DISK], DatanodeInfoWithStorage[127.0.0.1:45695,DS-838f78c3-a12d-4670-8f5d-0970fd4fa421,DISK], DatanodeInfoWithStorage[127.0.0.1:42490,DS-6bdecd14-60bf-475d-9fbe-335e891bd99c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-828604904-172.17.0.12-1598416087189:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33274,DS-9bc884c8-f19c-41b4-9b39-a44b9cdccadb,DISK], DatanodeInfoWithStorage[127.0.0.1:34699,DS-3f411527-eae6-450a-8ca2-2e185a58bdce,DISK], DatanodeInfoWithStorage[127.0.0.1:43144,DS-dfcca72f-412c-4f70-aa3a-8a88c2f1c098,DISK], DatanodeInfoWithStorage[127.0.0.1:34460,DS-c6886875-7d2d-48ab-b87f-7a7536cc3285,DISK], DatanodeInfoWithStorage[127.0.0.1:40301,DS-65491c25-9899-4a3a-aa1a-c0e5ee5b6901,DISK], DatanodeInfoWithStorage[127.0.0.1:33027,DS-5ef78828-3498-47c4-b2c4-ab50ae47a02c,DISK], DatanodeInfoWithStorage[127.0.0.1:45695,DS-838f78c3-a12d-4670-8f5d-0970fd4fa421,DISK], DatanodeInfoWithStorage[127.0.0.1:42490,DS-6bdecd14-60bf-475d-9fbe-335e891bd99c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.block-pinning.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2064786873-172.17.0.12-1598416425849:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42281,DS-0d75e9f7-19e8-44c5-a8fb-4c1743c98d46,DISK], DatanodeInfoWithStorage[127.0.0.1:38786,DS-9c3db2fc-9373-4d5d-a7d6-fe8afce31516,DISK], DatanodeInfoWithStorage[127.0.0.1:42885,DS-e50b5db7-36c0-44b5-a4e5-9f4d72350e38,DISK], DatanodeInfoWithStorage[127.0.0.1:35000,DS-5433a6ce-e6ca-4cca-8bc1-aead1c97ec7f,DISK], DatanodeInfoWithStorage[127.0.0.1:42091,DS-918b9bab-a864-4081-815e-a9ea25f7996b,DISK], DatanodeInfoWithStorage[127.0.0.1:44515,DS-338df66a-3213-4227-841e-140ef044d449,DISK], DatanodeInfoWithStorage[127.0.0.1:39333,DS-c9e1ad7e-2b35-434a-a59b-00ae6aef0894,DISK], DatanodeInfoWithStorage[127.0.0.1:44006,DS-0eac0388-6d46-4e36-b608-4cf05bcb86ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2064786873-172.17.0.12-1598416425849:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42281,DS-0d75e9f7-19e8-44c5-a8fb-4c1743c98d46,DISK], DatanodeInfoWithStorage[127.0.0.1:38786,DS-9c3db2fc-9373-4d5d-a7d6-fe8afce31516,DISK], DatanodeInfoWithStorage[127.0.0.1:42885,DS-e50b5db7-36c0-44b5-a4e5-9f4d72350e38,DISK], DatanodeInfoWithStorage[127.0.0.1:35000,DS-5433a6ce-e6ca-4cca-8bc1-aead1c97ec7f,DISK], DatanodeInfoWithStorage[127.0.0.1:42091,DS-918b9bab-a864-4081-815e-a9ea25f7996b,DISK], DatanodeInfoWithStorage[127.0.0.1:44515,DS-338df66a-3213-4227-841e-140ef044d449,DISK], DatanodeInfoWithStorage[127.0.0.1:39333,DS-c9e1ad7e-2b35-434a-a59b-00ae6aef0894,DISK], DatanodeInfoWithStorage[127.0.0.1:44006,DS-0eac0388-6d46-4e36-b608-4cf05bcb86ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.block-pinning.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2112711104-172.17.0.12-1598416760190:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32955,DS-c16eb667-8009-4b1f-8387-ffd0843e7ccb,DISK], DatanodeInfoWithStorage[127.0.0.1:45254,DS-20799c9a-f8f4-4306-b6f7-5f3f280084ae,DISK], DatanodeInfoWithStorage[127.0.0.1:40991,DS-16ced90f-6c0e-4f4e-b032-e5438c78bf49,DISK], DatanodeInfoWithStorage[127.0.0.1:39831,DS-fc5b762e-97e0-4339-a59f-6bf9942e2d3e,DISK], DatanodeInfoWithStorage[127.0.0.1:37967,DS-3fffdffb-cb71-4add-9504-755c53091fb4,DISK], DatanodeInfoWithStorage[127.0.0.1:37761,DS-5035f169-ea0a-491d-9a1f-a0f4b9add607,DISK], DatanodeInfoWithStorage[127.0.0.1:39294,DS-fec33eea-7e4e-4fe8-8220-1547fa2d9404,DISK], DatanodeInfoWithStorage[127.0.0.1:34710,DS-211669d6-9d2e-4e39-99f5-9f9c369f1632,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2112711104-172.17.0.12-1598416760190:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32955,DS-c16eb667-8009-4b1f-8387-ffd0843e7ccb,DISK], DatanodeInfoWithStorage[127.0.0.1:45254,DS-20799c9a-f8f4-4306-b6f7-5f3f280084ae,DISK], DatanodeInfoWithStorage[127.0.0.1:40991,DS-16ced90f-6c0e-4f4e-b032-e5438c78bf49,DISK], DatanodeInfoWithStorage[127.0.0.1:39831,DS-fc5b762e-97e0-4339-a59f-6bf9942e2d3e,DISK], DatanodeInfoWithStorage[127.0.0.1:37967,DS-3fffdffb-cb71-4add-9504-755c53091fb4,DISK], DatanodeInfoWithStorage[127.0.0.1:37761,DS-5035f169-ea0a-491d-9a1f-a0f4b9add607,DISK], DatanodeInfoWithStorage[127.0.0.1:39294,DS-fec33eea-7e4e-4fe8-8220-1547fa2d9404,DISK], DatanodeInfoWithStorage[127.0.0.1:34710,DS-211669d6-9d2e-4e39-99f5-9f9c369f1632,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5084
