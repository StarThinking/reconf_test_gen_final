reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-599001225-172.17.0.7-1598335749925:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42852,DS-15e4dd96-fdf6-48f8-b542-ed2221ac1a53,DISK], DatanodeInfoWithStorage[127.0.0.1:33878,DS-d86402f0-d94a-4384-a94f-072146ebc655,DISK], DatanodeInfoWithStorage[127.0.0.1:33310,DS-46f82b8d-9e17-461b-a562-f8884a956d18,DISK], DatanodeInfoWithStorage[127.0.0.1:38469,DS-2712c626-da34-434f-b67c-8f4d904e7f28,DISK], DatanodeInfoWithStorage[127.0.0.1:39166,DS-bad73109-c4b6-444d-8e4d-ea3aa1d9fa86,DISK], DatanodeInfoWithStorage[127.0.0.1:42609,DS-ae070afd-0e40-4a58-bcd1-779988cc7970,DISK], DatanodeInfoWithStorage[127.0.0.1:34466,DS-af68943c-d2cb-4087-bc52-b7b6adf4864f,DISK], DatanodeInfoWithStorage[127.0.0.1:38218,DS-52f06e4e-b568-4333-ac70-29df19090367,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-599001225-172.17.0.7-1598335749925:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42852,DS-15e4dd96-fdf6-48f8-b542-ed2221ac1a53,DISK], DatanodeInfoWithStorage[127.0.0.1:33878,DS-d86402f0-d94a-4384-a94f-072146ebc655,DISK], DatanodeInfoWithStorage[127.0.0.1:33310,DS-46f82b8d-9e17-461b-a562-f8884a956d18,DISK], DatanodeInfoWithStorage[127.0.0.1:38469,DS-2712c626-da34-434f-b67c-8f4d904e7f28,DISK], DatanodeInfoWithStorage[127.0.0.1:39166,DS-bad73109-c4b6-444d-8e4d-ea3aa1d9fa86,DISK], DatanodeInfoWithStorage[127.0.0.1:42609,DS-ae070afd-0e40-4a58-bcd1-779988cc7970,DISK], DatanodeInfoWithStorage[127.0.0.1:34466,DS-af68943c-d2cb-4087-bc52-b7b6adf4864f,DISK], DatanodeInfoWithStorage[127.0.0.1:38218,DS-52f06e4e-b568-4333-ac70-29df19090367,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-314213884-172.17.0.7-1598336047132:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39658,DS-00b9f402-eb14-449f-81f9-307e8faaeb54,DISK], DatanodeInfoWithStorage[127.0.0.1:42895,DS-1ca4047e-762d-430d-bc7d-19a02832457b,DISK], DatanodeInfoWithStorage[127.0.0.1:38993,DS-365fa927-6204-486c-a8ca-a72612fd5385,DISK], DatanodeInfoWithStorage[127.0.0.1:39163,DS-84d26cc3-65b8-4e18-9917-442b5c301dc8,DISK], DatanodeInfoWithStorage[127.0.0.1:42609,DS-3ece4ecf-e89b-413b-838f-5852f652bcfb,DISK], DatanodeInfoWithStorage[127.0.0.1:34259,DS-f315be31-6d9e-49d5-9cb2-01dde016fba5,DISK], DatanodeInfoWithStorage[127.0.0.1:35645,DS-ec873c19-63aa-4401-a1ae-9654466b6fcd,DISK], DatanodeInfoWithStorage[127.0.0.1:37399,DS-1f603fa0-1dfc-421f-a076-e0b2b1d5ba13,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-314213884-172.17.0.7-1598336047132:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39658,DS-00b9f402-eb14-449f-81f9-307e8faaeb54,DISK], DatanodeInfoWithStorage[127.0.0.1:42895,DS-1ca4047e-762d-430d-bc7d-19a02832457b,DISK], DatanodeInfoWithStorage[127.0.0.1:38993,DS-365fa927-6204-486c-a8ca-a72612fd5385,DISK], DatanodeInfoWithStorage[127.0.0.1:39163,DS-84d26cc3-65b8-4e18-9917-442b5c301dc8,DISK], DatanodeInfoWithStorage[127.0.0.1:42609,DS-3ece4ecf-e89b-413b-838f-5852f652bcfb,DISK], DatanodeInfoWithStorage[127.0.0.1:34259,DS-f315be31-6d9e-49d5-9cb2-01dde016fba5,DISK], DatanodeInfoWithStorage[127.0.0.1:35645,DS-ec873c19-63aa-4401-a1ae-9654466b6fcd,DISK], DatanodeInfoWithStorage[127.0.0.1:37399,DS-1f603fa0-1dfc-421f-a076-e0b2b1d5ba13,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1742973144-172.17.0.7-1598336401693:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39950,DS-11c52961-34fa-4ab4-accc-00ffd5006596,DISK], DatanodeInfoWithStorage[127.0.0.1:35643,DS-ba0f0ce3-31d2-4937-820d-b2a815e74f71,DISK], DatanodeInfoWithStorage[127.0.0.1:37355,DS-c6c85494-fd2c-4ffa-a7e1-b74a0c8f8815,DISK], DatanodeInfoWithStorage[127.0.0.1:42763,DS-332c6657-11b7-4a3f-920e-91695f94e72a,DISK], DatanodeInfoWithStorage[127.0.0.1:46560,DS-af719e8e-589c-446c-848e-8bff0a20e9fa,DISK], DatanodeInfoWithStorage[127.0.0.1:46694,DS-cdc0d275-8e36-4dee-9de2-cebc426d74c2,DISK], DatanodeInfoWithStorage[127.0.0.1:34719,DS-cf75c490-4e1d-4ce0-baf1-de703041671b,DISK], DatanodeInfoWithStorage[127.0.0.1:35720,DS-819b6843-3480-473b-8799-8c60de4d1eb3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1742973144-172.17.0.7-1598336401693:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39950,DS-11c52961-34fa-4ab4-accc-00ffd5006596,DISK], DatanodeInfoWithStorage[127.0.0.1:35643,DS-ba0f0ce3-31d2-4937-820d-b2a815e74f71,DISK], DatanodeInfoWithStorage[127.0.0.1:37355,DS-c6c85494-fd2c-4ffa-a7e1-b74a0c8f8815,DISK], DatanodeInfoWithStorage[127.0.0.1:42763,DS-332c6657-11b7-4a3f-920e-91695f94e72a,DISK], DatanodeInfoWithStorage[127.0.0.1:46560,DS-af719e8e-589c-446c-848e-8bff0a20e9fa,DISK], DatanodeInfoWithStorage[127.0.0.1:46694,DS-cdc0d275-8e36-4dee-9de2-cebc426d74c2,DISK], DatanodeInfoWithStorage[127.0.0.1:34719,DS-cf75c490-4e1d-4ce0-baf1-de703041671b,DISK], DatanodeInfoWithStorage[127.0.0.1:35720,DS-819b6843-3480-473b-8799-8c60de4d1eb3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1717638524-172.17.0.7-1598336508811:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43363,DS-091686a9-62ec-4f17-9821-ab50098519d7,DISK], DatanodeInfoWithStorage[127.0.0.1:42997,DS-a2766b06-199b-44a6-a23f-1b49b266cde1,DISK], DatanodeInfoWithStorage[127.0.0.1:33543,DS-8af09cf4-8983-4921-87cd-ecef551fbe39,DISK], DatanodeInfoWithStorage[127.0.0.1:42021,DS-06ac7377-fde5-481a-ab15-1c18f3677c2f,DISK], DatanodeInfoWithStorage[127.0.0.1:40540,DS-f2a45764-d316-47bc-8379-e246cc04186f,DISK], DatanodeInfoWithStorage[127.0.0.1:45270,DS-bfa43262-1564-4de8-b8d6-3bd1c5319349,DISK], DatanodeInfoWithStorage[127.0.0.1:39243,DS-ec31409d-3f77-4323-ab2c-8f1430bac226,DISK], DatanodeInfoWithStorage[127.0.0.1:36675,DS-c9a3ca67-efe9-42a6-b945-b3434ad96721,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1717638524-172.17.0.7-1598336508811:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43363,DS-091686a9-62ec-4f17-9821-ab50098519d7,DISK], DatanodeInfoWithStorage[127.0.0.1:42997,DS-a2766b06-199b-44a6-a23f-1b49b266cde1,DISK], DatanodeInfoWithStorage[127.0.0.1:33543,DS-8af09cf4-8983-4921-87cd-ecef551fbe39,DISK], DatanodeInfoWithStorage[127.0.0.1:42021,DS-06ac7377-fde5-481a-ab15-1c18f3677c2f,DISK], DatanodeInfoWithStorage[127.0.0.1:40540,DS-f2a45764-d316-47bc-8379-e246cc04186f,DISK], DatanodeInfoWithStorage[127.0.0.1:45270,DS-bfa43262-1564-4de8-b8d6-3bd1c5319349,DISK], DatanodeInfoWithStorage[127.0.0.1:39243,DS-ec31409d-3f77-4323-ab2c-8f1430bac226,DISK], DatanodeInfoWithStorage[127.0.0.1:36675,DS-c9a3ca67-efe9-42a6-b945-b3434ad96721,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1921610972-172.17.0.7-1598338336127:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39305,DS-cd82bd5a-8cfb-4bc8-ba21-dc88a54c836a,DISK], DatanodeInfoWithStorage[127.0.0.1:34609,DS-f69a5749-827d-4025-a08c-f7fc480f6940,DISK], DatanodeInfoWithStorage[127.0.0.1:42946,DS-a32ae526-3046-4b6b-993e-d1473b1dd8d5,DISK], DatanodeInfoWithStorage[127.0.0.1:42538,DS-82df03b6-c948-4ceb-9780-daaff3f1c798,DISK], DatanodeInfoWithStorage[127.0.0.1:34608,DS-7c077026-b1b6-4866-b67d-9d1317442061,DISK], DatanodeInfoWithStorage[127.0.0.1:39690,DS-5e29f794-439a-4218-8029-4f2f45f2be73,DISK], DatanodeInfoWithStorage[127.0.0.1:34618,DS-aa4e132c-ad82-4bc3-8a47-9f840e005860,DISK], DatanodeInfoWithStorage[127.0.0.1:46071,DS-3db3436a-e9b6-4b61-8c49-a42969540340,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1921610972-172.17.0.7-1598338336127:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39305,DS-cd82bd5a-8cfb-4bc8-ba21-dc88a54c836a,DISK], DatanodeInfoWithStorage[127.0.0.1:34609,DS-f69a5749-827d-4025-a08c-f7fc480f6940,DISK], DatanodeInfoWithStorage[127.0.0.1:42946,DS-a32ae526-3046-4b6b-993e-d1473b1dd8d5,DISK], DatanodeInfoWithStorage[127.0.0.1:42538,DS-82df03b6-c948-4ceb-9780-daaff3f1c798,DISK], DatanodeInfoWithStorage[127.0.0.1:34608,DS-7c077026-b1b6-4866-b67d-9d1317442061,DISK], DatanodeInfoWithStorage[127.0.0.1:39690,DS-5e29f794-439a-4218-8029-4f2f45f2be73,DISK], DatanodeInfoWithStorage[127.0.0.1:34618,DS-aa4e132c-ad82-4bc3-8a47-9f840e005860,DISK], DatanodeInfoWithStorage[127.0.0.1:46071,DS-3db3436a-e9b6-4b61-8c49-a42969540340,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1863027806-172.17.0.7-1598338762248:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35895,DS-31c67a4c-feb3-4120-b011-222642fc24b2,DISK], DatanodeInfoWithStorage[127.0.0.1:37287,DS-ef75d5b5-b9be-41cc-9246-1e5d19fb33da,DISK], DatanodeInfoWithStorage[127.0.0.1:40602,DS-edeb79a8-5dad-43b3-aade-bd1654d9beed,DISK], DatanodeInfoWithStorage[127.0.0.1:36763,DS-5bde50f0-0c69-4b8d-a7ab-3dc694f13467,DISK], DatanodeInfoWithStorage[127.0.0.1:36224,DS-bf7263eb-b6ea-4c22-a4fc-0dc0aad12553,DISK], DatanodeInfoWithStorage[127.0.0.1:39026,DS-4afd34d0-2c81-4b58-a82d-9f9355e35141,DISK], DatanodeInfoWithStorage[127.0.0.1:33055,DS-d1b9b59d-d409-4093-b356-da6148afef61,DISK], DatanodeInfoWithStorage[127.0.0.1:33600,DS-6694a818-d1a0-4479-806d-aeb88f6db596,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1863027806-172.17.0.7-1598338762248:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35895,DS-31c67a4c-feb3-4120-b011-222642fc24b2,DISK], DatanodeInfoWithStorage[127.0.0.1:37287,DS-ef75d5b5-b9be-41cc-9246-1e5d19fb33da,DISK], DatanodeInfoWithStorage[127.0.0.1:40602,DS-edeb79a8-5dad-43b3-aade-bd1654d9beed,DISK], DatanodeInfoWithStorage[127.0.0.1:36763,DS-5bde50f0-0c69-4b8d-a7ab-3dc694f13467,DISK], DatanodeInfoWithStorage[127.0.0.1:36224,DS-bf7263eb-b6ea-4c22-a4fc-0dc0aad12553,DISK], DatanodeInfoWithStorage[127.0.0.1:39026,DS-4afd34d0-2c81-4b58-a82d-9f9355e35141,DISK], DatanodeInfoWithStorage[127.0.0.1:33055,DS-d1b9b59d-d409-4093-b356-da6148afef61,DISK], DatanodeInfoWithStorage[127.0.0.1:33600,DS-6694a818-d1a0-4479-806d-aeb88f6db596,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1473645615-172.17.0.7-1598339280752:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33279,DS-1492dbc5-c5ec-41a2-8f41-0e6656f6991e,DISK], DatanodeInfoWithStorage[127.0.0.1:35700,DS-35e433fb-61f4-425c-bcc5-57f8639934b3,DISK], DatanodeInfoWithStorage[127.0.0.1:35539,DS-13f75974-89ff-43f5-a268-b03addac6c72,DISK], DatanodeInfoWithStorage[127.0.0.1:36647,DS-87596087-4a0b-49be-b22b-f243127ed936,DISK], DatanodeInfoWithStorage[127.0.0.1:37057,DS-344cb99c-e5a7-4bf2-b461-f1bde94866b8,DISK], DatanodeInfoWithStorage[127.0.0.1:37904,DS-8fa1dddb-3d0f-4b3b-810e-e03ffafabfed,DISK], DatanodeInfoWithStorage[127.0.0.1:40399,DS-7df84d1c-9060-4a80-a65e-8d217f67aaa5,DISK], DatanodeInfoWithStorage[127.0.0.1:33044,DS-843904e9-3097-46db-8a5a-f4e85a5a4d66,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1473645615-172.17.0.7-1598339280752:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33279,DS-1492dbc5-c5ec-41a2-8f41-0e6656f6991e,DISK], DatanodeInfoWithStorage[127.0.0.1:35700,DS-35e433fb-61f4-425c-bcc5-57f8639934b3,DISK], DatanodeInfoWithStorage[127.0.0.1:35539,DS-13f75974-89ff-43f5-a268-b03addac6c72,DISK], DatanodeInfoWithStorage[127.0.0.1:36647,DS-87596087-4a0b-49be-b22b-f243127ed936,DISK], DatanodeInfoWithStorage[127.0.0.1:37057,DS-344cb99c-e5a7-4bf2-b461-f1bde94866b8,DISK], DatanodeInfoWithStorage[127.0.0.1:37904,DS-8fa1dddb-3d0f-4b3b-810e-e03ffafabfed,DISK], DatanodeInfoWithStorage[127.0.0.1:40399,DS-7df84d1c-9060-4a80-a65e-8d217f67aaa5,DISK], DatanodeInfoWithStorage[127.0.0.1:33044,DS-843904e9-3097-46db-8a5a-f4e85a5a4d66,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2022941523-172.17.0.7-1598340541748:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46866,DS-92d80b25-9ee8-4436-8bb1-7c7bf89442f1,DISK], DatanodeInfoWithStorage[127.0.0.1:42552,DS-cba0acf1-498a-4377-9217-011f06ff0ad8,DISK], DatanodeInfoWithStorage[127.0.0.1:34248,DS-0048fba0-0176-43be-85fc-fae4427c9244,DISK], DatanodeInfoWithStorage[127.0.0.1:40597,DS-9ab82a24-2534-4a7c-94c4-cbe0095fbd0e,DISK], DatanodeInfoWithStorage[127.0.0.1:37720,DS-4e2d9196-4e1a-4380-a7e0-b2d6b7e1ed06,DISK], DatanodeInfoWithStorage[127.0.0.1:45771,DS-9bf28922-4707-4023-a2f1-def78b700bd8,DISK], DatanodeInfoWithStorage[127.0.0.1:41472,DS-b4308819-deca-4d76-93d6-251c17b1a81d,DISK], DatanodeInfoWithStorage[127.0.0.1:36880,DS-f97d057b-e96d-46ab-af4a-49b89e499945,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2022941523-172.17.0.7-1598340541748:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46866,DS-92d80b25-9ee8-4436-8bb1-7c7bf89442f1,DISK], DatanodeInfoWithStorage[127.0.0.1:42552,DS-cba0acf1-498a-4377-9217-011f06ff0ad8,DISK], DatanodeInfoWithStorage[127.0.0.1:34248,DS-0048fba0-0176-43be-85fc-fae4427c9244,DISK], DatanodeInfoWithStorage[127.0.0.1:40597,DS-9ab82a24-2534-4a7c-94c4-cbe0095fbd0e,DISK], DatanodeInfoWithStorage[127.0.0.1:37720,DS-4e2d9196-4e1a-4380-a7e0-b2d6b7e1ed06,DISK], DatanodeInfoWithStorage[127.0.0.1:45771,DS-9bf28922-4707-4023-a2f1-def78b700bd8,DISK], DatanodeInfoWithStorage[127.0.0.1:41472,DS-b4308819-deca-4d76-93d6-251c17b1a81d,DISK], DatanodeInfoWithStorage[127.0.0.1:36880,DS-f97d057b-e96d-46ab-af4a-49b89e499945,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1219525863-172.17.0.7-1598340787916:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39926,DS-2e45e206-7f32-4804-aab1-30d8f1323769,DISK], DatanodeInfoWithStorage[127.0.0.1:34162,DS-a948af98-31a4-4a4e-9c5e-f1a9b37ccc92,DISK], DatanodeInfoWithStorage[127.0.0.1:43350,DS-418594f2-ccec-4fb1-8d73-1d037e4c4c15,DISK], DatanodeInfoWithStorage[127.0.0.1:38625,DS-36c9bfc4-e2f5-4821-a371-e3e66f6cc7d3,DISK], DatanodeInfoWithStorage[127.0.0.1:46372,DS-be868443-c964-4fc4-8f85-0d362cb102e0,DISK], DatanodeInfoWithStorage[127.0.0.1:41002,DS-1035d47d-f926-4f0e-ac81-25d8e93920fd,DISK], DatanodeInfoWithStorage[127.0.0.1:41149,DS-41652601-d50d-4d3b-b207-6a0498230949,DISK], DatanodeInfoWithStorage[127.0.0.1:41604,DS-81adba47-ecb0-4c10-b131-2e12a1bb7c24,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1219525863-172.17.0.7-1598340787916:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39926,DS-2e45e206-7f32-4804-aab1-30d8f1323769,DISK], DatanodeInfoWithStorage[127.0.0.1:34162,DS-a948af98-31a4-4a4e-9c5e-f1a9b37ccc92,DISK], DatanodeInfoWithStorage[127.0.0.1:43350,DS-418594f2-ccec-4fb1-8d73-1d037e4c4c15,DISK], DatanodeInfoWithStorage[127.0.0.1:38625,DS-36c9bfc4-e2f5-4821-a371-e3e66f6cc7d3,DISK], DatanodeInfoWithStorage[127.0.0.1:46372,DS-be868443-c964-4fc4-8f85-0d362cb102e0,DISK], DatanodeInfoWithStorage[127.0.0.1:41002,DS-1035d47d-f926-4f0e-ac81-25d8e93920fd,DISK], DatanodeInfoWithStorage[127.0.0.1:41149,DS-41652601-d50d-4d3b-b207-6a0498230949,DISK], DatanodeInfoWithStorage[127.0.0.1:41604,DS-81adba47-ecb0-4c10-b131-2e12a1bb7c24,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 1 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 5548
