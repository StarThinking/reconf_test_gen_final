reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1208739819-172.17.0.2-1598145317276:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44441,DS-3737868a-b955-4a46-b8f9-123cabac11b5,DISK], DatanodeInfoWithStorage[127.0.0.1:44311,DS-b534dc81-ab41-40f6-9709-b656bae00bc3,DISK], DatanodeInfoWithStorage[127.0.0.1:39727,DS-2d5db2b0-6765-4865-b146-f27897a3d9e8,DISK], DatanodeInfoWithStorage[127.0.0.1:35115,DS-4316f4e5-dffb-4aaf-a7c4-89544c31fb9c,DISK], DatanodeInfoWithStorage[127.0.0.1:45017,DS-005118f9-89c9-4df7-a385-c919f96b6fb6,DISK], DatanodeInfoWithStorage[127.0.0.1:45144,DS-798be527-a215-4322-8b6f-bd32a47e5403,DISK], DatanodeInfoWithStorage[127.0.0.1:38839,DS-aeec8b44-87f0-4ea4-a15d-b4d5ba66c99b,DISK], DatanodeInfoWithStorage[127.0.0.1:34329,DS-17abb684-31af-4fdc-8bf2-af5b33aacccd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1208739819-172.17.0.2-1598145317276:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44441,DS-3737868a-b955-4a46-b8f9-123cabac11b5,DISK], DatanodeInfoWithStorage[127.0.0.1:44311,DS-b534dc81-ab41-40f6-9709-b656bae00bc3,DISK], DatanodeInfoWithStorage[127.0.0.1:39727,DS-2d5db2b0-6765-4865-b146-f27897a3d9e8,DISK], DatanodeInfoWithStorage[127.0.0.1:35115,DS-4316f4e5-dffb-4aaf-a7c4-89544c31fb9c,DISK], DatanodeInfoWithStorage[127.0.0.1:45017,DS-005118f9-89c9-4df7-a385-c919f96b6fb6,DISK], DatanodeInfoWithStorage[127.0.0.1:45144,DS-798be527-a215-4322-8b6f-bd32a47e5403,DISK], DatanodeInfoWithStorage[127.0.0.1:38839,DS-aeec8b44-87f0-4ea4-a15d-b4d5ba66c99b,DISK], DatanodeInfoWithStorage[127.0.0.1:34329,DS-17abb684-31af-4fdc-8bf2-af5b33aacccd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-634726596-172.17.0.2-1598145344357:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45682,DS-1dbdb93b-5cc6-4789-996f-3b8d4e9b8218,DISK], DatanodeInfoWithStorage[127.0.0.1:36350,DS-e0852333-3536-4a78-a73f-8c0a7768ac21,DISK], DatanodeInfoWithStorage[127.0.0.1:37599,DS-5b12ded3-eb37-43b7-a69b-ffdb96208008,DISK], DatanodeInfoWithStorage[127.0.0.1:37003,DS-67d91559-11c9-4293-81af-44a26df1167b,DISK], DatanodeInfoWithStorage[127.0.0.1:37198,DS-16bebea8-ee03-4d1d-9c62-69a4dcc5528a,DISK], DatanodeInfoWithStorage[127.0.0.1:46326,DS-dcb66ca8-c602-4695-a5d1-cfb8ddec8216,DISK], DatanodeInfoWithStorage[127.0.0.1:34672,DS-602aab42-c34a-4a6e-b98b-dd50ccc191e5,DISK], DatanodeInfoWithStorage[127.0.0.1:43767,DS-6e49967f-ad9d-4fda-8c1d-5db36a7e1d25,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-634726596-172.17.0.2-1598145344357:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45682,DS-1dbdb93b-5cc6-4789-996f-3b8d4e9b8218,DISK], DatanodeInfoWithStorage[127.0.0.1:36350,DS-e0852333-3536-4a78-a73f-8c0a7768ac21,DISK], DatanodeInfoWithStorage[127.0.0.1:37599,DS-5b12ded3-eb37-43b7-a69b-ffdb96208008,DISK], DatanodeInfoWithStorage[127.0.0.1:37003,DS-67d91559-11c9-4293-81af-44a26df1167b,DISK], DatanodeInfoWithStorage[127.0.0.1:37198,DS-16bebea8-ee03-4d1d-9c62-69a4dcc5528a,DISK], DatanodeInfoWithStorage[127.0.0.1:46326,DS-dcb66ca8-c602-4695-a5d1-cfb8ddec8216,DISK], DatanodeInfoWithStorage[127.0.0.1:34672,DS-602aab42-c34a-4a6e-b98b-dd50ccc191e5,DISK], DatanodeInfoWithStorage[127.0.0.1:43767,DS-6e49967f-ad9d-4fda-8c1d-5db36a7e1d25,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1174403071-172.17.0.2-1598145411778:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42699,DS-f9468b10-2d06-456d-ae3e-af4773a5fc0a,DISK], DatanodeInfoWithStorage[127.0.0.1:35700,DS-ca8fc65c-0cd3-405f-bf1b-5969143c923f,DISK], DatanodeInfoWithStorage[127.0.0.1:45485,DS-79af62e7-9c80-4e9d-82ea-6fd5cede1b57,DISK], DatanodeInfoWithStorage[127.0.0.1:40788,DS-46cb8ff9-4793-4d0f-bf26-e98a24db065e,DISK], DatanodeInfoWithStorage[127.0.0.1:42649,DS-e1152aed-452a-4abd-b3e8-dd767166f147,DISK], DatanodeInfoWithStorage[127.0.0.1:42793,DS-37f6c39c-d3e0-4da9-9360-61c86db2844c,DISK], DatanodeInfoWithStorage[127.0.0.1:32925,DS-860e3df1-ae18-4e87-8ca3-8907af2a115a,DISK], DatanodeInfoWithStorage[127.0.0.1:38620,DS-78fef756-f580-442b-9580-ec8f0605bebd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1174403071-172.17.0.2-1598145411778:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42699,DS-f9468b10-2d06-456d-ae3e-af4773a5fc0a,DISK], DatanodeInfoWithStorage[127.0.0.1:35700,DS-ca8fc65c-0cd3-405f-bf1b-5969143c923f,DISK], DatanodeInfoWithStorage[127.0.0.1:45485,DS-79af62e7-9c80-4e9d-82ea-6fd5cede1b57,DISK], DatanodeInfoWithStorage[127.0.0.1:40788,DS-46cb8ff9-4793-4d0f-bf26-e98a24db065e,DISK], DatanodeInfoWithStorage[127.0.0.1:42649,DS-e1152aed-452a-4abd-b3e8-dd767166f147,DISK], DatanodeInfoWithStorage[127.0.0.1:42793,DS-37f6c39c-d3e0-4da9-9360-61c86db2844c,DISK], DatanodeInfoWithStorage[127.0.0.1:32925,DS-860e3df1-ae18-4e87-8ca3-8907af2a115a,DISK], DatanodeInfoWithStorage[127.0.0.1:38620,DS-78fef756-f580-442b-9580-ec8f0605bebd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1584147102-172.17.0.2-1598146018818:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35834,DS-70b1ca2e-f354-49ba-93c9-e555e0266a5c,DISK], DatanodeInfoWithStorage[127.0.0.1:40627,DS-c9bb4f69-57c7-4dad-b000-638658cb86cd,DISK], DatanodeInfoWithStorage[127.0.0.1:33626,DS-953f77f5-3d75-4098-afb1-99c18b632a15,DISK], DatanodeInfoWithStorage[127.0.0.1:40499,DS-bd638b11-d6a2-44a8-bd75-4f3c393bc9a8,DISK], DatanodeInfoWithStorage[127.0.0.1:44142,DS-1b6845c1-4de0-4296-9eb0-e7b3aa6f02c9,DISK], DatanodeInfoWithStorage[127.0.0.1:33659,DS-1d2698d1-c2e6-4913-8be1-8a5fe5965b41,DISK], DatanodeInfoWithStorage[127.0.0.1:41680,DS-d8103c29-879d-4daa-b07a-3bb9a8620928,DISK], DatanodeInfoWithStorage[127.0.0.1:41630,DS-c95277b4-ec29-4b97-b695-eea3e11d166c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1584147102-172.17.0.2-1598146018818:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35834,DS-70b1ca2e-f354-49ba-93c9-e555e0266a5c,DISK], DatanodeInfoWithStorage[127.0.0.1:40627,DS-c9bb4f69-57c7-4dad-b000-638658cb86cd,DISK], DatanodeInfoWithStorage[127.0.0.1:33626,DS-953f77f5-3d75-4098-afb1-99c18b632a15,DISK], DatanodeInfoWithStorage[127.0.0.1:40499,DS-bd638b11-d6a2-44a8-bd75-4f3c393bc9a8,DISK], DatanodeInfoWithStorage[127.0.0.1:44142,DS-1b6845c1-4de0-4296-9eb0-e7b3aa6f02c9,DISK], DatanodeInfoWithStorage[127.0.0.1:33659,DS-1d2698d1-c2e6-4913-8be1-8a5fe5965b41,DISK], DatanodeInfoWithStorage[127.0.0.1:41680,DS-d8103c29-879d-4daa-b07a-3bb9a8620928,DISK], DatanodeInfoWithStorage[127.0.0.1:41630,DS-c95277b4-ec29-4b97-b695-eea3e11d166c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2112260002-172.17.0.2-1598146306686:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43620,DS-1d186492-3045-4397-9dba-9c2b74f1e70f,DISK], DatanodeInfoWithStorage[127.0.0.1:32881,DS-c7d6c5f6-7414-402b-990c-76b0f0d49272,DISK], DatanodeInfoWithStorage[127.0.0.1:39054,DS-af322bcc-cea1-4cb1-b985-d6526b7a5840,DISK], DatanodeInfoWithStorage[127.0.0.1:42167,DS-dee72c0a-d1b2-4fd7-ba38-48b6f30acd03,DISK], DatanodeInfoWithStorage[127.0.0.1:42454,DS-c8b61c62-be68-4a62-b863-0b322fef4d17,DISK], DatanodeInfoWithStorage[127.0.0.1:35930,DS-2dbab026-02d3-4337-b2b4-220f3be7c914,DISK], DatanodeInfoWithStorage[127.0.0.1:36241,DS-9c6b32a8-ffb6-45d7-9e48-fecd2e690445,DISK], DatanodeInfoWithStorage[127.0.0.1:36471,DS-5f491763-63fb-4cba-9073-349f5c40d980,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2112260002-172.17.0.2-1598146306686:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43620,DS-1d186492-3045-4397-9dba-9c2b74f1e70f,DISK], DatanodeInfoWithStorage[127.0.0.1:32881,DS-c7d6c5f6-7414-402b-990c-76b0f0d49272,DISK], DatanodeInfoWithStorage[127.0.0.1:39054,DS-af322bcc-cea1-4cb1-b985-d6526b7a5840,DISK], DatanodeInfoWithStorage[127.0.0.1:42167,DS-dee72c0a-d1b2-4fd7-ba38-48b6f30acd03,DISK], DatanodeInfoWithStorage[127.0.0.1:42454,DS-c8b61c62-be68-4a62-b863-0b322fef4d17,DISK], DatanodeInfoWithStorage[127.0.0.1:35930,DS-2dbab026-02d3-4337-b2b4-220f3be7c914,DISK], DatanodeInfoWithStorage[127.0.0.1:36241,DS-9c6b32a8-ffb6-45d7-9e48-fecd2e690445,DISK], DatanodeInfoWithStorage[127.0.0.1:36471,DS-5f491763-63fb-4cba-9073-349f5c40d980,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1767555878-172.17.0.2-1598146512380:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37276,DS-e3a9bde5-959b-46d9-a597-bfd338415761,DISK], DatanodeInfoWithStorage[127.0.0.1:42897,DS-0276b2fb-7d18-4966-913a-54822cb751fb,DISK], DatanodeInfoWithStorage[127.0.0.1:33759,DS-617b7a23-ad75-431c-b69d-cd00d497d3a9,DISK], DatanodeInfoWithStorage[127.0.0.1:40478,DS-1a937d34-c54c-4526-86e3-f65afa64d2b4,DISK], DatanodeInfoWithStorage[127.0.0.1:43353,DS-b3e7df7b-c174-43c0-b03a-a8db2e196483,DISK], DatanodeInfoWithStorage[127.0.0.1:34075,DS-c0ed5ebc-28e5-4a95-8f5b-e1b66de8b4e2,DISK], DatanodeInfoWithStorage[127.0.0.1:41569,DS-5fc6fef0-bf57-424f-8648-bb58232ad12a,DISK], DatanodeInfoWithStorage[127.0.0.1:39052,DS-57b1e4b0-3ecc-439b-8045-5d846f3859c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1767555878-172.17.0.2-1598146512380:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37276,DS-e3a9bde5-959b-46d9-a597-bfd338415761,DISK], DatanodeInfoWithStorage[127.0.0.1:42897,DS-0276b2fb-7d18-4966-913a-54822cb751fb,DISK], DatanodeInfoWithStorage[127.0.0.1:33759,DS-617b7a23-ad75-431c-b69d-cd00d497d3a9,DISK], DatanodeInfoWithStorage[127.0.0.1:40478,DS-1a937d34-c54c-4526-86e3-f65afa64d2b4,DISK], DatanodeInfoWithStorage[127.0.0.1:43353,DS-b3e7df7b-c174-43c0-b03a-a8db2e196483,DISK], DatanodeInfoWithStorage[127.0.0.1:34075,DS-c0ed5ebc-28e5-4a95-8f5b-e1b66de8b4e2,DISK], DatanodeInfoWithStorage[127.0.0.1:41569,DS-5fc6fef0-bf57-424f-8648-bb58232ad12a,DISK], DatanodeInfoWithStorage[127.0.0.1:39052,DS-57b1e4b0-3ecc-439b-8045-5d846f3859c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1060580658-172.17.0.2-1598147392099:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37591,DS-0db604d2-0a8f-42cd-9ab5-16fcef54c28c,DISK], DatanodeInfoWithStorage[127.0.0.1:36374,DS-cc2f0b48-87f8-43c5-857e-3fe91fbff1fd,DISK], DatanodeInfoWithStorage[127.0.0.1:43112,DS-4748ce2d-bf7b-42b0-97e6-f0077efc9ba5,DISK], DatanodeInfoWithStorage[127.0.0.1:34342,DS-df0af36c-e1e5-4502-838e-36da202c0b19,DISK], DatanodeInfoWithStorage[127.0.0.1:45808,DS-3298045f-540b-44f1-b97e-2f45aea20f9d,DISK], DatanodeInfoWithStorage[127.0.0.1:43255,DS-f3373527-fa80-4230-9b25-be1a8859b355,DISK], DatanodeInfoWithStorage[127.0.0.1:38491,DS-864e2c39-0f08-4344-b824-d3fa7b67b3e2,DISK], DatanodeInfoWithStorage[127.0.0.1:34283,DS-d13614e1-5d81-4176-b08d-f847b591a1ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1060580658-172.17.0.2-1598147392099:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37591,DS-0db604d2-0a8f-42cd-9ab5-16fcef54c28c,DISK], DatanodeInfoWithStorage[127.0.0.1:36374,DS-cc2f0b48-87f8-43c5-857e-3fe91fbff1fd,DISK], DatanodeInfoWithStorage[127.0.0.1:43112,DS-4748ce2d-bf7b-42b0-97e6-f0077efc9ba5,DISK], DatanodeInfoWithStorage[127.0.0.1:34342,DS-df0af36c-e1e5-4502-838e-36da202c0b19,DISK], DatanodeInfoWithStorage[127.0.0.1:45808,DS-3298045f-540b-44f1-b97e-2f45aea20f9d,DISK], DatanodeInfoWithStorage[127.0.0.1:43255,DS-f3373527-fa80-4230-9b25-be1a8859b355,DISK], DatanodeInfoWithStorage[127.0.0.1:38491,DS-864e2c39-0f08-4344-b824-d3fa7b67b3e2,DISK], DatanodeInfoWithStorage[127.0.0.1:34283,DS-d13614e1-5d81-4176-b08d-f847b591a1ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1590496502-172.17.0.2-1598147854197:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37747,DS-b4cd1362-0b75-4df4-b543-7d59e3874de4,DISK], DatanodeInfoWithStorage[127.0.0.1:44593,DS-14c72dd7-3e1e-4b75-9df8-a63e020bd1b8,DISK], DatanodeInfoWithStorage[127.0.0.1:43652,DS-9670e530-d41c-47ee-bd23-1eb3f3fabaa1,DISK], DatanodeInfoWithStorage[127.0.0.1:45220,DS-25e07740-bfc7-4456-8cd6-2f2bc1dda660,DISK], DatanodeInfoWithStorage[127.0.0.1:43556,DS-171aff57-877d-4695-a042-6ff43b347699,DISK], DatanodeInfoWithStorage[127.0.0.1:42468,DS-40b2cd6a-66d3-4d2e-9a6a-2f345ea62d58,DISK], DatanodeInfoWithStorage[127.0.0.1:46227,DS-7e3349e5-dfd3-42de-aedf-542ebcad8593,DISK], DatanodeInfoWithStorage[127.0.0.1:33778,DS-1e442c2e-73f7-47c1-9747-063da4e62fba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1590496502-172.17.0.2-1598147854197:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37747,DS-b4cd1362-0b75-4df4-b543-7d59e3874de4,DISK], DatanodeInfoWithStorage[127.0.0.1:44593,DS-14c72dd7-3e1e-4b75-9df8-a63e020bd1b8,DISK], DatanodeInfoWithStorage[127.0.0.1:43652,DS-9670e530-d41c-47ee-bd23-1eb3f3fabaa1,DISK], DatanodeInfoWithStorage[127.0.0.1:45220,DS-25e07740-bfc7-4456-8cd6-2f2bc1dda660,DISK], DatanodeInfoWithStorage[127.0.0.1:43556,DS-171aff57-877d-4695-a042-6ff43b347699,DISK], DatanodeInfoWithStorage[127.0.0.1:42468,DS-40b2cd6a-66d3-4d2e-9a6a-2f345ea62d58,DISK], DatanodeInfoWithStorage[127.0.0.1:46227,DS-7e3349e5-dfd3-42de-aedf-542ebcad8593,DISK], DatanodeInfoWithStorage[127.0.0.1:33778,DS-1e442c2e-73f7-47c1-9747-063da4e62fba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-846863315-172.17.0.2-1598147925417:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41925,DS-71af03a0-25b0-4fc0-966c-ce56c0c51a44,DISK], DatanodeInfoWithStorage[127.0.0.1:45244,DS-761f8f42-62ea-45c2-9c26-f6d86092441a,DISK], DatanodeInfoWithStorage[127.0.0.1:33587,DS-59e875ce-1ede-4c40-98f3-77422bbe5856,DISK], DatanodeInfoWithStorage[127.0.0.1:40760,DS-e7706b50-456c-4235-9930-d32db3cc6c23,DISK], DatanodeInfoWithStorage[127.0.0.1:39416,DS-deefc532-5b2e-4a4f-a4ed-7e6fae1a0103,DISK], DatanodeInfoWithStorage[127.0.0.1:42861,DS-bd19f499-cdc3-4571-8b33-80ef651f253f,DISK], DatanodeInfoWithStorage[127.0.0.1:45724,DS-c857231c-3aa3-4fb6-8dbf-5b0214e51eb4,DISK], DatanodeInfoWithStorage[127.0.0.1:35105,DS-baab0195-3ea2-4545-b93f-ad5fe8617617,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-846863315-172.17.0.2-1598147925417:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41925,DS-71af03a0-25b0-4fc0-966c-ce56c0c51a44,DISK], DatanodeInfoWithStorage[127.0.0.1:45244,DS-761f8f42-62ea-45c2-9c26-f6d86092441a,DISK], DatanodeInfoWithStorage[127.0.0.1:33587,DS-59e875ce-1ede-4c40-98f3-77422bbe5856,DISK], DatanodeInfoWithStorage[127.0.0.1:40760,DS-e7706b50-456c-4235-9930-d32db3cc6c23,DISK], DatanodeInfoWithStorage[127.0.0.1:39416,DS-deefc532-5b2e-4a4f-a4ed-7e6fae1a0103,DISK], DatanodeInfoWithStorage[127.0.0.1:42861,DS-bd19f499-cdc3-4571-8b33-80ef651f253f,DISK], DatanodeInfoWithStorage[127.0.0.1:45724,DS-c857231c-3aa3-4fb6-8dbf-5b0214e51eb4,DISK], DatanodeInfoWithStorage[127.0.0.1:35105,DS-baab0195-3ea2-4545-b93f-ad5fe8617617,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1732030797-172.17.0.2-1598148233367:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37630,DS-8a2441cc-261d-4c75-b51c-cd5502ba28a2,DISK], DatanodeInfoWithStorage[127.0.0.1:33723,DS-a9900807-4772-4b25-b659-26b7d5d4a5cc,DISK], DatanodeInfoWithStorage[127.0.0.1:35005,DS-4ab6066d-646e-4ae6-b923-f85b235394bc,DISK], DatanodeInfoWithStorage[127.0.0.1:42094,DS-c8800ae0-aded-410f-a7fe-1034d149d485,DISK], DatanodeInfoWithStorage[127.0.0.1:43623,DS-41e0241e-1f7a-400b-98a4-4e526a5d0916,DISK], DatanodeInfoWithStorage[127.0.0.1:43356,DS-30764248-c00c-4c1d-a792-913562fb1805,DISK], DatanodeInfoWithStorage[127.0.0.1:41767,DS-2b4b7b38-dd5e-443e-9f19-b4e239a9be95,DISK], DatanodeInfoWithStorage[127.0.0.1:38662,DS-82c2e97f-8578-47d2-b17a-5770148a4b6a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1732030797-172.17.0.2-1598148233367:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37630,DS-8a2441cc-261d-4c75-b51c-cd5502ba28a2,DISK], DatanodeInfoWithStorage[127.0.0.1:33723,DS-a9900807-4772-4b25-b659-26b7d5d4a5cc,DISK], DatanodeInfoWithStorage[127.0.0.1:35005,DS-4ab6066d-646e-4ae6-b923-f85b235394bc,DISK], DatanodeInfoWithStorage[127.0.0.1:42094,DS-c8800ae0-aded-410f-a7fe-1034d149d485,DISK], DatanodeInfoWithStorage[127.0.0.1:43623,DS-41e0241e-1f7a-400b-98a4-4e526a5d0916,DISK], DatanodeInfoWithStorage[127.0.0.1:43356,DS-30764248-c00c-4c1d-a792-913562fb1805,DISK], DatanodeInfoWithStorage[127.0.0.1:41767,DS-2b4b7b38-dd5e-443e-9f19-b4e239a9be95,DISK], DatanodeInfoWithStorage[127.0.0.1:38662,DS-82c2e97f-8578-47d2-b17a-5770148a4b6a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1204134798-172.17.0.2-1598148391092:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34588,DS-70bc20c8-ab0b-455e-8d1e-fd247b5c08d4,DISK], DatanodeInfoWithStorage[127.0.0.1:37851,DS-9362e910-b13e-4d46-9406-13c5f41ea540,DISK], DatanodeInfoWithStorage[127.0.0.1:44059,DS-5534d62f-ad47-463c-8011-68d3840acc6f,DISK], DatanodeInfoWithStorage[127.0.0.1:43661,DS-46bc152f-b4bd-4b72-b1cc-ae2773192bbb,DISK], DatanodeInfoWithStorage[127.0.0.1:41492,DS-ed605900-a608-412b-886f-bb5858771d08,DISK], DatanodeInfoWithStorage[127.0.0.1:40744,DS-8cec9e7e-5b0f-4f8d-b24b-abd019b091d2,DISK], DatanodeInfoWithStorage[127.0.0.1:34200,DS-661554de-e29f-4160-9c0b-d46dc79c71d9,DISK], DatanodeInfoWithStorage[127.0.0.1:42197,DS-27118ab7-15d6-49ba-8e73-741ed5f34be0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1204134798-172.17.0.2-1598148391092:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34588,DS-70bc20c8-ab0b-455e-8d1e-fd247b5c08d4,DISK], DatanodeInfoWithStorage[127.0.0.1:37851,DS-9362e910-b13e-4d46-9406-13c5f41ea540,DISK], DatanodeInfoWithStorage[127.0.0.1:44059,DS-5534d62f-ad47-463c-8011-68d3840acc6f,DISK], DatanodeInfoWithStorage[127.0.0.1:43661,DS-46bc152f-b4bd-4b72-b1cc-ae2773192bbb,DISK], DatanodeInfoWithStorage[127.0.0.1:41492,DS-ed605900-a608-412b-886f-bb5858771d08,DISK], DatanodeInfoWithStorage[127.0.0.1:40744,DS-8cec9e7e-5b0f-4f8d-b24b-abd019b091d2,DISK], DatanodeInfoWithStorage[127.0.0.1:34200,DS-661554de-e29f-4160-9c0b-d46dc79c71d9,DISK], DatanodeInfoWithStorage[127.0.0.1:42197,DS-27118ab7-15d6-49ba-8e73-741ed5f34be0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1095930961-172.17.0.2-1598148464902:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36727,DS-b538a98e-3875-4d2d-b4c6-61f714ed56f5,DISK], DatanodeInfoWithStorage[127.0.0.1:46337,DS-44bbdb7b-0856-43a5-8352-9dec73c526ac,DISK], DatanodeInfoWithStorage[127.0.0.1:33036,DS-1d053155-4f39-479b-97c7-172f607da1d0,DISK], DatanodeInfoWithStorage[127.0.0.1:34238,DS-29bf1b87-d2b8-40ec-910d-16f5619e90ef,DISK], DatanodeInfoWithStorage[127.0.0.1:33913,DS-2084e836-bbe0-4827-a0e6-bd64b55ba840,DISK], DatanodeInfoWithStorage[127.0.0.1:32823,DS-b4ffc076-3d11-431f-8b89-239da479cefd,DISK], DatanodeInfoWithStorage[127.0.0.1:38919,DS-11374482-1452-4d9e-99a7-6a1b44d7a92d,DISK], DatanodeInfoWithStorage[127.0.0.1:40754,DS-85c8fd91-df59-4c72-872c-bb1a5f6cb071,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1095930961-172.17.0.2-1598148464902:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36727,DS-b538a98e-3875-4d2d-b4c6-61f714ed56f5,DISK], DatanodeInfoWithStorage[127.0.0.1:46337,DS-44bbdb7b-0856-43a5-8352-9dec73c526ac,DISK], DatanodeInfoWithStorage[127.0.0.1:33036,DS-1d053155-4f39-479b-97c7-172f607da1d0,DISK], DatanodeInfoWithStorage[127.0.0.1:34238,DS-29bf1b87-d2b8-40ec-910d-16f5619e90ef,DISK], DatanodeInfoWithStorage[127.0.0.1:33913,DS-2084e836-bbe0-4827-a0e6-bd64b55ba840,DISK], DatanodeInfoWithStorage[127.0.0.1:32823,DS-b4ffc076-3d11-431f-8b89-239da479cefd,DISK], DatanodeInfoWithStorage[127.0.0.1:38919,DS-11374482-1452-4d9e-99a7-6a1b44d7a92d,DISK], DatanodeInfoWithStorage[127.0.0.1:40754,DS-85c8fd91-df59-4c72-872c-bb1a5f6cb071,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-270324958-172.17.0.2-1598148562789:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46509,DS-0249177a-0c1c-4573-9d07-009c96ef69a0,DISK], DatanodeInfoWithStorage[127.0.0.1:43195,DS-0435b6a0-5bc2-4dc9-90eb-607cb4b703b0,DISK], DatanodeInfoWithStorage[127.0.0.1:44712,DS-7684329f-4ed2-44c2-87fe-c4e9b576f0f3,DISK], DatanodeInfoWithStorage[127.0.0.1:46143,DS-eabd00a4-cc54-4c03-8d10-ae3402f97ae7,DISK], DatanodeInfoWithStorage[127.0.0.1:35026,DS-91f2e80d-441d-42f9-829c-ccd4582e63a6,DISK], DatanodeInfoWithStorage[127.0.0.1:44544,DS-9501e078-8113-4b5c-a344-8267ac5cd4a5,DISK], DatanodeInfoWithStorage[127.0.0.1:38383,DS-142fa19e-8f33-4af1-8f58-96ddd5adfa13,DISK], DatanodeInfoWithStorage[127.0.0.1:38747,DS-6249e246-80c6-4bc4-9261-26baa7292fda,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-270324958-172.17.0.2-1598148562789:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46509,DS-0249177a-0c1c-4573-9d07-009c96ef69a0,DISK], DatanodeInfoWithStorage[127.0.0.1:43195,DS-0435b6a0-5bc2-4dc9-90eb-607cb4b703b0,DISK], DatanodeInfoWithStorage[127.0.0.1:44712,DS-7684329f-4ed2-44c2-87fe-c4e9b576f0f3,DISK], DatanodeInfoWithStorage[127.0.0.1:46143,DS-eabd00a4-cc54-4c03-8d10-ae3402f97ae7,DISK], DatanodeInfoWithStorage[127.0.0.1:35026,DS-91f2e80d-441d-42f9-829c-ccd4582e63a6,DISK], DatanodeInfoWithStorage[127.0.0.1:44544,DS-9501e078-8113-4b5c-a344-8267ac5cd4a5,DISK], DatanodeInfoWithStorage[127.0.0.1:38383,DS-142fa19e-8f33-4af1-8f58-96ddd5adfa13,DISK], DatanodeInfoWithStorage[127.0.0.1:38747,DS-6249e246-80c6-4bc4-9261-26baa7292fda,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-170271881-172.17.0.2-1598148664533:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44863,DS-b6604355-8c91-45b5-9c41-6ed8638147c9,DISK], DatanodeInfoWithStorage[127.0.0.1:43907,DS-37c0013b-75e3-4b6f-b82e-b4227689a5bf,DISK], DatanodeInfoWithStorage[127.0.0.1:44815,DS-0506989b-316a-4cf0-a78d-adf0b647f917,DISK], DatanodeInfoWithStorage[127.0.0.1:46581,DS-116298b9-190e-46f3-a597-e9d3060c83c6,DISK], DatanodeInfoWithStorage[127.0.0.1:45292,DS-8b4ac526-b653-477c-b90a-1c8a7a23cdd1,DISK], DatanodeInfoWithStorage[127.0.0.1:41852,DS-5914fd56-f499-4b42-b759-856a02fcd915,DISK], DatanodeInfoWithStorage[127.0.0.1:35068,DS-61992753-c192-4961-90cc-864266bbb4e8,DISK], DatanodeInfoWithStorage[127.0.0.1:37160,DS-c19e017b-23a2-4f0f-9a6c-fd8ed424491a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-170271881-172.17.0.2-1598148664533:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44863,DS-b6604355-8c91-45b5-9c41-6ed8638147c9,DISK], DatanodeInfoWithStorage[127.0.0.1:43907,DS-37c0013b-75e3-4b6f-b82e-b4227689a5bf,DISK], DatanodeInfoWithStorage[127.0.0.1:44815,DS-0506989b-316a-4cf0-a78d-adf0b647f917,DISK], DatanodeInfoWithStorage[127.0.0.1:46581,DS-116298b9-190e-46f3-a597-e9d3060c83c6,DISK], DatanodeInfoWithStorage[127.0.0.1:45292,DS-8b4ac526-b653-477c-b90a-1c8a7a23cdd1,DISK], DatanodeInfoWithStorage[127.0.0.1:41852,DS-5914fd56-f499-4b42-b759-856a02fcd915,DISK], DatanodeInfoWithStorage[127.0.0.1:35068,DS-61992753-c192-4961-90cc-864266bbb4e8,DISK], DatanodeInfoWithStorage[127.0.0.1:37160,DS-c19e017b-23a2-4f0f-9a6c-fd8ed424491a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-380083404-172.17.0.2-1598149083390:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34658,DS-db260ce7-1661-4be8-a5f8-8bd772d5f8ed,DISK], DatanodeInfoWithStorage[127.0.0.1:34634,DS-85fc1acf-c34d-4ebf-903e-602c80cf6204,DISK], DatanodeInfoWithStorage[127.0.0.1:46525,DS-95b0b55b-6499-46e5-9af6-11d4fa607014,DISK], DatanodeInfoWithStorage[127.0.0.1:43937,DS-b424a60f-a8a5-46e3-9fd4-36266a3cca09,DISK], DatanodeInfoWithStorage[127.0.0.1:44919,DS-bd847787-1621-49ed-8788-de9012cf053d,DISK], DatanodeInfoWithStorage[127.0.0.1:40698,DS-8fc46492-38c0-48df-86bc-81f13a212ec5,DISK], DatanodeInfoWithStorage[127.0.0.1:36517,DS-4d687b64-4dd5-42c6-874f-b73ae4042fb9,DISK], DatanodeInfoWithStorage[127.0.0.1:39747,DS-b4d6f791-87f3-4c82-b02b-aa1f9a2fa77d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-380083404-172.17.0.2-1598149083390:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34658,DS-db260ce7-1661-4be8-a5f8-8bd772d5f8ed,DISK], DatanodeInfoWithStorage[127.0.0.1:34634,DS-85fc1acf-c34d-4ebf-903e-602c80cf6204,DISK], DatanodeInfoWithStorage[127.0.0.1:46525,DS-95b0b55b-6499-46e5-9af6-11d4fa607014,DISK], DatanodeInfoWithStorage[127.0.0.1:43937,DS-b424a60f-a8a5-46e3-9fd4-36266a3cca09,DISK], DatanodeInfoWithStorage[127.0.0.1:44919,DS-bd847787-1621-49ed-8788-de9012cf053d,DISK], DatanodeInfoWithStorage[127.0.0.1:40698,DS-8fc46492-38c0-48df-86bc-81f13a212ec5,DISK], DatanodeInfoWithStorage[127.0.0.1:36517,DS-4d687b64-4dd5-42c6-874f-b73ae4042fb9,DISK], DatanodeInfoWithStorage[127.0.0.1:39747,DS-b4d6f791-87f3-4c82-b02b-aa1f9a2fa77d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1125316911-172.17.0.2-1598149181194:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34732,DS-8a268788-e2fe-4a5f-a4cf-a05ba761225d,DISK], DatanodeInfoWithStorage[127.0.0.1:33292,DS-aa10563a-5d0d-4fe9-9200-d8781a31f16d,DISK], DatanodeInfoWithStorage[127.0.0.1:44763,DS-718d93ab-7d45-4380-ae4d-33461f38f9b0,DISK], DatanodeInfoWithStorage[127.0.0.1:33198,DS-cc5d40cd-10f4-4646-9946-ce252285be15,DISK], DatanodeInfoWithStorage[127.0.0.1:43225,DS-9029c659-e9e3-40b8-b819-000729a7269b,DISK], DatanodeInfoWithStorage[127.0.0.1:34188,DS-9b4fbcc1-ca0a-404f-8d99-7e1078713fb6,DISK], DatanodeInfoWithStorage[127.0.0.1:41465,DS-1b27371c-e815-4b5e-a3a0-a99b2b718a73,DISK], DatanodeInfoWithStorage[127.0.0.1:34210,DS-c84922ae-2098-4cd6-9f71-96e8e8b05d0e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1125316911-172.17.0.2-1598149181194:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34732,DS-8a268788-e2fe-4a5f-a4cf-a05ba761225d,DISK], DatanodeInfoWithStorage[127.0.0.1:33292,DS-aa10563a-5d0d-4fe9-9200-d8781a31f16d,DISK], DatanodeInfoWithStorage[127.0.0.1:44763,DS-718d93ab-7d45-4380-ae4d-33461f38f9b0,DISK], DatanodeInfoWithStorage[127.0.0.1:33198,DS-cc5d40cd-10f4-4646-9946-ce252285be15,DISK], DatanodeInfoWithStorage[127.0.0.1:43225,DS-9029c659-e9e3-40b8-b819-000729a7269b,DISK], DatanodeInfoWithStorage[127.0.0.1:34188,DS-9b4fbcc1-ca0a-404f-8d99-7e1078713fb6,DISK], DatanodeInfoWithStorage[127.0.0.1:41465,DS-1b27371c-e815-4b5e-a3a0-a99b2b718a73,DISK], DatanodeInfoWithStorage[127.0.0.1:34210,DS-c84922ae-2098-4cd6-9f71-96e8e8b05d0e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1906670409-172.17.0.2-1598150013753:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33554,DS-8ca21a56-0de6-4adb-81e8-54a935ef7ff0,DISK], DatanodeInfoWithStorage[127.0.0.1:40788,DS-d0bd13cb-bc58-4379-9d01-5a98f7b3077c,DISK], DatanodeInfoWithStorage[127.0.0.1:38518,DS-4f299ae1-56e7-47bd-9b27-db1a2f232a00,DISK], DatanodeInfoWithStorage[127.0.0.1:38982,DS-0da69f60-e3a9-443e-8810-8ab4a87917b4,DISK], DatanodeInfoWithStorage[127.0.0.1:38207,DS-12486447-4ebf-43a2-8b6c-4093f424a26f,DISK], DatanodeInfoWithStorage[127.0.0.1:33142,DS-55a5590f-af0b-4ab9-b106-870d94f02170,DISK], DatanodeInfoWithStorage[127.0.0.1:44917,DS-63e4193a-8e24-46e5-b5ad-de36df1ce61d,DISK], DatanodeInfoWithStorage[127.0.0.1:38400,DS-5a0e13af-1df9-49bb-8e9a-428162bd09d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1906670409-172.17.0.2-1598150013753:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33554,DS-8ca21a56-0de6-4adb-81e8-54a935ef7ff0,DISK], DatanodeInfoWithStorage[127.0.0.1:40788,DS-d0bd13cb-bc58-4379-9d01-5a98f7b3077c,DISK], DatanodeInfoWithStorage[127.0.0.1:38518,DS-4f299ae1-56e7-47bd-9b27-db1a2f232a00,DISK], DatanodeInfoWithStorage[127.0.0.1:38982,DS-0da69f60-e3a9-443e-8810-8ab4a87917b4,DISK], DatanodeInfoWithStorage[127.0.0.1:38207,DS-12486447-4ebf-43a2-8b6c-4093f424a26f,DISK], DatanodeInfoWithStorage[127.0.0.1:33142,DS-55a5590f-af0b-4ab9-b106-870d94f02170,DISK], DatanodeInfoWithStorage[127.0.0.1:44917,DS-63e4193a-8e24-46e5-b5ad-de36df1ce61d,DISK], DatanodeInfoWithStorage[127.0.0.1:38400,DS-5a0e13af-1df9-49bb-8e9a-428162bd09d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 5163
