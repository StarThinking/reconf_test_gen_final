reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-594045936-172.17.0.15-1598197703055:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38092,DS-c625a9e6-f8bf-4b74-b530-9639ff1e48e0,DISK], DatanodeInfoWithStorage[127.0.0.1:36464,DS-fa14342e-89c6-40b6-a3df-1a96d5eb14c2,DISK], DatanodeInfoWithStorage[127.0.0.1:38776,DS-1cef8d46-fe62-48de-9301-45bde76aaac3,DISK], DatanodeInfoWithStorage[127.0.0.1:43676,DS-867b5df0-4f53-466a-80d5-e10d67537865,DISK], DatanodeInfoWithStorage[127.0.0.1:33355,DS-1e9e5d73-ef85-4df8-a71d-aeac9bbe22e9,DISK], DatanodeInfoWithStorage[127.0.0.1:46549,DS-d840935d-be0f-458f-96db-f67d6af71d29,DISK], DatanodeInfoWithStorage[127.0.0.1:40040,DS-9cb47d30-9afd-4b02-9b63-5670421faefd,DISK], DatanodeInfoWithStorage[127.0.0.1:46263,DS-2d51cd3c-73d5-498c-a1cf-b210ab9bdc44,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-594045936-172.17.0.15-1598197703055:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38092,DS-c625a9e6-f8bf-4b74-b530-9639ff1e48e0,DISK], DatanodeInfoWithStorage[127.0.0.1:36464,DS-fa14342e-89c6-40b6-a3df-1a96d5eb14c2,DISK], DatanodeInfoWithStorage[127.0.0.1:38776,DS-1cef8d46-fe62-48de-9301-45bde76aaac3,DISK], DatanodeInfoWithStorage[127.0.0.1:43676,DS-867b5df0-4f53-466a-80d5-e10d67537865,DISK], DatanodeInfoWithStorage[127.0.0.1:33355,DS-1e9e5d73-ef85-4df8-a71d-aeac9bbe22e9,DISK], DatanodeInfoWithStorage[127.0.0.1:46549,DS-d840935d-be0f-458f-96db-f67d6af71d29,DISK], DatanodeInfoWithStorage[127.0.0.1:40040,DS-9cb47d30-9afd-4b02-9b63-5670421faefd,DISK], DatanodeInfoWithStorage[127.0.0.1:46263,DS-2d51cd3c-73d5-498c-a1cf-b210ab9bdc44,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1985440129-172.17.0.15-1598197751544:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38472,DS-2b1514e2-9451-4832-81cd-7e25ab077f1c,DISK], DatanodeInfoWithStorage[127.0.0.1:42769,DS-7818a599-25d2-463e-9e34-24c8c0c8bbad,DISK], DatanodeInfoWithStorage[127.0.0.1:33982,DS-78ff2f62-04de-44b2-b154-e785aa0b6202,DISK], DatanodeInfoWithStorage[127.0.0.1:37662,DS-e5986fb6-18b1-47fb-bc5b-1d095adde377,DISK], DatanodeInfoWithStorage[127.0.0.1:36276,DS-10cdf339-235c-469f-8e4d-6bfa9fca741c,DISK], DatanodeInfoWithStorage[127.0.0.1:38050,DS-d3a0376d-c870-47a4-b110-706c92dd6529,DISK], DatanodeInfoWithStorage[127.0.0.1:38567,DS-1919725d-627d-447a-8178-129d7625d5ed,DISK], DatanodeInfoWithStorage[127.0.0.1:37599,DS-efd1d5d7-8bec-41ee-8ab6-7285e47c4efb,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1985440129-172.17.0.15-1598197751544:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38472,DS-2b1514e2-9451-4832-81cd-7e25ab077f1c,DISK], DatanodeInfoWithStorage[127.0.0.1:42769,DS-7818a599-25d2-463e-9e34-24c8c0c8bbad,DISK], DatanodeInfoWithStorage[127.0.0.1:33982,DS-78ff2f62-04de-44b2-b154-e785aa0b6202,DISK], DatanodeInfoWithStorage[127.0.0.1:37662,DS-e5986fb6-18b1-47fb-bc5b-1d095adde377,DISK], DatanodeInfoWithStorage[127.0.0.1:36276,DS-10cdf339-235c-469f-8e4d-6bfa9fca741c,DISK], DatanodeInfoWithStorage[127.0.0.1:38050,DS-d3a0376d-c870-47a4-b110-706c92dd6529,DISK], DatanodeInfoWithStorage[127.0.0.1:38567,DS-1919725d-627d-447a-8178-129d7625d5ed,DISK], DatanodeInfoWithStorage[127.0.0.1:37599,DS-efd1d5d7-8bec-41ee-8ab6-7285e47c4efb,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1561082700-172.17.0.15-1598197896937:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35247,DS-f55da034-61df-4e5e-b9b7-54c764abf9ca,DISK], DatanodeInfoWithStorage[127.0.0.1:34004,DS-d91e4ae3-ebd6-47d8-8372-acd608896618,DISK], DatanodeInfoWithStorage[127.0.0.1:43956,DS-701a1cde-5e37-4e63-86a2-3f4a1606d0ab,DISK], DatanodeInfoWithStorage[127.0.0.1:45937,DS-61c5c57e-b9b8-4bb4-ae41-3a5e26a8ad34,DISK], DatanodeInfoWithStorage[127.0.0.1:42267,DS-585963a2-ad50-4be4-b5cf-bb264960e9ef,DISK], DatanodeInfoWithStorage[127.0.0.1:45902,DS-d00531aa-1671-4a6a-befc-6270dd10d1d4,DISK], DatanodeInfoWithStorage[127.0.0.1:35475,DS-16952ccf-c91a-487e-b9f7-6d3a5101b8c5,DISK], DatanodeInfoWithStorage[127.0.0.1:39109,DS-2a4ace3f-270e-49ee-8135-c56e0fe87051,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1561082700-172.17.0.15-1598197896937:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35247,DS-f55da034-61df-4e5e-b9b7-54c764abf9ca,DISK], DatanodeInfoWithStorage[127.0.0.1:34004,DS-d91e4ae3-ebd6-47d8-8372-acd608896618,DISK], DatanodeInfoWithStorage[127.0.0.1:43956,DS-701a1cde-5e37-4e63-86a2-3f4a1606d0ab,DISK], DatanodeInfoWithStorage[127.0.0.1:45937,DS-61c5c57e-b9b8-4bb4-ae41-3a5e26a8ad34,DISK], DatanodeInfoWithStorage[127.0.0.1:42267,DS-585963a2-ad50-4be4-b5cf-bb264960e9ef,DISK], DatanodeInfoWithStorage[127.0.0.1:45902,DS-d00531aa-1671-4a6a-befc-6270dd10d1d4,DISK], DatanodeInfoWithStorage[127.0.0.1:35475,DS-16952ccf-c91a-487e-b9f7-6d3a5101b8c5,DISK], DatanodeInfoWithStorage[127.0.0.1:39109,DS-2a4ace3f-270e-49ee-8135-c56e0fe87051,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-943078670-172.17.0.15-1598198011721:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35774,DS-9029268e-f0e3-48c3-bd88-8c259f9386cf,DISK], DatanodeInfoWithStorage[127.0.0.1:33141,DS-e275c403-ee09-4503-9a09-8e5ad86439c6,DISK], DatanodeInfoWithStorage[127.0.0.1:36393,DS-84abd28b-fe5e-46d2-8cdc-4d052e84a0d8,DISK], DatanodeInfoWithStorage[127.0.0.1:42551,DS-94ee7a81-d365-4401-9ea6-81e5343c47e2,DISK], DatanodeInfoWithStorage[127.0.0.1:35993,DS-c15972d4-9394-47b8-8a88-a03f37a81db1,DISK], DatanodeInfoWithStorage[127.0.0.1:33286,DS-7e71837d-d110-4402-8348-ab962051b839,DISK], DatanodeInfoWithStorage[127.0.0.1:42868,DS-13d87fda-866f-4fa9-9820-40d74f6020f4,DISK], DatanodeInfoWithStorage[127.0.0.1:46775,DS-eef59ecf-ab91-44a8-9ded-3a10fb4f4b34,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-943078670-172.17.0.15-1598198011721:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35774,DS-9029268e-f0e3-48c3-bd88-8c259f9386cf,DISK], DatanodeInfoWithStorage[127.0.0.1:33141,DS-e275c403-ee09-4503-9a09-8e5ad86439c6,DISK], DatanodeInfoWithStorage[127.0.0.1:36393,DS-84abd28b-fe5e-46d2-8cdc-4d052e84a0d8,DISK], DatanodeInfoWithStorage[127.0.0.1:42551,DS-94ee7a81-d365-4401-9ea6-81e5343c47e2,DISK], DatanodeInfoWithStorage[127.0.0.1:35993,DS-c15972d4-9394-47b8-8a88-a03f37a81db1,DISK], DatanodeInfoWithStorage[127.0.0.1:33286,DS-7e71837d-d110-4402-8348-ab962051b839,DISK], DatanodeInfoWithStorage[127.0.0.1:42868,DS-13d87fda-866f-4fa9-9820-40d74f6020f4,DISK], DatanodeInfoWithStorage[127.0.0.1:46775,DS-eef59ecf-ab91-44a8-9ded-3a10fb4f4b34,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1396755204-172.17.0.15-1598198044043:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41599,DS-c08779e0-e907-420d-bfca-f2e11301393e,DISK], DatanodeInfoWithStorage[127.0.0.1:36743,DS-ce1d3776-2244-417e-9abe-aa0ec6064fae,DISK], DatanodeInfoWithStorage[127.0.0.1:41045,DS-56f78ea8-1782-4329-9aac-6a115923b646,DISK], DatanodeInfoWithStorage[127.0.0.1:44250,DS-8102d17c-f953-4b51-bbc0-7c7713de0626,DISK], DatanodeInfoWithStorage[127.0.0.1:37314,DS-3ae9c275-b9dd-4c36-b9c8-ac31dc1e0c9d,DISK], DatanodeInfoWithStorage[127.0.0.1:33058,DS-c554efae-f53b-491e-aec7-661cd3e82c01,DISK], DatanodeInfoWithStorage[127.0.0.1:34213,DS-76843383-44bd-4d29-90bf-cfa41dfb35f3,DISK], DatanodeInfoWithStorage[127.0.0.1:34469,DS-0dd46dd0-3a06-43d1-972a-9160c1fc8ded,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1396755204-172.17.0.15-1598198044043:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41599,DS-c08779e0-e907-420d-bfca-f2e11301393e,DISK], DatanodeInfoWithStorage[127.0.0.1:36743,DS-ce1d3776-2244-417e-9abe-aa0ec6064fae,DISK], DatanodeInfoWithStorage[127.0.0.1:41045,DS-56f78ea8-1782-4329-9aac-6a115923b646,DISK], DatanodeInfoWithStorage[127.0.0.1:44250,DS-8102d17c-f953-4b51-bbc0-7c7713de0626,DISK], DatanodeInfoWithStorage[127.0.0.1:37314,DS-3ae9c275-b9dd-4c36-b9c8-ac31dc1e0c9d,DISK], DatanodeInfoWithStorage[127.0.0.1:33058,DS-c554efae-f53b-491e-aec7-661cd3e82c01,DISK], DatanodeInfoWithStorage[127.0.0.1:34213,DS-76843383-44bd-4d29-90bf-cfa41dfb35f3,DISK], DatanodeInfoWithStorage[127.0.0.1:34469,DS-0dd46dd0-3a06-43d1-972a-9160c1fc8ded,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-733457650-172.17.0.15-1598198107558:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38616,DS-524679e7-822b-4fe6-9f1d-469420b6508b,DISK], DatanodeInfoWithStorage[127.0.0.1:46225,DS-09431816-bf1b-49c1-919f-3dce93a99b35,DISK], DatanodeInfoWithStorage[127.0.0.1:39147,DS-6af18ae9-3da4-4da0-9e0e-79854bd85cbb,DISK], DatanodeInfoWithStorage[127.0.0.1:38726,DS-9588f3d0-577f-4054-9b1b-ef4895183c24,DISK], DatanodeInfoWithStorage[127.0.0.1:43957,DS-2b32c2e4-2073-4486-beee-3a863a5791d5,DISK], DatanodeInfoWithStorage[127.0.0.1:36774,DS-b271c5cd-3ed0-4295-831f-449f936e29bb,DISK], DatanodeInfoWithStorage[127.0.0.1:41309,DS-26fc4b8c-00c7-409b-b899-5f105d5bd911,DISK], DatanodeInfoWithStorage[127.0.0.1:43404,DS-f9b8dee5-63df-42e5-b95a-b975a916da6b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-733457650-172.17.0.15-1598198107558:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38616,DS-524679e7-822b-4fe6-9f1d-469420b6508b,DISK], DatanodeInfoWithStorage[127.0.0.1:46225,DS-09431816-bf1b-49c1-919f-3dce93a99b35,DISK], DatanodeInfoWithStorage[127.0.0.1:39147,DS-6af18ae9-3da4-4da0-9e0e-79854bd85cbb,DISK], DatanodeInfoWithStorage[127.0.0.1:38726,DS-9588f3d0-577f-4054-9b1b-ef4895183c24,DISK], DatanodeInfoWithStorage[127.0.0.1:43957,DS-2b32c2e4-2073-4486-beee-3a863a5791d5,DISK], DatanodeInfoWithStorage[127.0.0.1:36774,DS-b271c5cd-3ed0-4295-831f-449f936e29bb,DISK], DatanodeInfoWithStorage[127.0.0.1:41309,DS-26fc4b8c-00c7-409b-b899-5f105d5bd911,DISK], DatanodeInfoWithStorage[127.0.0.1:43404,DS-f9b8dee5-63df-42e5-b95a-b975a916da6b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1739933337-172.17.0.15-1598198123983:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43902,DS-7e925ff4-9250-4fbf-b8ba-7dfea97c5b28,DISK], DatanodeInfoWithStorage[127.0.0.1:37347,DS-8e80732e-01a6-4dee-a3bc-1c5db05e3579,DISK], DatanodeInfoWithStorage[127.0.0.1:34345,DS-052d88b8-3ff4-40dd-9e48-317d31434fa5,DISK], DatanodeInfoWithStorage[127.0.0.1:45891,DS-72762983-1a7e-4def-a7d8-8428f7a51f2e,DISK], DatanodeInfoWithStorage[127.0.0.1:45245,DS-77ad851f-59e1-4001-9426-392fe4bb1a0c,DISK], DatanodeInfoWithStorage[127.0.0.1:46011,DS-878ad011-f751-49bf-bf07-3ce0a76b87dd,DISK], DatanodeInfoWithStorage[127.0.0.1:40982,DS-060565d5-6744-4630-a52a-18c409daa6d1,DISK], DatanodeInfoWithStorage[127.0.0.1:35903,DS-5c4d5af2-6872-4b5e-8a9d-7b29344be48c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1739933337-172.17.0.15-1598198123983:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43902,DS-7e925ff4-9250-4fbf-b8ba-7dfea97c5b28,DISK], DatanodeInfoWithStorage[127.0.0.1:37347,DS-8e80732e-01a6-4dee-a3bc-1c5db05e3579,DISK], DatanodeInfoWithStorage[127.0.0.1:34345,DS-052d88b8-3ff4-40dd-9e48-317d31434fa5,DISK], DatanodeInfoWithStorage[127.0.0.1:45891,DS-72762983-1a7e-4def-a7d8-8428f7a51f2e,DISK], DatanodeInfoWithStorage[127.0.0.1:45245,DS-77ad851f-59e1-4001-9426-392fe4bb1a0c,DISK], DatanodeInfoWithStorage[127.0.0.1:46011,DS-878ad011-f751-49bf-bf07-3ce0a76b87dd,DISK], DatanodeInfoWithStorage[127.0.0.1:40982,DS-060565d5-6744-4630-a52a-18c409daa6d1,DISK], DatanodeInfoWithStorage[127.0.0.1:35903,DS-5c4d5af2-6872-4b5e-8a9d-7b29344be48c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1886230531-172.17.0.15-1598198556860:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42752,DS-3db08d4e-212b-4d8b-9fee-7ab67983a076,DISK], DatanodeInfoWithStorage[127.0.0.1:35251,DS-3ca8e276-2e2f-4598-b50d-73c57c3e0f2d,DISK], DatanodeInfoWithStorage[127.0.0.1:36213,DS-3721b235-4783-4c2a-ba1b-66cf0d1d7090,DISK], DatanodeInfoWithStorage[127.0.0.1:32876,DS-2ad5cc62-23bd-4cca-8565-f0df544f5451,DISK], DatanodeInfoWithStorage[127.0.0.1:39606,DS-4eae0194-436a-4ad1-9b5a-c619da3f9859,DISK], DatanodeInfoWithStorage[127.0.0.1:42537,DS-d0bc32ba-972d-4da5-8706-a9ccff30294c,DISK], DatanodeInfoWithStorage[127.0.0.1:46341,DS-b4e7101b-b83d-4bdb-99dc-8d215803a4ec,DISK], DatanodeInfoWithStorage[127.0.0.1:36803,DS-929e4b1b-104e-4ecb-99eb-e428ef25a299,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1886230531-172.17.0.15-1598198556860:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42752,DS-3db08d4e-212b-4d8b-9fee-7ab67983a076,DISK], DatanodeInfoWithStorage[127.0.0.1:35251,DS-3ca8e276-2e2f-4598-b50d-73c57c3e0f2d,DISK], DatanodeInfoWithStorage[127.0.0.1:36213,DS-3721b235-4783-4c2a-ba1b-66cf0d1d7090,DISK], DatanodeInfoWithStorage[127.0.0.1:32876,DS-2ad5cc62-23bd-4cca-8565-f0df544f5451,DISK], DatanodeInfoWithStorage[127.0.0.1:39606,DS-4eae0194-436a-4ad1-9b5a-c619da3f9859,DISK], DatanodeInfoWithStorage[127.0.0.1:42537,DS-d0bc32ba-972d-4da5-8706-a9ccff30294c,DISK], DatanodeInfoWithStorage[127.0.0.1:46341,DS-b4e7101b-b83d-4bdb-99dc-8d215803a4ec,DISK], DatanodeInfoWithStorage[127.0.0.1:36803,DS-929e4b1b-104e-4ecb-99eb-e428ef25a299,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1865125011-172.17.0.15-1598198605463:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42191,DS-79afa4bf-8b20-4971-a13c-315040d571d6,DISK], DatanodeInfoWithStorage[127.0.0.1:46784,DS-f3807ab4-4ddf-4193-897c-c1b4fdbc217f,DISK], DatanodeInfoWithStorage[127.0.0.1:41869,DS-7ed15820-a8a1-47cb-b44c-c91a4f22d905,DISK], DatanodeInfoWithStorage[127.0.0.1:45945,DS-f239331e-4498-4a94-b214-bc7b2bd1b960,DISK], DatanodeInfoWithStorage[127.0.0.1:34086,DS-f6ceb264-7471-4534-bbdb-1d50cc62b5d5,DISK], DatanodeInfoWithStorage[127.0.0.1:38439,DS-85044bbb-853b-4e44-8c81-6cd5f35e63e2,DISK], DatanodeInfoWithStorage[127.0.0.1:45099,DS-c830dd06-3efe-4f67-9652-363032364dcd,DISK], DatanodeInfoWithStorage[127.0.0.1:35894,DS-d93be3ac-513b-456c-a0b8-7eca09e8d132,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1865125011-172.17.0.15-1598198605463:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42191,DS-79afa4bf-8b20-4971-a13c-315040d571d6,DISK], DatanodeInfoWithStorage[127.0.0.1:46784,DS-f3807ab4-4ddf-4193-897c-c1b4fdbc217f,DISK], DatanodeInfoWithStorage[127.0.0.1:41869,DS-7ed15820-a8a1-47cb-b44c-c91a4f22d905,DISK], DatanodeInfoWithStorage[127.0.0.1:45945,DS-f239331e-4498-4a94-b214-bc7b2bd1b960,DISK], DatanodeInfoWithStorage[127.0.0.1:34086,DS-f6ceb264-7471-4534-bbdb-1d50cc62b5d5,DISK], DatanodeInfoWithStorage[127.0.0.1:38439,DS-85044bbb-853b-4e44-8c81-6cd5f35e63e2,DISK], DatanodeInfoWithStorage[127.0.0.1:45099,DS-c830dd06-3efe-4f67-9652-363032364dcd,DISK], DatanodeInfoWithStorage[127.0.0.1:35894,DS-d93be3ac-513b-456c-a0b8-7eca09e8d132,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-477340775-172.17.0.15-1598198685461:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41004,DS-7a3fbe39-f5da-44b1-b8b9-81af3aaba481,DISK], DatanodeInfoWithStorage[127.0.0.1:40599,DS-83ddb70b-75b8-46fd-b42b-0ae4c54a5347,DISK], DatanodeInfoWithStorage[127.0.0.1:40228,DS-2c58c7b1-693c-4baa-94ae-ce27914111fd,DISK], DatanodeInfoWithStorage[127.0.0.1:40467,DS-0be2a392-0af5-46f2-be3f-04974828e6c9,DISK], DatanodeInfoWithStorage[127.0.0.1:43481,DS-4fd077e7-fbb4-450b-b5a4-860b99794704,DISK], DatanodeInfoWithStorage[127.0.0.1:34653,DS-f8c4cb75-db83-4276-9a9b-aa7d6a4e60bf,DISK], DatanodeInfoWithStorage[127.0.0.1:33734,DS-05317b51-6287-49de-86f0-d642db9622c5,DISK], DatanodeInfoWithStorage[127.0.0.1:38826,DS-c307a29b-25f9-49ba-8f32-8f352ad1dc40,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-477340775-172.17.0.15-1598198685461:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41004,DS-7a3fbe39-f5da-44b1-b8b9-81af3aaba481,DISK], DatanodeInfoWithStorage[127.0.0.1:40599,DS-83ddb70b-75b8-46fd-b42b-0ae4c54a5347,DISK], DatanodeInfoWithStorage[127.0.0.1:40228,DS-2c58c7b1-693c-4baa-94ae-ce27914111fd,DISK], DatanodeInfoWithStorage[127.0.0.1:40467,DS-0be2a392-0af5-46f2-be3f-04974828e6c9,DISK], DatanodeInfoWithStorage[127.0.0.1:43481,DS-4fd077e7-fbb4-450b-b5a4-860b99794704,DISK], DatanodeInfoWithStorage[127.0.0.1:34653,DS-f8c4cb75-db83-4276-9a9b-aa7d6a4e60bf,DISK], DatanodeInfoWithStorage[127.0.0.1:33734,DS-05317b51-6287-49de-86f0-d642db9622c5,DISK], DatanodeInfoWithStorage[127.0.0.1:38826,DS-c307a29b-25f9-49ba-8f32-8f352ad1dc40,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1020019282-172.17.0.15-1598198717523:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37527,DS-893a1fc1-021c-4794-8343-36c293c4d4ff,DISK], DatanodeInfoWithStorage[127.0.0.1:39888,DS-a98eb4e5-4df7-4488-8a7f-f0ecf8d61aac,DISK], DatanodeInfoWithStorage[127.0.0.1:37106,DS-71c9375c-1ed7-4ccb-b789-a61792c97b3b,DISK], DatanodeInfoWithStorage[127.0.0.1:38122,DS-38e27f9f-0389-4b62-9023-4d5404b13e36,DISK], DatanodeInfoWithStorage[127.0.0.1:41319,DS-d146c893-a019-4459-b8a2-5065c2020792,DISK], DatanodeInfoWithStorage[127.0.0.1:36718,DS-39aa5b2c-1643-42cb-92f6-1293303b6da4,DISK], DatanodeInfoWithStorage[127.0.0.1:46837,DS-8f97ce33-96ad-41c8-ade5-ca6ef61a2e63,DISK], DatanodeInfoWithStorage[127.0.0.1:44715,DS-2677bdd4-8f2d-4cb2-b2e1-5cfd758a2594,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1020019282-172.17.0.15-1598198717523:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37527,DS-893a1fc1-021c-4794-8343-36c293c4d4ff,DISK], DatanodeInfoWithStorage[127.0.0.1:39888,DS-a98eb4e5-4df7-4488-8a7f-f0ecf8d61aac,DISK], DatanodeInfoWithStorage[127.0.0.1:37106,DS-71c9375c-1ed7-4ccb-b789-a61792c97b3b,DISK], DatanodeInfoWithStorage[127.0.0.1:38122,DS-38e27f9f-0389-4b62-9023-4d5404b13e36,DISK], DatanodeInfoWithStorage[127.0.0.1:41319,DS-d146c893-a019-4459-b8a2-5065c2020792,DISK], DatanodeInfoWithStorage[127.0.0.1:36718,DS-39aa5b2c-1643-42cb-92f6-1293303b6da4,DISK], DatanodeInfoWithStorage[127.0.0.1:46837,DS-8f97ce33-96ad-41c8-ade5-ca6ef61a2e63,DISK], DatanodeInfoWithStorage[127.0.0.1:44715,DS-2677bdd4-8f2d-4cb2-b2e1-5cfd758a2594,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-997967225-172.17.0.15-1598198749124:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45416,DS-350fb071-3bab-43ca-a005-38d77849456b,DISK], DatanodeInfoWithStorage[127.0.0.1:36181,DS-4e09ea34-b19f-427e-b822-0c68ceeef0cf,DISK], DatanodeInfoWithStorage[127.0.0.1:40746,DS-889513b1-4206-4005-9fbf-068eb12439e0,DISK], DatanodeInfoWithStorage[127.0.0.1:35562,DS-8ee1a89a-a61f-45c7-8c5a-63659985b03f,DISK], DatanodeInfoWithStorage[127.0.0.1:34863,DS-2756534b-8d05-44d3-97a4-a0e48f610dbe,DISK], DatanodeInfoWithStorage[127.0.0.1:36329,DS-3d184fe3-a6cf-4534-8a3c-d4bd776ea82c,DISK], DatanodeInfoWithStorage[127.0.0.1:42138,DS-5e4dcd5b-cd60-4711-b2e7-b73fb00d931f,DISK], DatanodeInfoWithStorage[127.0.0.1:39999,DS-2f0977f5-9025-4b63-8303-1d3dd1248558,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-997967225-172.17.0.15-1598198749124:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45416,DS-350fb071-3bab-43ca-a005-38d77849456b,DISK], DatanodeInfoWithStorage[127.0.0.1:36181,DS-4e09ea34-b19f-427e-b822-0c68ceeef0cf,DISK], DatanodeInfoWithStorage[127.0.0.1:40746,DS-889513b1-4206-4005-9fbf-068eb12439e0,DISK], DatanodeInfoWithStorage[127.0.0.1:35562,DS-8ee1a89a-a61f-45c7-8c5a-63659985b03f,DISK], DatanodeInfoWithStorage[127.0.0.1:34863,DS-2756534b-8d05-44d3-97a4-a0e48f610dbe,DISK], DatanodeInfoWithStorage[127.0.0.1:36329,DS-3d184fe3-a6cf-4534-8a3c-d4bd776ea82c,DISK], DatanodeInfoWithStorage[127.0.0.1:42138,DS-5e4dcd5b-cd60-4711-b2e7-b73fb00d931f,DISK], DatanodeInfoWithStorage[127.0.0.1:39999,DS-2f0977f5-9025-4b63-8303-1d3dd1248558,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-533622340-172.17.0.15-1598198860833:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38801,DS-d224a13c-cbb2-4293-b0c6-3b8371df807b,DISK], DatanodeInfoWithStorage[127.0.0.1:33628,DS-b4963a92-5d8e-4ff0-8705-aac2b3bbb5ab,DISK], DatanodeInfoWithStorage[127.0.0.1:37575,DS-c339b7e7-b2ba-4cba-b43f-44637412e3de,DISK], DatanodeInfoWithStorage[127.0.0.1:44617,DS-bbe13831-08c9-4ae8-bdef-9f3c92a495cc,DISK], DatanodeInfoWithStorage[127.0.0.1:43533,DS-19c24d66-133e-43a1-bdfd-9d193f0bebd2,DISK], DatanodeInfoWithStorage[127.0.0.1:44604,DS-9d2f3972-a3ab-4b7e-b72c-ec0c415120e6,DISK], DatanodeInfoWithStorage[127.0.0.1:41117,DS-870d5280-cdfc-466a-8ffa-e068d6dbdb17,DISK], DatanodeInfoWithStorage[127.0.0.1:38128,DS-98cc7680-6172-4bad-8456-2c59dce4a7a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-533622340-172.17.0.15-1598198860833:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38801,DS-d224a13c-cbb2-4293-b0c6-3b8371df807b,DISK], DatanodeInfoWithStorage[127.0.0.1:33628,DS-b4963a92-5d8e-4ff0-8705-aac2b3bbb5ab,DISK], DatanodeInfoWithStorage[127.0.0.1:37575,DS-c339b7e7-b2ba-4cba-b43f-44637412e3de,DISK], DatanodeInfoWithStorage[127.0.0.1:44617,DS-bbe13831-08c9-4ae8-bdef-9f3c92a495cc,DISK], DatanodeInfoWithStorage[127.0.0.1:43533,DS-19c24d66-133e-43a1-bdfd-9d193f0bebd2,DISK], DatanodeInfoWithStorage[127.0.0.1:44604,DS-9d2f3972-a3ab-4b7e-b72c-ec0c415120e6,DISK], DatanodeInfoWithStorage[127.0.0.1:41117,DS-870d5280-cdfc-466a-8ffa-e068d6dbdb17,DISK], DatanodeInfoWithStorage[127.0.0.1:38128,DS-98cc7680-6172-4bad-8456-2c59dce4a7a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-230621416-172.17.0.15-1598198876749:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42464,DS-84edf134-5956-476c-8a07-f739e093bc4c,DISK], DatanodeInfoWithStorage[127.0.0.1:37314,DS-fe46a1be-ae43-419d-b968-e2e970a8b4e4,DISK], DatanodeInfoWithStorage[127.0.0.1:33866,DS-b4be5758-70fc-45f5-9dd1-e621dec913ab,DISK], DatanodeInfoWithStorage[127.0.0.1:33635,DS-fe01e694-ee03-421d-a677-0ba2f5ee044d,DISK], DatanodeInfoWithStorage[127.0.0.1:44139,DS-e07f47be-cfa8-48f6-969a-7e56df3fe1a8,DISK], DatanodeInfoWithStorage[127.0.0.1:42863,DS-d9c456be-349a-4420-aef7-214857497388,DISK], DatanodeInfoWithStorage[127.0.0.1:33810,DS-5b16e5ef-a86a-40d9-b8de-ef60865e34d1,DISK], DatanodeInfoWithStorage[127.0.0.1:34116,DS-f4e93686-a2bc-41ab-b480-4216ab85c843,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-230621416-172.17.0.15-1598198876749:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42464,DS-84edf134-5956-476c-8a07-f739e093bc4c,DISK], DatanodeInfoWithStorage[127.0.0.1:37314,DS-fe46a1be-ae43-419d-b968-e2e970a8b4e4,DISK], DatanodeInfoWithStorage[127.0.0.1:33866,DS-b4be5758-70fc-45f5-9dd1-e621dec913ab,DISK], DatanodeInfoWithStorage[127.0.0.1:33635,DS-fe01e694-ee03-421d-a677-0ba2f5ee044d,DISK], DatanodeInfoWithStorage[127.0.0.1:44139,DS-e07f47be-cfa8-48f6-969a-7e56df3fe1a8,DISK], DatanodeInfoWithStorage[127.0.0.1:42863,DS-d9c456be-349a-4420-aef7-214857497388,DISK], DatanodeInfoWithStorage[127.0.0.1:33810,DS-5b16e5ef-a86a-40d9-b8de-ef60865e34d1,DISK], DatanodeInfoWithStorage[127.0.0.1:34116,DS-f4e93686-a2bc-41ab-b480-4216ab85c843,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-265326561-172.17.0.15-1598198972034:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39085,DS-30186e3e-c2b7-487d-867c-9e864b3f2dfc,DISK], DatanodeInfoWithStorage[127.0.0.1:42363,DS-4d2fd3fb-016c-4c5c-8682-7595082f8487,DISK], DatanodeInfoWithStorage[127.0.0.1:43298,DS-3efa7367-87fc-4d3c-bafd-1b3477773b5c,DISK], DatanodeInfoWithStorage[127.0.0.1:43993,DS-a3544a4d-15a3-42b5-9b0c-2da008638b53,DISK], DatanodeInfoWithStorage[127.0.0.1:33186,DS-d091217b-84cf-47e3-867d-a0491a3be69b,DISK], DatanodeInfoWithStorage[127.0.0.1:33396,DS-a3f7254c-f52c-465d-a5b3-09d454758230,DISK], DatanodeInfoWithStorage[127.0.0.1:36875,DS-832b5f34-6b6d-48b7-bc50-403967d8365b,DISK], DatanodeInfoWithStorage[127.0.0.1:45619,DS-fea5f0a4-585c-4935-9910-a30e25410d8a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-265326561-172.17.0.15-1598198972034:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39085,DS-30186e3e-c2b7-487d-867c-9e864b3f2dfc,DISK], DatanodeInfoWithStorage[127.0.0.1:42363,DS-4d2fd3fb-016c-4c5c-8682-7595082f8487,DISK], DatanodeInfoWithStorage[127.0.0.1:43298,DS-3efa7367-87fc-4d3c-bafd-1b3477773b5c,DISK], DatanodeInfoWithStorage[127.0.0.1:43993,DS-a3544a4d-15a3-42b5-9b0c-2da008638b53,DISK], DatanodeInfoWithStorage[127.0.0.1:33186,DS-d091217b-84cf-47e3-867d-a0491a3be69b,DISK], DatanodeInfoWithStorage[127.0.0.1:33396,DS-a3f7254c-f52c-465d-a5b3-09d454758230,DISK], DatanodeInfoWithStorage[127.0.0.1:36875,DS-832b5f34-6b6d-48b7-bc50-403967d8365b,DISK], DatanodeInfoWithStorage[127.0.0.1:45619,DS-fea5f0a4-585c-4935-9910-a30e25410d8a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1255952147-172.17.0.15-1598199003610:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33450,DS-9fe38f1e-7a59-41cf-8b5c-456ae8795fb5,DISK], DatanodeInfoWithStorage[127.0.0.1:45234,DS-d1212155-885e-475a-9d21-f7a725cb2282,DISK], DatanodeInfoWithStorage[127.0.0.1:39710,DS-b2201335-b528-499c-90e1-08e15432fb0c,DISK], DatanodeInfoWithStorage[127.0.0.1:39405,DS-a7728ba6-6a7a-4343-86ea-70089d31b3aa,DISK], DatanodeInfoWithStorage[127.0.0.1:33884,DS-56b34e6e-1749-4578-b5c0-666c7a05508f,DISK], DatanodeInfoWithStorage[127.0.0.1:41451,DS-a429650a-5f00-4635-bd5f-22ab6713dd0a,DISK], DatanodeInfoWithStorage[127.0.0.1:43094,DS-688a42ce-6f54-4fc7-bb6a-c7a26cab9717,DISK], DatanodeInfoWithStorage[127.0.0.1:43806,DS-b8d85443-d40b-4caa-819c-926790d6b36e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1255952147-172.17.0.15-1598199003610:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33450,DS-9fe38f1e-7a59-41cf-8b5c-456ae8795fb5,DISK], DatanodeInfoWithStorage[127.0.0.1:45234,DS-d1212155-885e-475a-9d21-f7a725cb2282,DISK], DatanodeInfoWithStorage[127.0.0.1:39710,DS-b2201335-b528-499c-90e1-08e15432fb0c,DISK], DatanodeInfoWithStorage[127.0.0.1:39405,DS-a7728ba6-6a7a-4343-86ea-70089d31b3aa,DISK], DatanodeInfoWithStorage[127.0.0.1:33884,DS-56b34e6e-1749-4578-b5c0-666c7a05508f,DISK], DatanodeInfoWithStorage[127.0.0.1:41451,DS-a429650a-5f00-4635-bd5f-22ab6713dd0a,DISK], DatanodeInfoWithStorage[127.0.0.1:43094,DS-688a42ce-6f54-4fc7-bb6a-c7a26cab9717,DISK], DatanodeInfoWithStorage[127.0.0.1:43806,DS-b8d85443-d40b-4caa-819c-926790d6b36e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-864202453-172.17.0.15-1598199178251:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34450,DS-62614dcc-d790-4dca-967e-1736eacc6f74,DISK], DatanodeInfoWithStorage[127.0.0.1:38540,DS-3623a8c6-a868-4c66-a066-6a270c5aa078,DISK], DatanodeInfoWithStorage[127.0.0.1:44933,DS-e0dd3ea5-3b39-4197-bb0d-37ea607d8362,DISK], DatanodeInfoWithStorage[127.0.0.1:41333,DS-a80f78eb-d6a1-47a0-9542-ae243e2c05e6,DISK], DatanodeInfoWithStorage[127.0.0.1:43753,DS-6eff0d54-d338-477d-83b2-d9b034fd1723,DISK], DatanodeInfoWithStorage[127.0.0.1:41003,DS-7a29e2d5-32dd-48ed-ba6d-be309aa85010,DISK], DatanodeInfoWithStorage[127.0.0.1:38689,DS-1e554525-8811-499f-abd0-6aff1efbcb7d,DISK], DatanodeInfoWithStorage[127.0.0.1:33271,DS-99bb5aff-f52a-478c-ad37-416c7979d852,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-864202453-172.17.0.15-1598199178251:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34450,DS-62614dcc-d790-4dca-967e-1736eacc6f74,DISK], DatanodeInfoWithStorage[127.0.0.1:38540,DS-3623a8c6-a868-4c66-a066-6a270c5aa078,DISK], DatanodeInfoWithStorage[127.0.0.1:44933,DS-e0dd3ea5-3b39-4197-bb0d-37ea607d8362,DISK], DatanodeInfoWithStorage[127.0.0.1:41333,DS-a80f78eb-d6a1-47a0-9542-ae243e2c05e6,DISK], DatanodeInfoWithStorage[127.0.0.1:43753,DS-6eff0d54-d338-477d-83b2-d9b034fd1723,DISK], DatanodeInfoWithStorage[127.0.0.1:41003,DS-7a29e2d5-32dd-48ed-ba6d-be309aa85010,DISK], DatanodeInfoWithStorage[127.0.0.1:38689,DS-1e554525-8811-499f-abd0-6aff1efbcb7d,DISK], DatanodeInfoWithStorage[127.0.0.1:33271,DS-99bb5aff-f52a-478c-ad37-416c7979d852,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-291595041-172.17.0.15-1598199289124:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33619,DS-12037029-c1e9-4b17-b3dd-345cf3864ec6,DISK], DatanodeInfoWithStorage[127.0.0.1:45215,DS-80889a10-8dc9-434b-8283-39350899781d,DISK], DatanodeInfoWithStorage[127.0.0.1:41438,DS-c4ada42a-4f2c-40b0-90af-69ff8eaeae79,DISK], DatanodeInfoWithStorage[127.0.0.1:41363,DS-526494e8-f1f5-4511-bb10-5ecef24bfadd,DISK], DatanodeInfoWithStorage[127.0.0.1:44228,DS-1ad63df2-ace5-44f4-ae5a-58836c403d48,DISK], DatanodeInfoWithStorage[127.0.0.1:46344,DS-0b3b3f93-02e8-424b-9859-696f9c1531b8,DISK], DatanodeInfoWithStorage[127.0.0.1:37821,DS-5f20b016-9366-4414-a838-ee6a1da0dac1,DISK], DatanodeInfoWithStorage[127.0.0.1:41745,DS-39b087a2-ab20-4de0-b5eb-70974cd45082,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-291595041-172.17.0.15-1598199289124:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33619,DS-12037029-c1e9-4b17-b3dd-345cf3864ec6,DISK], DatanodeInfoWithStorage[127.0.0.1:45215,DS-80889a10-8dc9-434b-8283-39350899781d,DISK], DatanodeInfoWithStorage[127.0.0.1:41438,DS-c4ada42a-4f2c-40b0-90af-69ff8eaeae79,DISK], DatanodeInfoWithStorage[127.0.0.1:41363,DS-526494e8-f1f5-4511-bb10-5ecef24bfadd,DISK], DatanodeInfoWithStorage[127.0.0.1:44228,DS-1ad63df2-ace5-44f4-ae5a-58836c403d48,DISK], DatanodeInfoWithStorage[127.0.0.1:46344,DS-0b3b3f93-02e8-424b-9859-696f9c1531b8,DISK], DatanodeInfoWithStorage[127.0.0.1:37821,DS-5f20b016-9366-4414-a838-ee6a1da0dac1,DISK], DatanodeInfoWithStorage[127.0.0.1:41745,DS-39b087a2-ab20-4de0-b5eb-70974cd45082,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1878316049-172.17.0.15-1598199320868:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46671,DS-2476dec0-b2bd-40b9-ad75-0f0b24d286bf,DISK], DatanodeInfoWithStorage[127.0.0.1:42118,DS-33c9f9cc-9f6f-41fc-a597-3ed8db6c8691,DISK], DatanodeInfoWithStorage[127.0.0.1:34020,DS-93a5f099-d9f0-4acc-9ce7-518538983ab6,DISK], DatanodeInfoWithStorage[127.0.0.1:41864,DS-11566229-03b2-4798-9a91-ceb10b46681c,DISK], DatanodeInfoWithStorage[127.0.0.1:41413,DS-3bd65592-afe6-4b55-9bb5-a58cb137e0c7,DISK], DatanodeInfoWithStorage[127.0.0.1:36224,DS-3b9d723c-33f5-4475-af87-29e13a3bcb59,DISK], DatanodeInfoWithStorage[127.0.0.1:43042,DS-f7c23f5f-6429-4312-9a6b-7d68e7a86040,DISK], DatanodeInfoWithStorage[127.0.0.1:44468,DS-a82b0c41-afb2-4a7f-ae6c-e1555e7d1122,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1878316049-172.17.0.15-1598199320868:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46671,DS-2476dec0-b2bd-40b9-ad75-0f0b24d286bf,DISK], DatanodeInfoWithStorage[127.0.0.1:42118,DS-33c9f9cc-9f6f-41fc-a597-3ed8db6c8691,DISK], DatanodeInfoWithStorage[127.0.0.1:34020,DS-93a5f099-d9f0-4acc-9ce7-518538983ab6,DISK], DatanodeInfoWithStorage[127.0.0.1:41864,DS-11566229-03b2-4798-9a91-ceb10b46681c,DISK], DatanodeInfoWithStorage[127.0.0.1:41413,DS-3bd65592-afe6-4b55-9bb5-a58cb137e0c7,DISK], DatanodeInfoWithStorage[127.0.0.1:36224,DS-3b9d723c-33f5-4475-af87-29e13a3bcb59,DISK], DatanodeInfoWithStorage[127.0.0.1:43042,DS-f7c23f5f-6429-4312-9a6b-7d68e7a86040,DISK], DatanodeInfoWithStorage[127.0.0.1:44468,DS-a82b0c41-afb2-4a7f-ae6c-e1555e7d1122,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-947153291-172.17.0.15-1598199384607:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33714,DS-e9126e6f-997b-44ec-93e4-1a4a34966fa7,DISK], DatanodeInfoWithStorage[127.0.0.1:38013,DS-11315605-64cc-4d2c-bbf3-1dd026680748,DISK], DatanodeInfoWithStorage[127.0.0.1:44675,DS-7dda16cc-735e-4dbb-86b5-e31e4d8e649d,DISK], DatanodeInfoWithStorage[127.0.0.1:34636,DS-3ab45304-c089-4bc5-b2c0-40153b0699eb,DISK], DatanodeInfoWithStorage[127.0.0.1:39606,DS-f0abc2fe-0427-4e55-a582-a9c0458b6179,DISK], DatanodeInfoWithStorage[127.0.0.1:38781,DS-6afc89ea-b453-40c2-9eec-495080a703ab,DISK], DatanodeInfoWithStorage[127.0.0.1:46735,DS-c6e8b5af-201f-4bb6-8b97-2c17371cb647,DISK], DatanodeInfoWithStorage[127.0.0.1:37438,DS-bb2a05e3-a144-4114-8671-e96717366b91,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-947153291-172.17.0.15-1598199384607:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33714,DS-e9126e6f-997b-44ec-93e4-1a4a34966fa7,DISK], DatanodeInfoWithStorage[127.0.0.1:38013,DS-11315605-64cc-4d2c-bbf3-1dd026680748,DISK], DatanodeInfoWithStorage[127.0.0.1:44675,DS-7dda16cc-735e-4dbb-86b5-e31e4d8e649d,DISK], DatanodeInfoWithStorage[127.0.0.1:34636,DS-3ab45304-c089-4bc5-b2c0-40153b0699eb,DISK], DatanodeInfoWithStorage[127.0.0.1:39606,DS-f0abc2fe-0427-4e55-a582-a9c0458b6179,DISK], DatanodeInfoWithStorage[127.0.0.1:38781,DS-6afc89ea-b453-40c2-9eec-495080a703ab,DISK], DatanodeInfoWithStorage[127.0.0.1:46735,DS-c6e8b5af-201f-4bb6-8b97-2c17371cb647,DISK], DatanodeInfoWithStorage[127.0.0.1:37438,DS-bb2a05e3-a144-4114-8671-e96717366b91,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-167968070-172.17.0.15-1598199400645:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33531,DS-a325047d-0186-4984-8ec9-f92e683a76d4,DISK], DatanodeInfoWithStorage[127.0.0.1:33603,DS-2bd066c8-992a-45c6-af2d-3f3c9d13af7c,DISK], DatanodeInfoWithStorage[127.0.0.1:40575,DS-33821f96-9245-4ba5-8ea9-92d9cfb41975,DISK], DatanodeInfoWithStorage[127.0.0.1:39676,DS-94ce545e-76b9-4f02-9267-292008213ae4,DISK], DatanodeInfoWithStorage[127.0.0.1:36573,DS-4bf6631f-4708-4ff6-aa90-a78b30c9d7f1,DISK], DatanodeInfoWithStorage[127.0.0.1:46603,DS-a171f075-2b5c-46b9-8c42-661cf9f282db,DISK], DatanodeInfoWithStorage[127.0.0.1:39251,DS-632844e5-4fc6-45ae-9f48-81aef9b0b7a2,DISK], DatanodeInfoWithStorage[127.0.0.1:44679,DS-24df31a7-22c3-48ac-9bef-fcc5e3694f73,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-167968070-172.17.0.15-1598199400645:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33531,DS-a325047d-0186-4984-8ec9-f92e683a76d4,DISK], DatanodeInfoWithStorage[127.0.0.1:33603,DS-2bd066c8-992a-45c6-af2d-3f3c9d13af7c,DISK], DatanodeInfoWithStorage[127.0.0.1:40575,DS-33821f96-9245-4ba5-8ea9-92d9cfb41975,DISK], DatanodeInfoWithStorage[127.0.0.1:39676,DS-94ce545e-76b9-4f02-9267-292008213ae4,DISK], DatanodeInfoWithStorage[127.0.0.1:36573,DS-4bf6631f-4708-4ff6-aa90-a78b30c9d7f1,DISK], DatanodeInfoWithStorage[127.0.0.1:46603,DS-a171f075-2b5c-46b9-8c42-661cf9f282db,DISK], DatanodeInfoWithStorage[127.0.0.1:39251,DS-632844e5-4fc6-45ae-9f48-81aef9b0b7a2,DISK], DatanodeInfoWithStorage[127.0.0.1:44679,DS-24df31a7-22c3-48ac-9bef-fcc5e3694f73,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-981701617-172.17.0.15-1598199479341:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41468,DS-a9ad1d03-31a4-408e-9c35-99f09cf80c31,DISK], DatanodeInfoWithStorage[127.0.0.1:46177,DS-26004775-ccdf-4264-8758-928c2a50f60f,DISK], DatanodeInfoWithStorage[127.0.0.1:38699,DS-8467c8e0-f13d-4c1a-9498-75662ef8ef3c,DISK], DatanodeInfoWithStorage[127.0.0.1:38339,DS-053a00b3-12cb-4068-9b2e-c6c85d4a814b,DISK], DatanodeInfoWithStorage[127.0.0.1:46185,DS-6deb5d93-b173-4af2-9000-217595e1ddbb,DISK], DatanodeInfoWithStorage[127.0.0.1:40458,DS-46dbb058-4cad-4dd1-93f0-8aa6872bbed0,DISK], DatanodeInfoWithStorage[127.0.0.1:44608,DS-c2bf5cce-75c5-4ba4-9ac3-5d1f848f5ff8,DISK], DatanodeInfoWithStorage[127.0.0.1:42516,DS-fb5d00f3-1830-4664-9517-6b3fc954b551,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-981701617-172.17.0.15-1598199479341:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41468,DS-a9ad1d03-31a4-408e-9c35-99f09cf80c31,DISK], DatanodeInfoWithStorage[127.0.0.1:46177,DS-26004775-ccdf-4264-8758-928c2a50f60f,DISK], DatanodeInfoWithStorage[127.0.0.1:38699,DS-8467c8e0-f13d-4c1a-9498-75662ef8ef3c,DISK], DatanodeInfoWithStorage[127.0.0.1:38339,DS-053a00b3-12cb-4068-9b2e-c6c85d4a814b,DISK], DatanodeInfoWithStorage[127.0.0.1:46185,DS-6deb5d93-b173-4af2-9000-217595e1ddbb,DISK], DatanodeInfoWithStorage[127.0.0.1:40458,DS-46dbb058-4cad-4dd1-93f0-8aa6872bbed0,DISK], DatanodeInfoWithStorage[127.0.0.1:44608,DS-c2bf5cce-75c5-4ba4-9ac3-5d1f848f5ff8,DISK], DatanodeInfoWithStorage[127.0.0.1:42516,DS-fb5d00f3-1830-4664-9517-6b3fc954b551,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-329173298-172.17.0.15-1598199526777:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41279,DS-0a661c43-2f8b-4155-bfaa-8fe463be4124,DISK], DatanodeInfoWithStorage[127.0.0.1:39035,DS-ac2edf59-1cc0-4dc3-aeaa-4e2abf90326a,DISK], DatanodeInfoWithStorage[127.0.0.1:46273,DS-105a988f-d156-4e63-9731-8a49053e167f,DISK], DatanodeInfoWithStorage[127.0.0.1:36661,DS-393d019d-76aa-4276-8786-a6ea856f1188,DISK], DatanodeInfoWithStorage[127.0.0.1:46611,DS-6116d39b-eaf3-40aa-a934-369c251df547,DISK], DatanodeInfoWithStorage[127.0.0.1:35425,DS-6d90af9f-1713-4092-868e-f15d67bd5eac,DISK], DatanodeInfoWithStorage[127.0.0.1:34652,DS-dda048c2-d805-4272-8d01-8f15b4d3aa0f,DISK], DatanodeInfoWithStorage[127.0.0.1:35961,DS-669c36d6-b583-4d55-8d9e-9665af8ae080,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-329173298-172.17.0.15-1598199526777:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41279,DS-0a661c43-2f8b-4155-bfaa-8fe463be4124,DISK], DatanodeInfoWithStorage[127.0.0.1:39035,DS-ac2edf59-1cc0-4dc3-aeaa-4e2abf90326a,DISK], DatanodeInfoWithStorage[127.0.0.1:46273,DS-105a988f-d156-4e63-9731-8a49053e167f,DISK], DatanodeInfoWithStorage[127.0.0.1:36661,DS-393d019d-76aa-4276-8786-a6ea856f1188,DISK], DatanodeInfoWithStorage[127.0.0.1:46611,DS-6116d39b-eaf3-40aa-a934-369c251df547,DISK], DatanodeInfoWithStorage[127.0.0.1:35425,DS-6d90af9f-1713-4092-868e-f15d67bd5eac,DISK], DatanodeInfoWithStorage[127.0.0.1:34652,DS-dda048c2-d805-4272-8d01-8f15b4d3aa0f,DISK], DatanodeInfoWithStorage[127.0.0.1:35961,DS-669c36d6-b583-4d55-8d9e-9665af8ae080,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1655970883-172.17.0.15-1598199606059:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44627,DS-27171ea4-0156-4680-82fa-ee42bdc2c2f3,DISK], DatanodeInfoWithStorage[127.0.0.1:33077,DS-df8937b7-031f-49da-af73-2d44aede4798,DISK], DatanodeInfoWithStorage[127.0.0.1:43450,DS-b7cf5b25-f592-4188-bbe2-0f3e6d5ab4ce,DISK], DatanodeInfoWithStorage[127.0.0.1:42836,DS-af57c10f-389a-4a8f-9416-e20c0e97d30e,DISK], DatanodeInfoWithStorage[127.0.0.1:38600,DS-39877227-a5b1-4d89-830c-63bf8065d672,DISK], DatanodeInfoWithStorage[127.0.0.1:33496,DS-7d6a2334-edb8-4ce3-a3bb-4fbe06fee564,DISK], DatanodeInfoWithStorage[127.0.0.1:33878,DS-35f7c571-3a19-4f49-844b-12b06ab6cdb6,DISK], DatanodeInfoWithStorage[127.0.0.1:43573,DS-a6ea2b74-1a65-4500-97cd-e0705f57e3b7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1655970883-172.17.0.15-1598199606059:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44627,DS-27171ea4-0156-4680-82fa-ee42bdc2c2f3,DISK], DatanodeInfoWithStorage[127.0.0.1:33077,DS-df8937b7-031f-49da-af73-2d44aede4798,DISK], DatanodeInfoWithStorage[127.0.0.1:43450,DS-b7cf5b25-f592-4188-bbe2-0f3e6d5ab4ce,DISK], DatanodeInfoWithStorage[127.0.0.1:42836,DS-af57c10f-389a-4a8f-9416-e20c0e97d30e,DISK], DatanodeInfoWithStorage[127.0.0.1:38600,DS-39877227-a5b1-4d89-830c-63bf8065d672,DISK], DatanodeInfoWithStorage[127.0.0.1:33496,DS-7d6a2334-edb8-4ce3-a3bb-4fbe06fee564,DISK], DatanodeInfoWithStorage[127.0.0.1:33878,DS-35f7c571-3a19-4f49-844b-12b06ab6cdb6,DISK], DatanodeInfoWithStorage[127.0.0.1:43573,DS-a6ea2b74-1a65-4500-97cd-e0705f57e3b7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-444802018-172.17.0.15-1598199622109:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40886,DS-12766a0c-8821-418d-b150-0c820e8f53f9,DISK], DatanodeInfoWithStorage[127.0.0.1:39061,DS-0441c00f-7be4-4193-b970-aeb4522eac92,DISK], DatanodeInfoWithStorage[127.0.0.1:46390,DS-685e64d4-6cc6-47e2-954e-c0f2c3aa12c1,DISK], DatanodeInfoWithStorage[127.0.0.1:33677,DS-d45f880a-577f-4526-bd9c-7f28b555f59a,DISK], DatanodeInfoWithStorage[127.0.0.1:37719,DS-d7808855-5b44-45dc-875f-930bbe1d5900,DISK], DatanodeInfoWithStorage[127.0.0.1:40301,DS-36fdabd0-3995-4804-a791-5b98b51c0a67,DISK], DatanodeInfoWithStorage[127.0.0.1:43160,DS-fe2cf358-7202-44bd-9b2d-89f62d14aefc,DISK], DatanodeInfoWithStorage[127.0.0.1:45517,DS-5675476f-8a31-43c3-b4a3-d1c86e91f647,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-444802018-172.17.0.15-1598199622109:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40886,DS-12766a0c-8821-418d-b150-0c820e8f53f9,DISK], DatanodeInfoWithStorage[127.0.0.1:39061,DS-0441c00f-7be4-4193-b970-aeb4522eac92,DISK], DatanodeInfoWithStorage[127.0.0.1:46390,DS-685e64d4-6cc6-47e2-954e-c0f2c3aa12c1,DISK], DatanodeInfoWithStorage[127.0.0.1:33677,DS-d45f880a-577f-4526-bd9c-7f28b555f59a,DISK], DatanodeInfoWithStorage[127.0.0.1:37719,DS-d7808855-5b44-45dc-875f-930bbe1d5900,DISK], DatanodeInfoWithStorage[127.0.0.1:40301,DS-36fdabd0-3995-4804-a791-5b98b51c0a67,DISK], DatanodeInfoWithStorage[127.0.0.1:43160,DS-fe2cf358-7202-44bd-9b2d-89f62d14aefc,DISK], DatanodeInfoWithStorage[127.0.0.1:45517,DS-5675476f-8a31-43c3-b4a3-d1c86e91f647,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-471785132-172.17.0.15-1598199637931:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42944,DS-94e364f4-c90e-4655-b6c9-f5bb7ea5befd,DISK], DatanodeInfoWithStorage[127.0.0.1:36763,DS-1814c906-b586-42a3-98cb-ddd370a182b3,DISK], DatanodeInfoWithStorage[127.0.0.1:33828,DS-89f41982-9840-44e8-9e85-fd61a33a3ab5,DISK], DatanodeInfoWithStorage[127.0.0.1:37176,DS-50d5b429-ff3d-4453-ac1a-683b5196d5b0,DISK], DatanodeInfoWithStorage[127.0.0.1:34458,DS-9ae696b1-724b-4e29-bd3a-d5b8d8f0bcc4,DISK], DatanodeInfoWithStorage[127.0.0.1:39375,DS-a38b1cc8-5193-41c6-9a01-ee263e99b1bb,DISK], DatanodeInfoWithStorage[127.0.0.1:36878,DS-53c42a0f-abb7-41a7-8d9d-bc3f57079ab4,DISK], DatanodeInfoWithStorage[127.0.0.1:36318,DS-3bb16844-af8f-430b-bfdd-a56c69aae045,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-471785132-172.17.0.15-1598199637931:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42944,DS-94e364f4-c90e-4655-b6c9-f5bb7ea5befd,DISK], DatanodeInfoWithStorage[127.0.0.1:36763,DS-1814c906-b586-42a3-98cb-ddd370a182b3,DISK], DatanodeInfoWithStorage[127.0.0.1:33828,DS-89f41982-9840-44e8-9e85-fd61a33a3ab5,DISK], DatanodeInfoWithStorage[127.0.0.1:37176,DS-50d5b429-ff3d-4453-ac1a-683b5196d5b0,DISK], DatanodeInfoWithStorage[127.0.0.1:34458,DS-9ae696b1-724b-4e29-bd3a-d5b8d8f0bcc4,DISK], DatanodeInfoWithStorage[127.0.0.1:39375,DS-a38b1cc8-5193-41c6-9a01-ee263e99b1bb,DISK], DatanodeInfoWithStorage[127.0.0.1:36878,DS-53c42a0f-abb7-41a7-8d9d-bc3f57079ab4,DISK], DatanodeInfoWithStorage[127.0.0.1:36318,DS-3bb16844-af8f-430b-bfdd-a56c69aae045,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-307813459-172.17.0.15-1598199653982:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44839,DS-54f508e3-0603-46ac-a5a4-f746cea9da33,DISK], DatanodeInfoWithStorage[127.0.0.1:39310,DS-6f5f6d4a-50fd-4b9a-b661-4088c8f269e9,DISK], DatanodeInfoWithStorage[127.0.0.1:41941,DS-2509e389-09f7-4a8f-8338-a1bba38eed06,DISK], DatanodeInfoWithStorage[127.0.0.1:34258,DS-8fdf3b0a-2bbb-43dd-985c-e9edb24a0050,DISK], DatanodeInfoWithStorage[127.0.0.1:46063,DS-d3bc4bee-9f0b-4216-8b00-9ec72accc1aa,DISK], DatanodeInfoWithStorage[127.0.0.1:39001,DS-410e3fd2-7d54-4035-ac94-42b1d68e0c05,DISK], DatanodeInfoWithStorage[127.0.0.1:43539,DS-2eacb7e2-10a8-466e-b44c-566ef6fce4ad,DISK], DatanodeInfoWithStorage[127.0.0.1:41210,DS-d2ced731-7008-40e4-a06e-7c01b2df9341,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-307813459-172.17.0.15-1598199653982:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44839,DS-54f508e3-0603-46ac-a5a4-f746cea9da33,DISK], DatanodeInfoWithStorage[127.0.0.1:39310,DS-6f5f6d4a-50fd-4b9a-b661-4088c8f269e9,DISK], DatanodeInfoWithStorage[127.0.0.1:41941,DS-2509e389-09f7-4a8f-8338-a1bba38eed06,DISK], DatanodeInfoWithStorage[127.0.0.1:34258,DS-8fdf3b0a-2bbb-43dd-985c-e9edb24a0050,DISK], DatanodeInfoWithStorage[127.0.0.1:46063,DS-d3bc4bee-9f0b-4216-8b00-9ec72accc1aa,DISK], DatanodeInfoWithStorage[127.0.0.1:39001,DS-410e3fd2-7d54-4035-ac94-42b1d68e0c05,DISK], DatanodeInfoWithStorage[127.0.0.1:43539,DS-2eacb7e2-10a8-466e-b44c-566ef6fce4ad,DISK], DatanodeInfoWithStorage[127.0.0.1:41210,DS-d2ced731-7008-40e4-a06e-7c01b2df9341,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-116402207-172.17.0.15-1598199669780:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37725,DS-cf0c388c-3c8a-497e-9f91-4ed29db7ada5,DISK], DatanodeInfoWithStorage[127.0.0.1:42257,DS-4506d42b-5977-48ac-84cd-93efd17d4f0f,DISK], DatanodeInfoWithStorage[127.0.0.1:36280,DS-b407f80c-6415-4726-bc44-d024842442ac,DISK], DatanodeInfoWithStorage[127.0.0.1:42517,DS-a7fc4ee7-2ef5-4ac3-930a-1518c527867a,DISK], DatanodeInfoWithStorage[127.0.0.1:42739,DS-b0d3d028-83b0-4de4-946c-91b7b185490c,DISK], DatanodeInfoWithStorage[127.0.0.1:41129,DS-41a0b4c2-ea7e-4268-8c9a-bb3fecdfdfba,DISK], DatanodeInfoWithStorage[127.0.0.1:35660,DS-1c8c585f-4ff3-4555-81ad-4014088d63d7,DISK], DatanodeInfoWithStorage[127.0.0.1:44510,DS-c536572c-8aed-4eb1-9079-6fb9c01fd089,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-116402207-172.17.0.15-1598199669780:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37725,DS-cf0c388c-3c8a-497e-9f91-4ed29db7ada5,DISK], DatanodeInfoWithStorage[127.0.0.1:42257,DS-4506d42b-5977-48ac-84cd-93efd17d4f0f,DISK], DatanodeInfoWithStorage[127.0.0.1:36280,DS-b407f80c-6415-4726-bc44-d024842442ac,DISK], DatanodeInfoWithStorage[127.0.0.1:42517,DS-a7fc4ee7-2ef5-4ac3-930a-1518c527867a,DISK], DatanodeInfoWithStorage[127.0.0.1:42739,DS-b0d3d028-83b0-4de4-946c-91b7b185490c,DISK], DatanodeInfoWithStorage[127.0.0.1:41129,DS-41a0b4c2-ea7e-4268-8c9a-bb3fecdfdfba,DISK], DatanodeInfoWithStorage[127.0.0.1:35660,DS-1c8c585f-4ff3-4555-81ad-4014088d63d7,DISK], DatanodeInfoWithStorage[127.0.0.1:44510,DS-c536572c-8aed-4eb1-9079-6fb9c01fd089,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1187545410-172.17.0.15-1598199764828:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44570,DS-11ec7e22-2f30-4b2b-9283-3d71b3495ccc,DISK], DatanodeInfoWithStorage[127.0.0.1:46299,DS-6332cb78-2ae1-40b7-b4b1-fa4a3afe0b90,DISK], DatanodeInfoWithStorage[127.0.0.1:34072,DS-97fe12a6-92c8-48fc-9baf-89126a4aef58,DISK], DatanodeInfoWithStorage[127.0.0.1:42916,DS-575fcf49-abd6-4c0c-93f3-32b136c1cc3b,DISK], DatanodeInfoWithStorage[127.0.0.1:37095,DS-4d5d5a2d-577f-421c-8016-ecad50f5c225,DISK], DatanodeInfoWithStorage[127.0.0.1:33445,DS-ed49615a-ad28-4829-98f8-89adef74969e,DISK], DatanodeInfoWithStorage[127.0.0.1:41289,DS-3cca79c6-c09f-41e4-92a3-02d10a4038ab,DISK], DatanodeInfoWithStorage[127.0.0.1:43563,DS-146f8df8-5bef-4c4b-b7be-8344f5b8a547,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1187545410-172.17.0.15-1598199764828:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44570,DS-11ec7e22-2f30-4b2b-9283-3d71b3495ccc,DISK], DatanodeInfoWithStorage[127.0.0.1:46299,DS-6332cb78-2ae1-40b7-b4b1-fa4a3afe0b90,DISK], DatanodeInfoWithStorage[127.0.0.1:34072,DS-97fe12a6-92c8-48fc-9baf-89126a4aef58,DISK], DatanodeInfoWithStorage[127.0.0.1:42916,DS-575fcf49-abd6-4c0c-93f3-32b136c1cc3b,DISK], DatanodeInfoWithStorage[127.0.0.1:37095,DS-4d5d5a2d-577f-421c-8016-ecad50f5c225,DISK], DatanodeInfoWithStorage[127.0.0.1:33445,DS-ed49615a-ad28-4829-98f8-89adef74969e,DISK], DatanodeInfoWithStorage[127.0.0.1:41289,DS-3cca79c6-c09f-41e4-92a3-02d10a4038ab,DISK], DatanodeInfoWithStorage[127.0.0.1:43563,DS-146f8df8-5bef-4c4b-b7be-8344f5b8a547,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1872940414-172.17.0.15-1598199796473:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37333,DS-308d155d-05ff-4414-b09d-ab8e7226d826,DISK], DatanodeInfoWithStorage[127.0.0.1:34406,DS-05aa8713-4186-4a2d-ba37-f6e928cf8647,DISK], DatanodeInfoWithStorage[127.0.0.1:35973,DS-8b0a697c-0ba4-4775-b87f-bed26f01d512,DISK], DatanodeInfoWithStorage[127.0.0.1:41742,DS-56d190c4-c464-425a-949b-a238c9038755,DISK], DatanodeInfoWithStorage[127.0.0.1:39186,DS-78cdc3a4-7e2f-450b-a9f1-4df1b42d80c6,DISK], DatanodeInfoWithStorage[127.0.0.1:45592,DS-f641e10b-ba4b-4687-9e09-257df43e861f,DISK], DatanodeInfoWithStorage[127.0.0.1:42737,DS-5552a37f-1f1e-4414-834e-1e9ff5f6237f,DISK], DatanodeInfoWithStorage[127.0.0.1:41706,DS-b2426d23-80ea-4cb9-a2dc-6093e5f06bb1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1872940414-172.17.0.15-1598199796473:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37333,DS-308d155d-05ff-4414-b09d-ab8e7226d826,DISK], DatanodeInfoWithStorage[127.0.0.1:34406,DS-05aa8713-4186-4a2d-ba37-f6e928cf8647,DISK], DatanodeInfoWithStorage[127.0.0.1:35973,DS-8b0a697c-0ba4-4775-b87f-bed26f01d512,DISK], DatanodeInfoWithStorage[127.0.0.1:41742,DS-56d190c4-c464-425a-949b-a238c9038755,DISK], DatanodeInfoWithStorage[127.0.0.1:39186,DS-78cdc3a4-7e2f-450b-a9f1-4df1b42d80c6,DISK], DatanodeInfoWithStorage[127.0.0.1:45592,DS-f641e10b-ba4b-4687-9e09-257df43e861f,DISK], DatanodeInfoWithStorage[127.0.0.1:42737,DS-5552a37f-1f1e-4414-834e-1e9ff5f6237f,DISK], DatanodeInfoWithStorage[127.0.0.1:41706,DS-b2426d23-80ea-4cb9-a2dc-6093e5f06bb1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-489493040-172.17.0.15-1598199891539:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36069,DS-f74e892c-eb08-4eba-869e-943f9ee7ab73,DISK], DatanodeInfoWithStorage[127.0.0.1:34558,DS-2a64c380-e117-418e-8178-628d115b4109,DISK], DatanodeInfoWithStorage[127.0.0.1:45087,DS-7f34aeb6-82fe-4fc7-953a-455817352796,DISK], DatanodeInfoWithStorage[127.0.0.1:43080,DS-f3f96d83-5c72-48f6-b228-fd6493e9ae58,DISK], DatanodeInfoWithStorage[127.0.0.1:33601,DS-c746afc9-aa33-48aa-b841-69ff555f438e,DISK], DatanodeInfoWithStorage[127.0.0.1:44345,DS-45b1d2f2-eb48-48b5-a61d-31225c907e66,DISK], DatanodeInfoWithStorage[127.0.0.1:46341,DS-fffed53b-d30d-4091-a574-504976300738,DISK], DatanodeInfoWithStorage[127.0.0.1:39554,DS-3a2d1fe4-e110-4abd-a748-760b8fdb77a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-489493040-172.17.0.15-1598199891539:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36069,DS-f74e892c-eb08-4eba-869e-943f9ee7ab73,DISK], DatanodeInfoWithStorage[127.0.0.1:34558,DS-2a64c380-e117-418e-8178-628d115b4109,DISK], DatanodeInfoWithStorage[127.0.0.1:45087,DS-7f34aeb6-82fe-4fc7-953a-455817352796,DISK], DatanodeInfoWithStorage[127.0.0.1:43080,DS-f3f96d83-5c72-48f6-b228-fd6493e9ae58,DISK], DatanodeInfoWithStorage[127.0.0.1:33601,DS-c746afc9-aa33-48aa-b841-69ff555f438e,DISK], DatanodeInfoWithStorage[127.0.0.1:44345,DS-45b1d2f2-eb48-48b5-a61d-31225c907e66,DISK], DatanodeInfoWithStorage[127.0.0.1:46341,DS-fffed53b-d30d-4091-a574-504976300738,DISK], DatanodeInfoWithStorage[127.0.0.1:39554,DS-3a2d1fe4-e110-4abd-a748-760b8fdb77a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1235272169-172.17.0.15-1598199954769:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39188,DS-c11d1337-6149-4693-9b71-cd1247c47e8c,DISK], DatanodeInfoWithStorage[127.0.0.1:45708,DS-8527f77b-c6ef-470b-8072-d5fa52cc2393,DISK], DatanodeInfoWithStorage[127.0.0.1:37599,DS-c74127e4-a6cd-403c-b7b8-969a9b0e0d73,DISK], DatanodeInfoWithStorage[127.0.0.1:44812,DS-9da06451-b096-4408-85d5-16bebc8893a8,DISK], DatanodeInfoWithStorage[127.0.0.1:41838,DS-61f12ef5-f5f2-434d-af9a-0d2eda045829,DISK], DatanodeInfoWithStorage[127.0.0.1:46827,DS-97ad6050-04c4-4905-adfe-a5fa60299b79,DISK], DatanodeInfoWithStorage[127.0.0.1:41460,DS-238630cb-ae38-4cc3-94a0-ecbee10e7832,DISK], DatanodeInfoWithStorage[127.0.0.1:36865,DS-06518534-f91b-4b7b-9b47-8145c4f4d9b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1235272169-172.17.0.15-1598199954769:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39188,DS-c11d1337-6149-4693-9b71-cd1247c47e8c,DISK], DatanodeInfoWithStorage[127.0.0.1:45708,DS-8527f77b-c6ef-470b-8072-d5fa52cc2393,DISK], DatanodeInfoWithStorage[127.0.0.1:37599,DS-c74127e4-a6cd-403c-b7b8-969a9b0e0d73,DISK], DatanodeInfoWithStorage[127.0.0.1:44812,DS-9da06451-b096-4408-85d5-16bebc8893a8,DISK], DatanodeInfoWithStorage[127.0.0.1:41838,DS-61f12ef5-f5f2-434d-af9a-0d2eda045829,DISK], DatanodeInfoWithStorage[127.0.0.1:46827,DS-97ad6050-04c4-4905-adfe-a5fa60299b79,DISK], DatanodeInfoWithStorage[127.0.0.1:41460,DS-238630cb-ae38-4cc3-94a0-ecbee10e7832,DISK], DatanodeInfoWithStorage[127.0.0.1:36865,DS-06518534-f91b-4b7b-9b47-8145c4f4d9b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2071700570-172.17.0.15-1598199970643:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34330,DS-738bf6ee-baec-4193-856e-fd003239eaaf,DISK], DatanodeInfoWithStorage[127.0.0.1:38666,DS-e0d45a3e-10de-4b2a-a997-41ce72adcab1,DISK], DatanodeInfoWithStorage[127.0.0.1:41778,DS-90e23bca-4977-442f-ae9d-9d2f3a485e1a,DISK], DatanodeInfoWithStorage[127.0.0.1:34381,DS-0cc0517a-08d6-4631-84aa-0deb4925c1ee,DISK], DatanodeInfoWithStorage[127.0.0.1:41880,DS-8107d0c4-ab0f-47a6-b515-71c282e337b9,DISK], DatanodeInfoWithStorage[127.0.0.1:37137,DS-da8e4339-4d20-4fae-940f-66e1716cc777,DISK], DatanodeInfoWithStorage[127.0.0.1:36293,DS-7e572b98-b6a5-4ff4-9a58-1061760d7c67,DISK], DatanodeInfoWithStorage[127.0.0.1:46672,DS-b8ed6db1-cb52-403d-b398-3fd6b227b48e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2071700570-172.17.0.15-1598199970643:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34330,DS-738bf6ee-baec-4193-856e-fd003239eaaf,DISK], DatanodeInfoWithStorage[127.0.0.1:38666,DS-e0d45a3e-10de-4b2a-a997-41ce72adcab1,DISK], DatanodeInfoWithStorage[127.0.0.1:41778,DS-90e23bca-4977-442f-ae9d-9d2f3a485e1a,DISK], DatanodeInfoWithStorage[127.0.0.1:34381,DS-0cc0517a-08d6-4631-84aa-0deb4925c1ee,DISK], DatanodeInfoWithStorage[127.0.0.1:41880,DS-8107d0c4-ab0f-47a6-b515-71c282e337b9,DISK], DatanodeInfoWithStorage[127.0.0.1:37137,DS-da8e4339-4d20-4fae-940f-66e1716cc777,DISK], DatanodeInfoWithStorage[127.0.0.1:36293,DS-7e572b98-b6a5-4ff4-9a58-1061760d7c67,DISK], DatanodeInfoWithStorage[127.0.0.1:46672,DS-b8ed6db1-cb52-403d-b398-3fd6b227b48e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 10 out of 50
v1v1v2v2 failed with probability 19 out of 50
result: false positive !!!
Total execution time in seconds : 2396
