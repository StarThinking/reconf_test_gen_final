reconf_parameter: dfs.namenode.edits.noeditlogchannelflush
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edits.noeditlogchannelflush
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1994528445-172.17.0.8-1598410319383:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32805,DS-388fa863-cc0c-4d47-a7ef-4a8b928792e7,DISK], DatanodeInfoWithStorage[127.0.0.1:34851,DS-548542c0-f428-4ce6-a653-d6589debe4fc,DISK], DatanodeInfoWithStorage[127.0.0.1:34610,DS-879c5076-0205-4ead-a29a-d21db9b296a4,DISK], DatanodeInfoWithStorage[127.0.0.1:45945,DS-ff4b93f4-b529-457b-a3ae-0e9f31533139,DISK], DatanodeInfoWithStorage[127.0.0.1:34283,DS-9bfab495-e990-4314-a8ef-464771cd5380,DISK], DatanodeInfoWithStorage[127.0.0.1:43714,DS-70c3f9f4-6986-49d6-a72c-13faad04aeff,DISK], DatanodeInfoWithStorage[127.0.0.1:40559,DS-d140b672-5ded-4145-beef-e976d43a2048,DISK], DatanodeInfoWithStorage[127.0.0.1:39511,DS-e67dd212-fa0f-4c03-88ae-c97a3be80458,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1994528445-172.17.0.8-1598410319383:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32805,DS-388fa863-cc0c-4d47-a7ef-4a8b928792e7,DISK], DatanodeInfoWithStorage[127.0.0.1:34851,DS-548542c0-f428-4ce6-a653-d6589debe4fc,DISK], DatanodeInfoWithStorage[127.0.0.1:34610,DS-879c5076-0205-4ead-a29a-d21db9b296a4,DISK], DatanodeInfoWithStorage[127.0.0.1:45945,DS-ff4b93f4-b529-457b-a3ae-0e9f31533139,DISK], DatanodeInfoWithStorage[127.0.0.1:34283,DS-9bfab495-e990-4314-a8ef-464771cd5380,DISK], DatanodeInfoWithStorage[127.0.0.1:43714,DS-70c3f9f4-6986-49d6-a72c-13faad04aeff,DISK], DatanodeInfoWithStorage[127.0.0.1:40559,DS-d140b672-5ded-4145-beef-e976d43a2048,DISK], DatanodeInfoWithStorage[127.0.0.1:39511,DS-e67dd212-fa0f-4c03-88ae-c97a3be80458,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edits.noeditlogchannelflush
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2133545674-172.17.0.8-1598410406053:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40068,DS-5b9840cb-a0fb-457a-9be6-89900d41c734,DISK], DatanodeInfoWithStorage[127.0.0.1:40837,DS-e4ff2de9-cf35-4489-b45b-d35511c576af,DISK], DatanodeInfoWithStorage[127.0.0.1:33798,DS-d277c9b8-2885-4f1e-b32e-577e5b68a9d7,DISK], DatanodeInfoWithStorage[127.0.0.1:38477,DS-847a7330-f35b-4314-84d3-48af6a8d1fa0,DISK], DatanodeInfoWithStorage[127.0.0.1:38296,DS-24b6ff4e-aeb1-4ff4-840a-241265daabd2,DISK], DatanodeInfoWithStorage[127.0.0.1:37335,DS-2ea9c6a7-1ece-442a-966c-cb91b9410686,DISK], DatanodeInfoWithStorage[127.0.0.1:37157,DS-f4f63a9d-5b62-425c-b668-1383178fb357,DISK], DatanodeInfoWithStorage[127.0.0.1:35825,DS-97ada327-cb6e-4cd0-888d-fd1a003cb95f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2133545674-172.17.0.8-1598410406053:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40068,DS-5b9840cb-a0fb-457a-9be6-89900d41c734,DISK], DatanodeInfoWithStorage[127.0.0.1:40837,DS-e4ff2de9-cf35-4489-b45b-d35511c576af,DISK], DatanodeInfoWithStorage[127.0.0.1:33798,DS-d277c9b8-2885-4f1e-b32e-577e5b68a9d7,DISK], DatanodeInfoWithStorage[127.0.0.1:38477,DS-847a7330-f35b-4314-84d3-48af6a8d1fa0,DISK], DatanodeInfoWithStorage[127.0.0.1:38296,DS-24b6ff4e-aeb1-4ff4-840a-241265daabd2,DISK], DatanodeInfoWithStorage[127.0.0.1:37335,DS-2ea9c6a7-1ece-442a-966c-cb91b9410686,DISK], DatanodeInfoWithStorage[127.0.0.1:37157,DS-f4f63a9d-5b62-425c-b668-1383178fb357,DISK], DatanodeInfoWithStorage[127.0.0.1:35825,DS-97ada327-cb6e-4cd0-888d-fd1a003cb95f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edits.noeditlogchannelflush
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2066787491-172.17.0.8-1598410609489:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42710,DS-544d5e42-2ec3-427d-8e44-9b2bd859f9cd,DISK], DatanodeInfoWithStorage[127.0.0.1:34847,DS-7b6d08fb-bccd-4cce-acb3-2a5f28ff1ce1,DISK], DatanodeInfoWithStorage[127.0.0.1:33241,DS-d7e16dda-b1b7-459c-9f31-46698db2783f,DISK], DatanodeInfoWithStorage[127.0.0.1:33096,DS-490a9b14-80a4-4853-92e5-226a52ed9f1c,DISK], DatanodeInfoWithStorage[127.0.0.1:42370,DS-fe210a68-00cc-48ec-8d82-1075ae048c8b,DISK], DatanodeInfoWithStorage[127.0.0.1:33650,DS-87ad23be-6600-47cf-b1c7-3c9a0b13df5b,DISK], DatanodeInfoWithStorage[127.0.0.1:46360,DS-caad91ed-32be-4e8d-9b71-ad8465fed65c,DISK], DatanodeInfoWithStorage[127.0.0.1:41604,DS-c3bf1643-7f6b-46f7-b075-1837667169df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2066787491-172.17.0.8-1598410609489:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42710,DS-544d5e42-2ec3-427d-8e44-9b2bd859f9cd,DISK], DatanodeInfoWithStorage[127.0.0.1:34847,DS-7b6d08fb-bccd-4cce-acb3-2a5f28ff1ce1,DISK], DatanodeInfoWithStorage[127.0.0.1:33241,DS-d7e16dda-b1b7-459c-9f31-46698db2783f,DISK], DatanodeInfoWithStorage[127.0.0.1:33096,DS-490a9b14-80a4-4853-92e5-226a52ed9f1c,DISK], DatanodeInfoWithStorage[127.0.0.1:42370,DS-fe210a68-00cc-48ec-8d82-1075ae048c8b,DISK], DatanodeInfoWithStorage[127.0.0.1:33650,DS-87ad23be-6600-47cf-b1c7-3c9a0b13df5b,DISK], DatanodeInfoWithStorage[127.0.0.1:46360,DS-caad91ed-32be-4e8d-9b71-ad8465fed65c,DISK], DatanodeInfoWithStorage[127.0.0.1:41604,DS-c3bf1643-7f6b-46f7-b075-1837667169df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.noeditlogchannelflush
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1141943763-172.17.0.8-1598410674089:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34260,DS-59c7552c-4452-4f35-bb65-aec1962aabc3,DISK], DatanodeInfoWithStorage[127.0.0.1:38273,DS-6fbbabbd-e3de-473c-b1c5-d4c6febb8363,DISK], DatanodeInfoWithStorage[127.0.0.1:34863,DS-b83a40a4-9d7e-4851-b536-261f2de3cb75,DISK], DatanodeInfoWithStorage[127.0.0.1:34808,DS-b09b044a-4729-4c67-950d-8aec760ca0dd,DISK], DatanodeInfoWithStorage[127.0.0.1:33831,DS-0167d51a-5b1d-410b-a731-456cee231009,DISK], DatanodeInfoWithStorage[127.0.0.1:37320,DS-4c7a48e1-4f04-4c40-8462-3b3c27363cef,DISK], DatanodeInfoWithStorage[127.0.0.1:41988,DS-15ad88a5-08ed-4f03-a7d2-602f92001918,DISK], DatanodeInfoWithStorage[127.0.0.1:37112,DS-7c6ae9a9-2c70-4982-9203-109ea464dd05,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1141943763-172.17.0.8-1598410674089:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34260,DS-59c7552c-4452-4f35-bb65-aec1962aabc3,DISK], DatanodeInfoWithStorage[127.0.0.1:38273,DS-6fbbabbd-e3de-473c-b1c5-d4c6febb8363,DISK], DatanodeInfoWithStorage[127.0.0.1:34863,DS-b83a40a4-9d7e-4851-b536-261f2de3cb75,DISK], DatanodeInfoWithStorage[127.0.0.1:34808,DS-b09b044a-4729-4c67-950d-8aec760ca0dd,DISK], DatanodeInfoWithStorage[127.0.0.1:33831,DS-0167d51a-5b1d-410b-a731-456cee231009,DISK], DatanodeInfoWithStorage[127.0.0.1:37320,DS-4c7a48e1-4f04-4c40-8462-3b3c27363cef,DISK], DatanodeInfoWithStorage[127.0.0.1:41988,DS-15ad88a5-08ed-4f03-a7d2-602f92001918,DISK], DatanodeInfoWithStorage[127.0.0.1:37112,DS-7c6ae9a9-2c70-4982-9203-109ea464dd05,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.noeditlogchannelflush
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1930893588-172.17.0.8-1598411048524:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32934,DS-d439a14a-e93b-424a-aac7-cf9afe0ef643,DISK], DatanodeInfoWithStorage[127.0.0.1:34469,DS-9efab023-6473-455f-a7c8-e27138ea199c,DISK], DatanodeInfoWithStorage[127.0.0.1:42610,DS-35f7cd55-2037-4da8-920e-7997ac0311de,DISK], DatanodeInfoWithStorage[127.0.0.1:43835,DS-e8e643f1-4168-49b6-833a-a13bc91a2076,DISK], DatanodeInfoWithStorage[127.0.0.1:43028,DS-2ccf6a0b-3b90-4d36-b5f6-2c5d952d9a75,DISK], DatanodeInfoWithStorage[127.0.0.1:44903,DS-8463cbee-3466-40aa-8cc6-6e82e4b0df6c,DISK], DatanodeInfoWithStorage[127.0.0.1:37083,DS-f3bb7d67-e53d-46a3-9528-33ea6b967193,DISK], DatanodeInfoWithStorage[127.0.0.1:45837,DS-f34b7b9b-934e-47b8-aa44-c5d9561ae00c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1930893588-172.17.0.8-1598411048524:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32934,DS-d439a14a-e93b-424a-aac7-cf9afe0ef643,DISK], DatanodeInfoWithStorage[127.0.0.1:34469,DS-9efab023-6473-455f-a7c8-e27138ea199c,DISK], DatanodeInfoWithStorage[127.0.0.1:42610,DS-35f7cd55-2037-4da8-920e-7997ac0311de,DISK], DatanodeInfoWithStorage[127.0.0.1:43835,DS-e8e643f1-4168-49b6-833a-a13bc91a2076,DISK], DatanodeInfoWithStorage[127.0.0.1:43028,DS-2ccf6a0b-3b90-4d36-b5f6-2c5d952d9a75,DISK], DatanodeInfoWithStorage[127.0.0.1:44903,DS-8463cbee-3466-40aa-8cc6-6e82e4b0df6c,DISK], DatanodeInfoWithStorage[127.0.0.1:37083,DS-f3bb7d67-e53d-46a3-9528-33ea6b967193,DISK], DatanodeInfoWithStorage[127.0.0.1:45837,DS-f34b7b9b-934e-47b8-aa44-c5d9561ae00c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.noeditlogchannelflush
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1261956720-172.17.0.8-1598411144053:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39832,DS-d1f85f3a-9450-4cfb-bdf1-2eea8562353f,DISK], DatanodeInfoWithStorage[127.0.0.1:43674,DS-9ff699b3-fd10-44d4-af75-1749c4c98317,DISK], DatanodeInfoWithStorage[127.0.0.1:34187,DS-864e898b-bce4-4e9e-a244-ca12a0017c2c,DISK], DatanodeInfoWithStorage[127.0.0.1:44930,DS-4c165647-4f5f-4cc1-8c86-9ce027382bd8,DISK], DatanodeInfoWithStorage[127.0.0.1:42028,DS-211f2c3f-249d-4280-8069-9f366ec40804,DISK], DatanodeInfoWithStorage[127.0.0.1:42350,DS-e0817b19-a450-4d0e-9598-e6d7da9964a5,DISK], DatanodeInfoWithStorage[127.0.0.1:38434,DS-dafef41e-21fd-4db1-8b7e-d26e710e6019,DISK], DatanodeInfoWithStorage[127.0.0.1:38049,DS-f4271405-ee55-45dc-a180-a0b59dec5d5a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1261956720-172.17.0.8-1598411144053:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39832,DS-d1f85f3a-9450-4cfb-bdf1-2eea8562353f,DISK], DatanodeInfoWithStorage[127.0.0.1:43674,DS-9ff699b3-fd10-44d4-af75-1749c4c98317,DISK], DatanodeInfoWithStorage[127.0.0.1:34187,DS-864e898b-bce4-4e9e-a244-ca12a0017c2c,DISK], DatanodeInfoWithStorage[127.0.0.1:44930,DS-4c165647-4f5f-4cc1-8c86-9ce027382bd8,DISK], DatanodeInfoWithStorage[127.0.0.1:42028,DS-211f2c3f-249d-4280-8069-9f366ec40804,DISK], DatanodeInfoWithStorage[127.0.0.1:42350,DS-e0817b19-a450-4d0e-9598-e6d7da9964a5,DISK], DatanodeInfoWithStorage[127.0.0.1:38434,DS-dafef41e-21fd-4db1-8b7e-d26e710e6019,DISK], DatanodeInfoWithStorage[127.0.0.1:38049,DS-f4271405-ee55-45dc-a180-a0b59dec5d5a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.noeditlogchannelflush
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1403454069-172.17.0.8-1598411245624:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34155,DS-11b6757b-06b1-44cb-a815-c1fce422314c,DISK], DatanodeInfoWithStorage[127.0.0.1:34188,DS-a96bbddd-4954-4d8e-b259-7756f0434204,DISK], DatanodeInfoWithStorage[127.0.0.1:43739,DS-1a39a976-d1b2-4bca-843d-54758c3f2e46,DISK], DatanodeInfoWithStorage[127.0.0.1:45771,DS-c22d5177-c660-47a9-a617-27e83f3f40c6,DISK], DatanodeInfoWithStorage[127.0.0.1:33156,DS-68ca0348-52f9-4a1f-8b99-75840de39ea4,DISK], DatanodeInfoWithStorage[127.0.0.1:36511,DS-5f2ad3be-e879-4c66-abf2-48e7d276007e,DISK], DatanodeInfoWithStorage[127.0.0.1:44862,DS-5098d6fc-5791-4f1a-ac2a-5544692170fa,DISK], DatanodeInfoWithStorage[127.0.0.1:38093,DS-51659129-458b-4d33-b37c-8fcb1c6af560,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1403454069-172.17.0.8-1598411245624:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34155,DS-11b6757b-06b1-44cb-a815-c1fce422314c,DISK], DatanodeInfoWithStorage[127.0.0.1:34188,DS-a96bbddd-4954-4d8e-b259-7756f0434204,DISK], DatanodeInfoWithStorage[127.0.0.1:43739,DS-1a39a976-d1b2-4bca-843d-54758c3f2e46,DISK], DatanodeInfoWithStorage[127.0.0.1:45771,DS-c22d5177-c660-47a9-a617-27e83f3f40c6,DISK], DatanodeInfoWithStorage[127.0.0.1:33156,DS-68ca0348-52f9-4a1f-8b99-75840de39ea4,DISK], DatanodeInfoWithStorage[127.0.0.1:36511,DS-5f2ad3be-e879-4c66-abf2-48e7d276007e,DISK], DatanodeInfoWithStorage[127.0.0.1:44862,DS-5098d6fc-5791-4f1a-ac2a-5544692170fa,DISK], DatanodeInfoWithStorage[127.0.0.1:38093,DS-51659129-458b-4d33-b37c-8fcb1c6af560,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.noeditlogchannelflush
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1763136413-172.17.0.8-1598411556926:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38482,DS-4126a054-fa94-46cc-b515-840e7a10d075,DISK], DatanodeInfoWithStorage[127.0.0.1:34713,DS-902b3821-4423-4e77-9b5a-8f6c110f60e4,DISK], DatanodeInfoWithStorage[127.0.0.1:36395,DS-76bef8f9-7253-4ec7-9a0e-eae0a60548c7,DISK], DatanodeInfoWithStorage[127.0.0.1:35402,DS-478a0da6-83b3-4f76-844c-a2ffa7f95ff6,DISK], DatanodeInfoWithStorage[127.0.0.1:40241,DS-3981aea9-3de9-4e5f-b166-84f04a80849c,DISK], DatanodeInfoWithStorage[127.0.0.1:36780,DS-439b1bcb-63de-4a0e-aaea-ddfd98f5348b,DISK], DatanodeInfoWithStorage[127.0.0.1:37207,DS-7c774cd7-8229-4cda-a081-dd9e38d5f6c9,DISK], DatanodeInfoWithStorage[127.0.0.1:42316,DS-1eaae3ce-9385-40fd-9c03-787795d8a0f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1763136413-172.17.0.8-1598411556926:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38482,DS-4126a054-fa94-46cc-b515-840e7a10d075,DISK], DatanodeInfoWithStorage[127.0.0.1:34713,DS-902b3821-4423-4e77-9b5a-8f6c110f60e4,DISK], DatanodeInfoWithStorage[127.0.0.1:36395,DS-76bef8f9-7253-4ec7-9a0e-eae0a60548c7,DISK], DatanodeInfoWithStorage[127.0.0.1:35402,DS-478a0da6-83b3-4f76-844c-a2ffa7f95ff6,DISK], DatanodeInfoWithStorage[127.0.0.1:40241,DS-3981aea9-3de9-4e5f-b166-84f04a80849c,DISK], DatanodeInfoWithStorage[127.0.0.1:36780,DS-439b1bcb-63de-4a0e-aaea-ddfd98f5348b,DISK], DatanodeInfoWithStorage[127.0.0.1:37207,DS-7c774cd7-8229-4cda-a081-dd9e38d5f6c9,DISK], DatanodeInfoWithStorage[127.0.0.1:42316,DS-1eaae3ce-9385-40fd-9c03-787795d8a0f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edits.noeditlogchannelflush
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-384237096-172.17.0.8-1598411688009:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38826,DS-e6bbc603-39da-4696-aaec-a0de4bdda53d,DISK], DatanodeInfoWithStorage[127.0.0.1:39130,DS-c452a3d1-94b5-4070-97b3-6a8bf9620bb7,DISK], DatanodeInfoWithStorage[127.0.0.1:32985,DS-cd1b55f5-ef5a-4c7d-a406-47092cda8740,DISK], DatanodeInfoWithStorage[127.0.0.1:39794,DS-f2e128ed-ae21-46fd-8a31-7915dbc0ea45,DISK], DatanodeInfoWithStorage[127.0.0.1:46720,DS-6f5a7338-718e-4885-b1ce-a29be2474d2e,DISK], DatanodeInfoWithStorage[127.0.0.1:43477,DS-f32b34de-f29b-4cd0-ac14-166fe79add1c,DISK], DatanodeInfoWithStorage[127.0.0.1:43335,DS-e4203243-c889-4956-816e-3cfd13c28187,DISK], DatanodeInfoWithStorage[127.0.0.1:37018,DS-80220dbf-13eb-451f-af99-2ace34a8f012,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-384237096-172.17.0.8-1598411688009:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38826,DS-e6bbc603-39da-4696-aaec-a0de4bdda53d,DISK], DatanodeInfoWithStorage[127.0.0.1:39130,DS-c452a3d1-94b5-4070-97b3-6a8bf9620bb7,DISK], DatanodeInfoWithStorage[127.0.0.1:32985,DS-cd1b55f5-ef5a-4c7d-a406-47092cda8740,DISK], DatanodeInfoWithStorage[127.0.0.1:39794,DS-f2e128ed-ae21-46fd-8a31-7915dbc0ea45,DISK], DatanodeInfoWithStorage[127.0.0.1:46720,DS-6f5a7338-718e-4885-b1ce-a29be2474d2e,DISK], DatanodeInfoWithStorage[127.0.0.1:43477,DS-f32b34de-f29b-4cd0-ac14-166fe79add1c,DISK], DatanodeInfoWithStorage[127.0.0.1:43335,DS-e4203243-c889-4956-816e-3cfd13c28187,DISK], DatanodeInfoWithStorage[127.0.0.1:37018,DS-80220dbf-13eb-451f-af99-2ace34a8f012,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.noeditlogchannelflush
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1618119740-172.17.0.8-1598411834976:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32974,DS-2823c2ba-e1a6-4ce7-8048-bd5ec99b26b7,DISK], DatanodeInfoWithStorage[127.0.0.1:36845,DS-8026f5de-ea61-4f34-9fc4-27be328be82d,DISK], DatanodeInfoWithStorage[127.0.0.1:35396,DS-0d5377a4-6b23-4198-a884-776ff62afb0b,DISK], DatanodeInfoWithStorage[127.0.0.1:39767,DS-16844e14-762d-44b2-8406-26c7c2774298,DISK], DatanodeInfoWithStorage[127.0.0.1:43460,DS-63b43c18-5e14-4dd3-bcc8-caf55f383974,DISK], DatanodeInfoWithStorage[127.0.0.1:43934,DS-c8db7b06-ebe3-4a12-bd1b-e47761ae7a52,DISK], DatanodeInfoWithStorage[127.0.0.1:35146,DS-e528fcd3-b60f-4856-b3e5-f76cb781dc42,DISK], DatanodeInfoWithStorage[127.0.0.1:38010,DS-34517c15-e4b0-4829-a635-82586e589fec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1618119740-172.17.0.8-1598411834976:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32974,DS-2823c2ba-e1a6-4ce7-8048-bd5ec99b26b7,DISK], DatanodeInfoWithStorage[127.0.0.1:36845,DS-8026f5de-ea61-4f34-9fc4-27be328be82d,DISK], DatanodeInfoWithStorage[127.0.0.1:35396,DS-0d5377a4-6b23-4198-a884-776ff62afb0b,DISK], DatanodeInfoWithStorage[127.0.0.1:39767,DS-16844e14-762d-44b2-8406-26c7c2774298,DISK], DatanodeInfoWithStorage[127.0.0.1:43460,DS-63b43c18-5e14-4dd3-bcc8-caf55f383974,DISK], DatanodeInfoWithStorage[127.0.0.1:43934,DS-c8db7b06-ebe3-4a12-bd1b-e47761ae7a52,DISK], DatanodeInfoWithStorage[127.0.0.1:35146,DS-e528fcd3-b60f-4856-b3e5-f76cb781dc42,DISK], DatanodeInfoWithStorage[127.0.0.1:38010,DS-34517c15-e4b0-4829-a635-82586e589fec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.noeditlogchannelflush
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-285618601-172.17.0.8-1598412184856:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45143,DS-05f605f2-eb11-42eb-92c1-fefa958cfe4b,DISK], DatanodeInfoWithStorage[127.0.0.1:34002,DS-107d912a-1a45-45c7-8055-e7b1d4b906ce,DISK], DatanodeInfoWithStorage[127.0.0.1:40079,DS-19f1f686-cf92-436f-b4cd-57b406450ce9,DISK], DatanodeInfoWithStorage[127.0.0.1:37353,DS-acc17191-3a23-4c72-8904-307a3651c95f,DISK], DatanodeInfoWithStorage[127.0.0.1:40005,DS-12381b48-b4ee-404e-bc7c-9a04bfd5464b,DISK], DatanodeInfoWithStorage[127.0.0.1:39660,DS-dbe84617-722d-420d-8885-5883cac59334,DISK], DatanodeInfoWithStorage[127.0.0.1:42025,DS-e9c11b7a-1c5a-4a5c-b02a-6b92be305e09,DISK], DatanodeInfoWithStorage[127.0.0.1:36182,DS-4e3eee04-75b5-4c19-add5-c13cc7d11748,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-285618601-172.17.0.8-1598412184856:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45143,DS-05f605f2-eb11-42eb-92c1-fefa958cfe4b,DISK], DatanodeInfoWithStorage[127.0.0.1:34002,DS-107d912a-1a45-45c7-8055-e7b1d4b906ce,DISK], DatanodeInfoWithStorage[127.0.0.1:40079,DS-19f1f686-cf92-436f-b4cd-57b406450ce9,DISK], DatanodeInfoWithStorage[127.0.0.1:37353,DS-acc17191-3a23-4c72-8904-307a3651c95f,DISK], DatanodeInfoWithStorage[127.0.0.1:40005,DS-12381b48-b4ee-404e-bc7c-9a04bfd5464b,DISK], DatanodeInfoWithStorage[127.0.0.1:39660,DS-dbe84617-722d-420d-8885-5883cac59334,DISK], DatanodeInfoWithStorage[127.0.0.1:42025,DS-e9c11b7a-1c5a-4a5c-b02a-6b92be305e09,DISK], DatanodeInfoWithStorage[127.0.0.1:36182,DS-4e3eee04-75b5-4c19-add5-c13cc7d11748,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.noeditlogchannelflush
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1284674075-172.17.0.8-1598412353977:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43531,DS-1dba0312-2a41-49ba-a70d-6a6da789c742,DISK], DatanodeInfoWithStorage[127.0.0.1:46215,DS-94e15c29-a32b-4ac5-a6f5-2c07cb83d5ac,DISK], DatanodeInfoWithStorage[127.0.0.1:46339,DS-b3c6480b-1eaa-4747-8281-8d59b873d2a7,DISK], DatanodeInfoWithStorage[127.0.0.1:32892,DS-53e69314-ca92-4d2c-91c6-1fb5a9e7444a,DISK], DatanodeInfoWithStorage[127.0.0.1:40392,DS-9cad5fb0-36b6-4ef2-8e11-dbfcc3187f7d,DISK], DatanodeInfoWithStorage[127.0.0.1:37358,DS-7e467c84-8e00-4c9f-882c-9efbd6e2af16,DISK], DatanodeInfoWithStorage[127.0.0.1:42760,DS-24c10fc5-caa6-4f84-99db-b01927cdd674,DISK], DatanodeInfoWithStorage[127.0.0.1:39539,DS-dae3b8ce-5783-4bd8-8120-72d9c94fd41a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1284674075-172.17.0.8-1598412353977:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43531,DS-1dba0312-2a41-49ba-a70d-6a6da789c742,DISK], DatanodeInfoWithStorage[127.0.0.1:46215,DS-94e15c29-a32b-4ac5-a6f5-2c07cb83d5ac,DISK], DatanodeInfoWithStorage[127.0.0.1:46339,DS-b3c6480b-1eaa-4747-8281-8d59b873d2a7,DISK], DatanodeInfoWithStorage[127.0.0.1:32892,DS-53e69314-ca92-4d2c-91c6-1fb5a9e7444a,DISK], DatanodeInfoWithStorage[127.0.0.1:40392,DS-9cad5fb0-36b6-4ef2-8e11-dbfcc3187f7d,DISK], DatanodeInfoWithStorage[127.0.0.1:37358,DS-7e467c84-8e00-4c9f-882c-9efbd6e2af16,DISK], DatanodeInfoWithStorage[127.0.0.1:42760,DS-24c10fc5-caa6-4f84-99db-b01927cdd674,DISK], DatanodeInfoWithStorage[127.0.0.1:39539,DS-dae3b8ce-5783-4bd8-8120-72d9c94fd41a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.noeditlogchannelflush
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1483458050-172.17.0.8-1598412488245:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32778,DS-90e2821f-7106-4225-af01-d1604d42c3f2,DISK], DatanodeInfoWithStorage[127.0.0.1:39047,DS-f8c87a1a-77c2-4554-9cb1-bdbe0773c0c9,DISK], DatanodeInfoWithStorage[127.0.0.1:42844,DS-cd15b356-1051-467b-9ad8-13d9559f7704,DISK], DatanodeInfoWithStorage[127.0.0.1:46017,DS-b0e25589-ddbe-46ac-9a35-0c13cbcebc3e,DISK], DatanodeInfoWithStorage[127.0.0.1:36486,DS-4ca45ea8-6608-430b-b5bc-4b4d06326989,DISK], DatanodeInfoWithStorage[127.0.0.1:41315,DS-00176706-337e-472d-9981-27d36210c359,DISK], DatanodeInfoWithStorage[127.0.0.1:43951,DS-d4687112-3228-4b08-b0d6-eebab792d8de,DISK], DatanodeInfoWithStorage[127.0.0.1:35090,DS-f941b50b-b7d2-406f-8ec7-f98b94d047d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1483458050-172.17.0.8-1598412488245:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32778,DS-90e2821f-7106-4225-af01-d1604d42c3f2,DISK], DatanodeInfoWithStorage[127.0.0.1:39047,DS-f8c87a1a-77c2-4554-9cb1-bdbe0773c0c9,DISK], DatanodeInfoWithStorage[127.0.0.1:42844,DS-cd15b356-1051-467b-9ad8-13d9559f7704,DISK], DatanodeInfoWithStorage[127.0.0.1:46017,DS-b0e25589-ddbe-46ac-9a35-0c13cbcebc3e,DISK], DatanodeInfoWithStorage[127.0.0.1:36486,DS-4ca45ea8-6608-430b-b5bc-4b4d06326989,DISK], DatanodeInfoWithStorage[127.0.0.1:41315,DS-00176706-337e-472d-9981-27d36210c359,DISK], DatanodeInfoWithStorage[127.0.0.1:43951,DS-d4687112-3228-4b08-b0d6-eebab792d8de,DISK], DatanodeInfoWithStorage[127.0.0.1:35090,DS-f941b50b-b7d2-406f-8ec7-f98b94d047d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edits.noeditlogchannelflush
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1039160315-172.17.0.8-1598412714216:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42363,DS-d65ef11f-2526-49e4-aaea-0aaf0599a565,DISK], DatanodeInfoWithStorage[127.0.0.1:35499,DS-1e7b6352-6a6e-4f04-9069-bc9c1da7b757,DISK], DatanodeInfoWithStorage[127.0.0.1:38158,DS-6781bb5d-a5ef-4160-9248-fe540c0214ba,DISK], DatanodeInfoWithStorage[127.0.0.1:45378,DS-02d9608f-c645-4591-afcb-a806ccd4da5a,DISK], DatanodeInfoWithStorage[127.0.0.1:37917,DS-68b57ad4-3ce1-4f98-9165-a82fb8a17f68,DISK], DatanodeInfoWithStorage[127.0.0.1:40255,DS-819653ca-9263-415f-abb6-fdda7df4637c,DISK], DatanodeInfoWithStorage[127.0.0.1:42845,DS-3fec02dc-58c5-4fdf-9a91-0fb09e0bbe30,DISK], DatanodeInfoWithStorage[127.0.0.1:39438,DS-d8577c39-f53b-4c07-9f93-8331fe24bc20,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1039160315-172.17.0.8-1598412714216:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42363,DS-d65ef11f-2526-49e4-aaea-0aaf0599a565,DISK], DatanodeInfoWithStorage[127.0.0.1:35499,DS-1e7b6352-6a6e-4f04-9069-bc9c1da7b757,DISK], DatanodeInfoWithStorage[127.0.0.1:38158,DS-6781bb5d-a5ef-4160-9248-fe540c0214ba,DISK], DatanodeInfoWithStorage[127.0.0.1:45378,DS-02d9608f-c645-4591-afcb-a806ccd4da5a,DISK], DatanodeInfoWithStorage[127.0.0.1:37917,DS-68b57ad4-3ce1-4f98-9165-a82fb8a17f68,DISK], DatanodeInfoWithStorage[127.0.0.1:40255,DS-819653ca-9263-415f-abb6-fdda7df4637c,DISK], DatanodeInfoWithStorage[127.0.0.1:42845,DS-3fec02dc-58c5-4fdf-9a91-0fb09e0bbe30,DISK], DatanodeInfoWithStorage[127.0.0.1:39438,DS-d8577c39-f53b-4c07-9f93-8331fe24bc20,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.noeditlogchannelflush
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1587528443-172.17.0.8-1598413641704:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38777,DS-edabb395-3651-41b6-a964-acdfd1cc19dd,DISK], DatanodeInfoWithStorage[127.0.0.1:42432,DS-113e4222-d149-456d-9dd5-099e884b46aa,DISK], DatanodeInfoWithStorage[127.0.0.1:36444,DS-7c0be4c0-0a7a-4fdc-948e-797e5b756434,DISK], DatanodeInfoWithStorage[127.0.0.1:40504,DS-01c95f96-2690-475d-b4d6-8ae9bdd27f52,DISK], DatanodeInfoWithStorage[127.0.0.1:46354,DS-40a82e70-1e86-465d-92ca-ebac08a5d322,DISK], DatanodeInfoWithStorage[127.0.0.1:46521,DS-561076bf-5557-472c-bd86-47c740db46a8,DISK], DatanodeInfoWithStorage[127.0.0.1:42459,DS-6eedc427-3e97-4112-a5c9-4e824eab6afc,DISK], DatanodeInfoWithStorage[127.0.0.1:39421,DS-6a83f89d-0634-4bcc-a026-e0bc73a74008,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1587528443-172.17.0.8-1598413641704:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38777,DS-edabb395-3651-41b6-a964-acdfd1cc19dd,DISK], DatanodeInfoWithStorage[127.0.0.1:42432,DS-113e4222-d149-456d-9dd5-099e884b46aa,DISK], DatanodeInfoWithStorage[127.0.0.1:36444,DS-7c0be4c0-0a7a-4fdc-948e-797e5b756434,DISK], DatanodeInfoWithStorage[127.0.0.1:40504,DS-01c95f96-2690-475d-b4d6-8ae9bdd27f52,DISK], DatanodeInfoWithStorage[127.0.0.1:46354,DS-40a82e70-1e86-465d-92ca-ebac08a5d322,DISK], DatanodeInfoWithStorage[127.0.0.1:46521,DS-561076bf-5557-472c-bd86-47c740db46a8,DISK], DatanodeInfoWithStorage[127.0.0.1:42459,DS-6eedc427-3e97-4112-a5c9-4e824eab6afc,DISK], DatanodeInfoWithStorage[127.0.0.1:39421,DS-6a83f89d-0634-4bcc-a026-e0bc73a74008,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.noeditlogchannelflush
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-844023661-172.17.0.8-1598413937057:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44312,DS-b8dd1356-a314-40a4-b212-e4ddd518baba,DISK], DatanodeInfoWithStorage[127.0.0.1:38142,DS-27c83f25-2fb2-4915-a758-adb561fb8f70,DISK], DatanodeInfoWithStorage[127.0.0.1:46815,DS-9fba9569-e218-4fe0-83d8-4f3070164a6b,DISK], DatanodeInfoWithStorage[127.0.0.1:42694,DS-2037249f-3e49-4598-8a82-9df9cfb5a772,DISK], DatanodeInfoWithStorage[127.0.0.1:35417,DS-68212e18-46b4-4f76-9e3d-269355cc59e9,DISK], DatanodeInfoWithStorage[127.0.0.1:35494,DS-72bfc386-1965-46db-a213-d6a94a04d839,DISK], DatanodeInfoWithStorage[127.0.0.1:42109,DS-cc60b8d9-f872-4392-bb9b-d16630733af5,DISK], DatanodeInfoWithStorage[127.0.0.1:40536,DS-2b8dc5b2-215b-4fd6-895b-227f57734898,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-844023661-172.17.0.8-1598413937057:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44312,DS-b8dd1356-a314-40a4-b212-e4ddd518baba,DISK], DatanodeInfoWithStorage[127.0.0.1:38142,DS-27c83f25-2fb2-4915-a758-adb561fb8f70,DISK], DatanodeInfoWithStorage[127.0.0.1:46815,DS-9fba9569-e218-4fe0-83d8-4f3070164a6b,DISK], DatanodeInfoWithStorage[127.0.0.1:42694,DS-2037249f-3e49-4598-8a82-9df9cfb5a772,DISK], DatanodeInfoWithStorage[127.0.0.1:35417,DS-68212e18-46b4-4f76-9e3d-269355cc59e9,DISK], DatanodeInfoWithStorage[127.0.0.1:35494,DS-72bfc386-1965-46db-a213-d6a94a04d839,DISK], DatanodeInfoWithStorage[127.0.0.1:42109,DS-cc60b8d9-f872-4392-bb9b-d16630733af5,DISK], DatanodeInfoWithStorage[127.0.0.1:40536,DS-2b8dc5b2-215b-4fd6-895b-227f57734898,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edits.noeditlogchannelflush
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-187936298-172.17.0.8-1598413967850:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38712,DS-461d68b6-2234-49fe-9431-558b93eeac2f,DISK], DatanodeInfoWithStorage[127.0.0.1:36814,DS-1ae38a0f-625d-468b-83ff-81df1d9cb37b,DISK], DatanodeInfoWithStorage[127.0.0.1:33866,DS-c3ae663b-770a-4b2e-bb12-a6dd0713f6d8,DISK], DatanodeInfoWithStorage[127.0.0.1:37781,DS-85c5b6c7-7727-403f-9e39-3686a2328b11,DISK], DatanodeInfoWithStorage[127.0.0.1:40157,DS-55b0ba05-237a-49bf-82a7-cc1b11213065,DISK], DatanodeInfoWithStorage[127.0.0.1:32969,DS-ae12f60b-e03b-40ac-b10c-d9522780b2e7,DISK], DatanodeInfoWithStorage[127.0.0.1:44494,DS-856ac400-a8c0-49fb-adf7-df364838085a,DISK], DatanodeInfoWithStorage[127.0.0.1:43519,DS-940b5da5-d323-4558-aae1-0607d91a41ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-187936298-172.17.0.8-1598413967850:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38712,DS-461d68b6-2234-49fe-9431-558b93eeac2f,DISK], DatanodeInfoWithStorage[127.0.0.1:36814,DS-1ae38a0f-625d-468b-83ff-81df1d9cb37b,DISK], DatanodeInfoWithStorage[127.0.0.1:33866,DS-c3ae663b-770a-4b2e-bb12-a6dd0713f6d8,DISK], DatanodeInfoWithStorage[127.0.0.1:37781,DS-85c5b6c7-7727-403f-9e39-3686a2328b11,DISK], DatanodeInfoWithStorage[127.0.0.1:40157,DS-55b0ba05-237a-49bf-82a7-cc1b11213065,DISK], DatanodeInfoWithStorage[127.0.0.1:32969,DS-ae12f60b-e03b-40ac-b10c-d9522780b2e7,DISK], DatanodeInfoWithStorage[127.0.0.1:44494,DS-856ac400-a8c0-49fb-adf7-df364838085a,DISK], DatanodeInfoWithStorage[127.0.0.1:43519,DS-940b5da5-d323-4558-aae1-0607d91a41ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.noeditlogchannelflush
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1161169816-172.17.0.8-1598414093567:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40996,DS-d7120160-b956-4892-acc3-89e0c0fd516a,DISK], DatanodeInfoWithStorage[127.0.0.1:37162,DS-cdc08f8b-d7ee-4205-aeb3-1f618a40969c,DISK], DatanodeInfoWithStorage[127.0.0.1:35820,DS-54408b39-d5e2-4c4a-a1bc-797bedcb2b15,DISK], DatanodeInfoWithStorage[127.0.0.1:34018,DS-eee37b22-2fd0-449a-aa64-6f5e3bd6030e,DISK], DatanodeInfoWithStorage[127.0.0.1:43329,DS-0cdcfdb3-90ac-4dd6-a4c5-2282c9d30162,DISK], DatanodeInfoWithStorage[127.0.0.1:33174,DS-b71d39fc-5fd4-4dcb-92f1-671d1433244a,DISK], DatanodeInfoWithStorage[127.0.0.1:35347,DS-e35e5a0c-a26a-4d16-bfa3-62330404ea00,DISK], DatanodeInfoWithStorage[127.0.0.1:37525,DS-8652baa5-bff4-42ae-ba72-edca322d3a70,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1161169816-172.17.0.8-1598414093567:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40996,DS-d7120160-b956-4892-acc3-89e0c0fd516a,DISK], DatanodeInfoWithStorage[127.0.0.1:37162,DS-cdc08f8b-d7ee-4205-aeb3-1f618a40969c,DISK], DatanodeInfoWithStorage[127.0.0.1:35820,DS-54408b39-d5e2-4c4a-a1bc-797bedcb2b15,DISK], DatanodeInfoWithStorage[127.0.0.1:34018,DS-eee37b22-2fd0-449a-aa64-6f5e3bd6030e,DISK], DatanodeInfoWithStorage[127.0.0.1:43329,DS-0cdcfdb3-90ac-4dd6-a4c5-2282c9d30162,DISK], DatanodeInfoWithStorage[127.0.0.1:33174,DS-b71d39fc-5fd4-4dcb-92f1-671d1433244a,DISK], DatanodeInfoWithStorage[127.0.0.1:35347,DS-e35e5a0c-a26a-4d16-bfa3-62330404ea00,DISK], DatanodeInfoWithStorage[127.0.0.1:37525,DS-8652baa5-bff4-42ae-ba72-edca322d3a70,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 4957
