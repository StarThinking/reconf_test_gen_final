reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-273557475-172.17.0.18-1598472230319:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34992,DS-241ef3be-ef86-4b99-bcf3-aec213d1923a,DISK], DatanodeInfoWithStorage[127.0.0.1:43276,DS-7874f902-932a-4e13-8f90-56c7753c3ed4,DISK], DatanodeInfoWithStorage[127.0.0.1:42707,DS-32ca10cf-df72-424e-9aa0-140afc360579,DISK], DatanodeInfoWithStorage[127.0.0.1:41834,DS-4590d32f-c62c-4f47-bd0a-dba159c0af73,DISK], DatanodeInfoWithStorage[127.0.0.1:33453,DS-c7d10157-b928-452b-9b1d-ce2069661fde,DISK], DatanodeInfoWithStorage[127.0.0.1:32956,DS-fd934d07-e2b2-4b9c-aa95-900b22a7d168,DISK], DatanodeInfoWithStorage[127.0.0.1:41092,DS-aaaaefe3-2185-4c11-8b44-3252bcec2242,DISK], DatanodeInfoWithStorage[127.0.0.1:40112,DS-6db38445-ce85-4eb9-b5f8-eaf791fc26e1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-273557475-172.17.0.18-1598472230319:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34992,DS-241ef3be-ef86-4b99-bcf3-aec213d1923a,DISK], DatanodeInfoWithStorage[127.0.0.1:43276,DS-7874f902-932a-4e13-8f90-56c7753c3ed4,DISK], DatanodeInfoWithStorage[127.0.0.1:42707,DS-32ca10cf-df72-424e-9aa0-140afc360579,DISK], DatanodeInfoWithStorage[127.0.0.1:41834,DS-4590d32f-c62c-4f47-bd0a-dba159c0af73,DISK], DatanodeInfoWithStorage[127.0.0.1:33453,DS-c7d10157-b928-452b-9b1d-ce2069661fde,DISK], DatanodeInfoWithStorage[127.0.0.1:32956,DS-fd934d07-e2b2-4b9c-aa95-900b22a7d168,DISK], DatanodeInfoWithStorage[127.0.0.1:41092,DS-aaaaefe3-2185-4c11-8b44-3252bcec2242,DISK], DatanodeInfoWithStorage[127.0.0.1:40112,DS-6db38445-ce85-4eb9-b5f8-eaf791fc26e1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-997282694-172.17.0.18-1598472415375:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38394,DS-c70e9c22-efa0-4385-ae5f-4c3cb3afd571,DISK], DatanodeInfoWithStorage[127.0.0.1:44336,DS-593ac1fd-b35e-409a-9721-e0e34aad77b6,DISK], DatanodeInfoWithStorage[127.0.0.1:36328,DS-4d5ccd4f-ac1e-4127-b0e8-57a49435be05,DISK], DatanodeInfoWithStorage[127.0.0.1:43221,DS-b72e9092-7dca-41fb-8d22-825f31273023,DISK], DatanodeInfoWithStorage[127.0.0.1:45881,DS-1995df9d-b859-4eb5-bf09-f92408be77d6,DISK], DatanodeInfoWithStorage[127.0.0.1:40221,DS-af077d33-bb2d-452c-8301-6a1fea9668c3,DISK], DatanodeInfoWithStorage[127.0.0.1:35879,DS-375245f7-7507-4882-b05d-816334f950e0,DISK], DatanodeInfoWithStorage[127.0.0.1:39629,DS-415bcaa4-6f06-413c-b298-27d38566b2d3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-997282694-172.17.0.18-1598472415375:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38394,DS-c70e9c22-efa0-4385-ae5f-4c3cb3afd571,DISK], DatanodeInfoWithStorage[127.0.0.1:44336,DS-593ac1fd-b35e-409a-9721-e0e34aad77b6,DISK], DatanodeInfoWithStorage[127.0.0.1:36328,DS-4d5ccd4f-ac1e-4127-b0e8-57a49435be05,DISK], DatanodeInfoWithStorage[127.0.0.1:43221,DS-b72e9092-7dca-41fb-8d22-825f31273023,DISK], DatanodeInfoWithStorage[127.0.0.1:45881,DS-1995df9d-b859-4eb5-bf09-f92408be77d6,DISK], DatanodeInfoWithStorage[127.0.0.1:40221,DS-af077d33-bb2d-452c-8301-6a1fea9668c3,DISK], DatanodeInfoWithStorage[127.0.0.1:35879,DS-375245f7-7507-4882-b05d-816334f950e0,DISK], DatanodeInfoWithStorage[127.0.0.1:39629,DS-415bcaa4-6f06-413c-b298-27d38566b2d3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-95927943-172.17.0.18-1598472488089:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38689,DS-5eeb8baa-edd9-4cd7-b2ae-d0c8d6297e05,DISK], DatanodeInfoWithStorage[127.0.0.1:35293,DS-2631eadb-7a85-4cc2-9a59-ec9019213922,DISK], DatanodeInfoWithStorage[127.0.0.1:40447,DS-dd47bf73-99c4-469b-a211-cb91e02d511d,DISK], DatanodeInfoWithStorage[127.0.0.1:44494,DS-96e9a2c5-ebb6-4987-a75d-7fbfa53579a2,DISK], DatanodeInfoWithStorage[127.0.0.1:39605,DS-46f02d3f-6a32-4195-9566-240ec4a0bd53,DISK], DatanodeInfoWithStorage[127.0.0.1:39045,DS-f21a361b-4e6b-4dc9-8220-3f26b2708ce2,DISK], DatanodeInfoWithStorage[127.0.0.1:34593,DS-ea0b7e6d-2ae6-4565-8c83-630315cfe028,DISK], DatanodeInfoWithStorage[127.0.0.1:45563,DS-e23c042b-813c-4bce-af0a-3b7d7d26242e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-95927943-172.17.0.18-1598472488089:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38689,DS-5eeb8baa-edd9-4cd7-b2ae-d0c8d6297e05,DISK], DatanodeInfoWithStorage[127.0.0.1:35293,DS-2631eadb-7a85-4cc2-9a59-ec9019213922,DISK], DatanodeInfoWithStorage[127.0.0.1:40447,DS-dd47bf73-99c4-469b-a211-cb91e02d511d,DISK], DatanodeInfoWithStorage[127.0.0.1:44494,DS-96e9a2c5-ebb6-4987-a75d-7fbfa53579a2,DISK], DatanodeInfoWithStorage[127.0.0.1:39605,DS-46f02d3f-6a32-4195-9566-240ec4a0bd53,DISK], DatanodeInfoWithStorage[127.0.0.1:39045,DS-f21a361b-4e6b-4dc9-8220-3f26b2708ce2,DISK], DatanodeInfoWithStorage[127.0.0.1:34593,DS-ea0b7e6d-2ae6-4565-8c83-630315cfe028,DISK], DatanodeInfoWithStorage[127.0.0.1:45563,DS-e23c042b-813c-4bce-af0a-3b7d7d26242e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1561800326-172.17.0.18-1598472526989:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41191,DS-7fb3176b-d501-498e-8fb6-92e088207da3,DISK], DatanodeInfoWithStorage[127.0.0.1:42048,DS-fb4b8e37-f485-418b-89ed-4cfa8ec1c987,DISK], DatanodeInfoWithStorage[127.0.0.1:32784,DS-f7176e77-0978-4299-96c0-2216a6e510b0,DISK], DatanodeInfoWithStorage[127.0.0.1:33968,DS-8d93bed5-a060-4aa2-ac01-930b65860b23,DISK], DatanodeInfoWithStorage[127.0.0.1:41743,DS-69b2a153-4aba-4681-ac61-a8d67837ff05,DISK], DatanodeInfoWithStorage[127.0.0.1:41407,DS-a6852df2-b7c9-4d2d-9228-b8d45dba635e,DISK], DatanodeInfoWithStorage[127.0.0.1:36472,DS-820ea483-8b12-45a5-82f3-a3815cf47af0,DISK], DatanodeInfoWithStorage[127.0.0.1:37225,DS-9c4de6c7-7cbb-4bed-829b-6e746d6ea1af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1561800326-172.17.0.18-1598472526989:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41191,DS-7fb3176b-d501-498e-8fb6-92e088207da3,DISK], DatanodeInfoWithStorage[127.0.0.1:42048,DS-fb4b8e37-f485-418b-89ed-4cfa8ec1c987,DISK], DatanodeInfoWithStorage[127.0.0.1:32784,DS-f7176e77-0978-4299-96c0-2216a6e510b0,DISK], DatanodeInfoWithStorage[127.0.0.1:33968,DS-8d93bed5-a060-4aa2-ac01-930b65860b23,DISK], DatanodeInfoWithStorage[127.0.0.1:41743,DS-69b2a153-4aba-4681-ac61-a8d67837ff05,DISK], DatanodeInfoWithStorage[127.0.0.1:41407,DS-a6852df2-b7c9-4d2d-9228-b8d45dba635e,DISK], DatanodeInfoWithStorage[127.0.0.1:36472,DS-820ea483-8b12-45a5-82f3-a3815cf47af0,DISK], DatanodeInfoWithStorage[127.0.0.1:37225,DS-9c4de6c7-7cbb-4bed-829b-6e746d6ea1af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1130513887-172.17.0.18-1598472714055:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44418,DS-5e82408c-965c-441c-a542-20c9cbd0e54a,DISK], DatanodeInfoWithStorage[127.0.0.1:37683,DS-6b01a819-7bc3-44fd-b1fc-5e52f05e8e57,DISK], DatanodeInfoWithStorage[127.0.0.1:40393,DS-afe37f79-0b1d-4311-a52f-d4a9f14c7a62,DISK], DatanodeInfoWithStorage[127.0.0.1:36661,DS-6c300d08-37ed-4d3f-838a-4447aa5b6af3,DISK], DatanodeInfoWithStorage[127.0.0.1:46351,DS-015fa00c-7441-4209-8fb0-93c83fa7d4a7,DISK], DatanodeInfoWithStorage[127.0.0.1:33072,DS-ee60748f-f520-462b-a17b-d4cd816cc48f,DISK], DatanodeInfoWithStorage[127.0.0.1:36769,DS-2c37a4b0-9efb-4643-b047-8f8911482792,DISK], DatanodeInfoWithStorage[127.0.0.1:43154,DS-c6e4ed6c-d113-49b5-9e5d-55a654478d6d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1130513887-172.17.0.18-1598472714055:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44418,DS-5e82408c-965c-441c-a542-20c9cbd0e54a,DISK], DatanodeInfoWithStorage[127.0.0.1:37683,DS-6b01a819-7bc3-44fd-b1fc-5e52f05e8e57,DISK], DatanodeInfoWithStorage[127.0.0.1:40393,DS-afe37f79-0b1d-4311-a52f-d4a9f14c7a62,DISK], DatanodeInfoWithStorage[127.0.0.1:36661,DS-6c300d08-37ed-4d3f-838a-4447aa5b6af3,DISK], DatanodeInfoWithStorage[127.0.0.1:46351,DS-015fa00c-7441-4209-8fb0-93c83fa7d4a7,DISK], DatanodeInfoWithStorage[127.0.0.1:33072,DS-ee60748f-f520-462b-a17b-d4cd816cc48f,DISK], DatanodeInfoWithStorage[127.0.0.1:36769,DS-2c37a4b0-9efb-4643-b047-8f8911482792,DISK], DatanodeInfoWithStorage[127.0.0.1:43154,DS-c6e4ed6c-d113-49b5-9e5d-55a654478d6d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2042103693-172.17.0.18-1598472815081:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46811,DS-5543c94a-87b5-44ca-ab6b-dbb01274711b,DISK], DatanodeInfoWithStorage[127.0.0.1:34382,DS-1d55f3ac-5fd3-45d8-b63c-05566a3d063c,DISK], DatanodeInfoWithStorage[127.0.0.1:32903,DS-e295c0b2-1711-4d12-9ad6-0154e698b04d,DISK], DatanodeInfoWithStorage[127.0.0.1:35932,DS-212886a6-6b80-48dc-8b5d-717ca6bfaf1d,DISK], DatanodeInfoWithStorage[127.0.0.1:45848,DS-78c589a1-6e22-46df-bcca-3788a5a36a27,DISK], DatanodeInfoWithStorage[127.0.0.1:44904,DS-b991e141-e80d-4231-8639-d177de7391f1,DISK], DatanodeInfoWithStorage[127.0.0.1:33501,DS-d5f1fb26-a669-43f9-b36e-a7d85627c556,DISK], DatanodeInfoWithStorage[127.0.0.1:33873,DS-acde2e69-465a-4ba0-8dc9-10133044e799,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2042103693-172.17.0.18-1598472815081:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46811,DS-5543c94a-87b5-44ca-ab6b-dbb01274711b,DISK], DatanodeInfoWithStorage[127.0.0.1:34382,DS-1d55f3ac-5fd3-45d8-b63c-05566a3d063c,DISK], DatanodeInfoWithStorage[127.0.0.1:32903,DS-e295c0b2-1711-4d12-9ad6-0154e698b04d,DISK], DatanodeInfoWithStorage[127.0.0.1:35932,DS-212886a6-6b80-48dc-8b5d-717ca6bfaf1d,DISK], DatanodeInfoWithStorage[127.0.0.1:45848,DS-78c589a1-6e22-46df-bcca-3788a5a36a27,DISK], DatanodeInfoWithStorage[127.0.0.1:44904,DS-b991e141-e80d-4231-8639-d177de7391f1,DISK], DatanodeInfoWithStorage[127.0.0.1:33501,DS-d5f1fb26-a669-43f9-b36e-a7d85627c556,DISK], DatanodeInfoWithStorage[127.0.0.1:33873,DS-acde2e69-465a-4ba0-8dc9-10133044e799,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-549895282-172.17.0.18-1598472850457:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34586,DS-3924e940-7e7a-426b-a7ce-9a16f6688133,DISK], DatanodeInfoWithStorage[127.0.0.1:35925,DS-52020062-bd9b-469e-bf68-95e4085a394b,DISK], DatanodeInfoWithStorage[127.0.0.1:46360,DS-1a8ccf7c-a029-45bc-91b9-edcc2be7afee,DISK], DatanodeInfoWithStorage[127.0.0.1:36057,DS-41476e53-bf28-45bd-9699-fd0f1f383b3e,DISK], DatanodeInfoWithStorage[127.0.0.1:45133,DS-2bd49a9c-d915-4a48-b508-494269f32bd0,DISK], DatanodeInfoWithStorage[127.0.0.1:41734,DS-8d48ac3a-ec15-4adb-9e0d-33726cd49416,DISK], DatanodeInfoWithStorage[127.0.0.1:41198,DS-2d0a86a3-33e4-4947-b680-424efe04fbe7,DISK], DatanodeInfoWithStorage[127.0.0.1:35911,DS-f98c75ff-7da5-4c29-8155-07ef284bb841,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-549895282-172.17.0.18-1598472850457:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34586,DS-3924e940-7e7a-426b-a7ce-9a16f6688133,DISK], DatanodeInfoWithStorage[127.0.0.1:35925,DS-52020062-bd9b-469e-bf68-95e4085a394b,DISK], DatanodeInfoWithStorage[127.0.0.1:46360,DS-1a8ccf7c-a029-45bc-91b9-edcc2be7afee,DISK], DatanodeInfoWithStorage[127.0.0.1:36057,DS-41476e53-bf28-45bd-9699-fd0f1f383b3e,DISK], DatanodeInfoWithStorage[127.0.0.1:45133,DS-2bd49a9c-d915-4a48-b508-494269f32bd0,DISK], DatanodeInfoWithStorage[127.0.0.1:41734,DS-8d48ac3a-ec15-4adb-9e0d-33726cd49416,DISK], DatanodeInfoWithStorage[127.0.0.1:41198,DS-2d0a86a3-33e4-4947-b680-424efe04fbe7,DISK], DatanodeInfoWithStorage[127.0.0.1:35911,DS-f98c75ff-7da5-4c29-8155-07ef284bb841,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-837551724-172.17.0.18-1598472891729:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40370,DS-3ef7d588-b6c6-4f8e-888f-af68f902e22d,DISK], DatanodeInfoWithStorage[127.0.0.1:40901,DS-180cbcd1-aec4-40f3-bbee-94926b1ca74d,DISK], DatanodeInfoWithStorage[127.0.0.1:38257,DS-9c084c00-68a4-4509-b9df-b8cdcc847b54,DISK], DatanodeInfoWithStorage[127.0.0.1:37363,DS-31d1e82b-cde5-4b89-92a1-9c7183ffc102,DISK], DatanodeInfoWithStorage[127.0.0.1:35614,DS-9b8648cb-d26e-483d-a945-cd01df22c848,DISK], DatanodeInfoWithStorage[127.0.0.1:38124,DS-6d3c719e-eb23-406b-8860-0d6c681f2cce,DISK], DatanodeInfoWithStorage[127.0.0.1:42090,DS-83ad6e00-0f04-4bd6-838d-4e8c88b8f6f6,DISK], DatanodeInfoWithStorage[127.0.0.1:33828,DS-b6bbeaed-14bd-4f1b-99f6-fe8ac83beb66,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-837551724-172.17.0.18-1598472891729:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40370,DS-3ef7d588-b6c6-4f8e-888f-af68f902e22d,DISK], DatanodeInfoWithStorage[127.0.0.1:40901,DS-180cbcd1-aec4-40f3-bbee-94926b1ca74d,DISK], DatanodeInfoWithStorage[127.0.0.1:38257,DS-9c084c00-68a4-4509-b9df-b8cdcc847b54,DISK], DatanodeInfoWithStorage[127.0.0.1:37363,DS-31d1e82b-cde5-4b89-92a1-9c7183ffc102,DISK], DatanodeInfoWithStorage[127.0.0.1:35614,DS-9b8648cb-d26e-483d-a945-cd01df22c848,DISK], DatanodeInfoWithStorage[127.0.0.1:38124,DS-6d3c719e-eb23-406b-8860-0d6c681f2cce,DISK], DatanodeInfoWithStorage[127.0.0.1:42090,DS-83ad6e00-0f04-4bd6-838d-4e8c88b8f6f6,DISK], DatanodeInfoWithStorage[127.0.0.1:33828,DS-b6bbeaed-14bd-4f1b-99f6-fe8ac83beb66,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1233913232-172.17.0.18-1598472948943:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38610,DS-cb0be3e2-cc2b-4139-b435-fbe64371a79a,DISK], DatanodeInfoWithStorage[127.0.0.1:35048,DS-76a8b206-c65a-42d4-bad4-bdcb486c34a2,DISK], DatanodeInfoWithStorage[127.0.0.1:41882,DS-27b96e28-bb0a-4e57-bd4e-1dc0b6193d25,DISK], DatanodeInfoWithStorage[127.0.0.1:32919,DS-fe178f09-5662-42fa-8853-d69dc7b00108,DISK], DatanodeInfoWithStorage[127.0.0.1:37058,DS-f26f608b-5e83-4ef7-86ba-ffa5d2343e98,DISK], DatanodeInfoWithStorage[127.0.0.1:38038,DS-548846ff-b826-4353-a251-aec9f0390f89,DISK], DatanodeInfoWithStorage[127.0.0.1:37730,DS-6a096526-b0dd-4314-b153-2d0447dae8eb,DISK], DatanodeInfoWithStorage[127.0.0.1:38709,DS-76a14d29-0048-4840-9a1e-c5edd9b8127a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1233913232-172.17.0.18-1598472948943:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38610,DS-cb0be3e2-cc2b-4139-b435-fbe64371a79a,DISK], DatanodeInfoWithStorage[127.0.0.1:35048,DS-76a8b206-c65a-42d4-bad4-bdcb486c34a2,DISK], DatanodeInfoWithStorage[127.0.0.1:41882,DS-27b96e28-bb0a-4e57-bd4e-1dc0b6193d25,DISK], DatanodeInfoWithStorage[127.0.0.1:32919,DS-fe178f09-5662-42fa-8853-d69dc7b00108,DISK], DatanodeInfoWithStorage[127.0.0.1:37058,DS-f26f608b-5e83-4ef7-86ba-ffa5d2343e98,DISK], DatanodeInfoWithStorage[127.0.0.1:38038,DS-548846ff-b826-4353-a251-aec9f0390f89,DISK], DatanodeInfoWithStorage[127.0.0.1:37730,DS-6a096526-b0dd-4314-b153-2d0447dae8eb,DISK], DatanodeInfoWithStorage[127.0.0.1:38709,DS-76a14d29-0048-4840-9a1e-c5edd9b8127a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-590623036-172.17.0.18-1598473243152:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34101,DS-8123cb49-47fd-44c6-b07b-dd6a8f26714c,DISK], DatanodeInfoWithStorage[127.0.0.1:38699,DS-7988b07e-bd36-4ed6-a99c-8d87d0994f69,DISK], DatanodeInfoWithStorage[127.0.0.1:43500,DS-44e871b8-39de-4590-b61a-ab3ec90756f1,DISK], DatanodeInfoWithStorage[127.0.0.1:46705,DS-7509f69a-db16-47f2-883f-ab17b00f7721,DISK], DatanodeInfoWithStorage[127.0.0.1:39706,DS-b91c33fd-126e-47f1-89f3-8e58975f8710,DISK], DatanodeInfoWithStorage[127.0.0.1:34892,DS-73d7638f-6033-4641-aa9a-2439d2018d63,DISK], DatanodeInfoWithStorage[127.0.0.1:40160,DS-080f249e-d57a-4b54-ae20-4c9d300cd59d,DISK], DatanodeInfoWithStorage[127.0.0.1:42989,DS-4e736fe3-66f7-4efc-bd3b-05d4573cf88b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-590623036-172.17.0.18-1598473243152:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34101,DS-8123cb49-47fd-44c6-b07b-dd6a8f26714c,DISK], DatanodeInfoWithStorage[127.0.0.1:38699,DS-7988b07e-bd36-4ed6-a99c-8d87d0994f69,DISK], DatanodeInfoWithStorage[127.0.0.1:43500,DS-44e871b8-39de-4590-b61a-ab3ec90756f1,DISK], DatanodeInfoWithStorage[127.0.0.1:46705,DS-7509f69a-db16-47f2-883f-ab17b00f7721,DISK], DatanodeInfoWithStorage[127.0.0.1:39706,DS-b91c33fd-126e-47f1-89f3-8e58975f8710,DISK], DatanodeInfoWithStorage[127.0.0.1:34892,DS-73d7638f-6033-4641-aa9a-2439d2018d63,DISK], DatanodeInfoWithStorage[127.0.0.1:40160,DS-080f249e-d57a-4b54-ae20-4c9d300cd59d,DISK], DatanodeInfoWithStorage[127.0.0.1:42989,DS-4e736fe3-66f7-4efc-bd3b-05d4573cf88b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-148005162-172.17.0.18-1598473277779:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41241,DS-84e1f182-8c8b-4ca3-8d33-07e7e8857497,DISK], DatanodeInfoWithStorage[127.0.0.1:37421,DS-0443f7ad-fa84-4312-b826-d1ae4b2c2140,DISK], DatanodeInfoWithStorage[127.0.0.1:43892,DS-0b2a20a3-e891-41b5-a87a-72b1b784eea8,DISK], DatanodeInfoWithStorage[127.0.0.1:46832,DS-01772ce9-dd4e-4ea9-a149-9788ccafb339,DISK], DatanodeInfoWithStorage[127.0.0.1:39546,DS-b86bf132-7b99-40c0-a3e5-8b76cf89e69b,DISK], DatanodeInfoWithStorage[127.0.0.1:36917,DS-0e1393ab-10cd-4f1c-b7b9-4afcaacacd3f,DISK], DatanodeInfoWithStorage[127.0.0.1:43067,DS-2c5cc5ff-389d-4e4e-8e60-dfdd2d7d7706,DISK], DatanodeInfoWithStorage[127.0.0.1:44303,DS-610d9f11-c6a8-464a-97b9-033264cd9850,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-148005162-172.17.0.18-1598473277779:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41241,DS-84e1f182-8c8b-4ca3-8d33-07e7e8857497,DISK], DatanodeInfoWithStorage[127.0.0.1:37421,DS-0443f7ad-fa84-4312-b826-d1ae4b2c2140,DISK], DatanodeInfoWithStorage[127.0.0.1:43892,DS-0b2a20a3-e891-41b5-a87a-72b1b784eea8,DISK], DatanodeInfoWithStorage[127.0.0.1:46832,DS-01772ce9-dd4e-4ea9-a149-9788ccafb339,DISK], DatanodeInfoWithStorage[127.0.0.1:39546,DS-b86bf132-7b99-40c0-a3e5-8b76cf89e69b,DISK], DatanodeInfoWithStorage[127.0.0.1:36917,DS-0e1393ab-10cd-4f1c-b7b9-4afcaacacd3f,DISK], DatanodeInfoWithStorage[127.0.0.1:43067,DS-2c5cc5ff-389d-4e4e-8e60-dfdd2d7d7706,DISK], DatanodeInfoWithStorage[127.0.0.1:44303,DS-610d9f11-c6a8-464a-97b9-033264cd9850,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-487944740-172.17.0.18-1598473310156:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38960,DS-6c9b6652-3fe5-4010-bb1c-86d2301d73ac,DISK], DatanodeInfoWithStorage[127.0.0.1:43752,DS-62bca823-3311-48e5-9105-ba57b7715b50,DISK], DatanodeInfoWithStorage[127.0.0.1:42731,DS-56c5f779-5afb-4d35-bc92-44c5b369662d,DISK], DatanodeInfoWithStorage[127.0.0.1:45734,DS-a1b8634d-b0f1-4c8e-a777-6e4e5780dce4,DISK], DatanodeInfoWithStorage[127.0.0.1:34962,DS-eca2b054-4985-4cc4-bcea-48f764fbfca5,DISK], DatanodeInfoWithStorage[127.0.0.1:43165,DS-36c344a4-7474-4961-a9fb-ea364c0cc896,DISK], DatanodeInfoWithStorage[127.0.0.1:41121,DS-4a578e3d-16b1-466e-a0db-915d45a237a9,DISK], DatanodeInfoWithStorage[127.0.0.1:34082,DS-ef8b3dc3-9420-495f-981b-047eaaeeb477,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-487944740-172.17.0.18-1598473310156:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38960,DS-6c9b6652-3fe5-4010-bb1c-86d2301d73ac,DISK], DatanodeInfoWithStorage[127.0.0.1:43752,DS-62bca823-3311-48e5-9105-ba57b7715b50,DISK], DatanodeInfoWithStorage[127.0.0.1:42731,DS-56c5f779-5afb-4d35-bc92-44c5b369662d,DISK], DatanodeInfoWithStorage[127.0.0.1:45734,DS-a1b8634d-b0f1-4c8e-a777-6e4e5780dce4,DISK], DatanodeInfoWithStorage[127.0.0.1:34962,DS-eca2b054-4985-4cc4-bcea-48f764fbfca5,DISK], DatanodeInfoWithStorage[127.0.0.1:43165,DS-36c344a4-7474-4961-a9fb-ea364c0cc896,DISK], DatanodeInfoWithStorage[127.0.0.1:41121,DS-4a578e3d-16b1-466e-a0db-915d45a237a9,DISK], DatanodeInfoWithStorage[127.0.0.1:34082,DS-ef8b3dc3-9420-495f-981b-047eaaeeb477,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2099946733-172.17.0.18-1598473713972:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40936,DS-373235f5-891e-4802-a58e-d20973dc8620,DISK], DatanodeInfoWithStorage[127.0.0.1:45792,DS-2ab0faf0-d87c-41a4-90ac-f1dc364be271,DISK], DatanodeInfoWithStorage[127.0.0.1:42706,DS-9f9f7cb9-103e-41b3-b922-b085954f17b2,DISK], DatanodeInfoWithStorage[127.0.0.1:42835,DS-2c700ece-03df-46c9-9d0e-92d451cf56fc,DISK], DatanodeInfoWithStorage[127.0.0.1:35211,DS-799a931c-4808-4f9a-aa49-75cd1bf8fada,DISK], DatanodeInfoWithStorage[127.0.0.1:36457,DS-5b320ed7-3cea-458e-9327-9a033e887375,DISK], DatanodeInfoWithStorage[127.0.0.1:38398,DS-b7cc3293-484e-479b-aec9-b3368a3dab47,DISK], DatanodeInfoWithStorage[127.0.0.1:43429,DS-65d01308-7b27-4a14-b11c-2f5cf6e6ea8b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2099946733-172.17.0.18-1598473713972:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40936,DS-373235f5-891e-4802-a58e-d20973dc8620,DISK], DatanodeInfoWithStorage[127.0.0.1:45792,DS-2ab0faf0-d87c-41a4-90ac-f1dc364be271,DISK], DatanodeInfoWithStorage[127.0.0.1:42706,DS-9f9f7cb9-103e-41b3-b922-b085954f17b2,DISK], DatanodeInfoWithStorage[127.0.0.1:42835,DS-2c700ece-03df-46c9-9d0e-92d451cf56fc,DISK], DatanodeInfoWithStorage[127.0.0.1:35211,DS-799a931c-4808-4f9a-aa49-75cd1bf8fada,DISK], DatanodeInfoWithStorage[127.0.0.1:36457,DS-5b320ed7-3cea-458e-9327-9a033e887375,DISK], DatanodeInfoWithStorage[127.0.0.1:38398,DS-b7cc3293-484e-479b-aec9-b3368a3dab47,DISK], DatanodeInfoWithStorage[127.0.0.1:43429,DS-65d01308-7b27-4a14-b11c-2f5cf6e6ea8b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-245343599-172.17.0.18-1598473729974:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46212,DS-6c95c13c-de84-44a5-a46d-c9df09db38ae,DISK], DatanodeInfoWithStorage[127.0.0.1:40957,DS-43194f60-aa31-4c9c-a4f4-40eaad75cd37,DISK], DatanodeInfoWithStorage[127.0.0.1:37526,DS-372ebc25-49e2-4d9c-a5c5-8aa45529fd59,DISK], DatanodeInfoWithStorage[127.0.0.1:37484,DS-94fa259b-6118-4938-9d11-25b6de2b2c1b,DISK], DatanodeInfoWithStorage[127.0.0.1:36255,DS-e580febf-b2d6-464e-8385-648cb0316bed,DISK], DatanodeInfoWithStorage[127.0.0.1:42996,DS-2167f93d-cdeb-4e0d-aaa2-1315c47d1136,DISK], DatanodeInfoWithStorage[127.0.0.1:37036,DS-9847e0a1-5dd7-473c-95cb-cfcdce01fd05,DISK], DatanodeInfoWithStorage[127.0.0.1:38769,DS-3a49d760-ecef-4fb7-8879-57e439074ed8,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-245343599-172.17.0.18-1598473729974:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46212,DS-6c95c13c-de84-44a5-a46d-c9df09db38ae,DISK], DatanodeInfoWithStorage[127.0.0.1:40957,DS-43194f60-aa31-4c9c-a4f4-40eaad75cd37,DISK], DatanodeInfoWithStorage[127.0.0.1:37526,DS-372ebc25-49e2-4d9c-a5c5-8aa45529fd59,DISK], DatanodeInfoWithStorage[127.0.0.1:37484,DS-94fa259b-6118-4938-9d11-25b6de2b2c1b,DISK], DatanodeInfoWithStorage[127.0.0.1:36255,DS-e580febf-b2d6-464e-8385-648cb0316bed,DISK], DatanodeInfoWithStorage[127.0.0.1:42996,DS-2167f93d-cdeb-4e0d-aaa2-1315c47d1136,DISK], DatanodeInfoWithStorage[127.0.0.1:37036,DS-9847e0a1-5dd7-473c-95cb-cfcdce01fd05,DISK], DatanodeInfoWithStorage[127.0.0.1:38769,DS-3a49d760-ecef-4fb7-8879-57e439074ed8,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1572273489-172.17.0.18-1598473887970:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36725,DS-2cfb8dc2-8d27-405c-a064-ef7370c1308f,DISK], DatanodeInfoWithStorage[127.0.0.1:38945,DS-ec3f9295-2239-4580-b136-ccfe76ffea9d,DISK], DatanodeInfoWithStorage[127.0.0.1:38481,DS-2aa0bb9c-ee3d-4cc1-b6fd-708b0470621c,DISK], DatanodeInfoWithStorage[127.0.0.1:38941,DS-e2debe47-de2c-45a3-9ea1-a13e10f3246b,DISK], DatanodeInfoWithStorage[127.0.0.1:37866,DS-f0c214e4-f4e1-4085-acbc-3fb4c36ece94,DISK], DatanodeInfoWithStorage[127.0.0.1:44741,DS-4f54565b-71be-483f-a507-3ce73c6955ef,DISK], DatanodeInfoWithStorage[127.0.0.1:44023,DS-211d481a-9b8a-4a7c-a0c6-258c050b68cd,DISK], DatanodeInfoWithStorage[127.0.0.1:37364,DS-27ae0d40-fb3b-46d7-943b-ab7b116760ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1572273489-172.17.0.18-1598473887970:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36725,DS-2cfb8dc2-8d27-405c-a064-ef7370c1308f,DISK], DatanodeInfoWithStorage[127.0.0.1:38945,DS-ec3f9295-2239-4580-b136-ccfe76ffea9d,DISK], DatanodeInfoWithStorage[127.0.0.1:38481,DS-2aa0bb9c-ee3d-4cc1-b6fd-708b0470621c,DISK], DatanodeInfoWithStorage[127.0.0.1:38941,DS-e2debe47-de2c-45a3-9ea1-a13e10f3246b,DISK], DatanodeInfoWithStorage[127.0.0.1:37866,DS-f0c214e4-f4e1-4085-acbc-3fb4c36ece94,DISK], DatanodeInfoWithStorage[127.0.0.1:44741,DS-4f54565b-71be-483f-a507-3ce73c6955ef,DISK], DatanodeInfoWithStorage[127.0.0.1:44023,DS-211d481a-9b8a-4a7c-a0c6-258c050b68cd,DISK], DatanodeInfoWithStorage[127.0.0.1:37364,DS-27ae0d40-fb3b-46d7-943b-ab7b116760ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1591979477-172.17.0.18-1598473967231:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45102,DS-c8bcf184-dfc2-4b48-8d60-eb85d79a15f6,DISK], DatanodeInfoWithStorage[127.0.0.1:37942,DS-240dc719-4565-4887-886a-178c40f9215f,DISK], DatanodeInfoWithStorage[127.0.0.1:33047,DS-828ef3a9-6513-4a2b-a477-54e55fa34e4e,DISK], DatanodeInfoWithStorage[127.0.0.1:40872,DS-64c314cf-2259-4bbe-98fe-cbdf292cd3fc,DISK], DatanodeInfoWithStorage[127.0.0.1:33158,DS-c1625458-3fee-4f5d-a76a-a14da87a6188,DISK], DatanodeInfoWithStorage[127.0.0.1:32928,DS-1c36f3dc-208b-489d-86c3-2e8ba5589ba8,DISK], DatanodeInfoWithStorage[127.0.0.1:46819,DS-ca0f0646-45be-4ec6-9c25-6e9faf786591,DISK], DatanodeInfoWithStorage[127.0.0.1:43982,DS-79775dc5-0876-4fa1-9d12-44f99789dd45,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1591979477-172.17.0.18-1598473967231:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45102,DS-c8bcf184-dfc2-4b48-8d60-eb85d79a15f6,DISK], DatanodeInfoWithStorage[127.0.0.1:37942,DS-240dc719-4565-4887-886a-178c40f9215f,DISK], DatanodeInfoWithStorage[127.0.0.1:33047,DS-828ef3a9-6513-4a2b-a477-54e55fa34e4e,DISK], DatanodeInfoWithStorage[127.0.0.1:40872,DS-64c314cf-2259-4bbe-98fe-cbdf292cd3fc,DISK], DatanodeInfoWithStorage[127.0.0.1:33158,DS-c1625458-3fee-4f5d-a76a-a14da87a6188,DISK], DatanodeInfoWithStorage[127.0.0.1:32928,DS-1c36f3dc-208b-489d-86c3-2e8ba5589ba8,DISK], DatanodeInfoWithStorage[127.0.0.1:46819,DS-ca0f0646-45be-4ec6-9c25-6e9faf786591,DISK], DatanodeInfoWithStorage[127.0.0.1:43982,DS-79775dc5-0876-4fa1-9d12-44f99789dd45,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1041562697-172.17.0.18-1598473999215:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44815,DS-4ed5452c-4a27-4b18-8e14-f4c06d8a3045,DISK], DatanodeInfoWithStorage[127.0.0.1:38631,DS-737e71d6-217e-4a25-a225-2e68ed8073e4,DISK], DatanodeInfoWithStorage[127.0.0.1:38235,DS-ac5289f3-d57c-423d-822e-9e73ca383f16,DISK], DatanodeInfoWithStorage[127.0.0.1:37721,DS-5a48c4f7-ea23-4dda-a399-06f763927cdd,DISK], DatanodeInfoWithStorage[127.0.0.1:42804,DS-4e76a107-42a9-4566-b369-16f57b5f3516,DISK], DatanodeInfoWithStorage[127.0.0.1:43029,DS-005a913d-e0c1-486d-a133-4076d96946bd,DISK], DatanodeInfoWithStorage[127.0.0.1:34161,DS-8b0654ab-6af7-488b-b8a7-c70b79763009,DISK], DatanodeInfoWithStorage[127.0.0.1:38568,DS-2dadb10a-e82e-4b1c-869e-525d4467061d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1041562697-172.17.0.18-1598473999215:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44815,DS-4ed5452c-4a27-4b18-8e14-f4c06d8a3045,DISK], DatanodeInfoWithStorage[127.0.0.1:38631,DS-737e71d6-217e-4a25-a225-2e68ed8073e4,DISK], DatanodeInfoWithStorage[127.0.0.1:38235,DS-ac5289f3-d57c-423d-822e-9e73ca383f16,DISK], DatanodeInfoWithStorage[127.0.0.1:37721,DS-5a48c4f7-ea23-4dda-a399-06f763927cdd,DISK], DatanodeInfoWithStorage[127.0.0.1:42804,DS-4e76a107-42a9-4566-b369-16f57b5f3516,DISK], DatanodeInfoWithStorage[127.0.0.1:43029,DS-005a913d-e0c1-486d-a133-4076d96946bd,DISK], DatanodeInfoWithStorage[127.0.0.1:34161,DS-8b0654ab-6af7-488b-b8a7-c70b79763009,DISK], DatanodeInfoWithStorage[127.0.0.1:38568,DS-2dadb10a-e82e-4b1c-869e-525d4467061d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-944068592-172.17.0.18-1598474158353:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37597,DS-f448bcad-aaba-4d84-9b6a-24292d712801,DISK], DatanodeInfoWithStorage[127.0.0.1:40241,DS-2772863b-591c-42d6-b8ac-c2529014bc13,DISK], DatanodeInfoWithStorage[127.0.0.1:36936,DS-122f27cf-62a2-4911-90af-cc1d8eacf0c6,DISK], DatanodeInfoWithStorage[127.0.0.1:43445,DS-0f6d3546-4d55-4917-820c-9fa630bec56e,DISK], DatanodeInfoWithStorage[127.0.0.1:45478,DS-73958232-9335-47f2-b8e4-fb431c68fe65,DISK], DatanodeInfoWithStorage[127.0.0.1:42401,DS-7256b565-9666-4148-8d53-b0ff5124fdcd,DISK], DatanodeInfoWithStorage[127.0.0.1:39940,DS-4b70f3f3-956b-47a3-a291-0a757bae84b3,DISK], DatanodeInfoWithStorage[127.0.0.1:45173,DS-e9bfbc82-3551-4ac7-9c85-57ba916eba55,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-944068592-172.17.0.18-1598474158353:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37597,DS-f448bcad-aaba-4d84-9b6a-24292d712801,DISK], DatanodeInfoWithStorage[127.0.0.1:40241,DS-2772863b-591c-42d6-b8ac-c2529014bc13,DISK], DatanodeInfoWithStorage[127.0.0.1:36936,DS-122f27cf-62a2-4911-90af-cc1d8eacf0c6,DISK], DatanodeInfoWithStorage[127.0.0.1:43445,DS-0f6d3546-4d55-4917-820c-9fa630bec56e,DISK], DatanodeInfoWithStorage[127.0.0.1:45478,DS-73958232-9335-47f2-b8e4-fb431c68fe65,DISK], DatanodeInfoWithStorage[127.0.0.1:42401,DS-7256b565-9666-4148-8d53-b0ff5124fdcd,DISK], DatanodeInfoWithStorage[127.0.0.1:39940,DS-4b70f3f3-956b-47a3-a291-0a757bae84b3,DISK], DatanodeInfoWithStorage[127.0.0.1:45173,DS-e9bfbc82-3551-4ac7-9c85-57ba916eba55,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1220512736-172.17.0.18-1598474190153:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35880,DS-7421d347-fdb1-44aa-8146-f86deb3279e9,DISK], DatanodeInfoWithStorage[127.0.0.1:45739,DS-16ee5dc4-e8d3-4b89-993f-074ad023922e,DISK], DatanodeInfoWithStorage[127.0.0.1:45515,DS-6d48335c-a969-4df3-aaab-7edd429e53b5,DISK], DatanodeInfoWithStorage[127.0.0.1:46841,DS-d945a1b2-4773-4c4d-9491-7f6f44d75319,DISK], DatanodeInfoWithStorage[127.0.0.1:43857,DS-e143ff9d-1777-49fa-8107-149972252695,DISK], DatanodeInfoWithStorage[127.0.0.1:44106,DS-17c97ed7-b557-40cf-ac46-0ad2069e745e,DISK], DatanodeInfoWithStorage[127.0.0.1:41888,DS-a10505bb-ef96-4351-9981-d6e813de74b8,DISK], DatanodeInfoWithStorage[127.0.0.1:35998,DS-5efbca02-8394-414d-8adf-fad490fbdcd8,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1220512736-172.17.0.18-1598474190153:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35880,DS-7421d347-fdb1-44aa-8146-f86deb3279e9,DISK], DatanodeInfoWithStorage[127.0.0.1:45739,DS-16ee5dc4-e8d3-4b89-993f-074ad023922e,DISK], DatanodeInfoWithStorage[127.0.0.1:45515,DS-6d48335c-a969-4df3-aaab-7edd429e53b5,DISK], DatanodeInfoWithStorage[127.0.0.1:46841,DS-d945a1b2-4773-4c4d-9491-7f6f44d75319,DISK], DatanodeInfoWithStorage[127.0.0.1:43857,DS-e143ff9d-1777-49fa-8107-149972252695,DISK], DatanodeInfoWithStorage[127.0.0.1:44106,DS-17c97ed7-b557-40cf-ac46-0ad2069e745e,DISK], DatanodeInfoWithStorage[127.0.0.1:41888,DS-a10505bb-ef96-4351-9981-d6e813de74b8,DISK], DatanodeInfoWithStorage[127.0.0.1:35998,DS-5efbca02-8394-414d-8adf-fad490fbdcd8,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-773418682-172.17.0.18-1598474222145:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36531,DS-f542cb2f-36f0-4298-ac2a-24986ec8f695,DISK], DatanodeInfoWithStorage[127.0.0.1:38355,DS-86c172bd-b601-4f70-bfdd-01b5f1d5dc28,DISK], DatanodeInfoWithStorage[127.0.0.1:46262,DS-14635a16-cf92-4637-89d8-5289a561533a,DISK], DatanodeInfoWithStorage[127.0.0.1:34525,DS-55e00e45-96a3-463d-ad2d-90557b2ff031,DISK], DatanodeInfoWithStorage[127.0.0.1:39981,DS-2ceabb69-8801-4511-9aa2-15847abc996c,DISK], DatanodeInfoWithStorage[127.0.0.1:40336,DS-e6251e10-7af3-4cde-8d4d-6d3a3060cb6d,DISK], DatanodeInfoWithStorage[127.0.0.1:36181,DS-973cc5f1-172d-4a36-b51f-6f7d8575ab47,DISK], DatanodeInfoWithStorage[127.0.0.1:40415,DS-11ef6272-8b5e-44e8-9990-f6dc3ff95d50,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-773418682-172.17.0.18-1598474222145:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36531,DS-f542cb2f-36f0-4298-ac2a-24986ec8f695,DISK], DatanodeInfoWithStorage[127.0.0.1:38355,DS-86c172bd-b601-4f70-bfdd-01b5f1d5dc28,DISK], DatanodeInfoWithStorage[127.0.0.1:46262,DS-14635a16-cf92-4637-89d8-5289a561533a,DISK], DatanodeInfoWithStorage[127.0.0.1:34525,DS-55e00e45-96a3-463d-ad2d-90557b2ff031,DISK], DatanodeInfoWithStorage[127.0.0.1:39981,DS-2ceabb69-8801-4511-9aa2-15847abc996c,DISK], DatanodeInfoWithStorage[127.0.0.1:40336,DS-e6251e10-7af3-4cde-8d4d-6d3a3060cb6d,DISK], DatanodeInfoWithStorage[127.0.0.1:36181,DS-973cc5f1-172d-4a36-b51f-6f7d8575ab47,DISK], DatanodeInfoWithStorage[127.0.0.1:40415,DS-11ef6272-8b5e-44e8-9990-f6dc3ff95d50,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1097784361-172.17.0.18-1598474365008:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34632,DS-27a2e3e3-051f-4a3b-88a8-ad806a01d4e7,DISK], DatanodeInfoWithStorage[127.0.0.1:38304,DS-83c72c97-bf04-44b5-be48-0b90872968a9,DISK], DatanodeInfoWithStorage[127.0.0.1:46845,DS-b33abbf0-0db1-43f9-bb35-e6bdd8fe9293,DISK], DatanodeInfoWithStorage[127.0.0.1:39834,DS-13ac6b90-52b0-45f1-9680-5da4119bc745,DISK], DatanodeInfoWithStorage[127.0.0.1:39561,DS-e47359bf-3e96-4c58-afdc-84dd860bd384,DISK], DatanodeInfoWithStorage[127.0.0.1:44375,DS-1ad2be00-5e05-4c9a-a8fb-ca8a7fd8666e,DISK], DatanodeInfoWithStorage[127.0.0.1:40236,DS-c9002987-6834-4c08-b7f1-8af2b3d2c515,DISK], DatanodeInfoWithStorage[127.0.0.1:38230,DS-0d409829-5041-4502-bb0c-26f4b6a21034,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1097784361-172.17.0.18-1598474365008:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34632,DS-27a2e3e3-051f-4a3b-88a8-ad806a01d4e7,DISK], DatanodeInfoWithStorage[127.0.0.1:38304,DS-83c72c97-bf04-44b5-be48-0b90872968a9,DISK], DatanodeInfoWithStorage[127.0.0.1:46845,DS-b33abbf0-0db1-43f9-bb35-e6bdd8fe9293,DISK], DatanodeInfoWithStorage[127.0.0.1:39834,DS-13ac6b90-52b0-45f1-9680-5da4119bc745,DISK], DatanodeInfoWithStorage[127.0.0.1:39561,DS-e47359bf-3e96-4c58-afdc-84dd860bd384,DISK], DatanodeInfoWithStorage[127.0.0.1:44375,DS-1ad2be00-5e05-4c9a-a8fb-ca8a7fd8666e,DISK], DatanodeInfoWithStorage[127.0.0.1:40236,DS-c9002987-6834-4c08-b7f1-8af2b3d2c515,DISK], DatanodeInfoWithStorage[127.0.0.1:38230,DS-0d409829-5041-4502-bb0c-26f4b6a21034,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-101609737-172.17.0.18-1598474460723:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36463,DS-10504ec6-d8ae-4451-9ee1-41aec5d3b0c1,DISK], DatanodeInfoWithStorage[127.0.0.1:40075,DS-7696b1da-b3c8-4895-9ec6-1b1170b702f0,DISK], DatanodeInfoWithStorage[127.0.0.1:46638,DS-a00bbc42-c602-4769-9f34-9c588e14fef0,DISK], DatanodeInfoWithStorage[127.0.0.1:36122,DS-52f6d80b-a90a-4dcc-81ad-0396f2247d53,DISK], DatanodeInfoWithStorage[127.0.0.1:44743,DS-577aa012-4463-429d-8776-59db68f9cae7,DISK], DatanodeInfoWithStorage[127.0.0.1:43922,DS-46719a5c-db9d-42f2-bd3f-87ea5f7ef186,DISK], DatanodeInfoWithStorage[127.0.0.1:36960,DS-01e1203b-f8c1-47d2-ad5c-4f0608fd7539,DISK], DatanodeInfoWithStorage[127.0.0.1:34945,DS-7931c13f-b1dd-4d78-b35c-27bea92762f8,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-101609737-172.17.0.18-1598474460723:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36463,DS-10504ec6-d8ae-4451-9ee1-41aec5d3b0c1,DISK], DatanodeInfoWithStorage[127.0.0.1:40075,DS-7696b1da-b3c8-4895-9ec6-1b1170b702f0,DISK], DatanodeInfoWithStorage[127.0.0.1:46638,DS-a00bbc42-c602-4769-9f34-9c588e14fef0,DISK], DatanodeInfoWithStorage[127.0.0.1:36122,DS-52f6d80b-a90a-4dcc-81ad-0396f2247d53,DISK], DatanodeInfoWithStorage[127.0.0.1:44743,DS-577aa012-4463-429d-8776-59db68f9cae7,DISK], DatanodeInfoWithStorage[127.0.0.1:43922,DS-46719a5c-db9d-42f2-bd3f-87ea5f7ef186,DISK], DatanodeInfoWithStorage[127.0.0.1:36960,DS-01e1203b-f8c1-47d2-ad5c-4f0608fd7539,DISK], DatanodeInfoWithStorage[127.0.0.1:34945,DS-7931c13f-b1dd-4d78-b35c-27bea92762f8,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1005706549-172.17.0.18-1598474555880:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43359,DS-d7ceff50-80c9-4c56-bbea-c449fbaf93e1,DISK], DatanodeInfoWithStorage[127.0.0.1:34551,DS-cf8f949a-3a16-43c8-adf2-3bcdf93f712c,DISK], DatanodeInfoWithStorage[127.0.0.1:39684,DS-b807411b-a392-481f-926f-0239a2978ab9,DISK], DatanodeInfoWithStorage[127.0.0.1:33540,DS-3e4e99bf-6640-46f4-8ece-6fdbf5733d9a,DISK], DatanodeInfoWithStorage[127.0.0.1:33296,DS-c03e8588-75bb-44d9-a567-a295837b7685,DISK], DatanodeInfoWithStorage[127.0.0.1:39643,DS-1b7c53b7-3e6a-4ce7-a4ab-2128853681ed,DISK], DatanodeInfoWithStorage[127.0.0.1:41035,DS-41f097a2-2194-49db-86fa-5b4091ddd820,DISK], DatanodeInfoWithStorage[127.0.0.1:39190,DS-1cdcb77c-45ca-46db-8d55-267bc5aeab37,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1005706549-172.17.0.18-1598474555880:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43359,DS-d7ceff50-80c9-4c56-bbea-c449fbaf93e1,DISK], DatanodeInfoWithStorage[127.0.0.1:34551,DS-cf8f949a-3a16-43c8-adf2-3bcdf93f712c,DISK], DatanodeInfoWithStorage[127.0.0.1:39684,DS-b807411b-a392-481f-926f-0239a2978ab9,DISK], DatanodeInfoWithStorage[127.0.0.1:33540,DS-3e4e99bf-6640-46f4-8ece-6fdbf5733d9a,DISK], DatanodeInfoWithStorage[127.0.0.1:33296,DS-c03e8588-75bb-44d9-a567-a295837b7685,DISK], DatanodeInfoWithStorage[127.0.0.1:39643,DS-1b7c53b7-3e6a-4ce7-a4ab-2128853681ed,DISK], DatanodeInfoWithStorage[127.0.0.1:41035,DS-41f097a2-2194-49db-86fa-5b4091ddd820,DISK], DatanodeInfoWithStorage[127.0.0.1:39190,DS-1cdcb77c-45ca-46db-8d55-267bc5aeab37,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1000963574-172.17.0.18-1598474778560:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41917,DS-9ab67225-faad-4609-a3d8-c2a9eae59da6,DISK], DatanodeInfoWithStorage[127.0.0.1:33082,DS-cf2105ab-03a8-4ab3-820c-46a6a11aed60,DISK], DatanodeInfoWithStorage[127.0.0.1:39473,DS-babeb745-8fd5-4791-954c-0fe94850f929,DISK], DatanodeInfoWithStorage[127.0.0.1:38575,DS-1e351f7d-c457-4dd7-b0e7-c5f6403b0184,DISK], DatanodeInfoWithStorage[127.0.0.1:34140,DS-087e87e0-60e5-47b3-9797-d916d4356e28,DISK], DatanodeInfoWithStorage[127.0.0.1:40711,DS-967602b5-c2b3-4c59-a288-f5e700e89d6f,DISK], DatanodeInfoWithStorage[127.0.0.1:36601,DS-5fb78301-6152-436e-aef9-b06c8e3b04c8,DISK], DatanodeInfoWithStorage[127.0.0.1:41614,DS-81e1a10a-d36a-4f7c-878b-a1a0449fffe8,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1000963574-172.17.0.18-1598474778560:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41917,DS-9ab67225-faad-4609-a3d8-c2a9eae59da6,DISK], DatanodeInfoWithStorage[127.0.0.1:33082,DS-cf2105ab-03a8-4ab3-820c-46a6a11aed60,DISK], DatanodeInfoWithStorage[127.0.0.1:39473,DS-babeb745-8fd5-4791-954c-0fe94850f929,DISK], DatanodeInfoWithStorage[127.0.0.1:38575,DS-1e351f7d-c457-4dd7-b0e7-c5f6403b0184,DISK], DatanodeInfoWithStorage[127.0.0.1:34140,DS-087e87e0-60e5-47b3-9797-d916d4356e28,DISK], DatanodeInfoWithStorage[127.0.0.1:40711,DS-967602b5-c2b3-4c59-a288-f5e700e89d6f,DISK], DatanodeInfoWithStorage[127.0.0.1:36601,DS-5fb78301-6152-436e-aef9-b06c8e3b04c8,DISK], DatanodeInfoWithStorage[127.0.0.1:41614,DS-81e1a10a-d36a-4f7c-878b-a1a0449fffe8,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1955620148-172.17.0.18-1598474858078:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34886,DS-bae7c3e2-d386-4254-9ad5-be4cc503eab6,DISK], DatanodeInfoWithStorage[127.0.0.1:42685,DS-35bff6a2-e7d3-4f21-ab07-636f8e970b61,DISK], DatanodeInfoWithStorage[127.0.0.1:34418,DS-3f7f7a9e-9228-4ae1-a47e-7edfe0e0161c,DISK], DatanodeInfoWithStorage[127.0.0.1:39327,DS-9ea7493e-d3db-46e6-a5df-84b6b0c3c491,DISK], DatanodeInfoWithStorage[127.0.0.1:39036,DS-c48dd643-f8a7-4940-830f-9a10f5c05c6d,DISK], DatanodeInfoWithStorage[127.0.0.1:37148,DS-acfa32ba-2e1e-4229-a85f-030caf4d6719,DISK], DatanodeInfoWithStorage[127.0.0.1:41366,DS-a37cc0f8-c7ea-4b5c-ba45-fd4acb1fc896,DISK], DatanodeInfoWithStorage[127.0.0.1:40433,DS-e82c4748-66f4-4830-95b3-1972233fa96c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1955620148-172.17.0.18-1598474858078:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34886,DS-bae7c3e2-d386-4254-9ad5-be4cc503eab6,DISK], DatanodeInfoWithStorage[127.0.0.1:42685,DS-35bff6a2-e7d3-4f21-ab07-636f8e970b61,DISK], DatanodeInfoWithStorage[127.0.0.1:34418,DS-3f7f7a9e-9228-4ae1-a47e-7edfe0e0161c,DISK], DatanodeInfoWithStorage[127.0.0.1:39327,DS-9ea7493e-d3db-46e6-a5df-84b6b0c3c491,DISK], DatanodeInfoWithStorage[127.0.0.1:39036,DS-c48dd643-f8a7-4940-830f-9a10f5c05c6d,DISK], DatanodeInfoWithStorage[127.0.0.1:37148,DS-acfa32ba-2e1e-4229-a85f-030caf4d6719,DISK], DatanodeInfoWithStorage[127.0.0.1:41366,DS-a37cc0f8-c7ea-4b5c-ba45-fd4acb1fc896,DISK], DatanodeInfoWithStorage[127.0.0.1:40433,DS-e82c4748-66f4-4830-95b3-1972233fa96c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-836436207-172.17.0.18-1598474937376:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35449,DS-5a07a74d-300c-4d08-a747-094ebd825dce,DISK], DatanodeInfoWithStorage[127.0.0.1:36921,DS-3f30540f-81f6-4e94-9cbe-fa60102b38a5,DISK], DatanodeInfoWithStorage[127.0.0.1:37553,DS-60289c54-676e-4592-ab9c-3daede6ca328,DISK], DatanodeInfoWithStorage[127.0.0.1:36300,DS-aedff666-6abf-4cf1-9ba0-1589428336ab,DISK], DatanodeInfoWithStorage[127.0.0.1:35696,DS-639bdf40-9df3-40d8-bc3d-61897d1a0774,DISK], DatanodeInfoWithStorage[127.0.0.1:36261,DS-26e69c9d-56ed-46e6-a8f0-bb47651ba41b,DISK], DatanodeInfoWithStorage[127.0.0.1:37185,DS-695b855f-1a3e-4292-847f-8b2ee9216a67,DISK], DatanodeInfoWithStorage[127.0.0.1:45989,DS-04f4eb96-d007-4e36-96c0-9785f4750773,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-836436207-172.17.0.18-1598474937376:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35449,DS-5a07a74d-300c-4d08-a747-094ebd825dce,DISK], DatanodeInfoWithStorage[127.0.0.1:36921,DS-3f30540f-81f6-4e94-9cbe-fa60102b38a5,DISK], DatanodeInfoWithStorage[127.0.0.1:37553,DS-60289c54-676e-4592-ab9c-3daede6ca328,DISK], DatanodeInfoWithStorage[127.0.0.1:36300,DS-aedff666-6abf-4cf1-9ba0-1589428336ab,DISK], DatanodeInfoWithStorage[127.0.0.1:35696,DS-639bdf40-9df3-40d8-bc3d-61897d1a0774,DISK], DatanodeInfoWithStorage[127.0.0.1:36261,DS-26e69c9d-56ed-46e6-a8f0-bb47651ba41b,DISK], DatanodeInfoWithStorage[127.0.0.1:37185,DS-695b855f-1a3e-4292-847f-8b2ee9216a67,DISK], DatanodeInfoWithStorage[127.0.0.1:45989,DS-04f4eb96-d007-4e36-96c0-9785f4750773,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1393342714-172.17.0.18-1598474984903:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36127,DS-44b33bba-968f-4fc1-a1d5-54e361003ba6,DISK], DatanodeInfoWithStorage[127.0.0.1:44177,DS-53e322e5-3f3b-4544-b28b-38771d2cfc3e,DISK], DatanodeInfoWithStorage[127.0.0.1:39344,DS-83ce8d79-1daa-404a-88d9-0b235793d7d6,DISK], DatanodeInfoWithStorage[127.0.0.1:38514,DS-36b6ee76-72d7-4a5d-ba3b-8d515514962f,DISK], DatanodeInfoWithStorage[127.0.0.1:42137,DS-a40fb953-f9fd-4a19-81ce-53297a65a97f,DISK], DatanodeInfoWithStorage[127.0.0.1:35703,DS-82b6d07e-49a6-4b91-a89c-4af191e6d1a8,DISK], DatanodeInfoWithStorage[127.0.0.1:37062,DS-475803de-13d3-4fee-a19a-5bc6a9f3d529,DISK], DatanodeInfoWithStorage[127.0.0.1:43797,DS-8823cc75-4fe8-4ecd-81aa-6c584461e3ce,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1393342714-172.17.0.18-1598474984903:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36127,DS-44b33bba-968f-4fc1-a1d5-54e361003ba6,DISK], DatanodeInfoWithStorage[127.0.0.1:44177,DS-53e322e5-3f3b-4544-b28b-38771d2cfc3e,DISK], DatanodeInfoWithStorage[127.0.0.1:39344,DS-83ce8d79-1daa-404a-88d9-0b235793d7d6,DISK], DatanodeInfoWithStorage[127.0.0.1:38514,DS-36b6ee76-72d7-4a5d-ba3b-8d515514962f,DISK], DatanodeInfoWithStorage[127.0.0.1:42137,DS-a40fb953-f9fd-4a19-81ce-53297a65a97f,DISK], DatanodeInfoWithStorage[127.0.0.1:35703,DS-82b6d07e-49a6-4b91-a89c-4af191e6d1a8,DISK], DatanodeInfoWithStorage[127.0.0.1:37062,DS-475803de-13d3-4fee-a19a-5bc6a9f3d529,DISK], DatanodeInfoWithStorage[127.0.0.1:43797,DS-8823cc75-4fe8-4ecd-81aa-6c584461e3ce,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1118877672-172.17.0.18-1598475048306:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43637,DS-43e48abc-f39f-46aa-87df-3afcdd439b99,DISK], DatanodeInfoWithStorage[127.0.0.1:37913,DS-3779a722-66ba-40bc-bb06-41fbe7734ba0,DISK], DatanodeInfoWithStorage[127.0.0.1:40815,DS-a02ac25d-4d9f-4e30-b8cb-98a995124073,DISK], DatanodeInfoWithStorage[127.0.0.1:39458,DS-45f8da62-e0e3-4988-b5f4-8b40061d800f,DISK], DatanodeInfoWithStorage[127.0.0.1:45934,DS-3f2f9f6c-7d77-4891-aec4-29631924482d,DISK], DatanodeInfoWithStorage[127.0.0.1:34433,DS-998cf520-a08f-4191-814d-5aeb35b5f480,DISK], DatanodeInfoWithStorage[127.0.0.1:45108,DS-d5f52222-18f6-4765-98a6-88bca5e34e3f,DISK], DatanodeInfoWithStorage[127.0.0.1:36187,DS-4ab9a481-c01a-42f9-b1e3-d423bae9c15e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1118877672-172.17.0.18-1598475048306:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43637,DS-43e48abc-f39f-46aa-87df-3afcdd439b99,DISK], DatanodeInfoWithStorage[127.0.0.1:37913,DS-3779a722-66ba-40bc-bb06-41fbe7734ba0,DISK], DatanodeInfoWithStorage[127.0.0.1:40815,DS-a02ac25d-4d9f-4e30-b8cb-98a995124073,DISK], DatanodeInfoWithStorage[127.0.0.1:39458,DS-45f8da62-e0e3-4988-b5f4-8b40061d800f,DISK], DatanodeInfoWithStorage[127.0.0.1:45934,DS-3f2f9f6c-7d77-4891-aec4-29631924482d,DISK], DatanodeInfoWithStorage[127.0.0.1:34433,DS-998cf520-a08f-4191-814d-5aeb35b5f480,DISK], DatanodeInfoWithStorage[127.0.0.1:45108,DS-d5f52222-18f6-4765-98a6-88bca5e34e3f,DISK], DatanodeInfoWithStorage[127.0.0.1:36187,DS-4ab9a481-c01a-42f9-b1e3-d423bae9c15e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-220589616-172.17.0.18-1598475064113:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34587,DS-4612ca78-bad2-4d08-9463-ee5e62b70de7,DISK], DatanodeInfoWithStorage[127.0.0.1:46581,DS-627bf3e8-ef35-4d32-bdff-5ea7c8f3befd,DISK], DatanodeInfoWithStorage[127.0.0.1:36101,DS-1d40f488-4f5b-480f-9461-468d3397ee32,DISK], DatanodeInfoWithStorage[127.0.0.1:33328,DS-208e29b2-96cf-43c5-9ad1-bbde27cc9c8d,DISK], DatanodeInfoWithStorage[127.0.0.1:41701,DS-46c0e221-e95a-43db-987a-9d976024f931,DISK], DatanodeInfoWithStorage[127.0.0.1:38585,DS-4347ab6f-9bf0-4075-b11e-bdff927656e2,DISK], DatanodeInfoWithStorage[127.0.0.1:34112,DS-349cb7d9-ddc9-4e73-9871-7c68061e903e,DISK], DatanodeInfoWithStorage[127.0.0.1:35116,DS-5ebaa973-4676-47c8-b681-1c45cc927193,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-220589616-172.17.0.18-1598475064113:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34587,DS-4612ca78-bad2-4d08-9463-ee5e62b70de7,DISK], DatanodeInfoWithStorage[127.0.0.1:46581,DS-627bf3e8-ef35-4d32-bdff-5ea7c8f3befd,DISK], DatanodeInfoWithStorage[127.0.0.1:36101,DS-1d40f488-4f5b-480f-9461-468d3397ee32,DISK], DatanodeInfoWithStorage[127.0.0.1:33328,DS-208e29b2-96cf-43c5-9ad1-bbde27cc9c8d,DISK], DatanodeInfoWithStorage[127.0.0.1:41701,DS-46c0e221-e95a-43db-987a-9d976024f931,DISK], DatanodeInfoWithStorage[127.0.0.1:38585,DS-4347ab6f-9bf0-4075-b11e-bdff927656e2,DISK], DatanodeInfoWithStorage[127.0.0.1:34112,DS-349cb7d9-ddc9-4e73-9871-7c68061e903e,DISK], DatanodeInfoWithStorage[127.0.0.1:35116,DS-5ebaa973-4676-47c8-b681-1c45cc927193,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1662776987-172.17.0.18-1598475096066:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38330,DS-ba8c13af-1f43-4971-9db3-4e1978c8a4f1,DISK], DatanodeInfoWithStorage[127.0.0.1:46329,DS-3a7086db-22a8-47b9-9844-2b2efbb08f02,DISK], DatanodeInfoWithStorage[127.0.0.1:36141,DS-b43786f0-bffd-4266-8a75-2d6d4213f37d,DISK], DatanodeInfoWithStorage[127.0.0.1:43032,DS-b10dad2e-0288-428a-abc2-015034699266,DISK], DatanodeInfoWithStorage[127.0.0.1:42350,DS-83eef6d6-0960-4508-a80c-1371d7689cbf,DISK], DatanodeInfoWithStorage[127.0.0.1:36815,DS-6d1ba95f-ecc7-44e4-aedc-5743daf16c54,DISK], DatanodeInfoWithStorage[127.0.0.1:35615,DS-0ad91d38-9cfd-4749-ac2c-02f504492520,DISK], DatanodeInfoWithStorage[127.0.0.1:40654,DS-68ed00fd-ea3f-46ee-964e-2b46735b2314,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1662776987-172.17.0.18-1598475096066:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38330,DS-ba8c13af-1f43-4971-9db3-4e1978c8a4f1,DISK], DatanodeInfoWithStorage[127.0.0.1:46329,DS-3a7086db-22a8-47b9-9844-2b2efbb08f02,DISK], DatanodeInfoWithStorage[127.0.0.1:36141,DS-b43786f0-bffd-4266-8a75-2d6d4213f37d,DISK], DatanodeInfoWithStorage[127.0.0.1:43032,DS-b10dad2e-0288-428a-abc2-015034699266,DISK], DatanodeInfoWithStorage[127.0.0.1:42350,DS-83eef6d6-0960-4508-a80c-1371d7689cbf,DISK], DatanodeInfoWithStorage[127.0.0.1:36815,DS-6d1ba95f-ecc7-44e4-aedc-5743daf16c54,DISK], DatanodeInfoWithStorage[127.0.0.1:35615,DS-0ad91d38-9cfd-4749-ac2c-02f504492520,DISK], DatanodeInfoWithStorage[127.0.0.1:40654,DS-68ed00fd-ea3f-46ee-964e-2b46735b2314,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1235654507-172.17.0.18-1598475111843:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37120,DS-cea1fba8-0588-46bc-810f-1e2d833d911b,DISK], DatanodeInfoWithStorage[127.0.0.1:37513,DS-de148c91-329b-48e2-9937-4515ae958a8a,DISK], DatanodeInfoWithStorage[127.0.0.1:42999,DS-2a710b18-0436-41a1-bcc7-7430e047772d,DISK], DatanodeInfoWithStorage[127.0.0.1:43180,DS-ce37cd52-1562-41fc-9ba0-66fa7bfcca17,DISK], DatanodeInfoWithStorage[127.0.0.1:33601,DS-2b58150f-41e5-4fab-8d53-29241524e4f5,DISK], DatanodeInfoWithStorage[127.0.0.1:33924,DS-5a0af427-39c1-47ca-b8ce-299ca8ac354d,DISK], DatanodeInfoWithStorage[127.0.0.1:39412,DS-476e9641-6f4b-4533-aa7d-5cad98724ed1,DISK], DatanodeInfoWithStorage[127.0.0.1:41372,DS-24ad9591-351d-45eb-85ee-32d0927e5b93,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1235654507-172.17.0.18-1598475111843:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37120,DS-cea1fba8-0588-46bc-810f-1e2d833d911b,DISK], DatanodeInfoWithStorage[127.0.0.1:37513,DS-de148c91-329b-48e2-9937-4515ae958a8a,DISK], DatanodeInfoWithStorage[127.0.0.1:42999,DS-2a710b18-0436-41a1-bcc7-7430e047772d,DISK], DatanodeInfoWithStorage[127.0.0.1:43180,DS-ce37cd52-1562-41fc-9ba0-66fa7bfcca17,DISK], DatanodeInfoWithStorage[127.0.0.1:33601,DS-2b58150f-41e5-4fab-8d53-29241524e4f5,DISK], DatanodeInfoWithStorage[127.0.0.1:33924,DS-5a0af427-39c1-47ca-b8ce-299ca8ac354d,DISK], DatanodeInfoWithStorage[127.0.0.1:39412,DS-476e9641-6f4b-4533-aa7d-5cad98724ed1,DISK], DatanodeInfoWithStorage[127.0.0.1:41372,DS-24ad9591-351d-45eb-85ee-32d0927e5b93,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-359718865-172.17.0.18-1598475159448:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33298,DS-f1112f98-706f-4014-9fea-0728cf6b3941,DISK], DatanodeInfoWithStorage[127.0.0.1:33179,DS-b950a206-35e5-40a6-9813-7840385ccc65,DISK], DatanodeInfoWithStorage[127.0.0.1:37910,DS-ba28c255-2dab-4be8-bc7c-f3f870e9ffb3,DISK], DatanodeInfoWithStorage[127.0.0.1:38768,DS-4a81aebb-e2d7-463f-bf2d-bbc2dc1c75e2,DISK], DatanodeInfoWithStorage[127.0.0.1:35659,DS-f6db0518-2c69-47c2-9e1e-e5d22063b067,DISK], DatanodeInfoWithStorage[127.0.0.1:43191,DS-335832d0-b160-4bac-9f0f-d38cf4ccb23b,DISK], DatanodeInfoWithStorage[127.0.0.1:42352,DS-22114e49-c108-4900-a4cc-98781e324f91,DISK], DatanodeInfoWithStorage[127.0.0.1:40550,DS-993bc722-ddb9-4da6-9fa4-50ba23c9005e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-359718865-172.17.0.18-1598475159448:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33298,DS-f1112f98-706f-4014-9fea-0728cf6b3941,DISK], DatanodeInfoWithStorage[127.0.0.1:33179,DS-b950a206-35e5-40a6-9813-7840385ccc65,DISK], DatanodeInfoWithStorage[127.0.0.1:37910,DS-ba28c255-2dab-4be8-bc7c-f3f870e9ffb3,DISK], DatanodeInfoWithStorage[127.0.0.1:38768,DS-4a81aebb-e2d7-463f-bf2d-bbc2dc1c75e2,DISK], DatanodeInfoWithStorage[127.0.0.1:35659,DS-f6db0518-2c69-47c2-9e1e-e5d22063b067,DISK], DatanodeInfoWithStorage[127.0.0.1:43191,DS-335832d0-b160-4bac-9f0f-d38cf4ccb23b,DISK], DatanodeInfoWithStorage[127.0.0.1:42352,DS-22114e49-c108-4900-a4cc-98781e324f91,DISK], DatanodeInfoWithStorage[127.0.0.1:40550,DS-993bc722-ddb9-4da6-9fa4-50ba23c9005e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-399394068-172.17.0.18-1598475238760:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35048,DS-a0be526a-ca70-449e-b6c1-1474d33ae721,DISK], DatanodeInfoWithStorage[127.0.0.1:45729,DS-1784ce63-b653-48a9-9d36-c5da8ea81d10,DISK], DatanodeInfoWithStorage[127.0.0.1:38321,DS-bd9f396f-6435-41b0-abe2-d42e5b66b199,DISK], DatanodeInfoWithStorage[127.0.0.1:35283,DS-8f2864aa-119a-4dd9-a4d3-d2c5a19fc129,DISK], DatanodeInfoWithStorage[127.0.0.1:36975,DS-11c73d6f-b5c9-4d53-8602-36673733ba19,DISK], DatanodeInfoWithStorage[127.0.0.1:44845,DS-44286420-4967-4ce1-abe5-77f39f14846e,DISK], DatanodeInfoWithStorage[127.0.0.1:34517,DS-bc758566-6f72-4e62-a3d7-59cd90c5229a,DISK], DatanodeInfoWithStorage[127.0.0.1:46717,DS-b8522cd2-3de0-401f-b474-fbe147eb65cf,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-399394068-172.17.0.18-1598475238760:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35048,DS-a0be526a-ca70-449e-b6c1-1474d33ae721,DISK], DatanodeInfoWithStorage[127.0.0.1:45729,DS-1784ce63-b653-48a9-9d36-c5da8ea81d10,DISK], DatanodeInfoWithStorage[127.0.0.1:38321,DS-bd9f396f-6435-41b0-abe2-d42e5b66b199,DISK], DatanodeInfoWithStorage[127.0.0.1:35283,DS-8f2864aa-119a-4dd9-a4d3-d2c5a19fc129,DISK], DatanodeInfoWithStorage[127.0.0.1:36975,DS-11c73d6f-b5c9-4d53-8602-36673733ba19,DISK], DatanodeInfoWithStorage[127.0.0.1:44845,DS-44286420-4967-4ce1-abe5-77f39f14846e,DISK], DatanodeInfoWithStorage[127.0.0.1:34517,DS-bc758566-6f72-4e62-a3d7-59cd90c5229a,DISK], DatanodeInfoWithStorage[127.0.0.1:46717,DS-b8522cd2-3de0-401f-b474-fbe147eb65cf,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1330740519-172.17.0.18-1598475271137:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41515,DS-1e40e935-654b-4495-8bbe-aba8b34c0510,DISK], DatanodeInfoWithStorage[127.0.0.1:37063,DS-5433c8fd-bdea-4a43-8770-155d67e11d72,DISK], DatanodeInfoWithStorage[127.0.0.1:43303,DS-5a8763d9-3231-4a1d-91a0-a847e4ef5d5f,DISK], DatanodeInfoWithStorage[127.0.0.1:39560,DS-442dd18f-b6ed-4225-ba6d-4a8cf921f193,DISK], DatanodeInfoWithStorage[127.0.0.1:35712,DS-593079fb-20aa-449c-87e5-81135a63b943,DISK], DatanodeInfoWithStorage[127.0.0.1:40776,DS-0207b6c9-4d3e-4662-aa5a-8065a3f8ca67,DISK], DatanodeInfoWithStorage[127.0.0.1:36705,DS-8253a812-6409-48b4-8c22-9dfa17ea9028,DISK], DatanodeInfoWithStorage[127.0.0.1:38673,DS-213ad8a7-79fe-45dd-a060-a0da62c3caf8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1330740519-172.17.0.18-1598475271137:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41515,DS-1e40e935-654b-4495-8bbe-aba8b34c0510,DISK], DatanodeInfoWithStorage[127.0.0.1:37063,DS-5433c8fd-bdea-4a43-8770-155d67e11d72,DISK], DatanodeInfoWithStorage[127.0.0.1:43303,DS-5a8763d9-3231-4a1d-91a0-a847e4ef5d5f,DISK], DatanodeInfoWithStorage[127.0.0.1:39560,DS-442dd18f-b6ed-4225-ba6d-4a8cf921f193,DISK], DatanodeInfoWithStorage[127.0.0.1:35712,DS-593079fb-20aa-449c-87e5-81135a63b943,DISK], DatanodeInfoWithStorage[127.0.0.1:40776,DS-0207b6c9-4d3e-4662-aa5a-8065a3f8ca67,DISK], DatanodeInfoWithStorage[127.0.0.1:36705,DS-8253a812-6409-48b4-8c22-9dfa17ea9028,DISK], DatanodeInfoWithStorage[127.0.0.1:38673,DS-213ad8a7-79fe-45dd-a060-a0da62c3caf8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1633821406-172.17.0.18-1598475302955:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35250,DS-11e97892-4e91-4b64-b4f5-aedfb9010279,DISK], DatanodeInfoWithStorage[127.0.0.1:41260,DS-bb3ff2cd-c49e-4ce0-b347-73a1bbc7db6c,DISK], DatanodeInfoWithStorage[127.0.0.1:44296,DS-daeab99b-003d-41f7-8e7e-f90b20b7c568,DISK], DatanodeInfoWithStorage[127.0.0.1:39305,DS-a63a38ea-9325-4faf-aaeb-f44f2873811b,DISK], DatanodeInfoWithStorage[127.0.0.1:46188,DS-3620acc0-d31e-4770-b1e4-5c11ed66a550,DISK], DatanodeInfoWithStorage[127.0.0.1:33436,DS-819fedca-bb5e-4417-a570-f972408bbef1,DISK], DatanodeInfoWithStorage[127.0.0.1:39904,DS-d5d67acc-31af-490e-9421-828d1e5ed357,DISK], DatanodeInfoWithStorage[127.0.0.1:44929,DS-039cc77c-4480-402a-8466-23ba9b3f2fc2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1633821406-172.17.0.18-1598475302955:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35250,DS-11e97892-4e91-4b64-b4f5-aedfb9010279,DISK], DatanodeInfoWithStorage[127.0.0.1:41260,DS-bb3ff2cd-c49e-4ce0-b347-73a1bbc7db6c,DISK], DatanodeInfoWithStorage[127.0.0.1:44296,DS-daeab99b-003d-41f7-8e7e-f90b20b7c568,DISK], DatanodeInfoWithStorage[127.0.0.1:39305,DS-a63a38ea-9325-4faf-aaeb-f44f2873811b,DISK], DatanodeInfoWithStorage[127.0.0.1:46188,DS-3620acc0-d31e-4770-b1e4-5c11ed66a550,DISK], DatanodeInfoWithStorage[127.0.0.1:33436,DS-819fedca-bb5e-4417-a570-f972408bbef1,DISK], DatanodeInfoWithStorage[127.0.0.1:39904,DS-d5d67acc-31af-490e-9421-828d1e5ed357,DISK], DatanodeInfoWithStorage[127.0.0.1:44929,DS-039cc77c-4480-402a-8466-23ba9b3f2fc2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 11 out of 50
v1v1v2v2 failed with probability 18 out of 50
result: false positive !!!
Total execution time in seconds : 3297
