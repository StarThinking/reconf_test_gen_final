reconf_parameter: hadoop.security.authorization
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-185143740-172.17.0.21-1598084405228:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35494,DS-ea39c190-d14e-45dc-ba9a-fde96272744c,DISK], DatanodeInfoWithStorage[127.0.0.1:41654,DS-86889ead-521c-4f29-b5eb-8475708f5862,DISK], DatanodeInfoWithStorage[127.0.0.1:32900,DS-460e34e3-e6b5-46c6-b618-4d88e7ac3442,DISK], DatanodeInfoWithStorage[127.0.0.1:45369,DS-79131dc5-5f20-4d4b-b0df-28874154e705,DISK], DatanodeInfoWithStorage[127.0.0.1:44715,DS-cd7476df-e0cd-4e67-9e87-2f5fbfd0ccf4,DISK], DatanodeInfoWithStorage[127.0.0.1:39134,DS-03fe10c0-b067-4493-a804-b26a574dc5a1,DISK], DatanodeInfoWithStorage[127.0.0.1:33934,DS-af979054-b7e4-4be5-9978-7ff668ecdc95,DISK], DatanodeInfoWithStorage[127.0.0.1:35441,DS-5bc68426-5a14-4b75-a572-3ca0422f68b6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-185143740-172.17.0.21-1598084405228:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35494,DS-ea39c190-d14e-45dc-ba9a-fde96272744c,DISK], DatanodeInfoWithStorage[127.0.0.1:41654,DS-86889ead-521c-4f29-b5eb-8475708f5862,DISK], DatanodeInfoWithStorage[127.0.0.1:32900,DS-460e34e3-e6b5-46c6-b618-4d88e7ac3442,DISK], DatanodeInfoWithStorage[127.0.0.1:45369,DS-79131dc5-5f20-4d4b-b0df-28874154e705,DISK], DatanodeInfoWithStorage[127.0.0.1:44715,DS-cd7476df-e0cd-4e67-9e87-2f5fbfd0ccf4,DISK], DatanodeInfoWithStorage[127.0.0.1:39134,DS-03fe10c0-b067-4493-a804-b26a574dc5a1,DISK], DatanodeInfoWithStorage[127.0.0.1:33934,DS-af979054-b7e4-4be5-9978-7ff668ecdc95,DISK], DatanodeInfoWithStorage[127.0.0.1:35441,DS-5bc68426-5a14-4b75-a572-3ca0422f68b6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1253432349-172.17.0.21-1598084483633:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37837,DS-859c40cb-f779-4c3b-bca0-046a06f42dd7,DISK], DatanodeInfoWithStorage[127.0.0.1:37158,DS-5990358b-0cd4-43bd-94f3-953ba9b4fd12,DISK], DatanodeInfoWithStorage[127.0.0.1:36455,DS-a17c7d35-1480-407a-8436-7b0196aa8106,DISK], DatanodeInfoWithStorage[127.0.0.1:46748,DS-985e9d3e-218e-4ed0-bb6d-011a2f611120,DISK], DatanodeInfoWithStorage[127.0.0.1:41501,DS-887ace5b-6001-4b30-a5d3-6ec118b5216a,DISK], DatanodeInfoWithStorage[127.0.0.1:44696,DS-630a56d9-a4ba-4a91-967e-5093a85fa762,DISK], DatanodeInfoWithStorage[127.0.0.1:38224,DS-1deab90a-7349-4061-bd2f-e9880de96fe7,DISK], DatanodeInfoWithStorage[127.0.0.1:33845,DS-8f4ed764-e902-4a05-9772-207f5e08ab6b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1253432349-172.17.0.21-1598084483633:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37837,DS-859c40cb-f779-4c3b-bca0-046a06f42dd7,DISK], DatanodeInfoWithStorage[127.0.0.1:37158,DS-5990358b-0cd4-43bd-94f3-953ba9b4fd12,DISK], DatanodeInfoWithStorage[127.0.0.1:36455,DS-a17c7d35-1480-407a-8436-7b0196aa8106,DISK], DatanodeInfoWithStorage[127.0.0.1:46748,DS-985e9d3e-218e-4ed0-bb6d-011a2f611120,DISK], DatanodeInfoWithStorage[127.0.0.1:41501,DS-887ace5b-6001-4b30-a5d3-6ec118b5216a,DISK], DatanodeInfoWithStorage[127.0.0.1:44696,DS-630a56d9-a4ba-4a91-967e-5093a85fa762,DISK], DatanodeInfoWithStorage[127.0.0.1:38224,DS-1deab90a-7349-4061-bd2f-e9880de96fe7,DISK], DatanodeInfoWithStorage[127.0.0.1:33845,DS-8f4ed764-e902-4a05-9772-207f5e08ab6b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1982806497-172.17.0.21-1598084515886:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43174,DS-22244f97-0b76-4eca-bc3c-c6be4523c865,DISK], DatanodeInfoWithStorage[127.0.0.1:38637,DS-fe10e016-7c36-411b-b920-e44a726095cd,DISK], DatanodeInfoWithStorage[127.0.0.1:43572,DS-4c17a24d-88f6-4b4f-bebb-5a85e1388e83,DISK], DatanodeInfoWithStorage[127.0.0.1:37433,DS-4f9893b9-fca1-4773-83bd-9870e813be68,DISK], DatanodeInfoWithStorage[127.0.0.1:45241,DS-030bce01-e2a9-4029-b086-ce1ae4788f45,DISK], DatanodeInfoWithStorage[127.0.0.1:41961,DS-ec6d1a7b-5f38-4f33-aec2-bf1ea5f00440,DISK], DatanodeInfoWithStorage[127.0.0.1:34221,DS-20a16a42-f904-412b-a083-2b2610de7cbb,DISK], DatanodeInfoWithStorage[127.0.0.1:41203,DS-d91c8771-347b-41da-a138-3205dbb0b79a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1982806497-172.17.0.21-1598084515886:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43174,DS-22244f97-0b76-4eca-bc3c-c6be4523c865,DISK], DatanodeInfoWithStorage[127.0.0.1:38637,DS-fe10e016-7c36-411b-b920-e44a726095cd,DISK], DatanodeInfoWithStorage[127.0.0.1:43572,DS-4c17a24d-88f6-4b4f-bebb-5a85e1388e83,DISK], DatanodeInfoWithStorage[127.0.0.1:37433,DS-4f9893b9-fca1-4773-83bd-9870e813be68,DISK], DatanodeInfoWithStorage[127.0.0.1:45241,DS-030bce01-e2a9-4029-b086-ce1ae4788f45,DISK], DatanodeInfoWithStorage[127.0.0.1:41961,DS-ec6d1a7b-5f38-4f33-aec2-bf1ea5f00440,DISK], DatanodeInfoWithStorage[127.0.0.1:34221,DS-20a16a42-f904-412b-a083-2b2610de7cbb,DISK], DatanodeInfoWithStorage[127.0.0.1:41203,DS-d91c8771-347b-41da-a138-3205dbb0b79a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-55120069-172.17.0.21-1598084616264:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34940,DS-ab2dda43-5ac7-42a6-93f3-2f59b74ce477,DISK], DatanodeInfoWithStorage[127.0.0.1:43763,DS-013bf8f5-a2a1-4992-962b-756f38dbfc6c,DISK], DatanodeInfoWithStorage[127.0.0.1:45806,DS-a460f5d0-0e31-4a5b-81f9-1ea7a2ec4775,DISK], DatanodeInfoWithStorage[127.0.0.1:35861,DS-f5b6fc84-8249-4d5b-9f72-0d9e16eb0972,DISK], DatanodeInfoWithStorage[127.0.0.1:45880,DS-25d3155d-dd1d-4f80-a6de-ecd5b4028b5c,DISK], DatanodeInfoWithStorage[127.0.0.1:42598,DS-2371b7dc-eb45-4e49-818b-ee576fe819cd,DISK], DatanodeInfoWithStorage[127.0.0.1:44167,DS-aac1defb-1cab-4568-8c97-46629486e4b0,DISK], DatanodeInfoWithStorage[127.0.0.1:44708,DS-29628246-9baf-40f2-88fe-8771115dabe0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-55120069-172.17.0.21-1598084616264:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34940,DS-ab2dda43-5ac7-42a6-93f3-2f59b74ce477,DISK], DatanodeInfoWithStorage[127.0.0.1:43763,DS-013bf8f5-a2a1-4992-962b-756f38dbfc6c,DISK], DatanodeInfoWithStorage[127.0.0.1:45806,DS-a460f5d0-0e31-4a5b-81f9-1ea7a2ec4775,DISK], DatanodeInfoWithStorage[127.0.0.1:35861,DS-f5b6fc84-8249-4d5b-9f72-0d9e16eb0972,DISK], DatanodeInfoWithStorage[127.0.0.1:45880,DS-25d3155d-dd1d-4f80-a6de-ecd5b4028b5c,DISK], DatanodeInfoWithStorage[127.0.0.1:42598,DS-2371b7dc-eb45-4e49-818b-ee576fe819cd,DISK], DatanodeInfoWithStorage[127.0.0.1:44167,DS-aac1defb-1cab-4568-8c97-46629486e4b0,DISK], DatanodeInfoWithStorage[127.0.0.1:44708,DS-29628246-9baf-40f2-88fe-8771115dabe0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1522699068-172.17.0.21-1598084775346:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35770,DS-f4471f2d-799c-4934-95e1-d6dc16b4805f,DISK], DatanodeInfoWithStorage[127.0.0.1:43520,DS-80b4af02-d9c9-4f10-9bd1-22470fc684a7,DISK], DatanodeInfoWithStorage[127.0.0.1:33307,DS-911774b0-7d7e-4645-9ede-2bdefa8eb211,DISK], DatanodeInfoWithStorage[127.0.0.1:39091,DS-92bfb53c-7d3e-47d0-8cad-2397723316f8,DISK], DatanodeInfoWithStorage[127.0.0.1:34603,DS-82e493c9-1e0d-49b5-ab31-53504c44b983,DISK], DatanodeInfoWithStorage[127.0.0.1:41717,DS-5f29dfc9-8df8-4665-ba05-66600726f2ea,DISK], DatanodeInfoWithStorage[127.0.0.1:32848,DS-e8a7dc75-54f3-4984-b5a2-f00e80dacf24,DISK], DatanodeInfoWithStorage[127.0.0.1:39229,DS-3a92e616-1846-4b15-ae19-50523355d954,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1522699068-172.17.0.21-1598084775346:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35770,DS-f4471f2d-799c-4934-95e1-d6dc16b4805f,DISK], DatanodeInfoWithStorage[127.0.0.1:43520,DS-80b4af02-d9c9-4f10-9bd1-22470fc684a7,DISK], DatanodeInfoWithStorage[127.0.0.1:33307,DS-911774b0-7d7e-4645-9ede-2bdefa8eb211,DISK], DatanodeInfoWithStorage[127.0.0.1:39091,DS-92bfb53c-7d3e-47d0-8cad-2397723316f8,DISK], DatanodeInfoWithStorage[127.0.0.1:34603,DS-82e493c9-1e0d-49b5-ab31-53504c44b983,DISK], DatanodeInfoWithStorage[127.0.0.1:41717,DS-5f29dfc9-8df8-4665-ba05-66600726f2ea,DISK], DatanodeInfoWithStorage[127.0.0.1:32848,DS-e8a7dc75-54f3-4984-b5a2-f00e80dacf24,DISK], DatanodeInfoWithStorage[127.0.0.1:39229,DS-3a92e616-1846-4b15-ae19-50523355d954,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-860816119-172.17.0.21-1598085099454:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36540,DS-e822ae4e-7932-448e-9398-698f755c9662,DISK], DatanodeInfoWithStorage[127.0.0.1:34782,DS-4fff4924-79ae-4aa7-a3ff-8b152f4e7e58,DISK], DatanodeInfoWithStorage[127.0.0.1:45705,DS-4a033939-a6a5-42f5-b56d-56bd7f83361d,DISK], DatanodeInfoWithStorage[127.0.0.1:45490,DS-04792af0-46eb-4bb4-8381-7595c2afa200,DISK], DatanodeInfoWithStorage[127.0.0.1:41869,DS-b524511f-bd7a-4f27-9475-10897bf53625,DISK], DatanodeInfoWithStorage[127.0.0.1:33040,DS-fbc5dfba-cecf-4930-a651-96a473662cfa,DISK], DatanodeInfoWithStorage[127.0.0.1:41155,DS-68ee0d24-9d9b-4c99-b16b-a7157b508aa9,DISK], DatanodeInfoWithStorage[127.0.0.1:45350,DS-9f038467-764e-47c6-9a49-41d067ae8ec8,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-860816119-172.17.0.21-1598085099454:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36540,DS-e822ae4e-7932-448e-9398-698f755c9662,DISK], DatanodeInfoWithStorage[127.0.0.1:34782,DS-4fff4924-79ae-4aa7-a3ff-8b152f4e7e58,DISK], DatanodeInfoWithStorage[127.0.0.1:45705,DS-4a033939-a6a5-42f5-b56d-56bd7f83361d,DISK], DatanodeInfoWithStorage[127.0.0.1:45490,DS-04792af0-46eb-4bb4-8381-7595c2afa200,DISK], DatanodeInfoWithStorage[127.0.0.1:41869,DS-b524511f-bd7a-4f27-9475-10897bf53625,DISK], DatanodeInfoWithStorage[127.0.0.1:33040,DS-fbc5dfba-cecf-4930-a651-96a473662cfa,DISK], DatanodeInfoWithStorage[127.0.0.1:41155,DS-68ee0d24-9d9b-4c99-b16b-a7157b508aa9,DISK], DatanodeInfoWithStorage[127.0.0.1:45350,DS-9f038467-764e-47c6-9a49-41d067ae8ec8,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: hadoop.security.authorization
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1962789633-172.17.0.21-1598085134337:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38369,DS-44d2823f-b98a-47a0-ab7c-ebd57e4f1014,DISK], DatanodeInfoWithStorage[127.0.0.1:42256,DS-871ef9ae-466b-47f3-950b-a02e580e39e9,DISK], DatanodeInfoWithStorage[127.0.0.1:43923,DS-72384242-f4f1-4ca6-8cf9-5ef45945dbc5,DISK], DatanodeInfoWithStorage[127.0.0.1:34720,DS-ca4db2fc-5c8c-4858-bc8b-1b9b421d8680,DISK], DatanodeInfoWithStorage[127.0.0.1:38165,DS-a620a625-9ae5-4576-89c4-9b202a32d76c,DISK], DatanodeInfoWithStorage[127.0.0.1:39315,DS-45e4ec01-9d97-4be0-9c42-aa83d9e5086e,DISK], DatanodeInfoWithStorage[127.0.0.1:33218,DS-279eb4c8-80dd-4a3f-8fd4-e03670218e9e,DISK], DatanodeInfoWithStorage[127.0.0.1:33721,DS-01d98409-d69c-4dce-bf9c-15fbb0c88233,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1962789633-172.17.0.21-1598085134337:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38369,DS-44d2823f-b98a-47a0-ab7c-ebd57e4f1014,DISK], DatanodeInfoWithStorage[127.0.0.1:42256,DS-871ef9ae-466b-47f3-950b-a02e580e39e9,DISK], DatanodeInfoWithStorage[127.0.0.1:43923,DS-72384242-f4f1-4ca6-8cf9-5ef45945dbc5,DISK], DatanodeInfoWithStorage[127.0.0.1:34720,DS-ca4db2fc-5c8c-4858-bc8b-1b9b421d8680,DISK], DatanodeInfoWithStorage[127.0.0.1:38165,DS-a620a625-9ae5-4576-89c4-9b202a32d76c,DISK], DatanodeInfoWithStorage[127.0.0.1:39315,DS-45e4ec01-9d97-4be0-9c42-aa83d9e5086e,DISK], DatanodeInfoWithStorage[127.0.0.1:33218,DS-279eb4c8-80dd-4a3f-8fd4-e03670218e9e,DISK], DatanodeInfoWithStorage[127.0.0.1:33721,DS-01d98409-d69c-4dce-bf9c-15fbb0c88233,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-79003842-172.17.0.21-1598085247265:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34063,DS-ffc5fc21-d9fe-454a-883a-e63e2a3e3ca1,DISK], DatanodeInfoWithStorage[127.0.0.1:35609,DS-0e2273f8-18a5-4bcd-bf82-c5fa2e00e1d0,DISK], DatanodeInfoWithStorage[127.0.0.1:39096,DS-74db3197-8bba-4378-abf1-298b26e6c208,DISK], DatanodeInfoWithStorage[127.0.0.1:40052,DS-ebd4a055-06b9-418e-95dd-8b37ee6667d7,DISK], DatanodeInfoWithStorage[127.0.0.1:46781,DS-0df4ba33-a694-4849-82d3-7d4b8041e31e,DISK], DatanodeInfoWithStorage[127.0.0.1:35135,DS-2566ab70-686e-4ee7-9792-0d7ef0979528,DISK], DatanodeInfoWithStorage[127.0.0.1:42918,DS-81959201-b479-46bc-84e1-a48afb8341ca,DISK], DatanodeInfoWithStorage[127.0.0.1:41718,DS-8d512921-20a7-49f2-8be2-24e3cad53015,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-79003842-172.17.0.21-1598085247265:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34063,DS-ffc5fc21-d9fe-454a-883a-e63e2a3e3ca1,DISK], DatanodeInfoWithStorage[127.0.0.1:35609,DS-0e2273f8-18a5-4bcd-bf82-c5fa2e00e1d0,DISK], DatanodeInfoWithStorage[127.0.0.1:39096,DS-74db3197-8bba-4378-abf1-298b26e6c208,DISK], DatanodeInfoWithStorage[127.0.0.1:40052,DS-ebd4a055-06b9-418e-95dd-8b37ee6667d7,DISK], DatanodeInfoWithStorage[127.0.0.1:46781,DS-0df4ba33-a694-4849-82d3-7d4b8041e31e,DISK], DatanodeInfoWithStorage[127.0.0.1:35135,DS-2566ab70-686e-4ee7-9792-0d7ef0979528,DISK], DatanodeInfoWithStorage[127.0.0.1:42918,DS-81959201-b479-46bc-84e1-a48afb8341ca,DISK], DatanodeInfoWithStorage[127.0.0.1:41718,DS-8d512921-20a7-49f2-8be2-24e3cad53015,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-185607546-172.17.0.21-1598085283701:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40167,DS-b3a7aabc-54d2-434e-b3ec-6d860979a9db,DISK], DatanodeInfoWithStorage[127.0.0.1:45496,DS-97aaf137-8635-4808-947f-cb1a5ff815e0,DISK], DatanodeInfoWithStorage[127.0.0.1:40532,DS-0bea772e-0d21-466b-a042-2d1653ff9c19,DISK], DatanodeInfoWithStorage[127.0.0.1:38018,DS-8abb5ecd-454c-4728-ade6-6b12b3746c6c,DISK], DatanodeInfoWithStorage[127.0.0.1:34487,DS-ea837aca-c618-45ed-8a61-28e8d3af5675,DISK], DatanodeInfoWithStorage[127.0.0.1:39466,DS-a254a77f-98d8-4279-9b5b-f53fb3e6ff9e,DISK], DatanodeInfoWithStorage[127.0.0.1:40078,DS-932b8094-5a2b-4c95-89e9-ddad4950ad2e,DISK], DatanodeInfoWithStorage[127.0.0.1:46207,DS-45b4205d-7d94-416c-9507-013ad555e8e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-185607546-172.17.0.21-1598085283701:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40167,DS-b3a7aabc-54d2-434e-b3ec-6d860979a9db,DISK], DatanodeInfoWithStorage[127.0.0.1:45496,DS-97aaf137-8635-4808-947f-cb1a5ff815e0,DISK], DatanodeInfoWithStorage[127.0.0.1:40532,DS-0bea772e-0d21-466b-a042-2d1653ff9c19,DISK], DatanodeInfoWithStorage[127.0.0.1:38018,DS-8abb5ecd-454c-4728-ade6-6b12b3746c6c,DISK], DatanodeInfoWithStorage[127.0.0.1:34487,DS-ea837aca-c618-45ed-8a61-28e8d3af5675,DISK], DatanodeInfoWithStorage[127.0.0.1:39466,DS-a254a77f-98d8-4279-9b5b-f53fb3e6ff9e,DISK], DatanodeInfoWithStorage[127.0.0.1:40078,DS-932b8094-5a2b-4c95-89e9-ddad4950ad2e,DISK], DatanodeInfoWithStorage[127.0.0.1:46207,DS-45b4205d-7d94-416c-9507-013ad555e8e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2075362101-172.17.0.21-1598085996991:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36805,DS-4452baaf-e59d-460e-9863-9da1201a6c3c,DISK], DatanodeInfoWithStorage[127.0.0.1:37979,DS-8716790d-488b-458d-a94d-20a07ece55dd,DISK], DatanodeInfoWithStorage[127.0.0.1:33570,DS-e82cf585-4105-4166-bd73-06f0bd71d31b,DISK], DatanodeInfoWithStorage[127.0.0.1:37746,DS-ab1893c3-4d77-44fa-89a7-0cb79d2b4932,DISK], DatanodeInfoWithStorage[127.0.0.1:38977,DS-7feccc0c-53b8-43b8-b4e3-57fe7cb8184b,DISK], DatanodeInfoWithStorage[127.0.0.1:37373,DS-df04369c-2409-406d-ba4b-8ccbeef51fec,DISK], DatanodeInfoWithStorage[127.0.0.1:34721,DS-d19afe1c-35d0-46eb-89d9-5d2259dc7b41,DISK], DatanodeInfoWithStorage[127.0.0.1:34634,DS-555c3d3a-f9e1-4365-adb8-7b146407355a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2075362101-172.17.0.21-1598085996991:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36805,DS-4452baaf-e59d-460e-9863-9da1201a6c3c,DISK], DatanodeInfoWithStorage[127.0.0.1:37979,DS-8716790d-488b-458d-a94d-20a07ece55dd,DISK], DatanodeInfoWithStorage[127.0.0.1:33570,DS-e82cf585-4105-4166-bd73-06f0bd71d31b,DISK], DatanodeInfoWithStorage[127.0.0.1:37746,DS-ab1893c3-4d77-44fa-89a7-0cb79d2b4932,DISK], DatanodeInfoWithStorage[127.0.0.1:38977,DS-7feccc0c-53b8-43b8-b4e3-57fe7cb8184b,DISK], DatanodeInfoWithStorage[127.0.0.1:37373,DS-df04369c-2409-406d-ba4b-8ccbeef51fec,DISK], DatanodeInfoWithStorage[127.0.0.1:34721,DS-d19afe1c-35d0-46eb-89d9-5d2259dc7b41,DISK], DatanodeInfoWithStorage[127.0.0.1:34634,DS-555c3d3a-f9e1-4365-adb8-7b146407355a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-486956631-172.17.0.21-1598086150086:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43654,DS-e1fdb9b1-586e-48b4-8ff4-65483c463f3e,DISK], DatanodeInfoWithStorage[127.0.0.1:33327,DS-3f4b39cc-6f87-4dbb-9d42-06ae1a3f89e4,DISK], DatanodeInfoWithStorage[127.0.0.1:36428,DS-c6f98cbd-d0a3-47af-b23f-899c32b689a1,DISK], DatanodeInfoWithStorage[127.0.0.1:39495,DS-95af971c-dfba-431d-afc9-c105bba1c845,DISK], DatanodeInfoWithStorage[127.0.0.1:44398,DS-a889de19-3d4d-433a-a70e-bdec73265fc5,DISK], DatanodeInfoWithStorage[127.0.0.1:37039,DS-0e1ae947-6094-407a-a09b-bec1481b96b7,DISK], DatanodeInfoWithStorage[127.0.0.1:41976,DS-8a531cfb-8be4-4380-9481-91df67dea527,DISK], DatanodeInfoWithStorage[127.0.0.1:39666,DS-591c460a-63c0-4e09-95c8-ca678a7decc9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-486956631-172.17.0.21-1598086150086:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43654,DS-e1fdb9b1-586e-48b4-8ff4-65483c463f3e,DISK], DatanodeInfoWithStorage[127.0.0.1:33327,DS-3f4b39cc-6f87-4dbb-9d42-06ae1a3f89e4,DISK], DatanodeInfoWithStorage[127.0.0.1:36428,DS-c6f98cbd-d0a3-47af-b23f-899c32b689a1,DISK], DatanodeInfoWithStorage[127.0.0.1:39495,DS-95af971c-dfba-431d-afc9-c105bba1c845,DISK], DatanodeInfoWithStorage[127.0.0.1:44398,DS-a889de19-3d4d-433a-a70e-bdec73265fc5,DISK], DatanodeInfoWithStorage[127.0.0.1:37039,DS-0e1ae947-6094-407a-a09b-bec1481b96b7,DISK], DatanodeInfoWithStorage[127.0.0.1:41976,DS-8a531cfb-8be4-4380-9481-91df67dea527,DISK], DatanodeInfoWithStorage[127.0.0.1:39666,DS-591c460a-63c0-4e09-95c8-ca678a7decc9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-529132064-172.17.0.21-1598086316746:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45998,DS-94640afb-5e46-43e1-9dde-e64f7ca7da23,DISK], DatanodeInfoWithStorage[127.0.0.1:34299,DS-6426136c-f39a-4814-ac24-6c970ac9df59,DISK], DatanodeInfoWithStorage[127.0.0.1:44771,DS-99ba2ae6-61bc-4c2d-b7b6-5c4e1153b19e,DISK], DatanodeInfoWithStorage[127.0.0.1:36534,DS-364f2e9b-858b-40d2-b8bf-1fb0bf9cf34e,DISK], DatanodeInfoWithStorage[127.0.0.1:41604,DS-b3905a9b-5ebd-4067-b9a1-73c098717f29,DISK], DatanodeInfoWithStorage[127.0.0.1:34025,DS-53623766-9127-46f0-ba15-03c42903e648,DISK], DatanodeInfoWithStorage[127.0.0.1:46587,DS-2f9d93aa-2cff-4fcd-b878-5f1b5c1500fc,DISK], DatanodeInfoWithStorage[127.0.0.1:38501,DS-17a6e225-0ce9-464d-a3ad-b20faf4be45f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-529132064-172.17.0.21-1598086316746:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45998,DS-94640afb-5e46-43e1-9dde-e64f7ca7da23,DISK], DatanodeInfoWithStorage[127.0.0.1:34299,DS-6426136c-f39a-4814-ac24-6c970ac9df59,DISK], DatanodeInfoWithStorage[127.0.0.1:44771,DS-99ba2ae6-61bc-4c2d-b7b6-5c4e1153b19e,DISK], DatanodeInfoWithStorage[127.0.0.1:36534,DS-364f2e9b-858b-40d2-b8bf-1fb0bf9cf34e,DISK], DatanodeInfoWithStorage[127.0.0.1:41604,DS-b3905a9b-5ebd-4067-b9a1-73c098717f29,DISK], DatanodeInfoWithStorage[127.0.0.1:34025,DS-53623766-9127-46f0-ba15-03c42903e648,DISK], DatanodeInfoWithStorage[127.0.0.1:46587,DS-2f9d93aa-2cff-4fcd-b878-5f1b5c1500fc,DISK], DatanodeInfoWithStorage[127.0.0.1:38501,DS-17a6e225-0ce9-464d-a3ad-b20faf4be45f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-72720326-172.17.0.21-1598086435388:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43339,DS-a3923ae1-2e93-4c88-9ca8-210976c607ca,DISK], DatanodeInfoWithStorage[127.0.0.1:34872,DS-5fce370e-571f-4f08-9146-cb1e79877ea0,DISK], DatanodeInfoWithStorage[127.0.0.1:38982,DS-56ac5211-f007-4366-bce5-f02bc26d3cbf,DISK], DatanodeInfoWithStorage[127.0.0.1:41648,DS-45764933-4be7-4e36-8e0f-8ae46147b19c,DISK], DatanodeInfoWithStorage[127.0.0.1:38784,DS-95556831-8247-4beb-b826-8a4b5507d768,DISK], DatanodeInfoWithStorage[127.0.0.1:37736,DS-f03b1f07-e2cf-4c06-839e-db9c22f1f13a,DISK], DatanodeInfoWithStorage[127.0.0.1:36645,DS-9599a904-6996-4aee-a655-7e00d3900dfb,DISK], DatanodeInfoWithStorage[127.0.0.1:34200,DS-18ea4fde-c6cf-4481-9949-85c58754a38d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-72720326-172.17.0.21-1598086435388:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43339,DS-a3923ae1-2e93-4c88-9ca8-210976c607ca,DISK], DatanodeInfoWithStorage[127.0.0.1:34872,DS-5fce370e-571f-4f08-9146-cb1e79877ea0,DISK], DatanodeInfoWithStorage[127.0.0.1:38982,DS-56ac5211-f007-4366-bce5-f02bc26d3cbf,DISK], DatanodeInfoWithStorage[127.0.0.1:41648,DS-45764933-4be7-4e36-8e0f-8ae46147b19c,DISK], DatanodeInfoWithStorage[127.0.0.1:38784,DS-95556831-8247-4beb-b826-8a4b5507d768,DISK], DatanodeInfoWithStorage[127.0.0.1:37736,DS-f03b1f07-e2cf-4c06-839e-db9c22f1f13a,DISK], DatanodeInfoWithStorage[127.0.0.1:36645,DS-9599a904-6996-4aee-a655-7e00d3900dfb,DISK], DatanodeInfoWithStorage[127.0.0.1:34200,DS-18ea4fde-c6cf-4481-9949-85c58754a38d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1310221891-172.17.0.21-1598086559812:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38147,DS-fcb0f879-d43b-4a0c-a5c3-cfb3d74c18d7,DISK], DatanodeInfoWithStorage[127.0.0.1:37633,DS-b8843fdd-d44d-4d6d-8f39-09751c23a1e2,DISK], DatanodeInfoWithStorage[127.0.0.1:40625,DS-b5f3f360-8b8d-4553-9877-f478e8e14425,DISK], DatanodeInfoWithStorage[127.0.0.1:35322,DS-e81cf006-e573-4c27-8cbc-6c5c3eb80524,DISK], DatanodeInfoWithStorage[127.0.0.1:40278,DS-33dafbd3-e4a4-4cf2-96cd-059a7a1e65e5,DISK], DatanodeInfoWithStorage[127.0.0.1:37334,DS-e3817d23-698f-49a3-89be-51ed2f5602a9,DISK], DatanodeInfoWithStorage[127.0.0.1:45077,DS-d904e6e2-6fc8-4379-ad28-c45f55c10f64,DISK], DatanodeInfoWithStorage[127.0.0.1:35316,DS-dd153a21-977d-43bc-82a3-aad4d8d4f5df,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1310221891-172.17.0.21-1598086559812:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38147,DS-fcb0f879-d43b-4a0c-a5c3-cfb3d74c18d7,DISK], DatanodeInfoWithStorage[127.0.0.1:37633,DS-b8843fdd-d44d-4d6d-8f39-09751c23a1e2,DISK], DatanodeInfoWithStorage[127.0.0.1:40625,DS-b5f3f360-8b8d-4553-9877-f478e8e14425,DISK], DatanodeInfoWithStorage[127.0.0.1:35322,DS-e81cf006-e573-4c27-8cbc-6c5c3eb80524,DISK], DatanodeInfoWithStorage[127.0.0.1:40278,DS-33dafbd3-e4a4-4cf2-96cd-059a7a1e65e5,DISK], DatanodeInfoWithStorage[127.0.0.1:37334,DS-e3817d23-698f-49a3-89be-51ed2f5602a9,DISK], DatanodeInfoWithStorage[127.0.0.1:45077,DS-d904e6e2-6fc8-4379-ad28-c45f55c10f64,DISK], DatanodeInfoWithStorage[127.0.0.1:35316,DS-dd153a21-977d-43bc-82a3-aad4d8d4f5df,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-109425972-172.17.0.21-1598086719246:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45711,DS-74d55193-8a63-4cb7-9a96-b9422c8a124c,DISK], DatanodeInfoWithStorage[127.0.0.1:35463,DS-47d45cb1-8734-44ee-8292-b437bd8d4a27,DISK], DatanodeInfoWithStorage[127.0.0.1:37870,DS-c407805a-b369-4078-a986-183d3cbb2b31,DISK], DatanodeInfoWithStorage[127.0.0.1:38897,DS-4ffbf2dd-98c1-4557-89d1-2d80848f5db4,DISK], DatanodeInfoWithStorage[127.0.0.1:40655,DS-11f767ee-f340-4914-886e-12f31c38ba17,DISK], DatanodeInfoWithStorage[127.0.0.1:33811,DS-39f1bffd-5e46-4ff2-b05c-fbc6129aa568,DISK], DatanodeInfoWithStorage[127.0.0.1:34320,DS-dd4796f7-ce62-4d3e-a246-debe6813eec5,DISK], DatanodeInfoWithStorage[127.0.0.1:45392,DS-47bc98a9-a3d4-40d8-9076-16b9f5bda94e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-109425972-172.17.0.21-1598086719246:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45711,DS-74d55193-8a63-4cb7-9a96-b9422c8a124c,DISK], DatanodeInfoWithStorage[127.0.0.1:35463,DS-47d45cb1-8734-44ee-8292-b437bd8d4a27,DISK], DatanodeInfoWithStorage[127.0.0.1:37870,DS-c407805a-b369-4078-a986-183d3cbb2b31,DISK], DatanodeInfoWithStorage[127.0.0.1:38897,DS-4ffbf2dd-98c1-4557-89d1-2d80848f5db4,DISK], DatanodeInfoWithStorage[127.0.0.1:40655,DS-11f767ee-f340-4914-886e-12f31c38ba17,DISK], DatanodeInfoWithStorage[127.0.0.1:33811,DS-39f1bffd-5e46-4ff2-b05c-fbc6129aa568,DISK], DatanodeInfoWithStorage[127.0.0.1:34320,DS-dd4796f7-ce62-4d3e-a246-debe6813eec5,DISK], DatanodeInfoWithStorage[127.0.0.1:45392,DS-47bc98a9-a3d4-40d8-9076-16b9f5bda94e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-18242676-172.17.0.21-1598086788193:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43512,DS-74e1261c-a0ff-4907-9652-91645b82b0e8,DISK], DatanodeInfoWithStorage[127.0.0.1:42879,DS-0e754016-c497-4eb5-af97-acd347e22c0a,DISK], DatanodeInfoWithStorage[127.0.0.1:38517,DS-d1870caf-1d71-47a6-a147-2df015f189e7,DISK], DatanodeInfoWithStorage[127.0.0.1:42383,DS-ee77d166-413b-435b-8f55-efb221715d46,DISK], DatanodeInfoWithStorage[127.0.0.1:46328,DS-f19cee30-1d3b-44cb-9c78-b64473ff1a35,DISK], DatanodeInfoWithStorage[127.0.0.1:36282,DS-d5e93c83-5158-45b9-95a3-10206ed41aba,DISK], DatanodeInfoWithStorage[127.0.0.1:41154,DS-4fd1b809-c1af-43c3-a589-18968919db23,DISK], DatanodeInfoWithStorage[127.0.0.1:39927,DS-3dbfcf4f-9d2a-4184-81ef-caea71bb52ed,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-18242676-172.17.0.21-1598086788193:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43512,DS-74e1261c-a0ff-4907-9652-91645b82b0e8,DISK], DatanodeInfoWithStorage[127.0.0.1:42879,DS-0e754016-c497-4eb5-af97-acd347e22c0a,DISK], DatanodeInfoWithStorage[127.0.0.1:38517,DS-d1870caf-1d71-47a6-a147-2df015f189e7,DISK], DatanodeInfoWithStorage[127.0.0.1:42383,DS-ee77d166-413b-435b-8f55-efb221715d46,DISK], DatanodeInfoWithStorage[127.0.0.1:46328,DS-f19cee30-1d3b-44cb-9c78-b64473ff1a35,DISK], DatanodeInfoWithStorage[127.0.0.1:36282,DS-d5e93c83-5158-45b9-95a3-10206ed41aba,DISK], DatanodeInfoWithStorage[127.0.0.1:41154,DS-4fd1b809-c1af-43c3-a589-18968919db23,DISK], DatanodeInfoWithStorage[127.0.0.1:39927,DS-3dbfcf4f-9d2a-4184-81ef-caea71bb52ed,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-357718583-172.17.0.21-1598086863551:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45027,DS-67f66007-cdf3-4195-9d1e-20d055cde2bb,DISK], DatanodeInfoWithStorage[127.0.0.1:34332,DS-7f206e3e-4663-46de-ac2b-557c45284f15,DISK], DatanodeInfoWithStorage[127.0.0.1:39802,DS-c90c9ed0-5893-4e99-9a9b-ec7f907ddb78,DISK], DatanodeInfoWithStorage[127.0.0.1:37658,DS-bf50633d-d5c9-4847-bb78-7437dbb96cf5,DISK], DatanodeInfoWithStorage[127.0.0.1:42165,DS-3cea45e1-a8e0-459f-a7d5-2a5fb522ff18,DISK], DatanodeInfoWithStorage[127.0.0.1:41183,DS-113ac77b-5a33-4f53-8855-1be10b0bde51,DISK], DatanodeInfoWithStorage[127.0.0.1:37906,DS-01e7d686-83dd-4a78-8183-c0f4df7d00b2,DISK], DatanodeInfoWithStorage[127.0.0.1:36426,DS-9d5070c8-c53b-4bb0-af5a-8d8f5e9bf21b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-357718583-172.17.0.21-1598086863551:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45027,DS-67f66007-cdf3-4195-9d1e-20d055cde2bb,DISK], DatanodeInfoWithStorage[127.0.0.1:34332,DS-7f206e3e-4663-46de-ac2b-557c45284f15,DISK], DatanodeInfoWithStorage[127.0.0.1:39802,DS-c90c9ed0-5893-4e99-9a9b-ec7f907ddb78,DISK], DatanodeInfoWithStorage[127.0.0.1:37658,DS-bf50633d-d5c9-4847-bb78-7437dbb96cf5,DISK], DatanodeInfoWithStorage[127.0.0.1:42165,DS-3cea45e1-a8e0-459f-a7d5-2a5fb522ff18,DISK], DatanodeInfoWithStorage[127.0.0.1:41183,DS-113ac77b-5a33-4f53-8855-1be10b0bde51,DISK], DatanodeInfoWithStorage[127.0.0.1:37906,DS-01e7d686-83dd-4a78-8183-c0f4df7d00b2,DISK], DatanodeInfoWithStorage[127.0.0.1:36426,DS-9d5070c8-c53b-4bb0-af5a-8d8f5e9bf21b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1811872048-172.17.0.21-1598086901804:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37499,DS-702d93b2-1f8c-42fc-b297-cd6b02bff480,DISK], DatanodeInfoWithStorage[127.0.0.1:41077,DS-51242e0f-2c77-4a01-9961-c0768b94ce20,DISK], DatanodeInfoWithStorage[127.0.0.1:36685,DS-474dd884-7107-412b-a918-08dddf1be7d5,DISK], DatanodeInfoWithStorage[127.0.0.1:41886,DS-b8e86fe2-c0c2-4ef3-907d-cc2e0b676299,DISK], DatanodeInfoWithStorage[127.0.0.1:38166,DS-bc00b634-80ae-4ae3-b498-668053599815,DISK], DatanodeInfoWithStorage[127.0.0.1:38563,DS-f09e53a7-0374-4655-bbdc-dc612f105bf0,DISK], DatanodeInfoWithStorage[127.0.0.1:45149,DS-d09f0053-f111-48d0-af42-6808d7aefe16,DISK], DatanodeInfoWithStorage[127.0.0.1:44659,DS-da5dc8a7-94b3-4ecb-a635-480f970a4b7f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1811872048-172.17.0.21-1598086901804:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37499,DS-702d93b2-1f8c-42fc-b297-cd6b02bff480,DISK], DatanodeInfoWithStorage[127.0.0.1:41077,DS-51242e0f-2c77-4a01-9961-c0768b94ce20,DISK], DatanodeInfoWithStorage[127.0.0.1:36685,DS-474dd884-7107-412b-a918-08dddf1be7d5,DISK], DatanodeInfoWithStorage[127.0.0.1:41886,DS-b8e86fe2-c0c2-4ef3-907d-cc2e0b676299,DISK], DatanodeInfoWithStorage[127.0.0.1:38166,DS-bc00b634-80ae-4ae3-b498-668053599815,DISK], DatanodeInfoWithStorage[127.0.0.1:38563,DS-f09e53a7-0374-4655-bbdc-dc612f105bf0,DISK], DatanodeInfoWithStorage[127.0.0.1:45149,DS-d09f0053-f111-48d0-af42-6808d7aefe16,DISK], DatanodeInfoWithStorage[127.0.0.1:44659,DS-da5dc8a7-94b3-4ecb-a635-480f970a4b7f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-592914665-172.17.0.21-1598087090633:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38144,DS-92d0413c-f5f6-4ba4-af67-90a48776fa07,DISK], DatanodeInfoWithStorage[127.0.0.1:33280,DS-6c3cad4f-9840-47c4-b9ce-ee5b63688712,DISK], DatanodeInfoWithStorage[127.0.0.1:36797,DS-8076533f-74b8-4a0a-9f39-abcfb71d2868,DISK], DatanodeInfoWithStorage[127.0.0.1:35597,DS-fbb3ac30-ac4d-4e94-abc2-0bfc1bbf555b,DISK], DatanodeInfoWithStorage[127.0.0.1:43732,DS-44aa40da-64eb-46e7-8f22-b1eb46651125,DISK], DatanodeInfoWithStorage[127.0.0.1:44479,DS-4d194862-4d39-4b16-be93-0b2a7ed0f512,DISK], DatanodeInfoWithStorage[127.0.0.1:38122,DS-a972f50b-9d4a-485f-8e39-aa8f8d14d37b,DISK], DatanodeInfoWithStorage[127.0.0.1:43739,DS-6d882b73-fec6-4608-99ea-eecdb8752126,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-592914665-172.17.0.21-1598087090633:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38144,DS-92d0413c-f5f6-4ba4-af67-90a48776fa07,DISK], DatanodeInfoWithStorage[127.0.0.1:33280,DS-6c3cad4f-9840-47c4-b9ce-ee5b63688712,DISK], DatanodeInfoWithStorage[127.0.0.1:36797,DS-8076533f-74b8-4a0a-9f39-abcfb71d2868,DISK], DatanodeInfoWithStorage[127.0.0.1:35597,DS-fbb3ac30-ac4d-4e94-abc2-0bfc1bbf555b,DISK], DatanodeInfoWithStorage[127.0.0.1:43732,DS-44aa40da-64eb-46e7-8f22-b1eb46651125,DISK], DatanodeInfoWithStorage[127.0.0.1:44479,DS-4d194862-4d39-4b16-be93-0b2a7ed0f512,DISK], DatanodeInfoWithStorage[127.0.0.1:38122,DS-a972f50b-9d4a-485f-8e39-aa8f8d14d37b,DISK], DatanodeInfoWithStorage[127.0.0.1:43739,DS-6d882b73-fec6-4608-99ea-eecdb8752126,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-449255485-172.17.0.21-1598087233426:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45833,DS-7460f5d3-98fc-4bc2-b799-c993601e06b6,DISK], DatanodeInfoWithStorage[127.0.0.1:34902,DS-5a7ef38b-1dd2-46ac-8bab-600fe812eb9c,DISK], DatanodeInfoWithStorage[127.0.0.1:42265,DS-3db725ed-6011-40c8-b73a-42c101e72f48,DISK], DatanodeInfoWithStorage[127.0.0.1:40052,DS-645f529f-d982-4c5b-a2cf-2e622facd740,DISK], DatanodeInfoWithStorage[127.0.0.1:35975,DS-0e4e0d59-3472-4ca9-be7f-f68fc812c142,DISK], DatanodeInfoWithStorage[127.0.0.1:41825,DS-4058fa38-fb41-4844-9f35-55e8f882ceb6,DISK], DatanodeInfoWithStorage[127.0.0.1:35428,DS-b69bb5ce-effd-479a-8e82-35c7f52172ff,DISK], DatanodeInfoWithStorage[127.0.0.1:33134,DS-72aa4986-de24-44b7-9e02-2fe0ccbf43b3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-449255485-172.17.0.21-1598087233426:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45833,DS-7460f5d3-98fc-4bc2-b799-c993601e06b6,DISK], DatanodeInfoWithStorage[127.0.0.1:34902,DS-5a7ef38b-1dd2-46ac-8bab-600fe812eb9c,DISK], DatanodeInfoWithStorage[127.0.0.1:42265,DS-3db725ed-6011-40c8-b73a-42c101e72f48,DISK], DatanodeInfoWithStorage[127.0.0.1:40052,DS-645f529f-d982-4c5b-a2cf-2e622facd740,DISK], DatanodeInfoWithStorage[127.0.0.1:35975,DS-0e4e0d59-3472-4ca9-be7f-f68fc812c142,DISK], DatanodeInfoWithStorage[127.0.0.1:41825,DS-4058fa38-fb41-4844-9f35-55e8f882ceb6,DISK], DatanodeInfoWithStorage[127.0.0.1:35428,DS-b69bb5ce-effd-479a-8e82-35c7f52172ff,DISK], DatanodeInfoWithStorage[127.0.0.1:33134,DS-72aa4986-de24-44b7-9e02-2fe0ccbf43b3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: hadoop.security.authorization
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-297986936-172.17.0.21-1598087274956:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42161,DS-a251d3c6-6cfe-4122-9765-0c3aeb4c64d4,DISK], DatanodeInfoWithStorage[127.0.0.1:42728,DS-17e3653f-04be-41e2-a542-381c7b0ad61b,DISK], DatanodeInfoWithStorage[127.0.0.1:33410,DS-c6ef4497-7d7d-486b-96a3-151d910779ef,DISK], DatanodeInfoWithStorage[127.0.0.1:45644,DS-e2156b87-f662-4b52-a6e0-7b731a227941,DISK], DatanodeInfoWithStorage[127.0.0.1:38056,DS-0b1e7482-5860-477a-acda-79fb93e328da,DISK], DatanodeInfoWithStorage[127.0.0.1:45110,DS-802c8b60-16a8-4635-a0df-a0b497ec160e,DISK], DatanodeInfoWithStorage[127.0.0.1:37108,DS-93528fde-16ad-4d4b-b4b4-abca0e49f21a,DISK], DatanodeInfoWithStorage[127.0.0.1:35950,DS-57c0d258-ba0e-4db6-b846-bae89b6ec610,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-297986936-172.17.0.21-1598087274956:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42161,DS-a251d3c6-6cfe-4122-9765-0c3aeb4c64d4,DISK], DatanodeInfoWithStorage[127.0.0.1:42728,DS-17e3653f-04be-41e2-a542-381c7b0ad61b,DISK], DatanodeInfoWithStorage[127.0.0.1:33410,DS-c6ef4497-7d7d-486b-96a3-151d910779ef,DISK], DatanodeInfoWithStorage[127.0.0.1:45644,DS-e2156b87-f662-4b52-a6e0-7b731a227941,DISK], DatanodeInfoWithStorage[127.0.0.1:38056,DS-0b1e7482-5860-477a-acda-79fb93e328da,DISK], DatanodeInfoWithStorage[127.0.0.1:45110,DS-802c8b60-16a8-4635-a0df-a0b497ec160e,DISK], DatanodeInfoWithStorage[127.0.0.1:37108,DS-93528fde-16ad-4d4b-b4b4-abca0e49f21a,DISK], DatanodeInfoWithStorage[127.0.0.1:35950,DS-57c0d258-ba0e-4db6-b846-bae89b6ec610,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-907872705-172.17.0.21-1598087316154:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43285,DS-537fb14f-dc27-459b-b3b3-8cad93a22149,DISK], DatanodeInfoWithStorage[127.0.0.1:41764,DS-3f804dda-46ba-49f6-a589-6a99376aa838,DISK], DatanodeInfoWithStorage[127.0.0.1:43823,DS-7d75b7c0-c930-4d8f-a3d5-2f28401fd75a,DISK], DatanodeInfoWithStorage[127.0.0.1:40655,DS-8751062d-e718-46b7-9c15-0383f0e14b18,DISK], DatanodeInfoWithStorage[127.0.0.1:33571,DS-356d2356-9bc6-435d-93ba-bda8fbf059e2,DISK], DatanodeInfoWithStorage[127.0.0.1:34586,DS-81e9c0fd-4e84-436a-845a-ea49b84ff3b1,DISK], DatanodeInfoWithStorage[127.0.0.1:45026,DS-318fb67f-12f0-4342-8b64-b6ff985cb941,DISK], DatanodeInfoWithStorage[127.0.0.1:35232,DS-5cbd9c32-4b41-43a4-9205-37156cf7f672,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-907872705-172.17.0.21-1598087316154:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43285,DS-537fb14f-dc27-459b-b3b3-8cad93a22149,DISK], DatanodeInfoWithStorage[127.0.0.1:41764,DS-3f804dda-46ba-49f6-a589-6a99376aa838,DISK], DatanodeInfoWithStorage[127.0.0.1:43823,DS-7d75b7c0-c930-4d8f-a3d5-2f28401fd75a,DISK], DatanodeInfoWithStorage[127.0.0.1:40655,DS-8751062d-e718-46b7-9c15-0383f0e14b18,DISK], DatanodeInfoWithStorage[127.0.0.1:33571,DS-356d2356-9bc6-435d-93ba-bda8fbf059e2,DISK], DatanodeInfoWithStorage[127.0.0.1:34586,DS-81e9c0fd-4e84-436a-845a-ea49b84ff3b1,DISK], DatanodeInfoWithStorage[127.0.0.1:45026,DS-318fb67f-12f0-4342-8b64-b6ff985cb941,DISK], DatanodeInfoWithStorage[127.0.0.1:35232,DS-5cbd9c32-4b41-43a4-9205-37156cf7f672,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2057467059-172.17.0.21-1598087430049:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38191,DS-8e2821e2-d36f-4077-8e69-ad648fdb863c,DISK], DatanodeInfoWithStorage[127.0.0.1:38916,DS-f090ae31-82b3-49ac-9653-f7bb3362f65c,DISK], DatanodeInfoWithStorage[127.0.0.1:43477,DS-ea494412-00ff-4316-9a8e-e9e451b438a9,DISK], DatanodeInfoWithStorage[127.0.0.1:34178,DS-bc857a83-45de-4d62-91bd-4bb9e609a581,DISK], DatanodeInfoWithStorage[127.0.0.1:40045,DS-f071cb1b-4c7e-40af-849e-5d25302e5f0b,DISK], DatanodeInfoWithStorage[127.0.0.1:38399,DS-0eaa8efc-7d7a-4b59-a379-2e0e8ea40793,DISK], DatanodeInfoWithStorage[127.0.0.1:33166,DS-3a4e0f46-c9d3-4eeb-b5b9-116bccab8d09,DISK], DatanodeInfoWithStorage[127.0.0.1:44270,DS-a7eb8e28-8a4a-4ae6-a9ac-57c46ccf8446,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2057467059-172.17.0.21-1598087430049:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38191,DS-8e2821e2-d36f-4077-8e69-ad648fdb863c,DISK], DatanodeInfoWithStorage[127.0.0.1:38916,DS-f090ae31-82b3-49ac-9653-f7bb3362f65c,DISK], DatanodeInfoWithStorage[127.0.0.1:43477,DS-ea494412-00ff-4316-9a8e-e9e451b438a9,DISK], DatanodeInfoWithStorage[127.0.0.1:34178,DS-bc857a83-45de-4d62-91bd-4bb9e609a581,DISK], DatanodeInfoWithStorage[127.0.0.1:40045,DS-f071cb1b-4c7e-40af-849e-5d25302e5f0b,DISK], DatanodeInfoWithStorage[127.0.0.1:38399,DS-0eaa8efc-7d7a-4b59-a379-2e0e8ea40793,DISK], DatanodeInfoWithStorage[127.0.0.1:33166,DS-3a4e0f46-c9d3-4eeb-b5b9-116bccab8d09,DISK], DatanodeInfoWithStorage[127.0.0.1:44270,DS-a7eb8e28-8a4a-4ae6-a9ac-57c46ccf8446,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1825826991-172.17.0.21-1598087548891:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40032,DS-2af04b9c-4755-4e24-93a4-67a3163cdc9d,DISK], DatanodeInfoWithStorage[127.0.0.1:40823,DS-67f3ff8e-9b36-463b-b5bd-5ec83b859b52,DISK], DatanodeInfoWithStorage[127.0.0.1:38853,DS-de396af2-a63f-4448-98e9-8d61d1a56270,DISK], DatanodeInfoWithStorage[127.0.0.1:38880,DS-23f2b97b-2a3a-4213-9615-ea696f50af28,DISK], DatanodeInfoWithStorage[127.0.0.1:42614,DS-a48cd2ef-8c2b-4f7b-8596-9c9e489f9657,DISK], DatanodeInfoWithStorage[127.0.0.1:42799,DS-5a309d98-79e7-4934-91e4-693da78c4c12,DISK], DatanodeInfoWithStorage[127.0.0.1:43396,DS-c5035588-c2c8-47e6-847f-726164611cf8,DISK], DatanodeInfoWithStorage[127.0.0.1:35538,DS-a8fe0925-5007-4a65-b087-b03174d4895f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1825826991-172.17.0.21-1598087548891:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40032,DS-2af04b9c-4755-4e24-93a4-67a3163cdc9d,DISK], DatanodeInfoWithStorage[127.0.0.1:40823,DS-67f3ff8e-9b36-463b-b5bd-5ec83b859b52,DISK], DatanodeInfoWithStorage[127.0.0.1:38853,DS-de396af2-a63f-4448-98e9-8d61d1a56270,DISK], DatanodeInfoWithStorage[127.0.0.1:38880,DS-23f2b97b-2a3a-4213-9615-ea696f50af28,DISK], DatanodeInfoWithStorage[127.0.0.1:42614,DS-a48cd2ef-8c2b-4f7b-8596-9c9e489f9657,DISK], DatanodeInfoWithStorage[127.0.0.1:42799,DS-5a309d98-79e7-4934-91e4-693da78c4c12,DISK], DatanodeInfoWithStorage[127.0.0.1:43396,DS-c5035588-c2c8-47e6-847f-726164611cf8,DISK], DatanodeInfoWithStorage[127.0.0.1:35538,DS-a8fe0925-5007-4a65-b087-b03174d4895f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1884231359-172.17.0.21-1598087590048:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36211,DS-81df2245-8348-4f63-92f3-fc2173bd4b79,DISK], DatanodeInfoWithStorage[127.0.0.1:43804,DS-9733a47c-b950-480f-9031-e8ad95ff7505,DISK], DatanodeInfoWithStorage[127.0.0.1:37114,DS-d3ace4e3-b518-4e56-bde7-bee5efb3eae5,DISK], DatanodeInfoWithStorage[127.0.0.1:35237,DS-4d13e58e-7aff-45ad-aa13-762aca514a69,DISK], DatanodeInfoWithStorage[127.0.0.1:32981,DS-4f5cffd7-1f28-460a-a5eb-9c27df46f2bf,DISK], DatanodeInfoWithStorage[127.0.0.1:32800,DS-9bda5156-1a5e-4a0a-b6d5-75c54ef3afdb,DISK], DatanodeInfoWithStorage[127.0.0.1:43694,DS-bc88de57-e353-4db4-85f0-deb6bf7b7a61,DISK], DatanodeInfoWithStorage[127.0.0.1:45599,DS-db4ab803-23b3-4011-96a9-722b8dbc04ac,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1884231359-172.17.0.21-1598087590048:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36211,DS-81df2245-8348-4f63-92f3-fc2173bd4b79,DISK], DatanodeInfoWithStorage[127.0.0.1:43804,DS-9733a47c-b950-480f-9031-e8ad95ff7505,DISK], DatanodeInfoWithStorage[127.0.0.1:37114,DS-d3ace4e3-b518-4e56-bde7-bee5efb3eae5,DISK], DatanodeInfoWithStorage[127.0.0.1:35237,DS-4d13e58e-7aff-45ad-aa13-762aca514a69,DISK], DatanodeInfoWithStorage[127.0.0.1:32981,DS-4f5cffd7-1f28-460a-a5eb-9c27df46f2bf,DISK], DatanodeInfoWithStorage[127.0.0.1:32800,DS-9bda5156-1a5e-4a0a-b6d5-75c54ef3afdb,DISK], DatanodeInfoWithStorage[127.0.0.1:43694,DS-bc88de57-e353-4db4-85f0-deb6bf7b7a61,DISK], DatanodeInfoWithStorage[127.0.0.1:45599,DS-db4ab803-23b3-4011-96a9-722b8dbc04ac,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1458979651-172.17.0.21-1598087733198:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43974,DS-5edad1c7-297e-4798-8658-f0bed7994bca,DISK], DatanodeInfoWithStorage[127.0.0.1:43589,DS-9ed4a18c-e1be-4bb9-8064-16f251babde1,DISK], DatanodeInfoWithStorage[127.0.0.1:41280,DS-cbd8959b-3779-4f6d-bddb-1047e27a5eec,DISK], DatanodeInfoWithStorage[127.0.0.1:45677,DS-43da0bbb-cdb4-4d37-8012-84c56462aca0,DISK], DatanodeInfoWithStorage[127.0.0.1:34290,DS-d59cbc51-1f72-40b8-9fc2-648e05bd3c8a,DISK], DatanodeInfoWithStorage[127.0.0.1:42289,DS-fe1bfcba-0272-4052-b125-4ff7ae53e971,DISK], DatanodeInfoWithStorage[127.0.0.1:46251,DS-33427ef0-f4c7-4410-9646-86ba8f48fef1,DISK], DatanodeInfoWithStorage[127.0.0.1:43715,DS-77bf7b5e-d8d6-4708-a727-0edfa60fd5be,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1458979651-172.17.0.21-1598087733198:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43974,DS-5edad1c7-297e-4798-8658-f0bed7994bca,DISK], DatanodeInfoWithStorage[127.0.0.1:43589,DS-9ed4a18c-e1be-4bb9-8064-16f251babde1,DISK], DatanodeInfoWithStorage[127.0.0.1:41280,DS-cbd8959b-3779-4f6d-bddb-1047e27a5eec,DISK], DatanodeInfoWithStorage[127.0.0.1:45677,DS-43da0bbb-cdb4-4d37-8012-84c56462aca0,DISK], DatanodeInfoWithStorage[127.0.0.1:34290,DS-d59cbc51-1f72-40b8-9fc2-648e05bd3c8a,DISK], DatanodeInfoWithStorage[127.0.0.1:42289,DS-fe1bfcba-0272-4052-b125-4ff7ae53e971,DISK], DatanodeInfoWithStorage[127.0.0.1:46251,DS-33427ef0-f4c7-4410-9646-86ba8f48fef1,DISK], DatanodeInfoWithStorage[127.0.0.1:43715,DS-77bf7b5e-d8d6-4708-a727-0edfa60fd5be,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-916846744-172.17.0.21-1598087774283:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44356,DS-3eb21e55-53bf-4d44-acf0-a0dba13f24a7,DISK], DatanodeInfoWithStorage[127.0.0.1:38858,DS-6c129ab5-e892-4bdb-9193-8e8c169921a7,DISK], DatanodeInfoWithStorage[127.0.0.1:40800,DS-46d87392-5523-4ef0-9714-206e46cd1655,DISK], DatanodeInfoWithStorage[127.0.0.1:41508,DS-e85f4256-f5a8-41d5-9b18-559fdc5d9a09,DISK], DatanodeInfoWithStorage[127.0.0.1:38171,DS-0363f16c-f22b-44a6-a2f8-cc20f2ed42d5,DISK], DatanodeInfoWithStorage[127.0.0.1:34236,DS-9999a698-7795-4d9f-8a84-adc88344d0c4,DISK], DatanodeInfoWithStorage[127.0.0.1:40935,DS-47de00fa-6f26-43e5-ab93-fe2f65d3c300,DISK], DatanodeInfoWithStorage[127.0.0.1:36090,DS-e9007d29-913a-4885-993d-1dd1effcc05e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-916846744-172.17.0.21-1598087774283:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44356,DS-3eb21e55-53bf-4d44-acf0-a0dba13f24a7,DISK], DatanodeInfoWithStorage[127.0.0.1:38858,DS-6c129ab5-e892-4bdb-9193-8e8c169921a7,DISK], DatanodeInfoWithStorage[127.0.0.1:40800,DS-46d87392-5523-4ef0-9714-206e46cd1655,DISK], DatanodeInfoWithStorage[127.0.0.1:41508,DS-e85f4256-f5a8-41d5-9b18-559fdc5d9a09,DISK], DatanodeInfoWithStorage[127.0.0.1:38171,DS-0363f16c-f22b-44a6-a2f8-cc20f2ed42d5,DISK], DatanodeInfoWithStorage[127.0.0.1:34236,DS-9999a698-7795-4d9f-8a84-adc88344d0c4,DISK], DatanodeInfoWithStorage[127.0.0.1:40935,DS-47de00fa-6f26-43e5-ab93-fe2f65d3c300,DISK], DatanodeInfoWithStorage[127.0.0.1:36090,DS-e9007d29-913a-4885-993d-1dd1effcc05e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-186280867-172.17.0.21-1598087850338:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46724,DS-bc849d2a-4dfe-4a30-87d3-05322f08f0dc,DISK], DatanodeInfoWithStorage[127.0.0.1:36487,DS-f0d0a4fd-aae9-4e68-a24d-847c29ea161b,DISK], DatanodeInfoWithStorage[127.0.0.1:34919,DS-974f0008-b8de-432c-b0e1-3573b5a5f345,DISK], DatanodeInfoWithStorage[127.0.0.1:41133,DS-bebcb0d8-0e8a-4177-999c-83998b6bb4c5,DISK], DatanodeInfoWithStorage[127.0.0.1:37509,DS-28a2ee55-8851-4b93-b9f9-166f7786ee1c,DISK], DatanodeInfoWithStorage[127.0.0.1:42892,DS-6dff54d5-2b15-4239-8b56-1694526c2d03,DISK], DatanodeInfoWithStorage[127.0.0.1:41107,DS-8c8d6e88-ef0f-4f3d-9f7d-57975d6c7c6a,DISK], DatanodeInfoWithStorage[127.0.0.1:41929,DS-095542ec-2038-4c93-90e5-a2617925950c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-186280867-172.17.0.21-1598087850338:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46724,DS-bc849d2a-4dfe-4a30-87d3-05322f08f0dc,DISK], DatanodeInfoWithStorage[127.0.0.1:36487,DS-f0d0a4fd-aae9-4e68-a24d-847c29ea161b,DISK], DatanodeInfoWithStorage[127.0.0.1:34919,DS-974f0008-b8de-432c-b0e1-3573b5a5f345,DISK], DatanodeInfoWithStorage[127.0.0.1:41133,DS-bebcb0d8-0e8a-4177-999c-83998b6bb4c5,DISK], DatanodeInfoWithStorage[127.0.0.1:37509,DS-28a2ee55-8851-4b93-b9f9-166f7786ee1c,DISK], DatanodeInfoWithStorage[127.0.0.1:42892,DS-6dff54d5-2b15-4239-8b56-1694526c2d03,DISK], DatanodeInfoWithStorage[127.0.0.1:41107,DS-8c8d6e88-ef0f-4f3d-9f7d-57975d6c7c6a,DISK], DatanodeInfoWithStorage[127.0.0.1:41929,DS-095542ec-2038-4c93-90e5-a2617925950c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1044003679-172.17.0.21-1598088084297:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39081,DS-abcfc1cb-292b-4a32-9d1f-bcd93c80f360,DISK], DatanodeInfoWithStorage[127.0.0.1:41091,DS-d19bfdae-2578-42fd-8047-c96856635330,DISK], DatanodeInfoWithStorage[127.0.0.1:37430,DS-92f9e8ff-5dba-4d1a-b3db-e3caf5ec51be,DISK], DatanodeInfoWithStorage[127.0.0.1:40925,DS-ff1e3169-548b-4a63-a66b-5879a9baf246,DISK], DatanodeInfoWithStorage[127.0.0.1:36019,DS-049fa1c4-1d3d-4e55-815e-00b4ee937965,DISK], DatanodeInfoWithStorage[127.0.0.1:33635,DS-efbcc0c0-a773-4064-86c5-214025fb57dd,DISK], DatanodeInfoWithStorage[127.0.0.1:45060,DS-1fa2c85a-19aa-4fa4-8289-243cccca9e08,DISK], DatanodeInfoWithStorage[127.0.0.1:37191,DS-4efe7a53-b09b-4752-bf00-189badd7ef0a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1044003679-172.17.0.21-1598088084297:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39081,DS-abcfc1cb-292b-4a32-9d1f-bcd93c80f360,DISK], DatanodeInfoWithStorage[127.0.0.1:41091,DS-d19bfdae-2578-42fd-8047-c96856635330,DISK], DatanodeInfoWithStorage[127.0.0.1:37430,DS-92f9e8ff-5dba-4d1a-b3db-e3caf5ec51be,DISK], DatanodeInfoWithStorage[127.0.0.1:40925,DS-ff1e3169-548b-4a63-a66b-5879a9baf246,DISK], DatanodeInfoWithStorage[127.0.0.1:36019,DS-049fa1c4-1d3d-4e55-815e-00b4ee937965,DISK], DatanodeInfoWithStorage[127.0.0.1:33635,DS-efbcc0c0-a773-4064-86c5-214025fb57dd,DISK], DatanodeInfoWithStorage[127.0.0.1:45060,DS-1fa2c85a-19aa-4fa4-8289-243cccca9e08,DISK], DatanodeInfoWithStorage[127.0.0.1:37191,DS-4efe7a53-b09b-4752-bf00-189badd7ef0a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-295880755-172.17.0.21-1598088208310:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40763,DS-d79999bb-7356-48d1-beed-5d2c2b0543c1,DISK], DatanodeInfoWithStorage[127.0.0.1:33654,DS-b9644c02-0341-49fc-9200-b1dfd09d3631,DISK], DatanodeInfoWithStorage[127.0.0.1:45994,DS-0352cf3f-f9ea-4b56-b70e-b7c0bcc6fe85,DISK], DatanodeInfoWithStorage[127.0.0.1:46733,DS-dd95ec7d-e95e-404d-9135-ae2c1b500c99,DISK], DatanodeInfoWithStorage[127.0.0.1:36020,DS-10478ab0-c788-4e39-954d-17c3c8458d10,DISK], DatanodeInfoWithStorage[127.0.0.1:44267,DS-abfd2de6-c5ca-46a5-b536-92754cb1dacd,DISK], DatanodeInfoWithStorage[127.0.0.1:36259,DS-0cdaab7b-d424-488f-9c26-53ab55b4576b,DISK], DatanodeInfoWithStorage[127.0.0.1:43516,DS-05b141d5-98f8-4192-9ee0-8fbe0494b814,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-295880755-172.17.0.21-1598088208310:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40763,DS-d79999bb-7356-48d1-beed-5d2c2b0543c1,DISK], DatanodeInfoWithStorage[127.0.0.1:33654,DS-b9644c02-0341-49fc-9200-b1dfd09d3631,DISK], DatanodeInfoWithStorage[127.0.0.1:45994,DS-0352cf3f-f9ea-4b56-b70e-b7c0bcc6fe85,DISK], DatanodeInfoWithStorage[127.0.0.1:46733,DS-dd95ec7d-e95e-404d-9135-ae2c1b500c99,DISK], DatanodeInfoWithStorage[127.0.0.1:36020,DS-10478ab0-c788-4e39-954d-17c3c8458d10,DISK], DatanodeInfoWithStorage[127.0.0.1:44267,DS-abfd2de6-c5ca-46a5-b536-92754cb1dacd,DISK], DatanodeInfoWithStorage[127.0.0.1:36259,DS-0cdaab7b-d424-488f-9c26-53ab55b4576b,DISK], DatanodeInfoWithStorage[127.0.0.1:43516,DS-05b141d5-98f8-4192-9ee0-8fbe0494b814,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-517921848-172.17.0.21-1598088287849:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46319,DS-ebdde85c-4243-4786-bf28-23e19cf1a207,DISK], DatanodeInfoWithStorage[127.0.0.1:33356,DS-f6a44d21-7db9-4ce1-9b2f-bbd397a0a018,DISK], DatanodeInfoWithStorage[127.0.0.1:40143,DS-18525dfd-d249-4f92-bec0-cd200ccfc771,DISK], DatanodeInfoWithStorage[127.0.0.1:46833,DS-d8b94b74-5d88-497a-ae28-dc5f58fe8a7b,DISK], DatanodeInfoWithStorage[127.0.0.1:36309,DS-22899c29-54d5-4e3a-a8fa-c9ea307fb67f,DISK], DatanodeInfoWithStorage[127.0.0.1:36060,DS-dbf64345-65f4-4ae1-8be5-5d0104840497,DISK], DatanodeInfoWithStorage[127.0.0.1:42180,DS-236d45ce-f1b9-4954-8759-034bac630807,DISK], DatanodeInfoWithStorage[127.0.0.1:41230,DS-ec2d0176-c5ae-41a5-b5e1-db0a9818c10d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-517921848-172.17.0.21-1598088287849:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46319,DS-ebdde85c-4243-4786-bf28-23e19cf1a207,DISK], DatanodeInfoWithStorage[127.0.0.1:33356,DS-f6a44d21-7db9-4ce1-9b2f-bbd397a0a018,DISK], DatanodeInfoWithStorage[127.0.0.1:40143,DS-18525dfd-d249-4f92-bec0-cd200ccfc771,DISK], DatanodeInfoWithStorage[127.0.0.1:46833,DS-d8b94b74-5d88-497a-ae28-dc5f58fe8a7b,DISK], DatanodeInfoWithStorage[127.0.0.1:36309,DS-22899c29-54d5-4e3a-a8fa-c9ea307fb67f,DISK], DatanodeInfoWithStorage[127.0.0.1:36060,DS-dbf64345-65f4-4ae1-8be5-5d0104840497,DISK], DatanodeInfoWithStorage[127.0.0.1:42180,DS-236d45ce-f1b9-4954-8759-034bac630807,DISK], DatanodeInfoWithStorage[127.0.0.1:41230,DS-ec2d0176-c5ae-41a5-b5e1-db0a9818c10d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: hadoop.security.authorization
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1816464438-172.17.0.21-1598088320847:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37343,DS-bd140702-82b2-484b-8dce-27e88b92d2a7,DISK], DatanodeInfoWithStorage[127.0.0.1:44094,DS-0edafd87-2338-49b7-9fe1-af143f3cae1a,DISK], DatanodeInfoWithStorage[127.0.0.1:34415,DS-1757d522-e7c2-4e44-a0e0-bd1f900de5a9,DISK], DatanodeInfoWithStorage[127.0.0.1:33621,DS-cd478060-4fae-4bb2-a335-33c28749c9ff,DISK], DatanodeInfoWithStorage[127.0.0.1:38005,DS-b5d898d1-b828-40aa-a7f9-4d6e9a1bc416,DISK], DatanodeInfoWithStorage[127.0.0.1:35002,DS-392e4072-1990-43d4-ae29-d9e0d63bfdfd,DISK], DatanodeInfoWithStorage[127.0.0.1:36296,DS-8e74032f-0a5f-4d03-a198-8c19368209b8,DISK], DatanodeInfoWithStorage[127.0.0.1:40749,DS-7dbacd69-b736-4aab-b40d-97d3809f506e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1816464438-172.17.0.21-1598088320847:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37343,DS-bd140702-82b2-484b-8dce-27e88b92d2a7,DISK], DatanodeInfoWithStorage[127.0.0.1:44094,DS-0edafd87-2338-49b7-9fe1-af143f3cae1a,DISK], DatanodeInfoWithStorage[127.0.0.1:34415,DS-1757d522-e7c2-4e44-a0e0-bd1f900de5a9,DISK], DatanodeInfoWithStorage[127.0.0.1:33621,DS-cd478060-4fae-4bb2-a335-33c28749c9ff,DISK], DatanodeInfoWithStorage[127.0.0.1:38005,DS-b5d898d1-b828-40aa-a7f9-4d6e9a1bc416,DISK], DatanodeInfoWithStorage[127.0.0.1:35002,DS-392e4072-1990-43d4-ae29-d9e0d63bfdfd,DISK], DatanodeInfoWithStorage[127.0.0.1:36296,DS-8e74032f-0a5f-4d03-a198-8c19368209b8,DISK], DatanodeInfoWithStorage[127.0.0.1:40749,DS-7dbacd69-b736-4aab-b40d-97d3809f506e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-429227603-172.17.0.21-1598088359680:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37076,DS-a26a2f69-23db-4b49-ab83-d8111b84e58c,DISK], DatanodeInfoWithStorage[127.0.0.1:45090,DS-b0fe7f5d-aca0-4ebc-b694-5f9afd81039c,DISK], DatanodeInfoWithStorage[127.0.0.1:33139,DS-a2e88eca-7a3b-4ff5-bed1-a0486bc7ed07,DISK], DatanodeInfoWithStorage[127.0.0.1:32998,DS-0a140624-b025-4681-ad20-9827b6a04511,DISK], DatanodeInfoWithStorage[127.0.0.1:44383,DS-ef17d623-ece7-433c-b3b7-449c15b3dab5,DISK], DatanodeInfoWithStorage[127.0.0.1:43428,DS-2420650d-7c2b-42b6-abb7-8869c61d1daf,DISK], DatanodeInfoWithStorage[127.0.0.1:34515,DS-8413c937-9eb3-4cf1-a6c5-58cc50c9b4c6,DISK], DatanodeInfoWithStorage[127.0.0.1:36561,DS-6657e9c9-3806-404c-9bb2-e06de2947759,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-429227603-172.17.0.21-1598088359680:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37076,DS-a26a2f69-23db-4b49-ab83-d8111b84e58c,DISK], DatanodeInfoWithStorage[127.0.0.1:45090,DS-b0fe7f5d-aca0-4ebc-b694-5f9afd81039c,DISK], DatanodeInfoWithStorage[127.0.0.1:33139,DS-a2e88eca-7a3b-4ff5-bed1-a0486bc7ed07,DISK], DatanodeInfoWithStorage[127.0.0.1:32998,DS-0a140624-b025-4681-ad20-9827b6a04511,DISK], DatanodeInfoWithStorage[127.0.0.1:44383,DS-ef17d623-ece7-433c-b3b7-449c15b3dab5,DISK], DatanodeInfoWithStorage[127.0.0.1:43428,DS-2420650d-7c2b-42b6-abb7-8869c61d1daf,DISK], DatanodeInfoWithStorage[127.0.0.1:34515,DS-8413c937-9eb3-4cf1-a6c5-58cc50c9b4c6,DISK], DatanodeInfoWithStorage[127.0.0.1:36561,DS-6657e9c9-3806-404c-9bb2-e06de2947759,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1810958162-172.17.0.21-1598088404294:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35190,DS-34361c64-c37f-4ffb-8d87-32183c7a45bb,DISK], DatanodeInfoWithStorage[127.0.0.1:35204,DS-cdb9d04f-3f7a-41dd-9497-bb67583b4273,DISK], DatanodeInfoWithStorage[127.0.0.1:46222,DS-a11eece6-16ba-4106-a33c-58c8d5c49faf,DISK], DatanodeInfoWithStorage[127.0.0.1:38365,DS-d60dd0b5-1049-4b2d-992a-65e019225d79,DISK], DatanodeInfoWithStorage[127.0.0.1:38278,DS-4ac396b9-9d5d-4b0c-8fc6-8940827b1e6a,DISK], DatanodeInfoWithStorage[127.0.0.1:36202,DS-2266efee-f870-4472-9367-36716704c941,DISK], DatanodeInfoWithStorage[127.0.0.1:35385,DS-41368aa0-61dc-42f8-8f07-e5a9828e4df4,DISK], DatanodeInfoWithStorage[127.0.0.1:42676,DS-b4e08ab9-75fe-4740-8f5c-7401471fe9b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1810958162-172.17.0.21-1598088404294:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35190,DS-34361c64-c37f-4ffb-8d87-32183c7a45bb,DISK], DatanodeInfoWithStorage[127.0.0.1:35204,DS-cdb9d04f-3f7a-41dd-9497-bb67583b4273,DISK], DatanodeInfoWithStorage[127.0.0.1:46222,DS-a11eece6-16ba-4106-a33c-58c8d5c49faf,DISK], DatanodeInfoWithStorage[127.0.0.1:38365,DS-d60dd0b5-1049-4b2d-992a-65e019225d79,DISK], DatanodeInfoWithStorage[127.0.0.1:38278,DS-4ac396b9-9d5d-4b0c-8fc6-8940827b1e6a,DISK], DatanodeInfoWithStorage[127.0.0.1:36202,DS-2266efee-f870-4472-9367-36716704c941,DISK], DatanodeInfoWithStorage[127.0.0.1:35385,DS-41368aa0-61dc-42f8-8f07-e5a9828e4df4,DISK], DatanodeInfoWithStorage[127.0.0.1:42676,DS-b4e08ab9-75fe-4740-8f5c-7401471fe9b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: hadoop.security.authorization
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1953533840-172.17.0.21-1598088438245:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34158,DS-eb994e99-8dee-4ffc-9d6b-06aae0cb5219,DISK], DatanodeInfoWithStorage[127.0.0.1:43261,DS-5bf7fcbc-f6b5-40c5-abce-9b459fc2fe4d,DISK], DatanodeInfoWithStorage[127.0.0.1:39642,DS-1f792e0e-8cee-4286-ad42-6a460b1b980b,DISK], DatanodeInfoWithStorage[127.0.0.1:43706,DS-902567c2-fa80-4096-a6de-47a8936745e5,DISK], DatanodeInfoWithStorage[127.0.0.1:35869,DS-3785bf34-4607-4b3e-a8a8-b266105f627e,DISK], DatanodeInfoWithStorage[127.0.0.1:38824,DS-6e971877-0b9d-49c5-a172-3a62630ad9d1,DISK], DatanodeInfoWithStorage[127.0.0.1:43190,DS-9367ee39-1971-48e3-b881-b537d06badd0,DISK], DatanodeInfoWithStorage[127.0.0.1:46866,DS-0603a981-a84f-4b4f-8a44-da41ac869dd0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1953533840-172.17.0.21-1598088438245:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34158,DS-eb994e99-8dee-4ffc-9d6b-06aae0cb5219,DISK], DatanodeInfoWithStorage[127.0.0.1:43261,DS-5bf7fcbc-f6b5-40c5-abce-9b459fc2fe4d,DISK], DatanodeInfoWithStorage[127.0.0.1:39642,DS-1f792e0e-8cee-4286-ad42-6a460b1b980b,DISK], DatanodeInfoWithStorage[127.0.0.1:43706,DS-902567c2-fa80-4096-a6de-47a8936745e5,DISK], DatanodeInfoWithStorage[127.0.0.1:35869,DS-3785bf34-4607-4b3e-a8a8-b266105f627e,DISK], DatanodeInfoWithStorage[127.0.0.1:38824,DS-6e971877-0b9d-49c5-a172-3a62630ad9d1,DISK], DatanodeInfoWithStorage[127.0.0.1:43190,DS-9367ee39-1971-48e3-b881-b537d06badd0,DISK], DatanodeInfoWithStorage[127.0.0.1:46866,DS-0603a981-a84f-4b4f-8a44-da41ac869dd0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2084380073-172.17.0.21-1598088851123:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39108,DS-0c41436f-8b77-4393-b886-1936ed0df24e,DISK], DatanodeInfoWithStorage[127.0.0.1:37105,DS-f56d9150-0bea-4fb4-aa48-ef460dca80f6,DISK], DatanodeInfoWithStorage[127.0.0.1:37878,DS-429013b3-2c63-4bdc-9ad4-6ca43a6f57e3,DISK], DatanodeInfoWithStorage[127.0.0.1:45158,DS-0b3fbc9f-cfd1-41c7-a037-2e74bf532ead,DISK], DatanodeInfoWithStorage[127.0.0.1:44085,DS-9cfed66d-6d1e-49a8-8ebd-a0686dddbd7f,DISK], DatanodeInfoWithStorage[127.0.0.1:34357,DS-6d57ba0c-74c6-4e03-9904-db9f3c98a939,DISK], DatanodeInfoWithStorage[127.0.0.1:44272,DS-82bbd614-45fd-4192-8db7-8446d449941d,DISK], DatanodeInfoWithStorage[127.0.0.1:34347,DS-6e234cf3-ea26-4c92-81e3-0445ab42a32e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2084380073-172.17.0.21-1598088851123:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39108,DS-0c41436f-8b77-4393-b886-1936ed0df24e,DISK], DatanodeInfoWithStorage[127.0.0.1:37105,DS-f56d9150-0bea-4fb4-aa48-ef460dca80f6,DISK], DatanodeInfoWithStorage[127.0.0.1:37878,DS-429013b3-2c63-4bdc-9ad4-6ca43a6f57e3,DISK], DatanodeInfoWithStorage[127.0.0.1:45158,DS-0b3fbc9f-cfd1-41c7-a037-2e74bf532ead,DISK], DatanodeInfoWithStorage[127.0.0.1:44085,DS-9cfed66d-6d1e-49a8-8ebd-a0686dddbd7f,DISK], DatanodeInfoWithStorage[127.0.0.1:34357,DS-6d57ba0c-74c6-4e03-9904-db9f3c98a939,DISK], DatanodeInfoWithStorage[127.0.0.1:44272,DS-82bbd614-45fd-4192-8db7-8446d449941d,DISK], DatanodeInfoWithStorage[127.0.0.1:34347,DS-6e234cf3-ea26-4c92-81e3-0445ab42a32e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: hadoop.security.authorization
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-902697267-172.17.0.21-1598088891584:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44490,DS-18c6771d-efa3-494f-a2fb-458b22903860,DISK], DatanodeInfoWithStorage[127.0.0.1:39896,DS-6c9c2453-6cab-4b04-b7cb-32c8fe9c28e4,DISK], DatanodeInfoWithStorage[127.0.0.1:36324,DS-a232e9da-8697-4959-9bd1-32aea12dfabb,DISK], DatanodeInfoWithStorage[127.0.0.1:37675,DS-d67d352b-72f8-41e7-9062-f90adb95b499,DISK], DatanodeInfoWithStorage[127.0.0.1:38700,DS-fac14a75-8b5d-40c3-b3c2-8788de51ed50,DISK], DatanodeInfoWithStorage[127.0.0.1:46144,DS-af297422-5319-4cd3-bd53-ed43d27f7ff7,DISK], DatanodeInfoWithStorage[127.0.0.1:38660,DS-5ecd031f-ec96-4b84-8430-fe95ad2bce6c,DISK], DatanodeInfoWithStorage[127.0.0.1:34314,DS-be4f5265-039f-45b1-a573-28e18226a530,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-902697267-172.17.0.21-1598088891584:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44490,DS-18c6771d-efa3-494f-a2fb-458b22903860,DISK], DatanodeInfoWithStorage[127.0.0.1:39896,DS-6c9c2453-6cab-4b04-b7cb-32c8fe9c28e4,DISK], DatanodeInfoWithStorage[127.0.0.1:36324,DS-a232e9da-8697-4959-9bd1-32aea12dfabb,DISK], DatanodeInfoWithStorage[127.0.0.1:37675,DS-d67d352b-72f8-41e7-9062-f90adb95b499,DISK], DatanodeInfoWithStorage[127.0.0.1:38700,DS-fac14a75-8b5d-40c3-b3c2-8788de51ed50,DISK], DatanodeInfoWithStorage[127.0.0.1:46144,DS-af297422-5319-4cd3-bd53-ed43d27f7ff7,DISK], DatanodeInfoWithStorage[127.0.0.1:38660,DS-5ecd031f-ec96-4b84-8430-fe95ad2bce6c,DISK], DatanodeInfoWithStorage[127.0.0.1:34314,DS-be4f5265-039f-45b1-a573-28e18226a530,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-985199027-172.17.0.21-1598088927963:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34675,DS-91af0346-a6c3-4350-be73-b257d68b972c,DISK], DatanodeInfoWithStorage[127.0.0.1:37202,DS-cc2f5cfb-b690-4e2c-912b-1452e39efb0d,DISK], DatanodeInfoWithStorage[127.0.0.1:42183,DS-1f5ee644-8afe-476d-8a78-042ab256e757,DISK], DatanodeInfoWithStorage[127.0.0.1:35728,DS-54696a5c-2598-423a-bfbd-5a9f3a5d8679,DISK], DatanodeInfoWithStorage[127.0.0.1:46743,DS-a04778f7-5aeb-46fc-aa50-ed7a4bcef922,DISK], DatanodeInfoWithStorage[127.0.0.1:42506,DS-9d33ecd1-db5f-4c4c-90ad-8a329ab419a7,DISK], DatanodeInfoWithStorage[127.0.0.1:44206,DS-9f8029f3-97a4-48b2-b539-d2adbc4099c5,DISK], DatanodeInfoWithStorage[127.0.0.1:38855,DS-b28fc359-ba28-4c98-9b32-008027210024,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-985199027-172.17.0.21-1598088927963:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34675,DS-91af0346-a6c3-4350-be73-b257d68b972c,DISK], DatanodeInfoWithStorage[127.0.0.1:37202,DS-cc2f5cfb-b690-4e2c-912b-1452e39efb0d,DISK], DatanodeInfoWithStorage[127.0.0.1:42183,DS-1f5ee644-8afe-476d-8a78-042ab256e757,DISK], DatanodeInfoWithStorage[127.0.0.1:35728,DS-54696a5c-2598-423a-bfbd-5a9f3a5d8679,DISK], DatanodeInfoWithStorage[127.0.0.1:46743,DS-a04778f7-5aeb-46fc-aa50-ed7a4bcef922,DISK], DatanodeInfoWithStorage[127.0.0.1:42506,DS-9d33ecd1-db5f-4c4c-90ad-8a329ab419a7,DISK], DatanodeInfoWithStorage[127.0.0.1:44206,DS-9f8029f3-97a4-48b2-b539-d2adbc4099c5,DISK], DatanodeInfoWithStorage[127.0.0.1:38855,DS-b28fc359-ba28-4c98-9b32-008027210024,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1015044414-172.17.0.21-1598089243823:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41637,DS-e7ca34ca-ceff-46b8-a535-cc312ab37912,DISK], DatanodeInfoWithStorage[127.0.0.1:45397,DS-f19685b0-963e-4f4c-8974-cf6d4282fe46,DISK], DatanodeInfoWithStorage[127.0.0.1:34000,DS-aba7dbf7-bedd-4f9e-8ef0-6f8ba5afaa04,DISK], DatanodeInfoWithStorage[127.0.0.1:36271,DS-1aba4208-3dd6-4970-8d1e-7224e8fcd84d,DISK], DatanodeInfoWithStorage[127.0.0.1:33577,DS-bee5503e-0dd4-493e-a3dc-5c84b953b435,DISK], DatanodeInfoWithStorage[127.0.0.1:42032,DS-a3aed3a0-e924-4973-94dd-a842887f5fab,DISK], DatanodeInfoWithStorage[127.0.0.1:44485,DS-aaca9ac1-1a85-49c9-9985-382e8d52cee8,DISK], DatanodeInfoWithStorage[127.0.0.1:44186,DS-490b95b4-b177-4daa-80ee-0496a8d7d64b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1015044414-172.17.0.21-1598089243823:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41637,DS-e7ca34ca-ceff-46b8-a535-cc312ab37912,DISK], DatanodeInfoWithStorage[127.0.0.1:45397,DS-f19685b0-963e-4f4c-8974-cf6d4282fe46,DISK], DatanodeInfoWithStorage[127.0.0.1:34000,DS-aba7dbf7-bedd-4f9e-8ef0-6f8ba5afaa04,DISK], DatanodeInfoWithStorage[127.0.0.1:36271,DS-1aba4208-3dd6-4970-8d1e-7224e8fcd84d,DISK], DatanodeInfoWithStorage[127.0.0.1:33577,DS-bee5503e-0dd4-493e-a3dc-5c84b953b435,DISK], DatanodeInfoWithStorage[127.0.0.1:42032,DS-a3aed3a0-e924-4973-94dd-a842887f5fab,DISK], DatanodeInfoWithStorage[127.0.0.1:44485,DS-aaca9ac1-1a85-49c9-9985-382e8d52cee8,DISK], DatanodeInfoWithStorage[127.0.0.1:44186,DS-490b95b4-b177-4daa-80ee-0496a8d7d64b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1258444694-172.17.0.21-1598089287018:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42824,DS-782eab9a-061d-45fa-8220-05db381afabf,DISK], DatanodeInfoWithStorage[127.0.0.1:45412,DS-fbaefec4-ccc6-483a-9457-f0872bd80ef6,DISK], DatanodeInfoWithStorage[127.0.0.1:40909,DS-7e7de7bb-96c2-4a43-bd09-d2b7a1b50cdc,DISK], DatanodeInfoWithStorage[127.0.0.1:34882,DS-92b24a12-9119-47ff-9620-8d2aaf4ec6d2,DISK], DatanodeInfoWithStorage[127.0.0.1:43987,DS-5f7f6940-e989-4dc6-9224-f0cfd60364d7,DISK], DatanodeInfoWithStorage[127.0.0.1:42122,DS-9c80227f-6312-4f52-9d36-ea7163fefe47,DISK], DatanodeInfoWithStorage[127.0.0.1:38750,DS-4e903a9f-97c4-4add-a32f-9fcbdb076b72,DISK], DatanodeInfoWithStorage[127.0.0.1:46676,DS-2af82be9-196e-4166-b692-989de734e9b9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1258444694-172.17.0.21-1598089287018:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42824,DS-782eab9a-061d-45fa-8220-05db381afabf,DISK], DatanodeInfoWithStorage[127.0.0.1:45412,DS-fbaefec4-ccc6-483a-9457-f0872bd80ef6,DISK], DatanodeInfoWithStorage[127.0.0.1:40909,DS-7e7de7bb-96c2-4a43-bd09-d2b7a1b50cdc,DISK], DatanodeInfoWithStorage[127.0.0.1:34882,DS-92b24a12-9119-47ff-9620-8d2aaf4ec6d2,DISK], DatanodeInfoWithStorage[127.0.0.1:43987,DS-5f7f6940-e989-4dc6-9224-f0cfd60364d7,DISK], DatanodeInfoWithStorage[127.0.0.1:42122,DS-9c80227f-6312-4f52-9d36-ea7163fefe47,DISK], DatanodeInfoWithStorage[127.0.0.1:38750,DS-4e903a9f-97c4-4add-a32f-9fcbdb076b72,DISK], DatanodeInfoWithStorage[127.0.0.1:46676,DS-2af82be9-196e-4166-b692-989de734e9b9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1937612499-172.17.0.21-1598089561158:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38990,DS-eb577f3f-09a9-4bec-9fe4-2d7e8ed6bd64,DISK], DatanodeInfoWithStorage[127.0.0.1:35815,DS-a7111e6d-21a1-4004-86da-da7e1d11e47f,DISK], DatanodeInfoWithStorage[127.0.0.1:35043,DS-48c98546-317d-462e-a903-7b6b7234345a,DISK], DatanodeInfoWithStorage[127.0.0.1:37213,DS-6a57ec1d-ab93-4f2b-9301-a73f2cb7da32,DISK], DatanodeInfoWithStorage[127.0.0.1:36535,DS-3d175114-7261-44ea-b686-3db7da57e626,DISK], DatanodeInfoWithStorage[127.0.0.1:41667,DS-a0b88112-69cc-4c4e-81a7-657254d6431a,DISK], DatanodeInfoWithStorage[127.0.0.1:45151,DS-d9e74b72-77a1-4192-9e45-63d7f2f58a04,DISK], DatanodeInfoWithStorage[127.0.0.1:44443,DS-cabbe37f-8f17-4f6d-8965-ef2963552f34,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1937612499-172.17.0.21-1598089561158:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38990,DS-eb577f3f-09a9-4bec-9fe4-2d7e8ed6bd64,DISK], DatanodeInfoWithStorage[127.0.0.1:35815,DS-a7111e6d-21a1-4004-86da-da7e1d11e47f,DISK], DatanodeInfoWithStorage[127.0.0.1:35043,DS-48c98546-317d-462e-a903-7b6b7234345a,DISK], DatanodeInfoWithStorage[127.0.0.1:37213,DS-6a57ec1d-ab93-4f2b-9301-a73f2cb7da32,DISK], DatanodeInfoWithStorage[127.0.0.1:36535,DS-3d175114-7261-44ea-b686-3db7da57e626,DISK], DatanodeInfoWithStorage[127.0.0.1:41667,DS-a0b88112-69cc-4c4e-81a7-657254d6431a,DISK], DatanodeInfoWithStorage[127.0.0.1:45151,DS-d9e74b72-77a1-4192-9e45-63d7f2f58a04,DISK], DatanodeInfoWithStorage[127.0.0.1:44443,DS-cabbe37f-8f17-4f6d-8965-ef2963552f34,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1721600467-172.17.0.21-1598089787443:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46742,DS-77dec29a-758b-4d3e-b951-c48fb9278032,DISK], DatanodeInfoWithStorage[127.0.0.1:33806,DS-cee82b26-4cbc-48b6-96ca-0d6e00b9362d,DISK], DatanodeInfoWithStorage[127.0.0.1:46560,DS-79b77c54-cd44-411f-a753-c6fa5ca61634,DISK], DatanodeInfoWithStorage[127.0.0.1:34633,DS-5ccb90d1-a270-4ef0-a943-eba64e6287b7,DISK], DatanodeInfoWithStorage[127.0.0.1:35873,DS-868824ff-ab33-4d5b-84f5-3cb4bf70549e,DISK], DatanodeInfoWithStorage[127.0.0.1:33503,DS-e5276b8f-7c29-4780-8e95-c543596bb729,DISK], DatanodeInfoWithStorage[127.0.0.1:33286,DS-55c5d290-95ef-4f48-b160-0c36dd09129a,DISK], DatanodeInfoWithStorage[127.0.0.1:36454,DS-126c262d-fad5-4009-8564-26bd029fd9f3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1721600467-172.17.0.21-1598089787443:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46742,DS-77dec29a-758b-4d3e-b951-c48fb9278032,DISK], DatanodeInfoWithStorage[127.0.0.1:33806,DS-cee82b26-4cbc-48b6-96ca-0d6e00b9362d,DISK], DatanodeInfoWithStorage[127.0.0.1:46560,DS-79b77c54-cd44-411f-a753-c6fa5ca61634,DISK], DatanodeInfoWithStorage[127.0.0.1:34633,DS-5ccb90d1-a270-4ef0-a943-eba64e6287b7,DISK], DatanodeInfoWithStorage[127.0.0.1:35873,DS-868824ff-ab33-4d5b-84f5-3cb4bf70549e,DISK], DatanodeInfoWithStorage[127.0.0.1:33503,DS-e5276b8f-7c29-4780-8e95-c543596bb729,DISK], DatanodeInfoWithStorage[127.0.0.1:33286,DS-55c5d290-95ef-4f48-b160-0c36dd09129a,DISK], DatanodeInfoWithStorage[127.0.0.1:36454,DS-126c262d-fad5-4009-8564-26bd029fd9f3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 14 out of 50
v1v1v2v2 failed with probability 23 out of 50
result: false positive !!!
Total execution time in seconds : 5688
