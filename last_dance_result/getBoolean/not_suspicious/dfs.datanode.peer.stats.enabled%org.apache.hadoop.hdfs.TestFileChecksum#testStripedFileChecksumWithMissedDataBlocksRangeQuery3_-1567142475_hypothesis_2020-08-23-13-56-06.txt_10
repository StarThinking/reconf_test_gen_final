reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-866981622-172.17.0.19-1598191361524:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34643,DS-10fd4ddd-cf49-4950-a79e-19ecf4e277c4,DISK], DatanodeInfoWithStorage[127.0.0.1:37833,DS-3d7c9c77-226e-4c3c-a035-a167d49166d5,DISK], DatanodeInfoWithStorage[127.0.0.1:37120,DS-5f00303f-3a29-408c-b1ab-3fcdcb12ac7f,DISK], DatanodeInfoWithStorage[127.0.0.1:44183,DS-35710205-0709-4e94-b76c-300e4cdd46ce,DISK], DatanodeInfoWithStorage[127.0.0.1:38408,DS-8e0a80a4-70ec-44ce-8342-8ca8b4f0b0c6,DISK], DatanodeInfoWithStorage[127.0.0.1:42435,DS-667d9dda-ac29-41ea-822b-67e6447b5470,DISK], DatanodeInfoWithStorage[127.0.0.1:32888,DS-11784a2c-dc2c-42ac-b566-fe14192162f2,DISK], DatanodeInfoWithStorage[127.0.0.1:35411,DS-eb1d9cc8-2dae-4311-8622-14e06686cd85,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-866981622-172.17.0.19-1598191361524:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34643,DS-10fd4ddd-cf49-4950-a79e-19ecf4e277c4,DISK], DatanodeInfoWithStorage[127.0.0.1:37833,DS-3d7c9c77-226e-4c3c-a035-a167d49166d5,DISK], DatanodeInfoWithStorage[127.0.0.1:37120,DS-5f00303f-3a29-408c-b1ab-3fcdcb12ac7f,DISK], DatanodeInfoWithStorage[127.0.0.1:44183,DS-35710205-0709-4e94-b76c-300e4cdd46ce,DISK], DatanodeInfoWithStorage[127.0.0.1:38408,DS-8e0a80a4-70ec-44ce-8342-8ca8b4f0b0c6,DISK], DatanodeInfoWithStorage[127.0.0.1:42435,DS-667d9dda-ac29-41ea-822b-67e6447b5470,DISK], DatanodeInfoWithStorage[127.0.0.1:32888,DS-11784a2c-dc2c-42ac-b566-fe14192162f2,DISK], DatanodeInfoWithStorage[127.0.0.1:35411,DS-eb1d9cc8-2dae-4311-8622-14e06686cd85,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1361735991-172.17.0.19-1598191661299:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42339,DS-f975e38f-a055-4334-a362-cdcf020c88a0,DISK], DatanodeInfoWithStorage[127.0.0.1:41255,DS-477d6218-b172-4cca-8226-9679480212a2,DISK], DatanodeInfoWithStorage[127.0.0.1:45321,DS-79975e8c-fc0d-4cb8-933d-a98364fc8810,DISK], DatanodeInfoWithStorage[127.0.0.1:45007,DS-8ecf2c3c-84c7-4a50-b5e0-087c34ab876a,DISK], DatanodeInfoWithStorage[127.0.0.1:36538,DS-a4535035-5524-49c3-9485-beb6f2145188,DISK], DatanodeInfoWithStorage[127.0.0.1:36328,DS-07e6613a-202a-4511-8d64-b17c0df7a8bb,DISK], DatanodeInfoWithStorage[127.0.0.1:43494,DS-5cdeafbe-00f6-449a-b86c-07ce23d10a95,DISK], DatanodeInfoWithStorage[127.0.0.1:46224,DS-d3684c16-dde2-4fea-98fc-e23990246c1b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1361735991-172.17.0.19-1598191661299:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42339,DS-f975e38f-a055-4334-a362-cdcf020c88a0,DISK], DatanodeInfoWithStorage[127.0.0.1:41255,DS-477d6218-b172-4cca-8226-9679480212a2,DISK], DatanodeInfoWithStorage[127.0.0.1:45321,DS-79975e8c-fc0d-4cb8-933d-a98364fc8810,DISK], DatanodeInfoWithStorage[127.0.0.1:45007,DS-8ecf2c3c-84c7-4a50-b5e0-087c34ab876a,DISK], DatanodeInfoWithStorage[127.0.0.1:36538,DS-a4535035-5524-49c3-9485-beb6f2145188,DISK], DatanodeInfoWithStorage[127.0.0.1:36328,DS-07e6613a-202a-4511-8d64-b17c0df7a8bb,DISK], DatanodeInfoWithStorage[127.0.0.1:43494,DS-5cdeafbe-00f6-449a-b86c-07ce23d10a95,DISK], DatanodeInfoWithStorage[127.0.0.1:46224,DS-d3684c16-dde2-4fea-98fc-e23990246c1b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2044526348-172.17.0.19-1598192007021:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34575,DS-82312a7d-324c-46ed-a20d-e4331701504b,DISK], DatanodeInfoWithStorage[127.0.0.1:42710,DS-36d97d3d-c49a-4d57-8896-7c2d45e032e6,DISK], DatanodeInfoWithStorage[127.0.0.1:42910,DS-1dcf0e81-5681-4446-84ec-ef148ea12e1d,DISK], DatanodeInfoWithStorage[127.0.0.1:43865,DS-e3ada81b-e803-44c8-a6cc-1d92cdef08c7,DISK], DatanodeInfoWithStorage[127.0.0.1:33055,DS-a3504e3d-1dab-4c1c-ad61-266910d82e7d,DISK], DatanodeInfoWithStorage[127.0.0.1:34079,DS-38a29d1f-4cb2-4d4b-a0de-04a822164c4c,DISK], DatanodeInfoWithStorage[127.0.0.1:40917,DS-1f52ab18-cd19-4160-8147-4c54d15704a8,DISK], DatanodeInfoWithStorage[127.0.0.1:42658,DS-0358ce2f-1377-4ca7-b5e8-56bff4b4481d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2044526348-172.17.0.19-1598192007021:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34575,DS-82312a7d-324c-46ed-a20d-e4331701504b,DISK], DatanodeInfoWithStorage[127.0.0.1:42710,DS-36d97d3d-c49a-4d57-8896-7c2d45e032e6,DISK], DatanodeInfoWithStorage[127.0.0.1:42910,DS-1dcf0e81-5681-4446-84ec-ef148ea12e1d,DISK], DatanodeInfoWithStorage[127.0.0.1:43865,DS-e3ada81b-e803-44c8-a6cc-1d92cdef08c7,DISK], DatanodeInfoWithStorage[127.0.0.1:33055,DS-a3504e3d-1dab-4c1c-ad61-266910d82e7d,DISK], DatanodeInfoWithStorage[127.0.0.1:34079,DS-38a29d1f-4cb2-4d4b-a0de-04a822164c4c,DISK], DatanodeInfoWithStorage[127.0.0.1:40917,DS-1f52ab18-cd19-4160-8147-4c54d15704a8,DISK], DatanodeInfoWithStorage[127.0.0.1:42658,DS-0358ce2f-1377-4ca7-b5e8-56bff4b4481d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-93690711-172.17.0.19-1598192850700:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33143,DS-d1b61dcd-4856-4fbf-9309-a649de87058c,DISK], DatanodeInfoWithStorage[127.0.0.1:40712,DS-ff0d3843-c284-43ec-99ff-6ee9b07a7038,DISK], DatanodeInfoWithStorage[127.0.0.1:38516,DS-162340b1-4fdc-4377-bcfc-241482f77e03,DISK], DatanodeInfoWithStorage[127.0.0.1:44364,DS-63b9dcfc-46b2-449e-bacd-9d2223aafec7,DISK], DatanodeInfoWithStorage[127.0.0.1:43377,DS-36e158da-d6c2-475f-a084-1995361a2023,DISK], DatanodeInfoWithStorage[127.0.0.1:45806,DS-78c73215-929c-43e0-ba5a-39c55a845a8d,DISK], DatanodeInfoWithStorage[127.0.0.1:43085,DS-568f1be6-7a93-4117-92c6-1d49ae797dc8,DISK], DatanodeInfoWithStorage[127.0.0.1:42389,DS-4160a428-52e9-4cfb-bad2-bbab4101827c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-93690711-172.17.0.19-1598192850700:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33143,DS-d1b61dcd-4856-4fbf-9309-a649de87058c,DISK], DatanodeInfoWithStorage[127.0.0.1:40712,DS-ff0d3843-c284-43ec-99ff-6ee9b07a7038,DISK], DatanodeInfoWithStorage[127.0.0.1:38516,DS-162340b1-4fdc-4377-bcfc-241482f77e03,DISK], DatanodeInfoWithStorage[127.0.0.1:44364,DS-63b9dcfc-46b2-449e-bacd-9d2223aafec7,DISK], DatanodeInfoWithStorage[127.0.0.1:43377,DS-36e158da-d6c2-475f-a084-1995361a2023,DISK], DatanodeInfoWithStorage[127.0.0.1:45806,DS-78c73215-929c-43e0-ba5a-39c55a845a8d,DISK], DatanodeInfoWithStorage[127.0.0.1:43085,DS-568f1be6-7a93-4117-92c6-1d49ae797dc8,DISK], DatanodeInfoWithStorage[127.0.0.1:42389,DS-4160a428-52e9-4cfb-bad2-bbab4101827c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1178002074-172.17.0.19-1598193170483:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40440,DS-958b9a12-e944-4d0c-837e-32f4354cde88,DISK], DatanodeInfoWithStorage[127.0.0.1:44200,DS-a2487899-e824-4fa6-a334-59250423174a,DISK], DatanodeInfoWithStorage[127.0.0.1:46430,DS-c4bf5e70-7910-45bf-856c-e1b1b2425689,DISK], DatanodeInfoWithStorage[127.0.0.1:39496,DS-e205697a-1f49-46f4-a405-eba1643de127,DISK], DatanodeInfoWithStorage[127.0.0.1:40935,DS-26baf4fc-42b5-4b83-a5f5-c6669e9c5a14,DISK], DatanodeInfoWithStorage[127.0.0.1:38246,DS-96134023-a103-494e-8855-1946f85d9c28,DISK], DatanodeInfoWithStorage[127.0.0.1:40069,DS-205672b9-c226-4b2e-976c-5f09d17a4925,DISK], DatanodeInfoWithStorage[127.0.0.1:34833,DS-4c97ca52-ca72-46d1-99a9-de0b7228a33b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1178002074-172.17.0.19-1598193170483:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40440,DS-958b9a12-e944-4d0c-837e-32f4354cde88,DISK], DatanodeInfoWithStorage[127.0.0.1:44200,DS-a2487899-e824-4fa6-a334-59250423174a,DISK], DatanodeInfoWithStorage[127.0.0.1:46430,DS-c4bf5e70-7910-45bf-856c-e1b1b2425689,DISK], DatanodeInfoWithStorage[127.0.0.1:39496,DS-e205697a-1f49-46f4-a405-eba1643de127,DISK], DatanodeInfoWithStorage[127.0.0.1:40935,DS-26baf4fc-42b5-4b83-a5f5-c6669e9c5a14,DISK], DatanodeInfoWithStorage[127.0.0.1:38246,DS-96134023-a103-494e-8855-1946f85d9c28,DISK], DatanodeInfoWithStorage[127.0.0.1:40069,DS-205672b9-c226-4b2e-976c-5f09d17a4925,DISK], DatanodeInfoWithStorage[127.0.0.1:34833,DS-4c97ca52-ca72-46d1-99a9-de0b7228a33b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-606859185-172.17.0.19-1598193425724:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38575,DS-0e181f95-32ef-4064-8b90-84672b9403c8,DISK], DatanodeInfoWithStorage[127.0.0.1:35698,DS-fe14fe0c-1fdd-4754-8e9a-3609a19e5014,DISK], DatanodeInfoWithStorage[127.0.0.1:33597,DS-7689c534-2c46-4cff-aa33-490ad7d08b13,DISK], DatanodeInfoWithStorage[127.0.0.1:40941,DS-4079abf0-46eb-43d7-b95a-f01ecce994a1,DISK], DatanodeInfoWithStorage[127.0.0.1:38483,DS-8088cb15-903e-4f7c-97e9-62b992930fbe,DISK], DatanodeInfoWithStorage[127.0.0.1:43707,DS-48131a96-fa9f-4f04-901d-68046da8735a,DISK], DatanodeInfoWithStorage[127.0.0.1:41118,DS-e104bf22-6db6-4401-ae34-373a8724c241,DISK], DatanodeInfoWithStorage[127.0.0.1:41674,DS-11bfa56d-5f5b-4c5c-ae5e-34e12c439888,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-606859185-172.17.0.19-1598193425724:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38575,DS-0e181f95-32ef-4064-8b90-84672b9403c8,DISK], DatanodeInfoWithStorage[127.0.0.1:35698,DS-fe14fe0c-1fdd-4754-8e9a-3609a19e5014,DISK], DatanodeInfoWithStorage[127.0.0.1:33597,DS-7689c534-2c46-4cff-aa33-490ad7d08b13,DISK], DatanodeInfoWithStorage[127.0.0.1:40941,DS-4079abf0-46eb-43d7-b95a-f01ecce994a1,DISK], DatanodeInfoWithStorage[127.0.0.1:38483,DS-8088cb15-903e-4f7c-97e9-62b992930fbe,DISK], DatanodeInfoWithStorage[127.0.0.1:43707,DS-48131a96-fa9f-4f04-901d-68046da8735a,DISK], DatanodeInfoWithStorage[127.0.0.1:41118,DS-e104bf22-6db6-4401-ae34-373a8724c241,DISK], DatanodeInfoWithStorage[127.0.0.1:41674,DS-11bfa56d-5f5b-4c5c-ae5e-34e12c439888,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1533353488-172.17.0.19-1598193649361:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39982,DS-12bab7b0-6686-48d5-a3f3-7a1b74c13d6c,DISK], DatanodeInfoWithStorage[127.0.0.1:36856,DS-23ed2b1e-3c62-4819-ab52-a005936a24b4,DISK], DatanodeInfoWithStorage[127.0.0.1:43409,DS-fda82391-3929-45c3-a876-a9b11c036418,DISK], DatanodeInfoWithStorage[127.0.0.1:34940,DS-28c72134-f802-4e7f-9c67-d8f038cb1acd,DISK], DatanodeInfoWithStorage[127.0.0.1:37323,DS-c04beac8-3b6c-4c85-9494-9fe43d8dacdb,DISK], DatanodeInfoWithStorage[127.0.0.1:43699,DS-584f6052-7a50-4644-a939-4f327805fc74,DISK], DatanodeInfoWithStorage[127.0.0.1:34774,DS-4c16527b-9aee-4caf-9ef5-88b71d5c7b0b,DISK], DatanodeInfoWithStorage[127.0.0.1:44945,DS-a5f2c5b7-e880-4f5b-8def-068b14153855,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1533353488-172.17.0.19-1598193649361:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39982,DS-12bab7b0-6686-48d5-a3f3-7a1b74c13d6c,DISK], DatanodeInfoWithStorage[127.0.0.1:36856,DS-23ed2b1e-3c62-4819-ab52-a005936a24b4,DISK], DatanodeInfoWithStorage[127.0.0.1:43409,DS-fda82391-3929-45c3-a876-a9b11c036418,DISK], DatanodeInfoWithStorage[127.0.0.1:34940,DS-28c72134-f802-4e7f-9c67-d8f038cb1acd,DISK], DatanodeInfoWithStorage[127.0.0.1:37323,DS-c04beac8-3b6c-4c85-9494-9fe43d8dacdb,DISK], DatanodeInfoWithStorage[127.0.0.1:43699,DS-584f6052-7a50-4644-a939-4f327805fc74,DISK], DatanodeInfoWithStorage[127.0.0.1:34774,DS-4c16527b-9aee-4caf-9ef5-88b71d5c7b0b,DISK], DatanodeInfoWithStorage[127.0.0.1:44945,DS-a5f2c5b7-e880-4f5b-8def-068b14153855,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-63150490-172.17.0.19-1598194041498:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41767,DS-551f8b21-c0ca-453b-a793-79e42d3ba000,DISK], DatanodeInfoWithStorage[127.0.0.1:46773,DS-344f9196-6c3a-4280-bb2f-ca2ca8c0d06c,DISK], DatanodeInfoWithStorage[127.0.0.1:36468,DS-624b7f20-c40a-409a-9cde-ed2ae2ba3383,DISK], DatanodeInfoWithStorage[127.0.0.1:45599,DS-43ec57ec-a538-4a72-ad90-b4d574b8e612,DISK], DatanodeInfoWithStorage[127.0.0.1:39893,DS-97a84925-2c19-4be7-a243-3fe2d61545e1,DISK], DatanodeInfoWithStorage[127.0.0.1:36811,DS-dc15b18a-bb4e-40ce-b9fd-2773717b27e0,DISK], DatanodeInfoWithStorage[127.0.0.1:38849,DS-63f6c94a-a82a-4b8f-a14b-9834d1bfacde,DISK], DatanodeInfoWithStorage[127.0.0.1:33566,DS-5577a618-28b1-4511-a5f7-536ee7ddf363,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-63150490-172.17.0.19-1598194041498:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41767,DS-551f8b21-c0ca-453b-a793-79e42d3ba000,DISK], DatanodeInfoWithStorage[127.0.0.1:46773,DS-344f9196-6c3a-4280-bb2f-ca2ca8c0d06c,DISK], DatanodeInfoWithStorage[127.0.0.1:36468,DS-624b7f20-c40a-409a-9cde-ed2ae2ba3383,DISK], DatanodeInfoWithStorage[127.0.0.1:45599,DS-43ec57ec-a538-4a72-ad90-b4d574b8e612,DISK], DatanodeInfoWithStorage[127.0.0.1:39893,DS-97a84925-2c19-4be7-a243-3fe2d61545e1,DISK], DatanodeInfoWithStorage[127.0.0.1:36811,DS-dc15b18a-bb4e-40ce-b9fd-2773717b27e0,DISK], DatanodeInfoWithStorage[127.0.0.1:38849,DS-63f6c94a-a82a-4b8f-a14b-9834d1bfacde,DISK], DatanodeInfoWithStorage[127.0.0.1:33566,DS-5577a618-28b1-4511-a5f7-536ee7ddf363,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1002452757-172.17.0.19-1598194985643:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35633,DS-90bc339a-a541-46eb-b149-818f1a5692aa,DISK], DatanodeInfoWithStorage[127.0.0.1:43820,DS-ea1312fb-e991-480a-9820-6cbcb9b6abd0,DISK], DatanodeInfoWithStorage[127.0.0.1:37082,DS-a3d0ece3-a31a-474b-947b-2bfa76b027d9,DISK], DatanodeInfoWithStorage[127.0.0.1:36583,DS-f75d7fc1-fbb8-4f11-b923-07ac7b981ba5,DISK], DatanodeInfoWithStorage[127.0.0.1:37898,DS-30f537e4-4889-4a91-bd34-3f3c5fb4a501,DISK], DatanodeInfoWithStorage[127.0.0.1:38403,DS-6d1453cd-83ef-4971-9063-b93bd40b6a8a,DISK], DatanodeInfoWithStorage[127.0.0.1:43571,DS-db5b1ad2-3fe8-470d-a03d-4f99ffbbd0fe,DISK], DatanodeInfoWithStorage[127.0.0.1:41315,DS-44da4f79-b8b7-45ea-a0c4-68bd7e7296ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1002452757-172.17.0.19-1598194985643:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35633,DS-90bc339a-a541-46eb-b149-818f1a5692aa,DISK], DatanodeInfoWithStorage[127.0.0.1:43820,DS-ea1312fb-e991-480a-9820-6cbcb9b6abd0,DISK], DatanodeInfoWithStorage[127.0.0.1:37082,DS-a3d0ece3-a31a-474b-947b-2bfa76b027d9,DISK], DatanodeInfoWithStorage[127.0.0.1:36583,DS-f75d7fc1-fbb8-4f11-b923-07ac7b981ba5,DISK], DatanodeInfoWithStorage[127.0.0.1:37898,DS-30f537e4-4889-4a91-bd34-3f3c5fb4a501,DISK], DatanodeInfoWithStorage[127.0.0.1:38403,DS-6d1453cd-83ef-4971-9063-b93bd40b6a8a,DISK], DatanodeInfoWithStorage[127.0.0.1:43571,DS-db5b1ad2-3fe8-470d-a03d-4f99ffbbd0fe,DISK], DatanodeInfoWithStorage[127.0.0.1:41315,DS-44da4f79-b8b7-45ea-a0c4-68bd7e7296ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1249359584-172.17.0.19-1598195710621:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43583,DS-fa929f63-d072-4690-a37f-1f3347885c32,DISK], DatanodeInfoWithStorage[127.0.0.1:45647,DS-9c5c44f9-e6f4-499f-9940-b3167b779a5b,DISK], DatanodeInfoWithStorage[127.0.0.1:45237,DS-34fdcbb6-435c-4963-8d03-d38cc4bd7e0e,DISK], DatanodeInfoWithStorage[127.0.0.1:38981,DS-1b9ca99e-eb6c-4a4d-b11a-1f617b4378bf,DISK], DatanodeInfoWithStorage[127.0.0.1:38230,DS-0555cb95-70a9-43d8-80ef-16ca02fce851,DISK], DatanodeInfoWithStorage[127.0.0.1:37251,DS-17259cb4-0aa2-45ce-b565-59cce465c2dc,DISK], DatanodeInfoWithStorage[127.0.0.1:36963,DS-c8b788e8-98bf-4706-8e33-fc0ba2bb19f2,DISK], DatanodeInfoWithStorage[127.0.0.1:45543,DS-e4188dd7-0757-421c-89e8-c0f569bf5b06,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1249359584-172.17.0.19-1598195710621:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43583,DS-fa929f63-d072-4690-a37f-1f3347885c32,DISK], DatanodeInfoWithStorage[127.0.0.1:45647,DS-9c5c44f9-e6f4-499f-9940-b3167b779a5b,DISK], DatanodeInfoWithStorage[127.0.0.1:45237,DS-34fdcbb6-435c-4963-8d03-d38cc4bd7e0e,DISK], DatanodeInfoWithStorage[127.0.0.1:38981,DS-1b9ca99e-eb6c-4a4d-b11a-1f617b4378bf,DISK], DatanodeInfoWithStorage[127.0.0.1:38230,DS-0555cb95-70a9-43d8-80ef-16ca02fce851,DISK], DatanodeInfoWithStorage[127.0.0.1:37251,DS-17259cb4-0aa2-45ce-b565-59cce465c2dc,DISK], DatanodeInfoWithStorage[127.0.0.1:36963,DS-c8b788e8-98bf-4706-8e33-fc0ba2bb19f2,DISK], DatanodeInfoWithStorage[127.0.0.1:45543,DS-e4188dd7-0757-421c-89e8-c0f569bf5b06,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-256953232-172.17.0.19-1598195777597:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42480,DS-2e989c8c-209e-41f2-8dac-7fd726012295,DISK], DatanodeInfoWithStorage[127.0.0.1:41864,DS-5da6ec75-c36e-4203-829c-2166d76b8296,DISK], DatanodeInfoWithStorage[127.0.0.1:34645,DS-66ec93a6-8e37-457b-b3bf-5b92b3a0984e,DISK], DatanodeInfoWithStorage[127.0.0.1:36444,DS-b54c7ea5-aeb9-4c99-9087-e4ba776d6c75,DISK], DatanodeInfoWithStorage[127.0.0.1:36524,DS-1fd770a5-4a13-440d-8fc0-f9684a67875d,DISK], DatanodeInfoWithStorage[127.0.0.1:35049,DS-440c923c-1f26-40c6-b647-27f380705616,DISK], DatanodeInfoWithStorage[127.0.0.1:40281,DS-cc487772-0d63-4d76-a17d-758860d393ab,DISK], DatanodeInfoWithStorage[127.0.0.1:40715,DS-892c1c7a-3c74-48cf-9f76-4fe31d203d64,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-256953232-172.17.0.19-1598195777597:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42480,DS-2e989c8c-209e-41f2-8dac-7fd726012295,DISK], DatanodeInfoWithStorage[127.0.0.1:41864,DS-5da6ec75-c36e-4203-829c-2166d76b8296,DISK], DatanodeInfoWithStorage[127.0.0.1:34645,DS-66ec93a6-8e37-457b-b3bf-5b92b3a0984e,DISK], DatanodeInfoWithStorage[127.0.0.1:36444,DS-b54c7ea5-aeb9-4c99-9087-e4ba776d6c75,DISK], DatanodeInfoWithStorage[127.0.0.1:36524,DS-1fd770a5-4a13-440d-8fc0-f9684a67875d,DISK], DatanodeInfoWithStorage[127.0.0.1:35049,DS-440c923c-1f26-40c6-b647-27f380705616,DISK], DatanodeInfoWithStorage[127.0.0.1:40281,DS-cc487772-0d63-4d76-a17d-758860d393ab,DISK], DatanodeInfoWithStorage[127.0.0.1:40715,DS-892c1c7a-3c74-48cf-9f76-4fe31d203d64,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-615887679-172.17.0.19-1598196055961:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34052,DS-79b7794b-5482-4f03-80a3-98390cd08a0a,DISK], DatanodeInfoWithStorage[127.0.0.1:39368,DS-79b2a403-5b9e-41dd-8e67-c5c366769e5d,DISK], DatanodeInfoWithStorage[127.0.0.1:39185,DS-5239f187-6a01-4928-85c7-7762a6c4beba,DISK], DatanodeInfoWithStorage[127.0.0.1:40551,DS-c84912d1-fff0-49e2-a186-8a5b6ab14bd2,DISK], DatanodeInfoWithStorage[127.0.0.1:42299,DS-50750072-dcec-4cd1-b548-677d34c7355f,DISK], DatanodeInfoWithStorage[127.0.0.1:36575,DS-cdee57b3-48b5-45f8-986c-763f47a05acf,DISK], DatanodeInfoWithStorage[127.0.0.1:40305,DS-6759fc26-22a3-431e-bcb3-82ef0713fa5f,DISK], DatanodeInfoWithStorage[127.0.0.1:36062,DS-28ca750c-5c68-48cd-976a-9cb53b2416d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-615887679-172.17.0.19-1598196055961:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34052,DS-79b7794b-5482-4f03-80a3-98390cd08a0a,DISK], DatanodeInfoWithStorage[127.0.0.1:39368,DS-79b2a403-5b9e-41dd-8e67-c5c366769e5d,DISK], DatanodeInfoWithStorage[127.0.0.1:39185,DS-5239f187-6a01-4928-85c7-7762a6c4beba,DISK], DatanodeInfoWithStorage[127.0.0.1:40551,DS-c84912d1-fff0-49e2-a186-8a5b6ab14bd2,DISK], DatanodeInfoWithStorage[127.0.0.1:42299,DS-50750072-dcec-4cd1-b548-677d34c7355f,DISK], DatanodeInfoWithStorage[127.0.0.1:36575,DS-cdee57b3-48b5-45f8-986c-763f47a05acf,DISK], DatanodeInfoWithStorage[127.0.0.1:40305,DS-6759fc26-22a3-431e-bcb3-82ef0713fa5f,DISK], DatanodeInfoWithStorage[127.0.0.1:36062,DS-28ca750c-5c68-48cd-976a-9cb53b2416d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 7 out of 50
result: false positive !!!
Total execution time in seconds : 5219
