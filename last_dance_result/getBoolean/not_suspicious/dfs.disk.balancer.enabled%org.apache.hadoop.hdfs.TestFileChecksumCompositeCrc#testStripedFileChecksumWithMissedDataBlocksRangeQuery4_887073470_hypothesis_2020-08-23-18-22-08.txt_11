reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1541405740-172.17.0.3-1598207630673:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41837,DS-eb618ace-2686-4e9f-a1d1-f52b5f3b321d,DISK], DatanodeInfoWithStorage[127.0.0.1:40588,DS-4f7597a5-1648-4467-8664-6d6ae4bb354d,DISK], DatanodeInfoWithStorage[127.0.0.1:41334,DS-534a7988-56d5-43fc-ac87-f2b9b6d4de84,DISK], DatanodeInfoWithStorage[127.0.0.1:38709,DS-778cdf9b-8f4c-47ae-908c-c97ba58cfd47,DISK], DatanodeInfoWithStorage[127.0.0.1:38741,DS-a757f8d5-d904-49e9-b32c-6412f1e7e9d2,DISK], DatanodeInfoWithStorage[127.0.0.1:35979,DS-01b29ba7-e869-47a5-8442-ae00380b2136,DISK], DatanodeInfoWithStorage[127.0.0.1:45971,DS-65875dfc-ec98-4d45-8ccc-f9c4f32f8ddd,DISK], DatanodeInfoWithStorage[127.0.0.1:40109,DS-5b575ff6-1bd2-4b6b-be09-0eb834f7390d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1541405740-172.17.0.3-1598207630673:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41837,DS-eb618ace-2686-4e9f-a1d1-f52b5f3b321d,DISK], DatanodeInfoWithStorage[127.0.0.1:40588,DS-4f7597a5-1648-4467-8664-6d6ae4bb354d,DISK], DatanodeInfoWithStorage[127.0.0.1:41334,DS-534a7988-56d5-43fc-ac87-f2b9b6d4de84,DISK], DatanodeInfoWithStorage[127.0.0.1:38709,DS-778cdf9b-8f4c-47ae-908c-c97ba58cfd47,DISK], DatanodeInfoWithStorage[127.0.0.1:38741,DS-a757f8d5-d904-49e9-b32c-6412f1e7e9d2,DISK], DatanodeInfoWithStorage[127.0.0.1:35979,DS-01b29ba7-e869-47a5-8442-ae00380b2136,DISK], DatanodeInfoWithStorage[127.0.0.1:45971,DS-65875dfc-ec98-4d45-8ccc-f9c4f32f8ddd,DISK], DatanodeInfoWithStorage[127.0.0.1:40109,DS-5b575ff6-1bd2-4b6b-be09-0eb834f7390d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-634878453-172.17.0.3-1598207738223:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37130,DS-d52c7f19-4a9f-4a2b-a87d-e947b1276754,DISK], DatanodeInfoWithStorage[127.0.0.1:44811,DS-70d1a917-ac3b-468c-8ccb-bf1bfca5132c,DISK], DatanodeInfoWithStorage[127.0.0.1:38885,DS-dfdb7d69-8cf7-4fac-92e1-bb3584db686e,DISK], DatanodeInfoWithStorage[127.0.0.1:44165,DS-70aeada1-1797-4c77-88e6-a08005eefdbe,DISK], DatanodeInfoWithStorage[127.0.0.1:43986,DS-5a2dbefb-e161-499d-91a8-152c30b11a00,DISK], DatanodeInfoWithStorage[127.0.0.1:42420,DS-87482e53-5d11-4b07-b77b-e827a05d3733,DISK], DatanodeInfoWithStorage[127.0.0.1:34458,DS-23562b11-ba6b-452c-b892-c561569d6c70,DISK], DatanodeInfoWithStorage[127.0.0.1:37891,DS-0f1853fc-b25a-4713-a47f-54655d61a688,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-634878453-172.17.0.3-1598207738223:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37130,DS-d52c7f19-4a9f-4a2b-a87d-e947b1276754,DISK], DatanodeInfoWithStorage[127.0.0.1:44811,DS-70d1a917-ac3b-468c-8ccb-bf1bfca5132c,DISK], DatanodeInfoWithStorage[127.0.0.1:38885,DS-dfdb7d69-8cf7-4fac-92e1-bb3584db686e,DISK], DatanodeInfoWithStorage[127.0.0.1:44165,DS-70aeada1-1797-4c77-88e6-a08005eefdbe,DISK], DatanodeInfoWithStorage[127.0.0.1:43986,DS-5a2dbefb-e161-499d-91a8-152c30b11a00,DISK], DatanodeInfoWithStorage[127.0.0.1:42420,DS-87482e53-5d11-4b07-b77b-e827a05d3733,DISK], DatanodeInfoWithStorage[127.0.0.1:34458,DS-23562b11-ba6b-452c-b892-c561569d6c70,DISK], DatanodeInfoWithStorage[127.0.0.1:37891,DS-0f1853fc-b25a-4713-a47f-54655d61a688,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-209404419-172.17.0.3-1598207826646:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46641,DS-7b7739e1-6ae2-486c-9b04-2d9f9146c431,DISK], DatanodeInfoWithStorage[127.0.0.1:40345,DS-f9c9c300-21f4-42c1-9367-960abfcc63f6,DISK], DatanodeInfoWithStorage[127.0.0.1:44825,DS-d92638ef-94f3-4495-b1e3-5fa423920fa8,DISK], DatanodeInfoWithStorage[127.0.0.1:41357,DS-0ecd2b70-d319-4c14-8ff0-18e9b15049a6,DISK], DatanodeInfoWithStorage[127.0.0.1:35061,DS-0cbc2fe1-493b-43fc-b6a2-4bb9378a7e45,DISK], DatanodeInfoWithStorage[127.0.0.1:40940,DS-1c371867-550a-42aa-aaea-085700fd886c,DISK], DatanodeInfoWithStorage[127.0.0.1:46098,DS-63aec013-ef3e-49ea-972a-385b43606e20,DISK], DatanodeInfoWithStorage[127.0.0.1:39907,DS-e2e72b89-d64b-46bc-93dd-1f3fea314596,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-209404419-172.17.0.3-1598207826646:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46641,DS-7b7739e1-6ae2-486c-9b04-2d9f9146c431,DISK], DatanodeInfoWithStorage[127.0.0.1:40345,DS-f9c9c300-21f4-42c1-9367-960abfcc63f6,DISK], DatanodeInfoWithStorage[127.0.0.1:44825,DS-d92638ef-94f3-4495-b1e3-5fa423920fa8,DISK], DatanodeInfoWithStorage[127.0.0.1:41357,DS-0ecd2b70-d319-4c14-8ff0-18e9b15049a6,DISK], DatanodeInfoWithStorage[127.0.0.1:35061,DS-0cbc2fe1-493b-43fc-b6a2-4bb9378a7e45,DISK], DatanodeInfoWithStorage[127.0.0.1:40940,DS-1c371867-550a-42aa-aaea-085700fd886c,DISK], DatanodeInfoWithStorage[127.0.0.1:46098,DS-63aec013-ef3e-49ea-972a-385b43606e20,DISK], DatanodeInfoWithStorage[127.0.0.1:39907,DS-e2e72b89-d64b-46bc-93dd-1f3fea314596,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1608156499-172.17.0.3-1598208113567:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37575,DS-6e0fed6c-d72e-427f-bdf8-4b4162accde4,DISK], DatanodeInfoWithStorage[127.0.0.1:36911,DS-d449854c-c6b6-456d-8e0f-29cfdf3bd5f4,DISK], DatanodeInfoWithStorage[127.0.0.1:39539,DS-1d5e79ad-d4ed-45b1-80f5-965026eb1343,DISK], DatanodeInfoWithStorage[127.0.0.1:41944,DS-b6aafacc-3cec-4901-a0e8-b4a1a0dfc1ac,DISK], DatanodeInfoWithStorage[127.0.0.1:37537,DS-7ea8f15b-6c24-4391-b0b7-bd79b0882b0b,DISK], DatanodeInfoWithStorage[127.0.0.1:38796,DS-0c16e158-eda9-475f-8be5-dda1b6df4206,DISK], DatanodeInfoWithStorage[127.0.0.1:43630,DS-3207406b-620c-45e2-9d51-ed76ce5f7789,DISK], DatanodeInfoWithStorage[127.0.0.1:46037,DS-a3876b23-8be2-4f56-90c7-4fd69890926b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1608156499-172.17.0.3-1598208113567:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37575,DS-6e0fed6c-d72e-427f-bdf8-4b4162accde4,DISK], DatanodeInfoWithStorage[127.0.0.1:36911,DS-d449854c-c6b6-456d-8e0f-29cfdf3bd5f4,DISK], DatanodeInfoWithStorage[127.0.0.1:39539,DS-1d5e79ad-d4ed-45b1-80f5-965026eb1343,DISK], DatanodeInfoWithStorage[127.0.0.1:41944,DS-b6aafacc-3cec-4901-a0e8-b4a1a0dfc1ac,DISK], DatanodeInfoWithStorage[127.0.0.1:37537,DS-7ea8f15b-6c24-4391-b0b7-bd79b0882b0b,DISK], DatanodeInfoWithStorage[127.0.0.1:38796,DS-0c16e158-eda9-475f-8be5-dda1b6df4206,DISK], DatanodeInfoWithStorage[127.0.0.1:43630,DS-3207406b-620c-45e2-9d51-ed76ce5f7789,DISK], DatanodeInfoWithStorage[127.0.0.1:46037,DS-a3876b23-8be2-4f56-90c7-4fd69890926b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-43500583-172.17.0.3-1598208238717:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42960,DS-f14b790a-ded0-4d79-bffd-228ab6b1c937,DISK], DatanodeInfoWithStorage[127.0.0.1:42835,DS-ef23ff9d-d277-4b23-ba94-0f90e966127e,DISK], DatanodeInfoWithStorage[127.0.0.1:41369,DS-0c1ae9f5-4bbd-433a-b787-2cbaab9cb726,DISK], DatanodeInfoWithStorage[127.0.0.1:43143,DS-a13bbfaa-c756-4813-9f18-6a665472c7fa,DISK], DatanodeInfoWithStorage[127.0.0.1:41030,DS-69c14046-6766-4049-bc28-e191adaf5447,DISK], DatanodeInfoWithStorage[127.0.0.1:42345,DS-66ef6fa1-fe8b-43af-80ff-16295f92c3e1,DISK], DatanodeInfoWithStorage[127.0.0.1:34271,DS-99681395-4333-4b6f-ae7b-6813ca14548a,DISK], DatanodeInfoWithStorage[127.0.0.1:33305,DS-39c65109-8e05-40b4-9e71-75cb52f59e47,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-43500583-172.17.0.3-1598208238717:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42960,DS-f14b790a-ded0-4d79-bffd-228ab6b1c937,DISK], DatanodeInfoWithStorage[127.0.0.1:42835,DS-ef23ff9d-d277-4b23-ba94-0f90e966127e,DISK], DatanodeInfoWithStorage[127.0.0.1:41369,DS-0c1ae9f5-4bbd-433a-b787-2cbaab9cb726,DISK], DatanodeInfoWithStorage[127.0.0.1:43143,DS-a13bbfaa-c756-4813-9f18-6a665472c7fa,DISK], DatanodeInfoWithStorage[127.0.0.1:41030,DS-69c14046-6766-4049-bc28-e191adaf5447,DISK], DatanodeInfoWithStorage[127.0.0.1:42345,DS-66ef6fa1-fe8b-43af-80ff-16295f92c3e1,DISK], DatanodeInfoWithStorage[127.0.0.1:34271,DS-99681395-4333-4b6f-ae7b-6813ca14548a,DISK], DatanodeInfoWithStorage[127.0.0.1:33305,DS-39c65109-8e05-40b4-9e71-75cb52f59e47,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-557696413-172.17.0.3-1598208667286:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34128,DS-83367dd5-3bd9-4e71-848d-6163f8e3d9f4,DISK], DatanodeInfoWithStorage[127.0.0.1:41640,DS-a8cbd9b6-725b-4e7f-b100-68ddc8b122f3,DISK], DatanodeInfoWithStorage[127.0.0.1:34696,DS-9c54251a-b3b0-442b-91b2-ea56ddc36633,DISK], DatanodeInfoWithStorage[127.0.0.1:45904,DS-63d2700d-aa27-4583-9499-602e1bd50e6b,DISK], DatanodeInfoWithStorage[127.0.0.1:40397,DS-002a4295-24da-4d89-81fa-01d54a14b09c,DISK], DatanodeInfoWithStorage[127.0.0.1:45402,DS-0b8b3e33-2a6b-4aa0-8d36-1ffa45ff9c28,DISK], DatanodeInfoWithStorage[127.0.0.1:36288,DS-99960081-f3ec-4d4c-9669-433fb55847cb,DISK], DatanodeInfoWithStorage[127.0.0.1:35037,DS-05a7d5bf-bb86-464f-9212-d8dbc07bee5a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-557696413-172.17.0.3-1598208667286:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34128,DS-83367dd5-3bd9-4e71-848d-6163f8e3d9f4,DISK], DatanodeInfoWithStorage[127.0.0.1:41640,DS-a8cbd9b6-725b-4e7f-b100-68ddc8b122f3,DISK], DatanodeInfoWithStorage[127.0.0.1:34696,DS-9c54251a-b3b0-442b-91b2-ea56ddc36633,DISK], DatanodeInfoWithStorage[127.0.0.1:45904,DS-63d2700d-aa27-4583-9499-602e1bd50e6b,DISK], DatanodeInfoWithStorage[127.0.0.1:40397,DS-002a4295-24da-4d89-81fa-01d54a14b09c,DISK], DatanodeInfoWithStorage[127.0.0.1:45402,DS-0b8b3e33-2a6b-4aa0-8d36-1ffa45ff9c28,DISK], DatanodeInfoWithStorage[127.0.0.1:36288,DS-99960081-f3ec-4d4c-9669-433fb55847cb,DISK], DatanodeInfoWithStorage[127.0.0.1:35037,DS-05a7d5bf-bb86-464f-9212-d8dbc07bee5a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-448498624-172.17.0.3-1598208991150:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44072,DS-66057838-2e2b-4e3c-8b62-bd314d5b4ff4,DISK], DatanodeInfoWithStorage[127.0.0.1:35623,DS-8701d717-c082-46d3-bcd3-22e0bef3f44f,DISK], DatanodeInfoWithStorage[127.0.0.1:33727,DS-0f763d2a-1606-4538-bd95-bea011b7a491,DISK], DatanodeInfoWithStorage[127.0.0.1:44325,DS-26e317a1-f57d-4328-bccc-5b195c25eb37,DISK], DatanodeInfoWithStorage[127.0.0.1:39763,DS-c6a8d3f5-7c77-476e-a1f7-07720e5939fe,DISK], DatanodeInfoWithStorage[127.0.0.1:45626,DS-20ee27a5-e049-42dc-9a7c-90dbf0a72125,DISK], DatanodeInfoWithStorage[127.0.0.1:37387,DS-c081da7b-f032-427e-a0cd-74f026ea2754,DISK], DatanodeInfoWithStorage[127.0.0.1:44717,DS-919c9422-8fe6-4e12-9dfd-fb2eab7ce8ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-448498624-172.17.0.3-1598208991150:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44072,DS-66057838-2e2b-4e3c-8b62-bd314d5b4ff4,DISK], DatanodeInfoWithStorage[127.0.0.1:35623,DS-8701d717-c082-46d3-bcd3-22e0bef3f44f,DISK], DatanodeInfoWithStorage[127.0.0.1:33727,DS-0f763d2a-1606-4538-bd95-bea011b7a491,DISK], DatanodeInfoWithStorage[127.0.0.1:44325,DS-26e317a1-f57d-4328-bccc-5b195c25eb37,DISK], DatanodeInfoWithStorage[127.0.0.1:39763,DS-c6a8d3f5-7c77-476e-a1f7-07720e5939fe,DISK], DatanodeInfoWithStorage[127.0.0.1:45626,DS-20ee27a5-e049-42dc-9a7c-90dbf0a72125,DISK], DatanodeInfoWithStorage[127.0.0.1:37387,DS-c081da7b-f032-427e-a0cd-74f026ea2754,DISK], DatanodeInfoWithStorage[127.0.0.1:44717,DS-919c9422-8fe6-4e12-9dfd-fb2eab7ce8ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1741247922-172.17.0.3-1598209441711:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35145,DS-a12ba6fc-b879-4603-9b22-ee3c89c5b2e5,DISK], DatanodeInfoWithStorage[127.0.0.1:46707,DS-578bebfb-9522-440f-bd99-24ae10509e89,DISK], DatanodeInfoWithStorage[127.0.0.1:42915,DS-407a7034-f70a-4d37-9144-e73aa3d72b09,DISK], DatanodeInfoWithStorage[127.0.0.1:33373,DS-5ddb24ac-9710-4c6e-b582-ad2ebb4eac82,DISK], DatanodeInfoWithStorage[127.0.0.1:45554,DS-cba1d7c4-4a5e-4825-8b41-52714c8c54c6,DISK], DatanodeInfoWithStorage[127.0.0.1:39098,DS-8c5fd173-efa5-4fd4-b408-cd592b3b405e,DISK], DatanodeInfoWithStorage[127.0.0.1:34308,DS-665edd98-b53e-4ca6-a948-75ea582c1539,DISK], DatanodeInfoWithStorage[127.0.0.1:41401,DS-b6cf6422-5baa-4985-a32f-84ea6013db55,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1741247922-172.17.0.3-1598209441711:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35145,DS-a12ba6fc-b879-4603-9b22-ee3c89c5b2e5,DISK], DatanodeInfoWithStorage[127.0.0.1:46707,DS-578bebfb-9522-440f-bd99-24ae10509e89,DISK], DatanodeInfoWithStorage[127.0.0.1:42915,DS-407a7034-f70a-4d37-9144-e73aa3d72b09,DISK], DatanodeInfoWithStorage[127.0.0.1:33373,DS-5ddb24ac-9710-4c6e-b582-ad2ebb4eac82,DISK], DatanodeInfoWithStorage[127.0.0.1:45554,DS-cba1d7c4-4a5e-4825-8b41-52714c8c54c6,DISK], DatanodeInfoWithStorage[127.0.0.1:39098,DS-8c5fd173-efa5-4fd4-b408-cd592b3b405e,DISK], DatanodeInfoWithStorage[127.0.0.1:34308,DS-665edd98-b53e-4ca6-a948-75ea582c1539,DISK], DatanodeInfoWithStorage[127.0.0.1:41401,DS-b6cf6422-5baa-4985-a32f-84ea6013db55,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-855796117-172.17.0.3-1598210305620:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33776,DS-7c9a3352-84e8-42bd-b3d2-e26a0e069b24,DISK], DatanodeInfoWithStorage[127.0.0.1:43213,DS-d981c34b-0fb3-449e-bf57-74918ea48fc5,DISK], DatanodeInfoWithStorage[127.0.0.1:39747,DS-3c943d88-28fe-4682-868c-587710f89866,DISK], DatanodeInfoWithStorage[127.0.0.1:33749,DS-8a1b30c8-666d-42b3-a062-07fd4f8665d7,DISK], DatanodeInfoWithStorage[127.0.0.1:33599,DS-f6184cd6-cfc2-41c9-bbad-1bc4f175e650,DISK], DatanodeInfoWithStorage[127.0.0.1:43958,DS-79a86733-313c-492b-a0e5-030ea18df07f,DISK], DatanodeInfoWithStorage[127.0.0.1:36947,DS-91858510-f5c8-4fa6-9d6c-4fa1babffb4a,DISK], DatanodeInfoWithStorage[127.0.0.1:44371,DS-5e3fc3e4-e6ea-401a-bde0-91d624b8cb09,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-855796117-172.17.0.3-1598210305620:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33776,DS-7c9a3352-84e8-42bd-b3d2-e26a0e069b24,DISK], DatanodeInfoWithStorage[127.0.0.1:43213,DS-d981c34b-0fb3-449e-bf57-74918ea48fc5,DISK], DatanodeInfoWithStorage[127.0.0.1:39747,DS-3c943d88-28fe-4682-868c-587710f89866,DISK], DatanodeInfoWithStorage[127.0.0.1:33749,DS-8a1b30c8-666d-42b3-a062-07fd4f8665d7,DISK], DatanodeInfoWithStorage[127.0.0.1:33599,DS-f6184cd6-cfc2-41c9-bbad-1bc4f175e650,DISK], DatanodeInfoWithStorage[127.0.0.1:43958,DS-79a86733-313c-492b-a0e5-030ea18df07f,DISK], DatanodeInfoWithStorage[127.0.0.1:36947,DS-91858510-f5c8-4fa6-9d6c-4fa1babffb4a,DISK], DatanodeInfoWithStorage[127.0.0.1:44371,DS-5e3fc3e4-e6ea-401a-bde0-91d624b8cb09,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-242252257-172.17.0.3-1598210349016:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38439,DS-08b4eb26-9fc4-45b9-aca9-9a693939ce23,DISK], DatanodeInfoWithStorage[127.0.0.1:37526,DS-a8a5d6cf-e788-41d1-aab6-9bb61f8d5ab0,DISK], DatanodeInfoWithStorage[127.0.0.1:38758,DS-e09312a6-32e1-41b0-a3ad-cad3b749fe72,DISK], DatanodeInfoWithStorage[127.0.0.1:45116,DS-a32cd2be-1681-4fbd-9317-38147ee1a9e1,DISK], DatanodeInfoWithStorage[127.0.0.1:37310,DS-9829cafb-cd12-461d-ab3c-a1cb13abc646,DISK], DatanodeInfoWithStorage[127.0.0.1:35934,DS-3742e814-3620-41b5-bb88-bab40c149d37,DISK], DatanodeInfoWithStorage[127.0.0.1:38461,DS-0ebc3fc3-e6a7-4465-87a8-8e74deff2e81,DISK], DatanodeInfoWithStorage[127.0.0.1:42082,DS-9eb7db23-b16e-4012-bbb9-45b88caff2e1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-242252257-172.17.0.3-1598210349016:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38439,DS-08b4eb26-9fc4-45b9-aca9-9a693939ce23,DISK], DatanodeInfoWithStorage[127.0.0.1:37526,DS-a8a5d6cf-e788-41d1-aab6-9bb61f8d5ab0,DISK], DatanodeInfoWithStorage[127.0.0.1:38758,DS-e09312a6-32e1-41b0-a3ad-cad3b749fe72,DISK], DatanodeInfoWithStorage[127.0.0.1:45116,DS-a32cd2be-1681-4fbd-9317-38147ee1a9e1,DISK], DatanodeInfoWithStorage[127.0.0.1:37310,DS-9829cafb-cd12-461d-ab3c-a1cb13abc646,DISK], DatanodeInfoWithStorage[127.0.0.1:35934,DS-3742e814-3620-41b5-bb88-bab40c149d37,DISK], DatanodeInfoWithStorage[127.0.0.1:38461,DS-0ebc3fc3-e6a7-4465-87a8-8e74deff2e81,DISK], DatanodeInfoWithStorage[127.0.0.1:42082,DS-9eb7db23-b16e-4012-bbb9-45b88caff2e1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-639552479-172.17.0.3-1598210765793:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36980,DS-0e2eb953-d0a3-4765-9267-037db37fe37a,DISK], DatanodeInfoWithStorage[127.0.0.1:36296,DS-428407f9-33ec-4f1c-b448-b9119f759890,DISK], DatanodeInfoWithStorage[127.0.0.1:33556,DS-870185ca-84e7-4d1d-86a6-c1c373f92254,DISK], DatanodeInfoWithStorage[127.0.0.1:33748,DS-de117b0f-e799-4e18-a666-12d7cda67f21,DISK], DatanodeInfoWithStorage[127.0.0.1:33155,DS-05e92ebd-b9bb-4290-96a2-ec9ef265578e,DISK], DatanodeInfoWithStorage[127.0.0.1:44388,DS-61c62512-8ab2-41af-b498-9a5d86848314,DISK], DatanodeInfoWithStorage[127.0.0.1:37240,DS-6eeaf26c-8418-4669-a27d-2e93eb21dcef,DISK], DatanodeInfoWithStorage[127.0.0.1:43327,DS-21db8c71-03f7-474f-b382-61149cc8bfe7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-639552479-172.17.0.3-1598210765793:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36980,DS-0e2eb953-d0a3-4765-9267-037db37fe37a,DISK], DatanodeInfoWithStorage[127.0.0.1:36296,DS-428407f9-33ec-4f1c-b448-b9119f759890,DISK], DatanodeInfoWithStorage[127.0.0.1:33556,DS-870185ca-84e7-4d1d-86a6-c1c373f92254,DISK], DatanodeInfoWithStorage[127.0.0.1:33748,DS-de117b0f-e799-4e18-a666-12d7cda67f21,DISK], DatanodeInfoWithStorage[127.0.0.1:33155,DS-05e92ebd-b9bb-4290-96a2-ec9ef265578e,DISK], DatanodeInfoWithStorage[127.0.0.1:44388,DS-61c62512-8ab2-41af-b498-9a5d86848314,DISK], DatanodeInfoWithStorage[127.0.0.1:37240,DS-6eeaf26c-8418-4669-a27d-2e93eb21dcef,DISK], DatanodeInfoWithStorage[127.0.0.1:43327,DS-21db8c71-03f7-474f-b382-61149cc8bfe7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1615836747-172.17.0.3-1598210796952:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45994,DS-7dd958a1-fb5e-409e-88fd-8ec02c1c2e76,DISK], DatanodeInfoWithStorage[127.0.0.1:37145,DS-2acb4f95-8d16-44f2-8f94-da32f6d6db7d,DISK], DatanodeInfoWithStorage[127.0.0.1:38833,DS-d00107c2-7439-41e3-a9c4-c4a6be620566,DISK], DatanodeInfoWithStorage[127.0.0.1:35566,DS-40a0bfcd-2ee1-4277-9771-d744e92f9b85,DISK], DatanodeInfoWithStorage[127.0.0.1:43848,DS-6800eeaa-3304-4703-922b-3a8711c86c85,DISK], DatanodeInfoWithStorage[127.0.0.1:40170,DS-668454c2-2930-4b39-8364-d0e0acc94531,DISK], DatanodeInfoWithStorage[127.0.0.1:34599,DS-4c8a310e-8be7-48d7-b666-7ca23afcddad,DISK], DatanodeInfoWithStorage[127.0.0.1:46840,DS-1bb0770f-a8b5-44e4-ba4b-0ccde6153502,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1615836747-172.17.0.3-1598210796952:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45994,DS-7dd958a1-fb5e-409e-88fd-8ec02c1c2e76,DISK], DatanodeInfoWithStorage[127.0.0.1:37145,DS-2acb4f95-8d16-44f2-8f94-da32f6d6db7d,DISK], DatanodeInfoWithStorage[127.0.0.1:38833,DS-d00107c2-7439-41e3-a9c4-c4a6be620566,DISK], DatanodeInfoWithStorage[127.0.0.1:35566,DS-40a0bfcd-2ee1-4277-9771-d744e92f9b85,DISK], DatanodeInfoWithStorage[127.0.0.1:43848,DS-6800eeaa-3304-4703-922b-3a8711c86c85,DISK], DatanodeInfoWithStorage[127.0.0.1:40170,DS-668454c2-2930-4b39-8364-d0e0acc94531,DISK], DatanodeInfoWithStorage[127.0.0.1:34599,DS-4c8a310e-8be7-48d7-b666-7ca23afcddad,DISK], DatanodeInfoWithStorage[127.0.0.1:46840,DS-1bb0770f-a8b5-44e4-ba4b-0ccde6153502,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-834981505-172.17.0.3-1598211737193:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44397,DS-1430b3fc-01be-4ccc-90d0-332ac8f7894d,DISK], DatanodeInfoWithStorage[127.0.0.1:42546,DS-85fea3db-c3b8-4921-a518-b55ff59e3002,DISK], DatanodeInfoWithStorage[127.0.0.1:43856,DS-4c07ed4e-82b8-40d9-b992-a8ebba3e0f5e,DISK], DatanodeInfoWithStorage[127.0.0.1:37447,DS-eb6b6478-3704-46b5-a533-0b65e6cf5900,DISK], DatanodeInfoWithStorage[127.0.0.1:40875,DS-570497c3-3b5b-4626-a46f-540b25dc0956,DISK], DatanodeInfoWithStorage[127.0.0.1:40215,DS-89409be2-6d61-4a40-863e-f60d50400582,DISK], DatanodeInfoWithStorage[127.0.0.1:41406,DS-e3a25c15-7525-4a47-84d5-d234b32ade5c,DISK], DatanodeInfoWithStorage[127.0.0.1:33166,DS-86b8ac21-2c66-4d5b-9b2c-8a5cb8a8550d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-834981505-172.17.0.3-1598211737193:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44397,DS-1430b3fc-01be-4ccc-90d0-332ac8f7894d,DISK], DatanodeInfoWithStorage[127.0.0.1:42546,DS-85fea3db-c3b8-4921-a518-b55ff59e3002,DISK], DatanodeInfoWithStorage[127.0.0.1:43856,DS-4c07ed4e-82b8-40d9-b992-a8ebba3e0f5e,DISK], DatanodeInfoWithStorage[127.0.0.1:37447,DS-eb6b6478-3704-46b5-a533-0b65e6cf5900,DISK], DatanodeInfoWithStorage[127.0.0.1:40875,DS-570497c3-3b5b-4626-a46f-540b25dc0956,DISK], DatanodeInfoWithStorage[127.0.0.1:40215,DS-89409be2-6d61-4a40-863e-f60d50400582,DISK], DatanodeInfoWithStorage[127.0.0.1:41406,DS-e3a25c15-7525-4a47-84d5-d234b32ade5c,DISK], DatanodeInfoWithStorage[127.0.0.1:33166,DS-86b8ac21-2c66-4d5b-9b2c-8a5cb8a8550d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-934321119-172.17.0.3-1598212097134:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33833,DS-a104a34f-7a46-49a7-9863-6abaa6fe5b21,DISK], DatanodeInfoWithStorage[127.0.0.1:41714,DS-19918358-a8d8-4936-bcc0-0b9a0e8c800f,DISK], DatanodeInfoWithStorage[127.0.0.1:39397,DS-25ab067d-9781-4618-90e3-dc13fe20768a,DISK], DatanodeInfoWithStorage[127.0.0.1:42130,DS-8bf56b95-773a-4228-8325-3e0d3eacfd00,DISK], DatanodeInfoWithStorage[127.0.0.1:35466,DS-23a52637-b653-421d-b11a-1d8b24cf0c23,DISK], DatanodeInfoWithStorage[127.0.0.1:33571,DS-e0e5a3e0-255a-447c-a1fe-d638d6ec5fec,DISK], DatanodeInfoWithStorage[127.0.0.1:43451,DS-098d0781-1693-4a43-b2b9-938be13992fa,DISK], DatanodeInfoWithStorage[127.0.0.1:35208,DS-9defbb53-bf1a-45a2-86d7-eabae1176e83,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-934321119-172.17.0.3-1598212097134:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33833,DS-a104a34f-7a46-49a7-9863-6abaa6fe5b21,DISK], DatanodeInfoWithStorage[127.0.0.1:41714,DS-19918358-a8d8-4936-bcc0-0b9a0e8c800f,DISK], DatanodeInfoWithStorage[127.0.0.1:39397,DS-25ab067d-9781-4618-90e3-dc13fe20768a,DISK], DatanodeInfoWithStorage[127.0.0.1:42130,DS-8bf56b95-773a-4228-8325-3e0d3eacfd00,DISK], DatanodeInfoWithStorage[127.0.0.1:35466,DS-23a52637-b653-421d-b11a-1d8b24cf0c23,DISK], DatanodeInfoWithStorage[127.0.0.1:33571,DS-e0e5a3e0-255a-447c-a1fe-d638d6ec5fec,DISK], DatanodeInfoWithStorage[127.0.0.1:43451,DS-098d0781-1693-4a43-b2b9-938be13992fa,DISK], DatanodeInfoWithStorage[127.0.0.1:35208,DS-9defbb53-bf1a-45a2-86d7-eabae1176e83,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-48656718-172.17.0.3-1598212421949:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42866,DS-446d7ee3-346c-49b5-829f-160fb624f283,DISK], DatanodeInfoWithStorage[127.0.0.1:35059,DS-5d1e42c7-8977-457b-84e9-9837941a781f,DISK], DatanodeInfoWithStorage[127.0.0.1:43325,DS-05169aaf-4bbf-4844-a896-2dd582c3c3af,DISK], DatanodeInfoWithStorage[127.0.0.1:36313,DS-9dce93d6-2a2b-4d06-8e36-5914220faa40,DISK], DatanodeInfoWithStorage[127.0.0.1:41221,DS-a9e1c4f0-4a91-4fa7-9f6d-e221e8ba2214,DISK], DatanodeInfoWithStorage[127.0.0.1:35531,DS-3f9f7827-8b6f-4c26-a376-0924e2859ce9,DISK], DatanodeInfoWithStorage[127.0.0.1:34058,DS-7786902d-7e5d-4f15-a24f-a74b8d6ded7d,DISK], DatanodeInfoWithStorage[127.0.0.1:43341,DS-474456e4-13fc-4d23-8679-59dc0d7b554c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-48656718-172.17.0.3-1598212421949:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42866,DS-446d7ee3-346c-49b5-829f-160fb624f283,DISK], DatanodeInfoWithStorage[127.0.0.1:35059,DS-5d1e42c7-8977-457b-84e9-9837941a781f,DISK], DatanodeInfoWithStorage[127.0.0.1:43325,DS-05169aaf-4bbf-4844-a896-2dd582c3c3af,DISK], DatanodeInfoWithStorage[127.0.0.1:36313,DS-9dce93d6-2a2b-4d06-8e36-5914220faa40,DISK], DatanodeInfoWithStorage[127.0.0.1:41221,DS-a9e1c4f0-4a91-4fa7-9f6d-e221e8ba2214,DISK], DatanodeInfoWithStorage[127.0.0.1:35531,DS-3f9f7827-8b6f-4c26-a376-0924e2859ce9,DISK], DatanodeInfoWithStorage[127.0.0.1:34058,DS-7786902d-7e5d-4f15-a24f-a74b8d6ded7d,DISK], DatanodeInfoWithStorage[127.0.0.1:43341,DS-474456e4-13fc-4d23-8679-59dc0d7b554c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-253058418-172.17.0.3-1598212743480:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40038,DS-13495ac9-b6f1-4243-a934-7f03001f627d,DISK], DatanodeInfoWithStorage[127.0.0.1:43582,DS-07023b10-67bd-4264-a743-2dc4465f7517,DISK], DatanodeInfoWithStorage[127.0.0.1:37519,DS-31b2469c-90ff-4876-87bb-ee2edbfff38d,DISK], DatanodeInfoWithStorage[127.0.0.1:35222,DS-6978f306-b771-4347-8004-0353fa60d6c2,DISK], DatanodeInfoWithStorage[127.0.0.1:33442,DS-c1e14160-dd87-4ca2-ae21-709b27a0d757,DISK], DatanodeInfoWithStorage[127.0.0.1:40116,DS-bd036bbe-37b6-4ca6-886d-65b066b093f6,DISK], DatanodeInfoWithStorage[127.0.0.1:43401,DS-b01892c6-6f52-40f8-bde0-b9ed30cd5b81,DISK], DatanodeInfoWithStorage[127.0.0.1:41437,DS-5a5f7c3e-266d-432a-b1d5-c630d1290a02,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-253058418-172.17.0.3-1598212743480:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40038,DS-13495ac9-b6f1-4243-a934-7f03001f627d,DISK], DatanodeInfoWithStorage[127.0.0.1:43582,DS-07023b10-67bd-4264-a743-2dc4465f7517,DISK], DatanodeInfoWithStorage[127.0.0.1:37519,DS-31b2469c-90ff-4876-87bb-ee2edbfff38d,DISK], DatanodeInfoWithStorage[127.0.0.1:35222,DS-6978f306-b771-4347-8004-0353fa60d6c2,DISK], DatanodeInfoWithStorage[127.0.0.1:33442,DS-c1e14160-dd87-4ca2-ae21-709b27a0d757,DISK], DatanodeInfoWithStorage[127.0.0.1:40116,DS-bd036bbe-37b6-4ca6-886d-65b066b093f6,DISK], DatanodeInfoWithStorage[127.0.0.1:43401,DS-b01892c6-6f52-40f8-bde0-b9ed30cd5b81,DISK], DatanodeInfoWithStorage[127.0.0.1:41437,DS-5a5f7c3e-266d-432a-b1d5-c630d1290a02,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-291066176-172.17.0.3-1598213045609:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45332,DS-b0ef303d-6833-440d-8cf0-c7ffb166b3d8,DISK], DatanodeInfoWithStorage[127.0.0.1:40775,DS-f0474808-f386-4a1f-85a2-04391fcf7522,DISK], DatanodeInfoWithStorage[127.0.0.1:33220,DS-71f10916-60f8-4444-a961-a4bbbe3382c5,DISK], DatanodeInfoWithStorage[127.0.0.1:46860,DS-84588890-b3ed-4fd2-9459-2ca4d250a0a0,DISK], DatanodeInfoWithStorage[127.0.0.1:41728,DS-c1b0cf24-40ea-4aae-ab2e-6409ed8605a0,DISK], DatanodeInfoWithStorage[127.0.0.1:41940,DS-67ac3dca-ea13-4fcf-9562-a0e59476b699,DISK], DatanodeInfoWithStorage[127.0.0.1:38011,DS-1be0229e-fc42-4cb9-883d-befd72fd739f,DISK], DatanodeInfoWithStorage[127.0.0.1:33024,DS-6cf61fec-5d5e-4746-8b05-08071037e392,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-291066176-172.17.0.3-1598213045609:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45332,DS-b0ef303d-6833-440d-8cf0-c7ffb166b3d8,DISK], DatanodeInfoWithStorage[127.0.0.1:40775,DS-f0474808-f386-4a1f-85a2-04391fcf7522,DISK], DatanodeInfoWithStorage[127.0.0.1:33220,DS-71f10916-60f8-4444-a961-a4bbbe3382c5,DISK], DatanodeInfoWithStorage[127.0.0.1:46860,DS-84588890-b3ed-4fd2-9459-2ca4d250a0a0,DISK], DatanodeInfoWithStorage[127.0.0.1:41728,DS-c1b0cf24-40ea-4aae-ab2e-6409ed8605a0,DISK], DatanodeInfoWithStorage[127.0.0.1:41940,DS-67ac3dca-ea13-4fcf-9562-a0e59476b699,DISK], DatanodeInfoWithStorage[127.0.0.1:38011,DS-1be0229e-fc42-4cb9-883d-befd72fd739f,DISK], DatanodeInfoWithStorage[127.0.0.1:33024,DS-6cf61fec-5d5e-4746-8b05-08071037e392,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 6727
