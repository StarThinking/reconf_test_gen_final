reconf_parameter: dfs.xframe.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1901686206-172.17.0.9-1598346399532:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45000,DS-42c9fb05-30e9-40b8-bdc0-3b159e05a437,DISK], DatanodeInfoWithStorage[127.0.0.1:44806,DS-f07f1e24-fac1-4361-9e33-b0d963699c8a,DISK], DatanodeInfoWithStorage[127.0.0.1:38263,DS-0bb0fb8d-d756-4089-a3c8-2101bf8bd63c,DISK], DatanodeInfoWithStorage[127.0.0.1:41860,DS-8a8e75e6-99c1-4011-abe0-2e5a722596ab,DISK], DatanodeInfoWithStorage[127.0.0.1:40328,DS-d2a61993-5757-4963-8100-e47b82e8f0e6,DISK], DatanodeInfoWithStorage[127.0.0.1:39120,DS-fdf1b501-6324-4baa-b39f-34defa2fca3a,DISK], DatanodeInfoWithStorage[127.0.0.1:40106,DS-b70858e6-cd15-476d-9551-48d9cd19bd79,DISK], DatanodeInfoWithStorage[127.0.0.1:46063,DS-50c24935-1fa7-47ae-97aa-3bd1aacac86f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1901686206-172.17.0.9-1598346399532:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45000,DS-42c9fb05-30e9-40b8-bdc0-3b159e05a437,DISK], DatanodeInfoWithStorage[127.0.0.1:44806,DS-f07f1e24-fac1-4361-9e33-b0d963699c8a,DISK], DatanodeInfoWithStorage[127.0.0.1:38263,DS-0bb0fb8d-d756-4089-a3c8-2101bf8bd63c,DISK], DatanodeInfoWithStorage[127.0.0.1:41860,DS-8a8e75e6-99c1-4011-abe0-2e5a722596ab,DISK], DatanodeInfoWithStorage[127.0.0.1:40328,DS-d2a61993-5757-4963-8100-e47b82e8f0e6,DISK], DatanodeInfoWithStorage[127.0.0.1:39120,DS-fdf1b501-6324-4baa-b39f-34defa2fca3a,DISK], DatanodeInfoWithStorage[127.0.0.1:40106,DS-b70858e6-cd15-476d-9551-48d9cd19bd79,DISK], DatanodeInfoWithStorage[127.0.0.1:46063,DS-50c24935-1fa7-47ae-97aa-3bd1aacac86f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1537354155-172.17.0.9-1598347046283:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44880,DS-a46ed50e-daad-4e45-9c33-d52c6018aea8,DISK], DatanodeInfoWithStorage[127.0.0.1:37120,DS-4fb9be94-5e41-473c-ab70-3c7ed75261c6,DISK], DatanodeInfoWithStorage[127.0.0.1:40755,DS-358f5d6b-b71a-47fd-a9d1-3f2a2886cbe3,DISK], DatanodeInfoWithStorage[127.0.0.1:45652,DS-82870d04-e24f-48e6-9460-d7a62e6bf5a5,DISK], DatanodeInfoWithStorage[127.0.0.1:38288,DS-c742b9ec-7045-43fb-95b0-370e250cc22d,DISK], DatanodeInfoWithStorage[127.0.0.1:39551,DS-946475dc-0222-4779-9a3c-224fb835701a,DISK], DatanodeInfoWithStorage[127.0.0.1:45107,DS-cfd0357f-c24f-454a-bd0b-412d1594b3c6,DISK], DatanodeInfoWithStorage[127.0.0.1:44213,DS-4915b9a6-5e5e-465c-8103-e91e3cc1a2fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1537354155-172.17.0.9-1598347046283:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44880,DS-a46ed50e-daad-4e45-9c33-d52c6018aea8,DISK], DatanodeInfoWithStorage[127.0.0.1:37120,DS-4fb9be94-5e41-473c-ab70-3c7ed75261c6,DISK], DatanodeInfoWithStorage[127.0.0.1:40755,DS-358f5d6b-b71a-47fd-a9d1-3f2a2886cbe3,DISK], DatanodeInfoWithStorage[127.0.0.1:45652,DS-82870d04-e24f-48e6-9460-d7a62e6bf5a5,DISK], DatanodeInfoWithStorage[127.0.0.1:38288,DS-c742b9ec-7045-43fb-95b0-370e250cc22d,DISK], DatanodeInfoWithStorage[127.0.0.1:39551,DS-946475dc-0222-4779-9a3c-224fb835701a,DISK], DatanodeInfoWithStorage[127.0.0.1:45107,DS-cfd0357f-c24f-454a-bd0b-412d1594b3c6,DISK], DatanodeInfoWithStorage[127.0.0.1:44213,DS-4915b9a6-5e5e-465c-8103-e91e3cc1a2fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-525687218-172.17.0.9-1598347081042:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43355,DS-bfb766ed-de7d-4259-b614-ce193a6d7e96,DISK], DatanodeInfoWithStorage[127.0.0.1:34756,DS-e83f5b65-7505-4dd7-8e5f-02273ee2d494,DISK], DatanodeInfoWithStorage[127.0.0.1:43854,DS-fa041078-adcd-471c-828d-7eadc0110dc9,DISK], DatanodeInfoWithStorage[127.0.0.1:35720,DS-685f5609-7ca8-4cae-b914-d8237de3b647,DISK], DatanodeInfoWithStorage[127.0.0.1:34247,DS-34068e6e-e2fb-427b-9802-4da0e37cc197,DISK], DatanodeInfoWithStorage[127.0.0.1:37171,DS-33ecbb86-5982-4588-9b18-f01461b581c7,DISK], DatanodeInfoWithStorage[127.0.0.1:38766,DS-bae4ec9f-0c89-4761-bcdb-887fe121b6b0,DISK], DatanodeInfoWithStorage[127.0.0.1:33649,DS-35a1c90f-cd13-4ee8-9c20-2ed307363a96,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-525687218-172.17.0.9-1598347081042:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43355,DS-bfb766ed-de7d-4259-b614-ce193a6d7e96,DISK], DatanodeInfoWithStorage[127.0.0.1:34756,DS-e83f5b65-7505-4dd7-8e5f-02273ee2d494,DISK], DatanodeInfoWithStorage[127.0.0.1:43854,DS-fa041078-adcd-471c-828d-7eadc0110dc9,DISK], DatanodeInfoWithStorage[127.0.0.1:35720,DS-685f5609-7ca8-4cae-b914-d8237de3b647,DISK], DatanodeInfoWithStorage[127.0.0.1:34247,DS-34068e6e-e2fb-427b-9802-4da0e37cc197,DISK], DatanodeInfoWithStorage[127.0.0.1:37171,DS-33ecbb86-5982-4588-9b18-f01461b581c7,DISK], DatanodeInfoWithStorage[127.0.0.1:38766,DS-bae4ec9f-0c89-4761-bcdb-887fe121b6b0,DISK], DatanodeInfoWithStorage[127.0.0.1:33649,DS-35a1c90f-cd13-4ee8-9c20-2ed307363a96,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-95029495-172.17.0.9-1598347765248:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38696,DS-ce9d46d5-0e0c-4518-a393-cb62fee380c6,DISK], DatanodeInfoWithStorage[127.0.0.1:34234,DS-1fc317b7-6154-4624-ae1e-c368cdd3d1c8,DISK], DatanodeInfoWithStorage[127.0.0.1:42039,DS-ed8c4eb2-5804-4f68-866d-fd72e7019e8b,DISK], DatanodeInfoWithStorage[127.0.0.1:44434,DS-7fe1367a-9b85-47b2-9eb5-eca13933714e,DISK], DatanodeInfoWithStorage[127.0.0.1:39843,DS-3fc99982-2cd7-4194-8ed9-a6286b581b0f,DISK], DatanodeInfoWithStorage[127.0.0.1:38679,DS-b69071b7-a800-4f60-b4e9-7848c9440224,DISK], DatanodeInfoWithStorage[127.0.0.1:40292,DS-47d3d6bd-bac8-4baf-908a-54d8d387392e,DISK], DatanodeInfoWithStorage[127.0.0.1:43010,DS-7e79d789-6a39-49d0-a21d-b043cf9a6f57,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-95029495-172.17.0.9-1598347765248:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38696,DS-ce9d46d5-0e0c-4518-a393-cb62fee380c6,DISK], DatanodeInfoWithStorage[127.0.0.1:34234,DS-1fc317b7-6154-4624-ae1e-c368cdd3d1c8,DISK], DatanodeInfoWithStorage[127.0.0.1:42039,DS-ed8c4eb2-5804-4f68-866d-fd72e7019e8b,DISK], DatanodeInfoWithStorage[127.0.0.1:44434,DS-7fe1367a-9b85-47b2-9eb5-eca13933714e,DISK], DatanodeInfoWithStorage[127.0.0.1:39843,DS-3fc99982-2cd7-4194-8ed9-a6286b581b0f,DISK], DatanodeInfoWithStorage[127.0.0.1:38679,DS-b69071b7-a800-4f60-b4e9-7848c9440224,DISK], DatanodeInfoWithStorage[127.0.0.1:40292,DS-47d3d6bd-bac8-4baf-908a-54d8d387392e,DISK], DatanodeInfoWithStorage[127.0.0.1:43010,DS-7e79d789-6a39-49d0-a21d-b043cf9a6f57,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2140602419-172.17.0.9-1598347916806:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46839,DS-120cee62-b3a6-4bd3-aaa4-a58b999f9834,DISK], DatanodeInfoWithStorage[127.0.0.1:33836,DS-2eee17f9-05d6-4147-bd26-87cf7421b8d8,DISK], DatanodeInfoWithStorage[127.0.0.1:33885,DS-a8d456fb-cb4b-4936-b267-f5979d73e608,DISK], DatanodeInfoWithStorage[127.0.0.1:37729,DS-ce02ce11-05c9-48cc-95f2-53bb31af23c6,DISK], DatanodeInfoWithStorage[127.0.0.1:40600,DS-5022e088-4adc-4a04-9491-96c376f6e45e,DISK], DatanodeInfoWithStorage[127.0.0.1:33717,DS-c7e4505e-15b7-4d14-a4c6-bf42c957fa86,DISK], DatanodeInfoWithStorage[127.0.0.1:45063,DS-4c567d8f-d1b6-4412-8d5e-3e97f3b294cc,DISK], DatanodeInfoWithStorage[127.0.0.1:37354,DS-483d7ea1-1ad7-4b5d-9e89-20246b3fc595,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2140602419-172.17.0.9-1598347916806:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46839,DS-120cee62-b3a6-4bd3-aaa4-a58b999f9834,DISK], DatanodeInfoWithStorage[127.0.0.1:33836,DS-2eee17f9-05d6-4147-bd26-87cf7421b8d8,DISK], DatanodeInfoWithStorage[127.0.0.1:33885,DS-a8d456fb-cb4b-4936-b267-f5979d73e608,DISK], DatanodeInfoWithStorage[127.0.0.1:37729,DS-ce02ce11-05c9-48cc-95f2-53bb31af23c6,DISK], DatanodeInfoWithStorage[127.0.0.1:40600,DS-5022e088-4adc-4a04-9491-96c376f6e45e,DISK], DatanodeInfoWithStorage[127.0.0.1:33717,DS-c7e4505e-15b7-4d14-a4c6-bf42c957fa86,DISK], DatanodeInfoWithStorage[127.0.0.1:45063,DS-4c567d8f-d1b6-4412-8d5e-3e97f3b294cc,DISK], DatanodeInfoWithStorage[127.0.0.1:37354,DS-483d7ea1-1ad7-4b5d-9e89-20246b3fc595,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-972407061-172.17.0.9-1598348181412:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45276,DS-ff113531-b278-4da6-bda7-78bb9d4f1c97,DISK], DatanodeInfoWithStorage[127.0.0.1:38109,DS-83d78210-f231-4778-9321-4d3daf705abf,DISK], DatanodeInfoWithStorage[127.0.0.1:40133,DS-7aec39de-8fcb-4b29-aada-65371a01c26f,DISK], DatanodeInfoWithStorage[127.0.0.1:45006,DS-d0adaff3-79af-4cee-a719-ec241d1af5bf,DISK], DatanodeInfoWithStorage[127.0.0.1:35765,DS-c25ac63e-09e3-4e11-a69a-917c348aa5c8,DISK], DatanodeInfoWithStorage[127.0.0.1:42261,DS-54e70691-1f0b-4908-b5b3-3607329cd4df,DISK], DatanodeInfoWithStorage[127.0.0.1:40401,DS-1407907c-907b-463a-82da-529acdf3cfcf,DISK], DatanodeInfoWithStorage[127.0.0.1:36570,DS-d6ee5a33-1777-4737-8833-51bd1712598d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-972407061-172.17.0.9-1598348181412:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45276,DS-ff113531-b278-4da6-bda7-78bb9d4f1c97,DISK], DatanodeInfoWithStorage[127.0.0.1:38109,DS-83d78210-f231-4778-9321-4d3daf705abf,DISK], DatanodeInfoWithStorage[127.0.0.1:40133,DS-7aec39de-8fcb-4b29-aada-65371a01c26f,DISK], DatanodeInfoWithStorage[127.0.0.1:45006,DS-d0adaff3-79af-4cee-a719-ec241d1af5bf,DISK], DatanodeInfoWithStorage[127.0.0.1:35765,DS-c25ac63e-09e3-4e11-a69a-917c348aa5c8,DISK], DatanodeInfoWithStorage[127.0.0.1:42261,DS-54e70691-1f0b-4908-b5b3-3607329cd4df,DISK], DatanodeInfoWithStorage[127.0.0.1:40401,DS-1407907c-907b-463a-82da-529acdf3cfcf,DISK], DatanodeInfoWithStorage[127.0.0.1:36570,DS-d6ee5a33-1777-4737-8833-51bd1712598d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-677750364-172.17.0.9-1598348617261:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38598,DS-8297d031-0ef6-4b0d-a598-7a76f0b3b5f0,DISK], DatanodeInfoWithStorage[127.0.0.1:34763,DS-da77c51c-12c3-4fce-a343-3168cb8ed841,DISK], DatanodeInfoWithStorage[127.0.0.1:35815,DS-c7418331-721a-4792-9bbb-9df967c2e05f,DISK], DatanodeInfoWithStorage[127.0.0.1:35668,DS-e2cb233c-da1d-4b90-bd3e-7df42d458a37,DISK], DatanodeInfoWithStorage[127.0.0.1:35803,DS-0e2f1aa9-53cc-4996-b135-69be0f6f6d62,DISK], DatanodeInfoWithStorage[127.0.0.1:36915,DS-aad5e0ed-86c1-4333-b664-53c2f0af3896,DISK], DatanodeInfoWithStorage[127.0.0.1:46024,DS-4b71da22-c00a-4e0c-825f-26c3b5286ffc,DISK], DatanodeInfoWithStorage[127.0.0.1:40907,DS-ca014a30-1748-4d94-82e7-39e9faf32d76,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-677750364-172.17.0.9-1598348617261:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38598,DS-8297d031-0ef6-4b0d-a598-7a76f0b3b5f0,DISK], DatanodeInfoWithStorage[127.0.0.1:34763,DS-da77c51c-12c3-4fce-a343-3168cb8ed841,DISK], DatanodeInfoWithStorage[127.0.0.1:35815,DS-c7418331-721a-4792-9bbb-9df967c2e05f,DISK], DatanodeInfoWithStorage[127.0.0.1:35668,DS-e2cb233c-da1d-4b90-bd3e-7df42d458a37,DISK], DatanodeInfoWithStorage[127.0.0.1:35803,DS-0e2f1aa9-53cc-4996-b135-69be0f6f6d62,DISK], DatanodeInfoWithStorage[127.0.0.1:36915,DS-aad5e0ed-86c1-4333-b664-53c2f0af3896,DISK], DatanodeInfoWithStorage[127.0.0.1:46024,DS-4b71da22-c00a-4e0c-825f-26c3b5286ffc,DISK], DatanodeInfoWithStorage[127.0.0.1:40907,DS-ca014a30-1748-4d94-82e7-39e9faf32d76,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.xframe.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-650143788-172.17.0.9-1598348651111:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45784,DS-5e500315-ffdb-4378-ae0a-6d4cb625ed4f,DISK], DatanodeInfoWithStorage[127.0.0.1:46523,DS-9e6e300f-b317-4082-8562-cd7e7f208f9b,DISK], DatanodeInfoWithStorage[127.0.0.1:45217,DS-4649694f-3dfb-455f-bc90-d2fa93419bfa,DISK], DatanodeInfoWithStorage[127.0.0.1:38024,DS-e8688ec7-0905-48b2-960e-7d892e4bec9c,DISK], DatanodeInfoWithStorage[127.0.0.1:39408,DS-30658d3c-2b7e-4174-9f2d-3f2640ffb02f,DISK], DatanodeInfoWithStorage[127.0.0.1:41836,DS-97738eb6-d793-4681-b326-1ebf2d05be1c,DISK], DatanodeInfoWithStorage[127.0.0.1:41719,DS-d62c2a4b-2c20-4fe2-b66a-1e668233a1eb,DISK], DatanodeInfoWithStorage[127.0.0.1:37398,DS-e7b4bac8-a410-41ae-a90c-ce59a007dbc9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-650143788-172.17.0.9-1598348651111:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45784,DS-5e500315-ffdb-4378-ae0a-6d4cb625ed4f,DISK], DatanodeInfoWithStorage[127.0.0.1:46523,DS-9e6e300f-b317-4082-8562-cd7e7f208f9b,DISK], DatanodeInfoWithStorage[127.0.0.1:45217,DS-4649694f-3dfb-455f-bc90-d2fa93419bfa,DISK], DatanodeInfoWithStorage[127.0.0.1:38024,DS-e8688ec7-0905-48b2-960e-7d892e4bec9c,DISK], DatanodeInfoWithStorage[127.0.0.1:39408,DS-30658d3c-2b7e-4174-9f2d-3f2640ffb02f,DISK], DatanodeInfoWithStorage[127.0.0.1:41836,DS-97738eb6-d793-4681-b326-1ebf2d05be1c,DISK], DatanodeInfoWithStorage[127.0.0.1:41719,DS-d62c2a4b-2c20-4fe2-b66a-1e668233a1eb,DISK], DatanodeInfoWithStorage[127.0.0.1:37398,DS-e7b4bac8-a410-41ae-a90c-ce59a007dbc9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-98455345-172.17.0.9-1598348799056:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35566,DS-b0d4db31-b3db-48dc-8f38-0c34e37c66ea,DISK], DatanodeInfoWithStorage[127.0.0.1:42171,DS-8db69e90-666e-4b1c-9541-6992d761e12e,DISK], DatanodeInfoWithStorage[127.0.0.1:39845,DS-33a54736-ed09-4fc7-9895-3b0f7ec23427,DISK], DatanodeInfoWithStorage[127.0.0.1:40089,DS-7ee74243-eb02-4bad-a9bd-ca0d7d727a26,DISK], DatanodeInfoWithStorage[127.0.0.1:44092,DS-ffb22084-6f44-405d-9345-6b79f5cb0e06,DISK], DatanodeInfoWithStorage[127.0.0.1:37085,DS-e8c50d29-e36d-40b9-ae1f-7a1ea4889567,DISK], DatanodeInfoWithStorage[127.0.0.1:37975,DS-08c084ee-063d-4004-a6d2-f2342bb7c3ad,DISK], DatanodeInfoWithStorage[127.0.0.1:37837,DS-a5ba0c12-fab0-4cbc-9789-5d299e2e2557,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-98455345-172.17.0.9-1598348799056:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35566,DS-b0d4db31-b3db-48dc-8f38-0c34e37c66ea,DISK], DatanodeInfoWithStorage[127.0.0.1:42171,DS-8db69e90-666e-4b1c-9541-6992d761e12e,DISK], DatanodeInfoWithStorage[127.0.0.1:39845,DS-33a54736-ed09-4fc7-9895-3b0f7ec23427,DISK], DatanodeInfoWithStorage[127.0.0.1:40089,DS-7ee74243-eb02-4bad-a9bd-ca0d7d727a26,DISK], DatanodeInfoWithStorage[127.0.0.1:44092,DS-ffb22084-6f44-405d-9345-6b79f5cb0e06,DISK], DatanodeInfoWithStorage[127.0.0.1:37085,DS-e8c50d29-e36d-40b9-ae1f-7a1ea4889567,DISK], DatanodeInfoWithStorage[127.0.0.1:37975,DS-08c084ee-063d-4004-a6d2-f2342bb7c3ad,DISK], DatanodeInfoWithStorage[127.0.0.1:37837,DS-a5ba0c12-fab0-4cbc-9789-5d299e2e2557,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-960267791-172.17.0.9-1598349350919:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45934,DS-b42962f0-9b25-4838-9f42-f57deb9d7f60,DISK], DatanodeInfoWithStorage[127.0.0.1:41585,DS-65b1b7eb-bf03-4216-901f-db79b19c6c30,DISK], DatanodeInfoWithStorage[127.0.0.1:43451,DS-85e7449e-c3d2-4458-bb37-04cb3622ba66,DISK], DatanodeInfoWithStorage[127.0.0.1:46394,DS-ecbb8726-6019-45ed-9036-1503431bb6ea,DISK], DatanodeInfoWithStorage[127.0.0.1:35467,DS-c528eba6-618a-4225-bf1e-3142c7a47171,DISK], DatanodeInfoWithStorage[127.0.0.1:33280,DS-d92379a5-1cd2-4fa2-8d8a-0ccf8010b986,DISK], DatanodeInfoWithStorage[127.0.0.1:44818,DS-52c319c8-8f9c-4235-ba6c-9e05d81433a5,DISK], DatanodeInfoWithStorage[127.0.0.1:37841,DS-c7663cf8-2bf2-4d09-9f94-4c3d51c8d631,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-960267791-172.17.0.9-1598349350919:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45934,DS-b42962f0-9b25-4838-9f42-f57deb9d7f60,DISK], DatanodeInfoWithStorage[127.0.0.1:41585,DS-65b1b7eb-bf03-4216-901f-db79b19c6c30,DISK], DatanodeInfoWithStorage[127.0.0.1:43451,DS-85e7449e-c3d2-4458-bb37-04cb3622ba66,DISK], DatanodeInfoWithStorage[127.0.0.1:46394,DS-ecbb8726-6019-45ed-9036-1503431bb6ea,DISK], DatanodeInfoWithStorage[127.0.0.1:35467,DS-c528eba6-618a-4225-bf1e-3142c7a47171,DISK], DatanodeInfoWithStorage[127.0.0.1:33280,DS-d92379a5-1cd2-4fa2-8d8a-0ccf8010b986,DISK], DatanodeInfoWithStorage[127.0.0.1:44818,DS-52c319c8-8f9c-4235-ba6c-9e05d81433a5,DISK], DatanodeInfoWithStorage[127.0.0.1:37841,DS-c7663cf8-2bf2-4d09-9f94-4c3d51c8d631,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1116399443-172.17.0.9-1598350376399:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44440,DS-b0f73665-f980-4a3d-bcc0-9f8f900744a5,DISK], DatanodeInfoWithStorage[127.0.0.1:37804,DS-2b725d02-554f-4008-a17e-7651a541560f,DISK], DatanodeInfoWithStorage[127.0.0.1:42579,DS-c12208cb-e129-40eb-b729-35239e776158,DISK], DatanodeInfoWithStorage[127.0.0.1:39578,DS-2e7c44c7-bbd1-44df-a476-c5dc490008fb,DISK], DatanodeInfoWithStorage[127.0.0.1:33571,DS-c702e89a-52d7-4a24-9cb7-9be58e2d9805,DISK], DatanodeInfoWithStorage[127.0.0.1:35108,DS-89357304-9ed6-493d-96fa-fbd6d39c0ac8,DISK], DatanodeInfoWithStorage[127.0.0.1:44756,DS-8c070a37-a24d-4ba0-86aa-b0e3aadcb162,DISK], DatanodeInfoWithStorage[127.0.0.1:36259,DS-49eeb2e7-fbd9-4089-b594-9ea89b46b699,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1116399443-172.17.0.9-1598350376399:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44440,DS-b0f73665-f980-4a3d-bcc0-9f8f900744a5,DISK], DatanodeInfoWithStorage[127.0.0.1:37804,DS-2b725d02-554f-4008-a17e-7651a541560f,DISK], DatanodeInfoWithStorage[127.0.0.1:42579,DS-c12208cb-e129-40eb-b729-35239e776158,DISK], DatanodeInfoWithStorage[127.0.0.1:39578,DS-2e7c44c7-bbd1-44df-a476-c5dc490008fb,DISK], DatanodeInfoWithStorage[127.0.0.1:33571,DS-c702e89a-52d7-4a24-9cb7-9be58e2d9805,DISK], DatanodeInfoWithStorage[127.0.0.1:35108,DS-89357304-9ed6-493d-96fa-fbd6d39c0ac8,DISK], DatanodeInfoWithStorage[127.0.0.1:44756,DS-8c070a37-a24d-4ba0-86aa-b0e3aadcb162,DISK], DatanodeInfoWithStorage[127.0.0.1:36259,DS-49eeb2e7-fbd9-4089-b594-9ea89b46b699,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1496924047-172.17.0.9-1598350709209:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35299,DS-bd27480f-d6f2-4afb-8e95-f9890d3f0587,DISK], DatanodeInfoWithStorage[127.0.0.1:46115,DS-e52fc089-723e-4011-b7ae-01da08cfeefd,DISK], DatanodeInfoWithStorage[127.0.0.1:38312,DS-70ec866d-7f9e-47a9-ae26-27aa91635c17,DISK], DatanodeInfoWithStorage[127.0.0.1:39184,DS-dbbe5dc3-377b-46f0-b723-9f476dc3e5b6,DISK], DatanodeInfoWithStorage[127.0.0.1:42484,DS-5ea88096-0a7f-4d3e-8944-414d9fc3590b,DISK], DatanodeInfoWithStorage[127.0.0.1:40888,DS-65a6e572-4e29-43ad-b4ed-c2b0de169110,DISK], DatanodeInfoWithStorage[127.0.0.1:33697,DS-81593588-c314-4557-88aa-d47ed47d0472,DISK], DatanodeInfoWithStorage[127.0.0.1:34306,DS-3348868a-9a6c-449a-a026-012311dce416,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1496924047-172.17.0.9-1598350709209:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35299,DS-bd27480f-d6f2-4afb-8e95-f9890d3f0587,DISK], DatanodeInfoWithStorage[127.0.0.1:46115,DS-e52fc089-723e-4011-b7ae-01da08cfeefd,DISK], DatanodeInfoWithStorage[127.0.0.1:38312,DS-70ec866d-7f9e-47a9-ae26-27aa91635c17,DISK], DatanodeInfoWithStorage[127.0.0.1:39184,DS-dbbe5dc3-377b-46f0-b723-9f476dc3e5b6,DISK], DatanodeInfoWithStorage[127.0.0.1:42484,DS-5ea88096-0a7f-4d3e-8944-414d9fc3590b,DISK], DatanodeInfoWithStorage[127.0.0.1:40888,DS-65a6e572-4e29-43ad-b4ed-c2b0de169110,DISK], DatanodeInfoWithStorage[127.0.0.1:33697,DS-81593588-c314-4557-88aa-d47ed47d0472,DISK], DatanodeInfoWithStorage[127.0.0.1:34306,DS-3348868a-9a6c-449a-a026-012311dce416,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-31855323-172.17.0.9-1598351565846:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37161,DS-9b6f7441-a826-4951-a1e3-5589ec869ddf,DISK], DatanodeInfoWithStorage[127.0.0.1:37820,DS-b79b944a-cea2-463a-a779-35fbaf20a4d9,DISK], DatanodeInfoWithStorage[127.0.0.1:33819,DS-abc49f42-cb7a-451f-8d3e-4f7e220d6c32,DISK], DatanodeInfoWithStorage[127.0.0.1:46657,DS-98635c11-a83d-48d7-9c0d-33e3f1f3397d,DISK], DatanodeInfoWithStorage[127.0.0.1:38723,DS-b43a2caa-d90b-43b3-b1ea-27b0c845b16d,DISK], DatanodeInfoWithStorage[127.0.0.1:38372,DS-fea57010-0eeb-4434-ac2d-4cf9d9f4511d,DISK], DatanodeInfoWithStorage[127.0.0.1:46033,DS-ce948b6b-b0ef-49ef-bf72-d44f245c7c25,DISK], DatanodeInfoWithStorage[127.0.0.1:44113,DS-cabe5a9e-5f2c-4d77-a8c3-7a2bc9a0d415,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-31855323-172.17.0.9-1598351565846:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37161,DS-9b6f7441-a826-4951-a1e3-5589ec869ddf,DISK], DatanodeInfoWithStorage[127.0.0.1:37820,DS-b79b944a-cea2-463a-a779-35fbaf20a4d9,DISK], DatanodeInfoWithStorage[127.0.0.1:33819,DS-abc49f42-cb7a-451f-8d3e-4f7e220d6c32,DISK], DatanodeInfoWithStorage[127.0.0.1:46657,DS-98635c11-a83d-48d7-9c0d-33e3f1f3397d,DISK], DatanodeInfoWithStorage[127.0.0.1:38723,DS-b43a2caa-d90b-43b3-b1ea-27b0c845b16d,DISK], DatanodeInfoWithStorage[127.0.0.1:38372,DS-fea57010-0eeb-4434-ac2d-4cf9d9f4511d,DISK], DatanodeInfoWithStorage[127.0.0.1:46033,DS-ce948b6b-b0ef-49ef-bf72-d44f245c7c25,DISK], DatanodeInfoWithStorage[127.0.0.1:44113,DS-cabe5a9e-5f2c-4d77-a8c3-7a2bc9a0d415,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 7 out of 50
result: false positive !!!
Total execution time in seconds : 5545
