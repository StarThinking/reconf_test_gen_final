reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-591881765-172.17.0.10-1598182998268:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34321,DS-747be0c9-5218-4522-9e83-11b0554b812a,DISK], DatanodeInfoWithStorage[127.0.0.1:45006,DS-488311b7-121f-4273-9c7a-f2ab535bfca6,DISK], DatanodeInfoWithStorage[127.0.0.1:41107,DS-f1ab8676-3df8-4c78-86b6-3a3e1258b663,DISK], DatanodeInfoWithStorage[127.0.0.1:34539,DS-8f692744-210f-4efe-bcf7-9fbbfbb1827a,DISK], DatanodeInfoWithStorage[127.0.0.1:41481,DS-1e687500-d586-47ce-a53c-b088dab98efa,DISK], DatanodeInfoWithStorage[127.0.0.1:41607,DS-1c426abf-2e92-4f70-94ea-40ae0ac92070,DISK], DatanodeInfoWithStorage[127.0.0.1:40410,DS-2de33afd-1dde-4f18-b950-bb092eb9bc66,DISK], DatanodeInfoWithStorage[127.0.0.1:43249,DS-159d7dec-c2bd-4fa5-ba58-569f803445a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-591881765-172.17.0.10-1598182998268:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34321,DS-747be0c9-5218-4522-9e83-11b0554b812a,DISK], DatanodeInfoWithStorage[127.0.0.1:45006,DS-488311b7-121f-4273-9c7a-f2ab535bfca6,DISK], DatanodeInfoWithStorage[127.0.0.1:41107,DS-f1ab8676-3df8-4c78-86b6-3a3e1258b663,DISK], DatanodeInfoWithStorage[127.0.0.1:34539,DS-8f692744-210f-4efe-bcf7-9fbbfbb1827a,DISK], DatanodeInfoWithStorage[127.0.0.1:41481,DS-1e687500-d586-47ce-a53c-b088dab98efa,DISK], DatanodeInfoWithStorage[127.0.0.1:41607,DS-1c426abf-2e92-4f70-94ea-40ae0ac92070,DISK], DatanodeInfoWithStorage[127.0.0.1:40410,DS-2de33afd-1dde-4f18-b950-bb092eb9bc66,DISK], DatanodeInfoWithStorage[127.0.0.1:43249,DS-159d7dec-c2bd-4fa5-ba58-569f803445a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-907508398-172.17.0.10-1598183409974:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40506,DS-8d075b68-3a0d-404d-b61a-d9bc59de8199,DISK], DatanodeInfoWithStorage[127.0.0.1:33626,DS-c4f04a22-b22d-4a83-af70-7755921a47d7,DISK], DatanodeInfoWithStorage[127.0.0.1:45358,DS-38de9a09-59cb-4e84-9451-307dadab7feb,DISK], DatanodeInfoWithStorage[127.0.0.1:33203,DS-2f9e36ec-ec5c-416b-9276-16c9356a1178,DISK], DatanodeInfoWithStorage[127.0.0.1:45493,DS-0ea72e19-927a-4ee4-962d-5b57c4a0f152,DISK], DatanodeInfoWithStorage[127.0.0.1:45992,DS-01e637ba-f4d1-4ece-bce3-dd1285746ec8,DISK], DatanodeInfoWithStorage[127.0.0.1:35762,DS-bdbc3ee9-e0df-4ad8-ab9d-df86566b7104,DISK], DatanodeInfoWithStorage[127.0.0.1:34645,DS-fc475e72-842c-4cbd-91c9-4f8cc44de74b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-907508398-172.17.0.10-1598183409974:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40506,DS-8d075b68-3a0d-404d-b61a-d9bc59de8199,DISK], DatanodeInfoWithStorage[127.0.0.1:33626,DS-c4f04a22-b22d-4a83-af70-7755921a47d7,DISK], DatanodeInfoWithStorage[127.0.0.1:45358,DS-38de9a09-59cb-4e84-9451-307dadab7feb,DISK], DatanodeInfoWithStorage[127.0.0.1:33203,DS-2f9e36ec-ec5c-416b-9276-16c9356a1178,DISK], DatanodeInfoWithStorage[127.0.0.1:45493,DS-0ea72e19-927a-4ee4-962d-5b57c4a0f152,DISK], DatanodeInfoWithStorage[127.0.0.1:45992,DS-01e637ba-f4d1-4ece-bce3-dd1285746ec8,DISK], DatanodeInfoWithStorage[127.0.0.1:35762,DS-bdbc3ee9-e0df-4ad8-ab9d-df86566b7104,DISK], DatanodeInfoWithStorage[127.0.0.1:34645,DS-fc475e72-842c-4cbd-91c9-4f8cc44de74b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1597226033-172.17.0.10-1598183503300:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36010,DS-0b6bdff7-4ee2-41d4-ae7b-6d217c33b221,DISK], DatanodeInfoWithStorage[127.0.0.1:40540,DS-557b6e12-9e0c-49e4-9f62-e116823ffb66,DISK], DatanodeInfoWithStorage[127.0.0.1:39164,DS-3bafe582-9076-48b9-aa7c-45da4cd8b8b6,DISK], DatanodeInfoWithStorage[127.0.0.1:38320,DS-bb6d87ac-9678-47a0-a3a7-e59db8f9bb23,DISK], DatanodeInfoWithStorage[127.0.0.1:35882,DS-c99276e6-aa3f-4c35-8e08-7226844214db,DISK], DatanodeInfoWithStorage[127.0.0.1:33127,DS-f58ca364-6fa4-4be7-bd10-b4ff2a72425c,DISK], DatanodeInfoWithStorage[127.0.0.1:41519,DS-17a38e33-7da4-446b-af95-46d1cc52e681,DISK], DatanodeInfoWithStorage[127.0.0.1:38863,DS-fcf2cf3b-5325-4339-b13f-469c1e03dcbb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1597226033-172.17.0.10-1598183503300:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36010,DS-0b6bdff7-4ee2-41d4-ae7b-6d217c33b221,DISK], DatanodeInfoWithStorage[127.0.0.1:40540,DS-557b6e12-9e0c-49e4-9f62-e116823ffb66,DISK], DatanodeInfoWithStorage[127.0.0.1:39164,DS-3bafe582-9076-48b9-aa7c-45da4cd8b8b6,DISK], DatanodeInfoWithStorage[127.0.0.1:38320,DS-bb6d87ac-9678-47a0-a3a7-e59db8f9bb23,DISK], DatanodeInfoWithStorage[127.0.0.1:35882,DS-c99276e6-aa3f-4c35-8e08-7226844214db,DISK], DatanodeInfoWithStorage[127.0.0.1:33127,DS-f58ca364-6fa4-4be7-bd10-b4ff2a72425c,DISK], DatanodeInfoWithStorage[127.0.0.1:41519,DS-17a38e33-7da4-446b-af95-46d1cc52e681,DISK], DatanodeInfoWithStorage[127.0.0.1:38863,DS-fcf2cf3b-5325-4339-b13f-469c1e03dcbb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1887285141-172.17.0.10-1598183847400:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34567,DS-407c2516-d116-452f-a107-0d872ea7e003,DISK], DatanodeInfoWithStorage[127.0.0.1:38482,DS-f09aa4c1-c020-475d-9579-64633119ac04,DISK], DatanodeInfoWithStorage[127.0.0.1:44459,DS-fd7b83cd-ab6a-4b94-bbc2-012c944c10ca,DISK], DatanodeInfoWithStorage[127.0.0.1:36021,DS-0605e661-4aa6-48ee-b7ac-6431eac7f23f,DISK], DatanodeInfoWithStorage[127.0.0.1:46194,DS-a61cdcc0-8254-436c-a188-749fbdd3d68b,DISK], DatanodeInfoWithStorage[127.0.0.1:37127,DS-53d005ad-ff79-4cf8-ba0d-e35811aa69ae,DISK], DatanodeInfoWithStorage[127.0.0.1:46796,DS-efc82036-6273-43f4-9581-e1a87698b25a,DISK], DatanodeInfoWithStorage[127.0.0.1:41785,DS-8fd5f5b3-1670-4c38-9e76-c8747046b7cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1887285141-172.17.0.10-1598183847400:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34567,DS-407c2516-d116-452f-a107-0d872ea7e003,DISK], DatanodeInfoWithStorage[127.0.0.1:38482,DS-f09aa4c1-c020-475d-9579-64633119ac04,DISK], DatanodeInfoWithStorage[127.0.0.1:44459,DS-fd7b83cd-ab6a-4b94-bbc2-012c944c10ca,DISK], DatanodeInfoWithStorage[127.0.0.1:36021,DS-0605e661-4aa6-48ee-b7ac-6431eac7f23f,DISK], DatanodeInfoWithStorage[127.0.0.1:46194,DS-a61cdcc0-8254-436c-a188-749fbdd3d68b,DISK], DatanodeInfoWithStorage[127.0.0.1:37127,DS-53d005ad-ff79-4cf8-ba0d-e35811aa69ae,DISK], DatanodeInfoWithStorage[127.0.0.1:46796,DS-efc82036-6273-43f4-9581-e1a87698b25a,DISK], DatanodeInfoWithStorage[127.0.0.1:41785,DS-8fd5f5b3-1670-4c38-9e76-c8747046b7cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-214966793-172.17.0.10-1598184828972:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44349,DS-b7079f9c-a928-46ad-abcc-803eb76ad894,DISK], DatanodeInfoWithStorage[127.0.0.1:34322,DS-145b4577-d0fe-44ee-b8da-0f5a380f401f,DISK], DatanodeInfoWithStorage[127.0.0.1:38106,DS-90805735-567f-4b49-91f7-c7d1d8dba94d,DISK], DatanodeInfoWithStorage[127.0.0.1:40408,DS-17748114-c8da-43ab-8bec-fe8db0ad53b5,DISK], DatanodeInfoWithStorage[127.0.0.1:45406,DS-584600a7-b188-4b0c-bbed-02e24cf3a421,DISK], DatanodeInfoWithStorage[127.0.0.1:40657,DS-1525a646-8310-4756-b562-915060fd9cf9,DISK], DatanodeInfoWithStorage[127.0.0.1:40315,DS-c582eb8c-4480-4ec3-8f4d-2c384c01828a,DISK], DatanodeInfoWithStorage[127.0.0.1:41383,DS-9c210bad-ffc5-4dfe-8c6f-9022db98201b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-214966793-172.17.0.10-1598184828972:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44349,DS-b7079f9c-a928-46ad-abcc-803eb76ad894,DISK], DatanodeInfoWithStorage[127.0.0.1:34322,DS-145b4577-d0fe-44ee-b8da-0f5a380f401f,DISK], DatanodeInfoWithStorage[127.0.0.1:38106,DS-90805735-567f-4b49-91f7-c7d1d8dba94d,DISK], DatanodeInfoWithStorage[127.0.0.1:40408,DS-17748114-c8da-43ab-8bec-fe8db0ad53b5,DISK], DatanodeInfoWithStorage[127.0.0.1:45406,DS-584600a7-b188-4b0c-bbed-02e24cf3a421,DISK], DatanodeInfoWithStorage[127.0.0.1:40657,DS-1525a646-8310-4756-b562-915060fd9cf9,DISK], DatanodeInfoWithStorage[127.0.0.1:40315,DS-c582eb8c-4480-4ec3-8f4d-2c384c01828a,DISK], DatanodeInfoWithStorage[127.0.0.1:41383,DS-9c210bad-ffc5-4dfe-8c6f-9022db98201b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1393595651-172.17.0.10-1598185043314:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42089,DS-c2d8350a-b0ac-45f4-a7a0-e8c90b0a1abb,DISK], DatanodeInfoWithStorage[127.0.0.1:34096,DS-b4af9087-ba68-4b0e-9241-28629b97151e,DISK], DatanodeInfoWithStorage[127.0.0.1:45925,DS-25042fd6-ac0d-46a9-9c78-5b80ec7a51e8,DISK], DatanodeInfoWithStorage[127.0.0.1:41639,DS-e9e0eb1f-fd53-4593-8eb7-8add37ae287b,DISK], DatanodeInfoWithStorage[127.0.0.1:45315,DS-6e0d705c-905e-4501-9701-f6af56322a05,DISK], DatanodeInfoWithStorage[127.0.0.1:41637,DS-a0b96762-5079-4204-99b6-8b3208e64c62,DISK], DatanodeInfoWithStorage[127.0.0.1:34532,DS-f152e3c2-d047-41b8-8cd0-e7b6e38609c3,DISK], DatanodeInfoWithStorage[127.0.0.1:32777,DS-86865bfd-cb2c-434b-a09d-d434a7524c29,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1393595651-172.17.0.10-1598185043314:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42089,DS-c2d8350a-b0ac-45f4-a7a0-e8c90b0a1abb,DISK], DatanodeInfoWithStorage[127.0.0.1:34096,DS-b4af9087-ba68-4b0e-9241-28629b97151e,DISK], DatanodeInfoWithStorage[127.0.0.1:45925,DS-25042fd6-ac0d-46a9-9c78-5b80ec7a51e8,DISK], DatanodeInfoWithStorage[127.0.0.1:41639,DS-e9e0eb1f-fd53-4593-8eb7-8add37ae287b,DISK], DatanodeInfoWithStorage[127.0.0.1:45315,DS-6e0d705c-905e-4501-9701-f6af56322a05,DISK], DatanodeInfoWithStorage[127.0.0.1:41637,DS-a0b96762-5079-4204-99b6-8b3208e64c62,DISK], DatanodeInfoWithStorage[127.0.0.1:34532,DS-f152e3c2-d047-41b8-8cd0-e7b6e38609c3,DISK], DatanodeInfoWithStorage[127.0.0.1:32777,DS-86865bfd-cb2c-434b-a09d-d434a7524c29,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1446662464-172.17.0.10-1598185426606:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34737,DS-51c60933-d441-468c-b583-c4ca88190de1,DISK], DatanodeInfoWithStorage[127.0.0.1:42615,DS-4a767867-a998-49fa-990a-a64109220214,DISK], DatanodeInfoWithStorage[127.0.0.1:33763,DS-cc3fbafa-01aa-4218-9baa-665e45c681a7,DISK], DatanodeInfoWithStorage[127.0.0.1:43229,DS-1aeeeb3a-a174-4a36-ae61-1cebcd9078f1,DISK], DatanodeInfoWithStorage[127.0.0.1:41967,DS-f0d5872a-3e46-417b-9ef1-a0091f61e99c,DISK], DatanodeInfoWithStorage[127.0.0.1:35227,DS-b4265544-9e61-480f-a38b-8691cdeb64a7,DISK], DatanodeInfoWithStorage[127.0.0.1:35260,DS-5dd9b6df-fd5c-475c-895b-f338c2ab84d1,DISK], DatanodeInfoWithStorage[127.0.0.1:34027,DS-de777e72-828a-4162-bc8b-11b756a68008,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1446662464-172.17.0.10-1598185426606:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34737,DS-51c60933-d441-468c-b583-c4ca88190de1,DISK], DatanodeInfoWithStorage[127.0.0.1:42615,DS-4a767867-a998-49fa-990a-a64109220214,DISK], DatanodeInfoWithStorage[127.0.0.1:33763,DS-cc3fbafa-01aa-4218-9baa-665e45c681a7,DISK], DatanodeInfoWithStorage[127.0.0.1:43229,DS-1aeeeb3a-a174-4a36-ae61-1cebcd9078f1,DISK], DatanodeInfoWithStorage[127.0.0.1:41967,DS-f0d5872a-3e46-417b-9ef1-a0091f61e99c,DISK], DatanodeInfoWithStorage[127.0.0.1:35227,DS-b4265544-9e61-480f-a38b-8691cdeb64a7,DISK], DatanodeInfoWithStorage[127.0.0.1:35260,DS-5dd9b6df-fd5c-475c-895b-f338c2ab84d1,DISK], DatanodeInfoWithStorage[127.0.0.1:34027,DS-de777e72-828a-4162-bc8b-11b756a68008,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-531442740-172.17.0.10-1598185467836:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34014,DS-1a3261cd-a7c3-4d11-92a1-1b57337786e7,DISK], DatanodeInfoWithStorage[127.0.0.1:34846,DS-52bd1eec-3c7b-433a-b482-7102a409a1ca,DISK], DatanodeInfoWithStorage[127.0.0.1:39224,DS-02fa72e1-956c-4b8f-a116-c2f6cca535d7,DISK], DatanodeInfoWithStorage[127.0.0.1:45554,DS-6369af99-b51f-4b9c-8940-7497f694974a,DISK], DatanodeInfoWithStorage[127.0.0.1:35854,DS-acdbd16d-4f74-403e-bd4b-85dba46af629,DISK], DatanodeInfoWithStorage[127.0.0.1:41107,DS-51af9049-e1a1-4807-a858-a34d65a53791,DISK], DatanodeInfoWithStorage[127.0.0.1:43451,DS-b4fc0821-375a-4be6-ab88-b5241b88659d,DISK], DatanodeInfoWithStorage[127.0.0.1:35584,DS-65f6cb96-5341-423f-a028-f95ac2d1bad5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-531442740-172.17.0.10-1598185467836:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34014,DS-1a3261cd-a7c3-4d11-92a1-1b57337786e7,DISK], DatanodeInfoWithStorage[127.0.0.1:34846,DS-52bd1eec-3c7b-433a-b482-7102a409a1ca,DISK], DatanodeInfoWithStorage[127.0.0.1:39224,DS-02fa72e1-956c-4b8f-a116-c2f6cca535d7,DISK], DatanodeInfoWithStorage[127.0.0.1:45554,DS-6369af99-b51f-4b9c-8940-7497f694974a,DISK], DatanodeInfoWithStorage[127.0.0.1:35854,DS-acdbd16d-4f74-403e-bd4b-85dba46af629,DISK], DatanodeInfoWithStorage[127.0.0.1:41107,DS-51af9049-e1a1-4807-a858-a34d65a53791,DISK], DatanodeInfoWithStorage[127.0.0.1:43451,DS-b4fc0821-375a-4be6-ab88-b5241b88659d,DISK], DatanodeInfoWithStorage[127.0.0.1:35584,DS-65f6cb96-5341-423f-a028-f95ac2d1bad5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1104350219-172.17.0.10-1598185826313:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46620,DS-738109e8-8f17-421a-935b-a73340eb50a6,DISK], DatanodeInfoWithStorage[127.0.0.1:45513,DS-4b8cc870-87f2-4a9a-a96b-cf2bd57506f0,DISK], DatanodeInfoWithStorage[127.0.0.1:46221,DS-48865a9e-6321-43f4-a190-60a4f8ab1d50,DISK], DatanodeInfoWithStorage[127.0.0.1:45840,DS-a87b0d9a-2b29-49f4-96e9-1c9a7c3a4dfe,DISK], DatanodeInfoWithStorage[127.0.0.1:35839,DS-797539d5-6009-4079-a44e-113d53de8ef6,DISK], DatanodeInfoWithStorage[127.0.0.1:37656,DS-c67f4283-49cf-4afc-a76f-8cd28353454b,DISK], DatanodeInfoWithStorage[127.0.0.1:44478,DS-367b67e4-c1ba-4ffd-a0c9-c93747d1015a,DISK], DatanodeInfoWithStorage[127.0.0.1:42746,DS-d2bf9d31-9b4c-4e85-8e63-0429c06cfe53,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1104350219-172.17.0.10-1598185826313:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46620,DS-738109e8-8f17-421a-935b-a73340eb50a6,DISK], DatanodeInfoWithStorage[127.0.0.1:45513,DS-4b8cc870-87f2-4a9a-a96b-cf2bd57506f0,DISK], DatanodeInfoWithStorage[127.0.0.1:46221,DS-48865a9e-6321-43f4-a190-60a4f8ab1d50,DISK], DatanodeInfoWithStorage[127.0.0.1:45840,DS-a87b0d9a-2b29-49f4-96e9-1c9a7c3a4dfe,DISK], DatanodeInfoWithStorage[127.0.0.1:35839,DS-797539d5-6009-4079-a44e-113d53de8ef6,DISK], DatanodeInfoWithStorage[127.0.0.1:37656,DS-c67f4283-49cf-4afc-a76f-8cd28353454b,DISK], DatanodeInfoWithStorage[127.0.0.1:44478,DS-367b67e4-c1ba-4ffd-a0c9-c93747d1015a,DISK], DatanodeInfoWithStorage[127.0.0.1:42746,DS-d2bf9d31-9b4c-4e85-8e63-0429c06cfe53,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-891816253-172.17.0.10-1598185942053:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41401,DS-40e98680-2b61-4ff6-b67a-85aecebca33d,DISK], DatanodeInfoWithStorage[127.0.0.1:44869,DS-95a6a7dc-aafb-48d7-bc6b-0cfbb059b947,DISK], DatanodeInfoWithStorage[127.0.0.1:46041,DS-3edb8a4e-2491-41f3-8172-8ae62507e598,DISK], DatanodeInfoWithStorage[127.0.0.1:44071,DS-a53bd380-9752-469d-9be4-55e4213c5b8a,DISK], DatanodeInfoWithStorage[127.0.0.1:35698,DS-eda52b9b-6a28-411d-ad27-876dc6c76463,DISK], DatanodeInfoWithStorage[127.0.0.1:39217,DS-0ad99fbb-4bea-42c4-bc1e-4dece67aaf7c,DISK], DatanodeInfoWithStorage[127.0.0.1:40192,DS-a89299f7-e40c-4889-a24a-4c019f76395a,DISK], DatanodeInfoWithStorage[127.0.0.1:45986,DS-8e8e9682-64de-4d97-b2f5-713dc47161a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-891816253-172.17.0.10-1598185942053:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41401,DS-40e98680-2b61-4ff6-b67a-85aecebca33d,DISK], DatanodeInfoWithStorage[127.0.0.1:44869,DS-95a6a7dc-aafb-48d7-bc6b-0cfbb059b947,DISK], DatanodeInfoWithStorage[127.0.0.1:46041,DS-3edb8a4e-2491-41f3-8172-8ae62507e598,DISK], DatanodeInfoWithStorage[127.0.0.1:44071,DS-a53bd380-9752-469d-9be4-55e4213c5b8a,DISK], DatanodeInfoWithStorage[127.0.0.1:35698,DS-eda52b9b-6a28-411d-ad27-876dc6c76463,DISK], DatanodeInfoWithStorage[127.0.0.1:39217,DS-0ad99fbb-4bea-42c4-bc1e-4dece67aaf7c,DISK], DatanodeInfoWithStorage[127.0.0.1:40192,DS-a89299f7-e40c-4889-a24a-4c019f76395a,DISK], DatanodeInfoWithStorage[127.0.0.1:45986,DS-8e8e9682-64de-4d97-b2f5-713dc47161a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-381259660-172.17.0.10-1598186405822:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44052,DS-b42e0508-e6e2-434d-9130-12a27c49951a,DISK], DatanodeInfoWithStorage[127.0.0.1:41353,DS-fa2c55c8-9f09-472b-ad9a-0478041926b8,DISK], DatanodeInfoWithStorage[127.0.0.1:34898,DS-ced87fe2-fd8d-429f-879e-866026cb7760,DISK], DatanodeInfoWithStorage[127.0.0.1:33500,DS-2c49ff56-a99c-4032-90b7-5e26c14ef1b1,DISK], DatanodeInfoWithStorage[127.0.0.1:43441,DS-bbcecb8c-04c9-479b-ac7d-4a9df1eb8f1d,DISK], DatanodeInfoWithStorage[127.0.0.1:34683,DS-80877955-d19b-43cd-81bd-3d513a555fdc,DISK], DatanodeInfoWithStorage[127.0.0.1:44211,DS-36bdb16b-6699-41c3-8594-c15b60efc9ae,DISK], DatanodeInfoWithStorage[127.0.0.1:33384,DS-f5b6a10c-da9b-43f7-a65a-4cd511ef3411,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-381259660-172.17.0.10-1598186405822:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44052,DS-b42e0508-e6e2-434d-9130-12a27c49951a,DISK], DatanodeInfoWithStorage[127.0.0.1:41353,DS-fa2c55c8-9f09-472b-ad9a-0478041926b8,DISK], DatanodeInfoWithStorage[127.0.0.1:34898,DS-ced87fe2-fd8d-429f-879e-866026cb7760,DISK], DatanodeInfoWithStorage[127.0.0.1:33500,DS-2c49ff56-a99c-4032-90b7-5e26c14ef1b1,DISK], DatanodeInfoWithStorage[127.0.0.1:43441,DS-bbcecb8c-04c9-479b-ac7d-4a9df1eb8f1d,DISK], DatanodeInfoWithStorage[127.0.0.1:34683,DS-80877955-d19b-43cd-81bd-3d513a555fdc,DISK], DatanodeInfoWithStorage[127.0.0.1:44211,DS-36bdb16b-6699-41c3-8594-c15b60efc9ae,DISK], DatanodeInfoWithStorage[127.0.0.1:33384,DS-f5b6a10c-da9b-43f7-a65a-4cd511ef3411,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-876335200-172.17.0.10-1598186602736:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39661,DS-4f847de7-ef9e-4849-a501-684d0f225f3c,DISK], DatanodeInfoWithStorage[127.0.0.1:34542,DS-ab2147b7-1369-4404-ad46-ac13942ce2f4,DISK], DatanodeInfoWithStorage[127.0.0.1:42452,DS-45fb81c0-8336-4497-a9a9-fe884654af52,DISK], DatanodeInfoWithStorage[127.0.0.1:40392,DS-d176eba3-94e0-43d9-bf22-ff050af031d5,DISK], DatanodeInfoWithStorage[127.0.0.1:45677,DS-241a37dd-1561-4ae5-940e-e2eff8ef091c,DISK], DatanodeInfoWithStorage[127.0.0.1:41375,DS-41bd482a-9644-4865-9358-3c2d39f1158e,DISK], DatanodeInfoWithStorage[127.0.0.1:41815,DS-ae660fa3-576e-405e-91e6-682aae8fc387,DISK], DatanodeInfoWithStorage[127.0.0.1:36114,DS-c37c4f64-bbe0-48c1-8c3f-3ca4358c0139,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-876335200-172.17.0.10-1598186602736:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39661,DS-4f847de7-ef9e-4849-a501-684d0f225f3c,DISK], DatanodeInfoWithStorage[127.0.0.1:34542,DS-ab2147b7-1369-4404-ad46-ac13942ce2f4,DISK], DatanodeInfoWithStorage[127.0.0.1:42452,DS-45fb81c0-8336-4497-a9a9-fe884654af52,DISK], DatanodeInfoWithStorage[127.0.0.1:40392,DS-d176eba3-94e0-43d9-bf22-ff050af031d5,DISK], DatanodeInfoWithStorage[127.0.0.1:45677,DS-241a37dd-1561-4ae5-940e-e2eff8ef091c,DISK], DatanodeInfoWithStorage[127.0.0.1:41375,DS-41bd482a-9644-4865-9358-3c2d39f1158e,DISK], DatanodeInfoWithStorage[127.0.0.1:41815,DS-ae660fa3-576e-405e-91e6-682aae8fc387,DISK], DatanodeInfoWithStorage[127.0.0.1:36114,DS-c37c4f64-bbe0-48c1-8c3f-3ca4358c0139,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1587757657-172.17.0.10-1598186876567:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37228,DS-cea05abf-6ce6-41bf-8e33-72a090ee662f,DISK], DatanodeInfoWithStorage[127.0.0.1:38301,DS-4b23ab08-8d50-412d-88d0-765dc4ac9d3b,DISK], DatanodeInfoWithStorage[127.0.0.1:43465,DS-10d612d3-7109-470f-899d-df54d45108c8,DISK], DatanodeInfoWithStorage[127.0.0.1:39929,DS-6c34535f-29f8-46bf-afb9-93e114c8e3a5,DISK], DatanodeInfoWithStorage[127.0.0.1:41277,DS-0f0d324d-f0fb-4bf0-8a9e-8051aacfb5dc,DISK], DatanodeInfoWithStorage[127.0.0.1:35873,DS-898705bb-99d3-4b74-b08a-fdfe462b390f,DISK], DatanodeInfoWithStorage[127.0.0.1:34175,DS-8df991c3-9a1b-4762-887b-63ddd60e13a1,DISK], DatanodeInfoWithStorage[127.0.0.1:43151,DS-b1ee9a44-a68c-4fcb-868e-f202af2c19a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1587757657-172.17.0.10-1598186876567:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37228,DS-cea05abf-6ce6-41bf-8e33-72a090ee662f,DISK], DatanodeInfoWithStorage[127.0.0.1:38301,DS-4b23ab08-8d50-412d-88d0-765dc4ac9d3b,DISK], DatanodeInfoWithStorage[127.0.0.1:43465,DS-10d612d3-7109-470f-899d-df54d45108c8,DISK], DatanodeInfoWithStorage[127.0.0.1:39929,DS-6c34535f-29f8-46bf-afb9-93e114c8e3a5,DISK], DatanodeInfoWithStorage[127.0.0.1:41277,DS-0f0d324d-f0fb-4bf0-8a9e-8051aacfb5dc,DISK], DatanodeInfoWithStorage[127.0.0.1:35873,DS-898705bb-99d3-4b74-b08a-fdfe462b390f,DISK], DatanodeInfoWithStorage[127.0.0.1:34175,DS-8df991c3-9a1b-4762-887b-63ddd60e13a1,DISK], DatanodeInfoWithStorage[127.0.0.1:43151,DS-b1ee9a44-a68c-4fcb-868e-f202af2c19a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1389469793-172.17.0.10-1598186915864:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35010,DS-7d123925-75ac-4935-82dc-60710b8439a3,DISK], DatanodeInfoWithStorage[127.0.0.1:39862,DS-2980d904-a716-4c91-8bde-97d09d8f9ab5,DISK], DatanodeInfoWithStorage[127.0.0.1:42793,DS-ed07c442-eac0-4277-b191-df2d9e184a67,DISK], DatanodeInfoWithStorage[127.0.0.1:33735,DS-bebcb645-d880-44ab-a15e-7007a0b2cfe2,DISK], DatanodeInfoWithStorage[127.0.0.1:45588,DS-54255d7a-b9c7-4a56-8043-90c66ba9dce6,DISK], DatanodeInfoWithStorage[127.0.0.1:34962,DS-13c174f1-fda4-430f-86f0-ed6048d1da25,DISK], DatanodeInfoWithStorage[127.0.0.1:33769,DS-62074f8a-c0aa-484e-8c86-fbf96e3a4305,DISK], DatanodeInfoWithStorage[127.0.0.1:44507,DS-0e0cec1c-1414-4d15-9318-9872e662efb3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1389469793-172.17.0.10-1598186915864:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35010,DS-7d123925-75ac-4935-82dc-60710b8439a3,DISK], DatanodeInfoWithStorage[127.0.0.1:39862,DS-2980d904-a716-4c91-8bde-97d09d8f9ab5,DISK], DatanodeInfoWithStorage[127.0.0.1:42793,DS-ed07c442-eac0-4277-b191-df2d9e184a67,DISK], DatanodeInfoWithStorage[127.0.0.1:33735,DS-bebcb645-d880-44ab-a15e-7007a0b2cfe2,DISK], DatanodeInfoWithStorage[127.0.0.1:45588,DS-54255d7a-b9c7-4a56-8043-90c66ba9dce6,DISK], DatanodeInfoWithStorage[127.0.0.1:34962,DS-13c174f1-fda4-430f-86f0-ed6048d1da25,DISK], DatanodeInfoWithStorage[127.0.0.1:33769,DS-62074f8a-c0aa-484e-8c86-fbf96e3a4305,DISK], DatanodeInfoWithStorage[127.0.0.1:44507,DS-0e0cec1c-1414-4d15-9318-9872e662efb3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1873071507-172.17.0.10-1598187417715:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35608,DS-4f2d00ae-1346-42be-8814-f9d017fc48e0,DISK], DatanodeInfoWithStorage[127.0.0.1:38940,DS-6d6feb82-b9b4-4785-89cf-d76584ff159c,DISK], DatanodeInfoWithStorage[127.0.0.1:46820,DS-f92ae660-688e-448f-9cb7-6d65d7b75759,DISK], DatanodeInfoWithStorage[127.0.0.1:33303,DS-fc619fe6-a58a-416c-a3ab-1cefa471804c,DISK], DatanodeInfoWithStorage[127.0.0.1:33393,DS-8b24fc0c-d0ae-4ba6-889a-f17436450636,DISK], DatanodeInfoWithStorage[127.0.0.1:39465,DS-a2751757-78be-491f-9f4e-4a65d9ba19d4,DISK], DatanodeInfoWithStorage[127.0.0.1:40116,DS-77207c88-8e26-4d6d-9b9b-71ee51143b53,DISK], DatanodeInfoWithStorage[127.0.0.1:44168,DS-10522a93-99a8-4e39-86de-8b6f1858bc48,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1873071507-172.17.0.10-1598187417715:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35608,DS-4f2d00ae-1346-42be-8814-f9d017fc48e0,DISK], DatanodeInfoWithStorage[127.0.0.1:38940,DS-6d6feb82-b9b4-4785-89cf-d76584ff159c,DISK], DatanodeInfoWithStorage[127.0.0.1:46820,DS-f92ae660-688e-448f-9cb7-6d65d7b75759,DISK], DatanodeInfoWithStorage[127.0.0.1:33303,DS-fc619fe6-a58a-416c-a3ab-1cefa471804c,DISK], DatanodeInfoWithStorage[127.0.0.1:33393,DS-8b24fc0c-d0ae-4ba6-889a-f17436450636,DISK], DatanodeInfoWithStorage[127.0.0.1:39465,DS-a2751757-78be-491f-9f4e-4a65d9ba19d4,DISK], DatanodeInfoWithStorage[127.0.0.1:40116,DS-77207c88-8e26-4d6d-9b9b-71ee51143b53,DISK], DatanodeInfoWithStorage[127.0.0.1:44168,DS-10522a93-99a8-4e39-86de-8b6f1858bc48,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-799135099-172.17.0.10-1598187559538:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35135,DS-520fb7a4-a716-41f6-b205-7dab4cc5e228,DISK], DatanodeInfoWithStorage[127.0.0.1:44909,DS-588154cf-b0e8-47d8-9e7f-d773f985b4a0,DISK], DatanodeInfoWithStorage[127.0.0.1:42964,DS-567593ec-998a-471e-9a2b-b87038285c9f,DISK], DatanodeInfoWithStorage[127.0.0.1:44115,DS-ad08d658-e256-4942-81b1-5a381d14df07,DISK], DatanodeInfoWithStorage[127.0.0.1:40321,DS-5f4fa4da-296e-42c7-bff1-fc551e00ce05,DISK], DatanodeInfoWithStorage[127.0.0.1:35964,DS-52e2f914-d8ae-444f-a8f5-f34e9e7daccf,DISK], DatanodeInfoWithStorage[127.0.0.1:43059,DS-0f2b018a-cfb8-4e5b-9199-2e741bf7df93,DISK], DatanodeInfoWithStorage[127.0.0.1:43574,DS-21fce13a-22b5-4247-be36-f3adbb12e311,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-799135099-172.17.0.10-1598187559538:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35135,DS-520fb7a4-a716-41f6-b205-7dab4cc5e228,DISK], DatanodeInfoWithStorage[127.0.0.1:44909,DS-588154cf-b0e8-47d8-9e7f-d773f985b4a0,DISK], DatanodeInfoWithStorage[127.0.0.1:42964,DS-567593ec-998a-471e-9a2b-b87038285c9f,DISK], DatanodeInfoWithStorage[127.0.0.1:44115,DS-ad08d658-e256-4942-81b1-5a381d14df07,DISK], DatanodeInfoWithStorage[127.0.0.1:40321,DS-5f4fa4da-296e-42c7-bff1-fc551e00ce05,DISK], DatanodeInfoWithStorage[127.0.0.1:35964,DS-52e2f914-d8ae-444f-a8f5-f34e9e7daccf,DISK], DatanodeInfoWithStorage[127.0.0.1:43059,DS-0f2b018a-cfb8-4e5b-9199-2e741bf7df93,DISK], DatanodeInfoWithStorage[127.0.0.1:43574,DS-21fce13a-22b5-4247-be36-f3adbb12e311,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1518170025-172.17.0.10-1598188426454:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33978,DS-89fa1993-64bf-4120-9841-66c3f863e063,DISK], DatanodeInfoWithStorage[127.0.0.1:46368,DS-ee453146-9d50-4085-b0ac-bebbf86d685d,DISK], DatanodeInfoWithStorage[127.0.0.1:35579,DS-d9ec054a-090f-4bfa-bd8d-297ab5a990eb,DISK], DatanodeInfoWithStorage[127.0.0.1:40276,DS-21d04c29-04d4-409e-bb18-ede47132932e,DISK], DatanodeInfoWithStorage[127.0.0.1:42249,DS-955930a2-c521-4495-adc3-08c627673829,DISK], DatanodeInfoWithStorage[127.0.0.1:43730,DS-5865ceab-ce2d-41c1-89c6-b267157819d8,DISK], DatanodeInfoWithStorage[127.0.0.1:41197,DS-e6fd557b-4fa2-4ecd-bcc2-270be39d6be6,DISK], DatanodeInfoWithStorage[127.0.0.1:40929,DS-fbcfa075-c6b8-44ce-9781-6715993e61d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1518170025-172.17.0.10-1598188426454:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33978,DS-89fa1993-64bf-4120-9841-66c3f863e063,DISK], DatanodeInfoWithStorage[127.0.0.1:46368,DS-ee453146-9d50-4085-b0ac-bebbf86d685d,DISK], DatanodeInfoWithStorage[127.0.0.1:35579,DS-d9ec054a-090f-4bfa-bd8d-297ab5a990eb,DISK], DatanodeInfoWithStorage[127.0.0.1:40276,DS-21d04c29-04d4-409e-bb18-ede47132932e,DISK], DatanodeInfoWithStorage[127.0.0.1:42249,DS-955930a2-c521-4495-adc3-08c627673829,DISK], DatanodeInfoWithStorage[127.0.0.1:43730,DS-5865ceab-ce2d-41c1-89c6-b267157819d8,DISK], DatanodeInfoWithStorage[127.0.0.1:41197,DS-e6fd557b-4fa2-4ecd-bcc2-270be39d6be6,DISK], DatanodeInfoWithStorage[127.0.0.1:40929,DS-fbcfa075-c6b8-44ce-9781-6715993e61d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 6476
