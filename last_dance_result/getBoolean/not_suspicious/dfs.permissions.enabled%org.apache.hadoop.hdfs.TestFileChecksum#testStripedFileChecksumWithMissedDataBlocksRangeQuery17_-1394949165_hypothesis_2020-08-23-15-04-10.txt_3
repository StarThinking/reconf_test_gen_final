reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-460940752-172.17.0.15-1598195622024:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33478,DS-5846b0b9-8035-4294-a29c-aa2d613529b2,DISK], DatanodeInfoWithStorage[127.0.0.1:39808,DS-f6502aea-e701-400e-9471-bd703b50a0ae,DISK], DatanodeInfoWithStorage[127.0.0.1:45781,DS-504edf34-bcb5-485f-9fc8-b2a656149845,DISK], DatanodeInfoWithStorage[127.0.0.1:40661,DS-3e5917c9-4b2d-4e6c-ab49-0c5f8ee06507,DISK], DatanodeInfoWithStorage[127.0.0.1:32867,DS-83707ccc-72b4-42da-82ca-e45734fdacad,DISK], DatanodeInfoWithStorage[127.0.0.1:43295,DS-bb9c9ea3-9c81-4c17-862d-4f726a66eab6,DISK], DatanodeInfoWithStorage[127.0.0.1:39233,DS-def8154d-dd67-4707-be2a-6f9e24dbd129,DISK], DatanodeInfoWithStorage[127.0.0.1:38028,DS-704e7f44-235b-4c0a-b8bf-3306b2082788,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-460940752-172.17.0.15-1598195622024:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33478,DS-5846b0b9-8035-4294-a29c-aa2d613529b2,DISK], DatanodeInfoWithStorage[127.0.0.1:39808,DS-f6502aea-e701-400e-9471-bd703b50a0ae,DISK], DatanodeInfoWithStorage[127.0.0.1:45781,DS-504edf34-bcb5-485f-9fc8-b2a656149845,DISK], DatanodeInfoWithStorage[127.0.0.1:40661,DS-3e5917c9-4b2d-4e6c-ab49-0c5f8ee06507,DISK], DatanodeInfoWithStorage[127.0.0.1:32867,DS-83707ccc-72b4-42da-82ca-e45734fdacad,DISK], DatanodeInfoWithStorage[127.0.0.1:43295,DS-bb9c9ea3-9c81-4c17-862d-4f726a66eab6,DISK], DatanodeInfoWithStorage[127.0.0.1:39233,DS-def8154d-dd67-4707-be2a-6f9e24dbd129,DISK], DatanodeInfoWithStorage[127.0.0.1:38028,DS-704e7f44-235b-4c0a-b8bf-3306b2082788,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1498707125-172.17.0.15-1598195758246:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35334,DS-7eb6cece-b6ef-45e6-8f56-a554fc4713a6,DISK], DatanodeInfoWithStorage[127.0.0.1:32805,DS-62e3363a-a28d-478a-b826-16ba6711f337,DISK], DatanodeInfoWithStorage[127.0.0.1:37898,DS-8f8da7ba-e8f7-426a-88bb-bcaf60f19cda,DISK], DatanodeInfoWithStorage[127.0.0.1:36560,DS-d04bdde5-5df9-4265-ba0a-b1b84ab4a314,DISK], DatanodeInfoWithStorage[127.0.0.1:46817,DS-abaf118b-6dda-4904-8764-c1a1538745c8,DISK], DatanodeInfoWithStorage[127.0.0.1:44798,DS-1aa5e5fd-f590-4e95-a1ff-3a19ba11d2e4,DISK], DatanodeInfoWithStorage[127.0.0.1:40412,DS-5514b52c-14ac-422f-9ca8-a357f77a8f80,DISK], DatanodeInfoWithStorage[127.0.0.1:43458,DS-fd9aab71-20df-4c0d-a301-c5a7ac27d21b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1498707125-172.17.0.15-1598195758246:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35334,DS-7eb6cece-b6ef-45e6-8f56-a554fc4713a6,DISK], DatanodeInfoWithStorage[127.0.0.1:32805,DS-62e3363a-a28d-478a-b826-16ba6711f337,DISK], DatanodeInfoWithStorage[127.0.0.1:37898,DS-8f8da7ba-e8f7-426a-88bb-bcaf60f19cda,DISK], DatanodeInfoWithStorage[127.0.0.1:36560,DS-d04bdde5-5df9-4265-ba0a-b1b84ab4a314,DISK], DatanodeInfoWithStorage[127.0.0.1:46817,DS-abaf118b-6dda-4904-8764-c1a1538745c8,DISK], DatanodeInfoWithStorage[127.0.0.1:44798,DS-1aa5e5fd-f590-4e95-a1ff-3a19ba11d2e4,DISK], DatanodeInfoWithStorage[127.0.0.1:40412,DS-5514b52c-14ac-422f-9ca8-a357f77a8f80,DISK], DatanodeInfoWithStorage[127.0.0.1:43458,DS-fd9aab71-20df-4c0d-a301-c5a7ac27d21b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1353000099-172.17.0.15-1598195789253:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44144,DS-624ec92f-9fb6-40b5-9216-1581fece9abe,DISK], DatanodeInfoWithStorage[127.0.0.1:44464,DS-70f36448-25c6-49ea-bdcf-ccdc4e18a9a0,DISK], DatanodeInfoWithStorage[127.0.0.1:33787,DS-454b1542-9d4b-4fe9-83a2-acb3ca25ac2c,DISK], DatanodeInfoWithStorage[127.0.0.1:40241,DS-7d0697cf-14b3-4242-83bb-d878af89710a,DISK], DatanodeInfoWithStorage[127.0.0.1:46527,DS-e7af6450-cbac-4843-8c59-e6829f0441ed,DISK], DatanodeInfoWithStorage[127.0.0.1:44975,DS-a545a84a-bce6-4263-a324-e0b0043ea0d2,DISK], DatanodeInfoWithStorage[127.0.0.1:36632,DS-ee5fe92c-93cc-4ebb-b487-6944f12aee7a,DISK], DatanodeInfoWithStorage[127.0.0.1:40319,DS-fd5f6f58-cae9-4745-899f-fae8360dab63,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1353000099-172.17.0.15-1598195789253:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44144,DS-624ec92f-9fb6-40b5-9216-1581fece9abe,DISK], DatanodeInfoWithStorage[127.0.0.1:44464,DS-70f36448-25c6-49ea-bdcf-ccdc4e18a9a0,DISK], DatanodeInfoWithStorage[127.0.0.1:33787,DS-454b1542-9d4b-4fe9-83a2-acb3ca25ac2c,DISK], DatanodeInfoWithStorage[127.0.0.1:40241,DS-7d0697cf-14b3-4242-83bb-d878af89710a,DISK], DatanodeInfoWithStorage[127.0.0.1:46527,DS-e7af6450-cbac-4843-8c59-e6829f0441ed,DISK], DatanodeInfoWithStorage[127.0.0.1:44975,DS-a545a84a-bce6-4263-a324-e0b0043ea0d2,DISK], DatanodeInfoWithStorage[127.0.0.1:36632,DS-ee5fe92c-93cc-4ebb-b487-6944f12aee7a,DISK], DatanodeInfoWithStorage[127.0.0.1:40319,DS-fd5f6f58-cae9-4745-899f-fae8360dab63,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-95815438-172.17.0.15-1598195890385:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43879,DS-b89e1cad-c6d9-42df-8e70-606f52842868,DISK], DatanodeInfoWithStorage[127.0.0.1:38036,DS-1f1d1220-8325-470b-8929-af599d1a2e33,DISK], DatanodeInfoWithStorage[127.0.0.1:45038,DS-8cdaac59-d63c-4010-90cd-d0c1646aa6ca,DISK], DatanodeInfoWithStorage[127.0.0.1:44955,DS-33c316cb-c98e-4e72-804e-477d5af537f7,DISK], DatanodeInfoWithStorage[127.0.0.1:33127,DS-d74357b1-2de7-40b8-9a04-cc9c215a566f,DISK], DatanodeInfoWithStorage[127.0.0.1:39191,DS-f55ea95a-ea2e-45b8-952c-6ba5fa092596,DISK], DatanodeInfoWithStorage[127.0.0.1:37748,DS-8f378266-f7c4-4d5c-bb77-26cdcc456a00,DISK], DatanodeInfoWithStorage[127.0.0.1:40411,DS-bc8f62f2-805a-4f6b-ab1b-fe92affec79d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-95815438-172.17.0.15-1598195890385:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43879,DS-b89e1cad-c6d9-42df-8e70-606f52842868,DISK], DatanodeInfoWithStorage[127.0.0.1:38036,DS-1f1d1220-8325-470b-8929-af599d1a2e33,DISK], DatanodeInfoWithStorage[127.0.0.1:45038,DS-8cdaac59-d63c-4010-90cd-d0c1646aa6ca,DISK], DatanodeInfoWithStorage[127.0.0.1:44955,DS-33c316cb-c98e-4e72-804e-477d5af537f7,DISK], DatanodeInfoWithStorage[127.0.0.1:33127,DS-d74357b1-2de7-40b8-9a04-cc9c215a566f,DISK], DatanodeInfoWithStorage[127.0.0.1:39191,DS-f55ea95a-ea2e-45b8-952c-6ba5fa092596,DISK], DatanodeInfoWithStorage[127.0.0.1:37748,DS-8f378266-f7c4-4d5c-bb77-26cdcc456a00,DISK], DatanodeInfoWithStorage[127.0.0.1:40411,DS-bc8f62f2-805a-4f6b-ab1b-fe92affec79d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1395210022-172.17.0.15-1598196143712:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42751,DS-e52d8992-1cc8-4fa0-a347-74d3798cbd5d,DISK], DatanodeInfoWithStorage[127.0.0.1:40778,DS-c424e5a7-18e3-4643-b7d7-c5658953580d,DISK], DatanodeInfoWithStorage[127.0.0.1:37542,DS-cfa1bc45-ddcb-4c38-a79b-c86dc95017ad,DISK], DatanodeInfoWithStorage[127.0.0.1:45911,DS-bd7746d5-233d-4cd4-b4c5-412933d168f3,DISK], DatanodeInfoWithStorage[127.0.0.1:38245,DS-bf3d4a0f-0f55-48c8-8e6f-3ab117953cbc,DISK], DatanodeInfoWithStorage[127.0.0.1:41583,DS-852d74a3-5077-4b21-a65e-7e55b7224e3e,DISK], DatanodeInfoWithStorage[127.0.0.1:35489,DS-4c507e1b-7561-4366-aba1-82423a54aea3,DISK], DatanodeInfoWithStorage[127.0.0.1:39253,DS-51fdf2ca-654e-4dd4-9eda-57cb901c96ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1395210022-172.17.0.15-1598196143712:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42751,DS-e52d8992-1cc8-4fa0-a347-74d3798cbd5d,DISK], DatanodeInfoWithStorage[127.0.0.1:40778,DS-c424e5a7-18e3-4643-b7d7-c5658953580d,DISK], DatanodeInfoWithStorage[127.0.0.1:37542,DS-cfa1bc45-ddcb-4c38-a79b-c86dc95017ad,DISK], DatanodeInfoWithStorage[127.0.0.1:45911,DS-bd7746d5-233d-4cd4-b4c5-412933d168f3,DISK], DatanodeInfoWithStorage[127.0.0.1:38245,DS-bf3d4a0f-0f55-48c8-8e6f-3ab117953cbc,DISK], DatanodeInfoWithStorage[127.0.0.1:41583,DS-852d74a3-5077-4b21-a65e-7e55b7224e3e,DISK], DatanodeInfoWithStorage[127.0.0.1:35489,DS-4c507e1b-7561-4366-aba1-82423a54aea3,DISK], DatanodeInfoWithStorage[127.0.0.1:39253,DS-51fdf2ca-654e-4dd4-9eda-57cb901c96ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-857612393-172.17.0.15-1598196424667:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34923,DS-094024de-0f43-4415-bd86-80b7938fa228,DISK], DatanodeInfoWithStorage[127.0.0.1:46368,DS-780f07d1-dfdf-4c1c-aa48-89502dbc23dd,DISK], DatanodeInfoWithStorage[127.0.0.1:37501,DS-b38a5a2c-c724-417a-a1cc-202e29d03637,DISK], DatanodeInfoWithStorage[127.0.0.1:44711,DS-315fefe4-6704-4655-841f-95be8f0fcff6,DISK], DatanodeInfoWithStorage[127.0.0.1:36163,DS-36d571f0-2709-4e3e-ad69-1bdf9f9ef38e,DISK], DatanodeInfoWithStorage[127.0.0.1:46795,DS-88f95c2e-ca8b-44c4-9429-a1dedc6bffdf,DISK], DatanodeInfoWithStorage[127.0.0.1:46774,DS-d35f81c4-b7ec-4742-a042-b2c14d6c1925,DISK], DatanodeInfoWithStorage[127.0.0.1:32998,DS-6a917c0a-6f16-496b-9da1-13cfae027d22,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-857612393-172.17.0.15-1598196424667:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34923,DS-094024de-0f43-4415-bd86-80b7938fa228,DISK], DatanodeInfoWithStorage[127.0.0.1:46368,DS-780f07d1-dfdf-4c1c-aa48-89502dbc23dd,DISK], DatanodeInfoWithStorage[127.0.0.1:37501,DS-b38a5a2c-c724-417a-a1cc-202e29d03637,DISK], DatanodeInfoWithStorage[127.0.0.1:44711,DS-315fefe4-6704-4655-841f-95be8f0fcff6,DISK], DatanodeInfoWithStorage[127.0.0.1:36163,DS-36d571f0-2709-4e3e-ad69-1bdf9f9ef38e,DISK], DatanodeInfoWithStorage[127.0.0.1:46795,DS-88f95c2e-ca8b-44c4-9429-a1dedc6bffdf,DISK], DatanodeInfoWithStorage[127.0.0.1:46774,DS-d35f81c4-b7ec-4742-a042-b2c14d6c1925,DISK], DatanodeInfoWithStorage[127.0.0.1:32998,DS-6a917c0a-6f16-496b-9da1-13cfae027d22,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1117621378-172.17.0.15-1598196441375:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35927,DS-25bc7924-cfcf-45b8-92b9-ff55250842d1,DISK], DatanodeInfoWithStorage[127.0.0.1:36841,DS-8c28ca88-5517-4090-978b-908aeedd1d0e,DISK], DatanodeInfoWithStorage[127.0.0.1:43958,DS-9a7ed464-948f-44d7-b9fb-594d041c0ebe,DISK], DatanodeInfoWithStorage[127.0.0.1:44602,DS-b8e453e3-f252-4570-9940-812dbb47fd13,DISK], DatanodeInfoWithStorage[127.0.0.1:33634,DS-b8420673-0208-4f74-be1d-3ae9ae0e7565,DISK], DatanodeInfoWithStorage[127.0.0.1:39841,DS-6147d77c-0c8d-4eb6-8251-ca470f664585,DISK], DatanodeInfoWithStorage[127.0.0.1:35255,DS-22b2f64d-7a31-4d48-b612-c69f2b742858,DISK], DatanodeInfoWithStorage[127.0.0.1:35827,DS-d6842859-b59c-4e03-876f-42ae5e39dd40,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1117621378-172.17.0.15-1598196441375:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35927,DS-25bc7924-cfcf-45b8-92b9-ff55250842d1,DISK], DatanodeInfoWithStorage[127.0.0.1:36841,DS-8c28ca88-5517-4090-978b-908aeedd1d0e,DISK], DatanodeInfoWithStorage[127.0.0.1:43958,DS-9a7ed464-948f-44d7-b9fb-594d041c0ebe,DISK], DatanodeInfoWithStorage[127.0.0.1:44602,DS-b8e453e3-f252-4570-9940-812dbb47fd13,DISK], DatanodeInfoWithStorage[127.0.0.1:33634,DS-b8420673-0208-4f74-be1d-3ae9ae0e7565,DISK], DatanodeInfoWithStorage[127.0.0.1:39841,DS-6147d77c-0c8d-4eb6-8251-ca470f664585,DISK], DatanodeInfoWithStorage[127.0.0.1:35255,DS-22b2f64d-7a31-4d48-b612-c69f2b742858,DISK], DatanodeInfoWithStorage[127.0.0.1:35827,DS-d6842859-b59c-4e03-876f-42ae5e39dd40,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1092879078-172.17.0.15-1598196491255:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36281,DS-2a8271a7-d8cd-48fa-916c-4d201661ebc4,DISK], DatanodeInfoWithStorage[127.0.0.1:37138,DS-edbf5eac-b5de-4502-bb2f-1d9e5715f3cd,DISK], DatanodeInfoWithStorage[127.0.0.1:45306,DS-6002db44-0dd8-4bef-9e21-8a8f98077d6a,DISK], DatanodeInfoWithStorage[127.0.0.1:32838,DS-ceee850e-a32c-4634-999e-953d9874ff44,DISK], DatanodeInfoWithStorage[127.0.0.1:41107,DS-32064ea0-52db-4471-9df1-8f01c9dead66,DISK], DatanodeInfoWithStorage[127.0.0.1:35155,DS-5c06c8cb-11ee-47d6-9718-8c19555d0f2a,DISK], DatanodeInfoWithStorage[127.0.0.1:33329,DS-bc98c397-a6bd-42ee-9e18-e3faa1d3a4ff,DISK], DatanodeInfoWithStorage[127.0.0.1:44970,DS-9ffe1b98-f6d8-4dce-8550-e603fb6a3edc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1092879078-172.17.0.15-1598196491255:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36281,DS-2a8271a7-d8cd-48fa-916c-4d201661ebc4,DISK], DatanodeInfoWithStorage[127.0.0.1:37138,DS-edbf5eac-b5de-4502-bb2f-1d9e5715f3cd,DISK], DatanodeInfoWithStorage[127.0.0.1:45306,DS-6002db44-0dd8-4bef-9e21-8a8f98077d6a,DISK], DatanodeInfoWithStorage[127.0.0.1:32838,DS-ceee850e-a32c-4634-999e-953d9874ff44,DISK], DatanodeInfoWithStorage[127.0.0.1:41107,DS-32064ea0-52db-4471-9df1-8f01c9dead66,DISK], DatanodeInfoWithStorage[127.0.0.1:35155,DS-5c06c8cb-11ee-47d6-9718-8c19555d0f2a,DISK], DatanodeInfoWithStorage[127.0.0.1:33329,DS-bc98c397-a6bd-42ee-9e18-e3faa1d3a4ff,DISK], DatanodeInfoWithStorage[127.0.0.1:44970,DS-9ffe1b98-f6d8-4dce-8550-e603fb6a3edc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-357832540-172.17.0.15-1598196507927:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33931,DS-0f1d5783-6598-46eb-9204-f0c49d727f71,DISK], DatanodeInfoWithStorage[127.0.0.1:34481,DS-34a4caad-ed8f-436e-9694-a534241400dc,DISK], DatanodeInfoWithStorage[127.0.0.1:38401,DS-3476859a-1f65-4499-8a11-a83a504b1c26,DISK], DatanodeInfoWithStorage[127.0.0.1:40371,DS-49f2c922-87d2-4d5b-a34f-4bc95ca95fdc,DISK], DatanodeInfoWithStorage[127.0.0.1:36657,DS-9a658005-5dbd-432a-a6e1-65b1fac77f08,DISK], DatanodeInfoWithStorage[127.0.0.1:37293,DS-9ccc8f44-2455-4895-b54e-6745b14a1df1,DISK], DatanodeInfoWithStorage[127.0.0.1:38058,DS-c9f11340-2c34-47a5-ad9d-b069ba7b64a7,DISK], DatanodeInfoWithStorage[127.0.0.1:46105,DS-e5bf83c0-01bf-4e1d-869d-4e701d52ed39,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-357832540-172.17.0.15-1598196507927:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33931,DS-0f1d5783-6598-46eb-9204-f0c49d727f71,DISK], DatanodeInfoWithStorage[127.0.0.1:34481,DS-34a4caad-ed8f-436e-9694-a534241400dc,DISK], DatanodeInfoWithStorage[127.0.0.1:38401,DS-3476859a-1f65-4499-8a11-a83a504b1c26,DISK], DatanodeInfoWithStorage[127.0.0.1:40371,DS-49f2c922-87d2-4d5b-a34f-4bc95ca95fdc,DISK], DatanodeInfoWithStorage[127.0.0.1:36657,DS-9a658005-5dbd-432a-a6e1-65b1fac77f08,DISK], DatanodeInfoWithStorage[127.0.0.1:37293,DS-9ccc8f44-2455-4895-b54e-6745b14a1df1,DISK], DatanodeInfoWithStorage[127.0.0.1:38058,DS-c9f11340-2c34-47a5-ad9d-b069ba7b64a7,DISK], DatanodeInfoWithStorage[127.0.0.1:46105,DS-e5bf83c0-01bf-4e1d-869d-4e701d52ed39,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1578630703-172.17.0.15-1598196703894:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33867,DS-764f090b-43f1-4274-b8b7-a8ed300ead62,DISK], DatanodeInfoWithStorage[127.0.0.1:42248,DS-2b311663-17a7-4093-b3f6-69f2a83a4c0e,DISK], DatanodeInfoWithStorage[127.0.0.1:43629,DS-b7e5bbc9-3335-42c7-a734-a954bbb7125d,DISK], DatanodeInfoWithStorage[127.0.0.1:37980,DS-d0ec6a03-de00-47bd-acfa-ada7a8a853f9,DISK], DatanodeInfoWithStorage[127.0.0.1:39884,DS-1f2790e7-7581-4109-a5b5-e9e90101b67d,DISK], DatanodeInfoWithStorage[127.0.0.1:34072,DS-3bf4873a-2e40-41ea-a223-1505bb99d40c,DISK], DatanodeInfoWithStorage[127.0.0.1:37477,DS-aba0aa4c-7208-4ac0-90ce-2c86473f0c33,DISK], DatanodeInfoWithStorage[127.0.0.1:36824,DS-cd8633a9-9fe1-4515-a3f8-8a2f1b8ef44f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1578630703-172.17.0.15-1598196703894:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33867,DS-764f090b-43f1-4274-b8b7-a8ed300ead62,DISK], DatanodeInfoWithStorage[127.0.0.1:42248,DS-2b311663-17a7-4093-b3f6-69f2a83a4c0e,DISK], DatanodeInfoWithStorage[127.0.0.1:43629,DS-b7e5bbc9-3335-42c7-a734-a954bbb7125d,DISK], DatanodeInfoWithStorage[127.0.0.1:37980,DS-d0ec6a03-de00-47bd-acfa-ada7a8a853f9,DISK], DatanodeInfoWithStorage[127.0.0.1:39884,DS-1f2790e7-7581-4109-a5b5-e9e90101b67d,DISK], DatanodeInfoWithStorage[127.0.0.1:34072,DS-3bf4873a-2e40-41ea-a223-1505bb99d40c,DISK], DatanodeInfoWithStorage[127.0.0.1:37477,DS-aba0aa4c-7208-4ac0-90ce-2c86473f0c33,DISK], DatanodeInfoWithStorage[127.0.0.1:36824,DS-cd8633a9-9fe1-4515-a3f8-8a2f1b8ef44f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-659758092-172.17.0.15-1598196801338:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36083,DS-a74a7a44-6d6f-4c46-b687-afd3e7c594a5,DISK], DatanodeInfoWithStorage[127.0.0.1:46653,DS-2cdce323-582d-4b1f-923e-bc16d60eaa30,DISK], DatanodeInfoWithStorage[127.0.0.1:33386,DS-24edd65f-ce3c-478a-93bb-154afefcdde2,DISK], DatanodeInfoWithStorage[127.0.0.1:37584,DS-e4dab0a0-cbc2-4b5f-b82b-0394fd96b06a,DISK], DatanodeInfoWithStorage[127.0.0.1:33906,DS-2d1266c3-9f27-42c1-942f-38c29cbd47ef,DISK], DatanodeInfoWithStorage[127.0.0.1:34891,DS-96c3bce3-2dd7-46fb-bf6d-1f7c7cc139b3,DISK], DatanodeInfoWithStorage[127.0.0.1:39707,DS-6b13df2e-3dec-4b7e-8556-278f3842be8f,DISK], DatanodeInfoWithStorage[127.0.0.1:34276,DS-d77ce80e-05c0-481b-bbd8-2f08b4c1a130,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-659758092-172.17.0.15-1598196801338:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36083,DS-a74a7a44-6d6f-4c46-b687-afd3e7c594a5,DISK], DatanodeInfoWithStorage[127.0.0.1:46653,DS-2cdce323-582d-4b1f-923e-bc16d60eaa30,DISK], DatanodeInfoWithStorage[127.0.0.1:33386,DS-24edd65f-ce3c-478a-93bb-154afefcdde2,DISK], DatanodeInfoWithStorage[127.0.0.1:37584,DS-e4dab0a0-cbc2-4b5f-b82b-0394fd96b06a,DISK], DatanodeInfoWithStorage[127.0.0.1:33906,DS-2d1266c3-9f27-42c1-942f-38c29cbd47ef,DISK], DatanodeInfoWithStorage[127.0.0.1:34891,DS-96c3bce3-2dd7-46fb-bf6d-1f7c7cc139b3,DISK], DatanodeInfoWithStorage[127.0.0.1:39707,DS-6b13df2e-3dec-4b7e-8556-278f3842be8f,DISK], DatanodeInfoWithStorage[127.0.0.1:34276,DS-d77ce80e-05c0-481b-bbd8-2f08b4c1a130,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-272931393-172.17.0.15-1598197015493:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35720,DS-d3820cf6-b946-4a27-97f5-12fdb3403c60,DISK], DatanodeInfoWithStorage[127.0.0.1:43688,DS-ac78c813-37e1-47d2-8c58-0f96b4af57ab,DISK], DatanodeInfoWithStorage[127.0.0.1:35457,DS-52774a20-1b70-462c-8cf4-c4d61e78c424,DISK], DatanodeInfoWithStorage[127.0.0.1:43681,DS-9f7d87b1-0572-41ea-b0d8-69f81853ab52,DISK], DatanodeInfoWithStorage[127.0.0.1:45548,DS-fa24107f-28f9-4fdf-98b7-8611da9e0a2c,DISK], DatanodeInfoWithStorage[127.0.0.1:42937,DS-6d8d8a18-dc31-4f0f-a7ba-2bc14e4be6b8,DISK], DatanodeInfoWithStorage[127.0.0.1:39986,DS-6ad8a574-c958-4c65-806b-05f40657d84c,DISK], DatanodeInfoWithStorage[127.0.0.1:36139,DS-0762365f-bb65-48d6-825b-85f70598d5f8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-272931393-172.17.0.15-1598197015493:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35720,DS-d3820cf6-b946-4a27-97f5-12fdb3403c60,DISK], DatanodeInfoWithStorage[127.0.0.1:43688,DS-ac78c813-37e1-47d2-8c58-0f96b4af57ab,DISK], DatanodeInfoWithStorage[127.0.0.1:35457,DS-52774a20-1b70-462c-8cf4-c4d61e78c424,DISK], DatanodeInfoWithStorage[127.0.0.1:43681,DS-9f7d87b1-0572-41ea-b0d8-69f81853ab52,DISK], DatanodeInfoWithStorage[127.0.0.1:45548,DS-fa24107f-28f9-4fdf-98b7-8611da9e0a2c,DISK], DatanodeInfoWithStorage[127.0.0.1:42937,DS-6d8d8a18-dc31-4f0f-a7ba-2bc14e4be6b8,DISK], DatanodeInfoWithStorage[127.0.0.1:39986,DS-6ad8a574-c958-4c65-806b-05f40657d84c,DISK], DatanodeInfoWithStorage[127.0.0.1:36139,DS-0762365f-bb65-48d6-825b-85f70598d5f8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1067045588-172.17.0.15-1598197360269:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40993,DS-c9615319-f436-47da-b985-5b762f9d3e3e,DISK], DatanodeInfoWithStorage[127.0.0.1:37366,DS-c4bbc227-1389-40bc-8b50-59939dd3fe1c,DISK], DatanodeInfoWithStorage[127.0.0.1:39712,DS-5ce70f46-3413-453c-b1f0-48b4fa34848c,DISK], DatanodeInfoWithStorage[127.0.0.1:44351,DS-8c43e387-c7ff-442c-b174-17e059e57f79,DISK], DatanodeInfoWithStorage[127.0.0.1:44791,DS-53ac7783-b3f4-444d-8844-a9fda633d2d5,DISK], DatanodeInfoWithStorage[127.0.0.1:43012,DS-87fcb449-618b-4c30-a930-ea8d229ad4fb,DISK], DatanodeInfoWithStorage[127.0.0.1:39394,DS-5890cc9b-424f-4875-b85f-f0523aad7bb4,DISK], DatanodeInfoWithStorage[127.0.0.1:42485,DS-69a37aaf-82c4-493d-a278-7280c4d488da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1067045588-172.17.0.15-1598197360269:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40993,DS-c9615319-f436-47da-b985-5b762f9d3e3e,DISK], DatanodeInfoWithStorage[127.0.0.1:37366,DS-c4bbc227-1389-40bc-8b50-59939dd3fe1c,DISK], DatanodeInfoWithStorage[127.0.0.1:39712,DS-5ce70f46-3413-453c-b1f0-48b4fa34848c,DISK], DatanodeInfoWithStorage[127.0.0.1:44351,DS-8c43e387-c7ff-442c-b174-17e059e57f79,DISK], DatanodeInfoWithStorage[127.0.0.1:44791,DS-53ac7783-b3f4-444d-8844-a9fda633d2d5,DISK], DatanodeInfoWithStorage[127.0.0.1:43012,DS-87fcb449-618b-4c30-a930-ea8d229ad4fb,DISK], DatanodeInfoWithStorage[127.0.0.1:39394,DS-5890cc9b-424f-4875-b85f-f0523aad7bb4,DISK], DatanodeInfoWithStorage[127.0.0.1:42485,DS-69a37aaf-82c4-493d-a278-7280c4d488da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2065263021-172.17.0.15-1598197410389:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37376,DS-95f66c31-0aa8-4177-b35d-3482d66994d8,DISK], DatanodeInfoWithStorage[127.0.0.1:37808,DS-809f4d01-a680-400c-b73b-ed8ce2b1fcd7,DISK], DatanodeInfoWithStorage[127.0.0.1:35442,DS-f4a8e981-0ff7-468c-80be-824e07856a33,DISK], DatanodeInfoWithStorage[127.0.0.1:44753,DS-930f5cbc-480f-47a6-9ff4-3782d44b52eb,DISK], DatanodeInfoWithStorage[127.0.0.1:36528,DS-3aa39c25-754e-46c7-9ec2-83ea8a6a64af,DISK], DatanodeInfoWithStorage[127.0.0.1:40180,DS-77486858-40fa-47f0-a30d-7c14dc66061e,DISK], DatanodeInfoWithStorage[127.0.0.1:46269,DS-ad909ca0-2c95-470c-8509-2f0c2270a8fe,DISK], DatanodeInfoWithStorage[127.0.0.1:45278,DS-46798db0-8443-450a-8815-56281d31f291,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2065263021-172.17.0.15-1598197410389:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37376,DS-95f66c31-0aa8-4177-b35d-3482d66994d8,DISK], DatanodeInfoWithStorage[127.0.0.1:37808,DS-809f4d01-a680-400c-b73b-ed8ce2b1fcd7,DISK], DatanodeInfoWithStorage[127.0.0.1:35442,DS-f4a8e981-0ff7-468c-80be-824e07856a33,DISK], DatanodeInfoWithStorage[127.0.0.1:44753,DS-930f5cbc-480f-47a6-9ff4-3782d44b52eb,DISK], DatanodeInfoWithStorage[127.0.0.1:36528,DS-3aa39c25-754e-46c7-9ec2-83ea8a6a64af,DISK], DatanodeInfoWithStorage[127.0.0.1:40180,DS-77486858-40fa-47f0-a30d-7c14dc66061e,DISK], DatanodeInfoWithStorage[127.0.0.1:46269,DS-ad909ca0-2c95-470c-8509-2f0c2270a8fe,DISK], DatanodeInfoWithStorage[127.0.0.1:45278,DS-46798db0-8443-450a-8815-56281d31f291,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-143325895-172.17.0.15-1598197492782:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37179,DS-54a40ada-0318-44c8-a514-2a944eb5601a,DISK], DatanodeInfoWithStorage[127.0.0.1:36618,DS-979a23a1-0b0e-466b-84a5-f9bc15018bd0,DISK], DatanodeInfoWithStorage[127.0.0.1:34321,DS-37013306-f7cd-4e66-b9a1-f82ac95daf34,DISK], DatanodeInfoWithStorage[127.0.0.1:36145,DS-6821fa01-8b56-4506-ba91-c256e91c1e08,DISK], DatanodeInfoWithStorage[127.0.0.1:42000,DS-860f5651-3b25-4ae9-9d1d-5d32b26e3b79,DISK], DatanodeInfoWithStorage[127.0.0.1:37037,DS-271ed6eb-c145-4cd5-8f73-b587eef8a86f,DISK], DatanodeInfoWithStorage[127.0.0.1:39704,DS-8a410d67-8647-4501-aa5d-1d7461d69d31,DISK], DatanodeInfoWithStorage[127.0.0.1:34305,DS-a9351f43-6812-43a1-8ce6-d6f159f69f42,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-143325895-172.17.0.15-1598197492782:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37179,DS-54a40ada-0318-44c8-a514-2a944eb5601a,DISK], DatanodeInfoWithStorage[127.0.0.1:36618,DS-979a23a1-0b0e-466b-84a5-f9bc15018bd0,DISK], DatanodeInfoWithStorage[127.0.0.1:34321,DS-37013306-f7cd-4e66-b9a1-f82ac95daf34,DISK], DatanodeInfoWithStorage[127.0.0.1:36145,DS-6821fa01-8b56-4506-ba91-c256e91c1e08,DISK], DatanodeInfoWithStorage[127.0.0.1:42000,DS-860f5651-3b25-4ae9-9d1d-5d32b26e3b79,DISK], DatanodeInfoWithStorage[127.0.0.1:37037,DS-271ed6eb-c145-4cd5-8f73-b587eef8a86f,DISK], DatanodeInfoWithStorage[127.0.0.1:39704,DS-8a410d67-8647-4501-aa5d-1d7461d69d31,DISK], DatanodeInfoWithStorage[127.0.0.1:34305,DS-a9351f43-6812-43a1-8ce6-d6f159f69f42,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1377631987-172.17.0.15-1598197541981:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33774,DS-38647098-3850-4d16-8939-6d3017f90e1d,DISK], DatanodeInfoWithStorage[127.0.0.1:40836,DS-11c9b131-3dd1-4a04-a2ae-2f4cbbb0400f,DISK], DatanodeInfoWithStorage[127.0.0.1:39516,DS-c3552a83-a829-43ff-8698-41d7dbca8a19,DISK], DatanodeInfoWithStorage[127.0.0.1:35291,DS-1413fd82-5f21-4f09-bfaf-45414e99f525,DISK], DatanodeInfoWithStorage[127.0.0.1:44477,DS-12c25b0b-950d-4015-b63f-4550afc72f26,DISK], DatanodeInfoWithStorage[127.0.0.1:46646,DS-f58306cb-18a2-4615-92fe-030c7965a7ac,DISK], DatanodeInfoWithStorage[127.0.0.1:42117,DS-eddc5dd1-6beb-41cc-9342-98db9bac8de3,DISK], DatanodeInfoWithStorage[127.0.0.1:42149,DS-655b3a7b-5cd4-4ce4-a3c6-43733696ce2a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1377631987-172.17.0.15-1598197541981:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33774,DS-38647098-3850-4d16-8939-6d3017f90e1d,DISK], DatanodeInfoWithStorage[127.0.0.1:40836,DS-11c9b131-3dd1-4a04-a2ae-2f4cbbb0400f,DISK], DatanodeInfoWithStorage[127.0.0.1:39516,DS-c3552a83-a829-43ff-8698-41d7dbca8a19,DISK], DatanodeInfoWithStorage[127.0.0.1:35291,DS-1413fd82-5f21-4f09-bfaf-45414e99f525,DISK], DatanodeInfoWithStorage[127.0.0.1:44477,DS-12c25b0b-950d-4015-b63f-4550afc72f26,DISK], DatanodeInfoWithStorage[127.0.0.1:46646,DS-f58306cb-18a2-4615-92fe-030c7965a7ac,DISK], DatanodeInfoWithStorage[127.0.0.1:42117,DS-eddc5dd1-6beb-41cc-9342-98db9bac8de3,DISK], DatanodeInfoWithStorage[127.0.0.1:42149,DS-655b3a7b-5cd4-4ce4-a3c6-43733696ce2a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1881936824-172.17.0.15-1598197738988:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42835,DS-ba1e7802-2fb4-463c-bf87-c03e0efc6b83,DISK], DatanodeInfoWithStorage[127.0.0.1:41756,DS-3eb60e6c-4db1-410d-a233-73e625a209ce,DISK], DatanodeInfoWithStorage[127.0.0.1:40708,DS-e48cbeec-b4a5-432a-826f-3e2bf58b1fbb,DISK], DatanodeInfoWithStorage[127.0.0.1:39549,DS-c670618a-ff62-49b6-aed2-3055cfbc2643,DISK], DatanodeInfoWithStorage[127.0.0.1:42784,DS-f8a50ade-e6cf-4796-96fa-94d902e9e68a,DISK], DatanodeInfoWithStorage[127.0.0.1:39052,DS-29132ae1-1969-4870-93c6-983bafd628b3,DISK], DatanodeInfoWithStorage[127.0.0.1:42941,DS-51df2f20-fd02-4c8f-a32f-7b08bc70279e,DISK], DatanodeInfoWithStorage[127.0.0.1:39981,DS-ed519964-34c8-4018-ad13-f20a3a837e2a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1881936824-172.17.0.15-1598197738988:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42835,DS-ba1e7802-2fb4-463c-bf87-c03e0efc6b83,DISK], DatanodeInfoWithStorage[127.0.0.1:41756,DS-3eb60e6c-4db1-410d-a233-73e625a209ce,DISK], DatanodeInfoWithStorage[127.0.0.1:40708,DS-e48cbeec-b4a5-432a-826f-3e2bf58b1fbb,DISK], DatanodeInfoWithStorage[127.0.0.1:39549,DS-c670618a-ff62-49b6-aed2-3055cfbc2643,DISK], DatanodeInfoWithStorage[127.0.0.1:42784,DS-f8a50ade-e6cf-4796-96fa-94d902e9e68a,DISK], DatanodeInfoWithStorage[127.0.0.1:39052,DS-29132ae1-1969-4870-93c6-983bafd628b3,DISK], DatanodeInfoWithStorage[127.0.0.1:42941,DS-51df2f20-fd02-4c8f-a32f-7b08bc70279e,DISK], DatanodeInfoWithStorage[127.0.0.1:39981,DS-ed519964-34c8-4018-ad13-f20a3a837e2a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2018950011-172.17.0.15-1598197771765:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39049,DS-632c8c10-b685-420b-9d0e-65d47fc3729b,DISK], DatanodeInfoWithStorage[127.0.0.1:33702,DS-e017a793-44ec-4d68-9d30-152d75165e9b,DISK], DatanodeInfoWithStorage[127.0.0.1:39942,DS-22c011c1-abe6-48bf-8cfe-20e9da83bb0c,DISK], DatanodeInfoWithStorage[127.0.0.1:40101,DS-926fff3d-abfb-4dcd-8d06-0f2210bac21a,DISK], DatanodeInfoWithStorage[127.0.0.1:33923,DS-44b21408-ae47-4629-9fef-e216b37187f7,DISK], DatanodeInfoWithStorage[127.0.0.1:39910,DS-5bbd99a4-2ebf-48ce-9547-22585a9afc50,DISK], DatanodeInfoWithStorage[127.0.0.1:42692,DS-c9fdc381-f244-4ede-b87b-74a398a4b9fc,DISK], DatanodeInfoWithStorage[127.0.0.1:39735,DS-6b775705-ac73-434a-b3ee-9697728a41ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2018950011-172.17.0.15-1598197771765:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39049,DS-632c8c10-b685-420b-9d0e-65d47fc3729b,DISK], DatanodeInfoWithStorage[127.0.0.1:33702,DS-e017a793-44ec-4d68-9d30-152d75165e9b,DISK], DatanodeInfoWithStorage[127.0.0.1:39942,DS-22c011c1-abe6-48bf-8cfe-20e9da83bb0c,DISK], DatanodeInfoWithStorage[127.0.0.1:40101,DS-926fff3d-abfb-4dcd-8d06-0f2210bac21a,DISK], DatanodeInfoWithStorage[127.0.0.1:33923,DS-44b21408-ae47-4629-9fef-e216b37187f7,DISK], DatanodeInfoWithStorage[127.0.0.1:39910,DS-5bbd99a4-2ebf-48ce-9547-22585a9afc50,DISK], DatanodeInfoWithStorage[127.0.0.1:42692,DS-c9fdc381-f244-4ede-b87b-74a398a4b9fc,DISK], DatanodeInfoWithStorage[127.0.0.1:39735,DS-6b775705-ac73-434a-b3ee-9697728a41ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1519306135-172.17.0.15-1598197788173:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39205,DS-b6c54fd1-80ae-44c6-942c-975bd795d4d3,DISK], DatanodeInfoWithStorage[127.0.0.1:36697,DS-b143b441-6d18-4739-a1b9-2deba50778a8,DISK], DatanodeInfoWithStorage[127.0.0.1:43017,DS-db777359-face-4402-a78c-3eefd85e7909,DISK], DatanodeInfoWithStorage[127.0.0.1:45602,DS-d335c2c6-7e8f-4bf3-b55a-3ebb072cbdd7,DISK], DatanodeInfoWithStorage[127.0.0.1:36415,DS-50333ec1-b33e-43e7-b9a1-4cc36b8e953d,DISK], DatanodeInfoWithStorage[127.0.0.1:34415,DS-5b77989e-97d6-4934-87a0-a49244661102,DISK], DatanodeInfoWithStorage[127.0.0.1:42812,DS-acad1490-4e55-4bb0-ab49-13620f4b4ab1,DISK], DatanodeInfoWithStorage[127.0.0.1:32927,DS-3f7d0db1-4d53-4552-9498-13882f4f164f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1519306135-172.17.0.15-1598197788173:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39205,DS-b6c54fd1-80ae-44c6-942c-975bd795d4d3,DISK], DatanodeInfoWithStorage[127.0.0.1:36697,DS-b143b441-6d18-4739-a1b9-2deba50778a8,DISK], DatanodeInfoWithStorage[127.0.0.1:43017,DS-db777359-face-4402-a78c-3eefd85e7909,DISK], DatanodeInfoWithStorage[127.0.0.1:45602,DS-d335c2c6-7e8f-4bf3-b55a-3ebb072cbdd7,DISK], DatanodeInfoWithStorage[127.0.0.1:36415,DS-50333ec1-b33e-43e7-b9a1-4cc36b8e953d,DISK], DatanodeInfoWithStorage[127.0.0.1:34415,DS-5b77989e-97d6-4934-87a0-a49244661102,DISK], DatanodeInfoWithStorage[127.0.0.1:42812,DS-acad1490-4e55-4bb0-ab49-13620f4b4ab1,DISK], DatanodeInfoWithStorage[127.0.0.1:32927,DS-3f7d0db1-4d53-4552-9498-13882f4f164f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1201200389-172.17.0.15-1598197935733:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38560,DS-c9eb6f90-db04-4ee4-9560-674a0ed4c9d3,DISK], DatanodeInfoWithStorage[127.0.0.1:34127,DS-e921ead5-ed7c-4746-aae9-21463cc3b059,DISK], DatanodeInfoWithStorage[127.0.0.1:34274,DS-2f448a51-18e4-4845-9762-bb220c1c1aa4,DISK], DatanodeInfoWithStorage[127.0.0.1:38958,DS-662d792a-13a6-42a0-afc4-31f593b9b610,DISK], DatanodeInfoWithStorage[127.0.0.1:38672,DS-7ef67066-4dc5-46bc-8989-90335d04bbb9,DISK], DatanodeInfoWithStorage[127.0.0.1:35492,DS-73bce501-c57e-414c-b187-0d3bc109027f,DISK], DatanodeInfoWithStorage[127.0.0.1:36733,DS-bbc6e39d-c9cf-4115-8d91-1fde3b5d994e,DISK], DatanodeInfoWithStorage[127.0.0.1:34593,DS-c0f52716-206e-449f-b26a-7cee5175db74,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1201200389-172.17.0.15-1598197935733:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38560,DS-c9eb6f90-db04-4ee4-9560-674a0ed4c9d3,DISK], DatanodeInfoWithStorage[127.0.0.1:34127,DS-e921ead5-ed7c-4746-aae9-21463cc3b059,DISK], DatanodeInfoWithStorage[127.0.0.1:34274,DS-2f448a51-18e4-4845-9762-bb220c1c1aa4,DISK], DatanodeInfoWithStorage[127.0.0.1:38958,DS-662d792a-13a6-42a0-afc4-31f593b9b610,DISK], DatanodeInfoWithStorage[127.0.0.1:38672,DS-7ef67066-4dc5-46bc-8989-90335d04bbb9,DISK], DatanodeInfoWithStorage[127.0.0.1:35492,DS-73bce501-c57e-414c-b187-0d3bc109027f,DISK], DatanodeInfoWithStorage[127.0.0.1:36733,DS-bbc6e39d-c9cf-4115-8d91-1fde3b5d994e,DISK], DatanodeInfoWithStorage[127.0.0.1:34593,DS-c0f52716-206e-449f-b26a-7cee5175db74,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1228793025-172.17.0.15-1598198017985:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43602,DS-3e7467da-d093-45d4-9505-af3729a1bae0,DISK], DatanodeInfoWithStorage[127.0.0.1:44261,DS-ab815f48-121d-40b3-9880-91d630dcff14,DISK], DatanodeInfoWithStorage[127.0.0.1:33814,DS-b3b1b38a-0752-4893-a841-fb71763d5470,DISK], DatanodeInfoWithStorage[127.0.0.1:34178,DS-4ae4ffac-02a4-4cca-a8a0-1222c6c5764a,DISK], DatanodeInfoWithStorage[127.0.0.1:39344,DS-1e9e5fc6-c98e-45a5-ab03-bde004fa7f5d,DISK], DatanodeInfoWithStorage[127.0.0.1:41389,DS-e05c8b77-ab5a-45c1-8b86-385a72fad155,DISK], DatanodeInfoWithStorage[127.0.0.1:41384,DS-7942fd87-9661-447a-aede-e53954a5c729,DISK], DatanodeInfoWithStorage[127.0.0.1:35454,DS-67826c64-007e-451e-9487-95a7d57e37dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1228793025-172.17.0.15-1598198017985:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43602,DS-3e7467da-d093-45d4-9505-af3729a1bae0,DISK], DatanodeInfoWithStorage[127.0.0.1:44261,DS-ab815f48-121d-40b3-9880-91d630dcff14,DISK], DatanodeInfoWithStorage[127.0.0.1:33814,DS-b3b1b38a-0752-4893-a841-fb71763d5470,DISK], DatanodeInfoWithStorage[127.0.0.1:34178,DS-4ae4ffac-02a4-4cca-a8a0-1222c6c5764a,DISK], DatanodeInfoWithStorage[127.0.0.1:39344,DS-1e9e5fc6-c98e-45a5-ab03-bde004fa7f5d,DISK], DatanodeInfoWithStorage[127.0.0.1:41389,DS-e05c8b77-ab5a-45c1-8b86-385a72fad155,DISK], DatanodeInfoWithStorage[127.0.0.1:41384,DS-7942fd87-9661-447a-aede-e53954a5c729,DISK], DatanodeInfoWithStorage[127.0.0.1:35454,DS-67826c64-007e-451e-9487-95a7d57e37dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 14 out of 50
result: false positive !!!
Total execution time in seconds : 3041
