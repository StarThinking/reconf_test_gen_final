reconf_parameter: dfs.storage.policy.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.storage.policy.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-162696368-172.17.0.17-1598460122001:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33343,DS-63ffabb7-e452-411f-b564-139415fa359c,DISK], DatanodeInfoWithStorage[127.0.0.1:45559,DS-04a7622a-4760-417a-b321-4cb3c4fa59cb,DISK], DatanodeInfoWithStorage[127.0.0.1:42753,DS-f83cbfcb-1bf7-42d9-a0b0-02295041dbe6,DISK], DatanodeInfoWithStorage[127.0.0.1:43537,DS-f632020c-5dbc-418c-8003-e3ac9e1296c0,DISK], DatanodeInfoWithStorage[127.0.0.1:39784,DS-7f59a6b0-1a85-4003-8467-483a48e72497,DISK], DatanodeInfoWithStorage[127.0.0.1:45278,DS-3b49345f-71f6-4cc3-9c57-676b0f90857f,DISK], DatanodeInfoWithStorage[127.0.0.1:38973,DS-c6171fad-c85c-4654-8791-d34e56be6668,DISK], DatanodeInfoWithStorage[127.0.0.1:45239,DS-16eb1603-6d5e-4517-b1cd-a06289cd945e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-162696368-172.17.0.17-1598460122001:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33343,DS-63ffabb7-e452-411f-b564-139415fa359c,DISK], DatanodeInfoWithStorage[127.0.0.1:45559,DS-04a7622a-4760-417a-b321-4cb3c4fa59cb,DISK], DatanodeInfoWithStorage[127.0.0.1:42753,DS-f83cbfcb-1bf7-42d9-a0b0-02295041dbe6,DISK], DatanodeInfoWithStorage[127.0.0.1:43537,DS-f632020c-5dbc-418c-8003-e3ac9e1296c0,DISK], DatanodeInfoWithStorage[127.0.0.1:39784,DS-7f59a6b0-1a85-4003-8467-483a48e72497,DISK], DatanodeInfoWithStorage[127.0.0.1:45278,DS-3b49345f-71f6-4cc3-9c57-676b0f90857f,DISK], DatanodeInfoWithStorage[127.0.0.1:38973,DS-c6171fad-c85c-4654-8791-d34e56be6668,DISK], DatanodeInfoWithStorage[127.0.0.1:45239,DS-16eb1603-6d5e-4517-b1cd-a06289cd945e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.storage.policy.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-48190595-172.17.0.17-1598460616532:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39074,DS-522273c7-5b3f-477e-8165-b7d626c39077,DISK], DatanodeInfoWithStorage[127.0.0.1:39193,DS-d193b500-9df7-4b5b-bbe4-34681a41658b,DISK], DatanodeInfoWithStorage[127.0.0.1:33027,DS-b595aa58-1f3a-491c-b1ae-ed30ef317f70,DISK], DatanodeInfoWithStorage[127.0.0.1:39685,DS-4d096fd9-45ca-436b-a2e0-0dcfbfde7508,DISK], DatanodeInfoWithStorage[127.0.0.1:41175,DS-1e392589-7bdd-4c5c-b308-bf2dbd9b08e3,DISK], DatanodeInfoWithStorage[127.0.0.1:33506,DS-ee24dedf-fe76-4051-b506-0c40a97e490b,DISK], DatanodeInfoWithStorage[127.0.0.1:42230,DS-21194fbb-510f-4753-ac6b-d384d3da4bc9,DISK], DatanodeInfoWithStorage[127.0.0.1:34197,DS-7a3a4417-b7e8-4015-8ef3-b5d437fe73b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-48190595-172.17.0.17-1598460616532:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39074,DS-522273c7-5b3f-477e-8165-b7d626c39077,DISK], DatanodeInfoWithStorage[127.0.0.1:39193,DS-d193b500-9df7-4b5b-bbe4-34681a41658b,DISK], DatanodeInfoWithStorage[127.0.0.1:33027,DS-b595aa58-1f3a-491c-b1ae-ed30ef317f70,DISK], DatanodeInfoWithStorage[127.0.0.1:39685,DS-4d096fd9-45ca-436b-a2e0-0dcfbfde7508,DISK], DatanodeInfoWithStorage[127.0.0.1:41175,DS-1e392589-7bdd-4c5c-b308-bf2dbd9b08e3,DISK], DatanodeInfoWithStorage[127.0.0.1:33506,DS-ee24dedf-fe76-4051-b506-0c40a97e490b,DISK], DatanodeInfoWithStorage[127.0.0.1:42230,DS-21194fbb-510f-4753-ac6b-d384d3da4bc9,DISK], DatanodeInfoWithStorage[127.0.0.1:34197,DS-7a3a4417-b7e8-4015-8ef3-b5d437fe73b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.storage.policy.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1832457477-172.17.0.17-1598460655257:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36653,DS-1e2e51cc-a0d4-472f-8ee2-7e5992ff1546,DISK], DatanodeInfoWithStorage[127.0.0.1:45892,DS-5931bed2-7d3b-4f4b-b111-1c0a38f2804d,DISK], DatanodeInfoWithStorage[127.0.0.1:45149,DS-0c7e121f-2b95-4d7a-9577-e0ebd0a55841,DISK], DatanodeInfoWithStorage[127.0.0.1:40166,DS-1b345643-a39c-4ee4-9de9-846dd6a3af62,DISK], DatanodeInfoWithStorage[127.0.0.1:34131,DS-a5250164-79a2-4554-9082-01ef0bae49d6,DISK], DatanodeInfoWithStorage[127.0.0.1:46750,DS-4fca63b6-afcb-4f99-bca0-86dd411609c8,DISK], DatanodeInfoWithStorage[127.0.0.1:37262,DS-82d53ec9-7c64-43b6-91e7-6bfbf4b422bc,DISK], DatanodeInfoWithStorage[127.0.0.1:42724,DS-7d500ffd-b2a0-4fee-8590-487570449cd1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1832457477-172.17.0.17-1598460655257:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36653,DS-1e2e51cc-a0d4-472f-8ee2-7e5992ff1546,DISK], DatanodeInfoWithStorage[127.0.0.1:45892,DS-5931bed2-7d3b-4f4b-b111-1c0a38f2804d,DISK], DatanodeInfoWithStorage[127.0.0.1:45149,DS-0c7e121f-2b95-4d7a-9577-e0ebd0a55841,DISK], DatanodeInfoWithStorage[127.0.0.1:40166,DS-1b345643-a39c-4ee4-9de9-846dd6a3af62,DISK], DatanodeInfoWithStorage[127.0.0.1:34131,DS-a5250164-79a2-4554-9082-01ef0bae49d6,DISK], DatanodeInfoWithStorage[127.0.0.1:46750,DS-4fca63b6-afcb-4f99-bca0-86dd411609c8,DISK], DatanodeInfoWithStorage[127.0.0.1:37262,DS-82d53ec9-7c64-43b6-91e7-6bfbf4b422bc,DISK], DatanodeInfoWithStorage[127.0.0.1:42724,DS-7d500ffd-b2a0-4fee-8590-487570449cd1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.storage.policy.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-682593970-172.17.0.17-1598460791291:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46365,DS-a47edaf9-57f5-4c13-b75d-68e2e8f76a91,DISK], DatanodeInfoWithStorage[127.0.0.1:40627,DS-7d6c5ff5-8cec-426e-a034-23171a3ff4f7,DISK], DatanodeInfoWithStorage[127.0.0.1:41252,DS-02d16106-7122-46b0-9158-fa7816655a97,DISK], DatanodeInfoWithStorage[127.0.0.1:42707,DS-8155be03-0de4-44dd-a3e1-391f2960ca9f,DISK], DatanodeInfoWithStorage[127.0.0.1:38918,DS-5850b86d-b930-4bc9-8637-ed2ed37e034e,DISK], DatanodeInfoWithStorage[127.0.0.1:40277,DS-91678df6-f124-46e1-885e-cda1af68e0cf,DISK], DatanodeInfoWithStorage[127.0.0.1:39870,DS-0a39b0a0-50fa-4092-8410-b4580f2588bb,DISK], DatanodeInfoWithStorage[127.0.0.1:40591,DS-38a6ee7b-42f8-4bb5-b2dc-2ff4d4f16a7e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-682593970-172.17.0.17-1598460791291:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46365,DS-a47edaf9-57f5-4c13-b75d-68e2e8f76a91,DISK], DatanodeInfoWithStorage[127.0.0.1:40627,DS-7d6c5ff5-8cec-426e-a034-23171a3ff4f7,DISK], DatanodeInfoWithStorage[127.0.0.1:41252,DS-02d16106-7122-46b0-9158-fa7816655a97,DISK], DatanodeInfoWithStorage[127.0.0.1:42707,DS-8155be03-0de4-44dd-a3e1-391f2960ca9f,DISK], DatanodeInfoWithStorage[127.0.0.1:38918,DS-5850b86d-b930-4bc9-8637-ed2ed37e034e,DISK], DatanodeInfoWithStorage[127.0.0.1:40277,DS-91678df6-f124-46e1-885e-cda1af68e0cf,DISK], DatanodeInfoWithStorage[127.0.0.1:39870,DS-0a39b0a0-50fa-4092-8410-b4580f2588bb,DISK], DatanodeInfoWithStorage[127.0.0.1:40591,DS-38a6ee7b-42f8-4bb5-b2dc-2ff4d4f16a7e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.storage.policy.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1329801583-172.17.0.17-1598460825899:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44923,DS-83bc71fc-890f-4559-9b1e-ebd2ffaa607c,DISK], DatanodeInfoWithStorage[127.0.0.1:33270,DS-cec1d3aa-202a-49ed-a157-f1980f9917ce,DISK], DatanodeInfoWithStorage[127.0.0.1:33849,DS-b5467e61-8e68-4f4b-b6f0-3024147bb3bf,DISK], DatanodeInfoWithStorage[127.0.0.1:41741,DS-95d35e79-2b9c-4363-afc6-22be6959b6ab,DISK], DatanodeInfoWithStorage[127.0.0.1:44560,DS-8a8a54e9-e6b8-40d6-9fd7-1c76fe0f6da0,DISK], DatanodeInfoWithStorage[127.0.0.1:38803,DS-59e8d6d6-5858-4041-9584-87b608859085,DISK], DatanodeInfoWithStorage[127.0.0.1:45364,DS-1a5ea94d-2ef1-4e1b-8748-f9a516052fc8,DISK], DatanodeInfoWithStorage[127.0.0.1:41491,DS-95473f8e-d8d1-4721-8197-979087b57398,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1329801583-172.17.0.17-1598460825899:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44923,DS-83bc71fc-890f-4559-9b1e-ebd2ffaa607c,DISK], DatanodeInfoWithStorage[127.0.0.1:33270,DS-cec1d3aa-202a-49ed-a157-f1980f9917ce,DISK], DatanodeInfoWithStorage[127.0.0.1:33849,DS-b5467e61-8e68-4f4b-b6f0-3024147bb3bf,DISK], DatanodeInfoWithStorage[127.0.0.1:41741,DS-95d35e79-2b9c-4363-afc6-22be6959b6ab,DISK], DatanodeInfoWithStorage[127.0.0.1:44560,DS-8a8a54e9-e6b8-40d6-9fd7-1c76fe0f6da0,DISK], DatanodeInfoWithStorage[127.0.0.1:38803,DS-59e8d6d6-5858-4041-9584-87b608859085,DISK], DatanodeInfoWithStorage[127.0.0.1:45364,DS-1a5ea94d-2ef1-4e1b-8748-f9a516052fc8,DISK], DatanodeInfoWithStorage[127.0.0.1:41491,DS-95473f8e-d8d1-4721-8197-979087b57398,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.storage.policy.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-905583198-172.17.0.17-1598461252133:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45922,DS-3770c2e7-ee07-4178-b5bd-4e0dd100c49d,DISK], DatanodeInfoWithStorage[127.0.0.1:44145,DS-58820eca-81fe-4a6f-a0b7-7bd12a06e904,DISK], DatanodeInfoWithStorage[127.0.0.1:33499,DS-be6d7bde-9e66-4a97-8239-849eafd7cc22,DISK], DatanodeInfoWithStorage[127.0.0.1:39772,DS-2e3bc530-a065-4b00-9c9f-c9ca6c9dd94b,DISK], DatanodeInfoWithStorage[127.0.0.1:46601,DS-43b7e73f-e939-4743-a139-14dde1dadac2,DISK], DatanodeInfoWithStorage[127.0.0.1:33622,DS-a4ce2763-5f69-4723-8fce-08d801ec6ee9,DISK], DatanodeInfoWithStorage[127.0.0.1:33928,DS-2f974a72-4ba8-4d82-a77e-8688e4c77ae8,DISK], DatanodeInfoWithStorage[127.0.0.1:40832,DS-4fa2a5de-5857-4348-9b6d-682ae3de13a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-905583198-172.17.0.17-1598461252133:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45922,DS-3770c2e7-ee07-4178-b5bd-4e0dd100c49d,DISK], DatanodeInfoWithStorage[127.0.0.1:44145,DS-58820eca-81fe-4a6f-a0b7-7bd12a06e904,DISK], DatanodeInfoWithStorage[127.0.0.1:33499,DS-be6d7bde-9e66-4a97-8239-849eafd7cc22,DISK], DatanodeInfoWithStorage[127.0.0.1:39772,DS-2e3bc530-a065-4b00-9c9f-c9ca6c9dd94b,DISK], DatanodeInfoWithStorage[127.0.0.1:46601,DS-43b7e73f-e939-4743-a139-14dde1dadac2,DISK], DatanodeInfoWithStorage[127.0.0.1:33622,DS-a4ce2763-5f69-4723-8fce-08d801ec6ee9,DISK], DatanodeInfoWithStorage[127.0.0.1:33928,DS-2f974a72-4ba8-4d82-a77e-8688e4c77ae8,DISK], DatanodeInfoWithStorage[127.0.0.1:40832,DS-4fa2a5de-5857-4348-9b6d-682ae3de13a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.storage.policy.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-588068864-172.17.0.17-1598462042287:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39641,DS-9092d356-58c0-4cfe-861c-e861ee695714,DISK], DatanodeInfoWithStorage[127.0.0.1:35960,DS-bc3248a3-0409-4b07-8099-72a9290efbe9,DISK], DatanodeInfoWithStorage[127.0.0.1:42199,DS-e756f841-fa87-45f1-8295-e3a48959676c,DISK], DatanodeInfoWithStorage[127.0.0.1:40056,DS-e57e881b-70f6-48a7-b302-20a5262d62b6,DISK], DatanodeInfoWithStorage[127.0.0.1:36556,DS-e6831ee3-9c45-4574-ab25-eb2e138d918e,DISK], DatanodeInfoWithStorage[127.0.0.1:34793,DS-7c90a499-be16-47b2-9cbe-d8fb4d0ae5fb,DISK], DatanodeInfoWithStorage[127.0.0.1:37599,DS-49cc067d-3e5f-423c-b33f-5d37f2e44334,DISK], DatanodeInfoWithStorage[127.0.0.1:40879,DS-28080fad-eae9-469c-b395-f8ce5cfefeba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-588068864-172.17.0.17-1598462042287:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39641,DS-9092d356-58c0-4cfe-861c-e861ee695714,DISK], DatanodeInfoWithStorage[127.0.0.1:35960,DS-bc3248a3-0409-4b07-8099-72a9290efbe9,DISK], DatanodeInfoWithStorage[127.0.0.1:42199,DS-e756f841-fa87-45f1-8295-e3a48959676c,DISK], DatanodeInfoWithStorage[127.0.0.1:40056,DS-e57e881b-70f6-48a7-b302-20a5262d62b6,DISK], DatanodeInfoWithStorage[127.0.0.1:36556,DS-e6831ee3-9c45-4574-ab25-eb2e138d918e,DISK], DatanodeInfoWithStorage[127.0.0.1:34793,DS-7c90a499-be16-47b2-9cbe-d8fb4d0ae5fb,DISK], DatanodeInfoWithStorage[127.0.0.1:37599,DS-49cc067d-3e5f-423c-b33f-5d37f2e44334,DISK], DatanodeInfoWithStorage[127.0.0.1:40879,DS-28080fad-eae9-469c-b395-f8ce5cfefeba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.storage.policy.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-639476281-172.17.0.17-1598462988750:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42486,DS-8aa798cc-bb0a-4e9f-9d5c-94f8e5d87a70,DISK], DatanodeInfoWithStorage[127.0.0.1:41654,DS-ddb4e084-a772-409a-845b-d225efbdaac0,DISK], DatanodeInfoWithStorage[127.0.0.1:44697,DS-bcc1836c-d712-4de9-86ec-3bd51aa47903,DISK], DatanodeInfoWithStorage[127.0.0.1:38453,DS-44625c65-77e2-42ca-84ee-df25cf79ceb6,DISK], DatanodeInfoWithStorage[127.0.0.1:33037,DS-9393bbaf-7ce7-4c18-885b-f781c6688ef9,DISK], DatanodeInfoWithStorage[127.0.0.1:38372,DS-59521632-8887-46c9-90dd-abf20b65dcf7,DISK], DatanodeInfoWithStorage[127.0.0.1:42472,DS-92410c95-8b82-481a-bdfc-5369aef6b266,DISK], DatanodeInfoWithStorage[127.0.0.1:38154,DS-6f177d6b-d083-4058-aa03-b8a09dc01392,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-639476281-172.17.0.17-1598462988750:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42486,DS-8aa798cc-bb0a-4e9f-9d5c-94f8e5d87a70,DISK], DatanodeInfoWithStorage[127.0.0.1:41654,DS-ddb4e084-a772-409a-845b-d225efbdaac0,DISK], DatanodeInfoWithStorage[127.0.0.1:44697,DS-bcc1836c-d712-4de9-86ec-3bd51aa47903,DISK], DatanodeInfoWithStorage[127.0.0.1:38453,DS-44625c65-77e2-42ca-84ee-df25cf79ceb6,DISK], DatanodeInfoWithStorage[127.0.0.1:33037,DS-9393bbaf-7ce7-4c18-885b-f781c6688ef9,DISK], DatanodeInfoWithStorage[127.0.0.1:38372,DS-59521632-8887-46c9-90dd-abf20b65dcf7,DISK], DatanodeInfoWithStorage[127.0.0.1:42472,DS-92410c95-8b82-481a-bdfc-5369aef6b266,DISK], DatanodeInfoWithStorage[127.0.0.1:38154,DS-6f177d6b-d083-4058-aa03-b8a09dc01392,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.storage.policy.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-827537778-172.17.0.17-1598463429368:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42369,DS-ef59c32b-5530-4cc1-9efd-bf4e29de79f2,DISK], DatanodeInfoWithStorage[127.0.0.1:45630,DS-fd11f14f-e6e5-43a0-8e63-1aed0e0342ec,DISK], DatanodeInfoWithStorage[127.0.0.1:34305,DS-996512d2-216d-439a-bb76-0285318fd466,DISK], DatanodeInfoWithStorage[127.0.0.1:36569,DS-2eded554-91f6-48ec-9734-8cefa3d76cc0,DISK], DatanodeInfoWithStorage[127.0.0.1:46485,DS-28467047-36d1-4a82-94b9-189a575e0c21,DISK], DatanodeInfoWithStorage[127.0.0.1:37297,DS-cf57e669-55d6-466a-8d27-56864c860f02,DISK], DatanodeInfoWithStorage[127.0.0.1:38172,DS-0dcea41a-b2ee-4236-8fb0-2e7e2529a32c,DISK], DatanodeInfoWithStorage[127.0.0.1:38837,DS-b947a375-cc47-4664-8340-471a831c6854,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-827537778-172.17.0.17-1598463429368:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42369,DS-ef59c32b-5530-4cc1-9efd-bf4e29de79f2,DISK], DatanodeInfoWithStorage[127.0.0.1:45630,DS-fd11f14f-e6e5-43a0-8e63-1aed0e0342ec,DISK], DatanodeInfoWithStorage[127.0.0.1:34305,DS-996512d2-216d-439a-bb76-0285318fd466,DISK], DatanodeInfoWithStorage[127.0.0.1:36569,DS-2eded554-91f6-48ec-9734-8cefa3d76cc0,DISK], DatanodeInfoWithStorage[127.0.0.1:46485,DS-28467047-36d1-4a82-94b9-189a575e0c21,DISK], DatanodeInfoWithStorage[127.0.0.1:37297,DS-cf57e669-55d6-466a-8d27-56864c860f02,DISK], DatanodeInfoWithStorage[127.0.0.1:38172,DS-0dcea41a-b2ee-4236-8fb0-2e7e2529a32c,DISK], DatanodeInfoWithStorage[127.0.0.1:38837,DS-b947a375-cc47-4664-8340-471a831c6854,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.storage.policy.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1192437504-172.17.0.17-1598463610596:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36960,DS-f1f8681c-cf3c-4d0a-b20f-f44bdfdca75d,DISK], DatanodeInfoWithStorage[127.0.0.1:34579,DS-f53a9a39-6c36-409b-a457-1997433bc709,DISK], DatanodeInfoWithStorage[127.0.0.1:43235,DS-7442f320-5241-44be-860e-d51429329218,DISK], DatanodeInfoWithStorage[127.0.0.1:40821,DS-5d619b10-f543-492e-87cc-5034c6472a94,DISK], DatanodeInfoWithStorage[127.0.0.1:43498,DS-da4b225f-692a-421b-bcef-15623057f291,DISK], DatanodeInfoWithStorage[127.0.0.1:41174,DS-5ed4cc55-dd29-4cbc-b189-feacadfdd0d0,DISK], DatanodeInfoWithStorage[127.0.0.1:35053,DS-10d9132f-da95-4f68-9ba4-7ea3937397c3,DISK], DatanodeInfoWithStorage[127.0.0.1:33979,DS-4f66d548-bee9-4969-bd60-3fe9b8004c4d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1192437504-172.17.0.17-1598463610596:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36960,DS-f1f8681c-cf3c-4d0a-b20f-f44bdfdca75d,DISK], DatanodeInfoWithStorage[127.0.0.1:34579,DS-f53a9a39-6c36-409b-a457-1997433bc709,DISK], DatanodeInfoWithStorage[127.0.0.1:43235,DS-7442f320-5241-44be-860e-d51429329218,DISK], DatanodeInfoWithStorage[127.0.0.1:40821,DS-5d619b10-f543-492e-87cc-5034c6472a94,DISK], DatanodeInfoWithStorage[127.0.0.1:43498,DS-da4b225f-692a-421b-bcef-15623057f291,DISK], DatanodeInfoWithStorage[127.0.0.1:41174,DS-5ed4cc55-dd29-4cbc-b189-feacadfdd0d0,DISK], DatanodeInfoWithStorage[127.0.0.1:35053,DS-10d9132f-da95-4f68-9ba4-7ea3937397c3,DISK], DatanodeInfoWithStorage[127.0.0.1:33979,DS-4f66d548-bee9-4969-bd60-3fe9b8004c4d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.storage.policy.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-109564397-172.17.0.17-1598463671482:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41307,DS-7b72a991-193e-4b48-924b-a5c7dcdd515f,DISK], DatanodeInfoWithStorage[127.0.0.1:33192,DS-497f4dd7-fc4e-4851-a016-d6b46786d9ab,DISK], DatanodeInfoWithStorage[127.0.0.1:41777,DS-819752a8-6c62-4ef9-82bd-1f437abb9509,DISK], DatanodeInfoWithStorage[127.0.0.1:37779,DS-0a99658c-9a60-45e3-b3f4-f1098aef9e3c,DISK], DatanodeInfoWithStorage[127.0.0.1:36897,DS-722b8466-756e-43e8-aef3-b42ce5135f8e,DISK], DatanodeInfoWithStorage[127.0.0.1:37410,DS-537e3a00-01e7-47f8-a89b-4a622dfda98d,DISK], DatanodeInfoWithStorage[127.0.0.1:40267,DS-25b29bd1-0b31-4b1e-aeb4-94c5820bdbb7,DISK], DatanodeInfoWithStorage[127.0.0.1:33061,DS-57316d2d-1dee-409f-b5d2-91c4f056b291,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-109564397-172.17.0.17-1598463671482:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41307,DS-7b72a991-193e-4b48-924b-a5c7dcdd515f,DISK], DatanodeInfoWithStorage[127.0.0.1:33192,DS-497f4dd7-fc4e-4851-a016-d6b46786d9ab,DISK], DatanodeInfoWithStorage[127.0.0.1:41777,DS-819752a8-6c62-4ef9-82bd-1f437abb9509,DISK], DatanodeInfoWithStorage[127.0.0.1:37779,DS-0a99658c-9a60-45e3-b3f4-f1098aef9e3c,DISK], DatanodeInfoWithStorage[127.0.0.1:36897,DS-722b8466-756e-43e8-aef3-b42ce5135f8e,DISK], DatanodeInfoWithStorage[127.0.0.1:37410,DS-537e3a00-01e7-47f8-a89b-4a622dfda98d,DISK], DatanodeInfoWithStorage[127.0.0.1:40267,DS-25b29bd1-0b31-4b1e-aeb4-94c5820bdbb7,DISK], DatanodeInfoWithStorage[127.0.0.1:33061,DS-57316d2d-1dee-409f-b5d2-91c4f056b291,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.storage.policy.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-896978170-172.17.0.17-1598463954971:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40829,DS-7a17c754-4b84-4d79-928c-ff99f17e7aaa,DISK], DatanodeInfoWithStorage[127.0.0.1:35940,DS-24972008-1e85-467a-a150-ee44c035d2cb,DISK], DatanodeInfoWithStorage[127.0.0.1:35227,DS-8cc22541-f07b-4030-a64a-1943dce5216c,DISK], DatanodeInfoWithStorage[127.0.0.1:41011,DS-fa38a2cc-3b52-4eb0-b0ac-520daf87ce5f,DISK], DatanodeInfoWithStorage[127.0.0.1:40526,DS-c1491521-1dc2-4e87-8718-0fd6d1fa86db,DISK], DatanodeInfoWithStorage[127.0.0.1:35594,DS-8723194a-960a-4ebc-aa0c-26ff82257529,DISK], DatanodeInfoWithStorage[127.0.0.1:46024,DS-03657264-a96c-4472-96bf-b545a7165366,DISK], DatanodeInfoWithStorage[127.0.0.1:39505,DS-eb44fa31-fc3c-401d-9974-72b7111d776d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-896978170-172.17.0.17-1598463954971:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40829,DS-7a17c754-4b84-4d79-928c-ff99f17e7aaa,DISK], DatanodeInfoWithStorage[127.0.0.1:35940,DS-24972008-1e85-467a-a150-ee44c035d2cb,DISK], DatanodeInfoWithStorage[127.0.0.1:35227,DS-8cc22541-f07b-4030-a64a-1943dce5216c,DISK], DatanodeInfoWithStorage[127.0.0.1:41011,DS-fa38a2cc-3b52-4eb0-b0ac-520daf87ce5f,DISK], DatanodeInfoWithStorage[127.0.0.1:40526,DS-c1491521-1dc2-4e87-8718-0fd6d1fa86db,DISK], DatanodeInfoWithStorage[127.0.0.1:35594,DS-8723194a-960a-4ebc-aa0c-26ff82257529,DISK], DatanodeInfoWithStorage[127.0.0.1:46024,DS-03657264-a96c-4472-96bf-b545a7165366,DISK], DatanodeInfoWithStorage[127.0.0.1:39505,DS-eb44fa31-fc3c-401d-9974-72b7111d776d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.storage.policy.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-311462113-172.17.0.17-1598464162351:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37339,DS-f0f54fc4-2f3c-458a-be64-8d61963edcf4,DISK], DatanodeInfoWithStorage[127.0.0.1:43250,DS-3905d7c9-41d4-4648-b5b7-6a829d074f76,DISK], DatanodeInfoWithStorage[127.0.0.1:34968,DS-f31aa3ca-7ea4-4fd1-aa6b-1cb84c4766a5,DISK], DatanodeInfoWithStorage[127.0.0.1:37086,DS-85f99170-f063-46f9-857f-8ef01bcac020,DISK], DatanodeInfoWithStorage[127.0.0.1:38611,DS-686553e9-c539-4c98-aa96-cfb70f1045e2,DISK], DatanodeInfoWithStorage[127.0.0.1:46824,DS-4c57a856-b2c0-4b03-99bc-cf0c737d3f0a,DISK], DatanodeInfoWithStorage[127.0.0.1:40184,DS-00062012-2774-40b3-92ad-bc308d70cbcc,DISK], DatanodeInfoWithStorage[127.0.0.1:39692,DS-109de0be-e67c-422d-be2b-9489a8da3f75,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-311462113-172.17.0.17-1598464162351:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37339,DS-f0f54fc4-2f3c-458a-be64-8d61963edcf4,DISK], DatanodeInfoWithStorage[127.0.0.1:43250,DS-3905d7c9-41d4-4648-b5b7-6a829d074f76,DISK], DatanodeInfoWithStorage[127.0.0.1:34968,DS-f31aa3ca-7ea4-4fd1-aa6b-1cb84c4766a5,DISK], DatanodeInfoWithStorage[127.0.0.1:37086,DS-85f99170-f063-46f9-857f-8ef01bcac020,DISK], DatanodeInfoWithStorage[127.0.0.1:38611,DS-686553e9-c539-4c98-aa96-cfb70f1045e2,DISK], DatanodeInfoWithStorage[127.0.0.1:46824,DS-4c57a856-b2c0-4b03-99bc-cf0c737d3f0a,DISK], DatanodeInfoWithStorage[127.0.0.1:40184,DS-00062012-2774-40b3-92ad-bc308d70cbcc,DISK], DatanodeInfoWithStorage[127.0.0.1:39692,DS-109de0be-e67c-422d-be2b-9489a8da3f75,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.storage.policy.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1103426549-172.17.0.17-1598464502067:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44725,DS-3674ea26-b8e8-46d8-ac82-fd7df9348d65,DISK], DatanodeInfoWithStorage[127.0.0.1:46254,DS-70a340aa-69ee-4936-a9d2-30125b7427ce,DISK], DatanodeInfoWithStorage[127.0.0.1:43127,DS-e1704842-4ee3-4647-b32c-57e7fe9f9134,DISK], DatanodeInfoWithStorage[127.0.0.1:46046,DS-c3a7e630-9d22-44b8-a087-8718bb9c3faa,DISK], DatanodeInfoWithStorage[127.0.0.1:46440,DS-0b500099-ae08-476c-923a-10afc960e01e,DISK], DatanodeInfoWithStorage[127.0.0.1:45642,DS-2b66358d-393f-4b0b-96d1-0171942ad213,DISK], DatanodeInfoWithStorage[127.0.0.1:34060,DS-f89dca2c-3f88-4895-9c17-d1dbf7e22e7f,DISK], DatanodeInfoWithStorage[127.0.0.1:46826,DS-a2bd691d-82dd-4356-81f5-9dd0599bbbd8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1103426549-172.17.0.17-1598464502067:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44725,DS-3674ea26-b8e8-46d8-ac82-fd7df9348d65,DISK], DatanodeInfoWithStorage[127.0.0.1:46254,DS-70a340aa-69ee-4936-a9d2-30125b7427ce,DISK], DatanodeInfoWithStorage[127.0.0.1:43127,DS-e1704842-4ee3-4647-b32c-57e7fe9f9134,DISK], DatanodeInfoWithStorage[127.0.0.1:46046,DS-c3a7e630-9d22-44b8-a087-8718bb9c3faa,DISK], DatanodeInfoWithStorage[127.0.0.1:46440,DS-0b500099-ae08-476c-923a-10afc960e01e,DISK], DatanodeInfoWithStorage[127.0.0.1:45642,DS-2b66358d-393f-4b0b-96d1-0171942ad213,DISK], DatanodeInfoWithStorage[127.0.0.1:34060,DS-f89dca2c-3f88-4895-9c17-d1dbf7e22e7f,DISK], DatanodeInfoWithStorage[127.0.0.1:46826,DS-a2bd691d-82dd-4356-81f5-9dd0599bbbd8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 4816
