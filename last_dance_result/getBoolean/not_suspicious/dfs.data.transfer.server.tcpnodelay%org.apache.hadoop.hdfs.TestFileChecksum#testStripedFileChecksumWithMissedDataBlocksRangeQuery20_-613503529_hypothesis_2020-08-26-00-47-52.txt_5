reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-447012335-172.17.0.7-1598402918744:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45616,DS-3eed4508-272c-4e7e-beaf-7fd9712df0d2,DISK], DatanodeInfoWithStorage[127.0.0.1:34815,DS-7b14546a-82e1-4e77-8418-5c3945229dff,DISK], DatanodeInfoWithStorage[127.0.0.1:36696,DS-4ede2bd3-550f-422e-ad45-c360a86171d2,DISK], DatanodeInfoWithStorage[127.0.0.1:34555,DS-5b3b2826-1df3-4e26-899e-88af4a3410c2,DISK], DatanodeInfoWithStorage[127.0.0.1:45530,DS-26bc6e3f-d343-47c1-867a-bddcdad68bcb,DISK], DatanodeInfoWithStorage[127.0.0.1:39690,DS-5f37dd3b-6a76-4f05-8b9e-d6d14c2f6130,DISK], DatanodeInfoWithStorage[127.0.0.1:37402,DS-b47ad5e5-9f73-4a78-a455-cc7dd5f9478e,DISK], DatanodeInfoWithStorage[127.0.0.1:37123,DS-3194c9b1-9d38-4809-9e65-5de446f1102c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-447012335-172.17.0.7-1598402918744:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45616,DS-3eed4508-272c-4e7e-beaf-7fd9712df0d2,DISK], DatanodeInfoWithStorage[127.0.0.1:34815,DS-7b14546a-82e1-4e77-8418-5c3945229dff,DISK], DatanodeInfoWithStorage[127.0.0.1:36696,DS-4ede2bd3-550f-422e-ad45-c360a86171d2,DISK], DatanodeInfoWithStorage[127.0.0.1:34555,DS-5b3b2826-1df3-4e26-899e-88af4a3410c2,DISK], DatanodeInfoWithStorage[127.0.0.1:45530,DS-26bc6e3f-d343-47c1-867a-bddcdad68bcb,DISK], DatanodeInfoWithStorage[127.0.0.1:39690,DS-5f37dd3b-6a76-4f05-8b9e-d6d14c2f6130,DISK], DatanodeInfoWithStorage[127.0.0.1:37402,DS-b47ad5e5-9f73-4a78-a455-cc7dd5f9478e,DISK], DatanodeInfoWithStorage[127.0.0.1:37123,DS-3194c9b1-9d38-4809-9e65-5de446f1102c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-285841423-172.17.0.7-1598403153557:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39828,DS-c14c7562-847c-455d-8b75-0a06555a9814,DISK], DatanodeInfoWithStorage[127.0.0.1:43345,DS-ece3c8e5-133e-4bb2-9200-009573fbe974,DISK], DatanodeInfoWithStorage[127.0.0.1:44453,DS-24021b67-b42e-4634-82ca-5f83996180f6,DISK], DatanodeInfoWithStorage[127.0.0.1:34698,DS-c90a0ef0-5fb7-4bc9-8f67-1a78ebba12ff,DISK], DatanodeInfoWithStorage[127.0.0.1:39743,DS-964bde7b-a12c-43a7-a85b-3527c6e9c35f,DISK], DatanodeInfoWithStorage[127.0.0.1:38678,DS-a2032688-f622-4550-bf28-8527905ce264,DISK], DatanodeInfoWithStorage[127.0.0.1:45383,DS-03f74908-4b72-41ed-8474-28cbfc1c0bb2,DISK], DatanodeInfoWithStorage[127.0.0.1:45812,DS-b4ef1261-1bd1-4234-925a-8f760d43840f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-285841423-172.17.0.7-1598403153557:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39828,DS-c14c7562-847c-455d-8b75-0a06555a9814,DISK], DatanodeInfoWithStorage[127.0.0.1:43345,DS-ece3c8e5-133e-4bb2-9200-009573fbe974,DISK], DatanodeInfoWithStorage[127.0.0.1:44453,DS-24021b67-b42e-4634-82ca-5f83996180f6,DISK], DatanodeInfoWithStorage[127.0.0.1:34698,DS-c90a0ef0-5fb7-4bc9-8f67-1a78ebba12ff,DISK], DatanodeInfoWithStorage[127.0.0.1:39743,DS-964bde7b-a12c-43a7-a85b-3527c6e9c35f,DISK], DatanodeInfoWithStorage[127.0.0.1:38678,DS-a2032688-f622-4550-bf28-8527905ce264,DISK], DatanodeInfoWithStorage[127.0.0.1:45383,DS-03f74908-4b72-41ed-8474-28cbfc1c0bb2,DISK], DatanodeInfoWithStorage[127.0.0.1:45812,DS-b4ef1261-1bd1-4234-925a-8f760d43840f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1104694798-172.17.0.7-1598403192748:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41211,DS-85db664e-195c-4246-a99d-ffbf1d634f35,DISK], DatanodeInfoWithStorage[127.0.0.1:45444,DS-f77b7e82-a9e3-4b79-828e-8596afb3b139,DISK], DatanodeInfoWithStorage[127.0.0.1:34908,DS-0f6d245f-0c76-4639-ab0c-05f5a2c391a3,DISK], DatanodeInfoWithStorage[127.0.0.1:36246,DS-ad9933a4-2823-4072-b04c-0d05a6e715ad,DISK], DatanodeInfoWithStorage[127.0.0.1:39279,DS-80cfcfe7-d40b-4ab0-a26b-8429eb52c101,DISK], DatanodeInfoWithStorage[127.0.0.1:46762,DS-0be13757-ead3-4ed9-8f16-b9e54a44c859,DISK], DatanodeInfoWithStorage[127.0.0.1:42979,DS-0abe0922-0d4e-4e31-b690-b1d1d34cdc16,DISK], DatanodeInfoWithStorage[127.0.0.1:34347,DS-9f152d5f-74a4-448f-8e7d-1df01dfd317a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1104694798-172.17.0.7-1598403192748:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41211,DS-85db664e-195c-4246-a99d-ffbf1d634f35,DISK], DatanodeInfoWithStorage[127.0.0.1:45444,DS-f77b7e82-a9e3-4b79-828e-8596afb3b139,DISK], DatanodeInfoWithStorage[127.0.0.1:34908,DS-0f6d245f-0c76-4639-ab0c-05f5a2c391a3,DISK], DatanodeInfoWithStorage[127.0.0.1:36246,DS-ad9933a4-2823-4072-b04c-0d05a6e715ad,DISK], DatanodeInfoWithStorage[127.0.0.1:39279,DS-80cfcfe7-d40b-4ab0-a26b-8429eb52c101,DISK], DatanodeInfoWithStorage[127.0.0.1:46762,DS-0be13757-ead3-4ed9-8f16-b9e54a44c859,DISK], DatanodeInfoWithStorage[127.0.0.1:42979,DS-0abe0922-0d4e-4e31-b690-b1d1d34cdc16,DISK], DatanodeInfoWithStorage[127.0.0.1:34347,DS-9f152d5f-74a4-448f-8e7d-1df01dfd317a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1481969905-172.17.0.7-1598403424986:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42324,DS-41480cc9-26d2-42dc-8dc7-275085ac2e50,DISK], DatanodeInfoWithStorage[127.0.0.1:38745,DS-e86190a4-abec-47d0-abf1-311e6fe23338,DISK], DatanodeInfoWithStorage[127.0.0.1:41611,DS-c65d5a3c-c3af-4c34-982a-7c4b7d711932,DISK], DatanodeInfoWithStorage[127.0.0.1:46177,DS-59fb61f6-5868-4005-9da7-ab8fae2c0dbf,DISK], DatanodeInfoWithStorage[127.0.0.1:46550,DS-30319515-a840-4202-90e3-9deaece47b19,DISK], DatanodeInfoWithStorage[127.0.0.1:35434,DS-7f73bd71-3502-4372-a935-40e012f9c498,DISK], DatanodeInfoWithStorage[127.0.0.1:37729,DS-b0dea22a-5610-40e3-b048-a5d8c8563fbf,DISK], DatanodeInfoWithStorage[127.0.0.1:37265,DS-e2ec8375-38e6-4d1c-b2c5-62b32289def2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1481969905-172.17.0.7-1598403424986:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42324,DS-41480cc9-26d2-42dc-8dc7-275085ac2e50,DISK], DatanodeInfoWithStorage[127.0.0.1:38745,DS-e86190a4-abec-47d0-abf1-311e6fe23338,DISK], DatanodeInfoWithStorage[127.0.0.1:41611,DS-c65d5a3c-c3af-4c34-982a-7c4b7d711932,DISK], DatanodeInfoWithStorage[127.0.0.1:46177,DS-59fb61f6-5868-4005-9da7-ab8fae2c0dbf,DISK], DatanodeInfoWithStorage[127.0.0.1:46550,DS-30319515-a840-4202-90e3-9deaece47b19,DISK], DatanodeInfoWithStorage[127.0.0.1:35434,DS-7f73bd71-3502-4372-a935-40e012f9c498,DISK], DatanodeInfoWithStorage[127.0.0.1:37729,DS-b0dea22a-5610-40e3-b048-a5d8c8563fbf,DISK], DatanodeInfoWithStorage[127.0.0.1:37265,DS-e2ec8375-38e6-4d1c-b2c5-62b32289def2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-320053147-172.17.0.7-1598403499053:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37235,DS-ed265f4a-d80e-4649-868b-b827262d28f9,DISK], DatanodeInfoWithStorage[127.0.0.1:35231,DS-e42b79d7-755e-4aa6-9c1f-4233289e2675,DISK], DatanodeInfoWithStorage[127.0.0.1:45972,DS-b36bd32f-5850-43c8-a094-81a5530fc627,DISK], DatanodeInfoWithStorage[127.0.0.1:41812,DS-c30472e3-aff9-481c-9054-344b200f46bd,DISK], DatanodeInfoWithStorage[127.0.0.1:42243,DS-9928ba87-1141-4b6c-8d25-107f5f822082,DISK], DatanodeInfoWithStorage[127.0.0.1:46582,DS-fb9b7028-b110-4aeb-b16b-b80778417be5,DISK], DatanodeInfoWithStorage[127.0.0.1:36676,DS-f4ef81b9-26ad-4d85-a51a-195c27514e81,DISK], DatanodeInfoWithStorage[127.0.0.1:43567,DS-9697d87d-5061-4775-b7be-dc332b5df013,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-320053147-172.17.0.7-1598403499053:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37235,DS-ed265f4a-d80e-4649-868b-b827262d28f9,DISK], DatanodeInfoWithStorage[127.0.0.1:35231,DS-e42b79d7-755e-4aa6-9c1f-4233289e2675,DISK], DatanodeInfoWithStorage[127.0.0.1:45972,DS-b36bd32f-5850-43c8-a094-81a5530fc627,DISK], DatanodeInfoWithStorage[127.0.0.1:41812,DS-c30472e3-aff9-481c-9054-344b200f46bd,DISK], DatanodeInfoWithStorage[127.0.0.1:42243,DS-9928ba87-1141-4b6c-8d25-107f5f822082,DISK], DatanodeInfoWithStorage[127.0.0.1:46582,DS-fb9b7028-b110-4aeb-b16b-b80778417be5,DISK], DatanodeInfoWithStorage[127.0.0.1:36676,DS-f4ef81b9-26ad-4d85-a51a-195c27514e81,DISK], DatanodeInfoWithStorage[127.0.0.1:43567,DS-9697d87d-5061-4775-b7be-dc332b5df013,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-549363410-172.17.0.7-1598403765447:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46408,DS-079727fc-de9f-46dd-9994-9f96cb564dec,DISK], DatanodeInfoWithStorage[127.0.0.1:34884,DS-72546a2c-b63d-4f63-8bc5-61cd7dd2342e,DISK], DatanodeInfoWithStorage[127.0.0.1:37161,DS-d29ae589-2ab9-4ae4-8bc4-45c11aec144e,DISK], DatanodeInfoWithStorage[127.0.0.1:42151,DS-294504f0-bf0b-4ad9-801e-686513b3b670,DISK], DatanodeInfoWithStorage[127.0.0.1:45704,DS-6b7141bb-c919-4503-80bb-9a04e8160829,DISK], DatanodeInfoWithStorage[127.0.0.1:32796,DS-d54663f3-8548-4de5-9124-a055c462e2bb,DISK], DatanodeInfoWithStorage[127.0.0.1:45993,DS-1e4681b3-a84d-4c76-b8c3-b35ebd48e2b5,DISK], DatanodeInfoWithStorage[127.0.0.1:38889,DS-ea513ad9-b245-433f-99f2-3deca61675aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-549363410-172.17.0.7-1598403765447:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46408,DS-079727fc-de9f-46dd-9994-9f96cb564dec,DISK], DatanodeInfoWithStorage[127.0.0.1:34884,DS-72546a2c-b63d-4f63-8bc5-61cd7dd2342e,DISK], DatanodeInfoWithStorage[127.0.0.1:37161,DS-d29ae589-2ab9-4ae4-8bc4-45c11aec144e,DISK], DatanodeInfoWithStorage[127.0.0.1:42151,DS-294504f0-bf0b-4ad9-801e-686513b3b670,DISK], DatanodeInfoWithStorage[127.0.0.1:45704,DS-6b7141bb-c919-4503-80bb-9a04e8160829,DISK], DatanodeInfoWithStorage[127.0.0.1:32796,DS-d54663f3-8548-4de5-9124-a055c462e2bb,DISK], DatanodeInfoWithStorage[127.0.0.1:45993,DS-1e4681b3-a84d-4c76-b8c3-b35ebd48e2b5,DISK], DatanodeInfoWithStorage[127.0.0.1:38889,DS-ea513ad9-b245-433f-99f2-3deca61675aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2091959380-172.17.0.7-1598404036750:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44222,DS-397e164b-4775-4c6c-8fa1-ce51852f5c2c,DISK], DatanodeInfoWithStorage[127.0.0.1:37009,DS-909303b4-4d7d-4a29-95e8-a0818d39608e,DISK], DatanodeInfoWithStorage[127.0.0.1:41749,DS-2ee28032-fad9-482c-ae5b-e44c15474d3f,DISK], DatanodeInfoWithStorage[127.0.0.1:46278,DS-1bb24889-b433-4363-ad53-51edcc442994,DISK], DatanodeInfoWithStorage[127.0.0.1:45308,DS-03c08d0e-57d4-48c6-b220-44bc11fbb645,DISK], DatanodeInfoWithStorage[127.0.0.1:37498,DS-381cf63c-fc4c-45fc-aace-22bd2fd76603,DISK], DatanodeInfoWithStorage[127.0.0.1:38023,DS-23c5f49f-e018-4e63-b635-bdc65859e178,DISK], DatanodeInfoWithStorage[127.0.0.1:33801,DS-30b9041d-b58e-4ae9-a8c7-978910c54494,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2091959380-172.17.0.7-1598404036750:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44222,DS-397e164b-4775-4c6c-8fa1-ce51852f5c2c,DISK], DatanodeInfoWithStorage[127.0.0.1:37009,DS-909303b4-4d7d-4a29-95e8-a0818d39608e,DISK], DatanodeInfoWithStorage[127.0.0.1:41749,DS-2ee28032-fad9-482c-ae5b-e44c15474d3f,DISK], DatanodeInfoWithStorage[127.0.0.1:46278,DS-1bb24889-b433-4363-ad53-51edcc442994,DISK], DatanodeInfoWithStorage[127.0.0.1:45308,DS-03c08d0e-57d4-48c6-b220-44bc11fbb645,DISK], DatanodeInfoWithStorage[127.0.0.1:37498,DS-381cf63c-fc4c-45fc-aace-22bd2fd76603,DISK], DatanodeInfoWithStorage[127.0.0.1:38023,DS-23c5f49f-e018-4e63-b635-bdc65859e178,DISK], DatanodeInfoWithStorage[127.0.0.1:33801,DS-30b9041d-b58e-4ae9-a8c7-978910c54494,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1353251133-172.17.0.7-1598404367377:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36876,DS-a5544ed7-2af8-4e5f-aa5e-f1a1c139cb87,DISK], DatanodeInfoWithStorage[127.0.0.1:42398,DS-eacbbb60-802a-4719-8d1a-7e4e32a6c55f,DISK], DatanodeInfoWithStorage[127.0.0.1:42674,DS-91377e36-1f67-464e-935d-ae70d6e05f4c,DISK], DatanodeInfoWithStorage[127.0.0.1:42173,DS-1b8fddf1-6e0a-494f-a062-20067f183ac5,DISK], DatanodeInfoWithStorage[127.0.0.1:40787,DS-0a60bb42-7091-4d5a-bc9c-6b4903e39295,DISK], DatanodeInfoWithStorage[127.0.0.1:40252,DS-34cd2000-d103-455a-af08-b55d381d6d63,DISK], DatanodeInfoWithStorage[127.0.0.1:37159,DS-120b7882-ed51-46c8-b6fb-afc2682250e0,DISK], DatanodeInfoWithStorage[127.0.0.1:45396,DS-80717d4d-c3f4-4d29-a63d-a020ba5eb1d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1353251133-172.17.0.7-1598404367377:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36876,DS-a5544ed7-2af8-4e5f-aa5e-f1a1c139cb87,DISK], DatanodeInfoWithStorage[127.0.0.1:42398,DS-eacbbb60-802a-4719-8d1a-7e4e32a6c55f,DISK], DatanodeInfoWithStorage[127.0.0.1:42674,DS-91377e36-1f67-464e-935d-ae70d6e05f4c,DISK], DatanodeInfoWithStorage[127.0.0.1:42173,DS-1b8fddf1-6e0a-494f-a062-20067f183ac5,DISK], DatanodeInfoWithStorage[127.0.0.1:40787,DS-0a60bb42-7091-4d5a-bc9c-6b4903e39295,DISK], DatanodeInfoWithStorage[127.0.0.1:40252,DS-34cd2000-d103-455a-af08-b55d381d6d63,DISK], DatanodeInfoWithStorage[127.0.0.1:37159,DS-120b7882-ed51-46c8-b6fb-afc2682250e0,DISK], DatanodeInfoWithStorage[127.0.0.1:45396,DS-80717d4d-c3f4-4d29-a63d-a020ba5eb1d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1613979474-172.17.0.7-1598404682177:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41242,DS-fa6df705-6fb8-40e2-aa02-fe00d2ee04b0,DISK], DatanodeInfoWithStorage[127.0.0.1:44190,DS-397472ed-bdee-4cd1-b705-3d0e83da1173,DISK], DatanodeInfoWithStorage[127.0.0.1:36714,DS-011cf7db-f40d-42f9-8da1-907476adb63c,DISK], DatanodeInfoWithStorage[127.0.0.1:39206,DS-750b360c-0266-4b01-9acd-73e608765c0d,DISK], DatanodeInfoWithStorage[127.0.0.1:34383,DS-d74f7fcc-7067-4f65-a3cb-842ddca1bb35,DISK], DatanodeInfoWithStorage[127.0.0.1:33473,DS-0fd193e5-b76e-47f1-b879-38a49117e293,DISK], DatanodeInfoWithStorage[127.0.0.1:36925,DS-9b4e56b8-6b02-4527-8658-e69c662d9806,DISK], DatanodeInfoWithStorage[127.0.0.1:46679,DS-c84320ee-8baa-4770-9e49-1135d5e5b688,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1613979474-172.17.0.7-1598404682177:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41242,DS-fa6df705-6fb8-40e2-aa02-fe00d2ee04b0,DISK], DatanodeInfoWithStorage[127.0.0.1:44190,DS-397472ed-bdee-4cd1-b705-3d0e83da1173,DISK], DatanodeInfoWithStorage[127.0.0.1:36714,DS-011cf7db-f40d-42f9-8da1-907476adb63c,DISK], DatanodeInfoWithStorage[127.0.0.1:39206,DS-750b360c-0266-4b01-9acd-73e608765c0d,DISK], DatanodeInfoWithStorage[127.0.0.1:34383,DS-d74f7fcc-7067-4f65-a3cb-842ddca1bb35,DISK], DatanodeInfoWithStorage[127.0.0.1:33473,DS-0fd193e5-b76e-47f1-b879-38a49117e293,DISK], DatanodeInfoWithStorage[127.0.0.1:36925,DS-9b4e56b8-6b02-4527-8658-e69c662d9806,DISK], DatanodeInfoWithStorage[127.0.0.1:46679,DS-c84320ee-8baa-4770-9e49-1135d5e5b688,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-872667915-172.17.0.7-1598404816575:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34878,DS-b0b29619-5ba3-48b0-b001-71090b583407,DISK], DatanodeInfoWithStorage[127.0.0.1:44721,DS-c145dc99-389f-4a23-89d5-cc77606b23b9,DISK], DatanodeInfoWithStorage[127.0.0.1:42447,DS-a10876d2-875c-4905-8288-414200f0d5fe,DISK], DatanodeInfoWithStorage[127.0.0.1:43695,DS-f6c4e74c-37f3-4f54-91ba-b47547728aa5,DISK], DatanodeInfoWithStorage[127.0.0.1:33131,DS-7a85dd10-e94c-4503-913c-1eb9b90d2ab7,DISK], DatanodeInfoWithStorage[127.0.0.1:37152,DS-5d4087c3-8c5d-4e7e-a48d-0515e87c6056,DISK], DatanodeInfoWithStorage[127.0.0.1:38757,DS-11d815ef-6937-4bde-83bb-e0ca9431783c,DISK], DatanodeInfoWithStorage[127.0.0.1:34846,DS-2e97982f-8c2c-4004-a147-edc46f9198df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-872667915-172.17.0.7-1598404816575:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34878,DS-b0b29619-5ba3-48b0-b001-71090b583407,DISK], DatanodeInfoWithStorage[127.0.0.1:44721,DS-c145dc99-389f-4a23-89d5-cc77606b23b9,DISK], DatanodeInfoWithStorage[127.0.0.1:42447,DS-a10876d2-875c-4905-8288-414200f0d5fe,DISK], DatanodeInfoWithStorage[127.0.0.1:43695,DS-f6c4e74c-37f3-4f54-91ba-b47547728aa5,DISK], DatanodeInfoWithStorage[127.0.0.1:33131,DS-7a85dd10-e94c-4503-913c-1eb9b90d2ab7,DISK], DatanodeInfoWithStorage[127.0.0.1:37152,DS-5d4087c3-8c5d-4e7e-a48d-0515e87c6056,DISK], DatanodeInfoWithStorage[127.0.0.1:38757,DS-11d815ef-6937-4bde-83bb-e0ca9431783c,DISK], DatanodeInfoWithStorage[127.0.0.1:34846,DS-2e97982f-8c2c-4004-a147-edc46f9198df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1143195903-172.17.0.7-1598404971323:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37887,DS-8c489d71-43e5-4c71-87d9-def1c4b1e751,DISK], DatanodeInfoWithStorage[127.0.0.1:36915,DS-c8467952-95dd-49ed-9479-f50d0cf20a22,DISK], DatanodeInfoWithStorage[127.0.0.1:41456,DS-ae64e884-eec1-4e97-a1fc-d8eacf62d016,DISK], DatanodeInfoWithStorage[127.0.0.1:34274,DS-33f8be35-653e-4c11-9b22-ee1b4beaad1e,DISK], DatanodeInfoWithStorage[127.0.0.1:34153,DS-86468559-e8ae-4b34-b26a-b8e04f85a934,DISK], DatanodeInfoWithStorage[127.0.0.1:35388,DS-bf7fcfd0-5249-4084-85f8-0b29c3431751,DISK], DatanodeInfoWithStorage[127.0.0.1:38006,DS-d6da1726-3e8c-4933-b7e7-9ef08629b3fd,DISK], DatanodeInfoWithStorage[127.0.0.1:42680,DS-c769d9a4-c5fb-4ce4-8ec7-7334c38e0727,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1143195903-172.17.0.7-1598404971323:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37887,DS-8c489d71-43e5-4c71-87d9-def1c4b1e751,DISK], DatanodeInfoWithStorage[127.0.0.1:36915,DS-c8467952-95dd-49ed-9479-f50d0cf20a22,DISK], DatanodeInfoWithStorage[127.0.0.1:41456,DS-ae64e884-eec1-4e97-a1fc-d8eacf62d016,DISK], DatanodeInfoWithStorage[127.0.0.1:34274,DS-33f8be35-653e-4c11-9b22-ee1b4beaad1e,DISK], DatanodeInfoWithStorage[127.0.0.1:34153,DS-86468559-e8ae-4b34-b26a-b8e04f85a934,DISK], DatanodeInfoWithStorage[127.0.0.1:35388,DS-bf7fcfd0-5249-4084-85f8-0b29c3431751,DISK], DatanodeInfoWithStorage[127.0.0.1:38006,DS-d6da1726-3e8c-4933-b7e7-9ef08629b3fd,DISK], DatanodeInfoWithStorage[127.0.0.1:42680,DS-c769d9a4-c5fb-4ce4-8ec7-7334c38e0727,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2032144962-172.17.0.7-1598405205758:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38764,DS-5d87fb21-704c-49ee-8ffd-32cf3a5b65af,DISK], DatanodeInfoWithStorage[127.0.0.1:41106,DS-a24f7599-1568-4a9a-a839-dea34d7e4397,DISK], DatanodeInfoWithStorage[127.0.0.1:37479,DS-561d4f85-1e98-467f-a8c8-9376277d2a67,DISK], DatanodeInfoWithStorage[127.0.0.1:44586,DS-5bfcb04a-aaf2-4c20-b558-0fe864eedfe7,DISK], DatanodeInfoWithStorage[127.0.0.1:46749,DS-1a310f5a-7beb-4edb-bac0-2e1eaee18e9d,DISK], DatanodeInfoWithStorage[127.0.0.1:34187,DS-094d0e80-2020-4059-81ca-07b5f1b268f7,DISK], DatanodeInfoWithStorage[127.0.0.1:40796,DS-2bb65bc3-1eed-491c-a138-ed42546b07c0,DISK], DatanodeInfoWithStorage[127.0.0.1:38982,DS-2699b11c-6994-4f19-ac4a-c1cff8745b6d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2032144962-172.17.0.7-1598405205758:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38764,DS-5d87fb21-704c-49ee-8ffd-32cf3a5b65af,DISK], DatanodeInfoWithStorage[127.0.0.1:41106,DS-a24f7599-1568-4a9a-a839-dea34d7e4397,DISK], DatanodeInfoWithStorage[127.0.0.1:37479,DS-561d4f85-1e98-467f-a8c8-9376277d2a67,DISK], DatanodeInfoWithStorage[127.0.0.1:44586,DS-5bfcb04a-aaf2-4c20-b558-0fe864eedfe7,DISK], DatanodeInfoWithStorage[127.0.0.1:46749,DS-1a310f5a-7beb-4edb-bac0-2e1eaee18e9d,DISK], DatanodeInfoWithStorage[127.0.0.1:34187,DS-094d0e80-2020-4059-81ca-07b5f1b268f7,DISK], DatanodeInfoWithStorage[127.0.0.1:40796,DS-2bb65bc3-1eed-491c-a138-ed42546b07c0,DISK], DatanodeInfoWithStorage[127.0.0.1:38982,DS-2699b11c-6994-4f19-ac4a-c1cff8745b6d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1764704526-172.17.0.7-1598405277145:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34744,DS-342dfdd4-1d83-42ab-9dba-2ee51b524225,DISK], DatanodeInfoWithStorage[127.0.0.1:34957,DS-247d110a-cffd-4d5d-83ca-4076fcd29c08,DISK], DatanodeInfoWithStorage[127.0.0.1:37035,DS-e4cdae38-5b85-476d-b38d-78ddb15532c6,DISK], DatanodeInfoWithStorage[127.0.0.1:34967,DS-e5b6c985-9c6a-4c26-b5a1-ddeba2ec7131,DISK], DatanodeInfoWithStorage[127.0.0.1:45910,DS-2a3aa679-c809-4f8f-9e97-3e3648f6f236,DISK], DatanodeInfoWithStorage[127.0.0.1:36541,DS-630ce551-73c5-4eee-8400-293eb463a930,DISK], DatanodeInfoWithStorage[127.0.0.1:40321,DS-66fefc58-5135-48c9-a8db-dbe62880d833,DISK], DatanodeInfoWithStorage[127.0.0.1:44616,DS-e7284f6e-93a7-429d-80b4-98cc99b65711,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1764704526-172.17.0.7-1598405277145:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34744,DS-342dfdd4-1d83-42ab-9dba-2ee51b524225,DISK], DatanodeInfoWithStorage[127.0.0.1:34957,DS-247d110a-cffd-4d5d-83ca-4076fcd29c08,DISK], DatanodeInfoWithStorage[127.0.0.1:37035,DS-e4cdae38-5b85-476d-b38d-78ddb15532c6,DISK], DatanodeInfoWithStorage[127.0.0.1:34967,DS-e5b6c985-9c6a-4c26-b5a1-ddeba2ec7131,DISK], DatanodeInfoWithStorage[127.0.0.1:45910,DS-2a3aa679-c809-4f8f-9e97-3e3648f6f236,DISK], DatanodeInfoWithStorage[127.0.0.1:36541,DS-630ce551-73c5-4eee-8400-293eb463a930,DISK], DatanodeInfoWithStorage[127.0.0.1:40321,DS-66fefc58-5135-48c9-a8db-dbe62880d833,DISK], DatanodeInfoWithStorage[127.0.0.1:44616,DS-e7284f6e-93a7-429d-80b4-98cc99b65711,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-102575370-172.17.0.7-1598405399436:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34486,DS-15e9af85-f667-4323-9eee-8b34fe5b187e,DISK], DatanodeInfoWithStorage[127.0.0.1:38412,DS-fbac9e4f-1a64-4c38-908f-d55b2ef209f6,DISK], DatanodeInfoWithStorage[127.0.0.1:42246,DS-cbcf260e-2df2-454f-a262-0715e92e4901,DISK], DatanodeInfoWithStorage[127.0.0.1:42295,DS-0ff4b944-a6d3-4c23-8ea2-6745b80bfcd1,DISK], DatanodeInfoWithStorage[127.0.0.1:42288,DS-8d3dbc03-56e0-4b5c-b6d3-b0d99c3f8494,DISK], DatanodeInfoWithStorage[127.0.0.1:43078,DS-606da5d1-b187-418d-8a12-4de4f3e70e31,DISK], DatanodeInfoWithStorage[127.0.0.1:35245,DS-d4dbcfc1-e9ce-45ab-8aa1-565f0bf2a5fb,DISK], DatanodeInfoWithStorage[127.0.0.1:36327,DS-4a6dabc3-382f-4305-9196-54121babb6a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-102575370-172.17.0.7-1598405399436:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34486,DS-15e9af85-f667-4323-9eee-8b34fe5b187e,DISK], DatanodeInfoWithStorage[127.0.0.1:38412,DS-fbac9e4f-1a64-4c38-908f-d55b2ef209f6,DISK], DatanodeInfoWithStorage[127.0.0.1:42246,DS-cbcf260e-2df2-454f-a262-0715e92e4901,DISK], DatanodeInfoWithStorage[127.0.0.1:42295,DS-0ff4b944-a6d3-4c23-8ea2-6745b80bfcd1,DISK], DatanodeInfoWithStorage[127.0.0.1:42288,DS-8d3dbc03-56e0-4b5c-b6d3-b0d99c3f8494,DISK], DatanodeInfoWithStorage[127.0.0.1:43078,DS-606da5d1-b187-418d-8a12-4de4f3e70e31,DISK], DatanodeInfoWithStorage[127.0.0.1:35245,DS-d4dbcfc1-e9ce-45ab-8aa1-565f0bf2a5fb,DISK], DatanodeInfoWithStorage[127.0.0.1:36327,DS-4a6dabc3-382f-4305-9196-54121babb6a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-264161682-172.17.0.7-1598405489240:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34812,DS-ef240a22-7509-4635-abbd-f099c21d9142,DISK], DatanodeInfoWithStorage[127.0.0.1:37341,DS-8aed6537-bc32-4f11-9b52-e48263e26532,DISK], DatanodeInfoWithStorage[127.0.0.1:45040,DS-dbaaded0-abfd-4750-b456-fc7338a2dbdf,DISK], DatanodeInfoWithStorage[127.0.0.1:46647,DS-979f1c7e-ae2c-4f7e-a8a5-851330adb57f,DISK], DatanodeInfoWithStorage[127.0.0.1:39232,DS-4cb4d364-e555-44fa-9a79-aa4f1a704d18,DISK], DatanodeInfoWithStorage[127.0.0.1:39177,DS-a5dabb31-3f24-457d-8845-d383f610c927,DISK], DatanodeInfoWithStorage[127.0.0.1:33641,DS-aeaa4094-c1a1-46b6-9194-d3fb09a2b6bb,DISK], DatanodeInfoWithStorage[127.0.0.1:40499,DS-a120685f-41d8-4a83-87a2-2c919f960a77,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-264161682-172.17.0.7-1598405489240:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34812,DS-ef240a22-7509-4635-abbd-f099c21d9142,DISK], DatanodeInfoWithStorage[127.0.0.1:37341,DS-8aed6537-bc32-4f11-9b52-e48263e26532,DISK], DatanodeInfoWithStorage[127.0.0.1:45040,DS-dbaaded0-abfd-4750-b456-fc7338a2dbdf,DISK], DatanodeInfoWithStorage[127.0.0.1:46647,DS-979f1c7e-ae2c-4f7e-a8a5-851330adb57f,DISK], DatanodeInfoWithStorage[127.0.0.1:39232,DS-4cb4d364-e555-44fa-9a79-aa4f1a704d18,DISK], DatanodeInfoWithStorage[127.0.0.1:39177,DS-a5dabb31-3f24-457d-8845-d383f610c927,DISK], DatanodeInfoWithStorage[127.0.0.1:33641,DS-aeaa4094-c1a1-46b6-9194-d3fb09a2b6bb,DISK], DatanodeInfoWithStorage[127.0.0.1:40499,DS-a120685f-41d8-4a83-87a2-2c919f960a77,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-234913417-172.17.0.7-1598405551883:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33462,DS-295ff039-d19e-46fa-8ad4-66fa61496c0b,DISK], DatanodeInfoWithStorage[127.0.0.1:37162,DS-e6c11301-2dd4-41df-9768-ad205b6c8c2b,DISK], DatanodeInfoWithStorage[127.0.0.1:36105,DS-c052e55e-380f-421b-ae17-61e85896fbbf,DISK], DatanodeInfoWithStorage[127.0.0.1:37533,DS-190163dc-40f8-44ec-9d1d-19478db117c3,DISK], DatanodeInfoWithStorage[127.0.0.1:44798,DS-8b75013a-5bfe-4d38-bec1-aa11f0a3ed63,DISK], DatanodeInfoWithStorage[127.0.0.1:39768,DS-6175241b-2981-4b76-84a1-778024f2a1a6,DISK], DatanodeInfoWithStorage[127.0.0.1:34107,DS-1252af4f-68f7-48e8-b4f5-88b61a4e8626,DISK], DatanodeInfoWithStorage[127.0.0.1:36541,DS-3ab25474-4052-4433-b618-dde94afbb1f2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-234913417-172.17.0.7-1598405551883:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33462,DS-295ff039-d19e-46fa-8ad4-66fa61496c0b,DISK], DatanodeInfoWithStorage[127.0.0.1:37162,DS-e6c11301-2dd4-41df-9768-ad205b6c8c2b,DISK], DatanodeInfoWithStorage[127.0.0.1:36105,DS-c052e55e-380f-421b-ae17-61e85896fbbf,DISK], DatanodeInfoWithStorage[127.0.0.1:37533,DS-190163dc-40f8-44ec-9d1d-19478db117c3,DISK], DatanodeInfoWithStorage[127.0.0.1:44798,DS-8b75013a-5bfe-4d38-bec1-aa11f0a3ed63,DISK], DatanodeInfoWithStorage[127.0.0.1:39768,DS-6175241b-2981-4b76-84a1-778024f2a1a6,DISK], DatanodeInfoWithStorage[127.0.0.1:34107,DS-1252af4f-68f7-48e8-b4f5-88b61a4e8626,DISK], DatanodeInfoWithStorage[127.0.0.1:36541,DS-3ab25474-4052-4433-b618-dde94afbb1f2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1961910121-172.17.0.7-1598405721965:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33862,DS-72c50183-6500-42f3-a761-551f8e0b059e,DISK], DatanodeInfoWithStorage[127.0.0.1:33607,DS-6921c263-6095-49c5-a982-25c7fa1085ba,DISK], DatanodeInfoWithStorage[127.0.0.1:40609,DS-e7406edb-9752-4fda-890f-f62cf3c707dc,DISK], DatanodeInfoWithStorage[127.0.0.1:46196,DS-d47850a9-1ddc-44c8-8e72-d9015c04328c,DISK], DatanodeInfoWithStorage[127.0.0.1:41194,DS-4d95157e-1b25-4324-9802-cef8cb8ad3b4,DISK], DatanodeInfoWithStorage[127.0.0.1:46453,DS-8cf49ce7-aaee-43a3-b2c4-0352137d172a,DISK], DatanodeInfoWithStorage[127.0.0.1:34946,DS-1ed2949d-b520-4693-87ec-7a752cf81ff1,DISK], DatanodeInfoWithStorage[127.0.0.1:42887,DS-980790e9-078c-4765-90c9-218a5681eb68,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1961910121-172.17.0.7-1598405721965:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33862,DS-72c50183-6500-42f3-a761-551f8e0b059e,DISK], DatanodeInfoWithStorage[127.0.0.1:33607,DS-6921c263-6095-49c5-a982-25c7fa1085ba,DISK], DatanodeInfoWithStorage[127.0.0.1:40609,DS-e7406edb-9752-4fda-890f-f62cf3c707dc,DISK], DatanodeInfoWithStorage[127.0.0.1:46196,DS-d47850a9-1ddc-44c8-8e72-d9015c04328c,DISK], DatanodeInfoWithStorage[127.0.0.1:41194,DS-4d95157e-1b25-4324-9802-cef8cb8ad3b4,DISK], DatanodeInfoWithStorage[127.0.0.1:46453,DS-8cf49ce7-aaee-43a3-b2c4-0352137d172a,DISK], DatanodeInfoWithStorage[127.0.0.1:34946,DS-1ed2949d-b520-4693-87ec-7a752cf81ff1,DISK], DatanodeInfoWithStorage[127.0.0.1:42887,DS-980790e9-078c-4765-90c9-218a5681eb68,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1836277732-172.17.0.7-1598407040770:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33102,DS-6b89b833-4637-43a2-922a-7983fb66639b,DISK], DatanodeInfoWithStorage[127.0.0.1:34205,DS-346c8f3d-ce30-4e00-b693-5eee5a77a4b1,DISK], DatanodeInfoWithStorage[127.0.0.1:45631,DS-26cb489b-fb94-4c52-be65-8ffd30dd92f5,DISK], DatanodeInfoWithStorage[127.0.0.1:42811,DS-00520d1e-5e69-498b-820f-615811a962a1,DISK], DatanodeInfoWithStorage[127.0.0.1:36352,DS-018d9298-83fe-40c3-9016-0dbb7624cc7e,DISK], DatanodeInfoWithStorage[127.0.0.1:41927,DS-5c100b63-d7f4-4f33-b205-a9b414b31e39,DISK], DatanodeInfoWithStorage[127.0.0.1:41634,DS-422c501c-4683-4016-b139-e3870e6c5213,DISK], DatanodeInfoWithStorage[127.0.0.1:46182,DS-8ab508aa-ef8e-45fa-ac52-cc53d00627a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1836277732-172.17.0.7-1598407040770:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33102,DS-6b89b833-4637-43a2-922a-7983fb66639b,DISK], DatanodeInfoWithStorage[127.0.0.1:34205,DS-346c8f3d-ce30-4e00-b693-5eee5a77a4b1,DISK], DatanodeInfoWithStorage[127.0.0.1:45631,DS-26cb489b-fb94-4c52-be65-8ffd30dd92f5,DISK], DatanodeInfoWithStorage[127.0.0.1:42811,DS-00520d1e-5e69-498b-820f-615811a962a1,DISK], DatanodeInfoWithStorage[127.0.0.1:36352,DS-018d9298-83fe-40c3-9016-0dbb7624cc7e,DISK], DatanodeInfoWithStorage[127.0.0.1:41927,DS-5c100b63-d7f4-4f33-b205-a9b414b31e39,DISK], DatanodeInfoWithStorage[127.0.0.1:41634,DS-422c501c-4683-4016-b139-e3870e6c5213,DISK], DatanodeInfoWithStorage[127.0.0.1:46182,DS-8ab508aa-ef8e-45fa-ac52-cc53d00627a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-302553968-172.17.0.7-1598407166675:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44517,DS-ccb26d13-a40e-4d37-81bf-46f02658b1d3,DISK], DatanodeInfoWithStorage[127.0.0.1:42783,DS-bb422f71-d264-4daa-b0cc-9a4bd763f0c5,DISK], DatanodeInfoWithStorage[127.0.0.1:41264,DS-7e541636-7b5a-4d3a-942b-4499807dbffb,DISK], DatanodeInfoWithStorage[127.0.0.1:38313,DS-23073223-3a01-4e46-959b-ab1f66b1a730,DISK], DatanodeInfoWithStorage[127.0.0.1:36669,DS-2773321d-375f-405b-8c58-4dcbf034f079,DISK], DatanodeInfoWithStorage[127.0.0.1:33124,DS-85b3ec60-1218-4c13-991a-b83f412c6681,DISK], DatanodeInfoWithStorage[127.0.0.1:37048,DS-5fd98178-2caa-4dfd-a53f-13b7fe4a7061,DISK], DatanodeInfoWithStorage[127.0.0.1:40477,DS-4d9a9a26-9f9c-487e-a08c-1c2164c88c16,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-302553968-172.17.0.7-1598407166675:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44517,DS-ccb26d13-a40e-4d37-81bf-46f02658b1d3,DISK], DatanodeInfoWithStorage[127.0.0.1:42783,DS-bb422f71-d264-4daa-b0cc-9a4bd763f0c5,DISK], DatanodeInfoWithStorage[127.0.0.1:41264,DS-7e541636-7b5a-4d3a-942b-4499807dbffb,DISK], DatanodeInfoWithStorage[127.0.0.1:38313,DS-23073223-3a01-4e46-959b-ab1f66b1a730,DISK], DatanodeInfoWithStorage[127.0.0.1:36669,DS-2773321d-375f-405b-8c58-4dcbf034f079,DISK], DatanodeInfoWithStorage[127.0.0.1:33124,DS-85b3ec60-1218-4c13-991a-b83f412c6681,DISK], DatanodeInfoWithStorage[127.0.0.1:37048,DS-5fd98178-2caa-4dfd-a53f-13b7fe4a7061,DISK], DatanodeInfoWithStorage[127.0.0.1:40477,DS-4d9a9a26-9f9c-487e-a08c-1c2164c88c16,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-408448323-172.17.0.7-1598407425246:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35417,DS-bed1a844-5d36-4aff-ada0-38690dde8ca0,DISK], DatanodeInfoWithStorage[127.0.0.1:44967,DS-b83d30fb-f21c-4827-b32e-bede8e660635,DISK], DatanodeInfoWithStorage[127.0.0.1:37046,DS-0ec51b37-9d73-426d-a7c7-6b22ead2b456,DISK], DatanodeInfoWithStorage[127.0.0.1:42056,DS-cf86bfc4-0e35-45b8-88e6-bda06e07b47f,DISK], DatanodeInfoWithStorage[127.0.0.1:43446,DS-e0ac5263-92e3-4cec-975b-42061ab69717,DISK], DatanodeInfoWithStorage[127.0.0.1:42086,DS-861fee0d-9444-4961-91f1-4704e1b8b269,DISK], DatanodeInfoWithStorage[127.0.0.1:43836,DS-9278ebe6-addf-4387-9a64-bd0e657cb2df,DISK], DatanodeInfoWithStorage[127.0.0.1:38284,DS-12c508f0-aa36-432e-bb67-95aed23f3afd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-408448323-172.17.0.7-1598407425246:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35417,DS-bed1a844-5d36-4aff-ada0-38690dde8ca0,DISK], DatanodeInfoWithStorage[127.0.0.1:44967,DS-b83d30fb-f21c-4827-b32e-bede8e660635,DISK], DatanodeInfoWithStorage[127.0.0.1:37046,DS-0ec51b37-9d73-426d-a7c7-6b22ead2b456,DISK], DatanodeInfoWithStorage[127.0.0.1:42056,DS-cf86bfc4-0e35-45b8-88e6-bda06e07b47f,DISK], DatanodeInfoWithStorage[127.0.0.1:43446,DS-e0ac5263-92e3-4cec-975b-42061ab69717,DISK], DatanodeInfoWithStorage[127.0.0.1:42086,DS-861fee0d-9444-4961-91f1-4704e1b8b269,DISK], DatanodeInfoWithStorage[127.0.0.1:43836,DS-9278ebe6-addf-4387-9a64-bd0e657cb2df,DISK], DatanodeInfoWithStorage[127.0.0.1:38284,DS-12c508f0-aa36-432e-bb67-95aed23f3afd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1183559739-172.17.0.7-1598407632427:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36692,DS-7c375b6f-5123-48e7-8264-b37a325ea4cd,DISK], DatanodeInfoWithStorage[127.0.0.1:46666,DS-362cdee6-8e49-4aaa-9826-2e9baee53b8f,DISK], DatanodeInfoWithStorage[127.0.0.1:44521,DS-b7487461-ce4a-4c2f-81b7-73a3f536ed88,DISK], DatanodeInfoWithStorage[127.0.0.1:41564,DS-12151532-a798-458b-b2ee-9797e24a55b7,DISK], DatanodeInfoWithStorage[127.0.0.1:37992,DS-47103843-7efa-4a37-aa1e-cc35c4bdde19,DISK], DatanodeInfoWithStorage[127.0.0.1:42705,DS-1d09c401-b799-40c0-9500-3f0215b612d9,DISK], DatanodeInfoWithStorage[127.0.0.1:42059,DS-83ca42c8-ac9b-497f-8843-2a33efa43ea6,DISK], DatanodeInfoWithStorage[127.0.0.1:33766,DS-63f03d0b-5804-4262-9a77-22fe9bdaffd6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1183559739-172.17.0.7-1598407632427:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36692,DS-7c375b6f-5123-48e7-8264-b37a325ea4cd,DISK], DatanodeInfoWithStorage[127.0.0.1:46666,DS-362cdee6-8e49-4aaa-9826-2e9baee53b8f,DISK], DatanodeInfoWithStorage[127.0.0.1:44521,DS-b7487461-ce4a-4c2f-81b7-73a3f536ed88,DISK], DatanodeInfoWithStorage[127.0.0.1:41564,DS-12151532-a798-458b-b2ee-9797e24a55b7,DISK], DatanodeInfoWithStorage[127.0.0.1:37992,DS-47103843-7efa-4a37-aa1e-cc35c4bdde19,DISK], DatanodeInfoWithStorage[127.0.0.1:42705,DS-1d09c401-b799-40c0-9500-3f0215b612d9,DISK], DatanodeInfoWithStorage[127.0.0.1:42059,DS-83ca42c8-ac9b-497f-8843-2a33efa43ea6,DISK], DatanodeInfoWithStorage[127.0.0.1:33766,DS-63f03d0b-5804-4262-9a77-22fe9bdaffd6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-622074431-172.17.0.7-1598407659767:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38337,DS-ef586ff4-b35d-49c0-9da9-5e1d069bef88,DISK], DatanodeInfoWithStorage[127.0.0.1:34820,DS-0dfac116-f8ad-4f27-a1cc-60fe3ff223a4,DISK], DatanodeInfoWithStorage[127.0.0.1:42529,DS-22fd4c13-1184-473a-bf72-7b7f93fbafd8,DISK], DatanodeInfoWithStorage[127.0.0.1:42275,DS-b895ba42-12f6-4d33-a956-97e615d51aa5,DISK], DatanodeInfoWithStorage[127.0.0.1:45225,DS-fa3b3c49-b939-4034-a2de-5db70244c414,DISK], DatanodeInfoWithStorage[127.0.0.1:43931,DS-25372e81-1dde-4905-82d8-015e932cf218,DISK], DatanodeInfoWithStorage[127.0.0.1:35771,DS-76adc9b1-6fe0-4271-96f2-60e53b232b84,DISK], DatanodeInfoWithStorage[127.0.0.1:43409,DS-bec2ac58-db28-403c-bfe5-a4e90344f353,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-622074431-172.17.0.7-1598407659767:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38337,DS-ef586ff4-b35d-49c0-9da9-5e1d069bef88,DISK], DatanodeInfoWithStorage[127.0.0.1:34820,DS-0dfac116-f8ad-4f27-a1cc-60fe3ff223a4,DISK], DatanodeInfoWithStorage[127.0.0.1:42529,DS-22fd4c13-1184-473a-bf72-7b7f93fbafd8,DISK], DatanodeInfoWithStorage[127.0.0.1:42275,DS-b895ba42-12f6-4d33-a956-97e615d51aa5,DISK], DatanodeInfoWithStorage[127.0.0.1:45225,DS-fa3b3c49-b939-4034-a2de-5db70244c414,DISK], DatanodeInfoWithStorage[127.0.0.1:43931,DS-25372e81-1dde-4905-82d8-015e932cf218,DISK], DatanodeInfoWithStorage[127.0.0.1:35771,DS-76adc9b1-6fe0-4271-96f2-60e53b232b84,DISK], DatanodeInfoWithStorage[127.0.0.1:43409,DS-bec2ac58-db28-403c-bfe5-a4e90344f353,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 14 out of 50
result: false positive !!!
Total execution time in seconds : 4873
