reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1278268235-172.17.0.4-1598396122012:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45880,DS-a2a6949e-f5ee-40e3-a3cf-bacbd8fd376a,DISK], DatanodeInfoWithStorage[127.0.0.1:44836,DS-c95480e4-b560-4769-95b7-8bde0e38d561,DISK], DatanodeInfoWithStorage[127.0.0.1:35358,DS-0551c1f5-2706-4bad-aa2f-e2f9e3705b09,DISK], DatanodeInfoWithStorage[127.0.0.1:36214,DS-463b25e6-4c80-4522-a1cf-b73f4137a60f,DISK], DatanodeInfoWithStorage[127.0.0.1:43951,DS-a3f11b35-3860-45ed-9e5a-c9094192da33,DISK], DatanodeInfoWithStorage[127.0.0.1:45271,DS-714dbe65-ae87-4405-8f11-b83dea33b3ae,DISK], DatanodeInfoWithStorage[127.0.0.1:42020,DS-e9e86ecd-442f-44cb-86b7-01e02e65cc47,DISK], DatanodeInfoWithStorage[127.0.0.1:42910,DS-9a53e258-879e-4e8d-adf2-8c3ab5e60bca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1278268235-172.17.0.4-1598396122012:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45880,DS-a2a6949e-f5ee-40e3-a3cf-bacbd8fd376a,DISK], DatanodeInfoWithStorage[127.0.0.1:44836,DS-c95480e4-b560-4769-95b7-8bde0e38d561,DISK], DatanodeInfoWithStorage[127.0.0.1:35358,DS-0551c1f5-2706-4bad-aa2f-e2f9e3705b09,DISK], DatanodeInfoWithStorage[127.0.0.1:36214,DS-463b25e6-4c80-4522-a1cf-b73f4137a60f,DISK], DatanodeInfoWithStorage[127.0.0.1:43951,DS-a3f11b35-3860-45ed-9e5a-c9094192da33,DISK], DatanodeInfoWithStorage[127.0.0.1:45271,DS-714dbe65-ae87-4405-8f11-b83dea33b3ae,DISK], DatanodeInfoWithStorage[127.0.0.1:42020,DS-e9e86ecd-442f-44cb-86b7-01e02e65cc47,DISK], DatanodeInfoWithStorage[127.0.0.1:42910,DS-9a53e258-879e-4e8d-adf2-8c3ab5e60bca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1151589682-172.17.0.4-1598396259803:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43320,DS-e048d413-6168-4eef-a421-c1b00156c517,DISK], DatanodeInfoWithStorage[127.0.0.1:38372,DS-85ad1cbb-747e-4210-a5d6-1ba689173b38,DISK], DatanodeInfoWithStorage[127.0.0.1:38287,DS-21708e53-005d-417f-a86a-afab656bd7b5,DISK], DatanodeInfoWithStorage[127.0.0.1:42788,DS-1f8f07c6-a917-408c-9b13-dcecc73c9582,DISK], DatanodeInfoWithStorage[127.0.0.1:33175,DS-6b2c125b-f6d0-4695-bea2-38b40fff3d46,DISK], DatanodeInfoWithStorage[127.0.0.1:45517,DS-6ac11690-d25a-4a3d-97a7-5b16f6b2fe1f,DISK], DatanodeInfoWithStorage[127.0.0.1:45109,DS-aca9a873-bdc3-43d6-8d64-083e83372bdd,DISK], DatanodeInfoWithStorage[127.0.0.1:41909,DS-07f9abb9-6019-4244-bf27-e4de65debd6b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1151589682-172.17.0.4-1598396259803:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43320,DS-e048d413-6168-4eef-a421-c1b00156c517,DISK], DatanodeInfoWithStorage[127.0.0.1:38372,DS-85ad1cbb-747e-4210-a5d6-1ba689173b38,DISK], DatanodeInfoWithStorage[127.0.0.1:38287,DS-21708e53-005d-417f-a86a-afab656bd7b5,DISK], DatanodeInfoWithStorage[127.0.0.1:42788,DS-1f8f07c6-a917-408c-9b13-dcecc73c9582,DISK], DatanodeInfoWithStorage[127.0.0.1:33175,DS-6b2c125b-f6d0-4695-bea2-38b40fff3d46,DISK], DatanodeInfoWithStorage[127.0.0.1:45517,DS-6ac11690-d25a-4a3d-97a7-5b16f6b2fe1f,DISK], DatanodeInfoWithStorage[127.0.0.1:45109,DS-aca9a873-bdc3-43d6-8d64-083e83372bdd,DISK], DatanodeInfoWithStorage[127.0.0.1:41909,DS-07f9abb9-6019-4244-bf27-e4de65debd6b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2052127300-172.17.0.4-1598396296118:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41414,DS-eebdb996-fafc-4483-a5db-5d5c95227e52,DISK], DatanodeInfoWithStorage[127.0.0.1:33649,DS-3c7280a4-d915-4a4e-98e7-8de8607fa112,DISK], DatanodeInfoWithStorage[127.0.0.1:44033,DS-7e942c98-2a96-420d-add8-0ad4c918791d,DISK], DatanodeInfoWithStorage[127.0.0.1:38074,DS-79f46a09-d188-4356-8f7e-129e4024464b,DISK], DatanodeInfoWithStorage[127.0.0.1:46519,DS-24df7372-ff41-4593-94db-07078be483ce,DISK], DatanodeInfoWithStorage[127.0.0.1:38762,DS-e4b7626f-566b-4057-add6-abb1c210af55,DISK], DatanodeInfoWithStorage[127.0.0.1:38794,DS-9c20fa5c-e8f6-4c44-b11f-62fc03b4a144,DISK], DatanodeInfoWithStorage[127.0.0.1:45638,DS-831728d3-ca1a-4d83-8d74-9e289a9dad27,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2052127300-172.17.0.4-1598396296118:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41414,DS-eebdb996-fafc-4483-a5db-5d5c95227e52,DISK], DatanodeInfoWithStorage[127.0.0.1:33649,DS-3c7280a4-d915-4a4e-98e7-8de8607fa112,DISK], DatanodeInfoWithStorage[127.0.0.1:44033,DS-7e942c98-2a96-420d-add8-0ad4c918791d,DISK], DatanodeInfoWithStorage[127.0.0.1:38074,DS-79f46a09-d188-4356-8f7e-129e4024464b,DISK], DatanodeInfoWithStorage[127.0.0.1:46519,DS-24df7372-ff41-4593-94db-07078be483ce,DISK], DatanodeInfoWithStorage[127.0.0.1:38762,DS-e4b7626f-566b-4057-add6-abb1c210af55,DISK], DatanodeInfoWithStorage[127.0.0.1:38794,DS-9c20fa5c-e8f6-4c44-b11f-62fc03b4a144,DISK], DatanodeInfoWithStorage[127.0.0.1:45638,DS-831728d3-ca1a-4d83-8d74-9e289a9dad27,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-255848193-172.17.0.4-1598396642300:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34621,DS-69a18db4-af1d-4962-a5f5-f20aee77698a,DISK], DatanodeInfoWithStorage[127.0.0.1:34929,DS-ed33a95b-9e39-48ef-a5ad-bc146be80975,DISK], DatanodeInfoWithStorage[127.0.0.1:44992,DS-461b8da8-e14b-45e2-961c-83b170c0ce84,DISK], DatanodeInfoWithStorage[127.0.0.1:35799,DS-869d3dd7-7a8d-4fd3-a04c-a01a9c850c20,DISK], DatanodeInfoWithStorage[127.0.0.1:35700,DS-28c7713c-a78e-41e1-8bef-bc44cc3a0633,DISK], DatanodeInfoWithStorage[127.0.0.1:37260,DS-bcc3c3d9-1fe2-445c-94c3-3ffc06e5d156,DISK], DatanodeInfoWithStorage[127.0.0.1:35346,DS-a7aa8e41-9973-4292-b0c8-0d9a215c60a2,DISK], DatanodeInfoWithStorage[127.0.0.1:38896,DS-bd971341-365f-4db0-b07b-19bd9712d615,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-255848193-172.17.0.4-1598396642300:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34621,DS-69a18db4-af1d-4962-a5f5-f20aee77698a,DISK], DatanodeInfoWithStorage[127.0.0.1:34929,DS-ed33a95b-9e39-48ef-a5ad-bc146be80975,DISK], DatanodeInfoWithStorage[127.0.0.1:44992,DS-461b8da8-e14b-45e2-961c-83b170c0ce84,DISK], DatanodeInfoWithStorage[127.0.0.1:35799,DS-869d3dd7-7a8d-4fd3-a04c-a01a9c850c20,DISK], DatanodeInfoWithStorage[127.0.0.1:35700,DS-28c7713c-a78e-41e1-8bef-bc44cc3a0633,DISK], DatanodeInfoWithStorage[127.0.0.1:37260,DS-bcc3c3d9-1fe2-445c-94c3-3ffc06e5d156,DISK], DatanodeInfoWithStorage[127.0.0.1:35346,DS-a7aa8e41-9973-4292-b0c8-0d9a215c60a2,DISK], DatanodeInfoWithStorage[127.0.0.1:38896,DS-bd971341-365f-4db0-b07b-19bd9712d615,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-844748531-172.17.0.4-1598396709430:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36754,DS-4969a19f-8dad-4798-beac-09710a27657e,DISK], DatanodeInfoWithStorage[127.0.0.1:33858,DS-4a43960a-48f8-4b23-9001-a0f266d263dc,DISK], DatanodeInfoWithStorage[127.0.0.1:41197,DS-e7783499-5bb7-47ae-a860-7aac885c88f6,DISK], DatanodeInfoWithStorage[127.0.0.1:33577,DS-843fc94f-57c8-4c82-a4f6-1a5e30ca8440,DISK], DatanodeInfoWithStorage[127.0.0.1:34338,DS-7532a1f3-24ec-4006-adc7-bc37d0e1e8ef,DISK], DatanodeInfoWithStorage[127.0.0.1:37202,DS-f3e49994-c2a9-4b96-a45a-604cc5e02539,DISK], DatanodeInfoWithStorage[127.0.0.1:41790,DS-4ac65975-177f-4187-894d-016aaed747f6,DISK], DatanodeInfoWithStorage[127.0.0.1:38381,DS-5cbd25cf-193d-4c8e-a04d-0a5f1f157052,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-844748531-172.17.0.4-1598396709430:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36754,DS-4969a19f-8dad-4798-beac-09710a27657e,DISK], DatanodeInfoWithStorage[127.0.0.1:33858,DS-4a43960a-48f8-4b23-9001-a0f266d263dc,DISK], DatanodeInfoWithStorage[127.0.0.1:41197,DS-e7783499-5bb7-47ae-a860-7aac885c88f6,DISK], DatanodeInfoWithStorage[127.0.0.1:33577,DS-843fc94f-57c8-4c82-a4f6-1a5e30ca8440,DISK], DatanodeInfoWithStorage[127.0.0.1:34338,DS-7532a1f3-24ec-4006-adc7-bc37d0e1e8ef,DISK], DatanodeInfoWithStorage[127.0.0.1:37202,DS-f3e49994-c2a9-4b96-a45a-604cc5e02539,DISK], DatanodeInfoWithStorage[127.0.0.1:41790,DS-4ac65975-177f-4187-894d-016aaed747f6,DISK], DatanodeInfoWithStorage[127.0.0.1:38381,DS-5cbd25cf-193d-4c8e-a04d-0a5f1f157052,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1370331055-172.17.0.4-1598397159588:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45178,DS-fa7f9522-89f8-4e75-a98b-9efd14e82bb6,DISK], DatanodeInfoWithStorage[127.0.0.1:33994,DS-641eb772-4caf-4514-b713-12aae1084306,DISK], DatanodeInfoWithStorage[127.0.0.1:34771,DS-289fd963-5622-48ce-8f50-33ad96494734,DISK], DatanodeInfoWithStorage[127.0.0.1:39364,DS-7bf9bd06-a209-4284-b220-45308509b877,DISK], DatanodeInfoWithStorage[127.0.0.1:40789,DS-833a0783-235b-44c0-94c6-251013f4a58f,DISK], DatanodeInfoWithStorage[127.0.0.1:34566,DS-48306f89-47f7-41bf-bddf-9f32dbcfaaea,DISK], DatanodeInfoWithStorage[127.0.0.1:46462,DS-eeeec050-a06d-4ae7-9f60-7977fb1b8aee,DISK], DatanodeInfoWithStorage[127.0.0.1:41324,DS-5008d9a8-b494-4be4-b014-56f4474b3e38,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1370331055-172.17.0.4-1598397159588:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45178,DS-fa7f9522-89f8-4e75-a98b-9efd14e82bb6,DISK], DatanodeInfoWithStorage[127.0.0.1:33994,DS-641eb772-4caf-4514-b713-12aae1084306,DISK], DatanodeInfoWithStorage[127.0.0.1:34771,DS-289fd963-5622-48ce-8f50-33ad96494734,DISK], DatanodeInfoWithStorage[127.0.0.1:39364,DS-7bf9bd06-a209-4284-b220-45308509b877,DISK], DatanodeInfoWithStorage[127.0.0.1:40789,DS-833a0783-235b-44c0-94c6-251013f4a58f,DISK], DatanodeInfoWithStorage[127.0.0.1:34566,DS-48306f89-47f7-41bf-bddf-9f32dbcfaaea,DISK], DatanodeInfoWithStorage[127.0.0.1:46462,DS-eeeec050-a06d-4ae7-9f60-7977fb1b8aee,DISK], DatanodeInfoWithStorage[127.0.0.1:41324,DS-5008d9a8-b494-4be4-b014-56f4474b3e38,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-830047737-172.17.0.4-1598397237217:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43510,DS-71c09c97-a7a3-4a65-b54e-0f10b1b61760,DISK], DatanodeInfoWithStorage[127.0.0.1:37849,DS-2bdee6fe-fd07-4cfc-a378-f715892f084c,DISK], DatanodeInfoWithStorage[127.0.0.1:38504,DS-2a885940-9d2a-41ce-a285-c87a88308fb1,DISK], DatanodeInfoWithStorage[127.0.0.1:42504,DS-7dc7b105-bc02-4475-831b-b3ff4737926c,DISK], DatanodeInfoWithStorage[127.0.0.1:33999,DS-fd70b432-e36a-4607-ac6e-8543ec7373cb,DISK], DatanodeInfoWithStorage[127.0.0.1:43713,DS-51cc52fa-8faa-4d80-b89e-c820a05fe905,DISK], DatanodeInfoWithStorage[127.0.0.1:37029,DS-707e1b1f-3892-48d4-9662-d85debd42ba1,DISK], DatanodeInfoWithStorage[127.0.0.1:34159,DS-b3cb79ff-89fd-4267-b5d8-6632e1dcaa3d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-830047737-172.17.0.4-1598397237217:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43510,DS-71c09c97-a7a3-4a65-b54e-0f10b1b61760,DISK], DatanodeInfoWithStorage[127.0.0.1:37849,DS-2bdee6fe-fd07-4cfc-a378-f715892f084c,DISK], DatanodeInfoWithStorage[127.0.0.1:38504,DS-2a885940-9d2a-41ce-a285-c87a88308fb1,DISK], DatanodeInfoWithStorage[127.0.0.1:42504,DS-7dc7b105-bc02-4475-831b-b3ff4737926c,DISK], DatanodeInfoWithStorage[127.0.0.1:33999,DS-fd70b432-e36a-4607-ac6e-8543ec7373cb,DISK], DatanodeInfoWithStorage[127.0.0.1:43713,DS-51cc52fa-8faa-4d80-b89e-c820a05fe905,DISK], DatanodeInfoWithStorage[127.0.0.1:37029,DS-707e1b1f-3892-48d4-9662-d85debd42ba1,DISK], DatanodeInfoWithStorage[127.0.0.1:34159,DS-b3cb79ff-89fd-4267-b5d8-6632e1dcaa3d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1098968053-172.17.0.4-1598397267250:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39724,DS-5df1d581-0d72-4e8a-9452-1d994bfb3c10,DISK], DatanodeInfoWithStorage[127.0.0.1:39060,DS-f0e3a934-de79-4d59-a669-e6380a58fa4c,DISK], DatanodeInfoWithStorage[127.0.0.1:38224,DS-5394a5b6-6023-4fcc-a560-b14c98be09f5,DISK], DatanodeInfoWithStorage[127.0.0.1:36191,DS-59d444ab-f4ac-4e21-9d99-58355f8f21e7,DISK], DatanodeInfoWithStorage[127.0.0.1:36212,DS-fa85ebb7-f5d8-427e-b3b6-5d86160963c5,DISK], DatanodeInfoWithStorage[127.0.0.1:42484,DS-71b91c15-549d-4291-9c6b-66ae93938bd4,DISK], DatanodeInfoWithStorage[127.0.0.1:41461,DS-76d4b1b8-e4dc-490e-9f66-620d39fef2eb,DISK], DatanodeInfoWithStorage[127.0.0.1:41450,DS-7b7c2a22-c58f-4186-94c5-110a337cf04b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1098968053-172.17.0.4-1598397267250:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39724,DS-5df1d581-0d72-4e8a-9452-1d994bfb3c10,DISK], DatanodeInfoWithStorage[127.0.0.1:39060,DS-f0e3a934-de79-4d59-a669-e6380a58fa4c,DISK], DatanodeInfoWithStorage[127.0.0.1:38224,DS-5394a5b6-6023-4fcc-a560-b14c98be09f5,DISK], DatanodeInfoWithStorage[127.0.0.1:36191,DS-59d444ab-f4ac-4e21-9d99-58355f8f21e7,DISK], DatanodeInfoWithStorage[127.0.0.1:36212,DS-fa85ebb7-f5d8-427e-b3b6-5d86160963c5,DISK], DatanodeInfoWithStorage[127.0.0.1:42484,DS-71b91c15-549d-4291-9c6b-66ae93938bd4,DISK], DatanodeInfoWithStorage[127.0.0.1:41461,DS-76d4b1b8-e4dc-490e-9f66-620d39fef2eb,DISK], DatanodeInfoWithStorage[127.0.0.1:41450,DS-7b7c2a22-c58f-4186-94c5-110a337cf04b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-616510400-172.17.0.4-1598397363154:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45900,DS-23f4f3e7-ed76-40a3-9f91-c0e7f565213b,DISK], DatanodeInfoWithStorage[127.0.0.1:41959,DS-f99b7f9c-aec5-465c-bd78-b2224dc1cb10,DISK], DatanodeInfoWithStorage[127.0.0.1:42437,DS-f2aa8ba1-67dc-430b-bd2c-051a53b52998,DISK], DatanodeInfoWithStorage[127.0.0.1:35676,DS-e1b461ad-ef05-4b05-b26f-eaa60cfd05ef,DISK], DatanodeInfoWithStorage[127.0.0.1:33341,DS-64bc0be9-2e1c-4c54-b4bd-1cbf8ac4556e,DISK], DatanodeInfoWithStorage[127.0.0.1:44853,DS-1da23825-0548-45d5-ba52-1076c0eb0f83,DISK], DatanodeInfoWithStorage[127.0.0.1:37376,DS-0b9d6292-5ea1-4677-a5b7-3416c5c70428,DISK], DatanodeInfoWithStorage[127.0.0.1:43669,DS-249d211b-de06-46a2-bd27-38cac93c2d82,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-616510400-172.17.0.4-1598397363154:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45900,DS-23f4f3e7-ed76-40a3-9f91-c0e7f565213b,DISK], DatanodeInfoWithStorage[127.0.0.1:41959,DS-f99b7f9c-aec5-465c-bd78-b2224dc1cb10,DISK], DatanodeInfoWithStorage[127.0.0.1:42437,DS-f2aa8ba1-67dc-430b-bd2c-051a53b52998,DISK], DatanodeInfoWithStorage[127.0.0.1:35676,DS-e1b461ad-ef05-4b05-b26f-eaa60cfd05ef,DISK], DatanodeInfoWithStorage[127.0.0.1:33341,DS-64bc0be9-2e1c-4c54-b4bd-1cbf8ac4556e,DISK], DatanodeInfoWithStorage[127.0.0.1:44853,DS-1da23825-0548-45d5-ba52-1076c0eb0f83,DISK], DatanodeInfoWithStorage[127.0.0.1:37376,DS-0b9d6292-5ea1-4677-a5b7-3416c5c70428,DISK], DatanodeInfoWithStorage[127.0.0.1:43669,DS-249d211b-de06-46a2-bd27-38cac93c2d82,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1469695787-172.17.0.4-1598397432775:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42271,DS-24b2f947-d132-4f82-9582-82a79a6e925a,DISK], DatanodeInfoWithStorage[127.0.0.1:34184,DS-8fd50fcc-e91a-4892-b09c-882f7f8d1425,DISK], DatanodeInfoWithStorage[127.0.0.1:35361,DS-3f02b327-ca82-48b1-906b-95b11acc36ad,DISK], DatanodeInfoWithStorage[127.0.0.1:42357,DS-dbd41041-7ed2-40c8-8d65-a12f352d6031,DISK], DatanodeInfoWithStorage[127.0.0.1:44581,DS-96c4e40c-f073-463b-9a58-b93c0220e5b5,DISK], DatanodeInfoWithStorage[127.0.0.1:39508,DS-c93684ad-4b59-435c-8d3d-bd2a8bbb5220,DISK], DatanodeInfoWithStorage[127.0.0.1:38861,DS-d9a61c00-1e27-4be4-b9b2-b18707c00f0b,DISK], DatanodeInfoWithStorage[127.0.0.1:39679,DS-81c7e228-153c-4397-a657-371eb8e141b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1469695787-172.17.0.4-1598397432775:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42271,DS-24b2f947-d132-4f82-9582-82a79a6e925a,DISK], DatanodeInfoWithStorage[127.0.0.1:34184,DS-8fd50fcc-e91a-4892-b09c-882f7f8d1425,DISK], DatanodeInfoWithStorage[127.0.0.1:35361,DS-3f02b327-ca82-48b1-906b-95b11acc36ad,DISK], DatanodeInfoWithStorage[127.0.0.1:42357,DS-dbd41041-7ed2-40c8-8d65-a12f352d6031,DISK], DatanodeInfoWithStorage[127.0.0.1:44581,DS-96c4e40c-f073-463b-9a58-b93c0220e5b5,DISK], DatanodeInfoWithStorage[127.0.0.1:39508,DS-c93684ad-4b59-435c-8d3d-bd2a8bbb5220,DISK], DatanodeInfoWithStorage[127.0.0.1:38861,DS-d9a61c00-1e27-4be4-b9b2-b18707c00f0b,DISK], DatanodeInfoWithStorage[127.0.0.1:39679,DS-81c7e228-153c-4397-a657-371eb8e141b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1019222619-172.17.0.4-1598397610931:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37841,DS-53786a76-a012-4797-bd6e-bc30df499a48,DISK], DatanodeInfoWithStorage[127.0.0.1:45015,DS-d4def6ac-6f2a-410c-8de4-55a9e98a77dd,DISK], DatanodeInfoWithStorage[127.0.0.1:42960,DS-ef16f57e-340b-42ab-802a-c5ee99917afc,DISK], DatanodeInfoWithStorage[127.0.0.1:41543,DS-b29d2367-2c8f-4807-886f-3051aecba47a,DISK], DatanodeInfoWithStorage[127.0.0.1:33045,DS-73a1f94b-f631-4c17-974e-fb4a32744b7c,DISK], DatanodeInfoWithStorage[127.0.0.1:37016,DS-2d0d118f-0204-4987-b725-ae8f8156d98f,DISK], DatanodeInfoWithStorage[127.0.0.1:45783,DS-43fb78ea-5d78-4cf3-a2ab-7fab62357408,DISK], DatanodeInfoWithStorage[127.0.0.1:45147,DS-2475e8cd-99a1-4c35-a10d-be502cc4fa81,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1019222619-172.17.0.4-1598397610931:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37841,DS-53786a76-a012-4797-bd6e-bc30df499a48,DISK], DatanodeInfoWithStorage[127.0.0.1:45015,DS-d4def6ac-6f2a-410c-8de4-55a9e98a77dd,DISK], DatanodeInfoWithStorage[127.0.0.1:42960,DS-ef16f57e-340b-42ab-802a-c5ee99917afc,DISK], DatanodeInfoWithStorage[127.0.0.1:41543,DS-b29d2367-2c8f-4807-886f-3051aecba47a,DISK], DatanodeInfoWithStorage[127.0.0.1:33045,DS-73a1f94b-f631-4c17-974e-fb4a32744b7c,DISK], DatanodeInfoWithStorage[127.0.0.1:37016,DS-2d0d118f-0204-4987-b725-ae8f8156d98f,DISK], DatanodeInfoWithStorage[127.0.0.1:45783,DS-43fb78ea-5d78-4cf3-a2ab-7fab62357408,DISK], DatanodeInfoWithStorage[127.0.0.1:45147,DS-2475e8cd-99a1-4c35-a10d-be502cc4fa81,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1768747648-172.17.0.4-1598398272326:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41241,DS-f20662e3-f063-4e00-be94-9a1cc9baa7f1,DISK], DatanodeInfoWithStorage[127.0.0.1:42941,DS-f8b43b47-a085-4e20-9ee6-9a45155c91a2,DISK], DatanodeInfoWithStorage[127.0.0.1:42277,DS-0c798caf-c1d1-4c5e-bced-fd0bec863782,DISK], DatanodeInfoWithStorage[127.0.0.1:40751,DS-af3e7525-8c5b-49d9-8676-8ab04bfeceaf,DISK], DatanodeInfoWithStorage[127.0.0.1:42971,DS-ce69a35f-4d44-46c0-9f10-11368dc4adf4,DISK], DatanodeInfoWithStorage[127.0.0.1:46138,DS-18f089b9-1a65-48b8-9b09-35a05db57b58,DISK], DatanodeInfoWithStorage[127.0.0.1:44985,DS-888d86bb-6558-46fc-a6cd-3b7c3f6d427f,DISK], DatanodeInfoWithStorage[127.0.0.1:45991,DS-ac944a12-f5dd-47dc-883b-c18b8edf3aec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1768747648-172.17.0.4-1598398272326:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41241,DS-f20662e3-f063-4e00-be94-9a1cc9baa7f1,DISK], DatanodeInfoWithStorage[127.0.0.1:42941,DS-f8b43b47-a085-4e20-9ee6-9a45155c91a2,DISK], DatanodeInfoWithStorage[127.0.0.1:42277,DS-0c798caf-c1d1-4c5e-bced-fd0bec863782,DISK], DatanodeInfoWithStorage[127.0.0.1:40751,DS-af3e7525-8c5b-49d9-8676-8ab04bfeceaf,DISK], DatanodeInfoWithStorage[127.0.0.1:42971,DS-ce69a35f-4d44-46c0-9f10-11368dc4adf4,DISK], DatanodeInfoWithStorage[127.0.0.1:46138,DS-18f089b9-1a65-48b8-9b09-35a05db57b58,DISK], DatanodeInfoWithStorage[127.0.0.1:44985,DS-888d86bb-6558-46fc-a6cd-3b7c3f6d427f,DISK], DatanodeInfoWithStorage[127.0.0.1:45991,DS-ac944a12-f5dd-47dc-883b-c18b8edf3aec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1512292043-172.17.0.4-1598398381597:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41181,DS-d29e1893-8c97-41b1-bb61-78889b228fe2,DISK], DatanodeInfoWithStorage[127.0.0.1:33770,DS-ddb4cd79-daab-4505-b510-02b738c83326,DISK], DatanodeInfoWithStorage[127.0.0.1:36460,DS-7e0c7d63-b792-41b4-b820-3d69bf81e686,DISK], DatanodeInfoWithStorage[127.0.0.1:44892,DS-da2a1af2-23cf-4d62-a36a-03e805f6091d,DISK], DatanodeInfoWithStorage[127.0.0.1:44818,DS-7e50fa9e-c4f6-480a-8c7d-23c8a8a9730d,DISK], DatanodeInfoWithStorage[127.0.0.1:42755,DS-7ea630cb-38c2-474e-8187-33adc03e2965,DISK], DatanodeInfoWithStorage[127.0.0.1:34074,DS-d4b76a3c-dffb-4f35-9170-65d59cccfb69,DISK], DatanodeInfoWithStorage[127.0.0.1:37567,DS-732b542c-2c4d-4950-abb0-cc46a76c50ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1512292043-172.17.0.4-1598398381597:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41181,DS-d29e1893-8c97-41b1-bb61-78889b228fe2,DISK], DatanodeInfoWithStorage[127.0.0.1:33770,DS-ddb4cd79-daab-4505-b510-02b738c83326,DISK], DatanodeInfoWithStorage[127.0.0.1:36460,DS-7e0c7d63-b792-41b4-b820-3d69bf81e686,DISK], DatanodeInfoWithStorage[127.0.0.1:44892,DS-da2a1af2-23cf-4d62-a36a-03e805f6091d,DISK], DatanodeInfoWithStorage[127.0.0.1:44818,DS-7e50fa9e-c4f6-480a-8c7d-23c8a8a9730d,DISK], DatanodeInfoWithStorage[127.0.0.1:42755,DS-7ea630cb-38c2-474e-8187-33adc03e2965,DISK], DatanodeInfoWithStorage[127.0.0.1:34074,DS-d4b76a3c-dffb-4f35-9170-65d59cccfb69,DISK], DatanodeInfoWithStorage[127.0.0.1:37567,DS-732b542c-2c4d-4950-abb0-cc46a76c50ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1095034089-172.17.0.4-1598398439663:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39284,DS-c4639ca2-0388-467a-bf33-05149d78de7e,DISK], DatanodeInfoWithStorage[127.0.0.1:37733,DS-0bcda1bf-cdeb-4484-978d-55dc4275a7b1,DISK], DatanodeInfoWithStorage[127.0.0.1:45035,DS-ea7a1da0-2bbb-476f-8af2-20fcaa39a2f9,DISK], DatanodeInfoWithStorage[127.0.0.1:33650,DS-fbc6897b-2979-49dc-aec3-964c78d53f31,DISK], DatanodeInfoWithStorage[127.0.0.1:44024,DS-79e68713-1ccd-47f9-bab9-72a518a5cb8c,DISK], DatanodeInfoWithStorage[127.0.0.1:41667,DS-a53fc83e-844c-4f74-9746-b3142a996e36,DISK], DatanodeInfoWithStorage[127.0.0.1:45616,DS-f8dd0b22-322f-4dd5-a1ee-702296e37e5e,DISK], DatanodeInfoWithStorage[127.0.0.1:40823,DS-59118d0d-9e42-4f49-af3d-8d2c3c36a01d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1095034089-172.17.0.4-1598398439663:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39284,DS-c4639ca2-0388-467a-bf33-05149d78de7e,DISK], DatanodeInfoWithStorage[127.0.0.1:37733,DS-0bcda1bf-cdeb-4484-978d-55dc4275a7b1,DISK], DatanodeInfoWithStorage[127.0.0.1:45035,DS-ea7a1da0-2bbb-476f-8af2-20fcaa39a2f9,DISK], DatanodeInfoWithStorage[127.0.0.1:33650,DS-fbc6897b-2979-49dc-aec3-964c78d53f31,DISK], DatanodeInfoWithStorage[127.0.0.1:44024,DS-79e68713-1ccd-47f9-bab9-72a518a5cb8c,DISK], DatanodeInfoWithStorage[127.0.0.1:41667,DS-a53fc83e-844c-4f74-9746-b3142a996e36,DISK], DatanodeInfoWithStorage[127.0.0.1:45616,DS-f8dd0b22-322f-4dd5-a1ee-702296e37e5e,DISK], DatanodeInfoWithStorage[127.0.0.1:40823,DS-59118d0d-9e42-4f49-af3d-8d2c3c36a01d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-254699630-172.17.0.4-1598398476086:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44867,DS-545ec6a6-a524-492b-90ea-6712f4f8059f,DISK], DatanodeInfoWithStorage[127.0.0.1:34935,DS-deaf2169-05b8-494b-b84e-f7fa5fea1343,DISK], DatanodeInfoWithStorage[127.0.0.1:41416,DS-bbda2177-fc7e-45e7-b97f-583f4c19366d,DISK], DatanodeInfoWithStorage[127.0.0.1:33926,DS-2060ea91-50d8-44e0-a433-ca3102a349a7,DISK], DatanodeInfoWithStorage[127.0.0.1:34961,DS-414b1497-aefb-4d01-9074-661894a5ca76,DISK], DatanodeInfoWithStorage[127.0.0.1:38495,DS-7d74d135-5ddd-4aaf-b0d6-894ff914eeac,DISK], DatanodeInfoWithStorage[127.0.0.1:43378,DS-82b79b20-8666-4835-ae9e-696de2ebe076,DISK], DatanodeInfoWithStorage[127.0.0.1:34978,DS-9422c74c-3d5f-4349-a5f9-d7c5696b8be4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-254699630-172.17.0.4-1598398476086:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44867,DS-545ec6a6-a524-492b-90ea-6712f4f8059f,DISK], DatanodeInfoWithStorage[127.0.0.1:34935,DS-deaf2169-05b8-494b-b84e-f7fa5fea1343,DISK], DatanodeInfoWithStorage[127.0.0.1:41416,DS-bbda2177-fc7e-45e7-b97f-583f4c19366d,DISK], DatanodeInfoWithStorage[127.0.0.1:33926,DS-2060ea91-50d8-44e0-a433-ca3102a349a7,DISK], DatanodeInfoWithStorage[127.0.0.1:34961,DS-414b1497-aefb-4d01-9074-661894a5ca76,DISK], DatanodeInfoWithStorage[127.0.0.1:38495,DS-7d74d135-5ddd-4aaf-b0d6-894ff914eeac,DISK], DatanodeInfoWithStorage[127.0.0.1:43378,DS-82b79b20-8666-4835-ae9e-696de2ebe076,DISK], DatanodeInfoWithStorage[127.0.0.1:34978,DS-9422c74c-3d5f-4349-a5f9-d7c5696b8be4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-489005469-172.17.0.4-1598398506985:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45707,DS-cc63842e-0127-48b3-868b-444914784dd9,DISK], DatanodeInfoWithStorage[127.0.0.1:43141,DS-fcd464f2-c14e-465c-876d-bfc866efd640,DISK], DatanodeInfoWithStorage[127.0.0.1:43979,DS-57272053-5d15-458f-af5c-e7492e711931,DISK], DatanodeInfoWithStorage[127.0.0.1:36029,DS-e34568c4-54aa-4a09-a21a-02611af90495,DISK], DatanodeInfoWithStorage[127.0.0.1:42624,DS-1feb318b-b482-4f37-98c0-cb1157c2405c,DISK], DatanodeInfoWithStorage[127.0.0.1:39778,DS-23f6588c-4064-4a5e-9bf0-ac77177a7892,DISK], DatanodeInfoWithStorage[127.0.0.1:43309,DS-ab320e36-8cdc-4bdf-ac1e-857c357d7947,DISK], DatanodeInfoWithStorage[127.0.0.1:45582,DS-c5e76850-4b12-4dab-bda3-75c1096e09e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-489005469-172.17.0.4-1598398506985:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45707,DS-cc63842e-0127-48b3-868b-444914784dd9,DISK], DatanodeInfoWithStorage[127.0.0.1:43141,DS-fcd464f2-c14e-465c-876d-bfc866efd640,DISK], DatanodeInfoWithStorage[127.0.0.1:43979,DS-57272053-5d15-458f-af5c-e7492e711931,DISK], DatanodeInfoWithStorage[127.0.0.1:36029,DS-e34568c4-54aa-4a09-a21a-02611af90495,DISK], DatanodeInfoWithStorage[127.0.0.1:42624,DS-1feb318b-b482-4f37-98c0-cb1157c2405c,DISK], DatanodeInfoWithStorage[127.0.0.1:39778,DS-23f6588c-4064-4a5e-9bf0-ac77177a7892,DISK], DatanodeInfoWithStorage[127.0.0.1:43309,DS-ab320e36-8cdc-4bdf-ac1e-857c357d7947,DISK], DatanodeInfoWithStorage[127.0.0.1:45582,DS-c5e76850-4b12-4dab-bda3-75c1096e09e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1028530833-172.17.0.4-1598398581681:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41475,DS-3a62a20d-d09e-4527-900e-47c336368bf2,DISK], DatanodeInfoWithStorage[127.0.0.1:34885,DS-a9a6626e-f2d6-41fe-938c-99832510945a,DISK], DatanodeInfoWithStorage[127.0.0.1:44160,DS-bf22986d-eae9-4b7d-bc42-22279b45098c,DISK], DatanodeInfoWithStorage[127.0.0.1:39100,DS-4cfbaccf-b70b-4d5b-a714-c5b41d9b562e,DISK], DatanodeInfoWithStorage[127.0.0.1:45402,DS-ddf64a68-9429-4d6b-bc16-c8ceeeca2fbb,DISK], DatanodeInfoWithStorage[127.0.0.1:38015,DS-8466a3ec-1725-4ebf-bbdf-3938b2df9775,DISK], DatanodeInfoWithStorage[127.0.0.1:46626,DS-919f2440-b4ed-45fe-8f8d-5e81639f1aeb,DISK], DatanodeInfoWithStorage[127.0.0.1:41194,DS-0e50bd5c-a4c8-45c7-9cfa-272ded72f95d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1028530833-172.17.0.4-1598398581681:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41475,DS-3a62a20d-d09e-4527-900e-47c336368bf2,DISK], DatanodeInfoWithStorage[127.0.0.1:34885,DS-a9a6626e-f2d6-41fe-938c-99832510945a,DISK], DatanodeInfoWithStorage[127.0.0.1:44160,DS-bf22986d-eae9-4b7d-bc42-22279b45098c,DISK], DatanodeInfoWithStorage[127.0.0.1:39100,DS-4cfbaccf-b70b-4d5b-a714-c5b41d9b562e,DISK], DatanodeInfoWithStorage[127.0.0.1:45402,DS-ddf64a68-9429-4d6b-bc16-c8ceeeca2fbb,DISK], DatanodeInfoWithStorage[127.0.0.1:38015,DS-8466a3ec-1725-4ebf-bbdf-3938b2df9775,DISK], DatanodeInfoWithStorage[127.0.0.1:46626,DS-919f2440-b4ed-45fe-8f8d-5e81639f1aeb,DISK], DatanodeInfoWithStorage[127.0.0.1:41194,DS-0e50bd5c-a4c8-45c7-9cfa-272ded72f95d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1047556195-172.17.0.4-1598398624624:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42503,DS-12eadaf9-fc8d-4b83-b595-af8754e242f5,DISK], DatanodeInfoWithStorage[127.0.0.1:35779,DS-a9e4aaa5-c981-4765-b9a8-8101a933b694,DISK], DatanodeInfoWithStorage[127.0.0.1:45957,DS-01081fd9-3c2f-4eb8-b79b-10f16c9dd6bd,DISK], DatanodeInfoWithStorage[127.0.0.1:40818,DS-aedfd5fb-0d6a-41ac-81ba-8c5deecf6a74,DISK], DatanodeInfoWithStorage[127.0.0.1:40522,DS-341e0619-9286-40cc-89ac-7feafc2e07e7,DISK], DatanodeInfoWithStorage[127.0.0.1:39113,DS-b469f7e6-23ca-4570-9c5e-60608effbe2c,DISK], DatanodeInfoWithStorage[127.0.0.1:34237,DS-3ba00a49-b890-4eb5-ad94-f1287e45cebe,DISK], DatanodeInfoWithStorage[127.0.0.1:40155,DS-1c6df543-ce2a-4bd6-a2b1-aaada54d9081,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1047556195-172.17.0.4-1598398624624:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42503,DS-12eadaf9-fc8d-4b83-b595-af8754e242f5,DISK], DatanodeInfoWithStorage[127.0.0.1:35779,DS-a9e4aaa5-c981-4765-b9a8-8101a933b694,DISK], DatanodeInfoWithStorage[127.0.0.1:45957,DS-01081fd9-3c2f-4eb8-b79b-10f16c9dd6bd,DISK], DatanodeInfoWithStorage[127.0.0.1:40818,DS-aedfd5fb-0d6a-41ac-81ba-8c5deecf6a74,DISK], DatanodeInfoWithStorage[127.0.0.1:40522,DS-341e0619-9286-40cc-89ac-7feafc2e07e7,DISK], DatanodeInfoWithStorage[127.0.0.1:39113,DS-b469f7e6-23ca-4570-9c5e-60608effbe2c,DISK], DatanodeInfoWithStorage[127.0.0.1:34237,DS-3ba00a49-b890-4eb5-ad94-f1287e45cebe,DISK], DatanodeInfoWithStorage[127.0.0.1:40155,DS-1c6df543-ce2a-4bd6-a2b1-aaada54d9081,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1022700784-172.17.0.4-1598398767097:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40329,DS-4f859177-2dd4-42a1-a875-13e6339e0b3a,DISK], DatanodeInfoWithStorage[127.0.0.1:33601,DS-8410fc28-37f0-4191-bd36-c4abe6d3f99f,DISK], DatanodeInfoWithStorage[127.0.0.1:37888,DS-48145946-dde6-4f33-99d0-0717d245d97a,DISK], DatanodeInfoWithStorage[127.0.0.1:43502,DS-4b23e55b-d03d-4fc9-ab84-abf2a0f0e459,DISK], DatanodeInfoWithStorage[127.0.0.1:37959,DS-6a5c3fbe-cac5-4166-8b12-2694211b2d91,DISK], DatanodeInfoWithStorage[127.0.0.1:44801,DS-fc1d9c36-42a7-4f46-a739-7edf1fd5f93c,DISK], DatanodeInfoWithStorage[127.0.0.1:39750,DS-92b05d38-0595-44e7-adde-70d6b0a37b67,DISK], DatanodeInfoWithStorage[127.0.0.1:34710,DS-26532313-139a-4fa7-9536-a105b52a2419,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1022700784-172.17.0.4-1598398767097:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40329,DS-4f859177-2dd4-42a1-a875-13e6339e0b3a,DISK], DatanodeInfoWithStorage[127.0.0.1:33601,DS-8410fc28-37f0-4191-bd36-c4abe6d3f99f,DISK], DatanodeInfoWithStorage[127.0.0.1:37888,DS-48145946-dde6-4f33-99d0-0717d245d97a,DISK], DatanodeInfoWithStorage[127.0.0.1:43502,DS-4b23e55b-d03d-4fc9-ab84-abf2a0f0e459,DISK], DatanodeInfoWithStorage[127.0.0.1:37959,DS-6a5c3fbe-cac5-4166-8b12-2694211b2d91,DISK], DatanodeInfoWithStorage[127.0.0.1:44801,DS-fc1d9c36-42a7-4f46-a739-7edf1fd5f93c,DISK], DatanodeInfoWithStorage[127.0.0.1:39750,DS-92b05d38-0595-44e7-adde-70d6b0a37b67,DISK], DatanodeInfoWithStorage[127.0.0.1:34710,DS-26532313-139a-4fa7-9536-a105b52a2419,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-945559469-172.17.0.4-1598398985429:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42987,DS-f44dc9d3-6127-4d94-98f1-a941a1d7df47,DISK], DatanodeInfoWithStorage[127.0.0.1:35140,DS-33a5485a-4734-4d67-b5fd-88d4320a2961,DISK], DatanodeInfoWithStorage[127.0.0.1:41113,DS-67ef7842-dd09-47a4-9a0e-18a0fb3f59c2,DISK], DatanodeInfoWithStorage[127.0.0.1:40914,DS-18d8723f-fc9e-4854-9ad0-d85fb5f240d6,DISK], DatanodeInfoWithStorage[127.0.0.1:45858,DS-ae8a3cb0-9758-4b0c-986f-bf7131b8b12c,DISK], DatanodeInfoWithStorage[127.0.0.1:44612,DS-d25f91ab-cf56-4a64-b44e-d31ac6c36157,DISK], DatanodeInfoWithStorage[127.0.0.1:35725,DS-36f80acd-0129-4228-a9a8-7fef475f01c0,DISK], DatanodeInfoWithStorage[127.0.0.1:39081,DS-da75d795-f2ca-4122-94b9-35b8fbfc8c69,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-945559469-172.17.0.4-1598398985429:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42987,DS-f44dc9d3-6127-4d94-98f1-a941a1d7df47,DISK], DatanodeInfoWithStorage[127.0.0.1:35140,DS-33a5485a-4734-4d67-b5fd-88d4320a2961,DISK], DatanodeInfoWithStorage[127.0.0.1:41113,DS-67ef7842-dd09-47a4-9a0e-18a0fb3f59c2,DISK], DatanodeInfoWithStorage[127.0.0.1:40914,DS-18d8723f-fc9e-4854-9ad0-d85fb5f240d6,DISK], DatanodeInfoWithStorage[127.0.0.1:45858,DS-ae8a3cb0-9758-4b0c-986f-bf7131b8b12c,DISK], DatanodeInfoWithStorage[127.0.0.1:44612,DS-d25f91ab-cf56-4a64-b44e-d31ac6c36157,DISK], DatanodeInfoWithStorage[127.0.0.1:35725,DS-36f80acd-0129-4228-a9a8-7fef475f01c0,DISK], DatanodeInfoWithStorage[127.0.0.1:39081,DS-da75d795-f2ca-4122-94b9-35b8fbfc8c69,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-969941039-172.17.0.4-1598399423978:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41395,DS-28a84b86-713f-489a-a80b-50766e7cfd1d,DISK], DatanodeInfoWithStorage[127.0.0.1:37416,DS-03bd91db-3ec7-4a12-b8d0-b8e030507bd9,DISK], DatanodeInfoWithStorage[127.0.0.1:40023,DS-f98ed247-3640-41a3-8149-0847d0261812,DISK], DatanodeInfoWithStorage[127.0.0.1:38858,DS-cf264795-9c3f-4bad-87b6-ca15affa04d1,DISK], DatanodeInfoWithStorage[127.0.0.1:45442,DS-9466e3bc-8e9b-44f9-8934-e0688857bdd9,DISK], DatanodeInfoWithStorage[127.0.0.1:43350,DS-fd14897e-dca2-4406-8c1c-092d5242d1c0,DISK], DatanodeInfoWithStorage[127.0.0.1:39583,DS-9c3ded32-6c46-4d36-9405-f2c0f8f88597,DISK], DatanodeInfoWithStorage[127.0.0.1:35440,DS-91e5d5a0-77e1-4b52-8ce4-f34a1d76641b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-969941039-172.17.0.4-1598399423978:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41395,DS-28a84b86-713f-489a-a80b-50766e7cfd1d,DISK], DatanodeInfoWithStorage[127.0.0.1:37416,DS-03bd91db-3ec7-4a12-b8d0-b8e030507bd9,DISK], DatanodeInfoWithStorage[127.0.0.1:40023,DS-f98ed247-3640-41a3-8149-0847d0261812,DISK], DatanodeInfoWithStorage[127.0.0.1:38858,DS-cf264795-9c3f-4bad-87b6-ca15affa04d1,DISK], DatanodeInfoWithStorage[127.0.0.1:45442,DS-9466e3bc-8e9b-44f9-8934-e0688857bdd9,DISK], DatanodeInfoWithStorage[127.0.0.1:43350,DS-fd14897e-dca2-4406-8c1c-092d5242d1c0,DISK], DatanodeInfoWithStorage[127.0.0.1:39583,DS-9c3ded32-6c46-4d36-9405-f2c0f8f88597,DISK], DatanodeInfoWithStorage[127.0.0.1:35440,DS-91e5d5a0-77e1-4b52-8ce4-f34a1d76641b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-302629532-172.17.0.4-1598399787116:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44005,DS-56be96d1-b65f-464d-9be8-970589504898,DISK], DatanodeInfoWithStorage[127.0.0.1:41069,DS-dfe1ac8e-f328-463c-866e-a597cc9d2b39,DISK], DatanodeInfoWithStorage[127.0.0.1:33225,DS-63026e7b-8187-4f99-b8f9-c82a1289aaae,DISK], DatanodeInfoWithStorage[127.0.0.1:35896,DS-29a877cf-3c7a-44d8-a37e-81d53504aa10,DISK], DatanodeInfoWithStorage[127.0.0.1:39119,DS-08f65db0-88ee-41d7-9f63-ad3bbe3c1a31,DISK], DatanodeInfoWithStorage[127.0.0.1:39168,DS-b5a935a7-c1ad-410d-9bf0-fcb5035d1d92,DISK], DatanodeInfoWithStorage[127.0.0.1:46830,DS-3e990089-962d-47b9-bebb-ab5fde1d620e,DISK], DatanodeInfoWithStorage[127.0.0.1:46688,DS-fbec7b72-a1b6-4c63-bea4-a07da574e7b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-302629532-172.17.0.4-1598399787116:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44005,DS-56be96d1-b65f-464d-9be8-970589504898,DISK], DatanodeInfoWithStorage[127.0.0.1:41069,DS-dfe1ac8e-f328-463c-866e-a597cc9d2b39,DISK], DatanodeInfoWithStorage[127.0.0.1:33225,DS-63026e7b-8187-4f99-b8f9-c82a1289aaae,DISK], DatanodeInfoWithStorage[127.0.0.1:35896,DS-29a877cf-3c7a-44d8-a37e-81d53504aa10,DISK], DatanodeInfoWithStorage[127.0.0.1:39119,DS-08f65db0-88ee-41d7-9f63-ad3bbe3c1a31,DISK], DatanodeInfoWithStorage[127.0.0.1:39168,DS-b5a935a7-c1ad-410d-9bf0-fcb5035d1d92,DISK], DatanodeInfoWithStorage[127.0.0.1:46830,DS-3e990089-962d-47b9-bebb-ab5fde1d620e,DISK], DatanodeInfoWithStorage[127.0.0.1:46688,DS-fbec7b72-a1b6-4c63-bea4-a07da574e7b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1011166500-172.17.0.4-1598400085751:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43585,DS-3ec92a75-3e95-4419-821e-5ee5d3404fc6,DISK], DatanodeInfoWithStorage[127.0.0.1:36124,DS-e83a825a-abaa-4eb5-8972-c8185b640701,DISK], DatanodeInfoWithStorage[127.0.0.1:46709,DS-2cc9e46b-c08e-41b8-af79-0a18228676ee,DISK], DatanodeInfoWithStorage[127.0.0.1:33872,DS-f38bfae3-59ad-43fe-bcb2-aa36dfb26584,DISK], DatanodeInfoWithStorage[127.0.0.1:38297,DS-15d5e06e-6194-47dd-8ad3-8a683df966af,DISK], DatanodeInfoWithStorage[127.0.0.1:44127,DS-efbad194-ed55-4cfb-b691-e066a17bba75,DISK], DatanodeInfoWithStorage[127.0.0.1:44073,DS-45051f0c-f2ae-4d74-bed1-586212d3509f,DISK], DatanodeInfoWithStorage[127.0.0.1:36075,DS-2c5178a2-1c27-4497-a5d0-12b839bad5f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1011166500-172.17.0.4-1598400085751:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43585,DS-3ec92a75-3e95-4419-821e-5ee5d3404fc6,DISK], DatanodeInfoWithStorage[127.0.0.1:36124,DS-e83a825a-abaa-4eb5-8972-c8185b640701,DISK], DatanodeInfoWithStorage[127.0.0.1:46709,DS-2cc9e46b-c08e-41b8-af79-0a18228676ee,DISK], DatanodeInfoWithStorage[127.0.0.1:33872,DS-f38bfae3-59ad-43fe-bcb2-aa36dfb26584,DISK], DatanodeInfoWithStorage[127.0.0.1:38297,DS-15d5e06e-6194-47dd-8ad3-8a683df966af,DISK], DatanodeInfoWithStorage[127.0.0.1:44127,DS-efbad194-ed55-4cfb-b691-e066a17bba75,DISK], DatanodeInfoWithStorage[127.0.0.1:44073,DS-45051f0c-f2ae-4d74-bed1-586212d3509f,DISK], DatanodeInfoWithStorage[127.0.0.1:36075,DS-2c5178a2-1c27-4497-a5d0-12b839bad5f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1823291187-172.17.0.4-1598400210381:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36008,DS-b85037fc-781d-40a9-b4ee-2a87535353f7,DISK], DatanodeInfoWithStorage[127.0.0.1:42637,DS-dd37c9ea-d7cc-4c11-80a2-a29dfecf5796,DISK], DatanodeInfoWithStorage[127.0.0.1:42707,DS-dc5d99f8-f556-48db-b457-5044ad7aba50,DISK], DatanodeInfoWithStorage[127.0.0.1:39495,DS-0f236003-419a-430d-87db-4e9c26f30913,DISK], DatanodeInfoWithStorage[127.0.0.1:37755,DS-1547a07b-da99-434d-b6d5-6bb7c3aa2eb5,DISK], DatanodeInfoWithStorage[127.0.0.1:41129,DS-3c373821-259c-4827-a14d-1d8a48f67159,DISK], DatanodeInfoWithStorage[127.0.0.1:39868,DS-28f5ef0d-ffc3-4105-8c35-5bd66590a590,DISK], DatanodeInfoWithStorage[127.0.0.1:36056,DS-9825eb55-d72a-4b15-bb94-82c0ab214e23,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1823291187-172.17.0.4-1598400210381:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36008,DS-b85037fc-781d-40a9-b4ee-2a87535353f7,DISK], DatanodeInfoWithStorage[127.0.0.1:42637,DS-dd37c9ea-d7cc-4c11-80a2-a29dfecf5796,DISK], DatanodeInfoWithStorage[127.0.0.1:42707,DS-dc5d99f8-f556-48db-b457-5044ad7aba50,DISK], DatanodeInfoWithStorage[127.0.0.1:39495,DS-0f236003-419a-430d-87db-4e9c26f30913,DISK], DatanodeInfoWithStorage[127.0.0.1:37755,DS-1547a07b-da99-434d-b6d5-6bb7c3aa2eb5,DISK], DatanodeInfoWithStorage[127.0.0.1:41129,DS-3c373821-259c-4827-a14d-1d8a48f67159,DISK], DatanodeInfoWithStorage[127.0.0.1:39868,DS-28f5ef0d-ffc3-4105-8c35-5bd66590a590,DISK], DatanodeInfoWithStorage[127.0.0.1:36056,DS-9825eb55-d72a-4b15-bb94-82c0ab214e23,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-325598419-172.17.0.4-1598400310007:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33898,DS-cad72e3c-cc4c-4854-8638-62bc7573d894,DISK], DatanodeInfoWithStorage[127.0.0.1:35429,DS-5492769a-70c1-40a5-a540-e49292e4fc44,DISK], DatanodeInfoWithStorage[127.0.0.1:46485,DS-85f92ba8-8b1e-435b-90af-3136a42cd512,DISK], DatanodeInfoWithStorage[127.0.0.1:40687,DS-a7aa4ae9-9ca6-485f-bcf8-b8a1a880ea55,DISK], DatanodeInfoWithStorage[127.0.0.1:33632,DS-20043329-b96b-48ad-ade4-564e037e4ae7,DISK], DatanodeInfoWithStorage[127.0.0.1:46465,DS-6a7ead4a-486f-4b93-a862-c29511130aea,DISK], DatanodeInfoWithStorage[127.0.0.1:37891,DS-a84eac0b-a47d-4230-8f0a-17e5a282f815,DISK], DatanodeInfoWithStorage[127.0.0.1:35124,DS-484c4fc7-2593-4183-9d4d-0c8db0acfc9f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-325598419-172.17.0.4-1598400310007:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33898,DS-cad72e3c-cc4c-4854-8638-62bc7573d894,DISK], DatanodeInfoWithStorage[127.0.0.1:35429,DS-5492769a-70c1-40a5-a540-e49292e4fc44,DISK], DatanodeInfoWithStorage[127.0.0.1:46485,DS-85f92ba8-8b1e-435b-90af-3136a42cd512,DISK], DatanodeInfoWithStorage[127.0.0.1:40687,DS-a7aa4ae9-9ca6-485f-bcf8-b8a1a880ea55,DISK], DatanodeInfoWithStorage[127.0.0.1:33632,DS-20043329-b96b-48ad-ade4-564e037e4ae7,DISK], DatanodeInfoWithStorage[127.0.0.1:46465,DS-6a7ead4a-486f-4b93-a862-c29511130aea,DISK], DatanodeInfoWithStorage[127.0.0.1:37891,DS-a84eac0b-a47d-4230-8f0a-17e5a282f815,DISK], DatanodeInfoWithStorage[127.0.0.1:35124,DS-484c4fc7-2593-4183-9d4d-0c8db0acfc9f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 12 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5029
