reconf_parameter: dfs.datanode.block-pinning.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.block-pinning.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1091918722-172.17.0.6-1598177394719:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46613,DS-956dcfd6-15b1-4ff8-8677-69ed11bce867,DISK], DatanodeInfoWithStorage[127.0.0.1:46544,DS-56fbb952-7af0-4c20-8ad8-ecc81924a628,DISK], DatanodeInfoWithStorage[127.0.0.1:39534,DS-b5989a99-0972-4571-929b-4f11b8c38120,DISK], DatanodeInfoWithStorage[127.0.0.1:46289,DS-dc85f8fd-a0bf-4d29-90f6-bdea00d31ab3,DISK], DatanodeInfoWithStorage[127.0.0.1:43780,DS-a5879f5c-1ff9-4c68-8bd8-be6a2ba7fa98,DISK], DatanodeInfoWithStorage[127.0.0.1:39092,DS-106b9099-f9e4-4adf-91cc-8e03fce82499,DISK], DatanodeInfoWithStorage[127.0.0.1:35980,DS-3fc5e051-2f5b-42a3-8d89-33e67adb5e67,DISK], DatanodeInfoWithStorage[127.0.0.1:40534,DS-0dfa5c6a-f92f-4b7e-b3b5-5d411c896246,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1091918722-172.17.0.6-1598177394719:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46613,DS-956dcfd6-15b1-4ff8-8677-69ed11bce867,DISK], DatanodeInfoWithStorage[127.0.0.1:46544,DS-56fbb952-7af0-4c20-8ad8-ecc81924a628,DISK], DatanodeInfoWithStorage[127.0.0.1:39534,DS-b5989a99-0972-4571-929b-4f11b8c38120,DISK], DatanodeInfoWithStorage[127.0.0.1:46289,DS-dc85f8fd-a0bf-4d29-90f6-bdea00d31ab3,DISK], DatanodeInfoWithStorage[127.0.0.1:43780,DS-a5879f5c-1ff9-4c68-8bd8-be6a2ba7fa98,DISK], DatanodeInfoWithStorage[127.0.0.1:39092,DS-106b9099-f9e4-4adf-91cc-8e03fce82499,DISK], DatanodeInfoWithStorage[127.0.0.1:35980,DS-3fc5e051-2f5b-42a3-8d89-33e67adb5e67,DISK], DatanodeInfoWithStorage[127.0.0.1:40534,DS-0dfa5c6a-f92f-4b7e-b3b5-5d411c896246,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.block-pinning.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-552659753-172.17.0.6-1598177708697:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43078,DS-4ed50305-cced-4847-bfb5-e59efbc00967,DISK], DatanodeInfoWithStorage[127.0.0.1:34673,DS-bace78cf-4fd6-40af-9d54-4851aeae4ab5,DISK], DatanodeInfoWithStorage[127.0.0.1:38401,DS-8e4398cb-71a8-4938-9ce8-c35467d03ba0,DISK], DatanodeInfoWithStorage[127.0.0.1:46320,DS-4a1f5772-d218-4404-b702-54fb08c0975c,DISK], DatanodeInfoWithStorage[127.0.0.1:42482,DS-b7ddc09e-675d-48bd-b469-a7d1347c4159,DISK], DatanodeInfoWithStorage[127.0.0.1:41634,DS-d587cc43-6e58-4d56-9ef1-bdc663e9485a,DISK], DatanodeInfoWithStorage[127.0.0.1:46111,DS-f8e278e4-0f5b-474c-a0b8-8f91bc0bef40,DISK], DatanodeInfoWithStorage[127.0.0.1:38899,DS-2abcdc4b-2355-4493-8bda-d6a9940bab41,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-552659753-172.17.0.6-1598177708697:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43078,DS-4ed50305-cced-4847-bfb5-e59efbc00967,DISK], DatanodeInfoWithStorage[127.0.0.1:34673,DS-bace78cf-4fd6-40af-9d54-4851aeae4ab5,DISK], DatanodeInfoWithStorage[127.0.0.1:38401,DS-8e4398cb-71a8-4938-9ce8-c35467d03ba0,DISK], DatanodeInfoWithStorage[127.0.0.1:46320,DS-4a1f5772-d218-4404-b702-54fb08c0975c,DISK], DatanodeInfoWithStorage[127.0.0.1:42482,DS-b7ddc09e-675d-48bd-b469-a7d1347c4159,DISK], DatanodeInfoWithStorage[127.0.0.1:41634,DS-d587cc43-6e58-4d56-9ef1-bdc663e9485a,DISK], DatanodeInfoWithStorage[127.0.0.1:46111,DS-f8e278e4-0f5b-474c-a0b8-8f91bc0bef40,DISK], DatanodeInfoWithStorage[127.0.0.1:38899,DS-2abcdc4b-2355-4493-8bda-d6a9940bab41,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.block-pinning.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-451444637-172.17.0.6-1598178015264:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46196,DS-1370064b-ae06-417e-ab4f-12c547c1fb31,DISK], DatanodeInfoWithStorage[127.0.0.1:33055,DS-84157ccb-1cce-4cdf-8ffb-fefc0f70e2de,DISK], DatanodeInfoWithStorage[127.0.0.1:33272,DS-92f6b7f0-7cf3-4d21-9ca5-9dd8a6b4c6ef,DISK], DatanodeInfoWithStorage[127.0.0.1:38563,DS-ffcf0df5-ab96-4091-9a93-874efd12dd73,DISK], DatanodeInfoWithStorage[127.0.0.1:45807,DS-3156756a-d385-4474-84d5-a8c5d6a103ae,DISK], DatanodeInfoWithStorage[127.0.0.1:36472,DS-26f7fee7-01d0-4610-890d-37af60a8a322,DISK], DatanodeInfoWithStorage[127.0.0.1:34987,DS-067e72f8-fa98-4663-8bb9-f435ccab7de6,DISK], DatanodeInfoWithStorage[127.0.0.1:42756,DS-87531844-6f4e-49dd-abe3-bb5ee40aa173,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-451444637-172.17.0.6-1598178015264:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46196,DS-1370064b-ae06-417e-ab4f-12c547c1fb31,DISK], DatanodeInfoWithStorage[127.0.0.1:33055,DS-84157ccb-1cce-4cdf-8ffb-fefc0f70e2de,DISK], DatanodeInfoWithStorage[127.0.0.1:33272,DS-92f6b7f0-7cf3-4d21-9ca5-9dd8a6b4c6ef,DISK], DatanodeInfoWithStorage[127.0.0.1:38563,DS-ffcf0df5-ab96-4091-9a93-874efd12dd73,DISK], DatanodeInfoWithStorage[127.0.0.1:45807,DS-3156756a-d385-4474-84d5-a8c5d6a103ae,DISK], DatanodeInfoWithStorage[127.0.0.1:36472,DS-26f7fee7-01d0-4610-890d-37af60a8a322,DISK], DatanodeInfoWithStorage[127.0.0.1:34987,DS-067e72f8-fa98-4663-8bb9-f435ccab7de6,DISK], DatanodeInfoWithStorage[127.0.0.1:42756,DS-87531844-6f4e-49dd-abe3-bb5ee40aa173,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.block-pinning.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1649240475-172.17.0.6-1598178359002:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34993,DS-1785c237-2c61-405f-9e9a-2c267b70e42d,DISK], DatanodeInfoWithStorage[127.0.0.1:39826,DS-bec4efac-8ce8-4ec6-85e3-b517e96d3099,DISK], DatanodeInfoWithStorage[127.0.0.1:34012,DS-dc2ad85a-a3e0-419e-9963-1ffebd036221,DISK], DatanodeInfoWithStorage[127.0.0.1:33561,DS-f282e922-ca7b-4333-b51a-9f362c363240,DISK], DatanodeInfoWithStorage[127.0.0.1:36678,DS-414f59b3-4cb9-4ffa-baec-e39dd3486d90,DISK], DatanodeInfoWithStorage[127.0.0.1:34062,DS-0c636343-39a5-4ef2-8bdc-d76d40759129,DISK], DatanodeInfoWithStorage[127.0.0.1:35779,DS-10df8412-2dba-426b-b6ef-db67e5d26518,DISK], DatanodeInfoWithStorage[127.0.0.1:45986,DS-61dc9bdb-0616-4b77-b29a-8048cad047db,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1649240475-172.17.0.6-1598178359002:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34993,DS-1785c237-2c61-405f-9e9a-2c267b70e42d,DISK], DatanodeInfoWithStorage[127.0.0.1:39826,DS-bec4efac-8ce8-4ec6-85e3-b517e96d3099,DISK], DatanodeInfoWithStorage[127.0.0.1:34012,DS-dc2ad85a-a3e0-419e-9963-1ffebd036221,DISK], DatanodeInfoWithStorage[127.0.0.1:33561,DS-f282e922-ca7b-4333-b51a-9f362c363240,DISK], DatanodeInfoWithStorage[127.0.0.1:36678,DS-414f59b3-4cb9-4ffa-baec-e39dd3486d90,DISK], DatanodeInfoWithStorage[127.0.0.1:34062,DS-0c636343-39a5-4ef2-8bdc-d76d40759129,DISK], DatanodeInfoWithStorage[127.0.0.1:35779,DS-10df8412-2dba-426b-b6ef-db67e5d26518,DISK], DatanodeInfoWithStorage[127.0.0.1:45986,DS-61dc9bdb-0616-4b77-b29a-8048cad047db,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.block-pinning.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1532883469-172.17.0.6-1598178439599:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45557,DS-fbbfd45c-da94-45de-afdd-bc824baa0e73,DISK], DatanodeInfoWithStorage[127.0.0.1:46693,DS-144c8c81-2e38-4e34-8615-aec73f993e70,DISK], DatanodeInfoWithStorage[127.0.0.1:45189,DS-6011e345-7127-474a-9353-32f70a90d568,DISK], DatanodeInfoWithStorage[127.0.0.1:43512,DS-ceeb6467-7c5d-4617-825a-ed11bb735282,DISK], DatanodeInfoWithStorage[127.0.0.1:40986,DS-0d192dcd-8592-4978-a5b3-6771678238a9,DISK], DatanodeInfoWithStorage[127.0.0.1:44213,DS-5742e720-b0b1-4868-9979-3ed189e330cf,DISK], DatanodeInfoWithStorage[127.0.0.1:36416,DS-f4ebe444-2511-478f-b898-98acd0abbaf4,DISK], DatanodeInfoWithStorage[127.0.0.1:43410,DS-88c0a25f-3d3d-42a1-9c4a-497dccf216ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1532883469-172.17.0.6-1598178439599:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45557,DS-fbbfd45c-da94-45de-afdd-bc824baa0e73,DISK], DatanodeInfoWithStorage[127.0.0.1:46693,DS-144c8c81-2e38-4e34-8615-aec73f993e70,DISK], DatanodeInfoWithStorage[127.0.0.1:45189,DS-6011e345-7127-474a-9353-32f70a90d568,DISK], DatanodeInfoWithStorage[127.0.0.1:43512,DS-ceeb6467-7c5d-4617-825a-ed11bb735282,DISK], DatanodeInfoWithStorage[127.0.0.1:40986,DS-0d192dcd-8592-4978-a5b3-6771678238a9,DISK], DatanodeInfoWithStorage[127.0.0.1:44213,DS-5742e720-b0b1-4868-9979-3ed189e330cf,DISK], DatanodeInfoWithStorage[127.0.0.1:36416,DS-f4ebe444-2511-478f-b898-98acd0abbaf4,DISK], DatanodeInfoWithStorage[127.0.0.1:43410,DS-88c0a25f-3d3d-42a1-9c4a-497dccf216ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.block-pinning.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-289291185-172.17.0.6-1598178873458:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34616,DS-f9c0c9ff-67fa-4052-af20-d8a951248415,DISK], DatanodeInfoWithStorage[127.0.0.1:44313,DS-c7e18fa9-af0e-4cd9-adf1-c8b0a93d939b,DISK], DatanodeInfoWithStorage[127.0.0.1:44004,DS-e8aa97e8-fd03-4c40-85a5-c3a8f2c8071f,DISK], DatanodeInfoWithStorage[127.0.0.1:41686,DS-f579a7c1-8722-499d-82dc-12b7b0eb4b5b,DISK], DatanodeInfoWithStorage[127.0.0.1:41124,DS-ef40728e-11ad-4d1b-b130-f7495bbfbe6f,DISK], DatanodeInfoWithStorage[127.0.0.1:34363,DS-11762dcb-352b-4f65-b244-b400521e5761,DISK], DatanodeInfoWithStorage[127.0.0.1:40886,DS-e50a77ec-5ee5-4521-abc8-5176014fd940,DISK], DatanodeInfoWithStorage[127.0.0.1:41248,DS-f78f1380-de83-4017-9295-6cc549dc69a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-289291185-172.17.0.6-1598178873458:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34616,DS-f9c0c9ff-67fa-4052-af20-d8a951248415,DISK], DatanodeInfoWithStorage[127.0.0.1:44313,DS-c7e18fa9-af0e-4cd9-adf1-c8b0a93d939b,DISK], DatanodeInfoWithStorage[127.0.0.1:44004,DS-e8aa97e8-fd03-4c40-85a5-c3a8f2c8071f,DISK], DatanodeInfoWithStorage[127.0.0.1:41686,DS-f579a7c1-8722-499d-82dc-12b7b0eb4b5b,DISK], DatanodeInfoWithStorage[127.0.0.1:41124,DS-ef40728e-11ad-4d1b-b130-f7495bbfbe6f,DISK], DatanodeInfoWithStorage[127.0.0.1:34363,DS-11762dcb-352b-4f65-b244-b400521e5761,DISK], DatanodeInfoWithStorage[127.0.0.1:40886,DS-e50a77ec-5ee5-4521-abc8-5176014fd940,DISK], DatanodeInfoWithStorage[127.0.0.1:41248,DS-f78f1380-de83-4017-9295-6cc549dc69a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.block-pinning.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1397429639-172.17.0.6-1598178932420:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46238,DS-1cdacfdb-ee34-4fe3-86a6-4be61391b023,DISK], DatanodeInfoWithStorage[127.0.0.1:42675,DS-1656d160-22fb-4ba3-882d-c5907e4e3cef,DISK], DatanodeInfoWithStorage[127.0.0.1:36133,DS-045d8b44-c0de-4d16-b03a-bd6428f98e15,DISK], DatanodeInfoWithStorage[127.0.0.1:39400,DS-bced5055-718a-43cf-b4cb-3c4c0107fec9,DISK], DatanodeInfoWithStorage[127.0.0.1:41937,DS-eb489c46-2d7a-4b24-a8c1-7a7f233f6ddf,DISK], DatanodeInfoWithStorage[127.0.0.1:44764,DS-2cf22caf-b18c-4e79-805b-e9d4ea638551,DISK], DatanodeInfoWithStorage[127.0.0.1:33333,DS-22cc3c3a-bfa7-4e92-a31f-6f61fee511b5,DISK], DatanodeInfoWithStorage[127.0.0.1:41128,DS-8d50d40f-be0f-4281-bce5-9c0d674778c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1397429639-172.17.0.6-1598178932420:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46238,DS-1cdacfdb-ee34-4fe3-86a6-4be61391b023,DISK], DatanodeInfoWithStorage[127.0.0.1:42675,DS-1656d160-22fb-4ba3-882d-c5907e4e3cef,DISK], DatanodeInfoWithStorage[127.0.0.1:36133,DS-045d8b44-c0de-4d16-b03a-bd6428f98e15,DISK], DatanodeInfoWithStorage[127.0.0.1:39400,DS-bced5055-718a-43cf-b4cb-3c4c0107fec9,DISK], DatanodeInfoWithStorage[127.0.0.1:41937,DS-eb489c46-2d7a-4b24-a8c1-7a7f233f6ddf,DISK], DatanodeInfoWithStorage[127.0.0.1:44764,DS-2cf22caf-b18c-4e79-805b-e9d4ea638551,DISK], DatanodeInfoWithStorage[127.0.0.1:33333,DS-22cc3c3a-bfa7-4e92-a31f-6f61fee511b5,DISK], DatanodeInfoWithStorage[127.0.0.1:41128,DS-8d50d40f-be0f-4281-bce5-9c0d674778c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.block-pinning.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1752493398-172.17.0.6-1598178971177:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36354,DS-c9c6f002-f188-45a4-8a6e-fb558af70300,DISK], DatanodeInfoWithStorage[127.0.0.1:41863,DS-6d161f61-3345-4168-8d8b-3d55cb95e460,DISK], DatanodeInfoWithStorage[127.0.0.1:45621,DS-bdbfafc4-9bd2-4ddc-bf26-2c62143ede18,DISK], DatanodeInfoWithStorage[127.0.0.1:41201,DS-e544d530-43ff-4540-b156-79b02a9e665d,DISK], DatanodeInfoWithStorage[127.0.0.1:40367,DS-f9ff2abf-21c4-4ea0-a6e3-f218169df05e,DISK], DatanodeInfoWithStorage[127.0.0.1:35243,DS-fc9d7c2d-0234-471e-af12-cc021eacd8e6,DISK], DatanodeInfoWithStorage[127.0.0.1:42822,DS-301535e5-1a26-4e54-8d39-c58f32c62255,DISK], DatanodeInfoWithStorage[127.0.0.1:44458,DS-24d98f0e-f6de-4f51-b878-8072e815b080,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1752493398-172.17.0.6-1598178971177:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36354,DS-c9c6f002-f188-45a4-8a6e-fb558af70300,DISK], DatanodeInfoWithStorage[127.0.0.1:41863,DS-6d161f61-3345-4168-8d8b-3d55cb95e460,DISK], DatanodeInfoWithStorage[127.0.0.1:45621,DS-bdbfafc4-9bd2-4ddc-bf26-2c62143ede18,DISK], DatanodeInfoWithStorage[127.0.0.1:41201,DS-e544d530-43ff-4540-b156-79b02a9e665d,DISK], DatanodeInfoWithStorage[127.0.0.1:40367,DS-f9ff2abf-21c4-4ea0-a6e3-f218169df05e,DISK], DatanodeInfoWithStorage[127.0.0.1:35243,DS-fc9d7c2d-0234-471e-af12-cc021eacd8e6,DISK], DatanodeInfoWithStorage[127.0.0.1:42822,DS-301535e5-1a26-4e54-8d39-c58f32c62255,DISK], DatanodeInfoWithStorage[127.0.0.1:44458,DS-24d98f0e-f6de-4f51-b878-8072e815b080,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.block-pinning.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-31896851-172.17.0.6-1598179446535:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40796,DS-7827b0a8-5c19-41bf-988b-de519f52f405,DISK], DatanodeInfoWithStorage[127.0.0.1:40079,DS-0e1d72d7-9511-4b07-9b7b-c6fe74cf6ba2,DISK], DatanodeInfoWithStorage[127.0.0.1:36135,DS-be097799-56ad-4a00-8942-6440c0869112,DISK], DatanodeInfoWithStorage[127.0.0.1:45450,DS-c329040f-21fe-4652-adfd-3879b5972bd9,DISK], DatanodeInfoWithStorage[127.0.0.1:35707,DS-55339789-fa75-4680-9052-558b5f6fa7ab,DISK], DatanodeInfoWithStorage[127.0.0.1:36763,DS-4935dd72-469a-4ce5-8dea-799b1f71d1b3,DISK], DatanodeInfoWithStorage[127.0.0.1:43261,DS-cf2824e7-9ea6-474d-9273-8655e4fc573e,DISK], DatanodeInfoWithStorage[127.0.0.1:41934,DS-07f2168b-2320-4a03-9fd6-0dcaeabbe82b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-31896851-172.17.0.6-1598179446535:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40796,DS-7827b0a8-5c19-41bf-988b-de519f52f405,DISK], DatanodeInfoWithStorage[127.0.0.1:40079,DS-0e1d72d7-9511-4b07-9b7b-c6fe74cf6ba2,DISK], DatanodeInfoWithStorage[127.0.0.1:36135,DS-be097799-56ad-4a00-8942-6440c0869112,DISK], DatanodeInfoWithStorage[127.0.0.1:45450,DS-c329040f-21fe-4652-adfd-3879b5972bd9,DISK], DatanodeInfoWithStorage[127.0.0.1:35707,DS-55339789-fa75-4680-9052-558b5f6fa7ab,DISK], DatanodeInfoWithStorage[127.0.0.1:36763,DS-4935dd72-469a-4ce5-8dea-799b1f71d1b3,DISK], DatanodeInfoWithStorage[127.0.0.1:43261,DS-cf2824e7-9ea6-474d-9273-8655e4fc573e,DISK], DatanodeInfoWithStorage[127.0.0.1:41934,DS-07f2168b-2320-4a03-9fd6-0dcaeabbe82b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.block-pinning.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-316103935-172.17.0.6-1598179518526:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43458,DS-c22d0b9b-d0ce-45b4-ada9-620335b6fd69,DISK], DatanodeInfoWithStorage[127.0.0.1:39880,DS-d5f31721-e6d1-4a74-a92d-1aa5a5277641,DISK], DatanodeInfoWithStorage[127.0.0.1:39715,DS-c0454a2f-1adc-45cb-bfb7-c6a0b5e61d20,DISK], DatanodeInfoWithStorage[127.0.0.1:40439,DS-48d1abd2-cd08-44de-bede-3f7e9a50291c,DISK], DatanodeInfoWithStorage[127.0.0.1:34698,DS-f44834ec-7ed3-4893-aaff-f98ba6fb9c82,DISK], DatanodeInfoWithStorage[127.0.0.1:35340,DS-76cea0c8-888c-44bc-9ea8-bea65a18d835,DISK], DatanodeInfoWithStorage[127.0.0.1:38476,DS-89bdfa0f-dbab-4b31-965e-a33609a36fa8,DISK], DatanodeInfoWithStorage[127.0.0.1:37283,DS-022d7cb0-1614-4aba-b61f-9b90699b54f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-316103935-172.17.0.6-1598179518526:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43458,DS-c22d0b9b-d0ce-45b4-ada9-620335b6fd69,DISK], DatanodeInfoWithStorage[127.0.0.1:39880,DS-d5f31721-e6d1-4a74-a92d-1aa5a5277641,DISK], DatanodeInfoWithStorage[127.0.0.1:39715,DS-c0454a2f-1adc-45cb-bfb7-c6a0b5e61d20,DISK], DatanodeInfoWithStorage[127.0.0.1:40439,DS-48d1abd2-cd08-44de-bede-3f7e9a50291c,DISK], DatanodeInfoWithStorage[127.0.0.1:34698,DS-f44834ec-7ed3-4893-aaff-f98ba6fb9c82,DISK], DatanodeInfoWithStorage[127.0.0.1:35340,DS-76cea0c8-888c-44bc-9ea8-bea65a18d835,DISK], DatanodeInfoWithStorage[127.0.0.1:38476,DS-89bdfa0f-dbab-4b31-965e-a33609a36fa8,DISK], DatanodeInfoWithStorage[127.0.0.1:37283,DS-022d7cb0-1614-4aba-b61f-9b90699b54f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.block-pinning.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1316604604-172.17.0.6-1598179809876:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36750,DS-73d5abff-3873-4455-ba03-913f6ce5580c,DISK], DatanodeInfoWithStorage[127.0.0.1:41598,DS-bdc5d2cf-2adb-45de-977f-0a7473950253,DISK], DatanodeInfoWithStorage[127.0.0.1:45785,DS-22278f9d-d084-4070-8c97-8e71515ca9e2,DISK], DatanodeInfoWithStorage[127.0.0.1:44627,DS-91e0bdae-7c67-4b8b-b236-0595693b3736,DISK], DatanodeInfoWithStorage[127.0.0.1:35327,DS-2c71864d-9e81-455e-a45e-5896138853b3,DISK], DatanodeInfoWithStorage[127.0.0.1:36662,DS-bbd25602-44a9-45e6-aea1-22797c44667f,DISK], DatanodeInfoWithStorage[127.0.0.1:44987,DS-0dabe4b8-bfba-44be-9f99-7a27b3f5e8d7,DISK], DatanodeInfoWithStorage[127.0.0.1:37334,DS-511973d5-c8bd-480b-890d-bc10366a7308,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1316604604-172.17.0.6-1598179809876:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36750,DS-73d5abff-3873-4455-ba03-913f6ce5580c,DISK], DatanodeInfoWithStorage[127.0.0.1:41598,DS-bdc5d2cf-2adb-45de-977f-0a7473950253,DISK], DatanodeInfoWithStorage[127.0.0.1:45785,DS-22278f9d-d084-4070-8c97-8e71515ca9e2,DISK], DatanodeInfoWithStorage[127.0.0.1:44627,DS-91e0bdae-7c67-4b8b-b236-0595693b3736,DISK], DatanodeInfoWithStorage[127.0.0.1:35327,DS-2c71864d-9e81-455e-a45e-5896138853b3,DISK], DatanodeInfoWithStorage[127.0.0.1:36662,DS-bbd25602-44a9-45e6-aea1-22797c44667f,DISK], DatanodeInfoWithStorage[127.0.0.1:44987,DS-0dabe4b8-bfba-44be-9f99-7a27b3f5e8d7,DISK], DatanodeInfoWithStorage[127.0.0.1:37334,DS-511973d5-c8bd-480b-890d-bc10366a7308,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.block-pinning.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-872498795-172.17.0.6-1598180286023:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43095,DS-a84a602a-6eaf-4e70-8a85-bd2763786f2a,DISK], DatanodeInfoWithStorage[127.0.0.1:36630,DS-92ccfabf-5291-4c31-a98a-7ee18bd4ca0d,DISK], DatanodeInfoWithStorage[127.0.0.1:35180,DS-830afddc-9409-460c-9537-5bb7662c7d78,DISK], DatanodeInfoWithStorage[127.0.0.1:40841,DS-8f761cb8-d9dc-4fbc-9bc6-dc08073b6c25,DISK], DatanodeInfoWithStorage[127.0.0.1:41258,DS-7b964fa1-c133-43ff-937d-164360eb5887,DISK], DatanodeInfoWithStorage[127.0.0.1:42303,DS-5f11e363-ed0f-4f8a-8942-1cbb478bb73a,DISK], DatanodeInfoWithStorage[127.0.0.1:40299,DS-ee2f00d9-d785-4a72-9b0d-5e4b11e95169,DISK], DatanodeInfoWithStorage[127.0.0.1:43981,DS-6b746d3e-f685-453c-b4f8-f1dbaf02d74d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-872498795-172.17.0.6-1598180286023:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43095,DS-a84a602a-6eaf-4e70-8a85-bd2763786f2a,DISK], DatanodeInfoWithStorage[127.0.0.1:36630,DS-92ccfabf-5291-4c31-a98a-7ee18bd4ca0d,DISK], DatanodeInfoWithStorage[127.0.0.1:35180,DS-830afddc-9409-460c-9537-5bb7662c7d78,DISK], DatanodeInfoWithStorage[127.0.0.1:40841,DS-8f761cb8-d9dc-4fbc-9bc6-dc08073b6c25,DISK], DatanodeInfoWithStorage[127.0.0.1:41258,DS-7b964fa1-c133-43ff-937d-164360eb5887,DISK], DatanodeInfoWithStorage[127.0.0.1:42303,DS-5f11e363-ed0f-4f8a-8942-1cbb478bb73a,DISK], DatanodeInfoWithStorage[127.0.0.1:40299,DS-ee2f00d9-d785-4a72-9b0d-5e4b11e95169,DISK], DatanodeInfoWithStorage[127.0.0.1:43981,DS-6b746d3e-f685-453c-b4f8-f1dbaf02d74d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.block-pinning.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1671104513-172.17.0.6-1598180350126:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34981,DS-0cac1c38-eb03-4d4f-8b9b-7864f7cb26bf,DISK], DatanodeInfoWithStorage[127.0.0.1:44515,DS-68fabb19-f805-409b-a7a5-96142ce1cd0f,DISK], DatanodeInfoWithStorage[127.0.0.1:36780,DS-fd9018fa-d393-417a-8119-f325a906824c,DISK], DatanodeInfoWithStorage[127.0.0.1:35965,DS-6eb54832-73bc-48db-9e1b-6640b16bdf4e,DISK], DatanodeInfoWithStorage[127.0.0.1:43577,DS-1c01c59d-89f4-4bca-bcea-96f969acd339,DISK], DatanodeInfoWithStorage[127.0.0.1:35023,DS-ec382d02-ccd9-4350-908a-450a11f65902,DISK], DatanodeInfoWithStorage[127.0.0.1:44007,DS-c97bf7a5-af27-4a6d-bc4c-97973d7f1e1a,DISK], DatanodeInfoWithStorage[127.0.0.1:44730,DS-8b554282-fbc1-42b6-825c-de70b7445a93,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1671104513-172.17.0.6-1598180350126:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34981,DS-0cac1c38-eb03-4d4f-8b9b-7864f7cb26bf,DISK], DatanodeInfoWithStorage[127.0.0.1:44515,DS-68fabb19-f805-409b-a7a5-96142ce1cd0f,DISK], DatanodeInfoWithStorage[127.0.0.1:36780,DS-fd9018fa-d393-417a-8119-f325a906824c,DISK], DatanodeInfoWithStorage[127.0.0.1:35965,DS-6eb54832-73bc-48db-9e1b-6640b16bdf4e,DISK], DatanodeInfoWithStorage[127.0.0.1:43577,DS-1c01c59d-89f4-4bca-bcea-96f969acd339,DISK], DatanodeInfoWithStorage[127.0.0.1:35023,DS-ec382d02-ccd9-4350-908a-450a11f65902,DISK], DatanodeInfoWithStorage[127.0.0.1:44007,DS-c97bf7a5-af27-4a6d-bc4c-97973d7f1e1a,DISK], DatanodeInfoWithStorage[127.0.0.1:44730,DS-8b554282-fbc1-42b6-825c-de70b7445a93,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.block-pinning.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1446715524-172.17.0.6-1598180416543:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46240,DS-75c581e0-59fb-4c57-ab59-8197b2079e14,DISK], DatanodeInfoWithStorage[127.0.0.1:34449,DS-6c7229d9-17d3-47c7-bad0-854683f5ef0e,DISK], DatanodeInfoWithStorage[127.0.0.1:45099,DS-75a7630e-01c2-4b9c-8a27-9a4fb06e7fd5,DISK], DatanodeInfoWithStorage[127.0.0.1:43203,DS-2cf893b0-037b-49fc-b06e-2c9bc9c61892,DISK], DatanodeInfoWithStorage[127.0.0.1:46504,DS-a388bb01-e476-447c-8521-20061ffdf82f,DISK], DatanodeInfoWithStorage[127.0.0.1:35924,DS-e575552b-acf4-40c4-adb5-538a18a5d556,DISK], DatanodeInfoWithStorage[127.0.0.1:45938,DS-f2c5aa16-1ff8-4f3d-85ef-3fd96afcfc35,DISK], DatanodeInfoWithStorage[127.0.0.1:37982,DS-244b5728-b3e4-4107-8929-fb6a5effadc6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1446715524-172.17.0.6-1598180416543:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46240,DS-75c581e0-59fb-4c57-ab59-8197b2079e14,DISK], DatanodeInfoWithStorage[127.0.0.1:34449,DS-6c7229d9-17d3-47c7-bad0-854683f5ef0e,DISK], DatanodeInfoWithStorage[127.0.0.1:45099,DS-75a7630e-01c2-4b9c-8a27-9a4fb06e7fd5,DISK], DatanodeInfoWithStorage[127.0.0.1:43203,DS-2cf893b0-037b-49fc-b06e-2c9bc9c61892,DISK], DatanodeInfoWithStorage[127.0.0.1:46504,DS-a388bb01-e476-447c-8521-20061ffdf82f,DISK], DatanodeInfoWithStorage[127.0.0.1:35924,DS-e575552b-acf4-40c4-adb5-538a18a5d556,DISK], DatanodeInfoWithStorage[127.0.0.1:45938,DS-f2c5aa16-1ff8-4f3d-85ef-3fd96afcfc35,DISK], DatanodeInfoWithStorage[127.0.0.1:37982,DS-244b5728-b3e4-4107-8929-fb6a5effadc6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.block-pinning.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-526719585-172.17.0.6-1598180488192:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46774,DS-82b6f4fa-8069-4a28-807c-bd3092f5dd0c,DISK], DatanodeInfoWithStorage[127.0.0.1:42495,DS-7d4fe8ac-2c52-426b-a3b7-1707e16afbc2,DISK], DatanodeInfoWithStorage[127.0.0.1:38529,DS-07acc5b8-dd7e-41e1-8e0e-d830ee408868,DISK], DatanodeInfoWithStorage[127.0.0.1:44212,DS-65fca834-0de9-440b-b781-45da6076ccda,DISK], DatanodeInfoWithStorage[127.0.0.1:35323,DS-ed07393a-f464-464d-92ed-44698bffa01b,DISK], DatanodeInfoWithStorage[127.0.0.1:38010,DS-628319bc-f5d1-4e78-ba07-28fc6b748892,DISK], DatanodeInfoWithStorage[127.0.0.1:46160,DS-408c35eb-4002-48da-a30a-5502d236f30b,DISK], DatanodeInfoWithStorage[127.0.0.1:43687,DS-b534f077-84d9-447a-83bd-01d2a15a0618,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-526719585-172.17.0.6-1598180488192:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46774,DS-82b6f4fa-8069-4a28-807c-bd3092f5dd0c,DISK], DatanodeInfoWithStorage[127.0.0.1:42495,DS-7d4fe8ac-2c52-426b-a3b7-1707e16afbc2,DISK], DatanodeInfoWithStorage[127.0.0.1:38529,DS-07acc5b8-dd7e-41e1-8e0e-d830ee408868,DISK], DatanodeInfoWithStorage[127.0.0.1:44212,DS-65fca834-0de9-440b-b781-45da6076ccda,DISK], DatanodeInfoWithStorage[127.0.0.1:35323,DS-ed07393a-f464-464d-92ed-44698bffa01b,DISK], DatanodeInfoWithStorage[127.0.0.1:38010,DS-628319bc-f5d1-4e78-ba07-28fc6b748892,DISK], DatanodeInfoWithStorage[127.0.0.1:46160,DS-408c35eb-4002-48da-a30a-5502d236f30b,DISK], DatanodeInfoWithStorage[127.0.0.1:43687,DS-b534f077-84d9-447a-83bd-01d2a15a0618,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.block-pinning.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1406860415-172.17.0.6-1598180529616:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35029,DS-74847b05-10c3-4f5b-a2b4-3a6d76dfd569,DISK], DatanodeInfoWithStorage[127.0.0.1:44668,DS-4e33389c-3b3d-438a-b0bd-1a48657e7bc1,DISK], DatanodeInfoWithStorage[127.0.0.1:43611,DS-d615462f-a186-416c-a365-cbf13f4dec30,DISK], DatanodeInfoWithStorage[127.0.0.1:41091,DS-ac9500ee-3e70-4456-a39a-b74f6fb2278a,DISK], DatanodeInfoWithStorage[127.0.0.1:40399,DS-7a39397c-8573-42c8-9f6d-1b16932e52ea,DISK], DatanodeInfoWithStorage[127.0.0.1:42704,DS-a3e82e2c-1596-4906-b448-dd8d05abae1c,DISK], DatanodeInfoWithStorage[127.0.0.1:45735,DS-d0cbed8f-9e9a-4e51-81cf-f10d764c1623,DISK], DatanodeInfoWithStorage[127.0.0.1:39499,DS-5e0dccbe-c8a2-4f01-bd20-bfa0cd2ac978,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1406860415-172.17.0.6-1598180529616:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35029,DS-74847b05-10c3-4f5b-a2b4-3a6d76dfd569,DISK], DatanodeInfoWithStorage[127.0.0.1:44668,DS-4e33389c-3b3d-438a-b0bd-1a48657e7bc1,DISK], DatanodeInfoWithStorage[127.0.0.1:43611,DS-d615462f-a186-416c-a365-cbf13f4dec30,DISK], DatanodeInfoWithStorage[127.0.0.1:41091,DS-ac9500ee-3e70-4456-a39a-b74f6fb2278a,DISK], DatanodeInfoWithStorage[127.0.0.1:40399,DS-7a39397c-8573-42c8-9f6d-1b16932e52ea,DISK], DatanodeInfoWithStorage[127.0.0.1:42704,DS-a3e82e2c-1596-4906-b448-dd8d05abae1c,DISK], DatanodeInfoWithStorage[127.0.0.1:45735,DS-d0cbed8f-9e9a-4e51-81cf-f10d764c1623,DISK], DatanodeInfoWithStorage[127.0.0.1:39499,DS-5e0dccbe-c8a2-4f01-bd20-bfa0cd2ac978,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.block-pinning.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1142971576-172.17.0.6-1598180687552:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33672,DS-83cd0a85-7e87-452c-86ab-79b234c75982,DISK], DatanodeInfoWithStorage[127.0.0.1:33357,DS-238e1f8b-dd25-4388-b99d-db6124f4dc99,DISK], DatanodeInfoWithStorage[127.0.0.1:42997,DS-ab79bfbe-c2fc-4b3f-b249-fbcdb3d864be,DISK], DatanodeInfoWithStorage[127.0.0.1:46128,DS-7b960e90-b388-4618-b65b-4f1bb0fc9c49,DISK], DatanodeInfoWithStorage[127.0.0.1:34068,DS-c1c667b5-d321-48d1-b243-d791f47d4795,DISK], DatanodeInfoWithStorage[127.0.0.1:40830,DS-cbf82cd1-3ef4-4f79-a851-f7c31d3049e9,DISK], DatanodeInfoWithStorage[127.0.0.1:38671,DS-d15abb1d-a677-4c7f-91b3-41fea654735a,DISK], DatanodeInfoWithStorage[127.0.0.1:45522,DS-949b1c1c-4dce-49e2-809d-6b15f0aaba3c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1142971576-172.17.0.6-1598180687552:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33672,DS-83cd0a85-7e87-452c-86ab-79b234c75982,DISK], DatanodeInfoWithStorage[127.0.0.1:33357,DS-238e1f8b-dd25-4388-b99d-db6124f4dc99,DISK], DatanodeInfoWithStorage[127.0.0.1:42997,DS-ab79bfbe-c2fc-4b3f-b249-fbcdb3d864be,DISK], DatanodeInfoWithStorage[127.0.0.1:46128,DS-7b960e90-b388-4618-b65b-4f1bb0fc9c49,DISK], DatanodeInfoWithStorage[127.0.0.1:34068,DS-c1c667b5-d321-48d1-b243-d791f47d4795,DISK], DatanodeInfoWithStorage[127.0.0.1:40830,DS-cbf82cd1-3ef4-4f79-a851-f7c31d3049e9,DISK], DatanodeInfoWithStorage[127.0.0.1:38671,DS-d15abb1d-a677-4c7f-91b3-41fea654735a,DISK], DatanodeInfoWithStorage[127.0.0.1:45522,DS-949b1c1c-4dce-49e2-809d-6b15f0aaba3c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.block-pinning.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1025459285-172.17.0.6-1598181726549:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40093,DS-8f95e0b1-aa17-4be8-a082-5384af533d68,DISK], DatanodeInfoWithStorage[127.0.0.1:44503,DS-bcdd50e7-1e9a-4a97-95fa-d46817902077,DISK], DatanodeInfoWithStorage[127.0.0.1:41304,DS-ed3ec937-c4e9-436f-b794-5db459ab10fc,DISK], DatanodeInfoWithStorage[127.0.0.1:43317,DS-92034a29-ccef-46b0-aab0-efdcbadef415,DISK], DatanodeInfoWithStorage[127.0.0.1:32973,DS-12b40b7d-2b7b-42d9-8d98-2af03371fa32,DISK], DatanodeInfoWithStorage[127.0.0.1:36403,DS-9848eba9-73d5-4f8d-b831-08cd02a9abe7,DISK], DatanodeInfoWithStorage[127.0.0.1:43112,DS-91d47093-76c9-4c0e-995c-32c2f67f8143,DISK], DatanodeInfoWithStorage[127.0.0.1:39875,DS-056669b4-69c8-40d7-a730-6ac6041b119d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1025459285-172.17.0.6-1598181726549:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40093,DS-8f95e0b1-aa17-4be8-a082-5384af533d68,DISK], DatanodeInfoWithStorage[127.0.0.1:44503,DS-bcdd50e7-1e9a-4a97-95fa-d46817902077,DISK], DatanodeInfoWithStorage[127.0.0.1:41304,DS-ed3ec937-c4e9-436f-b794-5db459ab10fc,DISK], DatanodeInfoWithStorage[127.0.0.1:43317,DS-92034a29-ccef-46b0-aab0-efdcbadef415,DISK], DatanodeInfoWithStorage[127.0.0.1:32973,DS-12b40b7d-2b7b-42d9-8d98-2af03371fa32,DISK], DatanodeInfoWithStorage[127.0.0.1:36403,DS-9848eba9-73d5-4f8d-b831-08cd02a9abe7,DISK], DatanodeInfoWithStorage[127.0.0.1:43112,DS-91d47093-76c9-4c0e-995c-32c2f67f8143,DISK], DatanodeInfoWithStorage[127.0.0.1:39875,DS-056669b4-69c8-40d7-a730-6ac6041b119d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.block-pinning.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-103632686-172.17.0.6-1598182194762:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38090,DS-f1eecb42-0fde-4145-b4fa-7242e6548cb8,DISK], DatanodeInfoWithStorage[127.0.0.1:46153,DS-cb4fd8cb-bd2f-4b79-9754-bcccca501010,DISK], DatanodeInfoWithStorage[127.0.0.1:35327,DS-48ca4797-a513-49a2-b5fb-3de7e8450798,DISK], DatanodeInfoWithStorage[127.0.0.1:41314,DS-622e5ff6-af09-4476-a11d-7ca879dd9d53,DISK], DatanodeInfoWithStorage[127.0.0.1:43247,DS-e5013764-50b0-4ca3-af7e-960dac4e06ee,DISK], DatanodeInfoWithStorage[127.0.0.1:42316,DS-58f1233a-0acc-4d13-9d9c-384df4110e0c,DISK], DatanodeInfoWithStorage[127.0.0.1:33861,DS-d6c8e2c9-5a01-4657-b514-ef2f7d809dbc,DISK], DatanodeInfoWithStorage[127.0.0.1:39448,DS-614346ee-f2e5-4992-bd14-3bb136afd803,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-103632686-172.17.0.6-1598182194762:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38090,DS-f1eecb42-0fde-4145-b4fa-7242e6548cb8,DISK], DatanodeInfoWithStorage[127.0.0.1:46153,DS-cb4fd8cb-bd2f-4b79-9754-bcccca501010,DISK], DatanodeInfoWithStorage[127.0.0.1:35327,DS-48ca4797-a513-49a2-b5fb-3de7e8450798,DISK], DatanodeInfoWithStorage[127.0.0.1:41314,DS-622e5ff6-af09-4476-a11d-7ca879dd9d53,DISK], DatanodeInfoWithStorage[127.0.0.1:43247,DS-e5013764-50b0-4ca3-af7e-960dac4e06ee,DISK], DatanodeInfoWithStorage[127.0.0.1:42316,DS-58f1233a-0acc-4d13-9d9c-384df4110e0c,DISK], DatanodeInfoWithStorage[127.0.0.1:33861,DS-d6c8e2c9-5a01-4657-b514-ef2f7d809dbc,DISK], DatanodeInfoWithStorage[127.0.0.1:39448,DS-614346ee-f2e5-4992-bd14-3bb136afd803,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.block-pinning.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-759797526-172.17.0.6-1598182395123:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34070,DS-f7736348-f5d2-4e74-9b71-3b89208b5022,DISK], DatanodeInfoWithStorage[127.0.0.1:33066,DS-2a237d4d-b38e-4617-a00e-85c8e60098b9,DISK], DatanodeInfoWithStorage[127.0.0.1:33099,DS-59628dc2-11ad-4871-a644-eec970c82a62,DISK], DatanodeInfoWithStorage[127.0.0.1:40155,DS-fd3c7cb1-006b-464e-b80a-f60a7da3d24d,DISK], DatanodeInfoWithStorage[127.0.0.1:46292,DS-334afee6-d68a-4bae-a646-269ae1ceb955,DISK], DatanodeInfoWithStorage[127.0.0.1:46635,DS-be6e75d8-a88f-4854-99ab-6787ec01b314,DISK], DatanodeInfoWithStorage[127.0.0.1:33018,DS-3d3bc323-6319-436b-9fc9-ce5ac679da86,DISK], DatanodeInfoWithStorage[127.0.0.1:36221,DS-ea38a500-ee0f-43ef-a6c9-ce5d14f9a54a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-759797526-172.17.0.6-1598182395123:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34070,DS-f7736348-f5d2-4e74-9b71-3b89208b5022,DISK], DatanodeInfoWithStorage[127.0.0.1:33066,DS-2a237d4d-b38e-4617-a00e-85c8e60098b9,DISK], DatanodeInfoWithStorage[127.0.0.1:33099,DS-59628dc2-11ad-4871-a644-eec970c82a62,DISK], DatanodeInfoWithStorage[127.0.0.1:40155,DS-fd3c7cb1-006b-464e-b80a-f60a7da3d24d,DISK], DatanodeInfoWithStorage[127.0.0.1:46292,DS-334afee6-d68a-4bae-a646-269ae1ceb955,DISK], DatanodeInfoWithStorage[127.0.0.1:46635,DS-be6e75d8-a88f-4854-99ab-6787ec01b314,DISK], DatanodeInfoWithStorage[127.0.0.1:33018,DS-3d3bc323-6319-436b-9fc9-ce5ac679da86,DISK], DatanodeInfoWithStorage[127.0.0.1:36221,DS-ea38a500-ee0f-43ef-a6c9-ce5d14f9a54a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.block-pinning.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1658211005-172.17.0.6-1598182486821:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44993,DS-b346f583-43a0-44c6-9914-a7e33ce8f52d,DISK], DatanodeInfoWithStorage[127.0.0.1:42238,DS-61dd1c7e-c3a5-4ce9-b065-ea14b433603d,DISK], DatanodeInfoWithStorage[127.0.0.1:35524,DS-d32f54ac-76c2-42e8-97f3-ef9a27de9e3e,DISK], DatanodeInfoWithStorage[127.0.0.1:37650,DS-6c0c83f9-8b2c-4a69-b50a-eb8e8b8b1772,DISK], DatanodeInfoWithStorage[127.0.0.1:46862,DS-48dc50ab-cd08-4c1e-a1f3-fde3823e7a9d,DISK], DatanodeInfoWithStorage[127.0.0.1:45992,DS-ddb17fe9-e1be-4501-80d0-569e4f902bff,DISK], DatanodeInfoWithStorage[127.0.0.1:46170,DS-f0d9704a-e78e-42e3-bce1-d8e812a3e4eb,DISK], DatanodeInfoWithStorage[127.0.0.1:46727,DS-ea5fc7df-1d9d-4ca7-8587-9239b455a422,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1658211005-172.17.0.6-1598182486821:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44993,DS-b346f583-43a0-44c6-9914-a7e33ce8f52d,DISK], DatanodeInfoWithStorage[127.0.0.1:42238,DS-61dd1c7e-c3a5-4ce9-b065-ea14b433603d,DISK], DatanodeInfoWithStorage[127.0.0.1:35524,DS-d32f54ac-76c2-42e8-97f3-ef9a27de9e3e,DISK], DatanodeInfoWithStorage[127.0.0.1:37650,DS-6c0c83f9-8b2c-4a69-b50a-eb8e8b8b1772,DISK], DatanodeInfoWithStorage[127.0.0.1:46862,DS-48dc50ab-cd08-4c1e-a1f3-fde3823e7a9d,DISK], DatanodeInfoWithStorage[127.0.0.1:45992,DS-ddb17fe9-e1be-4501-80d0-569e4f902bff,DISK], DatanodeInfoWithStorage[127.0.0.1:46170,DS-f0d9704a-e78e-42e3-bce1-d8e812a3e4eb,DISK], DatanodeInfoWithStorage[127.0.0.1:46727,DS-ea5fc7df-1d9d-4ca7-8587-9239b455a422,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 5386
