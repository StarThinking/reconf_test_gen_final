reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1232086257-172.17.0.7-1598464683950:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40356,DS-33bb2ef1-64a6-41f5-9118-8dc7d6086faa,DISK], DatanodeInfoWithStorage[127.0.0.1:39353,DS-a53f8ff7-8e3a-4a94-b113-0771ec669554,DISK], DatanodeInfoWithStorage[127.0.0.1:41975,DS-aa442af6-f8d9-4071-b25a-0928362717db,DISK], DatanodeInfoWithStorage[127.0.0.1:36559,DS-3534e976-7d3e-446c-810b-425cdd966746,DISK], DatanodeInfoWithStorage[127.0.0.1:40494,DS-c6625aa0-8d87-43e0-9d1a-a9b067baf60c,DISK], DatanodeInfoWithStorage[127.0.0.1:37148,DS-3cc55d16-7da3-4d1f-89ec-7ac772db88b9,DISK], DatanodeInfoWithStorage[127.0.0.1:41767,DS-1c45c6ea-13b4-4209-aaf3-1bb95c21348e,DISK], DatanodeInfoWithStorage[127.0.0.1:39328,DS-4f0fb9fb-4c03-4502-b584-74ae80e14525,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1232086257-172.17.0.7-1598464683950:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40356,DS-33bb2ef1-64a6-41f5-9118-8dc7d6086faa,DISK], DatanodeInfoWithStorage[127.0.0.1:39353,DS-a53f8ff7-8e3a-4a94-b113-0771ec669554,DISK], DatanodeInfoWithStorage[127.0.0.1:41975,DS-aa442af6-f8d9-4071-b25a-0928362717db,DISK], DatanodeInfoWithStorage[127.0.0.1:36559,DS-3534e976-7d3e-446c-810b-425cdd966746,DISK], DatanodeInfoWithStorage[127.0.0.1:40494,DS-c6625aa0-8d87-43e0-9d1a-a9b067baf60c,DISK], DatanodeInfoWithStorage[127.0.0.1:37148,DS-3cc55d16-7da3-4d1f-89ec-7ac772db88b9,DISK], DatanodeInfoWithStorage[127.0.0.1:41767,DS-1c45c6ea-13b4-4209-aaf3-1bb95c21348e,DISK], DatanodeInfoWithStorage[127.0.0.1:39328,DS-4f0fb9fb-4c03-4502-b584-74ae80e14525,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1338016997-172.17.0.7-1598465021098:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36660,DS-5ed83dcd-3166-41ab-a2fa-d1db5e610bd0,DISK], DatanodeInfoWithStorage[127.0.0.1:39771,DS-8cbc0258-8ea9-4ae5-a5a3-02baa0654441,DISK], DatanodeInfoWithStorage[127.0.0.1:34412,DS-4d3cfab6-0948-490c-9c25-688a34163e2a,DISK], DatanodeInfoWithStorage[127.0.0.1:40281,DS-005c7ca8-e18c-4ad5-a0be-d3ad0d57c0b9,DISK], DatanodeInfoWithStorage[127.0.0.1:36861,DS-0e5ae566-402c-475f-9464-48ffe4bbb2be,DISK], DatanodeInfoWithStorage[127.0.0.1:41875,DS-08199b1d-b258-48bf-b4c4-4593748487fd,DISK], DatanodeInfoWithStorage[127.0.0.1:41286,DS-d777fba5-103a-4f85-a47a-b3b5801c783e,DISK], DatanodeInfoWithStorage[127.0.0.1:35366,DS-530bf20e-474d-449e-a116-ec651dcd3c9b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1338016997-172.17.0.7-1598465021098:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36660,DS-5ed83dcd-3166-41ab-a2fa-d1db5e610bd0,DISK], DatanodeInfoWithStorage[127.0.0.1:39771,DS-8cbc0258-8ea9-4ae5-a5a3-02baa0654441,DISK], DatanodeInfoWithStorage[127.0.0.1:34412,DS-4d3cfab6-0948-490c-9c25-688a34163e2a,DISK], DatanodeInfoWithStorage[127.0.0.1:40281,DS-005c7ca8-e18c-4ad5-a0be-d3ad0d57c0b9,DISK], DatanodeInfoWithStorage[127.0.0.1:36861,DS-0e5ae566-402c-475f-9464-48ffe4bbb2be,DISK], DatanodeInfoWithStorage[127.0.0.1:41875,DS-08199b1d-b258-48bf-b4c4-4593748487fd,DISK], DatanodeInfoWithStorage[127.0.0.1:41286,DS-d777fba5-103a-4f85-a47a-b3b5801c783e,DISK], DatanodeInfoWithStorage[127.0.0.1:35366,DS-530bf20e-474d-449e-a116-ec651dcd3c9b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1817095524-172.17.0.7-1598465247120:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34162,DS-25bc81e2-1235-4ca0-adb9-5ef07a0ca0a6,DISK], DatanodeInfoWithStorage[127.0.0.1:39215,DS-c7ee36a9-5ab0-4d91-b304-df1f2600eee6,DISK], DatanodeInfoWithStorage[127.0.0.1:38512,DS-c78a9e97-7e69-4972-949c-694e747e775f,DISK], DatanodeInfoWithStorage[127.0.0.1:42511,DS-55088f26-8b3c-429d-8586-e3c803e51089,DISK], DatanodeInfoWithStorage[127.0.0.1:44133,DS-34bd678a-976c-4ded-b83e-12151e3c7147,DISK], DatanodeInfoWithStorage[127.0.0.1:39550,DS-e5943a99-2ea7-4316-b085-e9a2376c191f,DISK], DatanodeInfoWithStorage[127.0.0.1:34418,DS-f698732e-9ba9-426f-8fd1-f8fa7f63cca5,DISK], DatanodeInfoWithStorage[127.0.0.1:38426,DS-15209b41-817a-4426-80d2-5dbcd27eec1c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1817095524-172.17.0.7-1598465247120:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34162,DS-25bc81e2-1235-4ca0-adb9-5ef07a0ca0a6,DISK], DatanodeInfoWithStorage[127.0.0.1:39215,DS-c7ee36a9-5ab0-4d91-b304-df1f2600eee6,DISK], DatanodeInfoWithStorage[127.0.0.1:38512,DS-c78a9e97-7e69-4972-949c-694e747e775f,DISK], DatanodeInfoWithStorage[127.0.0.1:42511,DS-55088f26-8b3c-429d-8586-e3c803e51089,DISK], DatanodeInfoWithStorage[127.0.0.1:44133,DS-34bd678a-976c-4ded-b83e-12151e3c7147,DISK], DatanodeInfoWithStorage[127.0.0.1:39550,DS-e5943a99-2ea7-4316-b085-e9a2376c191f,DISK], DatanodeInfoWithStorage[127.0.0.1:34418,DS-f698732e-9ba9-426f-8fd1-f8fa7f63cca5,DISK], DatanodeInfoWithStorage[127.0.0.1:38426,DS-15209b41-817a-4426-80d2-5dbcd27eec1c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-822189954-172.17.0.7-1598465796561:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38611,DS-94d6cf1b-0c99-47d5-8bbf-33f185fef967,DISK], DatanodeInfoWithStorage[127.0.0.1:43158,DS-fdf659be-dd74-4b89-b0d9-8208960008bb,DISK], DatanodeInfoWithStorage[127.0.0.1:45819,DS-ea795c90-22b7-420f-8e76-0070b0942d02,DISK], DatanodeInfoWithStorage[127.0.0.1:41673,DS-6f03af03-8bfd-4f07-bb2d-87f0e48d45b5,DISK], DatanodeInfoWithStorage[127.0.0.1:35017,DS-074a38c7-16b0-4060-a958-0337c6c9bbfe,DISK], DatanodeInfoWithStorage[127.0.0.1:35485,DS-a416ba8d-2508-4d57-9a55-56b820af2111,DISK], DatanodeInfoWithStorage[127.0.0.1:38854,DS-317d6fe1-c12c-4951-8103-751b7a0d7052,DISK], DatanodeInfoWithStorage[127.0.0.1:40618,DS-31df4f00-cbd2-4093-8d63-8d30073881a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-822189954-172.17.0.7-1598465796561:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38611,DS-94d6cf1b-0c99-47d5-8bbf-33f185fef967,DISK], DatanodeInfoWithStorage[127.0.0.1:43158,DS-fdf659be-dd74-4b89-b0d9-8208960008bb,DISK], DatanodeInfoWithStorage[127.0.0.1:45819,DS-ea795c90-22b7-420f-8e76-0070b0942d02,DISK], DatanodeInfoWithStorage[127.0.0.1:41673,DS-6f03af03-8bfd-4f07-bb2d-87f0e48d45b5,DISK], DatanodeInfoWithStorage[127.0.0.1:35017,DS-074a38c7-16b0-4060-a958-0337c6c9bbfe,DISK], DatanodeInfoWithStorage[127.0.0.1:35485,DS-a416ba8d-2508-4d57-9a55-56b820af2111,DISK], DatanodeInfoWithStorage[127.0.0.1:38854,DS-317d6fe1-c12c-4951-8103-751b7a0d7052,DISK], DatanodeInfoWithStorage[127.0.0.1:40618,DS-31df4f00-cbd2-4093-8d63-8d30073881a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1813011953-172.17.0.7-1598465939683:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36609,DS-a0c4f13b-b9d7-44dc-80ff-dfbf8ec0970d,DISK], DatanodeInfoWithStorage[127.0.0.1:43809,DS-da7bba5f-a644-4bb7-8e4b-01c67df291fe,DISK], DatanodeInfoWithStorage[127.0.0.1:40736,DS-b37b54b9-a747-4fdb-b163-dcf8d4a6a9cc,DISK], DatanodeInfoWithStorage[127.0.0.1:34583,DS-c516db4d-9140-462e-bfe9-c4b2b83d1481,DISK], DatanodeInfoWithStorage[127.0.0.1:45468,DS-2b1a7221-56b0-4c7c-8d5a-6a8fe2764aa2,DISK], DatanodeInfoWithStorage[127.0.0.1:33035,DS-5f70e832-53e8-46ab-b051-2f033b7e76f2,DISK], DatanodeInfoWithStorage[127.0.0.1:34299,DS-675010f7-5408-49e9-ab74-022fa999ba60,DISK], DatanodeInfoWithStorage[127.0.0.1:38965,DS-b1675bdb-3ee0-43e4-96e5-15f2cff31e94,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1813011953-172.17.0.7-1598465939683:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36609,DS-a0c4f13b-b9d7-44dc-80ff-dfbf8ec0970d,DISK], DatanodeInfoWithStorage[127.0.0.1:43809,DS-da7bba5f-a644-4bb7-8e4b-01c67df291fe,DISK], DatanodeInfoWithStorage[127.0.0.1:40736,DS-b37b54b9-a747-4fdb-b163-dcf8d4a6a9cc,DISK], DatanodeInfoWithStorage[127.0.0.1:34583,DS-c516db4d-9140-462e-bfe9-c4b2b83d1481,DISK], DatanodeInfoWithStorage[127.0.0.1:45468,DS-2b1a7221-56b0-4c7c-8d5a-6a8fe2764aa2,DISK], DatanodeInfoWithStorage[127.0.0.1:33035,DS-5f70e832-53e8-46ab-b051-2f033b7e76f2,DISK], DatanodeInfoWithStorage[127.0.0.1:34299,DS-675010f7-5408-49e9-ab74-022fa999ba60,DISK], DatanodeInfoWithStorage[127.0.0.1:38965,DS-b1675bdb-3ee0-43e4-96e5-15f2cff31e94,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-508798262-172.17.0.7-1598466370310:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44376,DS-a6d6d51e-3813-4078-96b4-00bcae0ff89f,DISK], DatanodeInfoWithStorage[127.0.0.1:39306,DS-77f535d3-8607-4335-8a21-9b34ddbcfd31,DISK], DatanodeInfoWithStorage[127.0.0.1:44936,DS-3965574c-90f6-4d39-83f1-84005c39ee69,DISK], DatanodeInfoWithStorage[127.0.0.1:37565,DS-79f4eee4-3fd7-4cf7-b735-09d745be10f3,DISK], DatanodeInfoWithStorage[127.0.0.1:40554,DS-8896dc5e-f976-48f1-a869-a46ccdada962,DISK], DatanodeInfoWithStorage[127.0.0.1:34066,DS-1579f724-6f14-4b64-8640-893e4c41a866,DISK], DatanodeInfoWithStorage[127.0.0.1:40002,DS-4b9e701b-548d-4811-aca3-e9090c29ded8,DISK], DatanodeInfoWithStorage[127.0.0.1:35085,DS-c63f11f7-7a33-4f6f-9243-56a9c549be08,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-508798262-172.17.0.7-1598466370310:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44376,DS-a6d6d51e-3813-4078-96b4-00bcae0ff89f,DISK], DatanodeInfoWithStorage[127.0.0.1:39306,DS-77f535d3-8607-4335-8a21-9b34ddbcfd31,DISK], DatanodeInfoWithStorage[127.0.0.1:44936,DS-3965574c-90f6-4d39-83f1-84005c39ee69,DISK], DatanodeInfoWithStorage[127.0.0.1:37565,DS-79f4eee4-3fd7-4cf7-b735-09d745be10f3,DISK], DatanodeInfoWithStorage[127.0.0.1:40554,DS-8896dc5e-f976-48f1-a869-a46ccdada962,DISK], DatanodeInfoWithStorage[127.0.0.1:34066,DS-1579f724-6f14-4b64-8640-893e4c41a866,DISK], DatanodeInfoWithStorage[127.0.0.1:40002,DS-4b9e701b-548d-4811-aca3-e9090c29ded8,DISK], DatanodeInfoWithStorage[127.0.0.1:35085,DS-c63f11f7-7a33-4f6f-9243-56a9c549be08,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1760320221-172.17.0.7-1598466892641:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37576,DS-7e180fdd-1dff-4cdb-ae17-3b59ee0ca2a4,DISK], DatanodeInfoWithStorage[127.0.0.1:37677,DS-90386d64-96f4-4426-b51d-2516ca74fb42,DISK], DatanodeInfoWithStorage[127.0.0.1:42950,DS-7e3314f0-a13e-4dd8-9118-9695dd2fd6c4,DISK], DatanodeInfoWithStorage[127.0.0.1:46135,DS-7dd19eae-429e-4382-9706-1c4ea079e124,DISK], DatanodeInfoWithStorage[127.0.0.1:33363,DS-7d5ffb84-3477-4b53-8a0a-d40b5cef10eb,DISK], DatanodeInfoWithStorage[127.0.0.1:42913,DS-09dbd78a-9f5c-4cea-9073-ad2925efdeed,DISK], DatanodeInfoWithStorage[127.0.0.1:43622,DS-3f9a527e-3762-4ae3-8177-831914ae9d31,DISK], DatanodeInfoWithStorage[127.0.0.1:35173,DS-4a46e37b-2fde-4d98-8968-829f59dbb651,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1760320221-172.17.0.7-1598466892641:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37576,DS-7e180fdd-1dff-4cdb-ae17-3b59ee0ca2a4,DISK], DatanodeInfoWithStorage[127.0.0.1:37677,DS-90386d64-96f4-4426-b51d-2516ca74fb42,DISK], DatanodeInfoWithStorage[127.0.0.1:42950,DS-7e3314f0-a13e-4dd8-9118-9695dd2fd6c4,DISK], DatanodeInfoWithStorage[127.0.0.1:46135,DS-7dd19eae-429e-4382-9706-1c4ea079e124,DISK], DatanodeInfoWithStorage[127.0.0.1:33363,DS-7d5ffb84-3477-4b53-8a0a-d40b5cef10eb,DISK], DatanodeInfoWithStorage[127.0.0.1:42913,DS-09dbd78a-9f5c-4cea-9073-ad2925efdeed,DISK], DatanodeInfoWithStorage[127.0.0.1:43622,DS-3f9a527e-3762-4ae3-8177-831914ae9d31,DISK], DatanodeInfoWithStorage[127.0.0.1:35173,DS-4a46e37b-2fde-4d98-8968-829f59dbb651,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-161512325-172.17.0.7-1598467209773:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44387,DS-ad3a8639-df0b-45ba-b6fc-fc4f5d1f90ba,DISK], DatanodeInfoWithStorage[127.0.0.1:44142,DS-5a6a7d14-fa81-433d-b5ed-6f0ddf2120af,DISK], DatanodeInfoWithStorage[127.0.0.1:40046,DS-52e4d4ee-e144-4f00-b280-c143a355d8aa,DISK], DatanodeInfoWithStorage[127.0.0.1:34883,DS-44c80b44-0f10-4294-a9cc-e5f7c021f8ef,DISK], DatanodeInfoWithStorage[127.0.0.1:44207,DS-6f9e6a72-c63d-4ba3-9bf8-29dd4eb818a7,DISK], DatanodeInfoWithStorage[127.0.0.1:33009,DS-2e877e79-00fa-4bef-9afe-ebe956d3da1c,DISK], DatanodeInfoWithStorage[127.0.0.1:40342,DS-65f38220-624c-448f-be9d-0a887a0cd368,DISK], DatanodeInfoWithStorage[127.0.0.1:40491,DS-cbe98aa2-2c6f-4235-897d-7383fb4729ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-161512325-172.17.0.7-1598467209773:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44387,DS-ad3a8639-df0b-45ba-b6fc-fc4f5d1f90ba,DISK], DatanodeInfoWithStorage[127.0.0.1:44142,DS-5a6a7d14-fa81-433d-b5ed-6f0ddf2120af,DISK], DatanodeInfoWithStorage[127.0.0.1:40046,DS-52e4d4ee-e144-4f00-b280-c143a355d8aa,DISK], DatanodeInfoWithStorage[127.0.0.1:34883,DS-44c80b44-0f10-4294-a9cc-e5f7c021f8ef,DISK], DatanodeInfoWithStorage[127.0.0.1:44207,DS-6f9e6a72-c63d-4ba3-9bf8-29dd4eb818a7,DISK], DatanodeInfoWithStorage[127.0.0.1:33009,DS-2e877e79-00fa-4bef-9afe-ebe956d3da1c,DISK], DatanodeInfoWithStorage[127.0.0.1:40342,DS-65f38220-624c-448f-be9d-0a887a0cd368,DISK], DatanodeInfoWithStorage[127.0.0.1:40491,DS-cbe98aa2-2c6f-4235-897d-7383fb4729ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-506460472-172.17.0.7-1598467487951:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45807,DS-40d07fbf-de62-490e-9bea-b1dd23870958,DISK], DatanodeInfoWithStorage[127.0.0.1:38289,DS-6ead121f-2015-46f2-9f82-c5989faf9ace,DISK], DatanodeInfoWithStorage[127.0.0.1:38843,DS-2d0c8e54-11a6-41cf-a8ca-4202ae129ac1,DISK], DatanodeInfoWithStorage[127.0.0.1:34665,DS-ffe6936e-9dff-470f-87da-a62ccf820c17,DISK], DatanodeInfoWithStorage[127.0.0.1:40980,DS-943f6c73-c973-43f8-ae56-02c4bc7f415b,DISK], DatanodeInfoWithStorage[127.0.0.1:32872,DS-b526fa39-e3a5-4c95-aa79-49c25601298b,DISK], DatanodeInfoWithStorage[127.0.0.1:43964,DS-4584b123-a265-49b7-8541-a6c73da3cbaf,DISK], DatanodeInfoWithStorage[127.0.0.1:35921,DS-27b0b400-adad-49e3-a0fa-b283870f9aae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-506460472-172.17.0.7-1598467487951:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45807,DS-40d07fbf-de62-490e-9bea-b1dd23870958,DISK], DatanodeInfoWithStorage[127.0.0.1:38289,DS-6ead121f-2015-46f2-9f82-c5989faf9ace,DISK], DatanodeInfoWithStorage[127.0.0.1:38843,DS-2d0c8e54-11a6-41cf-a8ca-4202ae129ac1,DISK], DatanodeInfoWithStorage[127.0.0.1:34665,DS-ffe6936e-9dff-470f-87da-a62ccf820c17,DISK], DatanodeInfoWithStorage[127.0.0.1:40980,DS-943f6c73-c973-43f8-ae56-02c4bc7f415b,DISK], DatanodeInfoWithStorage[127.0.0.1:32872,DS-b526fa39-e3a5-4c95-aa79-49c25601298b,DISK], DatanodeInfoWithStorage[127.0.0.1:43964,DS-4584b123-a265-49b7-8541-a6c73da3cbaf,DISK], DatanodeInfoWithStorage[127.0.0.1:35921,DS-27b0b400-adad-49e3-a0fa-b283870f9aae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1305553016-172.17.0.7-1598468663623:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41664,DS-1fbdc601-889d-4d69-a26f-8b424f50e34d,DISK], DatanodeInfoWithStorage[127.0.0.1:35762,DS-fdd3c1fe-2af3-4571-a1ff-3fd887befd10,DISK], DatanodeInfoWithStorage[127.0.0.1:46337,DS-99af0f6d-b1df-4c7d-81b3-c8cd688de49a,DISK], DatanodeInfoWithStorage[127.0.0.1:36939,DS-bcff57d0-b30b-43bc-bfe5-c025fe2d551c,DISK], DatanodeInfoWithStorage[127.0.0.1:38445,DS-4291ff0e-8d8e-4b97-990b-6f731bd815fb,DISK], DatanodeInfoWithStorage[127.0.0.1:33297,DS-56f820e1-8d94-4b67-9f30-52e409019994,DISK], DatanodeInfoWithStorage[127.0.0.1:45239,DS-1ea3381e-8c3c-47eb-8dc0-f5e2f8bc931f,DISK], DatanodeInfoWithStorage[127.0.0.1:35102,DS-34507630-3238-4024-a511-2b566a5ecfdb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1305553016-172.17.0.7-1598468663623:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41664,DS-1fbdc601-889d-4d69-a26f-8b424f50e34d,DISK], DatanodeInfoWithStorage[127.0.0.1:35762,DS-fdd3c1fe-2af3-4571-a1ff-3fd887befd10,DISK], DatanodeInfoWithStorage[127.0.0.1:46337,DS-99af0f6d-b1df-4c7d-81b3-c8cd688de49a,DISK], DatanodeInfoWithStorage[127.0.0.1:36939,DS-bcff57d0-b30b-43bc-bfe5-c025fe2d551c,DISK], DatanodeInfoWithStorage[127.0.0.1:38445,DS-4291ff0e-8d8e-4b97-990b-6f731bd815fb,DISK], DatanodeInfoWithStorage[127.0.0.1:33297,DS-56f820e1-8d94-4b67-9f30-52e409019994,DISK], DatanodeInfoWithStorage[127.0.0.1:45239,DS-1ea3381e-8c3c-47eb-8dc0-f5e2f8bc931f,DISK], DatanodeInfoWithStorage[127.0.0.1:35102,DS-34507630-3238-4024-a511-2b566a5ecfdb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-476031812-172.17.0.7-1598468879541:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38903,DS-7280a458-9e3d-43ff-b8b5-dd1be510a12c,DISK], DatanodeInfoWithStorage[127.0.0.1:35705,DS-7afab96f-441c-4838-b9e8-a64678958f03,DISK], DatanodeInfoWithStorage[127.0.0.1:42819,DS-673a3bb3-81aa-482b-95c0-5f47382336bd,DISK], DatanodeInfoWithStorage[127.0.0.1:45291,DS-712b8fde-b95e-4b1d-8461-6ece87b89c4b,DISK], DatanodeInfoWithStorage[127.0.0.1:43104,DS-4c26d869-b56f-491f-998e-cb7751bf0a1b,DISK], DatanodeInfoWithStorage[127.0.0.1:38049,DS-98035cb4-8aa1-4bbf-af82-ef0ceda900ca,DISK], DatanodeInfoWithStorage[127.0.0.1:40693,DS-dbab2145-016a-427c-82cc-7d8539ca20d3,DISK], DatanodeInfoWithStorage[127.0.0.1:35129,DS-33b8ff0c-f877-46e6-9086-43e0623900a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-476031812-172.17.0.7-1598468879541:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38903,DS-7280a458-9e3d-43ff-b8b5-dd1be510a12c,DISK], DatanodeInfoWithStorage[127.0.0.1:35705,DS-7afab96f-441c-4838-b9e8-a64678958f03,DISK], DatanodeInfoWithStorage[127.0.0.1:42819,DS-673a3bb3-81aa-482b-95c0-5f47382336bd,DISK], DatanodeInfoWithStorage[127.0.0.1:45291,DS-712b8fde-b95e-4b1d-8461-6ece87b89c4b,DISK], DatanodeInfoWithStorage[127.0.0.1:43104,DS-4c26d869-b56f-491f-998e-cb7751bf0a1b,DISK], DatanodeInfoWithStorage[127.0.0.1:38049,DS-98035cb4-8aa1-4bbf-af82-ef0ceda900ca,DISK], DatanodeInfoWithStorage[127.0.0.1:40693,DS-dbab2145-016a-427c-82cc-7d8539ca20d3,DISK], DatanodeInfoWithStorage[127.0.0.1:35129,DS-33b8ff0c-f877-46e6-9086-43e0623900a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-81615312-172.17.0.7-1598468897073:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44887,DS-1d69e73a-bc15-449d-9be3-202d2c17f6cf,DISK], DatanodeInfoWithStorage[127.0.0.1:35000,DS-a1d73de8-c120-49ca-a13e-f96381e1326b,DISK], DatanodeInfoWithStorage[127.0.0.1:39503,DS-bd6670b7-755f-4d87-94c6-6cd49d8d09fb,DISK], DatanodeInfoWithStorage[127.0.0.1:34641,DS-496152b3-fddf-4d40-a315-bce070cc84fd,DISK], DatanodeInfoWithStorage[127.0.0.1:33249,DS-d6859d85-ad9f-4480-9fa3-a3c388acce6b,DISK], DatanodeInfoWithStorage[127.0.0.1:36930,DS-defa51de-09c6-4a92-b592-eac567dd2abf,DISK], DatanodeInfoWithStorage[127.0.0.1:36680,DS-76e845be-4aec-4899-93ae-a4e26d352e40,DISK], DatanodeInfoWithStorage[127.0.0.1:35694,DS-be10fc02-8085-421c-a52d-86ab8b981cdc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-81615312-172.17.0.7-1598468897073:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44887,DS-1d69e73a-bc15-449d-9be3-202d2c17f6cf,DISK], DatanodeInfoWithStorage[127.0.0.1:35000,DS-a1d73de8-c120-49ca-a13e-f96381e1326b,DISK], DatanodeInfoWithStorage[127.0.0.1:39503,DS-bd6670b7-755f-4d87-94c6-6cd49d8d09fb,DISK], DatanodeInfoWithStorage[127.0.0.1:34641,DS-496152b3-fddf-4d40-a315-bce070cc84fd,DISK], DatanodeInfoWithStorage[127.0.0.1:33249,DS-d6859d85-ad9f-4480-9fa3-a3c388acce6b,DISK], DatanodeInfoWithStorage[127.0.0.1:36930,DS-defa51de-09c6-4a92-b592-eac567dd2abf,DISK], DatanodeInfoWithStorage[127.0.0.1:36680,DS-76e845be-4aec-4899-93ae-a4e26d352e40,DISK], DatanodeInfoWithStorage[127.0.0.1:35694,DS-be10fc02-8085-421c-a52d-86ab8b981cdc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2014106318-172.17.0.7-1598469026841:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42903,DS-9f07d966-6a2f-4c15-b36c-8d82def4ca60,DISK], DatanodeInfoWithStorage[127.0.0.1:45320,DS-149858a2-838b-422b-a994-35435ef60f45,DISK], DatanodeInfoWithStorage[127.0.0.1:43994,DS-2f06686d-eb59-4363-9f1c-c69caff76a1f,DISK], DatanodeInfoWithStorage[127.0.0.1:34153,DS-62f80280-9db5-46d3-9b9d-fee5bbed91a5,DISK], DatanodeInfoWithStorage[127.0.0.1:39550,DS-d626364c-2fc0-42b9-bd90-9a0709e41339,DISK], DatanodeInfoWithStorage[127.0.0.1:46519,DS-e9d8b783-52b8-4801-ab82-3698dbe5ff13,DISK], DatanodeInfoWithStorage[127.0.0.1:40888,DS-c67ea6cf-c4f7-4db3-9afc-ed2b6b664e5c,DISK], DatanodeInfoWithStorage[127.0.0.1:39285,DS-421b2a57-2df3-4301-bd37-047ef0bba060,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2014106318-172.17.0.7-1598469026841:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42903,DS-9f07d966-6a2f-4c15-b36c-8d82def4ca60,DISK], DatanodeInfoWithStorage[127.0.0.1:45320,DS-149858a2-838b-422b-a994-35435ef60f45,DISK], DatanodeInfoWithStorage[127.0.0.1:43994,DS-2f06686d-eb59-4363-9f1c-c69caff76a1f,DISK], DatanodeInfoWithStorage[127.0.0.1:34153,DS-62f80280-9db5-46d3-9b9d-fee5bbed91a5,DISK], DatanodeInfoWithStorage[127.0.0.1:39550,DS-d626364c-2fc0-42b9-bd90-9a0709e41339,DISK], DatanodeInfoWithStorage[127.0.0.1:46519,DS-e9d8b783-52b8-4801-ab82-3698dbe5ff13,DISK], DatanodeInfoWithStorage[127.0.0.1:40888,DS-c67ea6cf-c4f7-4db3-9afc-ed2b6b664e5c,DISK], DatanodeInfoWithStorage[127.0.0.1:39285,DS-421b2a57-2df3-4301-bd37-047ef0bba060,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1506567938-172.17.0.7-1598469092225:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36272,DS-ab0b6051-913f-49e2-afa2-037a70859c71,DISK], DatanodeInfoWithStorage[127.0.0.1:38998,DS-cf17d7c0-e5d2-4dd3-80bb-eac622b54db7,DISK], DatanodeInfoWithStorage[127.0.0.1:42593,DS-1fe31c8a-982c-43ee-811a-373ff3e64e77,DISK], DatanodeInfoWithStorage[127.0.0.1:37216,DS-bb5b7138-b749-4b3e-841a-89b57e849d25,DISK], DatanodeInfoWithStorage[127.0.0.1:44335,DS-12efe1c8-40f1-4aa9-88d0-5925f6e829b8,DISK], DatanodeInfoWithStorage[127.0.0.1:44255,DS-cbbb037e-eef8-48c6-8591-22c64ce37db3,DISK], DatanodeInfoWithStorage[127.0.0.1:44065,DS-05097315-d7b5-41e3-8d08-1b68e8890351,DISK], DatanodeInfoWithStorage[127.0.0.1:41331,DS-916351a4-c2ce-4bce-85f3-58abe7c1fae4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1506567938-172.17.0.7-1598469092225:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36272,DS-ab0b6051-913f-49e2-afa2-037a70859c71,DISK], DatanodeInfoWithStorage[127.0.0.1:38998,DS-cf17d7c0-e5d2-4dd3-80bb-eac622b54db7,DISK], DatanodeInfoWithStorage[127.0.0.1:42593,DS-1fe31c8a-982c-43ee-811a-373ff3e64e77,DISK], DatanodeInfoWithStorage[127.0.0.1:37216,DS-bb5b7138-b749-4b3e-841a-89b57e849d25,DISK], DatanodeInfoWithStorage[127.0.0.1:44335,DS-12efe1c8-40f1-4aa9-88d0-5925f6e829b8,DISK], DatanodeInfoWithStorage[127.0.0.1:44255,DS-cbbb037e-eef8-48c6-8591-22c64ce37db3,DISK], DatanodeInfoWithStorage[127.0.0.1:44065,DS-05097315-d7b5-41e3-8d08-1b68e8890351,DISK], DatanodeInfoWithStorage[127.0.0.1:41331,DS-916351a4-c2ce-4bce-85f3-58abe7c1fae4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-982277684-172.17.0.7-1598469257294:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35285,DS-77b9f57c-34eb-4c82-a53e-7e6ef9032d5b,DISK], DatanodeInfoWithStorage[127.0.0.1:41595,DS-55ac76c6-3677-4e4a-9e47-e0d2f63b5b0f,DISK], DatanodeInfoWithStorage[127.0.0.1:35675,DS-a2830c52-c1f1-430a-9535-44b2e2b19a23,DISK], DatanodeInfoWithStorage[127.0.0.1:37008,DS-d62c0c53-cad3-4ee5-8fbf-7d92c7580321,DISK], DatanodeInfoWithStorage[127.0.0.1:35753,DS-e0f027f1-4d88-4e65-b091-4f0574cc6349,DISK], DatanodeInfoWithStorage[127.0.0.1:37749,DS-111d2b4d-da6a-4637-beda-708fd407e270,DISK], DatanodeInfoWithStorage[127.0.0.1:44918,DS-b25ae754-e2da-442d-8033-dc9b8e3cbec4,DISK], DatanodeInfoWithStorage[127.0.0.1:35149,DS-224e1121-e428-452c-85ea-256a45189d44,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-982277684-172.17.0.7-1598469257294:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35285,DS-77b9f57c-34eb-4c82-a53e-7e6ef9032d5b,DISK], DatanodeInfoWithStorage[127.0.0.1:41595,DS-55ac76c6-3677-4e4a-9e47-e0d2f63b5b0f,DISK], DatanodeInfoWithStorage[127.0.0.1:35675,DS-a2830c52-c1f1-430a-9535-44b2e2b19a23,DISK], DatanodeInfoWithStorage[127.0.0.1:37008,DS-d62c0c53-cad3-4ee5-8fbf-7d92c7580321,DISK], DatanodeInfoWithStorage[127.0.0.1:35753,DS-e0f027f1-4d88-4e65-b091-4f0574cc6349,DISK], DatanodeInfoWithStorage[127.0.0.1:37749,DS-111d2b4d-da6a-4637-beda-708fd407e270,DISK], DatanodeInfoWithStorage[127.0.0.1:44918,DS-b25ae754-e2da-442d-8033-dc9b8e3cbec4,DISK], DatanodeInfoWithStorage[127.0.0.1:35149,DS-224e1121-e428-452c-85ea-256a45189d44,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 4682
