reconf_parameter: dfs.pipeline.ecn
component: hdfs:DataNode
v1: false
v2: true
testProject: hbase
unitTest: org.apache.hadoop.hbase.wal.TestWALFactory#Broken_testSync
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.pipeline.ecn
component: hdfs:DataNode
v1: false
v2: true
testProject: hbase
unitTest: org.apache.hadoop.hbase.wal.TestWALFactory#Broken_testSync
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39270,DS-a86b8a20-9076-48c4-b396-864351c4f079,DISK], DatanodeInfoWithStorage[127.0.0.1:42433,DS-5a3ea9a7-09d7-4eb8-b084-77144d4eb463,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39270,DS-a86b8a20-9076-48c4-b396-864351c4f079,DISK], DatanodeInfoWithStorage[127.0.0.1:42433,DS-5a3ea9a7-09d7-4eb8-b084-77144d4eb463,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39270,DS-a86b8a20-9076-48c4-b396-864351c4f079,DISK], DatanodeInfoWithStorage[127.0.0.1:42433,DS-5a3ea9a7-09d7-4eb8-b084-77144d4eb463,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39270,DS-a86b8a20-9076-48c4-b396-864351c4f079,DISK], DatanodeInfoWithStorage[127.0.0.1:42433,DS-5a3ea9a7-09d7-4eb8-b084-77144d4eb463,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.pipeline.ecn
component: hdfs:DataNode
v1: false
v2: true
testProject: hbase
unitTest: org.apache.hadoop.hbase.wal.TestWALFactory#Broken_testSync
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45059,DS-e91fa30e-5cc6-4510-b801-512cebc6a917,DISK], DatanodeInfoWithStorage[127.0.0.1:36805,DS-6cad5900-32f1-4d5f-8388-c2302c8f3d9a,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36805,DS-6cad5900-32f1-4d5f-8388-c2302c8f3d9a,DISK], DatanodeInfoWithStorage[127.0.0.1:45059,DS-e91fa30e-5cc6-4510-b801-512cebc6a917,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45059,DS-e91fa30e-5cc6-4510-b801-512cebc6a917,DISK], DatanodeInfoWithStorage[127.0.0.1:36805,DS-6cad5900-32f1-4d5f-8388-c2302c8f3d9a,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36805,DS-6cad5900-32f1-4d5f-8388-c2302c8f3d9a,DISK], DatanodeInfoWithStorage[127.0.0.1:45059,DS-e91fa30e-5cc6-4510-b801-512cebc6a917,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.pipeline.ecn
component: hdfs:DataNode
v1: false
v2: true
testProject: hbase
unitTest: org.apache.hadoop.hbase.wal.TestWALFactory#Broken_testSync
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40321,DS-a3893b0d-53f3-4574-909d-563af10ceca6,DISK], DatanodeInfoWithStorage[127.0.0.1:39032,DS-8111179d-c870-4e04-b8f9-53c0188eb70d,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40321,DS-a3893b0d-53f3-4574-909d-563af10ceca6,DISK], DatanodeInfoWithStorage[127.0.0.1:39032,DS-8111179d-c870-4e04-b8f9-53c0188eb70d,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40321,DS-a3893b0d-53f3-4574-909d-563af10ceca6,DISK], DatanodeInfoWithStorage[127.0.0.1:39032,DS-8111179d-c870-4e04-b8f9-53c0188eb70d,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40321,DS-a3893b0d-53f3-4574-909d-563af10ceca6,DISK], DatanodeInfoWithStorage[127.0.0.1:39032,DS-8111179d-c870-4e04-b8f9-53c0188eb70d,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.pipeline.ecn
component: hdfs:DataNode
v1: false
v2: true
testProject: hbase
unitTest: org.apache.hadoop.hbase.wal.TestWALFactory#Broken_testSync
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37759,DS-b918bc9a-29ac-4d5e-bb0e-0fa3f249d615,DISK], DatanodeInfoWithStorage[127.0.0.1:43948,DS-94292f44-5f91-4c18-a010-4af4a83c6553,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37759,DS-b918bc9a-29ac-4d5e-bb0e-0fa3f249d615,DISK], DatanodeInfoWithStorage[127.0.0.1:43948,DS-94292f44-5f91-4c18-a010-4af4a83c6553,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37759,DS-b918bc9a-29ac-4d5e-bb0e-0fa3f249d615,DISK], DatanodeInfoWithStorage[127.0.0.1:43948,DS-94292f44-5f91-4c18-a010-4af4a83c6553,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37759,DS-b918bc9a-29ac-4d5e-bb0e-0fa3f249d615,DISK], DatanodeInfoWithStorage[127.0.0.1:43948,DS-94292f44-5f91-4c18-a010-4af4a83c6553,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.pipeline.ecn
component: hdfs:DataNode
v1: false
v2: true
testProject: hbase
unitTest: org.apache.hadoop.hbase.wal.TestWALFactory#Broken_testSync
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44324,DS-b0641d3a-7b9e-4949-a599-3b593ebeb263,DISK], DatanodeInfoWithStorage[127.0.0.1:45985,DS-5ca3fca3-354d-43df-8ffd-87c4a45e8546,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44324,DS-b0641d3a-7b9e-4949-a599-3b593ebeb263,DISK], DatanodeInfoWithStorage[127.0.0.1:45985,DS-5ca3fca3-354d-43df-8ffd-87c4a45e8546,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44324,DS-b0641d3a-7b9e-4949-a599-3b593ebeb263,DISK], DatanodeInfoWithStorage[127.0.0.1:45985,DS-5ca3fca3-354d-43df-8ffd-87c4a45e8546,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44324,DS-b0641d3a-7b9e-4949-a599-3b593ebeb263,DISK], DatanodeInfoWithStorage[127.0.0.1:45985,DS-5ca3fca3-354d-43df-8ffd-87c4a45e8546,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.pipeline.ecn
component: hdfs:DataNode
v1: false
v2: true
testProject: hbase
unitTest: org.apache.hadoop.hbase.wal.TestWALFactory#Broken_testSync
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45869,DS-3026a90f-2da4-4a3a-a48f-3de098dd994e,DISK], DatanodeInfoWithStorage[127.0.0.1:46590,DS-fed90b51-47b3-43f3-a07e-2a728694106d,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:46590,DS-fed90b51-47b3-43f3-a07e-2a728694106d,DISK], DatanodeInfoWithStorage[127.0.0.1:45869,DS-3026a90f-2da4-4a3a-a48f-3de098dd994e,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45869,DS-3026a90f-2da4-4a3a-a48f-3de098dd994e,DISK], DatanodeInfoWithStorage[127.0.0.1:46590,DS-fed90b51-47b3-43f3-a07e-2a728694106d,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:46590,DS-fed90b51-47b3-43f3-a07e-2a728694106d,DISK], DatanodeInfoWithStorage[127.0.0.1:45869,DS-3026a90f-2da4-4a3a-a48f-3de098dd994e,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.pipeline.ecn
component: hdfs:DataNode
v1: false
v2: true
testProject: hbase
unitTest: org.apache.hadoop.hbase.wal.TestWALFactory#Broken_testSync
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35261,DS-bd22fea0-6e0e-4263-ad88-232ca25b4a3d,DISK], DatanodeInfoWithStorage[127.0.0.1:39494,DS-931a4b80-b054-4157-b62c-c3446c3fa5ae,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35261,DS-bd22fea0-6e0e-4263-ad88-232ca25b4a3d,DISK], DatanodeInfoWithStorage[127.0.0.1:39494,DS-931a4b80-b054-4157-b62c-c3446c3fa5ae,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35261,DS-bd22fea0-6e0e-4263-ad88-232ca25b4a3d,DISK], DatanodeInfoWithStorage[127.0.0.1:39494,DS-931a4b80-b054-4157-b62c-c3446c3fa5ae,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35261,DS-bd22fea0-6e0e-4263-ad88-232ca25b4a3d,DISK], DatanodeInfoWithStorage[127.0.0.1:39494,DS-931a4b80-b054-4157-b62c-c3446c3fa5ae,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 4 out of 50
result: false positive !!!
Total execution time in seconds : 7318
