reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-101812341-172.17.0.14-1598082830188:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45535,DS-e33b2c33-43a0-4fae-b508-d7f03d5d8e09,DISK], DatanodeInfoWithStorage[127.0.0.1:34933,DS-b143bc47-1640-4178-9cc3-7166e5e465ee,DISK], DatanodeInfoWithStorage[127.0.0.1:45698,DS-b037d124-f402-4847-b192-27d6a8d3fb4b,DISK], DatanodeInfoWithStorage[127.0.0.1:33121,DS-bae4aa31-cab2-4e22-a705-892554165749,DISK], DatanodeInfoWithStorage[127.0.0.1:43265,DS-ad2efe10-2832-42a4-a1da-a7cc88ad39d5,DISK], DatanodeInfoWithStorage[127.0.0.1:33529,DS-058be800-522b-4778-a336-a1325dc11394,DISK], DatanodeInfoWithStorage[127.0.0.1:37840,DS-b2506d03-8b93-42c4-b6f5-b0accdd917cc,DISK], DatanodeInfoWithStorage[127.0.0.1:42363,DS-4abb5561-370e-4a78-9adf-0ef055204aa5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-101812341-172.17.0.14-1598082830188:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45535,DS-e33b2c33-43a0-4fae-b508-d7f03d5d8e09,DISK], DatanodeInfoWithStorage[127.0.0.1:34933,DS-b143bc47-1640-4178-9cc3-7166e5e465ee,DISK], DatanodeInfoWithStorage[127.0.0.1:45698,DS-b037d124-f402-4847-b192-27d6a8d3fb4b,DISK], DatanodeInfoWithStorage[127.0.0.1:33121,DS-bae4aa31-cab2-4e22-a705-892554165749,DISK], DatanodeInfoWithStorage[127.0.0.1:43265,DS-ad2efe10-2832-42a4-a1da-a7cc88ad39d5,DISK], DatanodeInfoWithStorage[127.0.0.1:33529,DS-058be800-522b-4778-a336-a1325dc11394,DISK], DatanodeInfoWithStorage[127.0.0.1:37840,DS-b2506d03-8b93-42c4-b6f5-b0accdd917cc,DISK], DatanodeInfoWithStorage[127.0.0.1:42363,DS-4abb5561-370e-4a78-9adf-0ef055204aa5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1305587713-172.17.0.14-1598083213361:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44531,DS-28b84d27-3104-47a2-a17d-0ac395cd6e80,DISK], DatanodeInfoWithStorage[127.0.0.1:42975,DS-07d91ab5-3890-4ff4-8f8f-90619ab97606,DISK], DatanodeInfoWithStorage[127.0.0.1:39648,DS-650e64a9-ecf4-4bd5-b277-9c4e3edca359,DISK], DatanodeInfoWithStorage[127.0.0.1:34258,DS-05b438bd-23e8-4cfc-91e7-eb6dcad44f0b,DISK], DatanodeInfoWithStorage[127.0.0.1:43080,DS-047c9790-bbc6-458d-8e19-83cddf82250b,DISK], DatanodeInfoWithStorage[127.0.0.1:40175,DS-24c43c41-00fc-4e23-b485-d50ee0a2309b,DISK], DatanodeInfoWithStorage[127.0.0.1:44534,DS-a12364f2-34b1-41f2-8856-9f4303f35d80,DISK], DatanodeInfoWithStorage[127.0.0.1:45381,DS-1b193994-affd-4adc-8880-f843c8be969e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1305587713-172.17.0.14-1598083213361:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44531,DS-28b84d27-3104-47a2-a17d-0ac395cd6e80,DISK], DatanodeInfoWithStorage[127.0.0.1:42975,DS-07d91ab5-3890-4ff4-8f8f-90619ab97606,DISK], DatanodeInfoWithStorage[127.0.0.1:39648,DS-650e64a9-ecf4-4bd5-b277-9c4e3edca359,DISK], DatanodeInfoWithStorage[127.0.0.1:34258,DS-05b438bd-23e8-4cfc-91e7-eb6dcad44f0b,DISK], DatanodeInfoWithStorage[127.0.0.1:43080,DS-047c9790-bbc6-458d-8e19-83cddf82250b,DISK], DatanodeInfoWithStorage[127.0.0.1:40175,DS-24c43c41-00fc-4e23-b485-d50ee0a2309b,DISK], DatanodeInfoWithStorage[127.0.0.1:44534,DS-a12364f2-34b1-41f2-8856-9f4303f35d80,DISK], DatanodeInfoWithStorage[127.0.0.1:45381,DS-1b193994-affd-4adc-8880-f843c8be969e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-381558082-172.17.0.14-1598083574258:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38376,DS-bfb1f4ad-a943-4add-affa-5d181156624d,DISK], DatanodeInfoWithStorage[127.0.0.1:38899,DS-209e097a-5746-4dd3-8bed-33fe0185c9e4,DISK], DatanodeInfoWithStorage[127.0.0.1:38564,DS-896c0495-7dff-46b4-943f-d7841e1fe0ac,DISK], DatanodeInfoWithStorage[127.0.0.1:44492,DS-1072baec-4203-4519-a3e1-d7999c698cf4,DISK], DatanodeInfoWithStorage[127.0.0.1:43463,DS-c5e1bc44-4213-45ca-8673-3fd9a0122d1d,DISK], DatanodeInfoWithStorage[127.0.0.1:36384,DS-37d3b4d4-06b8-4337-bda9-6bd276159971,DISK], DatanodeInfoWithStorage[127.0.0.1:34104,DS-62c621db-af0f-4365-b7ee-949a6dd91976,DISK], DatanodeInfoWithStorage[127.0.0.1:39141,DS-c07e4882-e4fc-4581-b148-ca67d2893800,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-381558082-172.17.0.14-1598083574258:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38376,DS-bfb1f4ad-a943-4add-affa-5d181156624d,DISK], DatanodeInfoWithStorage[127.0.0.1:38899,DS-209e097a-5746-4dd3-8bed-33fe0185c9e4,DISK], DatanodeInfoWithStorage[127.0.0.1:38564,DS-896c0495-7dff-46b4-943f-d7841e1fe0ac,DISK], DatanodeInfoWithStorage[127.0.0.1:44492,DS-1072baec-4203-4519-a3e1-d7999c698cf4,DISK], DatanodeInfoWithStorage[127.0.0.1:43463,DS-c5e1bc44-4213-45ca-8673-3fd9a0122d1d,DISK], DatanodeInfoWithStorage[127.0.0.1:36384,DS-37d3b4d4-06b8-4337-bda9-6bd276159971,DISK], DatanodeInfoWithStorage[127.0.0.1:34104,DS-62c621db-af0f-4365-b7ee-949a6dd91976,DISK], DatanodeInfoWithStorage[127.0.0.1:39141,DS-c07e4882-e4fc-4581-b148-ca67d2893800,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1793801919-172.17.0.14-1598084765975:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33553,DS-0b039525-aedd-401a-9ecc-d737689fc7e0,DISK], DatanodeInfoWithStorage[127.0.0.1:43758,DS-c893f942-128d-475a-a1f7-13dd1ae29996,DISK], DatanodeInfoWithStorage[127.0.0.1:33316,DS-1f317328-b681-40a0-ab5c-25757a4cfa7c,DISK], DatanodeInfoWithStorage[127.0.0.1:39457,DS-1c9237a2-4981-4d31-920f-b3e42467fde8,DISK], DatanodeInfoWithStorage[127.0.0.1:44082,DS-f7382558-25c7-4929-b99c-8e3a4249919c,DISK], DatanodeInfoWithStorage[127.0.0.1:44103,DS-72020862-b536-4995-9c10-206854bb2fe7,DISK], DatanodeInfoWithStorage[127.0.0.1:33668,DS-3e2845c4-a8e6-4289-a715-83bff2f8c116,DISK], DatanodeInfoWithStorage[127.0.0.1:39357,DS-e6fb6ba5-00b6-449a-b028-33caa9747d98,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1793801919-172.17.0.14-1598084765975:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33553,DS-0b039525-aedd-401a-9ecc-d737689fc7e0,DISK], DatanodeInfoWithStorage[127.0.0.1:43758,DS-c893f942-128d-475a-a1f7-13dd1ae29996,DISK], DatanodeInfoWithStorage[127.0.0.1:33316,DS-1f317328-b681-40a0-ab5c-25757a4cfa7c,DISK], DatanodeInfoWithStorage[127.0.0.1:39457,DS-1c9237a2-4981-4d31-920f-b3e42467fde8,DISK], DatanodeInfoWithStorage[127.0.0.1:44082,DS-f7382558-25c7-4929-b99c-8e3a4249919c,DISK], DatanodeInfoWithStorage[127.0.0.1:44103,DS-72020862-b536-4995-9c10-206854bb2fe7,DISK], DatanodeInfoWithStorage[127.0.0.1:33668,DS-3e2845c4-a8e6-4289-a715-83bff2f8c116,DISK], DatanodeInfoWithStorage[127.0.0.1:39357,DS-e6fb6ba5-00b6-449a-b028-33caa9747d98,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-385230057-172.17.0.14-1598085447880:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34774,DS-a6f47f5c-fcdb-4430-be5a-d2271efb355b,DISK], DatanodeInfoWithStorage[127.0.0.1:42054,DS-7f409e44-4381-411c-9b87-8fadc6b89340,DISK], DatanodeInfoWithStorage[127.0.0.1:35847,DS-90eac398-d8b9-4ee8-9383-caabc99c41ba,DISK], DatanodeInfoWithStorage[127.0.0.1:34627,DS-fb257b1f-c4c2-4870-9a11-23afdfd9af4a,DISK], DatanodeInfoWithStorage[127.0.0.1:41171,DS-a6766cd9-28d8-463e-9389-42f8e264aded,DISK], DatanodeInfoWithStorage[127.0.0.1:37218,DS-dc791d97-1102-4b86-abad-fa7f03557a63,DISK], DatanodeInfoWithStorage[127.0.0.1:44051,DS-1cece020-924f-42bb-b2ae-0bfd54611d6d,DISK], DatanodeInfoWithStorage[127.0.0.1:38204,DS-89fb3597-377f-483d-b5fe-06786ff3cc74,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-385230057-172.17.0.14-1598085447880:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34774,DS-a6f47f5c-fcdb-4430-be5a-d2271efb355b,DISK], DatanodeInfoWithStorage[127.0.0.1:42054,DS-7f409e44-4381-411c-9b87-8fadc6b89340,DISK], DatanodeInfoWithStorage[127.0.0.1:35847,DS-90eac398-d8b9-4ee8-9383-caabc99c41ba,DISK], DatanodeInfoWithStorage[127.0.0.1:34627,DS-fb257b1f-c4c2-4870-9a11-23afdfd9af4a,DISK], DatanodeInfoWithStorage[127.0.0.1:41171,DS-a6766cd9-28d8-463e-9389-42f8e264aded,DISK], DatanodeInfoWithStorage[127.0.0.1:37218,DS-dc791d97-1102-4b86-abad-fa7f03557a63,DISK], DatanodeInfoWithStorage[127.0.0.1:44051,DS-1cece020-924f-42bb-b2ae-0bfd54611d6d,DISK], DatanodeInfoWithStorage[127.0.0.1:38204,DS-89fb3597-377f-483d-b5fe-06786ff3cc74,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-155031080-172.17.0.14-1598085716463:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35789,DS-932e9238-1203-476f-ae6c-8544685cd8d5,DISK], DatanodeInfoWithStorage[127.0.0.1:37180,DS-203cde0c-8246-4514-9fe0-6f57a9cdfd75,DISK], DatanodeInfoWithStorage[127.0.0.1:37720,DS-f3655327-d22b-44a6-a4fd-09bc9014f43b,DISK], DatanodeInfoWithStorage[127.0.0.1:45789,DS-f6e88585-315f-4e85-9f0e-f17232158c5b,DISK], DatanodeInfoWithStorage[127.0.0.1:38450,DS-b8c20746-97a6-4524-86b8-109fd9c0e10e,DISK], DatanodeInfoWithStorage[127.0.0.1:37998,DS-39b219db-0d9d-4cdc-8da7-97910a535eaa,DISK], DatanodeInfoWithStorage[127.0.0.1:38669,DS-68871888-4676-4d7c-bb73-adc27d1b46ef,DISK], DatanodeInfoWithStorage[127.0.0.1:38461,DS-442795d9-9ffe-4f51-885c-f23c1fdd6e3c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-155031080-172.17.0.14-1598085716463:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35789,DS-932e9238-1203-476f-ae6c-8544685cd8d5,DISK], DatanodeInfoWithStorage[127.0.0.1:37180,DS-203cde0c-8246-4514-9fe0-6f57a9cdfd75,DISK], DatanodeInfoWithStorage[127.0.0.1:37720,DS-f3655327-d22b-44a6-a4fd-09bc9014f43b,DISK], DatanodeInfoWithStorage[127.0.0.1:45789,DS-f6e88585-315f-4e85-9f0e-f17232158c5b,DISK], DatanodeInfoWithStorage[127.0.0.1:38450,DS-b8c20746-97a6-4524-86b8-109fd9c0e10e,DISK], DatanodeInfoWithStorage[127.0.0.1:37998,DS-39b219db-0d9d-4cdc-8da7-97910a535eaa,DISK], DatanodeInfoWithStorage[127.0.0.1:38669,DS-68871888-4676-4d7c-bb73-adc27d1b46ef,DISK], DatanodeInfoWithStorage[127.0.0.1:38461,DS-442795d9-9ffe-4f51-885c-f23c1fdd6e3c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-498223365-172.17.0.14-1598086149515:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46845,DS-2a8b068d-6ccc-487c-8114-a1da4b475aba,DISK], DatanodeInfoWithStorage[127.0.0.1:40721,DS-f838e331-fcf6-4c1e-b5b7-9cd2600b941e,DISK], DatanodeInfoWithStorage[127.0.0.1:33939,DS-3c57ecb0-a697-480a-a58e-07f83e15b882,DISK], DatanodeInfoWithStorage[127.0.0.1:36720,DS-9e75aea0-bdec-4e1d-b9b8-6ec01d9c3761,DISK], DatanodeInfoWithStorage[127.0.0.1:46192,DS-f470b16a-049b-4f35-aa25-d7b27270af48,DISK], DatanodeInfoWithStorage[127.0.0.1:34524,DS-0b64af6c-3ea0-4166-b47e-de472cf2ad03,DISK], DatanodeInfoWithStorage[127.0.0.1:33358,DS-f8b502e9-4f03-4371-bedb-e1d16a3d6cce,DISK], DatanodeInfoWithStorage[127.0.0.1:38392,DS-86c4806e-7b73-4d99-9ac7-9ff55f6ece1e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-498223365-172.17.0.14-1598086149515:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46845,DS-2a8b068d-6ccc-487c-8114-a1da4b475aba,DISK], DatanodeInfoWithStorage[127.0.0.1:40721,DS-f838e331-fcf6-4c1e-b5b7-9cd2600b941e,DISK], DatanodeInfoWithStorage[127.0.0.1:33939,DS-3c57ecb0-a697-480a-a58e-07f83e15b882,DISK], DatanodeInfoWithStorage[127.0.0.1:36720,DS-9e75aea0-bdec-4e1d-b9b8-6ec01d9c3761,DISK], DatanodeInfoWithStorage[127.0.0.1:46192,DS-f470b16a-049b-4f35-aa25-d7b27270af48,DISK], DatanodeInfoWithStorage[127.0.0.1:34524,DS-0b64af6c-3ea0-4166-b47e-de472cf2ad03,DISK], DatanodeInfoWithStorage[127.0.0.1:33358,DS-f8b502e9-4f03-4371-bedb-e1d16a3d6cce,DISK], DatanodeInfoWithStorage[127.0.0.1:38392,DS-86c4806e-7b73-4d99-9ac7-9ff55f6ece1e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-837661755-172.17.0.14-1598086604047:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45681,DS-f2fe3a55-bb05-4c4a-9957-4ba16bd5a07f,DISK], DatanodeInfoWithStorage[127.0.0.1:38202,DS-3097277b-2bfd-4dbb-9e14-0c217c965155,DISK], DatanodeInfoWithStorage[127.0.0.1:43761,DS-372c01e9-111f-4388-a376-04913e4bb6bc,DISK], DatanodeInfoWithStorage[127.0.0.1:45182,DS-cf21c99c-2f62-47e3-9e17-ad854c9e57e2,DISK], DatanodeInfoWithStorage[127.0.0.1:42395,DS-615ad7cf-c231-4936-91b6-01fa635f1069,DISK], DatanodeInfoWithStorage[127.0.0.1:42185,DS-3ffe0829-3b10-4594-b322-6b7fdc56d63d,DISK], DatanodeInfoWithStorage[127.0.0.1:42650,DS-cbbb2756-7301-493d-9706-77a93f151c01,DISK], DatanodeInfoWithStorage[127.0.0.1:34915,DS-b60ea7a9-81e7-4c77-a7e8-c8c92963df93,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-837661755-172.17.0.14-1598086604047:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45681,DS-f2fe3a55-bb05-4c4a-9957-4ba16bd5a07f,DISK], DatanodeInfoWithStorage[127.0.0.1:38202,DS-3097277b-2bfd-4dbb-9e14-0c217c965155,DISK], DatanodeInfoWithStorage[127.0.0.1:43761,DS-372c01e9-111f-4388-a376-04913e4bb6bc,DISK], DatanodeInfoWithStorage[127.0.0.1:45182,DS-cf21c99c-2f62-47e3-9e17-ad854c9e57e2,DISK], DatanodeInfoWithStorage[127.0.0.1:42395,DS-615ad7cf-c231-4936-91b6-01fa635f1069,DISK], DatanodeInfoWithStorage[127.0.0.1:42185,DS-3ffe0829-3b10-4594-b322-6b7fdc56d63d,DISK], DatanodeInfoWithStorage[127.0.0.1:42650,DS-cbbb2756-7301-493d-9706-77a93f151c01,DISK], DatanodeInfoWithStorage[127.0.0.1:34915,DS-b60ea7a9-81e7-4c77-a7e8-c8c92963df93,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1420706463-172.17.0.14-1598086724467:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46554,DS-8263895d-5ffe-45eb-9dca-8b866974c665,DISK], DatanodeInfoWithStorage[127.0.0.1:44677,DS-3893f736-0e2b-40ff-9fc8-7dc2e18d0ca5,DISK], DatanodeInfoWithStorage[127.0.0.1:35846,DS-5e026961-ed5a-41fa-a7cf-6f7d2e70a4ac,DISK], DatanodeInfoWithStorage[127.0.0.1:40488,DS-75ce579d-9ce3-49d2-aabe-b4a5cacdd3d5,DISK], DatanodeInfoWithStorage[127.0.0.1:44644,DS-32b47999-4fa8-43bf-b8e2-b51fd09c3632,DISK], DatanodeInfoWithStorage[127.0.0.1:43366,DS-fc2ad068-a997-4df5-9000-b84c37323e49,DISK], DatanodeInfoWithStorage[127.0.0.1:43842,DS-693698f5-cce7-43e5-883f-271d1e45530a,DISK], DatanodeInfoWithStorage[127.0.0.1:37491,DS-d29bafd1-9040-492c-8659-6365ffcd9ea2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1420706463-172.17.0.14-1598086724467:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46554,DS-8263895d-5ffe-45eb-9dca-8b866974c665,DISK], DatanodeInfoWithStorage[127.0.0.1:44677,DS-3893f736-0e2b-40ff-9fc8-7dc2e18d0ca5,DISK], DatanodeInfoWithStorage[127.0.0.1:35846,DS-5e026961-ed5a-41fa-a7cf-6f7d2e70a4ac,DISK], DatanodeInfoWithStorage[127.0.0.1:40488,DS-75ce579d-9ce3-49d2-aabe-b4a5cacdd3d5,DISK], DatanodeInfoWithStorage[127.0.0.1:44644,DS-32b47999-4fa8-43bf-b8e2-b51fd09c3632,DISK], DatanodeInfoWithStorage[127.0.0.1:43366,DS-fc2ad068-a997-4df5-9000-b84c37323e49,DISK], DatanodeInfoWithStorage[127.0.0.1:43842,DS-693698f5-cce7-43e5-883f-271d1e45530a,DISK], DatanodeInfoWithStorage[127.0.0.1:37491,DS-d29bafd1-9040-492c-8659-6365ffcd9ea2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-915297123-172.17.0.14-1598087259588:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33640,DS-5412ac0f-82b5-4549-95b1-697f6274d10e,DISK], DatanodeInfoWithStorage[127.0.0.1:40748,DS-13b7c8cd-325f-4fd0-8b8e-b39b792d561b,DISK], DatanodeInfoWithStorage[127.0.0.1:37751,DS-5eb930f5-98ad-40b9-b1ad-661e2307c3a1,DISK], DatanodeInfoWithStorage[127.0.0.1:37128,DS-6d6b0518-69b0-4282-9b4e-cb9a5289d887,DISK], DatanodeInfoWithStorage[127.0.0.1:34057,DS-bc711b2b-61f4-45e8-ba3e-9fc9a1c9a45b,DISK], DatanodeInfoWithStorage[127.0.0.1:38830,DS-2398e508-a80f-4b45-adcc-f1f6e9c57eec,DISK], DatanodeInfoWithStorage[127.0.0.1:39711,DS-db16890f-8fe4-4d7c-9e32-dce6f899a221,DISK], DatanodeInfoWithStorage[127.0.0.1:42143,DS-1519dd01-7357-45bf-9492-1333f1147f89,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-915297123-172.17.0.14-1598087259588:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33640,DS-5412ac0f-82b5-4549-95b1-697f6274d10e,DISK], DatanodeInfoWithStorage[127.0.0.1:40748,DS-13b7c8cd-325f-4fd0-8b8e-b39b792d561b,DISK], DatanodeInfoWithStorage[127.0.0.1:37751,DS-5eb930f5-98ad-40b9-b1ad-661e2307c3a1,DISK], DatanodeInfoWithStorage[127.0.0.1:37128,DS-6d6b0518-69b0-4282-9b4e-cb9a5289d887,DISK], DatanodeInfoWithStorage[127.0.0.1:34057,DS-bc711b2b-61f4-45e8-ba3e-9fc9a1c9a45b,DISK], DatanodeInfoWithStorage[127.0.0.1:38830,DS-2398e508-a80f-4b45-adcc-f1f6e9c57eec,DISK], DatanodeInfoWithStorage[127.0.0.1:39711,DS-db16890f-8fe4-4d7c-9e32-dce6f899a221,DISK], DatanodeInfoWithStorage[127.0.0.1:42143,DS-1519dd01-7357-45bf-9492-1333f1147f89,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-674770579-172.17.0.14-1598087509498:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43665,DS-4dd2879e-a8a9-4413-a8e2-b6eb094aca1c,DISK], DatanodeInfoWithStorage[127.0.0.1:37198,DS-620b8386-361b-499d-8f4f-949a32b87f46,DISK], DatanodeInfoWithStorage[127.0.0.1:40613,DS-f18b9172-6a01-420a-b91b-1211eea14e80,DISK], DatanodeInfoWithStorage[127.0.0.1:39341,DS-8fcb5707-b0dc-4683-bde7-7c6ed3774456,DISK], DatanodeInfoWithStorage[127.0.0.1:46040,DS-ddf771b2-b1c5-4be0-983f-5c96119eb0ee,DISK], DatanodeInfoWithStorage[127.0.0.1:40672,DS-b958526f-3f00-4c26-b5b8-ae3302d0c67c,DISK], DatanodeInfoWithStorage[127.0.0.1:37854,DS-6d26a3ac-73bc-4bf1-8b56-577789fa5b26,DISK], DatanodeInfoWithStorage[127.0.0.1:43594,DS-a1250b1c-af0c-48fc-ac75-c71e257eb316,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-674770579-172.17.0.14-1598087509498:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43665,DS-4dd2879e-a8a9-4413-a8e2-b6eb094aca1c,DISK], DatanodeInfoWithStorage[127.0.0.1:37198,DS-620b8386-361b-499d-8f4f-949a32b87f46,DISK], DatanodeInfoWithStorage[127.0.0.1:40613,DS-f18b9172-6a01-420a-b91b-1211eea14e80,DISK], DatanodeInfoWithStorage[127.0.0.1:39341,DS-8fcb5707-b0dc-4683-bde7-7c6ed3774456,DISK], DatanodeInfoWithStorage[127.0.0.1:46040,DS-ddf771b2-b1c5-4be0-983f-5c96119eb0ee,DISK], DatanodeInfoWithStorage[127.0.0.1:40672,DS-b958526f-3f00-4c26-b5b8-ae3302d0c67c,DISK], DatanodeInfoWithStorage[127.0.0.1:37854,DS-6d26a3ac-73bc-4bf1-8b56-577789fa5b26,DISK], DatanodeInfoWithStorage[127.0.0.1:43594,DS-a1250b1c-af0c-48fc-ac75-c71e257eb316,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1938985666-172.17.0.14-1598087732375:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44482,DS-061d593e-aec6-443d-9929-7871022f3e72,DISK], DatanodeInfoWithStorage[127.0.0.1:43773,DS-ff014f79-e36d-4631-9b76-10d02fa896dc,DISK], DatanodeInfoWithStorage[127.0.0.1:44070,DS-412283d9-3cef-41fa-ae70-48f59e9fc688,DISK], DatanodeInfoWithStorage[127.0.0.1:38457,DS-6b8b2a3b-0695-4ac1-b732-cbae1d6eeb4f,DISK], DatanodeInfoWithStorage[127.0.0.1:37181,DS-fdf4feac-e5a6-4b99-a004-56e060c6aaf5,DISK], DatanodeInfoWithStorage[127.0.0.1:40417,DS-67cb2ca6-42a5-4fde-8ff7-073ad71502f5,DISK], DatanodeInfoWithStorage[127.0.0.1:35226,DS-03ef2f23-a88f-4aa5-8d89-1d931542947f,DISK], DatanodeInfoWithStorage[127.0.0.1:42948,DS-48773e75-d3ac-402d-b99b-9ebe6c696085,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1938985666-172.17.0.14-1598087732375:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44482,DS-061d593e-aec6-443d-9929-7871022f3e72,DISK], DatanodeInfoWithStorage[127.0.0.1:43773,DS-ff014f79-e36d-4631-9b76-10d02fa896dc,DISK], DatanodeInfoWithStorage[127.0.0.1:44070,DS-412283d9-3cef-41fa-ae70-48f59e9fc688,DISK], DatanodeInfoWithStorage[127.0.0.1:38457,DS-6b8b2a3b-0695-4ac1-b732-cbae1d6eeb4f,DISK], DatanodeInfoWithStorage[127.0.0.1:37181,DS-fdf4feac-e5a6-4b99-a004-56e060c6aaf5,DISK], DatanodeInfoWithStorage[127.0.0.1:40417,DS-67cb2ca6-42a5-4fde-8ff7-073ad71502f5,DISK], DatanodeInfoWithStorage[127.0.0.1:35226,DS-03ef2f23-a88f-4aa5-8d89-1d931542947f,DISK], DatanodeInfoWithStorage[127.0.0.1:42948,DS-48773e75-d3ac-402d-b99b-9ebe6c696085,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1287643895-172.17.0.14-1598087817886:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33218,DS-d4243f11-b64f-416e-9e2e-70eab8f8bd95,DISK], DatanodeInfoWithStorage[127.0.0.1:38598,DS-5de39622-2ba7-441f-b17a-ca50f0931e6d,DISK], DatanodeInfoWithStorage[127.0.0.1:32836,DS-63629c52-41c8-475d-aef3-0736046571bb,DISK], DatanodeInfoWithStorage[127.0.0.1:39415,DS-972a0833-1cb7-4d62-8aad-c6faf8c9d047,DISK], DatanodeInfoWithStorage[127.0.0.1:45350,DS-52379d38-83da-4cdc-99a8-a45e4d8a9c3c,DISK], DatanodeInfoWithStorage[127.0.0.1:36905,DS-0a873852-257a-41ff-ab0e-b19117e42b6c,DISK], DatanodeInfoWithStorage[127.0.0.1:43597,DS-2024e205-3f59-4ce0-8272-2c1576a4696f,DISK], DatanodeInfoWithStorage[127.0.0.1:33338,DS-1a091d75-e9fb-4b30-bc54-c31067f4f265,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1287643895-172.17.0.14-1598087817886:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33218,DS-d4243f11-b64f-416e-9e2e-70eab8f8bd95,DISK], DatanodeInfoWithStorage[127.0.0.1:38598,DS-5de39622-2ba7-441f-b17a-ca50f0931e6d,DISK], DatanodeInfoWithStorage[127.0.0.1:32836,DS-63629c52-41c8-475d-aef3-0736046571bb,DISK], DatanodeInfoWithStorage[127.0.0.1:39415,DS-972a0833-1cb7-4d62-8aad-c6faf8c9d047,DISK], DatanodeInfoWithStorage[127.0.0.1:45350,DS-52379d38-83da-4cdc-99a8-a45e4d8a9c3c,DISK], DatanodeInfoWithStorage[127.0.0.1:36905,DS-0a873852-257a-41ff-ab0e-b19117e42b6c,DISK], DatanodeInfoWithStorage[127.0.0.1:43597,DS-2024e205-3f59-4ce0-8272-2c1576a4696f,DISK], DatanodeInfoWithStorage[127.0.0.1:33338,DS-1a091d75-e9fb-4b30-bc54-c31067f4f265,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1036213226-172.17.0.14-1598087901615:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45646,DS-27632f28-00e6-494e-afb9-c093fe6a2973,DISK], DatanodeInfoWithStorage[127.0.0.1:40565,DS-00c881bc-64a7-4832-978c-68d6294e4454,DISK], DatanodeInfoWithStorage[127.0.0.1:45793,DS-53a4e71a-6a20-458c-b1d0-84910687fb5f,DISK], DatanodeInfoWithStorage[127.0.0.1:41302,DS-03697139-ed77-41c8-89a5-f4bb11976f7c,DISK], DatanodeInfoWithStorage[127.0.0.1:41362,DS-2be581c5-9b4a-49f0-8f06-d48baaceafb4,DISK], DatanodeInfoWithStorage[127.0.0.1:38193,DS-e08682f8-7b9c-4e97-ab7c-bc0821601b97,DISK], DatanodeInfoWithStorage[127.0.0.1:36001,DS-1e87cf73-9d10-4974-a44b-692dc4cfc973,DISK], DatanodeInfoWithStorage[127.0.0.1:38194,DS-30a10589-370c-4040-9064-ed475ce34417,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1036213226-172.17.0.14-1598087901615:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45646,DS-27632f28-00e6-494e-afb9-c093fe6a2973,DISK], DatanodeInfoWithStorage[127.0.0.1:40565,DS-00c881bc-64a7-4832-978c-68d6294e4454,DISK], DatanodeInfoWithStorage[127.0.0.1:45793,DS-53a4e71a-6a20-458c-b1d0-84910687fb5f,DISK], DatanodeInfoWithStorage[127.0.0.1:41302,DS-03697139-ed77-41c8-89a5-f4bb11976f7c,DISK], DatanodeInfoWithStorage[127.0.0.1:41362,DS-2be581c5-9b4a-49f0-8f06-d48baaceafb4,DISK], DatanodeInfoWithStorage[127.0.0.1:38193,DS-e08682f8-7b9c-4e97-ab7c-bc0821601b97,DISK], DatanodeInfoWithStorage[127.0.0.1:36001,DS-1e87cf73-9d10-4974-a44b-692dc4cfc973,DISK], DatanodeInfoWithStorage[127.0.0.1:38194,DS-30a10589-370c-4040-9064-ed475ce34417,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1448853077-172.17.0.14-1598088566217:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34947,DS-9c534e71-1baf-439e-9c1f-379629974d8d,DISK], DatanodeInfoWithStorage[127.0.0.1:41258,DS-8a996e4e-7c7f-4cbc-b2e2-28ba8f81c5e4,DISK], DatanodeInfoWithStorage[127.0.0.1:33560,DS-02bc06fb-3322-4b52-9a13-db06dca96cb0,DISK], DatanodeInfoWithStorage[127.0.0.1:33889,DS-f2eb5402-b6fd-4b59-ba9d-89200c3c9d38,DISK], DatanodeInfoWithStorage[127.0.0.1:45098,DS-530d631a-578c-452c-82a0-e4a230ebe1a6,DISK], DatanodeInfoWithStorage[127.0.0.1:43734,DS-5ecadc66-91e9-442d-a996-6a633deb95b7,DISK], DatanodeInfoWithStorage[127.0.0.1:45484,DS-f39a5fd9-010f-41ec-a39e-7ae6348892c3,DISK], DatanodeInfoWithStorage[127.0.0.1:43031,DS-53a6d750-ed80-4470-808c-e6ac7fa0b79a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1448853077-172.17.0.14-1598088566217:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34947,DS-9c534e71-1baf-439e-9c1f-379629974d8d,DISK], DatanodeInfoWithStorage[127.0.0.1:41258,DS-8a996e4e-7c7f-4cbc-b2e2-28ba8f81c5e4,DISK], DatanodeInfoWithStorage[127.0.0.1:33560,DS-02bc06fb-3322-4b52-9a13-db06dca96cb0,DISK], DatanodeInfoWithStorage[127.0.0.1:33889,DS-f2eb5402-b6fd-4b59-ba9d-89200c3c9d38,DISK], DatanodeInfoWithStorage[127.0.0.1:45098,DS-530d631a-578c-452c-82a0-e4a230ebe1a6,DISK], DatanodeInfoWithStorage[127.0.0.1:43734,DS-5ecadc66-91e9-442d-a996-6a633deb95b7,DISK], DatanodeInfoWithStorage[127.0.0.1:45484,DS-f39a5fd9-010f-41ec-a39e-7ae6348892c3,DISK], DatanodeInfoWithStorage[127.0.0.1:43031,DS-53a6d750-ed80-4470-808c-e6ac7fa0b79a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-850718117-172.17.0.14-1598088853614:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39311,DS-c25b38be-3bf9-4b4a-8bfa-a4b69d3001f2,DISK], DatanodeInfoWithStorage[127.0.0.1:38714,DS-2915ad60-d1e0-4206-8afb-02da129b95f8,DISK], DatanodeInfoWithStorage[127.0.0.1:46715,DS-c4e403fa-6446-4431-a9f4-2a747eddafb7,DISK], DatanodeInfoWithStorage[127.0.0.1:40579,DS-546001df-d131-454c-9209-e2729e0df33f,DISK], DatanodeInfoWithStorage[127.0.0.1:36641,DS-e36edbb7-77ca-41af-8a86-a7368d367bbc,DISK], DatanodeInfoWithStorage[127.0.0.1:46848,DS-e46cb15e-4f0e-4e7c-ae12-924f73ee1b88,DISK], DatanodeInfoWithStorage[127.0.0.1:42185,DS-2678075c-05b5-412c-aded-6a6be1dcfa28,DISK], DatanodeInfoWithStorage[127.0.0.1:43250,DS-647c75dc-e487-4cac-8eed-a630376f1276,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-850718117-172.17.0.14-1598088853614:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39311,DS-c25b38be-3bf9-4b4a-8bfa-a4b69d3001f2,DISK], DatanodeInfoWithStorage[127.0.0.1:38714,DS-2915ad60-d1e0-4206-8afb-02da129b95f8,DISK], DatanodeInfoWithStorage[127.0.0.1:46715,DS-c4e403fa-6446-4431-a9f4-2a747eddafb7,DISK], DatanodeInfoWithStorage[127.0.0.1:40579,DS-546001df-d131-454c-9209-e2729e0df33f,DISK], DatanodeInfoWithStorage[127.0.0.1:36641,DS-e36edbb7-77ca-41af-8a86-a7368d367bbc,DISK], DatanodeInfoWithStorage[127.0.0.1:46848,DS-e46cb15e-4f0e-4e7c-ae12-924f73ee1b88,DISK], DatanodeInfoWithStorage[127.0.0.1:42185,DS-2678075c-05b5-412c-aded-6a6be1dcfa28,DISK], DatanodeInfoWithStorage[127.0.0.1:43250,DS-647c75dc-e487-4cac-8eed-a630376f1276,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1395088240-172.17.0.14-1598089267796:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45081,DS-cbd360c9-6200-4b82-8f08-cb37efbb0df9,DISK], DatanodeInfoWithStorage[127.0.0.1:33325,DS-329d0093-8e70-4f49-921e-fb55fa0f11e8,DISK], DatanodeInfoWithStorage[127.0.0.1:44557,DS-38081821-7d75-4ae1-856c-35cc7f691cbc,DISK], DatanodeInfoWithStorage[127.0.0.1:38485,DS-d2b35fef-b5c1-48a9-be2d-451c4cc90f97,DISK], DatanodeInfoWithStorage[127.0.0.1:41437,DS-5936cbe4-56da-4151-98f1-d91ec3b1622d,DISK], DatanodeInfoWithStorage[127.0.0.1:33664,DS-c62e818a-f3a7-4a47-945a-2a1828836685,DISK], DatanodeInfoWithStorage[127.0.0.1:39409,DS-22e806a0-195e-47c6-8c70-cb6f0f927a60,DISK], DatanodeInfoWithStorage[127.0.0.1:42727,DS-334ac25c-a631-49c3-a299-d84bbabd8ba8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1395088240-172.17.0.14-1598089267796:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45081,DS-cbd360c9-6200-4b82-8f08-cb37efbb0df9,DISK], DatanodeInfoWithStorage[127.0.0.1:33325,DS-329d0093-8e70-4f49-921e-fb55fa0f11e8,DISK], DatanodeInfoWithStorage[127.0.0.1:44557,DS-38081821-7d75-4ae1-856c-35cc7f691cbc,DISK], DatanodeInfoWithStorage[127.0.0.1:38485,DS-d2b35fef-b5c1-48a9-be2d-451c4cc90f97,DISK], DatanodeInfoWithStorage[127.0.0.1:41437,DS-5936cbe4-56da-4151-98f1-d91ec3b1622d,DISK], DatanodeInfoWithStorage[127.0.0.1:33664,DS-c62e818a-f3a7-4a47-945a-2a1828836685,DISK], DatanodeInfoWithStorage[127.0.0.1:39409,DS-22e806a0-195e-47c6-8c70-cb6f0f927a60,DISK], DatanodeInfoWithStorage[127.0.0.1:42727,DS-334ac25c-a631-49c3-a299-d84bbabd8ba8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 6654
