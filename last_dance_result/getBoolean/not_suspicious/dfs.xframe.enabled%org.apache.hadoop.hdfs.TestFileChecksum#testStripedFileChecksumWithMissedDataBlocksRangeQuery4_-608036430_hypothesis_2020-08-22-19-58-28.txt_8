reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1406749447-172.17.0.21-1598126664137:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38876,DS-ab5cd179-dfaf-4fe4-9f27-3848ef1841c2,DISK], DatanodeInfoWithStorage[127.0.0.1:33954,DS-6d2d5211-6054-45ec-b6ca-0d449ac706bd,DISK], DatanodeInfoWithStorage[127.0.0.1:42276,DS-c8f34e11-536e-4ac3-b57f-8227a9c136ac,DISK], DatanodeInfoWithStorage[127.0.0.1:34794,DS-dce1ba77-ceef-44ce-ac75-1226f606cdeb,DISK], DatanodeInfoWithStorage[127.0.0.1:41671,DS-d6f0a44e-bdde-4442-b357-27b97cf85678,DISK], DatanodeInfoWithStorage[127.0.0.1:40790,DS-6a57b8e1-26fb-4999-acea-7632b28a43ca,DISK], DatanodeInfoWithStorage[127.0.0.1:42850,DS-e991f587-93ca-42a4-9af1-a4cf8644fcb8,DISK], DatanodeInfoWithStorage[127.0.0.1:35849,DS-bb90fad1-3fff-4dcb-b601-cd15937151ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1406749447-172.17.0.21-1598126664137:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38876,DS-ab5cd179-dfaf-4fe4-9f27-3848ef1841c2,DISK], DatanodeInfoWithStorage[127.0.0.1:33954,DS-6d2d5211-6054-45ec-b6ca-0d449ac706bd,DISK], DatanodeInfoWithStorage[127.0.0.1:42276,DS-c8f34e11-536e-4ac3-b57f-8227a9c136ac,DISK], DatanodeInfoWithStorage[127.0.0.1:34794,DS-dce1ba77-ceef-44ce-ac75-1226f606cdeb,DISK], DatanodeInfoWithStorage[127.0.0.1:41671,DS-d6f0a44e-bdde-4442-b357-27b97cf85678,DISK], DatanodeInfoWithStorage[127.0.0.1:40790,DS-6a57b8e1-26fb-4999-acea-7632b28a43ca,DISK], DatanodeInfoWithStorage[127.0.0.1:42850,DS-e991f587-93ca-42a4-9af1-a4cf8644fcb8,DISK], DatanodeInfoWithStorage[127.0.0.1:35849,DS-bb90fad1-3fff-4dcb-b601-cd15937151ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2055961748-172.17.0.21-1598126828106:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38353,DS-a41ffc07-224a-41bc-9c80-a28a144b4a93,DISK], DatanodeInfoWithStorage[127.0.0.1:36556,DS-de508963-2854-46a8-86a4-5fd124a26d26,DISK], DatanodeInfoWithStorage[127.0.0.1:33926,DS-5959b52e-7b86-47f8-8a38-ea44c1ba0233,DISK], DatanodeInfoWithStorage[127.0.0.1:36092,DS-b4d7815f-e7da-4b55-ba37-20a17d5a48c7,DISK], DatanodeInfoWithStorage[127.0.0.1:38657,DS-355fed9c-e272-45cc-be1c-ca6344dce988,DISK], DatanodeInfoWithStorage[127.0.0.1:42499,DS-9a53c6f0-7977-497d-b167-48238d9a9184,DISK], DatanodeInfoWithStorage[127.0.0.1:35623,DS-87ce5d2e-bc95-4a4d-a28d-633153e5bcda,DISK], DatanodeInfoWithStorage[127.0.0.1:37886,DS-dbd49cc3-cc60-4687-b86e-0a7e9780ba59,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2055961748-172.17.0.21-1598126828106:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38353,DS-a41ffc07-224a-41bc-9c80-a28a144b4a93,DISK], DatanodeInfoWithStorage[127.0.0.1:36556,DS-de508963-2854-46a8-86a4-5fd124a26d26,DISK], DatanodeInfoWithStorage[127.0.0.1:33926,DS-5959b52e-7b86-47f8-8a38-ea44c1ba0233,DISK], DatanodeInfoWithStorage[127.0.0.1:36092,DS-b4d7815f-e7da-4b55-ba37-20a17d5a48c7,DISK], DatanodeInfoWithStorage[127.0.0.1:38657,DS-355fed9c-e272-45cc-be1c-ca6344dce988,DISK], DatanodeInfoWithStorage[127.0.0.1:42499,DS-9a53c6f0-7977-497d-b167-48238d9a9184,DISK], DatanodeInfoWithStorage[127.0.0.1:35623,DS-87ce5d2e-bc95-4a4d-a28d-633153e5bcda,DISK], DatanodeInfoWithStorage[127.0.0.1:37886,DS-dbd49cc3-cc60-4687-b86e-0a7e9780ba59,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-158761575-172.17.0.21-1598127012062:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43117,DS-f204542a-6c72-4ccb-aa2b-6b8c2357caee,DISK], DatanodeInfoWithStorage[127.0.0.1:34480,DS-3dde19e6-d82a-4a28-8910-6d6238888529,DISK], DatanodeInfoWithStorage[127.0.0.1:35339,DS-d9e089b7-77da-41db-b2ab-c55737d214c2,DISK], DatanodeInfoWithStorage[127.0.0.1:37141,DS-98cfac09-7ba3-481e-9ad4-09cd6856909f,DISK], DatanodeInfoWithStorage[127.0.0.1:33547,DS-f447fb20-423b-4b23-aa41-ba2a3aae9684,DISK], DatanodeInfoWithStorage[127.0.0.1:38609,DS-665ee419-da1c-4529-84cc-22840b6158bc,DISK], DatanodeInfoWithStorage[127.0.0.1:35071,DS-fc01021c-226d-42e8-8749-ee8f828e9b72,DISK], DatanodeInfoWithStorage[127.0.0.1:34700,DS-28a7a8f1-0515-474a-ad64-d29bfba81e88,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-158761575-172.17.0.21-1598127012062:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43117,DS-f204542a-6c72-4ccb-aa2b-6b8c2357caee,DISK], DatanodeInfoWithStorage[127.0.0.1:34480,DS-3dde19e6-d82a-4a28-8910-6d6238888529,DISK], DatanodeInfoWithStorage[127.0.0.1:35339,DS-d9e089b7-77da-41db-b2ab-c55737d214c2,DISK], DatanodeInfoWithStorage[127.0.0.1:37141,DS-98cfac09-7ba3-481e-9ad4-09cd6856909f,DISK], DatanodeInfoWithStorage[127.0.0.1:33547,DS-f447fb20-423b-4b23-aa41-ba2a3aae9684,DISK], DatanodeInfoWithStorage[127.0.0.1:38609,DS-665ee419-da1c-4529-84cc-22840b6158bc,DISK], DatanodeInfoWithStorage[127.0.0.1:35071,DS-fc01021c-226d-42e8-8749-ee8f828e9b72,DISK], DatanodeInfoWithStorage[127.0.0.1:34700,DS-28a7a8f1-0515-474a-ad64-d29bfba81e88,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-906540170-172.17.0.21-1598127743620:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36524,DS-785b9e2e-9b76-468f-9985-164ae0b5587c,DISK], DatanodeInfoWithStorage[127.0.0.1:46136,DS-bfd43833-331b-44ba-ac96-bbac69ddaf8c,DISK], DatanodeInfoWithStorage[127.0.0.1:33040,DS-39b88355-cc33-45b9-be20-821f10022ecb,DISK], DatanodeInfoWithStorage[127.0.0.1:40184,DS-77facedb-ed83-4b4e-b0ac-9d6c26c2ae17,DISK], DatanodeInfoWithStorage[127.0.0.1:35350,DS-5d9a68c8-29c6-44c2-a7bc-dc627e3ae693,DISK], DatanodeInfoWithStorage[127.0.0.1:45888,DS-0d061935-5010-4ad1-9cc1-05333d3da453,DISK], DatanodeInfoWithStorage[127.0.0.1:38466,DS-58bb5152-4758-4cf9-8c01-23978220de07,DISK], DatanodeInfoWithStorage[127.0.0.1:35799,DS-2654ec65-2be9-43e3-8fc2-657bcb592ca6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-906540170-172.17.0.21-1598127743620:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36524,DS-785b9e2e-9b76-468f-9985-164ae0b5587c,DISK], DatanodeInfoWithStorage[127.0.0.1:46136,DS-bfd43833-331b-44ba-ac96-bbac69ddaf8c,DISK], DatanodeInfoWithStorage[127.0.0.1:33040,DS-39b88355-cc33-45b9-be20-821f10022ecb,DISK], DatanodeInfoWithStorage[127.0.0.1:40184,DS-77facedb-ed83-4b4e-b0ac-9d6c26c2ae17,DISK], DatanodeInfoWithStorage[127.0.0.1:35350,DS-5d9a68c8-29c6-44c2-a7bc-dc627e3ae693,DISK], DatanodeInfoWithStorage[127.0.0.1:45888,DS-0d061935-5010-4ad1-9cc1-05333d3da453,DISK], DatanodeInfoWithStorage[127.0.0.1:38466,DS-58bb5152-4758-4cf9-8c01-23978220de07,DISK], DatanodeInfoWithStorage[127.0.0.1:35799,DS-2654ec65-2be9-43e3-8fc2-657bcb592ca6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-172244921-172.17.0.21-1598127911110:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44741,DS-27d0adfc-6499-4b77-9a73-7f9b91a06391,DISK], DatanodeInfoWithStorage[127.0.0.1:46579,DS-93a2c11b-6651-49d6-bcb1-e95f77d99912,DISK], DatanodeInfoWithStorage[127.0.0.1:46728,DS-4c83053a-1a25-47c1-8302-7d09b6faa430,DISK], DatanodeInfoWithStorage[127.0.0.1:35164,DS-d28c60d9-414e-41d8-b1dd-353173d44331,DISK], DatanodeInfoWithStorage[127.0.0.1:43846,DS-f72f931a-1ea5-4c2e-b1e9-56b33c0532b3,DISK], DatanodeInfoWithStorage[127.0.0.1:46125,DS-ed4c5cfa-b01c-42cf-bdd3-92e32c7eac60,DISK], DatanodeInfoWithStorage[127.0.0.1:46178,DS-0bb92041-8289-474f-8ff4-28e6a6392cf5,DISK], DatanodeInfoWithStorage[127.0.0.1:46121,DS-40519039-ebb6-4559-852e-3ab0407938dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-172244921-172.17.0.21-1598127911110:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44741,DS-27d0adfc-6499-4b77-9a73-7f9b91a06391,DISK], DatanodeInfoWithStorage[127.0.0.1:46579,DS-93a2c11b-6651-49d6-bcb1-e95f77d99912,DISK], DatanodeInfoWithStorage[127.0.0.1:46728,DS-4c83053a-1a25-47c1-8302-7d09b6faa430,DISK], DatanodeInfoWithStorage[127.0.0.1:35164,DS-d28c60d9-414e-41d8-b1dd-353173d44331,DISK], DatanodeInfoWithStorage[127.0.0.1:43846,DS-f72f931a-1ea5-4c2e-b1e9-56b33c0532b3,DISK], DatanodeInfoWithStorage[127.0.0.1:46125,DS-ed4c5cfa-b01c-42cf-bdd3-92e32c7eac60,DISK], DatanodeInfoWithStorage[127.0.0.1:46178,DS-0bb92041-8289-474f-8ff4-28e6a6392cf5,DISK], DatanodeInfoWithStorage[127.0.0.1:46121,DS-40519039-ebb6-4559-852e-3ab0407938dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-401520967-172.17.0.21-1598128076823:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41494,DS-00485213-15aa-40b3-87a1-88f2adcee1f4,DISK], DatanodeInfoWithStorage[127.0.0.1:34315,DS-3532ea60-1090-4347-a2b7-3c37d6d02700,DISK], DatanodeInfoWithStorage[127.0.0.1:42641,DS-354d7e3a-7eec-49f3-8014-3738b4402500,DISK], DatanodeInfoWithStorage[127.0.0.1:38624,DS-839c266f-5da1-47c9-bf92-9b55525fafa9,DISK], DatanodeInfoWithStorage[127.0.0.1:43818,DS-b733f279-f29a-403a-9e95-e58696da70ba,DISK], DatanodeInfoWithStorage[127.0.0.1:42524,DS-eebce5ec-59ad-4018-9d93-56f6b4770fa3,DISK], DatanodeInfoWithStorage[127.0.0.1:42035,DS-0d77ca69-80dd-4987-bca4-84201ae89b28,DISK], DatanodeInfoWithStorage[127.0.0.1:41592,DS-baa5cf89-e386-4492-93d6-417d17401e22,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-401520967-172.17.0.21-1598128076823:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41494,DS-00485213-15aa-40b3-87a1-88f2adcee1f4,DISK], DatanodeInfoWithStorage[127.0.0.1:34315,DS-3532ea60-1090-4347-a2b7-3c37d6d02700,DISK], DatanodeInfoWithStorage[127.0.0.1:42641,DS-354d7e3a-7eec-49f3-8014-3738b4402500,DISK], DatanodeInfoWithStorage[127.0.0.1:38624,DS-839c266f-5da1-47c9-bf92-9b55525fafa9,DISK], DatanodeInfoWithStorage[127.0.0.1:43818,DS-b733f279-f29a-403a-9e95-e58696da70ba,DISK], DatanodeInfoWithStorage[127.0.0.1:42524,DS-eebce5ec-59ad-4018-9d93-56f6b4770fa3,DISK], DatanodeInfoWithStorage[127.0.0.1:42035,DS-0d77ca69-80dd-4987-bca4-84201ae89b28,DISK], DatanodeInfoWithStorage[127.0.0.1:41592,DS-baa5cf89-e386-4492-93d6-417d17401e22,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-271086144-172.17.0.21-1598128468182:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38470,DS-faa5e6a5-14b5-4914-ac31-9f291867588f,DISK], DatanodeInfoWithStorage[127.0.0.1:36496,DS-14d3a4be-b062-4734-9211-bad8c8a79bd1,DISK], DatanodeInfoWithStorage[127.0.0.1:37489,DS-2e1c910d-6bc2-4ec7-bb7b-97214eba8875,DISK], DatanodeInfoWithStorage[127.0.0.1:40811,DS-4f015b44-1094-4ede-b1e0-2bb62ebd8f7a,DISK], DatanodeInfoWithStorage[127.0.0.1:34345,DS-60959213-cf79-4c85-a5c2-8813a6ca3c9c,DISK], DatanodeInfoWithStorage[127.0.0.1:39512,DS-b1910ce9-a8bc-4884-8cfa-add6f313572c,DISK], DatanodeInfoWithStorage[127.0.0.1:45958,DS-1067c41d-259b-4439-9fab-d01144118089,DISK], DatanodeInfoWithStorage[127.0.0.1:43957,DS-35462f65-78f8-46b6-83c9-a9bf0563d196,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-271086144-172.17.0.21-1598128468182:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38470,DS-faa5e6a5-14b5-4914-ac31-9f291867588f,DISK], DatanodeInfoWithStorage[127.0.0.1:36496,DS-14d3a4be-b062-4734-9211-bad8c8a79bd1,DISK], DatanodeInfoWithStorage[127.0.0.1:37489,DS-2e1c910d-6bc2-4ec7-bb7b-97214eba8875,DISK], DatanodeInfoWithStorage[127.0.0.1:40811,DS-4f015b44-1094-4ede-b1e0-2bb62ebd8f7a,DISK], DatanodeInfoWithStorage[127.0.0.1:34345,DS-60959213-cf79-4c85-a5c2-8813a6ca3c9c,DISK], DatanodeInfoWithStorage[127.0.0.1:39512,DS-b1910ce9-a8bc-4884-8cfa-add6f313572c,DISK], DatanodeInfoWithStorage[127.0.0.1:45958,DS-1067c41d-259b-4439-9fab-d01144118089,DISK], DatanodeInfoWithStorage[127.0.0.1:43957,DS-35462f65-78f8-46b6-83c9-a9bf0563d196,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1507989044-172.17.0.21-1598128978373:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43912,DS-393bf9b9-4416-434d-a35c-1622b514337c,DISK], DatanodeInfoWithStorage[127.0.0.1:36697,DS-78a059fa-bd5a-4dfc-9ec2-880fa2359c77,DISK], DatanodeInfoWithStorage[127.0.0.1:36404,DS-c8a13e86-3ffb-40d9-a86c-01264e0e0708,DISK], DatanodeInfoWithStorage[127.0.0.1:33492,DS-b6e3044d-3102-41ff-93d4-c88734d7b793,DISK], DatanodeInfoWithStorage[127.0.0.1:36332,DS-3560ee1d-aeb3-4ca9-9e23-e7bbc7f0aa0a,DISK], DatanodeInfoWithStorage[127.0.0.1:38428,DS-524bebc7-40e7-4b25-a389-47b109176353,DISK], DatanodeInfoWithStorage[127.0.0.1:35283,DS-21059140-c57d-48a9-acc0-ca9de15a0b6b,DISK], DatanodeInfoWithStorage[127.0.0.1:36827,DS-fbb4e79c-3c89-4569-8471-316e9a71df12,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1507989044-172.17.0.21-1598128978373:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43912,DS-393bf9b9-4416-434d-a35c-1622b514337c,DISK], DatanodeInfoWithStorage[127.0.0.1:36697,DS-78a059fa-bd5a-4dfc-9ec2-880fa2359c77,DISK], DatanodeInfoWithStorage[127.0.0.1:36404,DS-c8a13e86-3ffb-40d9-a86c-01264e0e0708,DISK], DatanodeInfoWithStorage[127.0.0.1:33492,DS-b6e3044d-3102-41ff-93d4-c88734d7b793,DISK], DatanodeInfoWithStorage[127.0.0.1:36332,DS-3560ee1d-aeb3-4ca9-9e23-e7bbc7f0aa0a,DISK], DatanodeInfoWithStorage[127.0.0.1:38428,DS-524bebc7-40e7-4b25-a389-47b109176353,DISK], DatanodeInfoWithStorage[127.0.0.1:35283,DS-21059140-c57d-48a9-acc0-ca9de15a0b6b,DISK], DatanodeInfoWithStorage[127.0.0.1:36827,DS-fbb4e79c-3c89-4569-8471-316e9a71df12,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-151839409-172.17.0.21-1598129811554:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33685,DS-40b48f55-722d-4aae-9f13-198a411146d4,DISK], DatanodeInfoWithStorage[127.0.0.1:33868,DS-95393754-9d9b-4d5c-a50b-f471c153b443,DISK], DatanodeInfoWithStorage[127.0.0.1:35884,DS-c6f3b9a8-873b-4cf1-a0eb-d91971d776fd,DISK], DatanodeInfoWithStorage[127.0.0.1:38124,DS-a8af7333-0867-4fbb-94d8-8af3583f26bb,DISK], DatanodeInfoWithStorage[127.0.0.1:39825,DS-31001b1b-a398-4952-85d1-484633e989dd,DISK], DatanodeInfoWithStorage[127.0.0.1:33507,DS-6848fc8b-efd0-4536-a9a0-352b100d880c,DISK], DatanodeInfoWithStorage[127.0.0.1:45850,DS-5e599851-26ec-482a-a8a0-33f1bf25c161,DISK], DatanodeInfoWithStorage[127.0.0.1:36114,DS-58c10e1a-0e95-4b15-bb81-8042d259831b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-151839409-172.17.0.21-1598129811554:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33685,DS-40b48f55-722d-4aae-9f13-198a411146d4,DISK], DatanodeInfoWithStorage[127.0.0.1:33868,DS-95393754-9d9b-4d5c-a50b-f471c153b443,DISK], DatanodeInfoWithStorage[127.0.0.1:35884,DS-c6f3b9a8-873b-4cf1-a0eb-d91971d776fd,DISK], DatanodeInfoWithStorage[127.0.0.1:38124,DS-a8af7333-0867-4fbb-94d8-8af3583f26bb,DISK], DatanodeInfoWithStorage[127.0.0.1:39825,DS-31001b1b-a398-4952-85d1-484633e989dd,DISK], DatanodeInfoWithStorage[127.0.0.1:33507,DS-6848fc8b-efd0-4536-a9a0-352b100d880c,DISK], DatanodeInfoWithStorage[127.0.0.1:45850,DS-5e599851-26ec-482a-a8a0-33f1bf25c161,DISK], DatanodeInfoWithStorage[127.0.0.1:36114,DS-58c10e1a-0e95-4b15-bb81-8042d259831b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1342423973-172.17.0.21-1598129921567:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39687,DS-c7eef371-5dbd-4973-bbe4-63b424d0430d,DISK], DatanodeInfoWithStorage[127.0.0.1:34659,DS-f7d7b2d9-6b84-45b4-9d1c-eed7ad97de99,DISK], DatanodeInfoWithStorage[127.0.0.1:43053,DS-a684e351-9394-4600-bbca-68d5ff7ff1e0,DISK], DatanodeInfoWithStorage[127.0.0.1:43273,DS-3b3b914b-cc6e-4f14-a18e-bb4f3f8b636e,DISK], DatanodeInfoWithStorage[127.0.0.1:40715,DS-9cb11ddd-0802-479a-9c45-3d2b1f0a924c,DISK], DatanodeInfoWithStorage[127.0.0.1:38827,DS-bc135def-acbe-4c0c-869c-e5269178ea78,DISK], DatanodeInfoWithStorage[127.0.0.1:34951,DS-5e507070-abb8-4a55-b9b2-8250c06e9a7c,DISK], DatanodeInfoWithStorage[127.0.0.1:40788,DS-4621b249-df29-4f4c-bc38-c7584cf8ae6b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1342423973-172.17.0.21-1598129921567:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39687,DS-c7eef371-5dbd-4973-bbe4-63b424d0430d,DISK], DatanodeInfoWithStorage[127.0.0.1:34659,DS-f7d7b2d9-6b84-45b4-9d1c-eed7ad97de99,DISK], DatanodeInfoWithStorage[127.0.0.1:43053,DS-a684e351-9394-4600-bbca-68d5ff7ff1e0,DISK], DatanodeInfoWithStorage[127.0.0.1:43273,DS-3b3b914b-cc6e-4f14-a18e-bb4f3f8b636e,DISK], DatanodeInfoWithStorage[127.0.0.1:40715,DS-9cb11ddd-0802-479a-9c45-3d2b1f0a924c,DISK], DatanodeInfoWithStorage[127.0.0.1:38827,DS-bc135def-acbe-4c0c-869c-e5269178ea78,DISK], DatanodeInfoWithStorage[127.0.0.1:34951,DS-5e507070-abb8-4a55-b9b2-8250c06e9a7c,DISK], DatanodeInfoWithStorage[127.0.0.1:40788,DS-4621b249-df29-4f4c-bc38-c7584cf8ae6b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-324701417-172.17.0.21-1598130327710:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41480,DS-960f6edf-30bb-4c59-a8fe-0b60f293a891,DISK], DatanodeInfoWithStorage[127.0.0.1:46826,DS-86a94ec5-55ff-4bc2-a14b-dd36a5383875,DISK], DatanodeInfoWithStorage[127.0.0.1:39039,DS-dfa5c7a2-4a96-4763-83ce-767678e33366,DISK], DatanodeInfoWithStorage[127.0.0.1:40142,DS-bcd37936-5ad7-45bf-86eb-1156990df57f,DISK], DatanodeInfoWithStorage[127.0.0.1:42476,DS-91a60b9b-0023-407a-93fe-35165dde0102,DISK], DatanodeInfoWithStorage[127.0.0.1:42214,DS-4695a52c-f1e6-4ddd-9eab-6e0ca51b97ad,DISK], DatanodeInfoWithStorage[127.0.0.1:41546,DS-6dd90b89-9ae3-46a7-a9e7-3be6f340ae84,DISK], DatanodeInfoWithStorage[127.0.0.1:37313,DS-b16ff2e2-f83e-4bfc-b934-64bc80417f6c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-324701417-172.17.0.21-1598130327710:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41480,DS-960f6edf-30bb-4c59-a8fe-0b60f293a891,DISK], DatanodeInfoWithStorage[127.0.0.1:46826,DS-86a94ec5-55ff-4bc2-a14b-dd36a5383875,DISK], DatanodeInfoWithStorage[127.0.0.1:39039,DS-dfa5c7a2-4a96-4763-83ce-767678e33366,DISK], DatanodeInfoWithStorage[127.0.0.1:40142,DS-bcd37936-5ad7-45bf-86eb-1156990df57f,DISK], DatanodeInfoWithStorage[127.0.0.1:42476,DS-91a60b9b-0023-407a-93fe-35165dde0102,DISK], DatanodeInfoWithStorage[127.0.0.1:42214,DS-4695a52c-f1e6-4ddd-9eab-6e0ca51b97ad,DISK], DatanodeInfoWithStorage[127.0.0.1:41546,DS-6dd90b89-9ae3-46a7-a9e7-3be6f340ae84,DISK], DatanodeInfoWithStorage[127.0.0.1:37313,DS-b16ff2e2-f83e-4bfc-b934-64bc80417f6c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-719455022-172.17.0.21-1598130462060:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41986,DS-6488353e-04d5-48e3-ab47-e56effd7cf6e,DISK], DatanodeInfoWithStorage[127.0.0.1:34784,DS-e884ee52-eff7-4b08-acc5-bd4d3c6ead86,DISK], DatanodeInfoWithStorage[127.0.0.1:42416,DS-eda093ec-db3c-493d-9871-5ad30d560495,DISK], DatanodeInfoWithStorage[127.0.0.1:34547,DS-eb8fa241-b455-47bc-9c57-e5c72e527c46,DISK], DatanodeInfoWithStorage[127.0.0.1:45592,DS-ed5ae184-8ec0-483e-8ee2-6d703ba3619e,DISK], DatanodeInfoWithStorage[127.0.0.1:46491,DS-7b7127a2-5fd6-47bd-9480-c2428039cf4e,DISK], DatanodeInfoWithStorage[127.0.0.1:45992,DS-c8406f5d-62da-48bc-a8be-2d86b94cf488,DISK], DatanodeInfoWithStorage[127.0.0.1:41783,DS-524c5d1f-847a-4de8-8fba-91a3d642e1b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-719455022-172.17.0.21-1598130462060:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41986,DS-6488353e-04d5-48e3-ab47-e56effd7cf6e,DISK], DatanodeInfoWithStorage[127.0.0.1:34784,DS-e884ee52-eff7-4b08-acc5-bd4d3c6ead86,DISK], DatanodeInfoWithStorage[127.0.0.1:42416,DS-eda093ec-db3c-493d-9871-5ad30d560495,DISK], DatanodeInfoWithStorage[127.0.0.1:34547,DS-eb8fa241-b455-47bc-9c57-e5c72e527c46,DISK], DatanodeInfoWithStorage[127.0.0.1:45592,DS-ed5ae184-8ec0-483e-8ee2-6d703ba3619e,DISK], DatanodeInfoWithStorage[127.0.0.1:46491,DS-7b7127a2-5fd6-47bd-9480-c2428039cf4e,DISK], DatanodeInfoWithStorage[127.0.0.1:45992,DS-c8406f5d-62da-48bc-a8be-2d86b94cf488,DISK], DatanodeInfoWithStorage[127.0.0.1:41783,DS-524c5d1f-847a-4de8-8fba-91a3d642e1b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2023877274-172.17.0.21-1598130897352:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44877,DS-cb5f4239-239b-4f08-a746-67fa99fdba90,DISK], DatanodeInfoWithStorage[127.0.0.1:39706,DS-78cb5496-25bc-4f21-b3c5-ba900146efca,DISK], DatanodeInfoWithStorage[127.0.0.1:45655,DS-6c80f931-48ee-4ea1-9bfe-703c4e33b598,DISK], DatanodeInfoWithStorage[127.0.0.1:33464,DS-49c9ef0f-2f5c-4543-b73c-a38682f7fc1b,DISK], DatanodeInfoWithStorage[127.0.0.1:34120,DS-48f3fba3-aa77-4f0f-b699-8bd1a3f59368,DISK], DatanodeInfoWithStorage[127.0.0.1:39610,DS-a21f4e80-8439-41f9-a9be-c677d9dfa8f7,DISK], DatanodeInfoWithStorage[127.0.0.1:44253,DS-8cecb12b-39c3-449c-9a00-ae158b1c15d9,DISK], DatanodeInfoWithStorage[127.0.0.1:46221,DS-ec60f347-cfaa-4ed3-bc67-d2e258e19480,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2023877274-172.17.0.21-1598130897352:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44877,DS-cb5f4239-239b-4f08-a746-67fa99fdba90,DISK], DatanodeInfoWithStorage[127.0.0.1:39706,DS-78cb5496-25bc-4f21-b3c5-ba900146efca,DISK], DatanodeInfoWithStorage[127.0.0.1:45655,DS-6c80f931-48ee-4ea1-9bfe-703c4e33b598,DISK], DatanodeInfoWithStorage[127.0.0.1:33464,DS-49c9ef0f-2f5c-4543-b73c-a38682f7fc1b,DISK], DatanodeInfoWithStorage[127.0.0.1:34120,DS-48f3fba3-aa77-4f0f-b699-8bd1a3f59368,DISK], DatanodeInfoWithStorage[127.0.0.1:39610,DS-a21f4e80-8439-41f9-a9be-c677d9dfa8f7,DISK], DatanodeInfoWithStorage[127.0.0.1:44253,DS-8cecb12b-39c3-449c-9a00-ae158b1c15d9,DISK], DatanodeInfoWithStorage[127.0.0.1:46221,DS-ec60f347-cfaa-4ed3-bc67-d2e258e19480,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5353
