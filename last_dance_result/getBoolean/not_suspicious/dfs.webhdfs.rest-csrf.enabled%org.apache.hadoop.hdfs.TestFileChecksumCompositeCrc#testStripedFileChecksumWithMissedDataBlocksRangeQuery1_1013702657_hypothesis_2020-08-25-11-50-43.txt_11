reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-542219447-172.17.0.11-1598356291341:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44044,DS-2e13a83c-3661-4791-9af4-150183f9c7bc,DISK], DatanodeInfoWithStorage[127.0.0.1:38968,DS-0794691f-23b9-4f15-9296-4a84f722b26c,DISK], DatanodeInfoWithStorage[127.0.0.1:34213,DS-9f13135d-5509-437b-b2a3-30649e6e9027,DISK], DatanodeInfoWithStorage[127.0.0.1:41032,DS-0e52191c-f8e3-46c3-8dc4-7b141605d99b,DISK], DatanodeInfoWithStorage[127.0.0.1:43655,DS-3caefa97-4a63-4cd1-880d-c339c5d0828b,DISK], DatanodeInfoWithStorage[127.0.0.1:34866,DS-965ef9c7-d038-4862-965c-7618d24b846e,DISK], DatanodeInfoWithStorage[127.0.0.1:45001,DS-3b640063-32b6-43b8-bff2-15710a0861e0,DISK], DatanodeInfoWithStorage[127.0.0.1:44425,DS-5ab4364e-5ed5-47a2-8a94-0402b5c005ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-542219447-172.17.0.11-1598356291341:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44044,DS-2e13a83c-3661-4791-9af4-150183f9c7bc,DISK], DatanodeInfoWithStorage[127.0.0.1:38968,DS-0794691f-23b9-4f15-9296-4a84f722b26c,DISK], DatanodeInfoWithStorage[127.0.0.1:34213,DS-9f13135d-5509-437b-b2a3-30649e6e9027,DISK], DatanodeInfoWithStorage[127.0.0.1:41032,DS-0e52191c-f8e3-46c3-8dc4-7b141605d99b,DISK], DatanodeInfoWithStorage[127.0.0.1:43655,DS-3caefa97-4a63-4cd1-880d-c339c5d0828b,DISK], DatanodeInfoWithStorage[127.0.0.1:34866,DS-965ef9c7-d038-4862-965c-7618d24b846e,DISK], DatanodeInfoWithStorage[127.0.0.1:45001,DS-3b640063-32b6-43b8-bff2-15710a0861e0,DISK], DatanodeInfoWithStorage[127.0.0.1:44425,DS-5ab4364e-5ed5-47a2-8a94-0402b5c005ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1942702370-172.17.0.11-1598356386448:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45931,DS-3bb6eecc-b072-43cc-a647-5a8bf9b57aec,DISK], DatanodeInfoWithStorage[127.0.0.1:41321,DS-1641f414-afe1-4665-bbfa-2196d73bc4fb,DISK], DatanodeInfoWithStorage[127.0.0.1:37313,DS-8c3c1c6c-a078-4da9-8a86-6375d54b73ba,DISK], DatanodeInfoWithStorage[127.0.0.1:36051,DS-8e80afe4-f43d-418f-8425-4ac0c367b547,DISK], DatanodeInfoWithStorage[127.0.0.1:37928,DS-cdae5615-feee-4e54-a16a-e280537a204e,DISK], DatanodeInfoWithStorage[127.0.0.1:36075,DS-e85a1638-f7a9-4275-bd83-37ca7c1d5b14,DISK], DatanodeInfoWithStorage[127.0.0.1:43880,DS-908edd58-8c09-4b96-a9b2-85c6be9eda4a,DISK], DatanodeInfoWithStorage[127.0.0.1:34302,DS-ae42676f-e22f-4834-bad6-15e5321a66e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1942702370-172.17.0.11-1598356386448:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45931,DS-3bb6eecc-b072-43cc-a647-5a8bf9b57aec,DISK], DatanodeInfoWithStorage[127.0.0.1:41321,DS-1641f414-afe1-4665-bbfa-2196d73bc4fb,DISK], DatanodeInfoWithStorage[127.0.0.1:37313,DS-8c3c1c6c-a078-4da9-8a86-6375d54b73ba,DISK], DatanodeInfoWithStorage[127.0.0.1:36051,DS-8e80afe4-f43d-418f-8425-4ac0c367b547,DISK], DatanodeInfoWithStorage[127.0.0.1:37928,DS-cdae5615-feee-4e54-a16a-e280537a204e,DISK], DatanodeInfoWithStorage[127.0.0.1:36075,DS-e85a1638-f7a9-4275-bd83-37ca7c1d5b14,DISK], DatanodeInfoWithStorage[127.0.0.1:43880,DS-908edd58-8c09-4b96-a9b2-85c6be9eda4a,DISK], DatanodeInfoWithStorage[127.0.0.1:34302,DS-ae42676f-e22f-4834-bad6-15e5321a66e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1134759539-172.17.0.11-1598356466396:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41990,DS-aadf6036-b71a-4bdc-96d1-11fdf8d2aaa4,DISK], DatanodeInfoWithStorage[127.0.0.1:37141,DS-d69b11ba-127e-4fba-987a-e7425f73ab62,DISK], DatanodeInfoWithStorage[127.0.0.1:36502,DS-37da857e-6f54-4761-8eb9-d0d127994efe,DISK], DatanodeInfoWithStorage[127.0.0.1:37098,DS-23d1af2e-4af9-4658-ba95-250a308a4004,DISK], DatanodeInfoWithStorage[127.0.0.1:35998,DS-ba9e90c1-b31b-4f36-b25b-301efefa0121,DISK], DatanodeInfoWithStorage[127.0.0.1:42893,DS-a0dda718-4465-4763-9316-c0a6e7debe48,DISK], DatanodeInfoWithStorage[127.0.0.1:44368,DS-6f890549-bb52-4848-8299-117b07016004,DISK], DatanodeInfoWithStorage[127.0.0.1:44201,DS-b07f22b0-6761-4a43-a33a-60edcc6b09f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1134759539-172.17.0.11-1598356466396:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41990,DS-aadf6036-b71a-4bdc-96d1-11fdf8d2aaa4,DISK], DatanodeInfoWithStorage[127.0.0.1:37141,DS-d69b11ba-127e-4fba-987a-e7425f73ab62,DISK], DatanodeInfoWithStorage[127.0.0.1:36502,DS-37da857e-6f54-4761-8eb9-d0d127994efe,DISK], DatanodeInfoWithStorage[127.0.0.1:37098,DS-23d1af2e-4af9-4658-ba95-250a308a4004,DISK], DatanodeInfoWithStorage[127.0.0.1:35998,DS-ba9e90c1-b31b-4f36-b25b-301efefa0121,DISK], DatanodeInfoWithStorage[127.0.0.1:42893,DS-a0dda718-4465-4763-9316-c0a6e7debe48,DISK], DatanodeInfoWithStorage[127.0.0.1:44368,DS-6f890549-bb52-4848-8299-117b07016004,DISK], DatanodeInfoWithStorage[127.0.0.1:44201,DS-b07f22b0-6761-4a43-a33a-60edcc6b09f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1014878831-172.17.0.11-1598356604620:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45804,DS-9d666d23-b564-4a07-9db2-ae6d3e6bd714,DISK], DatanodeInfoWithStorage[127.0.0.1:46586,DS-03c868a1-19d8-44b2-85e8-c959d9567deb,DISK], DatanodeInfoWithStorage[127.0.0.1:44366,DS-39904f53-bfba-40a3-a414-da395028a31b,DISK], DatanodeInfoWithStorage[127.0.0.1:44906,DS-51106da6-0639-483a-b2e5-b90406ddb29a,DISK], DatanodeInfoWithStorage[127.0.0.1:33554,DS-7d6891be-cc50-4f9c-96e4-523b2b66d6d9,DISK], DatanodeInfoWithStorage[127.0.0.1:38801,DS-e9585011-841e-41a9-aad8-5ad3841f53ac,DISK], DatanodeInfoWithStorage[127.0.0.1:37945,DS-3eae26f4-f406-42f5-a03c-f633074a1932,DISK], DatanodeInfoWithStorage[127.0.0.1:36017,DS-7692b9e5-a411-41e5-bb9a-b36553c4e66a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1014878831-172.17.0.11-1598356604620:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45804,DS-9d666d23-b564-4a07-9db2-ae6d3e6bd714,DISK], DatanodeInfoWithStorage[127.0.0.1:46586,DS-03c868a1-19d8-44b2-85e8-c959d9567deb,DISK], DatanodeInfoWithStorage[127.0.0.1:44366,DS-39904f53-bfba-40a3-a414-da395028a31b,DISK], DatanodeInfoWithStorage[127.0.0.1:44906,DS-51106da6-0639-483a-b2e5-b90406ddb29a,DISK], DatanodeInfoWithStorage[127.0.0.1:33554,DS-7d6891be-cc50-4f9c-96e4-523b2b66d6d9,DISK], DatanodeInfoWithStorage[127.0.0.1:38801,DS-e9585011-841e-41a9-aad8-5ad3841f53ac,DISK], DatanodeInfoWithStorage[127.0.0.1:37945,DS-3eae26f4-f406-42f5-a03c-f633074a1932,DISK], DatanodeInfoWithStorage[127.0.0.1:36017,DS-7692b9e5-a411-41e5-bb9a-b36553c4e66a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1915154448-172.17.0.11-1598356912937:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38336,DS-06de937d-a765-4123-983a-13c85f446b80,DISK], DatanodeInfoWithStorage[127.0.0.1:35764,DS-a75c77ed-5e12-46f5-90d6-75e7383e6ada,DISK], DatanodeInfoWithStorage[127.0.0.1:33393,DS-0f0d8aa9-4e50-41f7-9dbc-d12ce7982edb,DISK], DatanodeInfoWithStorage[127.0.0.1:36011,DS-2cef1f93-7d93-4ec7-88cc-991f207584e6,DISK], DatanodeInfoWithStorage[127.0.0.1:36819,DS-8c7392ba-5b56-4aed-83d7-b136a861bf7c,DISK], DatanodeInfoWithStorage[127.0.0.1:43494,DS-1dbf9597-f9af-4a78-8336-82447276a034,DISK], DatanodeInfoWithStorage[127.0.0.1:39198,DS-d37cba9b-bdfa-458c-a5c2-55843c01c42b,DISK], DatanodeInfoWithStorage[127.0.0.1:39038,DS-376fe437-62f4-4542-9ba6-d5fdb2209931,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1915154448-172.17.0.11-1598356912937:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38336,DS-06de937d-a765-4123-983a-13c85f446b80,DISK], DatanodeInfoWithStorage[127.0.0.1:35764,DS-a75c77ed-5e12-46f5-90d6-75e7383e6ada,DISK], DatanodeInfoWithStorage[127.0.0.1:33393,DS-0f0d8aa9-4e50-41f7-9dbc-d12ce7982edb,DISK], DatanodeInfoWithStorage[127.0.0.1:36011,DS-2cef1f93-7d93-4ec7-88cc-991f207584e6,DISK], DatanodeInfoWithStorage[127.0.0.1:36819,DS-8c7392ba-5b56-4aed-83d7-b136a861bf7c,DISK], DatanodeInfoWithStorage[127.0.0.1:43494,DS-1dbf9597-f9af-4a78-8336-82447276a034,DISK], DatanodeInfoWithStorage[127.0.0.1:39198,DS-d37cba9b-bdfa-458c-a5c2-55843c01c42b,DISK], DatanodeInfoWithStorage[127.0.0.1:39038,DS-376fe437-62f4-4542-9ba6-d5fdb2209931,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-491546066-172.17.0.11-1598357210731:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45993,DS-c6cf1d6b-9f0a-4ef1-a4b9-f5a326269b1c,DISK], DatanodeInfoWithStorage[127.0.0.1:45260,DS-fc1f23cf-a8a1-4eb5-85a5-2e1c0612813f,DISK], DatanodeInfoWithStorage[127.0.0.1:40781,DS-0ad940c7-294e-4f5c-8c37-391872941ddb,DISK], DatanodeInfoWithStorage[127.0.0.1:45193,DS-44fb3344-bc6b-4f85-b8e5-82fd5d8acbea,DISK], DatanodeInfoWithStorage[127.0.0.1:44381,DS-73d88159-4b74-4929-8188-da6823731b27,DISK], DatanodeInfoWithStorage[127.0.0.1:34800,DS-212c033a-4c96-4b69-b0d7-b715a889604d,DISK], DatanodeInfoWithStorage[127.0.0.1:45943,DS-e5ecdc0a-6a42-49c3-a650-98c1ac347a14,DISK], DatanodeInfoWithStorage[127.0.0.1:45657,DS-4ca6bdc9-2bc5-4692-b0ce-fb2dd01e52b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-491546066-172.17.0.11-1598357210731:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45993,DS-c6cf1d6b-9f0a-4ef1-a4b9-f5a326269b1c,DISK], DatanodeInfoWithStorage[127.0.0.1:45260,DS-fc1f23cf-a8a1-4eb5-85a5-2e1c0612813f,DISK], DatanodeInfoWithStorage[127.0.0.1:40781,DS-0ad940c7-294e-4f5c-8c37-391872941ddb,DISK], DatanodeInfoWithStorage[127.0.0.1:45193,DS-44fb3344-bc6b-4f85-b8e5-82fd5d8acbea,DISK], DatanodeInfoWithStorage[127.0.0.1:44381,DS-73d88159-4b74-4929-8188-da6823731b27,DISK], DatanodeInfoWithStorage[127.0.0.1:34800,DS-212c033a-4c96-4b69-b0d7-b715a889604d,DISK], DatanodeInfoWithStorage[127.0.0.1:45943,DS-e5ecdc0a-6a42-49c3-a650-98c1ac347a14,DISK], DatanodeInfoWithStorage[127.0.0.1:45657,DS-4ca6bdc9-2bc5-4692-b0ce-fb2dd01e52b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-616258204-172.17.0.11-1598357417270:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46550,DS-df4026d5-698f-4c08-9263-d06d73f7de35,DISK], DatanodeInfoWithStorage[127.0.0.1:39163,DS-41aa240d-5e2c-4355-b55d-61d894d4caef,DISK], DatanodeInfoWithStorage[127.0.0.1:45230,DS-cbc8da50-f973-41e6-bc48-c80dfdd91527,DISK], DatanodeInfoWithStorage[127.0.0.1:37931,DS-a40cace3-7e9b-4462-845d-a07bbe7aae97,DISK], DatanodeInfoWithStorage[127.0.0.1:40037,DS-e94ca1c6-afdf-43ce-b88b-2e83183cecc6,DISK], DatanodeInfoWithStorage[127.0.0.1:41193,DS-12085bc0-b084-4721-9748-f8710f59efaa,DISK], DatanodeInfoWithStorage[127.0.0.1:37432,DS-5c61dad4-49b2-470c-ac18-45de5b4021b9,DISK], DatanodeInfoWithStorage[127.0.0.1:33839,DS-0ff8fe50-0e87-47e8-86c9-bfd8a142119b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-616258204-172.17.0.11-1598357417270:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46550,DS-df4026d5-698f-4c08-9263-d06d73f7de35,DISK], DatanodeInfoWithStorage[127.0.0.1:39163,DS-41aa240d-5e2c-4355-b55d-61d894d4caef,DISK], DatanodeInfoWithStorage[127.0.0.1:45230,DS-cbc8da50-f973-41e6-bc48-c80dfdd91527,DISK], DatanodeInfoWithStorage[127.0.0.1:37931,DS-a40cace3-7e9b-4462-845d-a07bbe7aae97,DISK], DatanodeInfoWithStorage[127.0.0.1:40037,DS-e94ca1c6-afdf-43ce-b88b-2e83183cecc6,DISK], DatanodeInfoWithStorage[127.0.0.1:41193,DS-12085bc0-b084-4721-9748-f8710f59efaa,DISK], DatanodeInfoWithStorage[127.0.0.1:37432,DS-5c61dad4-49b2-470c-ac18-45de5b4021b9,DISK], DatanodeInfoWithStorage[127.0.0.1:33839,DS-0ff8fe50-0e87-47e8-86c9-bfd8a142119b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2097611751-172.17.0.11-1598358055279:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33405,DS-bb2ca906-d742-49ab-8117-aa48690f71f2,DISK], DatanodeInfoWithStorage[127.0.0.1:44324,DS-85b96136-2636-4ab2-99a3-18e4c4aaee09,DISK], DatanodeInfoWithStorage[127.0.0.1:36046,DS-06897f33-c930-4e18-8fc0-ceb6c7fae4ad,DISK], DatanodeInfoWithStorage[127.0.0.1:43107,DS-c7b6c908-729a-49c0-8583-e7fa5f9f2224,DISK], DatanodeInfoWithStorage[127.0.0.1:45231,DS-0dd79fad-7b87-477f-9268-1b124436779e,DISK], DatanodeInfoWithStorage[127.0.0.1:38692,DS-b3b2bb22-1acc-406d-a67c-539397869163,DISK], DatanodeInfoWithStorage[127.0.0.1:37472,DS-5cc2546f-91c9-426c-8a3c-bc2fdf48331c,DISK], DatanodeInfoWithStorage[127.0.0.1:38699,DS-ce90a7ea-013c-44c2-a7fa-be91b674d2f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2097611751-172.17.0.11-1598358055279:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33405,DS-bb2ca906-d742-49ab-8117-aa48690f71f2,DISK], DatanodeInfoWithStorage[127.0.0.1:44324,DS-85b96136-2636-4ab2-99a3-18e4c4aaee09,DISK], DatanodeInfoWithStorage[127.0.0.1:36046,DS-06897f33-c930-4e18-8fc0-ceb6c7fae4ad,DISK], DatanodeInfoWithStorage[127.0.0.1:43107,DS-c7b6c908-729a-49c0-8583-e7fa5f9f2224,DISK], DatanodeInfoWithStorage[127.0.0.1:45231,DS-0dd79fad-7b87-477f-9268-1b124436779e,DISK], DatanodeInfoWithStorage[127.0.0.1:38692,DS-b3b2bb22-1acc-406d-a67c-539397869163,DISK], DatanodeInfoWithStorage[127.0.0.1:37472,DS-5cc2546f-91c9-426c-8a3c-bc2fdf48331c,DISK], DatanodeInfoWithStorage[127.0.0.1:38699,DS-ce90a7ea-013c-44c2-a7fa-be91b674d2f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-991274056-172.17.0.11-1598358086521:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44900,DS-144e6eec-7edb-45ea-923c-1677137644f4,DISK], DatanodeInfoWithStorage[127.0.0.1:41166,DS-e4cc5f49-1ee8-4db6-bffa-fb8ec874e8c1,DISK], DatanodeInfoWithStorage[127.0.0.1:42576,DS-19665aba-fc17-49fa-800a-ac5812dc94d3,DISK], DatanodeInfoWithStorage[127.0.0.1:33502,DS-6459e323-5aa0-4adb-88ab-232ad578a9c2,DISK], DatanodeInfoWithStorage[127.0.0.1:37796,DS-09c2a795-c9d6-4b3c-b192-c114b1460e16,DISK], DatanodeInfoWithStorage[127.0.0.1:33848,DS-3351b268-2ac4-49b1-8841-54e5264c0670,DISK], DatanodeInfoWithStorage[127.0.0.1:35406,DS-ca0dc7da-c39c-4d11-863d-386fa2718015,DISK], DatanodeInfoWithStorage[127.0.0.1:32970,DS-b09c2896-f192-4af9-8c28-2ae5ae247dc5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-991274056-172.17.0.11-1598358086521:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44900,DS-144e6eec-7edb-45ea-923c-1677137644f4,DISK], DatanodeInfoWithStorage[127.0.0.1:41166,DS-e4cc5f49-1ee8-4db6-bffa-fb8ec874e8c1,DISK], DatanodeInfoWithStorage[127.0.0.1:42576,DS-19665aba-fc17-49fa-800a-ac5812dc94d3,DISK], DatanodeInfoWithStorage[127.0.0.1:33502,DS-6459e323-5aa0-4adb-88ab-232ad578a9c2,DISK], DatanodeInfoWithStorage[127.0.0.1:37796,DS-09c2a795-c9d6-4b3c-b192-c114b1460e16,DISK], DatanodeInfoWithStorage[127.0.0.1:33848,DS-3351b268-2ac4-49b1-8841-54e5264c0670,DISK], DatanodeInfoWithStorage[127.0.0.1:35406,DS-ca0dc7da-c39c-4d11-863d-386fa2718015,DISK], DatanodeInfoWithStorage[127.0.0.1:32970,DS-b09c2896-f192-4af9-8c28-2ae5ae247dc5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1798704720-172.17.0.11-1598358243877:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33877,DS-15d16454-1b95-40b2-8ed4-3fed6e4f6d8b,DISK], DatanodeInfoWithStorage[127.0.0.1:44834,DS-23ae4835-1e08-4d8b-8a0e-3c350d1175a8,DISK], DatanodeInfoWithStorage[127.0.0.1:35459,DS-da79b8c4-b6fb-4000-bfbe-18eb29e4a85e,DISK], DatanodeInfoWithStorage[127.0.0.1:43537,DS-66939232-6e5c-435c-b917-8848bbae2da9,DISK], DatanodeInfoWithStorage[127.0.0.1:35945,DS-23cd5322-c2f3-41bf-a482-7ed9bc882dbd,DISK], DatanodeInfoWithStorage[127.0.0.1:38422,DS-4a290ad2-b039-4998-90a2-b5edf9777afa,DISK], DatanodeInfoWithStorage[127.0.0.1:42911,DS-2bfb7621-f0c5-4543-861a-5de485989301,DISK], DatanodeInfoWithStorage[127.0.0.1:44819,DS-551b289f-b42d-44ea-a609-84d78ff81a6e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1798704720-172.17.0.11-1598358243877:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33877,DS-15d16454-1b95-40b2-8ed4-3fed6e4f6d8b,DISK], DatanodeInfoWithStorage[127.0.0.1:44834,DS-23ae4835-1e08-4d8b-8a0e-3c350d1175a8,DISK], DatanodeInfoWithStorage[127.0.0.1:35459,DS-da79b8c4-b6fb-4000-bfbe-18eb29e4a85e,DISK], DatanodeInfoWithStorage[127.0.0.1:43537,DS-66939232-6e5c-435c-b917-8848bbae2da9,DISK], DatanodeInfoWithStorage[127.0.0.1:35945,DS-23cd5322-c2f3-41bf-a482-7ed9bc882dbd,DISK], DatanodeInfoWithStorage[127.0.0.1:38422,DS-4a290ad2-b039-4998-90a2-b5edf9777afa,DISK], DatanodeInfoWithStorage[127.0.0.1:42911,DS-2bfb7621-f0c5-4543-861a-5de485989301,DISK], DatanodeInfoWithStorage[127.0.0.1:44819,DS-551b289f-b42d-44ea-a609-84d78ff81a6e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1151868125-172.17.0.11-1598358279720:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41867,DS-bd9d9b8d-39db-41db-868e-e91b09c75f04,DISK], DatanodeInfoWithStorage[127.0.0.1:36420,DS-689b3e0d-62f8-4baf-860d-a4a3b6f0f518,DISK], DatanodeInfoWithStorage[127.0.0.1:40676,DS-b81c8482-3936-46c5-bf80-d8513e989ed8,DISK], DatanodeInfoWithStorage[127.0.0.1:42429,DS-5daa0048-dbde-4425-98cc-49971804359e,DISK], DatanodeInfoWithStorage[127.0.0.1:39000,DS-15132814-d055-4de5-a3ee-de1c726e6a12,DISK], DatanodeInfoWithStorage[127.0.0.1:42030,DS-7d7c97cb-06c4-44ac-bd07-a449ebf91f53,DISK], DatanodeInfoWithStorage[127.0.0.1:33137,DS-66f0c5dc-f4d6-4fb1-a4d7-3b680f2c0a76,DISK], DatanodeInfoWithStorage[127.0.0.1:39110,DS-3a0602e0-fa3d-4a1d-bf2c-b237241bfae8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1151868125-172.17.0.11-1598358279720:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41867,DS-bd9d9b8d-39db-41db-868e-e91b09c75f04,DISK], DatanodeInfoWithStorage[127.0.0.1:36420,DS-689b3e0d-62f8-4baf-860d-a4a3b6f0f518,DISK], DatanodeInfoWithStorage[127.0.0.1:40676,DS-b81c8482-3936-46c5-bf80-d8513e989ed8,DISK], DatanodeInfoWithStorage[127.0.0.1:42429,DS-5daa0048-dbde-4425-98cc-49971804359e,DISK], DatanodeInfoWithStorage[127.0.0.1:39000,DS-15132814-d055-4de5-a3ee-de1c726e6a12,DISK], DatanodeInfoWithStorage[127.0.0.1:42030,DS-7d7c97cb-06c4-44ac-bd07-a449ebf91f53,DISK], DatanodeInfoWithStorage[127.0.0.1:33137,DS-66f0c5dc-f4d6-4fb1-a4d7-3b680f2c0a76,DISK], DatanodeInfoWithStorage[127.0.0.1:39110,DS-3a0602e0-fa3d-4a1d-bf2c-b237241bfae8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1984066418-172.17.0.11-1598358921854:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34220,DS-fbde209c-85b4-4e1f-ab9b-12e2b2736dda,DISK], DatanodeInfoWithStorage[127.0.0.1:38022,DS-7dcbc4c6-7fbc-4c66-a869-7b87abdd8de9,DISK], DatanodeInfoWithStorage[127.0.0.1:46232,DS-e26917ae-5687-4774-834e-9d480459f37e,DISK], DatanodeInfoWithStorage[127.0.0.1:35849,DS-343641c3-f87f-409d-8869-016bf14bfb76,DISK], DatanodeInfoWithStorage[127.0.0.1:43066,DS-a78cb159-1b21-410f-8648-bbee40d8c1ad,DISK], DatanodeInfoWithStorage[127.0.0.1:39701,DS-4501df29-d7ff-4eb1-808a-c34fe8a73c31,DISK], DatanodeInfoWithStorage[127.0.0.1:35917,DS-07614379-b9c2-4395-bdc7-6dfb01feef96,DISK], DatanodeInfoWithStorage[127.0.0.1:34450,DS-94aafd4c-907c-4302-8a02-9edce6e5e7b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1984066418-172.17.0.11-1598358921854:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34220,DS-fbde209c-85b4-4e1f-ab9b-12e2b2736dda,DISK], DatanodeInfoWithStorage[127.0.0.1:38022,DS-7dcbc4c6-7fbc-4c66-a869-7b87abdd8de9,DISK], DatanodeInfoWithStorage[127.0.0.1:46232,DS-e26917ae-5687-4774-834e-9d480459f37e,DISK], DatanodeInfoWithStorage[127.0.0.1:35849,DS-343641c3-f87f-409d-8869-016bf14bfb76,DISK], DatanodeInfoWithStorage[127.0.0.1:43066,DS-a78cb159-1b21-410f-8648-bbee40d8c1ad,DISK], DatanodeInfoWithStorage[127.0.0.1:39701,DS-4501df29-d7ff-4eb1-808a-c34fe8a73c31,DISK], DatanodeInfoWithStorage[127.0.0.1:35917,DS-07614379-b9c2-4395-bdc7-6dfb01feef96,DISK], DatanodeInfoWithStorage[127.0.0.1:34450,DS-94aafd4c-907c-4302-8a02-9edce6e5e7b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-654352935-172.17.0.11-1598359272478:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39235,DS-4f0d9fe1-031c-4790-8049-e6e42e012db5,DISK], DatanodeInfoWithStorage[127.0.0.1:37610,DS-6c4234aa-37c3-4bbc-8cbb-12e8aa11f17a,DISK], DatanodeInfoWithStorage[127.0.0.1:45405,DS-4b351ec9-07df-478a-9f59-d3b9d6c1e677,DISK], DatanodeInfoWithStorage[127.0.0.1:43407,DS-050faa9f-58f2-432f-8271-d79f7fe5d65f,DISK], DatanodeInfoWithStorage[127.0.0.1:44752,DS-9f823222-76a6-4b76-bbd9-134b36efe98f,DISK], DatanodeInfoWithStorage[127.0.0.1:41972,DS-0572132b-14fd-440c-89af-6c430e93d4c1,DISK], DatanodeInfoWithStorage[127.0.0.1:38538,DS-42b35ce9-2f9b-463e-9d5a-943553f4c51b,DISK], DatanodeInfoWithStorage[127.0.0.1:40498,DS-c4afbe73-377a-4588-9769-6dfbc2ce1133,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-654352935-172.17.0.11-1598359272478:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39235,DS-4f0d9fe1-031c-4790-8049-e6e42e012db5,DISK], DatanodeInfoWithStorage[127.0.0.1:37610,DS-6c4234aa-37c3-4bbc-8cbb-12e8aa11f17a,DISK], DatanodeInfoWithStorage[127.0.0.1:45405,DS-4b351ec9-07df-478a-9f59-d3b9d6c1e677,DISK], DatanodeInfoWithStorage[127.0.0.1:43407,DS-050faa9f-58f2-432f-8271-d79f7fe5d65f,DISK], DatanodeInfoWithStorage[127.0.0.1:44752,DS-9f823222-76a6-4b76-bbd9-134b36efe98f,DISK], DatanodeInfoWithStorage[127.0.0.1:41972,DS-0572132b-14fd-440c-89af-6c430e93d4c1,DISK], DatanodeInfoWithStorage[127.0.0.1:38538,DS-42b35ce9-2f9b-463e-9d5a-943553f4c51b,DISK], DatanodeInfoWithStorage[127.0.0.1:40498,DS-c4afbe73-377a-4588-9769-6dfbc2ce1133,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2092059506-172.17.0.11-1598359707124:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34089,DS-c8a72dd6-f648-4cad-ad7a-aaf4bd31062d,DISK], DatanodeInfoWithStorage[127.0.0.1:43152,DS-f9bae6b6-4fc1-4bed-9aa3-06d6a1ea776f,DISK], DatanodeInfoWithStorage[127.0.0.1:42663,DS-b2f60182-eab0-4182-b3dc-82c23eb8930f,DISK], DatanodeInfoWithStorage[127.0.0.1:35706,DS-ec778587-7361-4d21-8924-204180b264c2,DISK], DatanodeInfoWithStorage[127.0.0.1:39119,DS-fb846ac7-95c7-44ae-bebc-d4edf63b82c4,DISK], DatanodeInfoWithStorage[127.0.0.1:46620,DS-b7cef91b-015c-42e8-8d95-22db61e082dc,DISK], DatanodeInfoWithStorage[127.0.0.1:44418,DS-f25d208c-fdfe-4a89-9f5b-aae02769c0bf,DISK], DatanodeInfoWithStorage[127.0.0.1:32784,DS-c91b01c3-0d2f-4aea-bee0-a8fee80b887b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2092059506-172.17.0.11-1598359707124:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34089,DS-c8a72dd6-f648-4cad-ad7a-aaf4bd31062d,DISK], DatanodeInfoWithStorage[127.0.0.1:43152,DS-f9bae6b6-4fc1-4bed-9aa3-06d6a1ea776f,DISK], DatanodeInfoWithStorage[127.0.0.1:42663,DS-b2f60182-eab0-4182-b3dc-82c23eb8930f,DISK], DatanodeInfoWithStorage[127.0.0.1:35706,DS-ec778587-7361-4d21-8924-204180b264c2,DISK], DatanodeInfoWithStorage[127.0.0.1:39119,DS-fb846ac7-95c7-44ae-bebc-d4edf63b82c4,DISK], DatanodeInfoWithStorage[127.0.0.1:46620,DS-b7cef91b-015c-42e8-8d95-22db61e082dc,DISK], DatanodeInfoWithStorage[127.0.0.1:44418,DS-f25d208c-fdfe-4a89-9f5b-aae02769c0bf,DISK], DatanodeInfoWithStorage[127.0.0.1:32784,DS-c91b01c3-0d2f-4aea-bee0-a8fee80b887b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-123427201-172.17.0.11-1598359810635:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33241,DS-f7659d78-eb00-4079-a0d0-5669c45795db,DISK], DatanodeInfoWithStorage[127.0.0.1:37163,DS-362ab305-7643-4118-a617-418508366a72,DISK], DatanodeInfoWithStorage[127.0.0.1:40186,DS-64610fe8-48ab-47c0-84d8-3bd13195ff70,DISK], DatanodeInfoWithStorage[127.0.0.1:41622,DS-e81573f6-3501-40d3-85dd-2df42c77e2fb,DISK], DatanodeInfoWithStorage[127.0.0.1:44895,DS-7319ec36-f53f-44d8-bf57-17495a8c10b6,DISK], DatanodeInfoWithStorage[127.0.0.1:42265,DS-f916ba36-b984-4274-8325-a6f7ad0f53a5,DISK], DatanodeInfoWithStorage[127.0.0.1:40991,DS-da5f6065-fd57-4138-9f00-8ce8aba190c8,DISK], DatanodeInfoWithStorage[127.0.0.1:36481,DS-0a3a0d6b-1e90-41d4-ba3a-54458fbde6b7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-123427201-172.17.0.11-1598359810635:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33241,DS-f7659d78-eb00-4079-a0d0-5669c45795db,DISK], DatanodeInfoWithStorage[127.0.0.1:37163,DS-362ab305-7643-4118-a617-418508366a72,DISK], DatanodeInfoWithStorage[127.0.0.1:40186,DS-64610fe8-48ab-47c0-84d8-3bd13195ff70,DISK], DatanodeInfoWithStorage[127.0.0.1:41622,DS-e81573f6-3501-40d3-85dd-2df42c77e2fb,DISK], DatanodeInfoWithStorage[127.0.0.1:44895,DS-7319ec36-f53f-44d8-bf57-17495a8c10b6,DISK], DatanodeInfoWithStorage[127.0.0.1:42265,DS-f916ba36-b984-4274-8325-a6f7ad0f53a5,DISK], DatanodeInfoWithStorage[127.0.0.1:40991,DS-da5f6065-fd57-4138-9f00-8ce8aba190c8,DISK], DatanodeInfoWithStorage[127.0.0.1:36481,DS-0a3a0d6b-1e90-41d4-ba3a-54458fbde6b7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-881370473-172.17.0.11-1598360166852:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37264,DS-3e593945-50e1-4d24-bf73-485daf89fd35,DISK], DatanodeInfoWithStorage[127.0.0.1:45247,DS-e06df6c7-56fb-4329-aafc-9ab700b47e33,DISK], DatanodeInfoWithStorage[127.0.0.1:34102,DS-670c1a43-b699-464f-9328-003f646e2484,DISK], DatanodeInfoWithStorage[127.0.0.1:40715,DS-0a245449-f88c-4a17-9c63-8aab7f6da0ec,DISK], DatanodeInfoWithStorage[127.0.0.1:33843,DS-60aa614a-ecaf-4c72-98c8-432b7856f4fd,DISK], DatanodeInfoWithStorage[127.0.0.1:34968,DS-6d9f5d8f-7282-4111-b207-e7b4a7289069,DISK], DatanodeInfoWithStorage[127.0.0.1:42863,DS-6ef73994-7e28-4ea1-ad1a-72e79b45b8f1,DISK], DatanodeInfoWithStorage[127.0.0.1:41838,DS-e3efa866-ea2f-455e-a541-d2b871751a94,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-881370473-172.17.0.11-1598360166852:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37264,DS-3e593945-50e1-4d24-bf73-485daf89fd35,DISK], DatanodeInfoWithStorage[127.0.0.1:45247,DS-e06df6c7-56fb-4329-aafc-9ab700b47e33,DISK], DatanodeInfoWithStorage[127.0.0.1:34102,DS-670c1a43-b699-464f-9328-003f646e2484,DISK], DatanodeInfoWithStorage[127.0.0.1:40715,DS-0a245449-f88c-4a17-9c63-8aab7f6da0ec,DISK], DatanodeInfoWithStorage[127.0.0.1:33843,DS-60aa614a-ecaf-4c72-98c8-432b7856f4fd,DISK], DatanodeInfoWithStorage[127.0.0.1:34968,DS-6d9f5d8f-7282-4111-b207-e7b4a7289069,DISK], DatanodeInfoWithStorage[127.0.0.1:42863,DS-6ef73994-7e28-4ea1-ad1a-72e79b45b8f1,DISK], DatanodeInfoWithStorage[127.0.0.1:41838,DS-e3efa866-ea2f-455e-a541-d2b871751a94,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1266739340-172.17.0.11-1598360378683:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42154,DS-7070c562-1650-4037-9d95-ea86fe971d8f,DISK], DatanodeInfoWithStorage[127.0.0.1:46637,DS-cf28957c-4178-4652-8c45-149aeb7e8176,DISK], DatanodeInfoWithStorage[127.0.0.1:36901,DS-d2ddd562-a38c-430b-bdc5-883e4f342117,DISK], DatanodeInfoWithStorage[127.0.0.1:40045,DS-745cef22-c51c-4876-8e43-49c29d08a07e,DISK], DatanodeInfoWithStorage[127.0.0.1:46338,DS-71e8660a-48f9-4a2b-a803-7fe6e48cdcb0,DISK], DatanodeInfoWithStorage[127.0.0.1:36870,DS-c87b45dd-b852-465d-9ad7-ebc0d792c1f5,DISK], DatanodeInfoWithStorage[127.0.0.1:43340,DS-c2c55a92-92d0-443e-8052-38f36f5278a4,DISK], DatanodeInfoWithStorage[127.0.0.1:38796,DS-b3e8bc49-2222-430f-9ffd-401982f9eda2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1266739340-172.17.0.11-1598360378683:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42154,DS-7070c562-1650-4037-9d95-ea86fe971d8f,DISK], DatanodeInfoWithStorage[127.0.0.1:46637,DS-cf28957c-4178-4652-8c45-149aeb7e8176,DISK], DatanodeInfoWithStorage[127.0.0.1:36901,DS-d2ddd562-a38c-430b-bdc5-883e4f342117,DISK], DatanodeInfoWithStorage[127.0.0.1:40045,DS-745cef22-c51c-4876-8e43-49c29d08a07e,DISK], DatanodeInfoWithStorage[127.0.0.1:46338,DS-71e8660a-48f9-4a2b-a803-7fe6e48cdcb0,DISK], DatanodeInfoWithStorage[127.0.0.1:36870,DS-c87b45dd-b852-465d-9ad7-ebc0d792c1f5,DISK], DatanodeInfoWithStorage[127.0.0.1:43340,DS-c2c55a92-92d0-443e-8052-38f36f5278a4,DISK], DatanodeInfoWithStorage[127.0.0.1:38796,DS-b3e8bc49-2222-430f-9ffd-401982f9eda2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-876368579-172.17.0.11-1598360484338:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36201,DS-1120b167-dca4-4cd8-b83b-39e85d3a0fb1,DISK], DatanodeInfoWithStorage[127.0.0.1:46229,DS-6d7d4619-92bb-4011-80bc-b99e659af780,DISK], DatanodeInfoWithStorage[127.0.0.1:46077,DS-a68ce384-1066-42db-8bb2-37dda25ae18f,DISK], DatanodeInfoWithStorage[127.0.0.1:44301,DS-c50a0e04-84c9-4f29-ae8c-19e72d7bf60c,DISK], DatanodeInfoWithStorage[127.0.0.1:37650,DS-0be7ec84-0b23-413b-b8d5-4b46f61914f5,DISK], DatanodeInfoWithStorage[127.0.0.1:38050,DS-99f35d87-35fb-4237-9732-13104c9b9688,DISK], DatanodeInfoWithStorage[127.0.0.1:36882,DS-97bdfa28-a119-4003-a232-f12650a0a046,DISK], DatanodeInfoWithStorage[127.0.0.1:45438,DS-0431ce91-a58b-4882-aba9-41a4be4e6b27,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-876368579-172.17.0.11-1598360484338:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36201,DS-1120b167-dca4-4cd8-b83b-39e85d3a0fb1,DISK], DatanodeInfoWithStorage[127.0.0.1:46229,DS-6d7d4619-92bb-4011-80bc-b99e659af780,DISK], DatanodeInfoWithStorage[127.0.0.1:46077,DS-a68ce384-1066-42db-8bb2-37dda25ae18f,DISK], DatanodeInfoWithStorage[127.0.0.1:44301,DS-c50a0e04-84c9-4f29-ae8c-19e72d7bf60c,DISK], DatanodeInfoWithStorage[127.0.0.1:37650,DS-0be7ec84-0b23-413b-b8d5-4b46f61914f5,DISK], DatanodeInfoWithStorage[127.0.0.1:38050,DS-99f35d87-35fb-4237-9732-13104c9b9688,DISK], DatanodeInfoWithStorage[127.0.0.1:36882,DS-97bdfa28-a119-4003-a232-f12650a0a046,DISK], DatanodeInfoWithStorage[127.0.0.1:45438,DS-0431ce91-a58b-4882-aba9-41a4be4e6b27,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2037840817-172.17.0.11-1598360609968:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42618,DS-39ff171e-5458-4702-bae6-c5d64c04da8d,DISK], DatanodeInfoWithStorage[127.0.0.1:33124,DS-1ec3b815-2dd8-42e8-a9c2-07961d0cf84a,DISK], DatanodeInfoWithStorage[127.0.0.1:41224,DS-6ad37770-b4a1-4f5e-9d28-11e428dbe183,DISK], DatanodeInfoWithStorage[127.0.0.1:44260,DS-82c10495-e810-4165-8b4f-4baaaf6ea0ea,DISK], DatanodeInfoWithStorage[127.0.0.1:40020,DS-a203e3c5-9727-4268-9678-2fea64ba33ac,DISK], DatanodeInfoWithStorage[127.0.0.1:43954,DS-aff76295-1e66-4c10-89e3-9f5385ae2a1c,DISK], DatanodeInfoWithStorage[127.0.0.1:40546,DS-609eb831-286e-4aa7-8416-0bd52f548ed1,DISK], DatanodeInfoWithStorage[127.0.0.1:40118,DS-fc9d5e38-2119-4758-ae04-7bf878ba0f37,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2037840817-172.17.0.11-1598360609968:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42618,DS-39ff171e-5458-4702-bae6-c5d64c04da8d,DISK], DatanodeInfoWithStorage[127.0.0.1:33124,DS-1ec3b815-2dd8-42e8-a9c2-07961d0cf84a,DISK], DatanodeInfoWithStorage[127.0.0.1:41224,DS-6ad37770-b4a1-4f5e-9d28-11e428dbe183,DISK], DatanodeInfoWithStorage[127.0.0.1:44260,DS-82c10495-e810-4165-8b4f-4baaaf6ea0ea,DISK], DatanodeInfoWithStorage[127.0.0.1:40020,DS-a203e3c5-9727-4268-9678-2fea64ba33ac,DISK], DatanodeInfoWithStorage[127.0.0.1:43954,DS-aff76295-1e66-4c10-89e3-9f5385ae2a1c,DISK], DatanodeInfoWithStorage[127.0.0.1:40546,DS-609eb831-286e-4aa7-8416-0bd52f548ed1,DISK], DatanodeInfoWithStorage[127.0.0.1:40118,DS-fc9d5e38-2119-4758-ae04-7bf878ba0f37,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-722304917-172.17.0.11-1598360940340:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33331,DS-c2e6b1e7-afb6-442e-8f92-8c832898775a,DISK], DatanodeInfoWithStorage[127.0.0.1:41223,DS-89bbca30-c310-4857-b9f4-6ec5330c4ff5,DISK], DatanodeInfoWithStorage[127.0.0.1:35084,DS-44667c83-9c9c-49b0-b465-a2a2e6038d7a,DISK], DatanodeInfoWithStorage[127.0.0.1:37620,DS-014b1094-65d2-4421-a1cd-3a7218acde44,DISK], DatanodeInfoWithStorage[127.0.0.1:43983,DS-60a6f1c2-3174-4d40-9a3d-a3a8d6988baf,DISK], DatanodeInfoWithStorage[127.0.0.1:34095,DS-5f7c0919-f798-47e9-9d21-53232dfa2664,DISK], DatanodeInfoWithStorage[127.0.0.1:41523,DS-faa3f8f3-1833-43c3-bba7-8ea78256144c,DISK], DatanodeInfoWithStorage[127.0.0.1:33248,DS-f6f3a415-443a-401a-831c-9e1e492af2ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-722304917-172.17.0.11-1598360940340:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33331,DS-c2e6b1e7-afb6-442e-8f92-8c832898775a,DISK], DatanodeInfoWithStorage[127.0.0.1:41223,DS-89bbca30-c310-4857-b9f4-6ec5330c4ff5,DISK], DatanodeInfoWithStorage[127.0.0.1:35084,DS-44667c83-9c9c-49b0-b465-a2a2e6038d7a,DISK], DatanodeInfoWithStorage[127.0.0.1:37620,DS-014b1094-65d2-4421-a1cd-3a7218acde44,DISK], DatanodeInfoWithStorage[127.0.0.1:43983,DS-60a6f1c2-3174-4d40-9a3d-a3a8d6988baf,DISK], DatanodeInfoWithStorage[127.0.0.1:34095,DS-5f7c0919-f798-47e9-9d21-53232dfa2664,DISK], DatanodeInfoWithStorage[127.0.0.1:41523,DS-faa3f8f3-1833-43c3-bba7-8ea78256144c,DISK], DatanodeInfoWithStorage[127.0.0.1:33248,DS-f6f3a415-443a-401a-831c-9e1e492af2ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1476159566-172.17.0.11-1598361239024:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44204,DS-4447252f-dcdc-4bc6-a474-05366247b7eb,DISK], DatanodeInfoWithStorage[127.0.0.1:46647,DS-bb7d0bfe-6db7-4a9a-8253-d1d7eb01b892,DISK], DatanodeInfoWithStorage[127.0.0.1:39124,DS-3b556087-e4ae-46c4-9a4b-9d1207aa96db,DISK], DatanodeInfoWithStorage[127.0.0.1:42011,DS-d11b02c1-6b31-4338-9c96-44c67b577610,DISK], DatanodeInfoWithStorage[127.0.0.1:42702,DS-171cfdbf-773f-40be-acad-976196238463,DISK], DatanodeInfoWithStorage[127.0.0.1:33781,DS-25ff8309-44de-457a-b0da-e1febc58429e,DISK], DatanodeInfoWithStorage[127.0.0.1:36323,DS-626f6f85-b401-4b3a-a67c-16913f0dc546,DISK], DatanodeInfoWithStorage[127.0.0.1:33206,DS-f36add10-ff60-4b41-90de-5bfd32b91feb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1476159566-172.17.0.11-1598361239024:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44204,DS-4447252f-dcdc-4bc6-a474-05366247b7eb,DISK], DatanodeInfoWithStorage[127.0.0.1:46647,DS-bb7d0bfe-6db7-4a9a-8253-d1d7eb01b892,DISK], DatanodeInfoWithStorage[127.0.0.1:39124,DS-3b556087-e4ae-46c4-9a4b-9d1207aa96db,DISK], DatanodeInfoWithStorage[127.0.0.1:42011,DS-d11b02c1-6b31-4338-9c96-44c67b577610,DISK], DatanodeInfoWithStorage[127.0.0.1:42702,DS-171cfdbf-773f-40be-acad-976196238463,DISK], DatanodeInfoWithStorage[127.0.0.1:33781,DS-25ff8309-44de-457a-b0da-e1febc58429e,DISK], DatanodeInfoWithStorage[127.0.0.1:36323,DS-626f6f85-b401-4b3a-a67c-16913f0dc546,DISK], DatanodeInfoWithStorage[127.0.0.1:33206,DS-f36add10-ff60-4b41-90de-5bfd32b91feb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1648405553-172.17.0.11-1598361278256:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42756,DS-649a8ed9-1807-4fcc-9243-537ae674ead0,DISK], DatanodeInfoWithStorage[127.0.0.1:33111,DS-1c69643b-991b-4036-9230-9fffbf99a3eb,DISK], DatanodeInfoWithStorage[127.0.0.1:42090,DS-93ccccc8-9676-4447-bd81-1f8461ab7c5d,DISK], DatanodeInfoWithStorage[127.0.0.1:39441,DS-ce76a280-76ac-4c5b-9e04-ed71774ea2ee,DISK], DatanodeInfoWithStorage[127.0.0.1:38583,DS-f9dc9502-feb8-4ccf-ac46-d66cb79adfef,DISK], DatanodeInfoWithStorage[127.0.0.1:38710,DS-b5a3459e-36af-4931-a65d-b83babe71e5d,DISK], DatanodeInfoWithStorage[127.0.0.1:39187,DS-776ab624-88b6-4acd-b4ef-18bf951204c3,DISK], DatanodeInfoWithStorage[127.0.0.1:38865,DS-c797b0f4-9339-45fe-a204-7181fa226d3a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1648405553-172.17.0.11-1598361278256:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42756,DS-649a8ed9-1807-4fcc-9243-537ae674ead0,DISK], DatanodeInfoWithStorage[127.0.0.1:33111,DS-1c69643b-991b-4036-9230-9fffbf99a3eb,DISK], DatanodeInfoWithStorage[127.0.0.1:42090,DS-93ccccc8-9676-4447-bd81-1f8461ab7c5d,DISK], DatanodeInfoWithStorage[127.0.0.1:39441,DS-ce76a280-76ac-4c5b-9e04-ed71774ea2ee,DISK], DatanodeInfoWithStorage[127.0.0.1:38583,DS-f9dc9502-feb8-4ccf-ac46-d66cb79adfef,DISK], DatanodeInfoWithStorage[127.0.0.1:38710,DS-b5a3459e-36af-4931-a65d-b83babe71e5d,DISK], DatanodeInfoWithStorage[127.0.0.1:39187,DS-776ab624-88b6-4acd-b4ef-18bf951204c3,DISK], DatanodeInfoWithStorage[127.0.0.1:38865,DS-c797b0f4-9339-45fe-a204-7181fa226d3a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 15 out of 50
result: false positive !!!
Total execution time in seconds : 5157
