reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1911852377-172.17.0.17-1598161355271:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43548,DS-b1eca74b-0396-4245-8e1d-7a35f79b6406,DISK], DatanodeInfoWithStorage[127.0.0.1:41093,DS-6474b3b7-c369-4b38-886a-3d6780943b48,DISK], DatanodeInfoWithStorage[127.0.0.1:37556,DS-b809e7f2-7745-47c7-b4fb-0cef4280e6b5,DISK], DatanodeInfoWithStorage[127.0.0.1:33985,DS-42f756aa-a837-4482-9974-7d9c46699f5f,DISK], DatanodeInfoWithStorage[127.0.0.1:43839,DS-30bc08ee-f2dd-40a7-8d97-1dfef612edd0,DISK], DatanodeInfoWithStorage[127.0.0.1:46228,DS-c8a56641-c9d6-4670-9c7b-205f128c155a,DISK], DatanodeInfoWithStorage[127.0.0.1:39742,DS-5dc16704-b110-4ff0-bbee-0b05a388fb3e,DISK], DatanodeInfoWithStorage[127.0.0.1:44592,DS-17b2a0e6-c500-41cc-85ed-603196f00eca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1911852377-172.17.0.17-1598161355271:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43548,DS-b1eca74b-0396-4245-8e1d-7a35f79b6406,DISK], DatanodeInfoWithStorage[127.0.0.1:41093,DS-6474b3b7-c369-4b38-886a-3d6780943b48,DISK], DatanodeInfoWithStorage[127.0.0.1:37556,DS-b809e7f2-7745-47c7-b4fb-0cef4280e6b5,DISK], DatanodeInfoWithStorage[127.0.0.1:33985,DS-42f756aa-a837-4482-9974-7d9c46699f5f,DISK], DatanodeInfoWithStorage[127.0.0.1:43839,DS-30bc08ee-f2dd-40a7-8d97-1dfef612edd0,DISK], DatanodeInfoWithStorage[127.0.0.1:46228,DS-c8a56641-c9d6-4670-9c7b-205f128c155a,DISK], DatanodeInfoWithStorage[127.0.0.1:39742,DS-5dc16704-b110-4ff0-bbee-0b05a388fb3e,DISK], DatanodeInfoWithStorage[127.0.0.1:44592,DS-17b2a0e6-c500-41cc-85ed-603196f00eca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1956410995-172.17.0.17-1598161860748:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33244,DS-da4f57ec-524d-4a6f-8662-2293097338fa,DISK], DatanodeInfoWithStorage[127.0.0.1:46244,DS-20e77af1-8a3a-4cfe-8ba0-08302dcb12d8,DISK], DatanodeInfoWithStorage[127.0.0.1:45019,DS-5b21ed12-10fc-4877-bca8-cd7d85447b2e,DISK], DatanodeInfoWithStorage[127.0.0.1:34205,DS-11e841a7-9aba-440a-b870-e2066650f91a,DISK], DatanodeInfoWithStorage[127.0.0.1:43635,DS-a8041564-ac95-4c67-816d-9a10378352bf,DISK], DatanodeInfoWithStorage[127.0.0.1:34592,DS-f19527f0-2448-4f47-ad71-fd4134d41a17,DISK], DatanodeInfoWithStorage[127.0.0.1:44369,DS-814cf640-2a88-48d9-964b-4ee3b61f2011,DISK], DatanodeInfoWithStorage[127.0.0.1:41050,DS-a3b56b71-f940-4366-b613-c51a64ff0321,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1956410995-172.17.0.17-1598161860748:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33244,DS-da4f57ec-524d-4a6f-8662-2293097338fa,DISK], DatanodeInfoWithStorage[127.0.0.1:46244,DS-20e77af1-8a3a-4cfe-8ba0-08302dcb12d8,DISK], DatanodeInfoWithStorage[127.0.0.1:45019,DS-5b21ed12-10fc-4877-bca8-cd7d85447b2e,DISK], DatanodeInfoWithStorage[127.0.0.1:34205,DS-11e841a7-9aba-440a-b870-e2066650f91a,DISK], DatanodeInfoWithStorage[127.0.0.1:43635,DS-a8041564-ac95-4c67-816d-9a10378352bf,DISK], DatanodeInfoWithStorage[127.0.0.1:34592,DS-f19527f0-2448-4f47-ad71-fd4134d41a17,DISK], DatanodeInfoWithStorage[127.0.0.1:44369,DS-814cf640-2a88-48d9-964b-4ee3b61f2011,DISK], DatanodeInfoWithStorage[127.0.0.1:41050,DS-a3b56b71-f940-4366-b613-c51a64ff0321,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-61477592-172.17.0.17-1598161902970:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45480,DS-1dc45e5f-fd07-452b-a6e5-cee03e23a7c2,DISK], DatanodeInfoWithStorage[127.0.0.1:37116,DS-3505d79d-64f7-4417-8220-3160aec732e0,DISK], DatanodeInfoWithStorage[127.0.0.1:45175,DS-237e4c36-5e57-41ce-a62d-68af730ccb75,DISK], DatanodeInfoWithStorage[127.0.0.1:37292,DS-8fd60556-86a6-418c-a0f1-ad38590dd458,DISK], DatanodeInfoWithStorage[127.0.0.1:45097,DS-c332d71e-376c-4c76-83e9-920395ccf991,DISK], DatanodeInfoWithStorage[127.0.0.1:42128,DS-f733218e-1dca-4117-9f5c-50c1ecb652a0,DISK], DatanodeInfoWithStorage[127.0.0.1:34110,DS-5be41712-b146-4b58-b6d4-c79f72eda391,DISK], DatanodeInfoWithStorage[127.0.0.1:35385,DS-014fd79b-9610-46af-ad23-e225f902ba9b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-61477592-172.17.0.17-1598161902970:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45480,DS-1dc45e5f-fd07-452b-a6e5-cee03e23a7c2,DISK], DatanodeInfoWithStorage[127.0.0.1:37116,DS-3505d79d-64f7-4417-8220-3160aec732e0,DISK], DatanodeInfoWithStorage[127.0.0.1:45175,DS-237e4c36-5e57-41ce-a62d-68af730ccb75,DISK], DatanodeInfoWithStorage[127.0.0.1:37292,DS-8fd60556-86a6-418c-a0f1-ad38590dd458,DISK], DatanodeInfoWithStorage[127.0.0.1:45097,DS-c332d71e-376c-4c76-83e9-920395ccf991,DISK], DatanodeInfoWithStorage[127.0.0.1:42128,DS-f733218e-1dca-4117-9f5c-50c1ecb652a0,DISK], DatanodeInfoWithStorage[127.0.0.1:34110,DS-5be41712-b146-4b58-b6d4-c79f72eda391,DISK], DatanodeInfoWithStorage[127.0.0.1:35385,DS-014fd79b-9610-46af-ad23-e225f902ba9b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-355764582-172.17.0.17-1598162185418:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37124,DS-c1eed93d-ddc5-4f7b-918f-7123390324d7,DISK], DatanodeInfoWithStorage[127.0.0.1:43491,DS-2a9cd31c-e2eb-4e9f-9a5c-1561f050c5bf,DISK], DatanodeInfoWithStorage[127.0.0.1:40032,DS-2cff1631-8166-466f-8c64-5f36ec77783a,DISK], DatanodeInfoWithStorage[127.0.0.1:39514,DS-29d7a653-97dd-407b-ac2f-66cbaccc5628,DISK], DatanodeInfoWithStorage[127.0.0.1:41521,DS-3c03b9c1-3d2b-41f1-b406-f99e1de94d10,DISK], DatanodeInfoWithStorage[127.0.0.1:43341,DS-1049351f-761f-49ff-9fc6-b9fd31496ad4,DISK], DatanodeInfoWithStorage[127.0.0.1:34125,DS-971b6098-750e-4e02-9327-63fcfb8f0d37,DISK], DatanodeInfoWithStorage[127.0.0.1:35103,DS-829ea749-bb40-4fb2-987f-2f624092883d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-355764582-172.17.0.17-1598162185418:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37124,DS-c1eed93d-ddc5-4f7b-918f-7123390324d7,DISK], DatanodeInfoWithStorage[127.0.0.1:43491,DS-2a9cd31c-e2eb-4e9f-9a5c-1561f050c5bf,DISK], DatanodeInfoWithStorage[127.0.0.1:40032,DS-2cff1631-8166-466f-8c64-5f36ec77783a,DISK], DatanodeInfoWithStorage[127.0.0.1:39514,DS-29d7a653-97dd-407b-ac2f-66cbaccc5628,DISK], DatanodeInfoWithStorage[127.0.0.1:41521,DS-3c03b9c1-3d2b-41f1-b406-f99e1de94d10,DISK], DatanodeInfoWithStorage[127.0.0.1:43341,DS-1049351f-761f-49ff-9fc6-b9fd31496ad4,DISK], DatanodeInfoWithStorage[127.0.0.1:34125,DS-971b6098-750e-4e02-9327-63fcfb8f0d37,DISK], DatanodeInfoWithStorage[127.0.0.1:35103,DS-829ea749-bb40-4fb2-987f-2f624092883d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1309555819-172.17.0.17-1598162456355:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41807,DS-46636eb9-17ec-4887-b6e8-d199bf5bdc10,DISK], DatanodeInfoWithStorage[127.0.0.1:41893,DS-b61773b8-f53d-4e1c-abe8-6cfe8e97ca12,DISK], DatanodeInfoWithStorage[127.0.0.1:41390,DS-ab440d55-0d6a-460d-9ee8-3ba2706c738d,DISK], DatanodeInfoWithStorage[127.0.0.1:39996,DS-a5c36e5b-00a0-421b-942a-607576c101b6,DISK], DatanodeInfoWithStorage[127.0.0.1:40020,DS-f373ec2d-14d2-4c6d-8751-4d51b872fc1e,DISK], DatanodeInfoWithStorage[127.0.0.1:37001,DS-3950d5a5-091c-4afe-97b1-6e01ed4dc7f6,DISK], DatanodeInfoWithStorage[127.0.0.1:36257,DS-e31dd43a-e0d5-49d9-a63a-4b197d9fd15b,DISK], DatanodeInfoWithStorage[127.0.0.1:41449,DS-aa24a471-a87e-497c-8917-47f06a86061e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1309555819-172.17.0.17-1598162456355:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41807,DS-46636eb9-17ec-4887-b6e8-d199bf5bdc10,DISK], DatanodeInfoWithStorage[127.0.0.1:41893,DS-b61773b8-f53d-4e1c-abe8-6cfe8e97ca12,DISK], DatanodeInfoWithStorage[127.0.0.1:41390,DS-ab440d55-0d6a-460d-9ee8-3ba2706c738d,DISK], DatanodeInfoWithStorage[127.0.0.1:39996,DS-a5c36e5b-00a0-421b-942a-607576c101b6,DISK], DatanodeInfoWithStorage[127.0.0.1:40020,DS-f373ec2d-14d2-4c6d-8751-4d51b872fc1e,DISK], DatanodeInfoWithStorage[127.0.0.1:37001,DS-3950d5a5-091c-4afe-97b1-6e01ed4dc7f6,DISK], DatanodeInfoWithStorage[127.0.0.1:36257,DS-e31dd43a-e0d5-49d9-a63a-4b197d9fd15b,DISK], DatanodeInfoWithStorage[127.0.0.1:41449,DS-aa24a471-a87e-497c-8917-47f06a86061e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1298602846-172.17.0.17-1598163003909:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34149,DS-43c5233a-706b-4ccb-9f05-f7bf462452f4,DISK], DatanodeInfoWithStorage[127.0.0.1:34103,DS-61b3a083-9fe1-4a5e-b5e7-e125b29a530c,DISK], DatanodeInfoWithStorage[127.0.0.1:33405,DS-1d506f07-8891-46d5-a85c-dbaa9c5b7d6c,DISK], DatanodeInfoWithStorage[127.0.0.1:37582,DS-be0b92ce-3748-4442-b51d-4ab8d7abdd72,DISK], DatanodeInfoWithStorage[127.0.0.1:38381,DS-02767061-d1e3-4a30-800d-2618836d3da7,DISK], DatanodeInfoWithStorage[127.0.0.1:44665,DS-c7a9aaf1-029c-4774-8e73-40822abdb78e,DISK], DatanodeInfoWithStorage[127.0.0.1:45221,DS-aca8806e-e132-4ba5-a075-331cc5726863,DISK], DatanodeInfoWithStorage[127.0.0.1:36492,DS-fe399567-9ef7-4ca3-a227-51d93691c3f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1298602846-172.17.0.17-1598163003909:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34149,DS-43c5233a-706b-4ccb-9f05-f7bf462452f4,DISK], DatanodeInfoWithStorage[127.0.0.1:34103,DS-61b3a083-9fe1-4a5e-b5e7-e125b29a530c,DISK], DatanodeInfoWithStorage[127.0.0.1:33405,DS-1d506f07-8891-46d5-a85c-dbaa9c5b7d6c,DISK], DatanodeInfoWithStorage[127.0.0.1:37582,DS-be0b92ce-3748-4442-b51d-4ab8d7abdd72,DISK], DatanodeInfoWithStorage[127.0.0.1:38381,DS-02767061-d1e3-4a30-800d-2618836d3da7,DISK], DatanodeInfoWithStorage[127.0.0.1:44665,DS-c7a9aaf1-029c-4774-8e73-40822abdb78e,DISK], DatanodeInfoWithStorage[127.0.0.1:45221,DS-aca8806e-e132-4ba5-a075-331cc5726863,DISK], DatanodeInfoWithStorage[127.0.0.1:36492,DS-fe399567-9ef7-4ca3-a227-51d93691c3f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-297016311-172.17.0.17-1598163147577:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41328,DS-ab8a0f06-a507-4d20-a7a7-4fb50ea23b12,DISK], DatanodeInfoWithStorage[127.0.0.1:44613,DS-db82bb86-97da-4af4-9a44-9556222304a1,DISK], DatanodeInfoWithStorage[127.0.0.1:37498,DS-834f9a6b-795e-4f8d-be7c-ccecd99b1554,DISK], DatanodeInfoWithStorage[127.0.0.1:44490,DS-9fd5db87-73a2-4733-8394-cc52c723005d,DISK], DatanodeInfoWithStorage[127.0.0.1:34219,DS-1d3a1746-2c3c-451b-80a3-a2b7a427b1ed,DISK], DatanodeInfoWithStorage[127.0.0.1:45839,DS-90a8dc34-f0d0-40fa-b7c7-ccd6b4368932,DISK], DatanodeInfoWithStorage[127.0.0.1:39879,DS-6acb15e2-12cc-4c6b-b4d2-ce20b4322458,DISK], DatanodeInfoWithStorage[127.0.0.1:37301,DS-316db251-6eb1-4959-82b1-930165d0fcf9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-297016311-172.17.0.17-1598163147577:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41328,DS-ab8a0f06-a507-4d20-a7a7-4fb50ea23b12,DISK], DatanodeInfoWithStorage[127.0.0.1:44613,DS-db82bb86-97da-4af4-9a44-9556222304a1,DISK], DatanodeInfoWithStorage[127.0.0.1:37498,DS-834f9a6b-795e-4f8d-be7c-ccecd99b1554,DISK], DatanodeInfoWithStorage[127.0.0.1:44490,DS-9fd5db87-73a2-4733-8394-cc52c723005d,DISK], DatanodeInfoWithStorage[127.0.0.1:34219,DS-1d3a1746-2c3c-451b-80a3-a2b7a427b1ed,DISK], DatanodeInfoWithStorage[127.0.0.1:45839,DS-90a8dc34-f0d0-40fa-b7c7-ccd6b4368932,DISK], DatanodeInfoWithStorage[127.0.0.1:39879,DS-6acb15e2-12cc-4c6b-b4d2-ce20b4322458,DISK], DatanodeInfoWithStorage[127.0.0.1:37301,DS-316db251-6eb1-4959-82b1-930165d0fcf9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-224108895-172.17.0.17-1598163605828:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42774,DS-56014dc3-fc01-40bf-8215-cc04e3811418,DISK], DatanodeInfoWithStorage[127.0.0.1:44822,DS-46099c83-a793-4253-9937-22762f5f86b2,DISK], DatanodeInfoWithStorage[127.0.0.1:37538,DS-2a44c6a5-acfe-48d0-b74a-33ee45417c1e,DISK], DatanodeInfoWithStorage[127.0.0.1:40268,DS-3550da43-2711-4173-bc0f-8d8d7aa36756,DISK], DatanodeInfoWithStorage[127.0.0.1:35323,DS-fd2c11a1-1ba2-4656-a77b-7e87503fb7fa,DISK], DatanodeInfoWithStorage[127.0.0.1:34167,DS-66d21500-5365-4c64-a78b-d35dc1d2d426,DISK], DatanodeInfoWithStorage[127.0.0.1:43736,DS-1be10268-1d26-4968-8a07-1e66c9cbb63a,DISK], DatanodeInfoWithStorage[127.0.0.1:37003,DS-4a8ea2f5-0d24-412b-ba06-74f46209934d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-224108895-172.17.0.17-1598163605828:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42774,DS-56014dc3-fc01-40bf-8215-cc04e3811418,DISK], DatanodeInfoWithStorage[127.0.0.1:44822,DS-46099c83-a793-4253-9937-22762f5f86b2,DISK], DatanodeInfoWithStorage[127.0.0.1:37538,DS-2a44c6a5-acfe-48d0-b74a-33ee45417c1e,DISK], DatanodeInfoWithStorage[127.0.0.1:40268,DS-3550da43-2711-4173-bc0f-8d8d7aa36756,DISK], DatanodeInfoWithStorage[127.0.0.1:35323,DS-fd2c11a1-1ba2-4656-a77b-7e87503fb7fa,DISK], DatanodeInfoWithStorage[127.0.0.1:34167,DS-66d21500-5365-4c64-a78b-d35dc1d2d426,DISK], DatanodeInfoWithStorage[127.0.0.1:43736,DS-1be10268-1d26-4968-8a07-1e66c9cbb63a,DISK], DatanodeInfoWithStorage[127.0.0.1:37003,DS-4a8ea2f5-0d24-412b-ba06-74f46209934d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2005949336-172.17.0.17-1598164010488:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46649,DS-136f4807-a6a8-4709-b1a3-6b247224465f,DISK], DatanodeInfoWithStorage[127.0.0.1:39069,DS-efd1d102-4727-4d67-8dce-c7befb474a9f,DISK], DatanodeInfoWithStorage[127.0.0.1:45672,DS-599f3201-82e0-4534-b33e-9a563e7f2e21,DISK], DatanodeInfoWithStorage[127.0.0.1:36539,DS-27d99651-ead7-41c6-b3a1-807d8f8c22e5,DISK], DatanodeInfoWithStorage[127.0.0.1:41285,DS-5442e452-d8e2-4fa1-beb6-ca5b4188929c,DISK], DatanodeInfoWithStorage[127.0.0.1:43820,DS-6fc35aea-125f-455d-adad-ad3b6ef9883a,DISK], DatanodeInfoWithStorage[127.0.0.1:40248,DS-f3e74223-bbb1-46ef-8cce-43da559878b2,DISK], DatanodeInfoWithStorage[127.0.0.1:46084,DS-1bee6a96-b0fe-452b-811b-de806329d43f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2005949336-172.17.0.17-1598164010488:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46649,DS-136f4807-a6a8-4709-b1a3-6b247224465f,DISK], DatanodeInfoWithStorage[127.0.0.1:39069,DS-efd1d102-4727-4d67-8dce-c7befb474a9f,DISK], DatanodeInfoWithStorage[127.0.0.1:45672,DS-599f3201-82e0-4534-b33e-9a563e7f2e21,DISK], DatanodeInfoWithStorage[127.0.0.1:36539,DS-27d99651-ead7-41c6-b3a1-807d8f8c22e5,DISK], DatanodeInfoWithStorage[127.0.0.1:41285,DS-5442e452-d8e2-4fa1-beb6-ca5b4188929c,DISK], DatanodeInfoWithStorage[127.0.0.1:43820,DS-6fc35aea-125f-455d-adad-ad3b6ef9883a,DISK], DatanodeInfoWithStorage[127.0.0.1:40248,DS-f3e74223-bbb1-46ef-8cce-43da559878b2,DISK], DatanodeInfoWithStorage[127.0.0.1:46084,DS-1bee6a96-b0fe-452b-811b-de806329d43f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-101079381-172.17.0.17-1598164381126:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38047,DS-7c58e737-ed8c-4cb4-bdf8-ce09399d72b8,DISK], DatanodeInfoWithStorage[127.0.0.1:39846,DS-2f484358-8684-427f-aa37-da11f7dce260,DISK], DatanodeInfoWithStorage[127.0.0.1:45562,DS-0c77a462-3d1b-4570-a7ce-771010a89e7d,DISK], DatanodeInfoWithStorage[127.0.0.1:32962,DS-81027808-d441-4958-b517-62ddf90b7016,DISK], DatanodeInfoWithStorage[127.0.0.1:38952,DS-44e2d664-c6c1-4621-b996-b13ef3946ff6,DISK], DatanodeInfoWithStorage[127.0.0.1:43258,DS-3dc80984-cb9a-4faa-91c6-f07a2d2ba825,DISK], DatanodeInfoWithStorage[127.0.0.1:40682,DS-48c568f7-207b-41a4-b670-104300651928,DISK], DatanodeInfoWithStorage[127.0.0.1:42412,DS-90b99bdc-4204-4af7-b930-757b426a11be,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-101079381-172.17.0.17-1598164381126:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38047,DS-7c58e737-ed8c-4cb4-bdf8-ce09399d72b8,DISK], DatanodeInfoWithStorage[127.0.0.1:39846,DS-2f484358-8684-427f-aa37-da11f7dce260,DISK], DatanodeInfoWithStorage[127.0.0.1:45562,DS-0c77a462-3d1b-4570-a7ce-771010a89e7d,DISK], DatanodeInfoWithStorage[127.0.0.1:32962,DS-81027808-d441-4958-b517-62ddf90b7016,DISK], DatanodeInfoWithStorage[127.0.0.1:38952,DS-44e2d664-c6c1-4621-b996-b13ef3946ff6,DISK], DatanodeInfoWithStorage[127.0.0.1:43258,DS-3dc80984-cb9a-4faa-91c6-f07a2d2ba825,DISK], DatanodeInfoWithStorage[127.0.0.1:40682,DS-48c568f7-207b-41a4-b670-104300651928,DISK], DatanodeInfoWithStorage[127.0.0.1:42412,DS-90b99bdc-4204-4af7-b930-757b426a11be,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1026239923-172.17.0.17-1598164871852:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33432,DS-10ffb623-a364-4827-a9b8-cb85f9d46e49,DISK], DatanodeInfoWithStorage[127.0.0.1:38489,DS-e580e09d-d443-4547-94e0-e90c883ec2a1,DISK], DatanodeInfoWithStorage[127.0.0.1:33872,DS-d2fdd509-c63a-4358-81be-d9e26f81f830,DISK], DatanodeInfoWithStorage[127.0.0.1:44953,DS-91794135-04c0-4000-9bfd-05e9f2abbc33,DISK], DatanodeInfoWithStorage[127.0.0.1:35667,DS-131bb38b-0f6e-4f69-b440-a3d7e9667646,DISK], DatanodeInfoWithStorage[127.0.0.1:39919,DS-94500a30-3ad3-4517-af0b-e6a1b78c1b4a,DISK], DatanodeInfoWithStorage[127.0.0.1:40149,DS-a10e3057-59f4-4382-84ea-e802d49a4cd5,DISK], DatanodeInfoWithStorage[127.0.0.1:39476,DS-3c329a2d-bfc1-49b9-9e4a-e4935a16e146,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1026239923-172.17.0.17-1598164871852:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33432,DS-10ffb623-a364-4827-a9b8-cb85f9d46e49,DISK], DatanodeInfoWithStorage[127.0.0.1:38489,DS-e580e09d-d443-4547-94e0-e90c883ec2a1,DISK], DatanodeInfoWithStorage[127.0.0.1:33872,DS-d2fdd509-c63a-4358-81be-d9e26f81f830,DISK], DatanodeInfoWithStorage[127.0.0.1:44953,DS-91794135-04c0-4000-9bfd-05e9f2abbc33,DISK], DatanodeInfoWithStorage[127.0.0.1:35667,DS-131bb38b-0f6e-4f69-b440-a3d7e9667646,DISK], DatanodeInfoWithStorage[127.0.0.1:39919,DS-94500a30-3ad3-4517-af0b-e6a1b78c1b4a,DISK], DatanodeInfoWithStorage[127.0.0.1:40149,DS-a10e3057-59f4-4382-84ea-e802d49a4cd5,DISK], DatanodeInfoWithStorage[127.0.0.1:39476,DS-3c329a2d-bfc1-49b9-9e4a-e4935a16e146,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1198035738-172.17.0.17-1598164996019:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39776,DS-9682a164-9aa7-4547-b5f9-2def659d2544,DISK], DatanodeInfoWithStorage[127.0.0.1:46882,DS-3307941f-5d04-4814-bbbf-6fdc568524e1,DISK], DatanodeInfoWithStorage[127.0.0.1:41082,DS-0c309c2d-ba42-4068-80f5-8bca57c7558c,DISK], DatanodeInfoWithStorage[127.0.0.1:44584,DS-d502564a-aaf9-4d1d-8906-04f23b8cc30a,DISK], DatanodeInfoWithStorage[127.0.0.1:34698,DS-d4cb4532-cb2c-46a9-8505-a9181846aa8c,DISK], DatanodeInfoWithStorage[127.0.0.1:37189,DS-738222d2-e4f7-49fd-8d7e-ee5edf8c8174,DISK], DatanodeInfoWithStorage[127.0.0.1:43365,DS-e4fcd6ba-4691-44b8-9222-f2d2e983c85e,DISK], DatanodeInfoWithStorage[127.0.0.1:41210,DS-4e5d9bc7-1535-42c6-ae3e-c600dc74d4ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1198035738-172.17.0.17-1598164996019:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39776,DS-9682a164-9aa7-4547-b5f9-2def659d2544,DISK], DatanodeInfoWithStorage[127.0.0.1:46882,DS-3307941f-5d04-4814-bbbf-6fdc568524e1,DISK], DatanodeInfoWithStorage[127.0.0.1:41082,DS-0c309c2d-ba42-4068-80f5-8bca57c7558c,DISK], DatanodeInfoWithStorage[127.0.0.1:44584,DS-d502564a-aaf9-4d1d-8906-04f23b8cc30a,DISK], DatanodeInfoWithStorage[127.0.0.1:34698,DS-d4cb4532-cb2c-46a9-8505-a9181846aa8c,DISK], DatanodeInfoWithStorage[127.0.0.1:37189,DS-738222d2-e4f7-49fd-8d7e-ee5edf8c8174,DISK], DatanodeInfoWithStorage[127.0.0.1:43365,DS-e4fcd6ba-4691-44b8-9222-f2d2e983c85e,DISK], DatanodeInfoWithStorage[127.0.0.1:41210,DS-4e5d9bc7-1535-42c6-ae3e-c600dc74d4ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1788538613-172.17.0.17-1598165038685:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38670,DS-feca01c1-14c4-4b9d-bac3-1fd084d161f3,DISK], DatanodeInfoWithStorage[127.0.0.1:38165,DS-6fa91779-4063-4a9d-9862-37459fc042ed,DISK], DatanodeInfoWithStorage[127.0.0.1:42248,DS-dd1668e6-de92-48d7-a1d6-c53e22cd8a46,DISK], DatanodeInfoWithStorage[127.0.0.1:35621,DS-9a1d45c4-f1a5-408a-ad3c-ecc923ca52c9,DISK], DatanodeInfoWithStorage[127.0.0.1:42939,DS-27d48766-3179-468c-bd33-02779173f0bd,DISK], DatanodeInfoWithStorage[127.0.0.1:44138,DS-788447bb-45da-4cc2-b1ad-8fa67ff500cd,DISK], DatanodeInfoWithStorage[127.0.0.1:38591,DS-64566dd4-61dd-41c4-9fb8-3375ceb6725e,DISK], DatanodeInfoWithStorage[127.0.0.1:45426,DS-dfd70586-97b0-4b2f-a3fc-422f7f0edfb6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1788538613-172.17.0.17-1598165038685:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38670,DS-feca01c1-14c4-4b9d-bac3-1fd084d161f3,DISK], DatanodeInfoWithStorage[127.0.0.1:38165,DS-6fa91779-4063-4a9d-9862-37459fc042ed,DISK], DatanodeInfoWithStorage[127.0.0.1:42248,DS-dd1668e6-de92-48d7-a1d6-c53e22cd8a46,DISK], DatanodeInfoWithStorage[127.0.0.1:35621,DS-9a1d45c4-f1a5-408a-ad3c-ecc923ca52c9,DISK], DatanodeInfoWithStorage[127.0.0.1:42939,DS-27d48766-3179-468c-bd33-02779173f0bd,DISK], DatanodeInfoWithStorage[127.0.0.1:44138,DS-788447bb-45da-4cc2-b1ad-8fa67ff500cd,DISK], DatanodeInfoWithStorage[127.0.0.1:38591,DS-64566dd4-61dd-41c4-9fb8-3375ceb6725e,DISK], DatanodeInfoWithStorage[127.0.0.1:45426,DS-dfd70586-97b0-4b2f-a3fc-422f7f0edfb6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1228321623-172.17.0.17-1598165218248:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35595,DS-1a5d3f04-bec8-44e7-bd0b-68580f42f102,DISK], DatanodeInfoWithStorage[127.0.0.1:39457,DS-2b25b932-1b2c-4d66-a948-f2312f639676,DISK], DatanodeInfoWithStorage[127.0.0.1:42954,DS-c9dea0a9-c098-4a4e-99d5-a816899be39d,DISK], DatanodeInfoWithStorage[127.0.0.1:43219,DS-c092beef-bfda-4404-afdd-b57b4b8909c7,DISK], DatanodeInfoWithStorage[127.0.0.1:38110,DS-42543892-55a7-492e-85ca-6d57506cbac0,DISK], DatanodeInfoWithStorage[127.0.0.1:35240,DS-ba36332a-71b5-4f5a-a0a4-bd2a88c66afd,DISK], DatanodeInfoWithStorage[127.0.0.1:34493,DS-01f2bdb5-836a-4cdb-8961-f004c19728f8,DISK], DatanodeInfoWithStorage[127.0.0.1:43225,DS-392c13d6-a6c8-4d18-9aab-6b5aacbf75e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1228321623-172.17.0.17-1598165218248:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35595,DS-1a5d3f04-bec8-44e7-bd0b-68580f42f102,DISK], DatanodeInfoWithStorage[127.0.0.1:39457,DS-2b25b932-1b2c-4d66-a948-f2312f639676,DISK], DatanodeInfoWithStorage[127.0.0.1:42954,DS-c9dea0a9-c098-4a4e-99d5-a816899be39d,DISK], DatanodeInfoWithStorage[127.0.0.1:43219,DS-c092beef-bfda-4404-afdd-b57b4b8909c7,DISK], DatanodeInfoWithStorage[127.0.0.1:38110,DS-42543892-55a7-492e-85ca-6d57506cbac0,DISK], DatanodeInfoWithStorage[127.0.0.1:35240,DS-ba36332a-71b5-4f5a-a0a4-bd2a88c66afd,DISK], DatanodeInfoWithStorage[127.0.0.1:34493,DS-01f2bdb5-836a-4cdb-8961-f004c19728f8,DISK], DatanodeInfoWithStorage[127.0.0.1:43225,DS-392c13d6-a6c8-4d18-9aab-6b5aacbf75e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2134471563-172.17.0.17-1598165266228:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45270,DS-e96e8f8b-7d75-4c3b-a855-cb1a7e0496e2,DISK], DatanodeInfoWithStorage[127.0.0.1:43971,DS-321dbcf7-5deb-46ad-9ebd-51282fc42d67,DISK], DatanodeInfoWithStorage[127.0.0.1:41287,DS-df8d3053-24ef-4d1a-99ad-90de6e71b035,DISK], DatanodeInfoWithStorage[127.0.0.1:35327,DS-098438e3-6630-474e-b7a3-d32d38099893,DISK], DatanodeInfoWithStorage[127.0.0.1:45941,DS-36b26d04-8732-4181-803b-da9c9558ec43,DISK], DatanodeInfoWithStorage[127.0.0.1:35829,DS-478b2b55-a5d7-41b2-859e-2339479ca395,DISK], DatanodeInfoWithStorage[127.0.0.1:44841,DS-849b2572-e492-43a2-b8e3-d169bf7594cb,DISK], DatanodeInfoWithStorage[127.0.0.1:42121,DS-f91c15b8-5522-4326-be94-6a39a59145c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2134471563-172.17.0.17-1598165266228:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45270,DS-e96e8f8b-7d75-4c3b-a855-cb1a7e0496e2,DISK], DatanodeInfoWithStorage[127.0.0.1:43971,DS-321dbcf7-5deb-46ad-9ebd-51282fc42d67,DISK], DatanodeInfoWithStorage[127.0.0.1:41287,DS-df8d3053-24ef-4d1a-99ad-90de6e71b035,DISK], DatanodeInfoWithStorage[127.0.0.1:35327,DS-098438e3-6630-474e-b7a3-d32d38099893,DISK], DatanodeInfoWithStorage[127.0.0.1:45941,DS-36b26d04-8732-4181-803b-da9c9558ec43,DISK], DatanodeInfoWithStorage[127.0.0.1:35829,DS-478b2b55-a5d7-41b2-859e-2339479ca395,DISK], DatanodeInfoWithStorage[127.0.0.1:44841,DS-849b2572-e492-43a2-b8e3-d169bf7594cb,DISK], DatanodeInfoWithStorage[127.0.0.1:42121,DS-f91c15b8-5522-4326-be94-6a39a59145c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1017482918-172.17.0.17-1598165301956:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45674,DS-c82bc349-449e-4571-9afe-5c0c89432284,DISK], DatanodeInfoWithStorage[127.0.0.1:37386,DS-238a0869-9cc3-44b9-9c0e-8b5866ca6c36,DISK], DatanodeInfoWithStorage[127.0.0.1:40014,DS-816b2424-c055-48a1-beb2-6ce17b430f10,DISK], DatanodeInfoWithStorage[127.0.0.1:33198,DS-0f8c6229-09f7-44db-bdd7-27fa5b4e5ce8,DISK], DatanodeInfoWithStorage[127.0.0.1:42949,DS-3f93da1a-dfaf-4c10-852e-e554b6a4e093,DISK], DatanodeInfoWithStorage[127.0.0.1:45920,DS-4167c076-4528-4b79-b173-4cbc07c3de73,DISK], DatanodeInfoWithStorage[127.0.0.1:34993,DS-8b80de6b-eb54-4953-abf5-96aa4359dcaf,DISK], DatanodeInfoWithStorage[127.0.0.1:36280,DS-08d94415-eb71-4ea8-84e5-6ea67f90de4a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1017482918-172.17.0.17-1598165301956:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45674,DS-c82bc349-449e-4571-9afe-5c0c89432284,DISK], DatanodeInfoWithStorage[127.0.0.1:37386,DS-238a0869-9cc3-44b9-9c0e-8b5866ca6c36,DISK], DatanodeInfoWithStorage[127.0.0.1:40014,DS-816b2424-c055-48a1-beb2-6ce17b430f10,DISK], DatanodeInfoWithStorage[127.0.0.1:33198,DS-0f8c6229-09f7-44db-bdd7-27fa5b4e5ce8,DISK], DatanodeInfoWithStorage[127.0.0.1:42949,DS-3f93da1a-dfaf-4c10-852e-e554b6a4e093,DISK], DatanodeInfoWithStorage[127.0.0.1:45920,DS-4167c076-4528-4b79-b173-4cbc07c3de73,DISK], DatanodeInfoWithStorage[127.0.0.1:34993,DS-8b80de6b-eb54-4953-abf5-96aa4359dcaf,DISK], DatanodeInfoWithStorage[127.0.0.1:36280,DS-08d94415-eb71-4ea8-84e5-6ea67f90de4a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1944314588-172.17.0.17-1598165439014:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36875,DS-6a27bbd0-215f-42c4-bf51-9c9844bc7145,DISK], DatanodeInfoWithStorage[127.0.0.1:38539,DS-64859f89-6328-426d-8821-e769768a9f52,DISK], DatanodeInfoWithStorage[127.0.0.1:36006,DS-ed3f8619-4aec-43ea-9173-d152acbaa1de,DISK], DatanodeInfoWithStorage[127.0.0.1:44591,DS-bf125bf5-c5d1-41d9-9730-bd62b1007c91,DISK], DatanodeInfoWithStorage[127.0.0.1:34577,DS-1cce5695-4803-4786-8c84-691e3ed827f1,DISK], DatanodeInfoWithStorage[127.0.0.1:34327,DS-2857d2c0-dfb5-45dc-a0ef-eb92e04a9990,DISK], DatanodeInfoWithStorage[127.0.0.1:35909,DS-76d81668-6bd1-47a5-b900-e3aee629e671,DISK], DatanodeInfoWithStorage[127.0.0.1:41672,DS-3797dd37-4f73-4e45-a08a-80db083c4da2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1944314588-172.17.0.17-1598165439014:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36875,DS-6a27bbd0-215f-42c4-bf51-9c9844bc7145,DISK], DatanodeInfoWithStorage[127.0.0.1:38539,DS-64859f89-6328-426d-8821-e769768a9f52,DISK], DatanodeInfoWithStorage[127.0.0.1:36006,DS-ed3f8619-4aec-43ea-9173-d152acbaa1de,DISK], DatanodeInfoWithStorage[127.0.0.1:44591,DS-bf125bf5-c5d1-41d9-9730-bd62b1007c91,DISK], DatanodeInfoWithStorage[127.0.0.1:34577,DS-1cce5695-4803-4786-8c84-691e3ed827f1,DISK], DatanodeInfoWithStorage[127.0.0.1:34327,DS-2857d2c0-dfb5-45dc-a0ef-eb92e04a9990,DISK], DatanodeInfoWithStorage[127.0.0.1:35909,DS-76d81668-6bd1-47a5-b900-e3aee629e671,DISK], DatanodeInfoWithStorage[127.0.0.1:41672,DS-3797dd37-4f73-4e45-a08a-80db083c4da2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1309238866-172.17.0.17-1598166128126:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38894,DS-808976df-c13d-4fb3-8153-3e1554670017,DISK], DatanodeInfoWithStorage[127.0.0.1:45879,DS-499619ca-5dd5-4139-8276-91c7f91640ed,DISK], DatanodeInfoWithStorage[127.0.0.1:34281,DS-d00a2964-d3bf-40eb-810b-e6e17e961303,DISK], DatanodeInfoWithStorage[127.0.0.1:39279,DS-fd23d135-880d-4fd9-81a2-d7e3330c611f,DISK], DatanodeInfoWithStorage[127.0.0.1:37812,DS-272847ae-b0d2-48c7-983f-3cec76a15147,DISK], DatanodeInfoWithStorage[127.0.0.1:41631,DS-05921cd7-75c3-4941-aa91-31a469c5714a,DISK], DatanodeInfoWithStorage[127.0.0.1:45280,DS-481f4ae1-4df1-4c1c-becd-6b035cbf7236,DISK], DatanodeInfoWithStorage[127.0.0.1:40853,DS-9bce2a85-d4fd-4055-bb99-0ff7362d6d93,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1309238866-172.17.0.17-1598166128126:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38894,DS-808976df-c13d-4fb3-8153-3e1554670017,DISK], DatanodeInfoWithStorage[127.0.0.1:45879,DS-499619ca-5dd5-4139-8276-91c7f91640ed,DISK], DatanodeInfoWithStorage[127.0.0.1:34281,DS-d00a2964-d3bf-40eb-810b-e6e17e961303,DISK], DatanodeInfoWithStorage[127.0.0.1:39279,DS-fd23d135-880d-4fd9-81a2-d7e3330c611f,DISK], DatanodeInfoWithStorage[127.0.0.1:37812,DS-272847ae-b0d2-48c7-983f-3cec76a15147,DISK], DatanodeInfoWithStorage[127.0.0.1:41631,DS-05921cd7-75c3-4941-aa91-31a469c5714a,DISK], DatanodeInfoWithStorage[127.0.0.1:45280,DS-481f4ae1-4df1-4c1c-becd-6b035cbf7236,DISK], DatanodeInfoWithStorage[127.0.0.1:40853,DS-9bce2a85-d4fd-4055-bb99-0ff7362d6d93,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-6909477-172.17.0.17-1598166167097:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35806,DS-3487b9b4-d656-4b02-8cdb-705ba0a662ed,DISK], DatanodeInfoWithStorage[127.0.0.1:39862,DS-9f503277-6600-44db-8a2a-90ff777263e2,DISK], DatanodeInfoWithStorage[127.0.0.1:34074,DS-6ba14f70-ddd2-4e19-acbb-fde34c98af9e,DISK], DatanodeInfoWithStorage[127.0.0.1:46058,DS-fd81b69d-9d07-4735-9382-132c16091780,DISK], DatanodeInfoWithStorage[127.0.0.1:36698,DS-597a7ed3-e0fe-4563-a976-f822470fee1d,DISK], DatanodeInfoWithStorage[127.0.0.1:39220,DS-284230b6-5205-4bf7-bdad-4033a749e10d,DISK], DatanodeInfoWithStorage[127.0.0.1:40469,DS-88062477-d172-47da-b2a7-8193171afaee,DISK], DatanodeInfoWithStorage[127.0.0.1:44025,DS-74d1f321-d949-4490-b94c-4703dbee2af0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-6909477-172.17.0.17-1598166167097:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35806,DS-3487b9b4-d656-4b02-8cdb-705ba0a662ed,DISK], DatanodeInfoWithStorage[127.0.0.1:39862,DS-9f503277-6600-44db-8a2a-90ff777263e2,DISK], DatanodeInfoWithStorage[127.0.0.1:34074,DS-6ba14f70-ddd2-4e19-acbb-fde34c98af9e,DISK], DatanodeInfoWithStorage[127.0.0.1:46058,DS-fd81b69d-9d07-4735-9382-132c16091780,DISK], DatanodeInfoWithStorage[127.0.0.1:36698,DS-597a7ed3-e0fe-4563-a976-f822470fee1d,DISK], DatanodeInfoWithStorage[127.0.0.1:39220,DS-284230b6-5205-4bf7-bdad-4033a749e10d,DISK], DatanodeInfoWithStorage[127.0.0.1:40469,DS-88062477-d172-47da-b2a7-8193171afaee,DISK], DatanodeInfoWithStorage[127.0.0.1:44025,DS-74d1f321-d949-4490-b94c-4703dbee2af0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-365347311-172.17.0.17-1598166384194:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37103,DS-3473ef0e-2b54-461c-8070-52af5d440655,DISK], DatanodeInfoWithStorage[127.0.0.1:39606,DS-9d58c262-2467-4227-b56e-698ed4fbdc42,DISK], DatanodeInfoWithStorage[127.0.0.1:45287,DS-26286854-60b4-4bf3-920e-b31e9a259c93,DISK], DatanodeInfoWithStorage[127.0.0.1:37532,DS-0a2d5a3d-75d7-42c6-ae04-2f1b0bf87957,DISK], DatanodeInfoWithStorage[127.0.0.1:36943,DS-266bc414-add7-48fd-a3de-883186daf2f8,DISK], DatanodeInfoWithStorage[127.0.0.1:35451,DS-0e867d96-7b91-4c95-a4a9-d45341bbbc16,DISK], DatanodeInfoWithStorage[127.0.0.1:45919,DS-dfa1cca3-f6dd-493e-97ba-9676317de5b6,DISK], DatanodeInfoWithStorage[127.0.0.1:46790,DS-5700d6d4-01c8-42fe-9a52-81367cbfc094,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-365347311-172.17.0.17-1598166384194:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37103,DS-3473ef0e-2b54-461c-8070-52af5d440655,DISK], DatanodeInfoWithStorage[127.0.0.1:39606,DS-9d58c262-2467-4227-b56e-698ed4fbdc42,DISK], DatanodeInfoWithStorage[127.0.0.1:45287,DS-26286854-60b4-4bf3-920e-b31e9a259c93,DISK], DatanodeInfoWithStorage[127.0.0.1:37532,DS-0a2d5a3d-75d7-42c6-ae04-2f1b0bf87957,DISK], DatanodeInfoWithStorage[127.0.0.1:36943,DS-266bc414-add7-48fd-a3de-883186daf2f8,DISK], DatanodeInfoWithStorage[127.0.0.1:35451,DS-0e867d96-7b91-4c95-a4a9-d45341bbbc16,DISK], DatanodeInfoWithStorage[127.0.0.1:45919,DS-dfa1cca3-f6dd-493e-97ba-9676317de5b6,DISK], DatanodeInfoWithStorage[127.0.0.1:46790,DS-5700d6d4-01c8-42fe-9a52-81367cbfc094,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-213762329-172.17.0.17-1598166477631:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35757,DS-2020192b-cf0b-4aa5-b6f1-f1a340993451,DISK], DatanodeInfoWithStorage[127.0.0.1:39370,DS-c0676a1c-4f76-448d-bef9-595b0558fd11,DISK], DatanodeInfoWithStorage[127.0.0.1:40761,DS-e7466085-bad2-4b21-bbdf-2282bd5afa3b,DISK], DatanodeInfoWithStorage[127.0.0.1:42676,DS-a084ef87-4879-4301-a223-c674bede8c14,DISK], DatanodeInfoWithStorage[127.0.0.1:44081,DS-cef29e9c-429d-4296-a0ec-2bf426bd8856,DISK], DatanodeInfoWithStorage[127.0.0.1:43674,DS-f2af4db4-2b99-498e-bc57-292b14d5bf3f,DISK], DatanodeInfoWithStorage[127.0.0.1:46478,DS-705c8312-be86-49dd-a4f8-166eab4b482c,DISK], DatanodeInfoWithStorage[127.0.0.1:37076,DS-63582601-f230-4c50-bdca-90915413a396,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-213762329-172.17.0.17-1598166477631:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35757,DS-2020192b-cf0b-4aa5-b6f1-f1a340993451,DISK], DatanodeInfoWithStorage[127.0.0.1:39370,DS-c0676a1c-4f76-448d-bef9-595b0558fd11,DISK], DatanodeInfoWithStorage[127.0.0.1:40761,DS-e7466085-bad2-4b21-bbdf-2282bd5afa3b,DISK], DatanodeInfoWithStorage[127.0.0.1:42676,DS-a084ef87-4879-4301-a223-c674bede8c14,DISK], DatanodeInfoWithStorage[127.0.0.1:44081,DS-cef29e9c-429d-4296-a0ec-2bf426bd8856,DISK], DatanodeInfoWithStorage[127.0.0.1:43674,DS-f2af4db4-2b99-498e-bc57-292b14d5bf3f,DISK], DatanodeInfoWithStorage[127.0.0.1:46478,DS-705c8312-be86-49dd-a4f8-166eab4b482c,DISK], DatanodeInfoWithStorage[127.0.0.1:37076,DS-63582601-f230-4c50-bdca-90915413a396,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-60710660-172.17.0.17-1598166705908:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44332,DS-2ab60ee0-e6a2-46a1-ac1a-a763c0e462a3,DISK], DatanodeInfoWithStorage[127.0.0.1:41470,DS-4a834b1c-b3ba-4687-904d-4b373d1d82ff,DISK], DatanodeInfoWithStorage[127.0.0.1:36287,DS-226617cf-6320-4f83-b908-b2d400cc185f,DISK], DatanodeInfoWithStorage[127.0.0.1:38964,DS-cae2b1e5-0f9b-4262-b022-5782799b11d4,DISK], DatanodeInfoWithStorage[127.0.0.1:34541,DS-0ed401d5-cdf9-4e42-a0f3-a77adfce3928,DISK], DatanodeInfoWithStorage[127.0.0.1:38222,DS-fd4d0714-d6a8-4e24-bef5-7ea69cce4f42,DISK], DatanodeInfoWithStorage[127.0.0.1:37325,DS-a3cc6468-08bb-4aff-95e9-c3a715446330,DISK], DatanodeInfoWithStorage[127.0.0.1:39642,DS-04a54c4a-1be9-43c4-956f-92d493bfbaac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-60710660-172.17.0.17-1598166705908:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44332,DS-2ab60ee0-e6a2-46a1-ac1a-a763c0e462a3,DISK], DatanodeInfoWithStorage[127.0.0.1:41470,DS-4a834b1c-b3ba-4687-904d-4b373d1d82ff,DISK], DatanodeInfoWithStorage[127.0.0.1:36287,DS-226617cf-6320-4f83-b908-b2d400cc185f,DISK], DatanodeInfoWithStorage[127.0.0.1:38964,DS-cae2b1e5-0f9b-4262-b022-5782799b11d4,DISK], DatanodeInfoWithStorage[127.0.0.1:34541,DS-0ed401d5-cdf9-4e42-a0f3-a77adfce3928,DISK], DatanodeInfoWithStorage[127.0.0.1:38222,DS-fd4d0714-d6a8-4e24-bef5-7ea69cce4f42,DISK], DatanodeInfoWithStorage[127.0.0.1:37325,DS-a3cc6468-08bb-4aff-95e9-c3a715446330,DISK], DatanodeInfoWithStorage[127.0.0.1:39642,DS-04a54c4a-1be9-43c4-956f-92d493bfbaac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1461492435-172.17.0.17-1598166880541:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44864,DS-435bea48-26dc-461a-940e-56afd331236d,DISK], DatanodeInfoWithStorage[127.0.0.1:41637,DS-dcd7e54a-fc13-4d7f-a9c1-537bbd91aa82,DISK], DatanodeInfoWithStorage[127.0.0.1:39092,DS-49319e8f-930f-41bd-8d1a-d15cb438ac1d,DISK], DatanodeInfoWithStorage[127.0.0.1:40943,DS-7a925533-4922-420c-a620-23b6a09c464e,DISK], DatanodeInfoWithStorage[127.0.0.1:33082,DS-f8c711ed-e2bd-4466-8c57-f948b231cec3,DISK], DatanodeInfoWithStorage[127.0.0.1:44842,DS-b99c69ae-ca64-4e19-bf72-9516e7ed00a5,DISK], DatanodeInfoWithStorage[127.0.0.1:38665,DS-f1af43cb-23e8-4a98-b1c3-85ea536ee5c5,DISK], DatanodeInfoWithStorage[127.0.0.1:44787,DS-e2b8f339-f7b2-4a93-ac79-78347876bc9a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1461492435-172.17.0.17-1598166880541:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44864,DS-435bea48-26dc-461a-940e-56afd331236d,DISK], DatanodeInfoWithStorage[127.0.0.1:41637,DS-dcd7e54a-fc13-4d7f-a9c1-537bbd91aa82,DISK], DatanodeInfoWithStorage[127.0.0.1:39092,DS-49319e8f-930f-41bd-8d1a-d15cb438ac1d,DISK], DatanodeInfoWithStorage[127.0.0.1:40943,DS-7a925533-4922-420c-a620-23b6a09c464e,DISK], DatanodeInfoWithStorage[127.0.0.1:33082,DS-f8c711ed-e2bd-4466-8c57-f948b231cec3,DISK], DatanodeInfoWithStorage[127.0.0.1:44842,DS-b99c69ae-ca64-4e19-bf72-9516e7ed00a5,DISK], DatanodeInfoWithStorage[127.0.0.1:38665,DS-f1af43cb-23e8-4a98-b1c3-85ea536ee5c5,DISK], DatanodeInfoWithStorage[127.0.0.1:44787,DS-e2b8f339-f7b2-4a93-ac79-78347876bc9a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 6839
