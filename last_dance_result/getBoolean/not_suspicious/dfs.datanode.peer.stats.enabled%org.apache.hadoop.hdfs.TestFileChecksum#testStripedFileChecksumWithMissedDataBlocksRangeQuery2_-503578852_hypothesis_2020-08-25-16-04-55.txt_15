reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-385307780-172.17.0.15-1598371549746:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33735,DS-191fc765-6e26-4861-b847-868130f6e620,DISK], DatanodeInfoWithStorage[127.0.0.1:46454,DS-540093af-53e3-48c1-87c0-3a616bd8a5fe,DISK], DatanodeInfoWithStorage[127.0.0.1:37354,DS-004a207d-6f3a-4284-a9b7-37df006c3adc,DISK], DatanodeInfoWithStorage[127.0.0.1:42492,DS-f1d9a7e5-5cc7-425d-8d0e-82fd69b69a48,DISK], DatanodeInfoWithStorage[127.0.0.1:44907,DS-8c6f0c39-2797-43af-8e60-3db845946757,DISK], DatanodeInfoWithStorage[127.0.0.1:43659,DS-629599ad-0bdf-4cd0-9112-4dd6f4e6fa7c,DISK], DatanodeInfoWithStorage[127.0.0.1:36919,DS-cb2bbb5e-3524-40ac-b859-be59592d8951,DISK], DatanodeInfoWithStorage[127.0.0.1:38627,DS-dba0c210-1a7d-4c36-b222-5b193ca7b4d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-385307780-172.17.0.15-1598371549746:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33735,DS-191fc765-6e26-4861-b847-868130f6e620,DISK], DatanodeInfoWithStorage[127.0.0.1:46454,DS-540093af-53e3-48c1-87c0-3a616bd8a5fe,DISK], DatanodeInfoWithStorage[127.0.0.1:37354,DS-004a207d-6f3a-4284-a9b7-37df006c3adc,DISK], DatanodeInfoWithStorage[127.0.0.1:42492,DS-f1d9a7e5-5cc7-425d-8d0e-82fd69b69a48,DISK], DatanodeInfoWithStorage[127.0.0.1:44907,DS-8c6f0c39-2797-43af-8e60-3db845946757,DISK], DatanodeInfoWithStorage[127.0.0.1:43659,DS-629599ad-0bdf-4cd0-9112-4dd6f4e6fa7c,DISK], DatanodeInfoWithStorage[127.0.0.1:36919,DS-cb2bbb5e-3524-40ac-b859-be59592d8951,DISK], DatanodeInfoWithStorage[127.0.0.1:38627,DS-dba0c210-1a7d-4c36-b222-5b193ca7b4d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1095710718-172.17.0.15-1598371583649:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39436,DS-e13289f8-de3c-4e8e-b82a-13ae6098d245,DISK], DatanodeInfoWithStorage[127.0.0.1:35007,DS-da658b43-9ebe-4f3f-a4a5-dfa7c74f8a78,DISK], DatanodeInfoWithStorage[127.0.0.1:38497,DS-0288330e-e300-439a-ba32-43dea508d8af,DISK], DatanodeInfoWithStorage[127.0.0.1:43926,DS-94a87f49-e160-44e1-85c8-a8729d832774,DISK], DatanodeInfoWithStorage[127.0.0.1:43959,DS-648db83c-38e3-4b11-914e-ae856ff69a66,DISK], DatanodeInfoWithStorage[127.0.0.1:42248,DS-470ce667-afff-4bec-88dc-670d78c9e529,DISK], DatanodeInfoWithStorage[127.0.0.1:41149,DS-41e4d655-b796-45d7-8b6e-adc8349fc88f,DISK], DatanodeInfoWithStorage[127.0.0.1:35921,DS-7794fe77-0217-48fa-a226-49e61648c21c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1095710718-172.17.0.15-1598371583649:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39436,DS-e13289f8-de3c-4e8e-b82a-13ae6098d245,DISK], DatanodeInfoWithStorage[127.0.0.1:35007,DS-da658b43-9ebe-4f3f-a4a5-dfa7c74f8a78,DISK], DatanodeInfoWithStorage[127.0.0.1:38497,DS-0288330e-e300-439a-ba32-43dea508d8af,DISK], DatanodeInfoWithStorage[127.0.0.1:43926,DS-94a87f49-e160-44e1-85c8-a8729d832774,DISK], DatanodeInfoWithStorage[127.0.0.1:43959,DS-648db83c-38e3-4b11-914e-ae856ff69a66,DISK], DatanodeInfoWithStorage[127.0.0.1:42248,DS-470ce667-afff-4bec-88dc-670d78c9e529,DISK], DatanodeInfoWithStorage[127.0.0.1:41149,DS-41e4d655-b796-45d7-8b6e-adc8349fc88f,DISK], DatanodeInfoWithStorage[127.0.0.1:35921,DS-7794fe77-0217-48fa-a226-49e61648c21c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-137936919-172.17.0.15-1598371712262:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34317,DS-8b3bec09-2b5f-4d6c-bcab-d5bde52fb358,DISK], DatanodeInfoWithStorage[127.0.0.1:35372,DS-d2d8b973-28ed-40e2-b8a7-22ba415fc693,DISK], DatanodeInfoWithStorage[127.0.0.1:41891,DS-25759297-dc9a-4e2b-b96e-bac1631a62ae,DISK], DatanodeInfoWithStorage[127.0.0.1:44043,DS-d8bdf927-6131-42e8-9f63-c12eee258cc0,DISK], DatanodeInfoWithStorage[127.0.0.1:36488,DS-77a336a6-202a-4518-a216-b330c8676cea,DISK], DatanodeInfoWithStorage[127.0.0.1:37059,DS-38732d09-9d22-4bfe-b5fd-78775aa1f3d9,DISK], DatanodeInfoWithStorage[127.0.0.1:36230,DS-8f96cc88-fe0f-406d-8565-ffb384be49f1,DISK], DatanodeInfoWithStorage[127.0.0.1:39933,DS-c1be5aab-dd37-48fd-b180-ab5b04a04d7a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-137936919-172.17.0.15-1598371712262:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34317,DS-8b3bec09-2b5f-4d6c-bcab-d5bde52fb358,DISK], DatanodeInfoWithStorage[127.0.0.1:35372,DS-d2d8b973-28ed-40e2-b8a7-22ba415fc693,DISK], DatanodeInfoWithStorage[127.0.0.1:41891,DS-25759297-dc9a-4e2b-b96e-bac1631a62ae,DISK], DatanodeInfoWithStorage[127.0.0.1:44043,DS-d8bdf927-6131-42e8-9f63-c12eee258cc0,DISK], DatanodeInfoWithStorage[127.0.0.1:36488,DS-77a336a6-202a-4518-a216-b330c8676cea,DISK], DatanodeInfoWithStorage[127.0.0.1:37059,DS-38732d09-9d22-4bfe-b5fd-78775aa1f3d9,DISK], DatanodeInfoWithStorage[127.0.0.1:36230,DS-8f96cc88-fe0f-406d-8565-ffb384be49f1,DISK], DatanodeInfoWithStorage[127.0.0.1:39933,DS-c1be5aab-dd37-48fd-b180-ab5b04a04d7a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-800739766-172.17.0.15-1598371976635:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36300,DS-92a90715-38c9-4354-b4c5-d977c3dd1239,DISK], DatanodeInfoWithStorage[127.0.0.1:33564,DS-96c7d1f9-bdfd-40d9-8390-f994e21470d3,DISK], DatanodeInfoWithStorage[127.0.0.1:38604,DS-8730e9eb-3257-401b-879c-927ea8570b35,DISK], DatanodeInfoWithStorage[127.0.0.1:43026,DS-8f6544c4-8c00-4231-93a9-28d5a506fbff,DISK], DatanodeInfoWithStorage[127.0.0.1:34249,DS-ce2b884b-ddce-403d-b43d-9edd9524971e,DISK], DatanodeInfoWithStorage[127.0.0.1:37666,DS-28f8de33-1def-4c1a-aafe-c8a7cea43868,DISK], DatanodeInfoWithStorage[127.0.0.1:46560,DS-ed29c31a-acdf-4f1a-9041-7590be7de8ad,DISK], DatanodeInfoWithStorage[127.0.0.1:34201,DS-ae9c7187-0c5b-4a86-a24d-0dcf114f835d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-800739766-172.17.0.15-1598371976635:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36300,DS-92a90715-38c9-4354-b4c5-d977c3dd1239,DISK], DatanodeInfoWithStorage[127.0.0.1:33564,DS-96c7d1f9-bdfd-40d9-8390-f994e21470d3,DISK], DatanodeInfoWithStorage[127.0.0.1:38604,DS-8730e9eb-3257-401b-879c-927ea8570b35,DISK], DatanodeInfoWithStorage[127.0.0.1:43026,DS-8f6544c4-8c00-4231-93a9-28d5a506fbff,DISK], DatanodeInfoWithStorage[127.0.0.1:34249,DS-ce2b884b-ddce-403d-b43d-9edd9524971e,DISK], DatanodeInfoWithStorage[127.0.0.1:37666,DS-28f8de33-1def-4c1a-aafe-c8a7cea43868,DISK], DatanodeInfoWithStorage[127.0.0.1:46560,DS-ed29c31a-acdf-4f1a-9041-7590be7de8ad,DISK], DatanodeInfoWithStorage[127.0.0.1:34201,DS-ae9c7187-0c5b-4a86-a24d-0dcf114f835d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1990660991-172.17.0.15-1598372033075:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42873,DS-016e04bd-d4b3-4453-92cd-b706d6c09c28,DISK], DatanodeInfoWithStorage[127.0.0.1:43422,DS-2c265e5a-0221-4d02-806c-87b544cb7c11,DISK], DatanodeInfoWithStorage[127.0.0.1:38362,DS-eb8bec0d-b316-4b23-b193-d430f633f7b0,DISK], DatanodeInfoWithStorage[127.0.0.1:41545,DS-42085465-c9e8-41f9-b565-bb24ed8f6ce1,DISK], DatanodeInfoWithStorage[127.0.0.1:43809,DS-a12f4830-5abe-43d8-b02a-a6085287df0e,DISK], DatanodeInfoWithStorage[127.0.0.1:41923,DS-ecfd74e1-0420-45ec-b0ef-1eadb5231f02,DISK], DatanodeInfoWithStorage[127.0.0.1:35453,DS-31c6cd34-bd9f-4406-aeb1-a0d13b04ea27,DISK], DatanodeInfoWithStorage[127.0.0.1:41245,DS-3ae9aa3c-6ae6-4f42-9c10-dbf4f35a7544,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1990660991-172.17.0.15-1598372033075:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42873,DS-016e04bd-d4b3-4453-92cd-b706d6c09c28,DISK], DatanodeInfoWithStorage[127.0.0.1:43422,DS-2c265e5a-0221-4d02-806c-87b544cb7c11,DISK], DatanodeInfoWithStorage[127.0.0.1:38362,DS-eb8bec0d-b316-4b23-b193-d430f633f7b0,DISK], DatanodeInfoWithStorage[127.0.0.1:41545,DS-42085465-c9e8-41f9-b565-bb24ed8f6ce1,DISK], DatanodeInfoWithStorage[127.0.0.1:43809,DS-a12f4830-5abe-43d8-b02a-a6085287df0e,DISK], DatanodeInfoWithStorage[127.0.0.1:41923,DS-ecfd74e1-0420-45ec-b0ef-1eadb5231f02,DISK], DatanodeInfoWithStorage[127.0.0.1:35453,DS-31c6cd34-bd9f-4406-aeb1-a0d13b04ea27,DISK], DatanodeInfoWithStorage[127.0.0.1:41245,DS-3ae9aa3c-6ae6-4f42-9c10-dbf4f35a7544,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-857592881-172.17.0.15-1598372306684:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33571,DS-6032b489-ec37-4cc2-9a61-edf2684206dd,DISK], DatanodeInfoWithStorage[127.0.0.1:42053,DS-cced2b85-02b8-4ca9-8f4b-493262745286,DISK], DatanodeInfoWithStorage[127.0.0.1:33201,DS-f183647d-fb01-441d-96de-d214d225eeef,DISK], DatanodeInfoWithStorage[127.0.0.1:39535,DS-72d7715e-8da9-4b9d-b0eb-14e025296837,DISK], DatanodeInfoWithStorage[127.0.0.1:33694,DS-f8dbc0ec-274d-41bd-89b4-c4cb6f3a79a4,DISK], DatanodeInfoWithStorage[127.0.0.1:41983,DS-3a8c372f-9742-4d23-8e32-17c2ae596c95,DISK], DatanodeInfoWithStorage[127.0.0.1:38316,DS-5eef5023-800e-4c2f-98a9-6b0b38065c18,DISK], DatanodeInfoWithStorage[127.0.0.1:42369,DS-850d184c-9bd8-44b7-8da5-924fb2ce1b1f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-857592881-172.17.0.15-1598372306684:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33571,DS-6032b489-ec37-4cc2-9a61-edf2684206dd,DISK], DatanodeInfoWithStorage[127.0.0.1:42053,DS-cced2b85-02b8-4ca9-8f4b-493262745286,DISK], DatanodeInfoWithStorage[127.0.0.1:33201,DS-f183647d-fb01-441d-96de-d214d225eeef,DISK], DatanodeInfoWithStorage[127.0.0.1:39535,DS-72d7715e-8da9-4b9d-b0eb-14e025296837,DISK], DatanodeInfoWithStorage[127.0.0.1:33694,DS-f8dbc0ec-274d-41bd-89b4-c4cb6f3a79a4,DISK], DatanodeInfoWithStorage[127.0.0.1:41983,DS-3a8c372f-9742-4d23-8e32-17c2ae596c95,DISK], DatanodeInfoWithStorage[127.0.0.1:38316,DS-5eef5023-800e-4c2f-98a9-6b0b38065c18,DISK], DatanodeInfoWithStorage[127.0.0.1:42369,DS-850d184c-9bd8-44b7-8da5-924fb2ce1b1f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-573374436-172.17.0.15-1598372407514:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32998,DS-86294a93-ee94-4142-b290-47198c4ff7c3,DISK], DatanodeInfoWithStorage[127.0.0.1:39114,DS-3c20133b-24f3-49f2-bfbd-3028746f938f,DISK], DatanodeInfoWithStorage[127.0.0.1:43197,DS-02dfda5b-22b2-453f-a76a-677a287786ee,DISK], DatanodeInfoWithStorage[127.0.0.1:44142,DS-caead41a-3295-4bba-a596-43945118fe03,DISK], DatanodeInfoWithStorage[127.0.0.1:44560,DS-ffb3a9be-084a-4dc8-8a44-7024851ad69d,DISK], DatanodeInfoWithStorage[127.0.0.1:39121,DS-46be6ed8-6147-4199-865b-b72be0d7e06a,DISK], DatanodeInfoWithStorage[127.0.0.1:42535,DS-a7c74f54-30ca-4336-bc52-a5aee8926710,DISK], DatanodeInfoWithStorage[127.0.0.1:41586,DS-b2f3b66f-4500-4227-a247-696aa482b7b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-573374436-172.17.0.15-1598372407514:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32998,DS-86294a93-ee94-4142-b290-47198c4ff7c3,DISK], DatanodeInfoWithStorage[127.0.0.1:39114,DS-3c20133b-24f3-49f2-bfbd-3028746f938f,DISK], DatanodeInfoWithStorage[127.0.0.1:43197,DS-02dfda5b-22b2-453f-a76a-677a287786ee,DISK], DatanodeInfoWithStorage[127.0.0.1:44142,DS-caead41a-3295-4bba-a596-43945118fe03,DISK], DatanodeInfoWithStorage[127.0.0.1:44560,DS-ffb3a9be-084a-4dc8-8a44-7024851ad69d,DISK], DatanodeInfoWithStorage[127.0.0.1:39121,DS-46be6ed8-6147-4199-865b-b72be0d7e06a,DISK], DatanodeInfoWithStorage[127.0.0.1:42535,DS-a7c74f54-30ca-4336-bc52-a5aee8926710,DISK], DatanodeInfoWithStorage[127.0.0.1:41586,DS-b2f3b66f-4500-4227-a247-696aa482b7b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-784620207-172.17.0.15-1598372757580:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34015,DS-b91a52fd-5441-4be5-b2ec-5cc78fb9acb2,DISK], DatanodeInfoWithStorage[127.0.0.1:46830,DS-07c6df05-f324-45a2-a0c9-75de6cec6654,DISK], DatanodeInfoWithStorage[127.0.0.1:36523,DS-1d126898-cb5b-4a9b-b0e7-6c1e011e78e3,DISK], DatanodeInfoWithStorage[127.0.0.1:34563,DS-add78b9b-bee2-4190-8e11-3c8e53b870f4,DISK], DatanodeInfoWithStorage[127.0.0.1:38678,DS-7188005b-f4d7-4530-bb82-b3a0889714a5,DISK], DatanodeInfoWithStorage[127.0.0.1:45049,DS-b358d649-ca59-4a16-9485-1d4533ae2bbf,DISK], DatanodeInfoWithStorage[127.0.0.1:38431,DS-8316e827-47e4-473f-9b1f-9e5ac6672321,DISK], DatanodeInfoWithStorage[127.0.0.1:33154,DS-2df83f0d-62de-448e-adb9-744b132e8d7e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-784620207-172.17.0.15-1598372757580:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34015,DS-b91a52fd-5441-4be5-b2ec-5cc78fb9acb2,DISK], DatanodeInfoWithStorage[127.0.0.1:46830,DS-07c6df05-f324-45a2-a0c9-75de6cec6654,DISK], DatanodeInfoWithStorage[127.0.0.1:36523,DS-1d126898-cb5b-4a9b-b0e7-6c1e011e78e3,DISK], DatanodeInfoWithStorage[127.0.0.1:34563,DS-add78b9b-bee2-4190-8e11-3c8e53b870f4,DISK], DatanodeInfoWithStorage[127.0.0.1:38678,DS-7188005b-f4d7-4530-bb82-b3a0889714a5,DISK], DatanodeInfoWithStorage[127.0.0.1:45049,DS-b358d649-ca59-4a16-9485-1d4533ae2bbf,DISK], DatanodeInfoWithStorage[127.0.0.1:38431,DS-8316e827-47e4-473f-9b1f-9e5ac6672321,DISK], DatanodeInfoWithStorage[127.0.0.1:33154,DS-2df83f0d-62de-448e-adb9-744b132e8d7e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1866972805-172.17.0.15-1598372858264:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43188,DS-af50630f-5e76-4824-917c-683085b3526e,DISK], DatanodeInfoWithStorage[127.0.0.1:43883,DS-dea0f35c-54a2-4ea4-9a59-2aaad2a677ef,DISK], DatanodeInfoWithStorage[127.0.0.1:42188,DS-f4d58cbf-5362-4b7a-91cf-e408f24316eb,DISK], DatanodeInfoWithStorage[127.0.0.1:46313,DS-ff2cbe5c-5dd7-4a92-af25-20c992505404,DISK], DatanodeInfoWithStorage[127.0.0.1:35609,DS-3a6e4c53-1a15-4628-8c58-703b7b61d2f8,DISK], DatanodeInfoWithStorage[127.0.0.1:38881,DS-f0b1b4aa-df52-4f31-a1c2-50a072882732,DISK], DatanodeInfoWithStorage[127.0.0.1:33988,DS-158b17c2-f44a-42a4-b7d9-568e4156fba3,DISK], DatanodeInfoWithStorage[127.0.0.1:37453,DS-c7cddbd5-6b42-4ecd-bfd2-2d3efc426f78,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1866972805-172.17.0.15-1598372858264:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43188,DS-af50630f-5e76-4824-917c-683085b3526e,DISK], DatanodeInfoWithStorage[127.0.0.1:43883,DS-dea0f35c-54a2-4ea4-9a59-2aaad2a677ef,DISK], DatanodeInfoWithStorage[127.0.0.1:42188,DS-f4d58cbf-5362-4b7a-91cf-e408f24316eb,DISK], DatanodeInfoWithStorage[127.0.0.1:46313,DS-ff2cbe5c-5dd7-4a92-af25-20c992505404,DISK], DatanodeInfoWithStorage[127.0.0.1:35609,DS-3a6e4c53-1a15-4628-8c58-703b7b61d2f8,DISK], DatanodeInfoWithStorage[127.0.0.1:38881,DS-f0b1b4aa-df52-4f31-a1c2-50a072882732,DISK], DatanodeInfoWithStorage[127.0.0.1:33988,DS-158b17c2-f44a-42a4-b7d9-568e4156fba3,DISK], DatanodeInfoWithStorage[127.0.0.1:37453,DS-c7cddbd5-6b42-4ecd-bfd2-2d3efc426f78,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-129788479-172.17.0.15-1598372976619:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43067,DS-e2c0978b-534e-475f-bb8f-a26c7b2613fe,DISK], DatanodeInfoWithStorage[127.0.0.1:35084,DS-83610a8a-b530-46d8-b05d-6f0320dadc35,DISK], DatanodeInfoWithStorage[127.0.0.1:33643,DS-2e9b6182-1f56-4bce-9639-5c8532deec86,DISK], DatanodeInfoWithStorage[127.0.0.1:34686,DS-cda0b102-3a22-45bc-ae09-e81273d6b599,DISK], DatanodeInfoWithStorage[127.0.0.1:45933,DS-de6aa880-0368-4076-ac0d-fd8d06a2b00d,DISK], DatanodeInfoWithStorage[127.0.0.1:36551,DS-65b53afe-9961-45e4-aa9a-24dc8c491567,DISK], DatanodeInfoWithStorage[127.0.0.1:42785,DS-2ef5ca24-b190-484c-9669-6a9e7a072397,DISK], DatanodeInfoWithStorage[127.0.0.1:44641,DS-35e83f8d-e4e9-498e-b85c-d4af4424a17d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-129788479-172.17.0.15-1598372976619:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43067,DS-e2c0978b-534e-475f-bb8f-a26c7b2613fe,DISK], DatanodeInfoWithStorage[127.0.0.1:35084,DS-83610a8a-b530-46d8-b05d-6f0320dadc35,DISK], DatanodeInfoWithStorage[127.0.0.1:33643,DS-2e9b6182-1f56-4bce-9639-5c8532deec86,DISK], DatanodeInfoWithStorage[127.0.0.1:34686,DS-cda0b102-3a22-45bc-ae09-e81273d6b599,DISK], DatanodeInfoWithStorage[127.0.0.1:45933,DS-de6aa880-0368-4076-ac0d-fd8d06a2b00d,DISK], DatanodeInfoWithStorage[127.0.0.1:36551,DS-65b53afe-9961-45e4-aa9a-24dc8c491567,DISK], DatanodeInfoWithStorage[127.0.0.1:42785,DS-2ef5ca24-b190-484c-9669-6a9e7a072397,DISK], DatanodeInfoWithStorage[127.0.0.1:44641,DS-35e83f8d-e4e9-498e-b85c-d4af4424a17d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1085196873-172.17.0.15-1598373965655:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40848,DS-067e68c2-6ece-404d-af3d-0746a37b4d62,DISK], DatanodeInfoWithStorage[127.0.0.1:35133,DS-5afce6fa-c146-4a02-9b9e-4cc99f2c4a4b,DISK], DatanodeInfoWithStorage[127.0.0.1:38213,DS-2d0dd6a0-db34-468c-ae24-19bcfb572e60,DISK], DatanodeInfoWithStorage[127.0.0.1:37386,DS-917d4c1b-baa9-4c61-84f5-6870a934eb93,DISK], DatanodeInfoWithStorage[127.0.0.1:35676,DS-7d384686-ad2e-4a94-98d9-f2729a10b708,DISK], DatanodeInfoWithStorage[127.0.0.1:42941,DS-7e936482-f303-4f77-b43a-e8803e982d21,DISK], DatanodeInfoWithStorage[127.0.0.1:46315,DS-940be0b4-db13-46fd-aa5b-14e6ada7d1b8,DISK], DatanodeInfoWithStorage[127.0.0.1:38073,DS-12514c42-4058-4d65-bc7e-88306caf39e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1085196873-172.17.0.15-1598373965655:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40848,DS-067e68c2-6ece-404d-af3d-0746a37b4d62,DISK], DatanodeInfoWithStorage[127.0.0.1:35133,DS-5afce6fa-c146-4a02-9b9e-4cc99f2c4a4b,DISK], DatanodeInfoWithStorage[127.0.0.1:38213,DS-2d0dd6a0-db34-468c-ae24-19bcfb572e60,DISK], DatanodeInfoWithStorage[127.0.0.1:37386,DS-917d4c1b-baa9-4c61-84f5-6870a934eb93,DISK], DatanodeInfoWithStorage[127.0.0.1:35676,DS-7d384686-ad2e-4a94-98d9-f2729a10b708,DISK], DatanodeInfoWithStorage[127.0.0.1:42941,DS-7e936482-f303-4f77-b43a-e8803e982d21,DISK], DatanodeInfoWithStorage[127.0.0.1:46315,DS-940be0b4-db13-46fd-aa5b-14e6ada7d1b8,DISK], DatanodeInfoWithStorage[127.0.0.1:38073,DS-12514c42-4058-4d65-bc7e-88306caf39e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1902525509-172.17.0.15-1598374002784:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37503,DS-f8fe1446-e163-4770-aca5-22c8e466e752,DISK], DatanodeInfoWithStorage[127.0.0.1:37602,DS-c269073e-7581-43ad-b7f6-65b885fa7e8b,DISK], DatanodeInfoWithStorage[127.0.0.1:41145,DS-f6574b27-8191-4f52-ba1c-fd5ed1aeecd7,DISK], DatanodeInfoWithStorage[127.0.0.1:40220,DS-83064cb7-9436-4bbe-858c-1614b932ce6f,DISK], DatanodeInfoWithStorage[127.0.0.1:35682,DS-65490bd9-add8-4258-90c1-d881fdbf2fb2,DISK], DatanodeInfoWithStorage[127.0.0.1:36662,DS-bc5f7d38-8bd2-49ad-bfac-9382ef9da7b3,DISK], DatanodeInfoWithStorage[127.0.0.1:46383,DS-39a3135b-a9e4-44aa-a4e1-722e99d9f810,DISK], DatanodeInfoWithStorage[127.0.0.1:43154,DS-1c26ddef-10df-47b9-81b5-f58173799157,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1902525509-172.17.0.15-1598374002784:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37503,DS-f8fe1446-e163-4770-aca5-22c8e466e752,DISK], DatanodeInfoWithStorage[127.0.0.1:37602,DS-c269073e-7581-43ad-b7f6-65b885fa7e8b,DISK], DatanodeInfoWithStorage[127.0.0.1:41145,DS-f6574b27-8191-4f52-ba1c-fd5ed1aeecd7,DISK], DatanodeInfoWithStorage[127.0.0.1:40220,DS-83064cb7-9436-4bbe-858c-1614b932ce6f,DISK], DatanodeInfoWithStorage[127.0.0.1:35682,DS-65490bd9-add8-4258-90c1-d881fdbf2fb2,DISK], DatanodeInfoWithStorage[127.0.0.1:36662,DS-bc5f7d38-8bd2-49ad-bfac-9382ef9da7b3,DISK], DatanodeInfoWithStorage[127.0.0.1:46383,DS-39a3135b-a9e4-44aa-a4e1-722e99d9f810,DISK], DatanodeInfoWithStorage[127.0.0.1:43154,DS-1c26ddef-10df-47b9-81b5-f58173799157,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-463179345-172.17.0.15-1598374420193:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33579,DS-64c337ef-e54b-457c-ab44-ad10de25e324,DISK], DatanodeInfoWithStorage[127.0.0.1:41718,DS-3c4a7b01-97c5-42fd-9531-1ea8d34e2b5d,DISK], DatanodeInfoWithStorage[127.0.0.1:35992,DS-02ed5f3d-089d-4f91-b012-e29a6ca1611f,DISK], DatanodeInfoWithStorage[127.0.0.1:35262,DS-3ef88b2c-3b46-4b76-8e21-ad04b6cd5836,DISK], DatanodeInfoWithStorage[127.0.0.1:35013,DS-59682015-19e4-4119-84c0-b224dca90b89,DISK], DatanodeInfoWithStorage[127.0.0.1:33307,DS-68b0f090-24ee-453b-848f-e4e329f144bb,DISK], DatanodeInfoWithStorage[127.0.0.1:40953,DS-1ec0d25a-5e5a-4668-83a5-b74bbaa892bb,DISK], DatanodeInfoWithStorage[127.0.0.1:42931,DS-dfef7a73-75c9-4b24-9989-acbfca004006,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-463179345-172.17.0.15-1598374420193:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33579,DS-64c337ef-e54b-457c-ab44-ad10de25e324,DISK], DatanodeInfoWithStorage[127.0.0.1:41718,DS-3c4a7b01-97c5-42fd-9531-1ea8d34e2b5d,DISK], DatanodeInfoWithStorage[127.0.0.1:35992,DS-02ed5f3d-089d-4f91-b012-e29a6ca1611f,DISK], DatanodeInfoWithStorage[127.0.0.1:35262,DS-3ef88b2c-3b46-4b76-8e21-ad04b6cd5836,DISK], DatanodeInfoWithStorage[127.0.0.1:35013,DS-59682015-19e4-4119-84c0-b224dca90b89,DISK], DatanodeInfoWithStorage[127.0.0.1:33307,DS-68b0f090-24ee-453b-848f-e4e329f144bb,DISK], DatanodeInfoWithStorage[127.0.0.1:40953,DS-1ec0d25a-5e5a-4668-83a5-b74bbaa892bb,DISK], DatanodeInfoWithStorage[127.0.0.1:42931,DS-dfef7a73-75c9-4b24-9989-acbfca004006,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-926937726-172.17.0.15-1598374609628:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40457,DS-ce235f79-b5ba-4e27-860c-2558d329679d,DISK], DatanodeInfoWithStorage[127.0.0.1:35677,DS-97f5efa2-c646-4b2e-ab90-7fa151774943,DISK], DatanodeInfoWithStorage[127.0.0.1:33612,DS-f3aa1dba-8cdd-40a8-aa8d-d85a2d8512e8,DISK], DatanodeInfoWithStorage[127.0.0.1:40834,DS-9423b579-9d85-4e42-a103-84348b0c2c0e,DISK], DatanodeInfoWithStorage[127.0.0.1:45878,DS-e3329afe-5772-4317-bc0d-ac9f4c99425e,DISK], DatanodeInfoWithStorage[127.0.0.1:44018,DS-fe2b452d-a4d1-4bee-80c0-a94f47831d7d,DISK], DatanodeInfoWithStorage[127.0.0.1:38921,DS-8d420710-a5b4-4f8f-bf99-67e1a2f718d4,DISK], DatanodeInfoWithStorage[127.0.0.1:42201,DS-3f226e86-88b0-4ca3-8a04-ea2e5bbeb21f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-926937726-172.17.0.15-1598374609628:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40457,DS-ce235f79-b5ba-4e27-860c-2558d329679d,DISK], DatanodeInfoWithStorage[127.0.0.1:35677,DS-97f5efa2-c646-4b2e-ab90-7fa151774943,DISK], DatanodeInfoWithStorage[127.0.0.1:33612,DS-f3aa1dba-8cdd-40a8-aa8d-d85a2d8512e8,DISK], DatanodeInfoWithStorage[127.0.0.1:40834,DS-9423b579-9d85-4e42-a103-84348b0c2c0e,DISK], DatanodeInfoWithStorage[127.0.0.1:45878,DS-e3329afe-5772-4317-bc0d-ac9f4c99425e,DISK], DatanodeInfoWithStorage[127.0.0.1:44018,DS-fe2b452d-a4d1-4bee-80c0-a94f47831d7d,DISK], DatanodeInfoWithStorage[127.0.0.1:38921,DS-8d420710-a5b4-4f8f-bf99-67e1a2f718d4,DISK], DatanodeInfoWithStorage[127.0.0.1:42201,DS-3f226e86-88b0-4ca3-8a04-ea2e5bbeb21f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1151930817-172.17.0.15-1598374810608:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36520,DS-35934294-03d5-48b0-9e66-8b1fdabf7c08,DISK], DatanodeInfoWithStorage[127.0.0.1:39540,DS-cf8bd6b1-1e8c-42b4-a781-ce93bd32ac17,DISK], DatanodeInfoWithStorage[127.0.0.1:34890,DS-c46a7186-8f4e-425a-997c-62a8668482cc,DISK], DatanodeInfoWithStorage[127.0.0.1:42612,DS-910104f7-9444-4a7b-b5e2-12358d92ec04,DISK], DatanodeInfoWithStorage[127.0.0.1:35611,DS-e00a35d8-0d2a-4288-b5e4-143158ca4b68,DISK], DatanodeInfoWithStorage[127.0.0.1:40528,DS-b54d99f3-def0-4f47-882e-b7630bd15bab,DISK], DatanodeInfoWithStorage[127.0.0.1:39067,DS-d72bd2cb-7991-4511-9536-81587753c38a,DISK], DatanodeInfoWithStorage[127.0.0.1:44481,DS-2127318b-04f3-4a97-90e4-9f7ca0490177,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1151930817-172.17.0.15-1598374810608:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36520,DS-35934294-03d5-48b0-9e66-8b1fdabf7c08,DISK], DatanodeInfoWithStorage[127.0.0.1:39540,DS-cf8bd6b1-1e8c-42b4-a781-ce93bd32ac17,DISK], DatanodeInfoWithStorage[127.0.0.1:34890,DS-c46a7186-8f4e-425a-997c-62a8668482cc,DISK], DatanodeInfoWithStorage[127.0.0.1:42612,DS-910104f7-9444-4a7b-b5e2-12358d92ec04,DISK], DatanodeInfoWithStorage[127.0.0.1:35611,DS-e00a35d8-0d2a-4288-b5e4-143158ca4b68,DISK], DatanodeInfoWithStorage[127.0.0.1:40528,DS-b54d99f3-def0-4f47-882e-b7630bd15bab,DISK], DatanodeInfoWithStorage[127.0.0.1:39067,DS-d72bd2cb-7991-4511-9536-81587753c38a,DISK], DatanodeInfoWithStorage[127.0.0.1:44481,DS-2127318b-04f3-4a97-90e4-9f7ca0490177,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-167772685-172.17.0.15-1598374951294:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42372,DS-f164e7d9-19c5-4aeb-9455-08c6a611ea43,DISK], DatanodeInfoWithStorage[127.0.0.1:45351,DS-a987161c-0d07-4457-940b-55c9ff8ad54e,DISK], DatanodeInfoWithStorage[127.0.0.1:36673,DS-2ae9be61-ccfd-4201-98d5-80733215f988,DISK], DatanodeInfoWithStorage[127.0.0.1:40214,DS-b177b2cd-2533-4b52-b62f-ab5887290f70,DISK], DatanodeInfoWithStorage[127.0.0.1:42550,DS-d52760d9-193d-4074-9dc8-7d28e8d5aeba,DISK], DatanodeInfoWithStorage[127.0.0.1:41321,DS-15402090-b80d-41ee-9f85-61c6d4c09bba,DISK], DatanodeInfoWithStorage[127.0.0.1:34045,DS-9bb3a462-f67d-47ae-8985-eb0f1277ac32,DISK], DatanodeInfoWithStorage[127.0.0.1:42737,DS-207f3dbd-fbd6-4455-b920-71ad9c7964ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-167772685-172.17.0.15-1598374951294:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42372,DS-f164e7d9-19c5-4aeb-9455-08c6a611ea43,DISK], DatanodeInfoWithStorage[127.0.0.1:45351,DS-a987161c-0d07-4457-940b-55c9ff8ad54e,DISK], DatanodeInfoWithStorage[127.0.0.1:36673,DS-2ae9be61-ccfd-4201-98d5-80733215f988,DISK], DatanodeInfoWithStorage[127.0.0.1:40214,DS-b177b2cd-2533-4b52-b62f-ab5887290f70,DISK], DatanodeInfoWithStorage[127.0.0.1:42550,DS-d52760d9-193d-4074-9dc8-7d28e8d5aeba,DISK], DatanodeInfoWithStorage[127.0.0.1:41321,DS-15402090-b80d-41ee-9f85-61c6d4c09bba,DISK], DatanodeInfoWithStorage[127.0.0.1:34045,DS-9bb3a462-f67d-47ae-8985-eb0f1277ac32,DISK], DatanodeInfoWithStorage[127.0.0.1:42737,DS-207f3dbd-fbd6-4455-b920-71ad9c7964ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-21653547-172.17.0.15-1598375219485:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40410,DS-67847619-28a4-4ec4-8692-c3145fe1790e,DISK], DatanodeInfoWithStorage[127.0.0.1:36866,DS-445607c0-2adf-4fad-bf0e-b9c09e4b2941,DISK], DatanodeInfoWithStorage[127.0.0.1:44227,DS-cbfc7b0a-ed26-482d-8df1-4dd128eaf850,DISK], DatanodeInfoWithStorage[127.0.0.1:33340,DS-f8042638-f230-4a4d-a762-b944fa52e3c9,DISK], DatanodeInfoWithStorage[127.0.0.1:38683,DS-14c0c299-d665-41ae-bddf-4ba8b8cca5a1,DISK], DatanodeInfoWithStorage[127.0.0.1:42988,DS-a276eb71-dd89-4c03-8737-ecb14ad61008,DISK], DatanodeInfoWithStorage[127.0.0.1:36926,DS-d4e5738e-a4e7-495c-904e-3e108fad0c8e,DISK], DatanodeInfoWithStorage[127.0.0.1:37807,DS-ecb2e315-3062-4d8c-8a58-08348c704386,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-21653547-172.17.0.15-1598375219485:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40410,DS-67847619-28a4-4ec4-8692-c3145fe1790e,DISK], DatanodeInfoWithStorage[127.0.0.1:36866,DS-445607c0-2adf-4fad-bf0e-b9c09e4b2941,DISK], DatanodeInfoWithStorage[127.0.0.1:44227,DS-cbfc7b0a-ed26-482d-8df1-4dd128eaf850,DISK], DatanodeInfoWithStorage[127.0.0.1:33340,DS-f8042638-f230-4a4d-a762-b944fa52e3c9,DISK], DatanodeInfoWithStorage[127.0.0.1:38683,DS-14c0c299-d665-41ae-bddf-4ba8b8cca5a1,DISK], DatanodeInfoWithStorage[127.0.0.1:42988,DS-a276eb71-dd89-4c03-8737-ecb14ad61008,DISK], DatanodeInfoWithStorage[127.0.0.1:36926,DS-d4e5738e-a4e7-495c-904e-3e108fad0c8e,DISK], DatanodeInfoWithStorage[127.0.0.1:37807,DS-ecb2e315-3062-4d8c-8a58-08348c704386,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-349768753-172.17.0.15-1598375354363:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42853,DS-fa41b0d1-c49e-4151-8969-8795e2a6de77,DISK], DatanodeInfoWithStorage[127.0.0.1:39845,DS-a27e59ea-b6f7-4474-b4c0-b4e36738d11c,DISK], DatanodeInfoWithStorage[127.0.0.1:40423,DS-de1521ad-def3-4e24-9bb5-2e6840187e6b,DISK], DatanodeInfoWithStorage[127.0.0.1:46062,DS-a29a76f7-b988-4109-bb9a-569fde25a2ae,DISK], DatanodeInfoWithStorage[127.0.0.1:39330,DS-26678700-5c8c-4b23-9bc9-2e4efdc8c85f,DISK], DatanodeInfoWithStorage[127.0.0.1:41559,DS-a9b47e5c-a5a4-42e2-b9c7-2b607db36471,DISK], DatanodeInfoWithStorage[127.0.0.1:36191,DS-288a4277-3a5f-42e2-8c2d-695f60d7541c,DISK], DatanodeInfoWithStorage[127.0.0.1:34557,DS-311e0f46-684d-42ee-bbbd-73b029544568,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-349768753-172.17.0.15-1598375354363:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42853,DS-fa41b0d1-c49e-4151-8969-8795e2a6de77,DISK], DatanodeInfoWithStorage[127.0.0.1:39845,DS-a27e59ea-b6f7-4474-b4c0-b4e36738d11c,DISK], DatanodeInfoWithStorage[127.0.0.1:40423,DS-de1521ad-def3-4e24-9bb5-2e6840187e6b,DISK], DatanodeInfoWithStorage[127.0.0.1:46062,DS-a29a76f7-b988-4109-bb9a-569fde25a2ae,DISK], DatanodeInfoWithStorage[127.0.0.1:39330,DS-26678700-5c8c-4b23-9bc9-2e4efdc8c85f,DISK], DatanodeInfoWithStorage[127.0.0.1:41559,DS-a9b47e5c-a5a4-42e2-b9c7-2b607db36471,DISK], DatanodeInfoWithStorage[127.0.0.1:36191,DS-288a4277-3a5f-42e2-8c2d-695f60d7541c,DISK], DatanodeInfoWithStorage[127.0.0.1:34557,DS-311e0f46-684d-42ee-bbbd-73b029544568,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-625095608-172.17.0.15-1598375420689:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38132,DS-09b9dc3f-798f-4a29-8a26-90dcbb54c227,DISK], DatanodeInfoWithStorage[127.0.0.1:44550,DS-a6416087-ddb8-4133-beb2-0fdb09de87b0,DISK], DatanodeInfoWithStorage[127.0.0.1:44770,DS-2e777712-351c-4a59-9ff6-9f035574d12f,DISK], DatanodeInfoWithStorage[127.0.0.1:36424,DS-f357dfe0-4ba9-4dc2-9400-54dabe75ebbc,DISK], DatanodeInfoWithStorage[127.0.0.1:41671,DS-b75243c0-1673-4684-b739-754b182889ce,DISK], DatanodeInfoWithStorage[127.0.0.1:45825,DS-ba5b5a2e-34e2-45a9-bb57-d2bfd4d2fb0d,DISK], DatanodeInfoWithStorage[127.0.0.1:34759,DS-f18e4391-3a74-41d8-816f-278c4261fe90,DISK], DatanodeInfoWithStorage[127.0.0.1:38003,DS-87faf2b8-3169-4573-87fa-9b26c5e7521c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-625095608-172.17.0.15-1598375420689:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38132,DS-09b9dc3f-798f-4a29-8a26-90dcbb54c227,DISK], DatanodeInfoWithStorage[127.0.0.1:44550,DS-a6416087-ddb8-4133-beb2-0fdb09de87b0,DISK], DatanodeInfoWithStorage[127.0.0.1:44770,DS-2e777712-351c-4a59-9ff6-9f035574d12f,DISK], DatanodeInfoWithStorage[127.0.0.1:36424,DS-f357dfe0-4ba9-4dc2-9400-54dabe75ebbc,DISK], DatanodeInfoWithStorage[127.0.0.1:41671,DS-b75243c0-1673-4684-b739-754b182889ce,DISK], DatanodeInfoWithStorage[127.0.0.1:45825,DS-ba5b5a2e-34e2-45a9-bb57-d2bfd4d2fb0d,DISK], DatanodeInfoWithStorage[127.0.0.1:34759,DS-f18e4391-3a74-41d8-816f-278c4261fe90,DISK], DatanodeInfoWithStorage[127.0.0.1:38003,DS-87faf2b8-3169-4573-87fa-9b26c5e7521c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1457215225-172.17.0.15-1598376555129:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45247,DS-1e8d6b9e-6cba-4889-9ee6-e42506d03948,DISK], DatanodeInfoWithStorage[127.0.0.1:34843,DS-73118a81-fab6-402d-a2ef-8f7db7432ae5,DISK], DatanodeInfoWithStorage[127.0.0.1:41429,DS-bfe717b9-c897-4a59-ad18-695801fc2047,DISK], DatanodeInfoWithStorage[127.0.0.1:41927,DS-54285d54-7e9e-4186-967b-1cd45e9f941e,DISK], DatanodeInfoWithStorage[127.0.0.1:38969,DS-9414003b-71d7-4cc4-93ad-9d5ed2d3a6c2,DISK], DatanodeInfoWithStorage[127.0.0.1:34394,DS-aa4aa10a-f0e9-4d6f-aa26-94d9623dbc73,DISK], DatanodeInfoWithStorage[127.0.0.1:35903,DS-9f17c802-53a9-4825-8f86-1f31d5e1eed3,DISK], DatanodeInfoWithStorage[127.0.0.1:43539,DS-86c36661-d1b4-4242-b133-675186b55225,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1457215225-172.17.0.15-1598376555129:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45247,DS-1e8d6b9e-6cba-4889-9ee6-e42506d03948,DISK], DatanodeInfoWithStorage[127.0.0.1:34843,DS-73118a81-fab6-402d-a2ef-8f7db7432ae5,DISK], DatanodeInfoWithStorage[127.0.0.1:41429,DS-bfe717b9-c897-4a59-ad18-695801fc2047,DISK], DatanodeInfoWithStorage[127.0.0.1:41927,DS-54285d54-7e9e-4186-967b-1cd45e9f941e,DISK], DatanodeInfoWithStorage[127.0.0.1:38969,DS-9414003b-71d7-4cc4-93ad-9d5ed2d3a6c2,DISK], DatanodeInfoWithStorage[127.0.0.1:34394,DS-aa4aa10a-f0e9-4d6f-aa26-94d9623dbc73,DISK], DatanodeInfoWithStorage[127.0.0.1:35903,DS-9f17c802-53a9-4825-8f86-1f31d5e1eed3,DISK], DatanodeInfoWithStorage[127.0.0.1:43539,DS-86c36661-d1b4-4242-b133-675186b55225,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5109
