reconf_parameter: dfs.namenode.reject-unresolved-dn-topology-mapping
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.reject-unresolved-dn-topology-mapping
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1826298176-172.17.0.9-1598441485038:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39763,DS-de9c3e9b-3820-4239-9d11-f3ffbaa27ab5,DISK], DatanodeInfoWithStorage[127.0.0.1:38153,DS-b066de7e-56c3-493c-a0d2-d95b73c2b4d3,DISK], DatanodeInfoWithStorage[127.0.0.1:39313,DS-eae6377f-a19a-42c7-9735-4adcb82da238,DISK], DatanodeInfoWithStorage[127.0.0.1:45121,DS-41071d55-7567-45d5-b559-e7a9bbda8ecf,DISK], DatanodeInfoWithStorage[127.0.0.1:44954,DS-433f77e3-4823-4ea4-9856-874521626e38,DISK], DatanodeInfoWithStorage[127.0.0.1:35663,DS-cbf7b1bc-e82f-4f60-9255-e8f008296c84,DISK], DatanodeInfoWithStorage[127.0.0.1:41464,DS-4f1926cf-0752-45cf-a4c5-8598589a9df4,DISK], DatanodeInfoWithStorage[127.0.0.1:39241,DS-eb702a92-a836-429f-9809-8ac5732d5759,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1826298176-172.17.0.9-1598441485038:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39763,DS-de9c3e9b-3820-4239-9d11-f3ffbaa27ab5,DISK], DatanodeInfoWithStorage[127.0.0.1:38153,DS-b066de7e-56c3-493c-a0d2-d95b73c2b4d3,DISK], DatanodeInfoWithStorage[127.0.0.1:39313,DS-eae6377f-a19a-42c7-9735-4adcb82da238,DISK], DatanodeInfoWithStorage[127.0.0.1:45121,DS-41071d55-7567-45d5-b559-e7a9bbda8ecf,DISK], DatanodeInfoWithStorage[127.0.0.1:44954,DS-433f77e3-4823-4ea4-9856-874521626e38,DISK], DatanodeInfoWithStorage[127.0.0.1:35663,DS-cbf7b1bc-e82f-4f60-9255-e8f008296c84,DISK], DatanodeInfoWithStorage[127.0.0.1:41464,DS-4f1926cf-0752-45cf-a4c5-8598589a9df4,DISK], DatanodeInfoWithStorage[127.0.0.1:39241,DS-eb702a92-a836-429f-9809-8ac5732d5759,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.reject-unresolved-dn-topology-mapping
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-667981879-172.17.0.9-1598442054963:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40015,DS-aedc7718-0554-4e2f-8a1c-d06c0209c485,DISK], DatanodeInfoWithStorage[127.0.0.1:34797,DS-eb45239d-73f0-4b39-81b0-5d4c67f081a2,DISK], DatanodeInfoWithStorage[127.0.0.1:36214,DS-c49cfd3c-8030-4225-a2ef-8c93f0a391af,DISK], DatanodeInfoWithStorage[127.0.0.1:41593,DS-580a01d4-1f3f-4d35-a48e-f6336d7b6372,DISK], DatanodeInfoWithStorage[127.0.0.1:36367,DS-8dedabf1-ec8e-44f5-92d4-7daf8beb037b,DISK], DatanodeInfoWithStorage[127.0.0.1:45905,DS-0a82f951-036e-4a71-bb47-73fdd4a4633a,DISK], DatanodeInfoWithStorage[127.0.0.1:39268,DS-82e0ea60-73aa-47f2-af9a-2b360b295798,DISK], DatanodeInfoWithStorage[127.0.0.1:33370,DS-ff6a314e-9b8f-4043-b914-cb77c9dda97a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-667981879-172.17.0.9-1598442054963:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40015,DS-aedc7718-0554-4e2f-8a1c-d06c0209c485,DISK], DatanodeInfoWithStorage[127.0.0.1:34797,DS-eb45239d-73f0-4b39-81b0-5d4c67f081a2,DISK], DatanodeInfoWithStorage[127.0.0.1:36214,DS-c49cfd3c-8030-4225-a2ef-8c93f0a391af,DISK], DatanodeInfoWithStorage[127.0.0.1:41593,DS-580a01d4-1f3f-4d35-a48e-f6336d7b6372,DISK], DatanodeInfoWithStorage[127.0.0.1:36367,DS-8dedabf1-ec8e-44f5-92d4-7daf8beb037b,DISK], DatanodeInfoWithStorage[127.0.0.1:45905,DS-0a82f951-036e-4a71-bb47-73fdd4a4633a,DISK], DatanodeInfoWithStorage[127.0.0.1:39268,DS-82e0ea60-73aa-47f2-af9a-2b360b295798,DISK], DatanodeInfoWithStorage[127.0.0.1:33370,DS-ff6a314e-9b8f-4043-b914-cb77c9dda97a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.reject-unresolved-dn-topology-mapping
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1844658159-172.17.0.9-1598442236894:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35113,DS-e8cad2d4-cd7d-454c-bc2a-59ceacb22fc1,DISK], DatanodeInfoWithStorage[127.0.0.1:35071,DS-54f2c71b-6878-442f-aa51-7df03e7aa111,DISK], DatanodeInfoWithStorage[127.0.0.1:33045,DS-6a3a5468-01e9-48b4-88f0-ce3821eafac8,DISK], DatanodeInfoWithStorage[127.0.0.1:42341,DS-924a3fbe-cb6e-4359-a34e-9d8b11011a9e,DISK], DatanodeInfoWithStorage[127.0.0.1:43370,DS-78135b67-530f-4e15-98fb-e33d2c5d0a92,DISK], DatanodeInfoWithStorage[127.0.0.1:35269,DS-9541e4aa-13b9-473a-a086-0aaf4bdfdba7,DISK], DatanodeInfoWithStorage[127.0.0.1:37686,DS-550db932-6b9e-446c-9ccc-3346f2dc0f44,DISK], DatanodeInfoWithStorage[127.0.0.1:33434,DS-2ba999c9-2c03-4ee6-9245-12a3d7609116,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1844658159-172.17.0.9-1598442236894:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35113,DS-e8cad2d4-cd7d-454c-bc2a-59ceacb22fc1,DISK], DatanodeInfoWithStorage[127.0.0.1:35071,DS-54f2c71b-6878-442f-aa51-7df03e7aa111,DISK], DatanodeInfoWithStorage[127.0.0.1:33045,DS-6a3a5468-01e9-48b4-88f0-ce3821eafac8,DISK], DatanodeInfoWithStorage[127.0.0.1:42341,DS-924a3fbe-cb6e-4359-a34e-9d8b11011a9e,DISK], DatanodeInfoWithStorage[127.0.0.1:43370,DS-78135b67-530f-4e15-98fb-e33d2c5d0a92,DISK], DatanodeInfoWithStorage[127.0.0.1:35269,DS-9541e4aa-13b9-473a-a086-0aaf4bdfdba7,DISK], DatanodeInfoWithStorage[127.0.0.1:37686,DS-550db932-6b9e-446c-9ccc-3346f2dc0f44,DISK], DatanodeInfoWithStorage[127.0.0.1:33434,DS-2ba999c9-2c03-4ee6-9245-12a3d7609116,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.reject-unresolved-dn-topology-mapping
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-546038649-172.17.0.9-1598442629485:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43691,DS-144e42b3-743e-4e04-9268-86b9bdacc050,DISK], DatanodeInfoWithStorage[127.0.0.1:43878,DS-8b030b49-8dd6-4b8a-8a9f-592256ef14d1,DISK], DatanodeInfoWithStorage[127.0.0.1:41970,DS-1cf85344-28ab-40b3-a6f0-b3dbd22ebdc4,DISK], DatanodeInfoWithStorage[127.0.0.1:34453,DS-7f29f719-181d-4378-86be-1c18beb8a55c,DISK], DatanodeInfoWithStorage[127.0.0.1:43712,DS-28a0e345-692b-40c2-b318-082f6441385b,DISK], DatanodeInfoWithStorage[127.0.0.1:44895,DS-62743e73-a755-439c-98da-0bde756f3294,DISK], DatanodeInfoWithStorage[127.0.0.1:42900,DS-d38e53f0-9200-459b-9311-f613869090b5,DISK], DatanodeInfoWithStorage[127.0.0.1:45171,DS-2462caf0-25a9-435b-bb1d-9c12039e3a51,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-546038649-172.17.0.9-1598442629485:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43691,DS-144e42b3-743e-4e04-9268-86b9bdacc050,DISK], DatanodeInfoWithStorage[127.0.0.1:43878,DS-8b030b49-8dd6-4b8a-8a9f-592256ef14d1,DISK], DatanodeInfoWithStorage[127.0.0.1:41970,DS-1cf85344-28ab-40b3-a6f0-b3dbd22ebdc4,DISK], DatanodeInfoWithStorage[127.0.0.1:34453,DS-7f29f719-181d-4378-86be-1c18beb8a55c,DISK], DatanodeInfoWithStorage[127.0.0.1:43712,DS-28a0e345-692b-40c2-b318-082f6441385b,DISK], DatanodeInfoWithStorage[127.0.0.1:44895,DS-62743e73-a755-439c-98da-0bde756f3294,DISK], DatanodeInfoWithStorage[127.0.0.1:42900,DS-d38e53f0-9200-459b-9311-f613869090b5,DISK], DatanodeInfoWithStorage[127.0.0.1:45171,DS-2462caf0-25a9-435b-bb1d-9c12039e3a51,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.reject-unresolved-dn-topology-mapping
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-797951454-172.17.0.9-1598442710544:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45376,DS-1659e746-a01c-4b23-af87-13f5404fc887,DISK], DatanodeInfoWithStorage[127.0.0.1:36301,DS-ef5c7bc3-c4d2-4255-8fab-b12c11c72eb6,DISK], DatanodeInfoWithStorage[127.0.0.1:34561,DS-694a29c0-6ac5-4af2-950d-ace4d5ac2d09,DISK], DatanodeInfoWithStorage[127.0.0.1:39849,DS-545c8eb2-11f8-4c68-b182-fa3ec2d03622,DISK], DatanodeInfoWithStorage[127.0.0.1:35650,DS-3e248d53-c0fb-4538-89ea-52e8d1332699,DISK], DatanodeInfoWithStorage[127.0.0.1:33360,DS-937643b8-0f40-4685-9a89-3a360af6902e,DISK], DatanodeInfoWithStorage[127.0.0.1:37872,DS-a5f9b772-40d3-4be0-94b8-3291c59e1bbd,DISK], DatanodeInfoWithStorage[127.0.0.1:41930,DS-5fcb6420-531a-4473-abeb-176611b9773b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-797951454-172.17.0.9-1598442710544:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45376,DS-1659e746-a01c-4b23-af87-13f5404fc887,DISK], DatanodeInfoWithStorage[127.0.0.1:36301,DS-ef5c7bc3-c4d2-4255-8fab-b12c11c72eb6,DISK], DatanodeInfoWithStorage[127.0.0.1:34561,DS-694a29c0-6ac5-4af2-950d-ace4d5ac2d09,DISK], DatanodeInfoWithStorage[127.0.0.1:39849,DS-545c8eb2-11f8-4c68-b182-fa3ec2d03622,DISK], DatanodeInfoWithStorage[127.0.0.1:35650,DS-3e248d53-c0fb-4538-89ea-52e8d1332699,DISK], DatanodeInfoWithStorage[127.0.0.1:33360,DS-937643b8-0f40-4685-9a89-3a360af6902e,DISK], DatanodeInfoWithStorage[127.0.0.1:37872,DS-a5f9b772-40d3-4be0-94b8-3291c59e1bbd,DISK], DatanodeInfoWithStorage[127.0.0.1:41930,DS-5fcb6420-531a-4473-abeb-176611b9773b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.reject-unresolved-dn-topology-mapping
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-554751435-172.17.0.9-1598442754849:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39664,DS-0e7951d3-f413-4534-ae75-449213cdfacc,DISK], DatanodeInfoWithStorage[127.0.0.1:44738,DS-d3de24ad-776d-4313-8616-8f3e1a861fdd,DISK], DatanodeInfoWithStorage[127.0.0.1:36118,DS-5e9f8f78-691d-46b9-ab5b-ea4738328ed4,DISK], DatanodeInfoWithStorage[127.0.0.1:35246,DS-cab5d3c9-9160-4129-ad89-50ddcebf1983,DISK], DatanodeInfoWithStorage[127.0.0.1:38011,DS-b03e39f8-3869-48cb-98bf-17bc3f35c838,DISK], DatanodeInfoWithStorage[127.0.0.1:34896,DS-6e12a236-b6e3-4ab4-8ece-7067be1ce8c7,DISK], DatanodeInfoWithStorage[127.0.0.1:46278,DS-1d674ea7-7b9d-4934-83a7-06a3ecd5c963,DISK], DatanodeInfoWithStorage[127.0.0.1:39427,DS-11755c21-8104-4bb4-8e00-1365bd33dd0f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-554751435-172.17.0.9-1598442754849:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39664,DS-0e7951d3-f413-4534-ae75-449213cdfacc,DISK], DatanodeInfoWithStorage[127.0.0.1:44738,DS-d3de24ad-776d-4313-8616-8f3e1a861fdd,DISK], DatanodeInfoWithStorage[127.0.0.1:36118,DS-5e9f8f78-691d-46b9-ab5b-ea4738328ed4,DISK], DatanodeInfoWithStorage[127.0.0.1:35246,DS-cab5d3c9-9160-4129-ad89-50ddcebf1983,DISK], DatanodeInfoWithStorage[127.0.0.1:38011,DS-b03e39f8-3869-48cb-98bf-17bc3f35c838,DISK], DatanodeInfoWithStorage[127.0.0.1:34896,DS-6e12a236-b6e3-4ab4-8ece-7067be1ce8c7,DISK], DatanodeInfoWithStorage[127.0.0.1:46278,DS-1d674ea7-7b9d-4934-83a7-06a3ecd5c963,DISK], DatanodeInfoWithStorage[127.0.0.1:39427,DS-11755c21-8104-4bb4-8e00-1365bd33dd0f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.reject-unresolved-dn-topology-mapping
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-769502226-172.17.0.9-1598442946977:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45623,DS-b051155e-a4ee-4fa5-8d1a-d5e0ca09a744,DISK], DatanodeInfoWithStorage[127.0.0.1:39168,DS-7261040a-8e5a-4762-a51d-10b028057cdd,DISK], DatanodeInfoWithStorage[127.0.0.1:38770,DS-93075a32-7f3f-49c5-aec8-48fd11541ce7,DISK], DatanodeInfoWithStorage[127.0.0.1:37735,DS-6ad4eec6-8926-40eb-8acb-f65f7b9997f7,DISK], DatanodeInfoWithStorage[127.0.0.1:38143,DS-57924c28-9bd7-482c-9de7-16e1729207b1,DISK], DatanodeInfoWithStorage[127.0.0.1:46218,DS-9f56c56e-f1f9-476c-8d9a-cf37578c27c2,DISK], DatanodeInfoWithStorage[127.0.0.1:37690,DS-53e6c5e5-c31b-46b8-a476-8700070f0f13,DISK], DatanodeInfoWithStorage[127.0.0.1:34290,DS-85edc2f9-4cd1-41d8-9684-68456ac9c2dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-769502226-172.17.0.9-1598442946977:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45623,DS-b051155e-a4ee-4fa5-8d1a-d5e0ca09a744,DISK], DatanodeInfoWithStorage[127.0.0.1:39168,DS-7261040a-8e5a-4762-a51d-10b028057cdd,DISK], DatanodeInfoWithStorage[127.0.0.1:38770,DS-93075a32-7f3f-49c5-aec8-48fd11541ce7,DISK], DatanodeInfoWithStorage[127.0.0.1:37735,DS-6ad4eec6-8926-40eb-8acb-f65f7b9997f7,DISK], DatanodeInfoWithStorage[127.0.0.1:38143,DS-57924c28-9bd7-482c-9de7-16e1729207b1,DISK], DatanodeInfoWithStorage[127.0.0.1:46218,DS-9f56c56e-f1f9-476c-8d9a-cf37578c27c2,DISK], DatanodeInfoWithStorage[127.0.0.1:37690,DS-53e6c5e5-c31b-46b8-a476-8700070f0f13,DISK], DatanodeInfoWithStorage[127.0.0.1:34290,DS-85edc2f9-4cd1-41d8-9684-68456ac9c2dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.reject-unresolved-dn-topology-mapping
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1041071611-172.17.0.9-1598443147960:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41901,DS-070828e5-17d3-41a7-bce9-ab6c05a4dd44,DISK], DatanodeInfoWithStorage[127.0.0.1:36550,DS-3641c4d3-3b2b-4fee-b35c-35fd507986e7,DISK], DatanodeInfoWithStorage[127.0.0.1:42695,DS-7ec32e16-f5d0-4db0-9e7f-3b61d4ae31c3,DISK], DatanodeInfoWithStorage[127.0.0.1:33712,DS-ac6c62ae-c81e-46ff-a068-827bf27ae1f2,DISK], DatanodeInfoWithStorage[127.0.0.1:46560,DS-946c698d-1847-4322-b825-b6cbc0685ad9,DISK], DatanodeInfoWithStorage[127.0.0.1:41792,DS-fc99933d-d403-4a0e-b60b-8c3bc78f4080,DISK], DatanodeInfoWithStorage[127.0.0.1:38100,DS-3d097646-a91e-4deb-9a6f-a429e88ea419,DISK], DatanodeInfoWithStorage[127.0.0.1:39664,DS-f485fcef-4c87-4e68-9b15-89e606d7526d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1041071611-172.17.0.9-1598443147960:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41901,DS-070828e5-17d3-41a7-bce9-ab6c05a4dd44,DISK], DatanodeInfoWithStorage[127.0.0.1:36550,DS-3641c4d3-3b2b-4fee-b35c-35fd507986e7,DISK], DatanodeInfoWithStorage[127.0.0.1:42695,DS-7ec32e16-f5d0-4db0-9e7f-3b61d4ae31c3,DISK], DatanodeInfoWithStorage[127.0.0.1:33712,DS-ac6c62ae-c81e-46ff-a068-827bf27ae1f2,DISK], DatanodeInfoWithStorage[127.0.0.1:46560,DS-946c698d-1847-4322-b825-b6cbc0685ad9,DISK], DatanodeInfoWithStorage[127.0.0.1:41792,DS-fc99933d-d403-4a0e-b60b-8c3bc78f4080,DISK], DatanodeInfoWithStorage[127.0.0.1:38100,DS-3d097646-a91e-4deb-9a6f-a429e88ea419,DISK], DatanodeInfoWithStorage[127.0.0.1:39664,DS-f485fcef-4c87-4e68-9b15-89e606d7526d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.reject-unresolved-dn-topology-mapping
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-700506903-172.17.0.9-1598443257601:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34263,DS-b1979466-0be2-4a08-9ccf-736164088471,DISK], DatanodeInfoWithStorage[127.0.0.1:39064,DS-5f40608a-bd51-4c4e-9fe4-5537bdd6c628,DISK], DatanodeInfoWithStorage[127.0.0.1:42963,DS-a27e2145-1ecc-4518-a461-1798d7b754a1,DISK], DatanodeInfoWithStorage[127.0.0.1:37887,DS-8c362a62-16c6-4770-abf8-d687340fd44c,DISK], DatanodeInfoWithStorage[127.0.0.1:33101,DS-a5da2901-aeb7-46c8-93d5-757294be9935,DISK], DatanodeInfoWithStorage[127.0.0.1:37296,DS-19ac6b07-1995-49d8-97f2-c52537a6024e,DISK], DatanodeInfoWithStorage[127.0.0.1:37715,DS-bde4d93a-a775-42d6-bd80-c5ba838ba826,DISK], DatanodeInfoWithStorage[127.0.0.1:43587,DS-08a859e4-c954-4b61-9ff9-f822df7b110c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-700506903-172.17.0.9-1598443257601:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34263,DS-b1979466-0be2-4a08-9ccf-736164088471,DISK], DatanodeInfoWithStorage[127.0.0.1:39064,DS-5f40608a-bd51-4c4e-9fe4-5537bdd6c628,DISK], DatanodeInfoWithStorage[127.0.0.1:42963,DS-a27e2145-1ecc-4518-a461-1798d7b754a1,DISK], DatanodeInfoWithStorage[127.0.0.1:37887,DS-8c362a62-16c6-4770-abf8-d687340fd44c,DISK], DatanodeInfoWithStorage[127.0.0.1:33101,DS-a5da2901-aeb7-46c8-93d5-757294be9935,DISK], DatanodeInfoWithStorage[127.0.0.1:37296,DS-19ac6b07-1995-49d8-97f2-c52537a6024e,DISK], DatanodeInfoWithStorage[127.0.0.1:37715,DS-bde4d93a-a775-42d6-bd80-c5ba838ba826,DISK], DatanodeInfoWithStorage[127.0.0.1:43587,DS-08a859e4-c954-4b61-9ff9-f822df7b110c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.reject-unresolved-dn-topology-mapping
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1342223862-172.17.0.9-1598443286091:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42866,DS-d98247ef-0754-4151-8825-6449a20ba47d,DISK], DatanodeInfoWithStorage[127.0.0.1:39672,DS-45901eab-df72-41e9-88da-15de0fb52dfb,DISK], DatanodeInfoWithStorage[127.0.0.1:45195,DS-3f8ef052-19dc-41cc-80d1-6a16ac92a3f4,DISK], DatanodeInfoWithStorage[127.0.0.1:41705,DS-2057cb1a-b5ef-41be-9403-f7625ac7aea1,DISK], DatanodeInfoWithStorage[127.0.0.1:34102,DS-4b02047b-4f69-4650-8b7b-402e080147f5,DISK], DatanodeInfoWithStorage[127.0.0.1:43297,DS-0c397f26-a30a-4359-9a4f-6cf5c4d48156,DISK], DatanodeInfoWithStorage[127.0.0.1:38558,DS-62388f61-5b27-4d0c-8c5a-40b735205a50,DISK], DatanodeInfoWithStorage[127.0.0.1:44823,DS-ddda36b9-699c-446c-a431-f19e286fa278,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1342223862-172.17.0.9-1598443286091:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42866,DS-d98247ef-0754-4151-8825-6449a20ba47d,DISK], DatanodeInfoWithStorage[127.0.0.1:39672,DS-45901eab-df72-41e9-88da-15de0fb52dfb,DISK], DatanodeInfoWithStorage[127.0.0.1:45195,DS-3f8ef052-19dc-41cc-80d1-6a16ac92a3f4,DISK], DatanodeInfoWithStorage[127.0.0.1:41705,DS-2057cb1a-b5ef-41be-9403-f7625ac7aea1,DISK], DatanodeInfoWithStorage[127.0.0.1:34102,DS-4b02047b-4f69-4650-8b7b-402e080147f5,DISK], DatanodeInfoWithStorage[127.0.0.1:43297,DS-0c397f26-a30a-4359-9a4f-6cf5c4d48156,DISK], DatanodeInfoWithStorage[127.0.0.1:38558,DS-62388f61-5b27-4d0c-8c5a-40b735205a50,DISK], DatanodeInfoWithStorage[127.0.0.1:44823,DS-ddda36b9-699c-446c-a431-f19e286fa278,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.reject-unresolved-dn-topology-mapping
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1196061121-172.17.0.9-1598443935104:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46050,DS-54137fe5-e322-4b9f-bfa9-41a93ed5ac93,DISK], DatanodeInfoWithStorage[127.0.0.1:36673,DS-37f17627-6cc6-495c-bb3a-ccee3e54034b,DISK], DatanodeInfoWithStorage[127.0.0.1:45103,DS-2930fdcf-3b1d-47ab-8fd0-0b5635f4f6c2,DISK], DatanodeInfoWithStorage[127.0.0.1:38679,DS-d06f6ecc-c28f-4b09-9b9a-0a1174a0c4d1,DISK], DatanodeInfoWithStorage[127.0.0.1:39259,DS-6c16bf56-51f9-4678-ab1e-59f09a39028a,DISK], DatanodeInfoWithStorage[127.0.0.1:46027,DS-cfd1e5fa-5a3f-4aaf-a407-d5d4749cb7e5,DISK], DatanodeInfoWithStorage[127.0.0.1:36178,DS-d9880a5a-29c9-4d9e-919c-64ae660f383f,DISK], DatanodeInfoWithStorage[127.0.0.1:39561,DS-04862cf3-7da5-4622-9a79-7eee2718eb93,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1196061121-172.17.0.9-1598443935104:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46050,DS-54137fe5-e322-4b9f-bfa9-41a93ed5ac93,DISK], DatanodeInfoWithStorage[127.0.0.1:36673,DS-37f17627-6cc6-495c-bb3a-ccee3e54034b,DISK], DatanodeInfoWithStorage[127.0.0.1:45103,DS-2930fdcf-3b1d-47ab-8fd0-0b5635f4f6c2,DISK], DatanodeInfoWithStorage[127.0.0.1:38679,DS-d06f6ecc-c28f-4b09-9b9a-0a1174a0c4d1,DISK], DatanodeInfoWithStorage[127.0.0.1:39259,DS-6c16bf56-51f9-4678-ab1e-59f09a39028a,DISK], DatanodeInfoWithStorage[127.0.0.1:46027,DS-cfd1e5fa-5a3f-4aaf-a407-d5d4749cb7e5,DISK], DatanodeInfoWithStorage[127.0.0.1:36178,DS-d9880a5a-29c9-4d9e-919c-64ae660f383f,DISK], DatanodeInfoWithStorage[127.0.0.1:39561,DS-04862cf3-7da5-4622-9a79-7eee2718eb93,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.reject-unresolved-dn-topology-mapping
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-740572450-172.17.0.9-1598444097177:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35914,DS-ad7fb3ce-8edf-4c40-9fc7-a1daf143b09f,DISK], DatanodeInfoWithStorage[127.0.0.1:32842,DS-943c9e68-ff15-4670-b257-3abd4866d3e8,DISK], DatanodeInfoWithStorage[127.0.0.1:41643,DS-c0159de0-19c3-4932-8ee4-c188f4bbe175,DISK], DatanodeInfoWithStorage[127.0.0.1:40661,DS-80e89530-ddc0-4d22-ac26-9e8d720d250b,DISK], DatanodeInfoWithStorage[127.0.0.1:35751,DS-1eef8f3c-402d-4820-9265-fdd8a829669d,DISK], DatanodeInfoWithStorage[127.0.0.1:40147,DS-58958811-4f78-4c07-b9a6-e5d1cbfbf400,DISK], DatanodeInfoWithStorage[127.0.0.1:37193,DS-2609d932-42b2-4dee-87c4-96667837dc21,DISK], DatanodeInfoWithStorage[127.0.0.1:33800,DS-51ccd9c4-ff08-4012-bb3e-0465c9a3a4db,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-740572450-172.17.0.9-1598444097177:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35914,DS-ad7fb3ce-8edf-4c40-9fc7-a1daf143b09f,DISK], DatanodeInfoWithStorage[127.0.0.1:32842,DS-943c9e68-ff15-4670-b257-3abd4866d3e8,DISK], DatanodeInfoWithStorage[127.0.0.1:41643,DS-c0159de0-19c3-4932-8ee4-c188f4bbe175,DISK], DatanodeInfoWithStorage[127.0.0.1:40661,DS-80e89530-ddc0-4d22-ac26-9e8d720d250b,DISK], DatanodeInfoWithStorage[127.0.0.1:35751,DS-1eef8f3c-402d-4820-9265-fdd8a829669d,DISK], DatanodeInfoWithStorage[127.0.0.1:40147,DS-58958811-4f78-4c07-b9a6-e5d1cbfbf400,DISK], DatanodeInfoWithStorage[127.0.0.1:37193,DS-2609d932-42b2-4dee-87c4-96667837dc21,DISK], DatanodeInfoWithStorage[127.0.0.1:33800,DS-51ccd9c4-ff08-4012-bb3e-0465c9a3a4db,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.reject-unresolved-dn-topology-mapping
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-551417315-172.17.0.9-1598444127401:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44005,DS-c361c1d5-31b9-4d78-9d6a-189fd14f33bc,DISK], DatanodeInfoWithStorage[127.0.0.1:45601,DS-497fde06-d95c-43d2-bc18-912dc6e842c0,DISK], DatanodeInfoWithStorage[127.0.0.1:35839,DS-b4bc846b-27cf-473b-bb3d-4ceea50d5ebc,DISK], DatanodeInfoWithStorage[127.0.0.1:46246,DS-e0550784-d19d-414d-b489-70020677ecd3,DISK], DatanodeInfoWithStorage[127.0.0.1:45268,DS-5ddc9e5b-e6e6-45ab-9b76-2c73e43339a0,DISK], DatanodeInfoWithStorage[127.0.0.1:39553,DS-9f979b9e-9fca-48e9-9458-79a89b519498,DISK], DatanodeInfoWithStorage[127.0.0.1:35273,DS-289ec4e1-7268-4e7a-ada8-dd5294898e7a,DISK], DatanodeInfoWithStorage[127.0.0.1:33096,DS-e5d4e0e1-da88-4aa8-a8d9-13a652c5963e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-551417315-172.17.0.9-1598444127401:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44005,DS-c361c1d5-31b9-4d78-9d6a-189fd14f33bc,DISK], DatanodeInfoWithStorage[127.0.0.1:45601,DS-497fde06-d95c-43d2-bc18-912dc6e842c0,DISK], DatanodeInfoWithStorage[127.0.0.1:35839,DS-b4bc846b-27cf-473b-bb3d-4ceea50d5ebc,DISK], DatanodeInfoWithStorage[127.0.0.1:46246,DS-e0550784-d19d-414d-b489-70020677ecd3,DISK], DatanodeInfoWithStorage[127.0.0.1:45268,DS-5ddc9e5b-e6e6-45ab-9b76-2c73e43339a0,DISK], DatanodeInfoWithStorage[127.0.0.1:39553,DS-9f979b9e-9fca-48e9-9458-79a89b519498,DISK], DatanodeInfoWithStorage[127.0.0.1:35273,DS-289ec4e1-7268-4e7a-ada8-dd5294898e7a,DISK], DatanodeInfoWithStorage[127.0.0.1:33096,DS-e5d4e0e1-da88-4aa8-a8d9-13a652c5963e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.reject-unresolved-dn-topology-mapping
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-339500566-172.17.0.9-1598444223355:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36224,DS-6032a81a-bc03-4c58-945b-73a0dbc5ebc0,DISK], DatanodeInfoWithStorage[127.0.0.1:35340,DS-d21b8c1a-4e98-48df-a13b-e8a6d31d6ae9,DISK], DatanodeInfoWithStorage[127.0.0.1:35668,DS-324acb81-3c3f-4595-a3db-f933875d837f,DISK], DatanodeInfoWithStorage[127.0.0.1:37433,DS-c13a8f62-3d28-4666-a786-8b259b54d6a9,DISK], DatanodeInfoWithStorage[127.0.0.1:38804,DS-129bff50-6b3d-4f3f-a043-aab9f69f4b1a,DISK], DatanodeInfoWithStorage[127.0.0.1:38429,DS-316c905e-b74e-4901-bd5f-d5950ec6f90e,DISK], DatanodeInfoWithStorage[127.0.0.1:41355,DS-968db0e9-4ff0-44c8-a095-9c82ce3cff1e,DISK], DatanodeInfoWithStorage[127.0.0.1:36302,DS-c2f0475e-4313-420e-b3e8-73ee4629592d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-339500566-172.17.0.9-1598444223355:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36224,DS-6032a81a-bc03-4c58-945b-73a0dbc5ebc0,DISK], DatanodeInfoWithStorage[127.0.0.1:35340,DS-d21b8c1a-4e98-48df-a13b-e8a6d31d6ae9,DISK], DatanodeInfoWithStorage[127.0.0.1:35668,DS-324acb81-3c3f-4595-a3db-f933875d837f,DISK], DatanodeInfoWithStorage[127.0.0.1:37433,DS-c13a8f62-3d28-4666-a786-8b259b54d6a9,DISK], DatanodeInfoWithStorage[127.0.0.1:38804,DS-129bff50-6b3d-4f3f-a043-aab9f69f4b1a,DISK], DatanodeInfoWithStorage[127.0.0.1:38429,DS-316c905e-b74e-4901-bd5f-d5950ec6f90e,DISK], DatanodeInfoWithStorage[127.0.0.1:41355,DS-968db0e9-4ff0-44c8-a095-9c82ce3cff1e,DISK], DatanodeInfoWithStorage[127.0.0.1:36302,DS-c2f0475e-4313-420e-b3e8-73ee4629592d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.reject-unresolved-dn-topology-mapping
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-404800417-172.17.0.9-1598444428936:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44993,DS-5e4d07f0-8444-4b1b-b785-7c922aae4af7,DISK], DatanodeInfoWithStorage[127.0.0.1:37347,DS-62472414-a69f-4b19-bc63-9a279c1b8f32,DISK], DatanodeInfoWithStorage[127.0.0.1:38009,DS-3e0de30b-43e5-4113-aa6e-900797301f6c,DISK], DatanodeInfoWithStorage[127.0.0.1:39774,DS-71957466-4cd5-49f6-b5d1-34bea19b541d,DISK], DatanodeInfoWithStorage[127.0.0.1:35874,DS-2435b53d-10c2-441b-9e9e-b2ed0d80d203,DISK], DatanodeInfoWithStorage[127.0.0.1:38270,DS-3f12c2e3-e0ba-42f4-976f-bccf90012ce3,DISK], DatanodeInfoWithStorage[127.0.0.1:38624,DS-c74093c3-ac40-4f87-a25f-ddbbd0610ad5,DISK], DatanodeInfoWithStorage[127.0.0.1:44783,DS-81d072ec-e5b4-4e9e-9faf-464ecbf5317e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-404800417-172.17.0.9-1598444428936:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44993,DS-5e4d07f0-8444-4b1b-b785-7c922aae4af7,DISK], DatanodeInfoWithStorage[127.0.0.1:37347,DS-62472414-a69f-4b19-bc63-9a279c1b8f32,DISK], DatanodeInfoWithStorage[127.0.0.1:38009,DS-3e0de30b-43e5-4113-aa6e-900797301f6c,DISK], DatanodeInfoWithStorage[127.0.0.1:39774,DS-71957466-4cd5-49f6-b5d1-34bea19b541d,DISK], DatanodeInfoWithStorage[127.0.0.1:35874,DS-2435b53d-10c2-441b-9e9e-b2ed0d80d203,DISK], DatanodeInfoWithStorage[127.0.0.1:38270,DS-3f12c2e3-e0ba-42f4-976f-bccf90012ce3,DISK], DatanodeInfoWithStorage[127.0.0.1:38624,DS-c74093c3-ac40-4f87-a25f-ddbbd0610ad5,DISK], DatanodeInfoWithStorage[127.0.0.1:44783,DS-81d072ec-e5b4-4e9e-9faf-464ecbf5317e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.reject-unresolved-dn-topology-mapping
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1297181359-172.17.0.9-1598444833759:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33087,DS-2ddc6b1a-5113-4f60-aaf1-4a032609fe70,DISK], DatanodeInfoWithStorage[127.0.0.1:42213,DS-6f3d3fba-1c44-4fa6-924b-a3632a2df3f9,DISK], DatanodeInfoWithStorage[127.0.0.1:37959,DS-04c2317f-5d70-4e81-a33e-4ae99f2cbceb,DISK], DatanodeInfoWithStorage[127.0.0.1:33423,DS-8f8f9a7b-dabc-41ef-95bf-e969626a0d64,DISK], DatanodeInfoWithStorage[127.0.0.1:42896,DS-1076a0ca-dd14-49bd-a2fb-9a9f9ae5cfce,DISK], DatanodeInfoWithStorage[127.0.0.1:41561,DS-41d5db06-b2a5-4759-9499-a6bf7d02e233,DISK], DatanodeInfoWithStorage[127.0.0.1:38362,DS-e94a40d2-bb0d-45af-8a1f-211b144c1c38,DISK], DatanodeInfoWithStorage[127.0.0.1:36209,DS-c630087c-0d81-49bb-bad3-e6e8f8a75a00,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1297181359-172.17.0.9-1598444833759:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33087,DS-2ddc6b1a-5113-4f60-aaf1-4a032609fe70,DISK], DatanodeInfoWithStorage[127.0.0.1:42213,DS-6f3d3fba-1c44-4fa6-924b-a3632a2df3f9,DISK], DatanodeInfoWithStorage[127.0.0.1:37959,DS-04c2317f-5d70-4e81-a33e-4ae99f2cbceb,DISK], DatanodeInfoWithStorage[127.0.0.1:33423,DS-8f8f9a7b-dabc-41ef-95bf-e969626a0d64,DISK], DatanodeInfoWithStorage[127.0.0.1:42896,DS-1076a0ca-dd14-49bd-a2fb-9a9f9ae5cfce,DISK], DatanodeInfoWithStorage[127.0.0.1:41561,DS-41d5db06-b2a5-4759-9499-a6bf7d02e233,DISK], DatanodeInfoWithStorage[127.0.0.1:38362,DS-e94a40d2-bb0d-45af-8a1f-211b144c1c38,DISK], DatanodeInfoWithStorage[127.0.0.1:36209,DS-c630087c-0d81-49bb-bad3-e6e8f8a75a00,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.reject-unresolved-dn-topology-mapping
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1112879953-172.17.0.9-1598445005782:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40869,DS-1697451f-134d-43bb-b9ce-aa2a79f217d2,DISK], DatanodeInfoWithStorage[127.0.0.1:42326,DS-96ebacb0-719f-4725-9cb0-be5da0ae12e5,DISK], DatanodeInfoWithStorage[127.0.0.1:46282,DS-b68a208e-1341-49f4-870b-c1f6820253d4,DISK], DatanodeInfoWithStorage[127.0.0.1:44581,DS-bb814675-6315-42f7-b547-fea084b0fc8d,DISK], DatanodeInfoWithStorage[127.0.0.1:46570,DS-9702c0a8-8351-4b85-bcc8-38318a62c99d,DISK], DatanodeInfoWithStorage[127.0.0.1:41919,DS-028588c0-6da6-4228-94b7-29d258d3def6,DISK], DatanodeInfoWithStorage[127.0.0.1:36185,DS-1c58d19c-4f5f-49c3-9437-07026d5ffabf,DISK], DatanodeInfoWithStorage[127.0.0.1:39311,DS-7b00805c-067a-48e3-b93e-75ae12689930,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1112879953-172.17.0.9-1598445005782:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40869,DS-1697451f-134d-43bb-b9ce-aa2a79f217d2,DISK], DatanodeInfoWithStorage[127.0.0.1:42326,DS-96ebacb0-719f-4725-9cb0-be5da0ae12e5,DISK], DatanodeInfoWithStorage[127.0.0.1:46282,DS-b68a208e-1341-49f4-870b-c1f6820253d4,DISK], DatanodeInfoWithStorage[127.0.0.1:44581,DS-bb814675-6315-42f7-b547-fea084b0fc8d,DISK], DatanodeInfoWithStorage[127.0.0.1:46570,DS-9702c0a8-8351-4b85-bcc8-38318a62c99d,DISK], DatanodeInfoWithStorage[127.0.0.1:41919,DS-028588c0-6da6-4228-94b7-29d258d3def6,DISK], DatanodeInfoWithStorage[127.0.0.1:36185,DS-1c58d19c-4f5f-49c3-9437-07026d5ffabf,DISK], DatanodeInfoWithStorage[127.0.0.1:39311,DS-7b00805c-067a-48e3-b93e-75ae12689930,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.reject-unresolved-dn-topology-mapping
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1415006525-172.17.0.9-1598445140634:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35043,DS-79e11b4d-0643-4bfd-9055-c214bb387543,DISK], DatanodeInfoWithStorage[127.0.0.1:44278,DS-58bea31a-b2a6-4048-8511-4d3e5b112e78,DISK], DatanodeInfoWithStorage[127.0.0.1:34796,DS-837ad0e2-889f-4073-8934-af89c1e2b665,DISK], DatanodeInfoWithStorage[127.0.0.1:41327,DS-c13e4431-a459-40e0-985e-c0e61e462f3b,DISK], DatanodeInfoWithStorage[127.0.0.1:45065,DS-535a1c6a-a1cf-4b42-86e7-a3cde7809da8,DISK], DatanodeInfoWithStorage[127.0.0.1:40424,DS-ba962041-c6d7-40d4-8e2c-9fee3340a217,DISK], DatanodeInfoWithStorage[127.0.0.1:36748,DS-662fe267-2829-40ef-8f23-cbfe98c594ae,DISK], DatanodeInfoWithStorage[127.0.0.1:40821,DS-90a1de6e-063e-493f-8a17-5735268af33b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1415006525-172.17.0.9-1598445140634:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35043,DS-79e11b4d-0643-4bfd-9055-c214bb387543,DISK], DatanodeInfoWithStorage[127.0.0.1:44278,DS-58bea31a-b2a6-4048-8511-4d3e5b112e78,DISK], DatanodeInfoWithStorage[127.0.0.1:34796,DS-837ad0e2-889f-4073-8934-af89c1e2b665,DISK], DatanodeInfoWithStorage[127.0.0.1:41327,DS-c13e4431-a459-40e0-985e-c0e61e462f3b,DISK], DatanodeInfoWithStorage[127.0.0.1:45065,DS-535a1c6a-a1cf-4b42-86e7-a3cde7809da8,DISK], DatanodeInfoWithStorage[127.0.0.1:40424,DS-ba962041-c6d7-40d4-8e2c-9fee3340a217,DISK], DatanodeInfoWithStorage[127.0.0.1:36748,DS-662fe267-2829-40ef-8f23-cbfe98c594ae,DISK], DatanodeInfoWithStorage[127.0.0.1:40821,DS-90a1de6e-063e-493f-8a17-5735268af33b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.reject-unresolved-dn-topology-mapping
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2088746577-172.17.0.9-1598445912561:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40511,DS-64109a43-b670-4f59-9c58-4360c9f773bf,DISK], DatanodeInfoWithStorage[127.0.0.1:46603,DS-bca2686d-1d56-437c-a726-dfef0af3bdf1,DISK], DatanodeInfoWithStorage[127.0.0.1:35752,DS-d586db0c-316d-465d-b10f-686c38f4af6d,DISK], DatanodeInfoWithStorage[127.0.0.1:36589,DS-64dd88e7-9a37-4ac9-90f0-11bd3f1b7bb7,DISK], DatanodeInfoWithStorage[127.0.0.1:33163,DS-4330d668-2e31-45a4-87ea-dc53473cd10a,DISK], DatanodeInfoWithStorage[127.0.0.1:44502,DS-089cf45b-0426-441a-b579-2480fc3cb97a,DISK], DatanodeInfoWithStorage[127.0.0.1:39050,DS-d70853b3-3bde-4b4f-8fef-92dab89ca4cc,DISK], DatanodeInfoWithStorage[127.0.0.1:45192,DS-6e885f31-452c-4c44-8671-d3523d4e2f67,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2088746577-172.17.0.9-1598445912561:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40511,DS-64109a43-b670-4f59-9c58-4360c9f773bf,DISK], DatanodeInfoWithStorage[127.0.0.1:46603,DS-bca2686d-1d56-437c-a726-dfef0af3bdf1,DISK], DatanodeInfoWithStorage[127.0.0.1:35752,DS-d586db0c-316d-465d-b10f-686c38f4af6d,DISK], DatanodeInfoWithStorage[127.0.0.1:36589,DS-64dd88e7-9a37-4ac9-90f0-11bd3f1b7bb7,DISK], DatanodeInfoWithStorage[127.0.0.1:33163,DS-4330d668-2e31-45a4-87ea-dc53473cd10a,DISK], DatanodeInfoWithStorage[127.0.0.1:44502,DS-089cf45b-0426-441a-b579-2480fc3cb97a,DISK], DatanodeInfoWithStorage[127.0.0.1:39050,DS-d70853b3-3bde-4b4f-8fef-92dab89ca4cc,DISK], DatanodeInfoWithStorage[127.0.0.1:45192,DS-6e885f31-452c-4c44-8671-d3523d4e2f67,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.reject-unresolved-dn-topology-mapping
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1323543717-172.17.0.9-1598446170167:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40738,DS-aded16d3-a966-4048-9834-9fa02b540298,DISK], DatanodeInfoWithStorage[127.0.0.1:38430,DS-1e78cf1b-a404-433a-b3e6-e09e57d160c4,DISK], DatanodeInfoWithStorage[127.0.0.1:46670,DS-42e524c3-42ce-41e6-a86a-f48f207b5e66,DISK], DatanodeInfoWithStorage[127.0.0.1:45923,DS-57c02a93-b308-4b4a-b1cd-0e561d6f7644,DISK], DatanodeInfoWithStorage[127.0.0.1:37815,DS-20e50a1e-00f9-4fec-9a7a-91c36d4f00c7,DISK], DatanodeInfoWithStorage[127.0.0.1:40361,DS-b0cd0239-3071-4ba1-98cf-f94ded5e98d4,DISK], DatanodeInfoWithStorage[127.0.0.1:35446,DS-6e5e2e8a-d420-4f57-8b32-016371342ea4,DISK], DatanodeInfoWithStorage[127.0.0.1:43411,DS-de469d6a-44f1-4c93-baad-8002ce56ea91,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1323543717-172.17.0.9-1598446170167:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40738,DS-aded16d3-a966-4048-9834-9fa02b540298,DISK], DatanodeInfoWithStorage[127.0.0.1:38430,DS-1e78cf1b-a404-433a-b3e6-e09e57d160c4,DISK], DatanodeInfoWithStorage[127.0.0.1:46670,DS-42e524c3-42ce-41e6-a86a-f48f207b5e66,DISK], DatanodeInfoWithStorage[127.0.0.1:45923,DS-57c02a93-b308-4b4a-b1cd-0e561d6f7644,DISK], DatanodeInfoWithStorage[127.0.0.1:37815,DS-20e50a1e-00f9-4fec-9a7a-91c36d4f00c7,DISK], DatanodeInfoWithStorage[127.0.0.1:40361,DS-b0cd0239-3071-4ba1-98cf-f94ded5e98d4,DISK], DatanodeInfoWithStorage[127.0.0.1:35446,DS-6e5e2e8a-d420-4f57-8b32-016371342ea4,DISK], DatanodeInfoWithStorage[127.0.0.1:43411,DS-de469d6a-44f1-4c93-baad-8002ce56ea91,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.reject-unresolved-dn-topology-mapping
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1959553425-172.17.0.9-1598446640661:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33015,DS-81bef711-247c-4977-b51f-56ba97e9eeeb,DISK], DatanodeInfoWithStorage[127.0.0.1:41822,DS-cae77761-3daf-48c4-9514-0b3c30b45757,DISK], DatanodeInfoWithStorage[127.0.0.1:45664,DS-05dbf0a6-dde0-4210-95eb-46b42553f2a3,DISK], DatanodeInfoWithStorage[127.0.0.1:45811,DS-04a6fc23-9da7-4767-ad85-bd81df58aa4d,DISK], DatanodeInfoWithStorage[127.0.0.1:34447,DS-ce2d8c80-b681-45ea-a59d-f4cda181a779,DISK], DatanodeInfoWithStorage[127.0.0.1:46410,DS-7d22abc1-4d7b-4b5c-8c33-c4fec6389911,DISK], DatanodeInfoWithStorage[127.0.0.1:45138,DS-055ccb2e-6732-4df8-9d39-3b760a6006f9,DISK], DatanodeInfoWithStorage[127.0.0.1:33040,DS-a30ef503-b61a-438c-bbb1-49ae166e633f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1959553425-172.17.0.9-1598446640661:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33015,DS-81bef711-247c-4977-b51f-56ba97e9eeeb,DISK], DatanodeInfoWithStorage[127.0.0.1:41822,DS-cae77761-3daf-48c4-9514-0b3c30b45757,DISK], DatanodeInfoWithStorage[127.0.0.1:45664,DS-05dbf0a6-dde0-4210-95eb-46b42553f2a3,DISK], DatanodeInfoWithStorage[127.0.0.1:45811,DS-04a6fc23-9da7-4767-ad85-bd81df58aa4d,DISK], DatanodeInfoWithStorage[127.0.0.1:34447,DS-ce2d8c80-b681-45ea-a59d-f4cda181a779,DISK], DatanodeInfoWithStorage[127.0.0.1:46410,DS-7d22abc1-4d7b-4b5c-8c33-c4fec6389911,DISK], DatanodeInfoWithStorage[127.0.0.1:45138,DS-055ccb2e-6732-4df8-9d39-3b760a6006f9,DISK], DatanodeInfoWithStorage[127.0.0.1:33040,DS-a30ef503-b61a-438c-bbb1-49ae166e633f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 11 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: might be true error
Total execution time in seconds : 5183
