reconf_parameter: dfs.namenode.redundancy.considerLoad
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.considerLoad
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-46346811-172.17.0.18-1598134687064:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46018,DS-02259e94-8d47-4cdc-93bc-c14103193787,DISK], DatanodeInfoWithStorage[127.0.0.1:34980,DS-88b29acd-e368-4859-91a5-f3bdca8d064d,DISK], DatanodeInfoWithStorage[127.0.0.1:37053,DS-1c3ef4bf-a848-452a-9d4e-323d7b871e33,DISK], DatanodeInfoWithStorage[127.0.0.1:36287,DS-18ac469c-e794-49a8-aa1f-17bcfa6eb087,DISK], DatanodeInfoWithStorage[127.0.0.1:35653,DS-423f3cd3-1e30-4615-b06b-3571fcb263e3,DISK], DatanodeInfoWithStorage[127.0.0.1:37664,DS-2e9b9dce-7069-4e62-abd6-b58a0a9757a8,DISK], DatanodeInfoWithStorage[127.0.0.1:41093,DS-5c39dd02-1b4e-4f78-ae25-f3cadb14e71b,DISK], DatanodeInfoWithStorage[127.0.0.1:39598,DS-ee832e6f-e0b0-4561-9a69-afc927bbc673,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-46346811-172.17.0.18-1598134687064:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46018,DS-02259e94-8d47-4cdc-93bc-c14103193787,DISK], DatanodeInfoWithStorage[127.0.0.1:34980,DS-88b29acd-e368-4859-91a5-f3bdca8d064d,DISK], DatanodeInfoWithStorage[127.0.0.1:37053,DS-1c3ef4bf-a848-452a-9d4e-323d7b871e33,DISK], DatanodeInfoWithStorage[127.0.0.1:36287,DS-18ac469c-e794-49a8-aa1f-17bcfa6eb087,DISK], DatanodeInfoWithStorage[127.0.0.1:35653,DS-423f3cd3-1e30-4615-b06b-3571fcb263e3,DISK], DatanodeInfoWithStorage[127.0.0.1:37664,DS-2e9b9dce-7069-4e62-abd6-b58a0a9757a8,DISK], DatanodeInfoWithStorage[127.0.0.1:41093,DS-5c39dd02-1b4e-4f78-ae25-f3cadb14e71b,DISK], DatanodeInfoWithStorage[127.0.0.1:39598,DS-ee832e6f-e0b0-4561-9a69-afc927bbc673,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.considerLoad
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1146272371-172.17.0.18-1598134790178:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41471,DS-ed145ba2-af43-4db3-b64e-f6f5bacfb7cd,DISK], DatanodeInfoWithStorage[127.0.0.1:43832,DS-cab740c7-49a8-4e78-a7bf-a8c2aec2d541,DISK], DatanodeInfoWithStorage[127.0.0.1:41459,DS-6412a31b-3adc-4392-8547-a052af34141f,DISK], DatanodeInfoWithStorage[127.0.0.1:39407,DS-9644471e-6470-4132-a224-68b51f1afa03,DISK], DatanodeInfoWithStorage[127.0.0.1:33240,DS-c5d977a9-b593-4e54-839b-daa8a3836b3a,DISK], DatanodeInfoWithStorage[127.0.0.1:36106,DS-98ea8ace-849c-4fc0-a291-ad5de2ae8111,DISK], DatanodeInfoWithStorage[127.0.0.1:43242,DS-c6d353f3-5131-43fd-91a4-30dc31db286f,DISK], DatanodeInfoWithStorage[127.0.0.1:37298,DS-54e54363-5bc6-4756-9bce-61a4e2f8e48e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1146272371-172.17.0.18-1598134790178:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41471,DS-ed145ba2-af43-4db3-b64e-f6f5bacfb7cd,DISK], DatanodeInfoWithStorage[127.0.0.1:43832,DS-cab740c7-49a8-4e78-a7bf-a8c2aec2d541,DISK], DatanodeInfoWithStorage[127.0.0.1:41459,DS-6412a31b-3adc-4392-8547-a052af34141f,DISK], DatanodeInfoWithStorage[127.0.0.1:39407,DS-9644471e-6470-4132-a224-68b51f1afa03,DISK], DatanodeInfoWithStorage[127.0.0.1:33240,DS-c5d977a9-b593-4e54-839b-daa8a3836b3a,DISK], DatanodeInfoWithStorage[127.0.0.1:36106,DS-98ea8ace-849c-4fc0-a291-ad5de2ae8111,DISK], DatanodeInfoWithStorage[127.0.0.1:43242,DS-c6d353f3-5131-43fd-91a4-30dc31db286f,DISK], DatanodeInfoWithStorage[127.0.0.1:37298,DS-54e54363-5bc6-4756-9bce-61a4e2f8e48e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.considerLoad
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1424274731-172.17.0.18-1598135010782:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33717,DS-8c667422-2987-4807-84fe-41882d4d6ce4,DISK], DatanodeInfoWithStorage[127.0.0.1:34040,DS-f16ec8ec-6803-4c99-a309-160311c4575f,DISK], DatanodeInfoWithStorage[127.0.0.1:38668,DS-643496c6-e2bc-42de-8aa0-79a78696a86f,DISK], DatanodeInfoWithStorage[127.0.0.1:45178,DS-c9f34abb-95d0-4fa7-9aa0-554b8a569cf6,DISK], DatanodeInfoWithStorage[127.0.0.1:43977,DS-5534df34-7a07-49b8-9ccb-79e2838aa195,DISK], DatanodeInfoWithStorage[127.0.0.1:34703,DS-ddbaa207-23aa-4a96-93d9-74a0e1335225,DISK], DatanodeInfoWithStorage[127.0.0.1:34220,DS-9eaa9945-c99e-49c8-a84b-d62d60a2d863,DISK], DatanodeInfoWithStorage[127.0.0.1:36248,DS-0a0a4881-b9bf-4e2f-8b33-a52e59b3f054,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1424274731-172.17.0.18-1598135010782:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33717,DS-8c667422-2987-4807-84fe-41882d4d6ce4,DISK], DatanodeInfoWithStorage[127.0.0.1:34040,DS-f16ec8ec-6803-4c99-a309-160311c4575f,DISK], DatanodeInfoWithStorage[127.0.0.1:38668,DS-643496c6-e2bc-42de-8aa0-79a78696a86f,DISK], DatanodeInfoWithStorage[127.0.0.1:45178,DS-c9f34abb-95d0-4fa7-9aa0-554b8a569cf6,DISK], DatanodeInfoWithStorage[127.0.0.1:43977,DS-5534df34-7a07-49b8-9ccb-79e2838aa195,DISK], DatanodeInfoWithStorage[127.0.0.1:34703,DS-ddbaa207-23aa-4a96-93d9-74a0e1335225,DISK], DatanodeInfoWithStorage[127.0.0.1:34220,DS-9eaa9945-c99e-49c8-a84b-d62d60a2d863,DISK], DatanodeInfoWithStorage[127.0.0.1:36248,DS-0a0a4881-b9bf-4e2f-8b33-a52e59b3f054,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.considerLoad
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-191296133-172.17.0.18-1598135201753:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43389,DS-a0d96232-d32f-49a2-8b9e-c12e077cb748,DISK], DatanodeInfoWithStorage[127.0.0.1:34850,DS-8425d803-b30a-43f9-8833-74684ef65eef,DISK], DatanodeInfoWithStorage[127.0.0.1:39395,DS-cf2deabf-478b-471d-a110-44846b51d71b,DISK], DatanodeInfoWithStorage[127.0.0.1:42243,DS-8c5f5782-9f9a-493c-8613-a22a033afe72,DISK], DatanodeInfoWithStorage[127.0.0.1:35967,DS-ac264a4e-6363-41e8-a501-606fe850faa2,DISK], DatanodeInfoWithStorage[127.0.0.1:33337,DS-2c5e463a-94af-4697-91ca-e1b1c953152a,DISK], DatanodeInfoWithStorage[127.0.0.1:43779,DS-f84e071d-9fc5-4527-807a-252cb32f9329,DISK], DatanodeInfoWithStorage[127.0.0.1:33134,DS-356f55ca-1e3d-477d-a44d-e32f82b07b0a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-191296133-172.17.0.18-1598135201753:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43389,DS-a0d96232-d32f-49a2-8b9e-c12e077cb748,DISK], DatanodeInfoWithStorage[127.0.0.1:34850,DS-8425d803-b30a-43f9-8833-74684ef65eef,DISK], DatanodeInfoWithStorage[127.0.0.1:39395,DS-cf2deabf-478b-471d-a110-44846b51d71b,DISK], DatanodeInfoWithStorage[127.0.0.1:42243,DS-8c5f5782-9f9a-493c-8613-a22a033afe72,DISK], DatanodeInfoWithStorage[127.0.0.1:35967,DS-ac264a4e-6363-41e8-a501-606fe850faa2,DISK], DatanodeInfoWithStorage[127.0.0.1:33337,DS-2c5e463a-94af-4697-91ca-e1b1c953152a,DISK], DatanodeInfoWithStorage[127.0.0.1:43779,DS-f84e071d-9fc5-4527-807a-252cb32f9329,DISK], DatanodeInfoWithStorage[127.0.0.1:33134,DS-356f55ca-1e3d-477d-a44d-e32f82b07b0a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.considerLoad
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-253524396-172.17.0.18-1598135677413:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36059,DS-6698c303-836c-47d0-b4ec-6064706014d3,DISK], DatanodeInfoWithStorage[127.0.0.1:34426,DS-7408870a-fcee-41c5-8326-2f320243aa11,DISK], DatanodeInfoWithStorage[127.0.0.1:33368,DS-6f2d8749-49ea-4b8b-bc75-79e1c4a679a7,DISK], DatanodeInfoWithStorage[127.0.0.1:45011,DS-013ab44a-ec64-4827-9581-e03194a7d21b,DISK], DatanodeInfoWithStorage[127.0.0.1:42449,DS-9580331e-bae5-44d5-8a7b-2c964fac2370,DISK], DatanodeInfoWithStorage[127.0.0.1:45569,DS-93363090-f4c1-4a41-b866-c7b71e022945,DISK], DatanodeInfoWithStorage[127.0.0.1:36434,DS-7eb66bba-9f0f-4985-9e3e-401dc0458020,DISK], DatanodeInfoWithStorage[127.0.0.1:43238,DS-66038190-43aa-44ba-85d1-13cc49a93145,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-253524396-172.17.0.18-1598135677413:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36059,DS-6698c303-836c-47d0-b4ec-6064706014d3,DISK], DatanodeInfoWithStorage[127.0.0.1:34426,DS-7408870a-fcee-41c5-8326-2f320243aa11,DISK], DatanodeInfoWithStorage[127.0.0.1:33368,DS-6f2d8749-49ea-4b8b-bc75-79e1c4a679a7,DISK], DatanodeInfoWithStorage[127.0.0.1:45011,DS-013ab44a-ec64-4827-9581-e03194a7d21b,DISK], DatanodeInfoWithStorage[127.0.0.1:42449,DS-9580331e-bae5-44d5-8a7b-2c964fac2370,DISK], DatanodeInfoWithStorage[127.0.0.1:45569,DS-93363090-f4c1-4a41-b866-c7b71e022945,DISK], DatanodeInfoWithStorage[127.0.0.1:36434,DS-7eb66bba-9f0f-4985-9e3e-401dc0458020,DISK], DatanodeInfoWithStorage[127.0.0.1:43238,DS-66038190-43aa-44ba-85d1-13cc49a93145,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.considerLoad
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-818175358-172.17.0.18-1598136099433:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43555,DS-d3d9466a-686c-4e71-8751-bd0deea4744b,DISK], DatanodeInfoWithStorage[127.0.0.1:44047,DS-9cb16575-c8a1-4c19-be7e-2f7cd01da0c0,DISK], DatanodeInfoWithStorage[127.0.0.1:38505,DS-7a403608-ff5a-411a-8d42-1a03aee456b3,DISK], DatanodeInfoWithStorage[127.0.0.1:39754,DS-92692e2d-5bd1-4ea0-b0a5-368306412ec8,DISK], DatanodeInfoWithStorage[127.0.0.1:44888,DS-f575ceb8-d0a7-4650-8d81-19f266b9ce29,DISK], DatanodeInfoWithStorage[127.0.0.1:44784,DS-ed609223-de74-482d-86da-efef09df60fd,DISK], DatanodeInfoWithStorage[127.0.0.1:35698,DS-6db5865b-3438-4985-896d-2be0b10d4ca5,DISK], DatanodeInfoWithStorage[127.0.0.1:43198,DS-5cab811b-164a-45c8-bb34-f40444374efc,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-818175358-172.17.0.18-1598136099433:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43555,DS-d3d9466a-686c-4e71-8751-bd0deea4744b,DISK], DatanodeInfoWithStorage[127.0.0.1:44047,DS-9cb16575-c8a1-4c19-be7e-2f7cd01da0c0,DISK], DatanodeInfoWithStorage[127.0.0.1:38505,DS-7a403608-ff5a-411a-8d42-1a03aee456b3,DISK], DatanodeInfoWithStorage[127.0.0.1:39754,DS-92692e2d-5bd1-4ea0-b0a5-368306412ec8,DISK], DatanodeInfoWithStorage[127.0.0.1:44888,DS-f575ceb8-d0a7-4650-8d81-19f266b9ce29,DISK], DatanodeInfoWithStorage[127.0.0.1:44784,DS-ed609223-de74-482d-86da-efef09df60fd,DISK], DatanodeInfoWithStorage[127.0.0.1:35698,DS-6db5865b-3438-4985-896d-2be0b10d4ca5,DISK], DatanodeInfoWithStorage[127.0.0.1:43198,DS-5cab811b-164a-45c8-bb34-f40444374efc,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.considerLoad
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-243630661-172.17.0.18-1598136211342:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39899,DS-f93f333b-9bdd-4c14-9e24-9611087c209a,DISK], DatanodeInfoWithStorage[127.0.0.1:39809,DS-5a6a689f-1b65-4949-aec4-95148091d0e2,DISK], DatanodeInfoWithStorage[127.0.0.1:39307,DS-1ac51f52-eb64-440b-aaa7-5d1afbd42176,DISK], DatanodeInfoWithStorage[127.0.0.1:37849,DS-b757a295-8ab0-4650-b082-ca27b4f48c2d,DISK], DatanodeInfoWithStorage[127.0.0.1:45081,DS-d5a7530b-4fac-4dd8-acda-d7ffb6b7b611,DISK], DatanodeInfoWithStorage[127.0.0.1:44444,DS-58f12639-1582-4465-a226-2e9db146bead,DISK], DatanodeInfoWithStorage[127.0.0.1:42585,DS-b56af542-9167-4de1-977f-e133cf129ac0,DISK], DatanodeInfoWithStorage[127.0.0.1:37543,DS-5e6b92df-62ab-4511-97dd-4b2b51a1fe31,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-243630661-172.17.0.18-1598136211342:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39899,DS-f93f333b-9bdd-4c14-9e24-9611087c209a,DISK], DatanodeInfoWithStorage[127.0.0.1:39809,DS-5a6a689f-1b65-4949-aec4-95148091d0e2,DISK], DatanodeInfoWithStorage[127.0.0.1:39307,DS-1ac51f52-eb64-440b-aaa7-5d1afbd42176,DISK], DatanodeInfoWithStorage[127.0.0.1:37849,DS-b757a295-8ab0-4650-b082-ca27b4f48c2d,DISK], DatanodeInfoWithStorage[127.0.0.1:45081,DS-d5a7530b-4fac-4dd8-acda-d7ffb6b7b611,DISK], DatanodeInfoWithStorage[127.0.0.1:44444,DS-58f12639-1582-4465-a226-2e9db146bead,DISK], DatanodeInfoWithStorage[127.0.0.1:42585,DS-b56af542-9167-4de1-977f-e133cf129ac0,DISK], DatanodeInfoWithStorage[127.0.0.1:37543,DS-5e6b92df-62ab-4511-97dd-4b2b51a1fe31,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.considerLoad
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1037523877-172.17.0.18-1598136276300:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37082,DS-a976809d-871d-43ea-847c-722675f20cc8,DISK], DatanodeInfoWithStorage[127.0.0.1:33024,DS-94a43ec6-40c1-403a-ab58-6fc5ff006503,DISK], DatanodeInfoWithStorage[127.0.0.1:42731,DS-3a2c6c90-4988-40d4-bca2-b0bc851363bc,DISK], DatanodeInfoWithStorage[127.0.0.1:45880,DS-6ef85c70-d223-4edf-8571-3dac65a4cba8,DISK], DatanodeInfoWithStorage[127.0.0.1:43338,DS-bf9e0374-cc31-4ac8-9be0-31157f7188ac,DISK], DatanodeInfoWithStorage[127.0.0.1:34195,DS-21b87b58-816d-466d-9d17-460a7f8099ae,DISK], DatanodeInfoWithStorage[127.0.0.1:43470,DS-81ab44ff-a72b-447b-86eb-d80ef8698111,DISK], DatanodeInfoWithStorage[127.0.0.1:45951,DS-cca9cd8d-a8ef-4edb-b6dd-d286e11cb6f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1037523877-172.17.0.18-1598136276300:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37082,DS-a976809d-871d-43ea-847c-722675f20cc8,DISK], DatanodeInfoWithStorage[127.0.0.1:33024,DS-94a43ec6-40c1-403a-ab58-6fc5ff006503,DISK], DatanodeInfoWithStorage[127.0.0.1:42731,DS-3a2c6c90-4988-40d4-bca2-b0bc851363bc,DISK], DatanodeInfoWithStorage[127.0.0.1:45880,DS-6ef85c70-d223-4edf-8571-3dac65a4cba8,DISK], DatanodeInfoWithStorage[127.0.0.1:43338,DS-bf9e0374-cc31-4ac8-9be0-31157f7188ac,DISK], DatanodeInfoWithStorage[127.0.0.1:34195,DS-21b87b58-816d-466d-9d17-460a7f8099ae,DISK], DatanodeInfoWithStorage[127.0.0.1:43470,DS-81ab44ff-a72b-447b-86eb-d80ef8698111,DISK], DatanodeInfoWithStorage[127.0.0.1:45951,DS-cca9cd8d-a8ef-4edb-b6dd-d286e11cb6f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.considerLoad
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-359556937-172.17.0.18-1598136387033:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33937,DS-dbdcb4a5-870e-4f00-a913-2a22b04eabfb,DISK], DatanodeInfoWithStorage[127.0.0.1:33184,DS-8c030a7b-4e94-4991-b910-69b7d7c20e93,DISK], DatanodeInfoWithStorage[127.0.0.1:40369,DS-8995e3a2-eac2-41a7-8463-82c16a0d6f8f,DISK], DatanodeInfoWithStorage[127.0.0.1:34168,DS-8317f89e-5fec-427b-9195-a55ef4d601f3,DISK], DatanodeInfoWithStorage[127.0.0.1:42194,DS-676a1322-8c88-4658-ae73-98111016ef9b,DISK], DatanodeInfoWithStorage[127.0.0.1:33904,DS-b4bc05fb-a352-44da-81d1-b5399e47ab6e,DISK], DatanodeInfoWithStorage[127.0.0.1:44502,DS-793bbd7e-72ef-4cf1-8d36-830e6caabdef,DISK], DatanodeInfoWithStorage[127.0.0.1:34733,DS-e9488de8-d070-408c-86ea-54767eb346c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-359556937-172.17.0.18-1598136387033:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33937,DS-dbdcb4a5-870e-4f00-a913-2a22b04eabfb,DISK], DatanodeInfoWithStorage[127.0.0.1:33184,DS-8c030a7b-4e94-4991-b910-69b7d7c20e93,DISK], DatanodeInfoWithStorage[127.0.0.1:40369,DS-8995e3a2-eac2-41a7-8463-82c16a0d6f8f,DISK], DatanodeInfoWithStorage[127.0.0.1:34168,DS-8317f89e-5fec-427b-9195-a55ef4d601f3,DISK], DatanodeInfoWithStorage[127.0.0.1:42194,DS-676a1322-8c88-4658-ae73-98111016ef9b,DISK], DatanodeInfoWithStorage[127.0.0.1:33904,DS-b4bc05fb-a352-44da-81d1-b5399e47ab6e,DISK], DatanodeInfoWithStorage[127.0.0.1:44502,DS-793bbd7e-72ef-4cf1-8d36-830e6caabdef,DISK], DatanodeInfoWithStorage[127.0.0.1:34733,DS-e9488de8-d070-408c-86ea-54767eb346c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.redundancy.considerLoad
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1223089692-172.17.0.18-1598136418565:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39833,DS-c15a3fe6-0a1f-46a6-9431-2fdb6c46cc06,DISK], DatanodeInfoWithStorage[127.0.0.1:45428,DS-6ffddf89-b1cc-4a15-ac7c-9bc7b3ff0d47,DISK], DatanodeInfoWithStorage[127.0.0.1:35236,DS-c6b7f313-1163-4dda-9164-af126199f7ac,DISK], DatanodeInfoWithStorage[127.0.0.1:39983,DS-7fbd7648-37e9-4fd9-ab94-d6f32be59298,DISK], DatanodeInfoWithStorage[127.0.0.1:34032,DS-c6dfa7a7-0186-4bb3-abeb-ce2c96114ab0,DISK], DatanodeInfoWithStorage[127.0.0.1:36571,DS-843ecf2d-ceed-4b74-a555-961c2b510607,DISK], DatanodeInfoWithStorage[127.0.0.1:40857,DS-99b8f524-30e7-4ed0-aa44-4540b313038e,DISK], DatanodeInfoWithStorage[127.0.0.1:43732,DS-0b154ec7-4062-4c1b-ac37-55979558674d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1223089692-172.17.0.18-1598136418565:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39833,DS-c15a3fe6-0a1f-46a6-9431-2fdb6c46cc06,DISK], DatanodeInfoWithStorage[127.0.0.1:45428,DS-6ffddf89-b1cc-4a15-ac7c-9bc7b3ff0d47,DISK], DatanodeInfoWithStorage[127.0.0.1:35236,DS-c6b7f313-1163-4dda-9164-af126199f7ac,DISK], DatanodeInfoWithStorage[127.0.0.1:39983,DS-7fbd7648-37e9-4fd9-ab94-d6f32be59298,DISK], DatanodeInfoWithStorage[127.0.0.1:34032,DS-c6dfa7a7-0186-4bb3-abeb-ce2c96114ab0,DISK], DatanodeInfoWithStorage[127.0.0.1:36571,DS-843ecf2d-ceed-4b74-a555-961c2b510607,DISK], DatanodeInfoWithStorage[127.0.0.1:40857,DS-99b8f524-30e7-4ed0-aa44-4540b313038e,DISK], DatanodeInfoWithStorage[127.0.0.1:43732,DS-0b154ec7-4062-4c1b-ac37-55979558674d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.considerLoad
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-22000665-172.17.0.18-1598136643425:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37180,DS-3ac55061-8367-44ff-b040-76f113731ae0,DISK], DatanodeInfoWithStorage[127.0.0.1:34602,DS-e69a5c41-d294-4c34-ada2-6ebb1edd0139,DISK], DatanodeInfoWithStorage[127.0.0.1:40957,DS-5ac88286-b323-4039-ae49-12a3d952d5a3,DISK], DatanodeInfoWithStorage[127.0.0.1:42974,DS-6fe80fd2-beb9-415d-bc4c-1b69a9f54fbe,DISK], DatanodeInfoWithStorage[127.0.0.1:40756,DS-d518a436-bc7e-4678-9499-f6dc5a1e979b,DISK], DatanodeInfoWithStorage[127.0.0.1:36728,DS-f2c09ec8-735f-4f98-8b45-ecf2400cf57b,DISK], DatanodeInfoWithStorage[127.0.0.1:34751,DS-f65b59de-4ae8-4ed3-902b-c0fc2a48a1eb,DISK], DatanodeInfoWithStorage[127.0.0.1:37053,DS-275a6a39-c31c-43b8-a6de-0c43faeeedd8,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-22000665-172.17.0.18-1598136643425:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37180,DS-3ac55061-8367-44ff-b040-76f113731ae0,DISK], DatanodeInfoWithStorage[127.0.0.1:34602,DS-e69a5c41-d294-4c34-ada2-6ebb1edd0139,DISK], DatanodeInfoWithStorage[127.0.0.1:40957,DS-5ac88286-b323-4039-ae49-12a3d952d5a3,DISK], DatanodeInfoWithStorage[127.0.0.1:42974,DS-6fe80fd2-beb9-415d-bc4c-1b69a9f54fbe,DISK], DatanodeInfoWithStorage[127.0.0.1:40756,DS-d518a436-bc7e-4678-9499-f6dc5a1e979b,DISK], DatanodeInfoWithStorage[127.0.0.1:36728,DS-f2c09ec8-735f-4f98-8b45-ecf2400cf57b,DISK], DatanodeInfoWithStorage[127.0.0.1:34751,DS-f65b59de-4ae8-4ed3-902b-c0fc2a48a1eb,DISK], DatanodeInfoWithStorage[127.0.0.1:37053,DS-275a6a39-c31c-43b8-a6de-0c43faeeedd8,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.considerLoad
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1302633409-172.17.0.18-1598136746967:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41974,DS-9e33a7bf-de51-447e-a801-c76bcd045fc6,DISK], DatanodeInfoWithStorage[127.0.0.1:45502,DS-e8ab4096-977b-4e89-8de0-ab52c7040b94,DISK], DatanodeInfoWithStorage[127.0.0.1:46555,DS-fb7f6dc5-c49d-41fc-86ec-0ba3dcaa50a2,DISK], DatanodeInfoWithStorage[127.0.0.1:40123,DS-6fc96149-3e03-4c76-91c1-f32f8c1846a7,DISK], DatanodeInfoWithStorage[127.0.0.1:41127,DS-9ed784c1-30a5-42f8-8046-7bec5a711a5a,DISK], DatanodeInfoWithStorage[127.0.0.1:37887,DS-456033ad-67d5-4c57-a695-a525d9c25090,DISK], DatanodeInfoWithStorage[127.0.0.1:32926,DS-6b6f616d-2c58-4119-8498-ba2b35a42832,DISK], DatanodeInfoWithStorage[127.0.0.1:35223,DS-0f1a337a-69a6-4973-b93e-f2d9aad4fe23,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1302633409-172.17.0.18-1598136746967:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41974,DS-9e33a7bf-de51-447e-a801-c76bcd045fc6,DISK], DatanodeInfoWithStorage[127.0.0.1:45502,DS-e8ab4096-977b-4e89-8de0-ab52c7040b94,DISK], DatanodeInfoWithStorage[127.0.0.1:46555,DS-fb7f6dc5-c49d-41fc-86ec-0ba3dcaa50a2,DISK], DatanodeInfoWithStorage[127.0.0.1:40123,DS-6fc96149-3e03-4c76-91c1-f32f8c1846a7,DISK], DatanodeInfoWithStorage[127.0.0.1:41127,DS-9ed784c1-30a5-42f8-8046-7bec5a711a5a,DISK], DatanodeInfoWithStorage[127.0.0.1:37887,DS-456033ad-67d5-4c57-a695-a525d9c25090,DISK], DatanodeInfoWithStorage[127.0.0.1:32926,DS-6b6f616d-2c58-4119-8498-ba2b35a42832,DISK], DatanodeInfoWithStorage[127.0.0.1:35223,DS-0f1a337a-69a6-4973-b93e-f2d9aad4fe23,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.considerLoad
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1781613532-172.17.0.18-1598137085254:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40416,DS-57974ad7-28b9-4128-9e8c-7fa8edff9175,DISK], DatanodeInfoWithStorage[127.0.0.1:41016,DS-6f731cde-20a8-4b9d-bb58-be779ce70717,DISK], DatanodeInfoWithStorage[127.0.0.1:42485,DS-708604b0-101c-48b9-bee4-57b8c916705b,DISK], DatanodeInfoWithStorage[127.0.0.1:45155,DS-501cc905-254c-455d-9a8d-c6052c55583b,DISK], DatanodeInfoWithStorage[127.0.0.1:39225,DS-7e174de7-c52a-4e5c-84fc-8635bd5494d6,DISK], DatanodeInfoWithStorage[127.0.0.1:45581,DS-dbd2e8af-9936-4824-aba4-279adce1200e,DISK], DatanodeInfoWithStorage[127.0.0.1:38880,DS-9f97ea3b-131c-4161-8854-87b202ba7942,DISK], DatanodeInfoWithStorage[127.0.0.1:43968,DS-68938098-cc65-494b-8c2b-6d81df0aa7b3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1781613532-172.17.0.18-1598137085254:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40416,DS-57974ad7-28b9-4128-9e8c-7fa8edff9175,DISK], DatanodeInfoWithStorage[127.0.0.1:41016,DS-6f731cde-20a8-4b9d-bb58-be779ce70717,DISK], DatanodeInfoWithStorage[127.0.0.1:42485,DS-708604b0-101c-48b9-bee4-57b8c916705b,DISK], DatanodeInfoWithStorage[127.0.0.1:45155,DS-501cc905-254c-455d-9a8d-c6052c55583b,DISK], DatanodeInfoWithStorage[127.0.0.1:39225,DS-7e174de7-c52a-4e5c-84fc-8635bd5494d6,DISK], DatanodeInfoWithStorage[127.0.0.1:45581,DS-dbd2e8af-9936-4824-aba4-279adce1200e,DISK], DatanodeInfoWithStorage[127.0.0.1:38880,DS-9f97ea3b-131c-4161-8854-87b202ba7942,DISK], DatanodeInfoWithStorage[127.0.0.1:43968,DS-68938098-cc65-494b-8c2b-6d81df0aa7b3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.considerLoad
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-252586018-172.17.0.18-1598137126576:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45458,DS-e6d1cabd-f079-4540-8e5e-e392809fba6f,DISK], DatanodeInfoWithStorage[127.0.0.1:36530,DS-3b7a8999-a2f6-4920-b126-62ef9a2cbab1,DISK], DatanodeInfoWithStorage[127.0.0.1:39751,DS-c5d970fe-1512-499d-911a-2037ac9ac220,DISK], DatanodeInfoWithStorage[127.0.0.1:38668,DS-bdf3f632-028d-41c4-8598-783ebd2cb8ba,DISK], DatanodeInfoWithStorage[127.0.0.1:36437,DS-42725512-4675-40e0-bb3a-881b1c8d4c67,DISK], DatanodeInfoWithStorage[127.0.0.1:40733,DS-a14c0231-a230-47e2-acd3-f2c70c0b3af3,DISK], DatanodeInfoWithStorage[127.0.0.1:42447,DS-189f6732-e904-4d0b-8f10-309d8635d06b,DISK], DatanodeInfoWithStorage[127.0.0.1:42245,DS-04c91363-19de-4ca2-8d7a-1e3d35be5bae,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-252586018-172.17.0.18-1598137126576:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45458,DS-e6d1cabd-f079-4540-8e5e-e392809fba6f,DISK], DatanodeInfoWithStorage[127.0.0.1:36530,DS-3b7a8999-a2f6-4920-b126-62ef9a2cbab1,DISK], DatanodeInfoWithStorage[127.0.0.1:39751,DS-c5d970fe-1512-499d-911a-2037ac9ac220,DISK], DatanodeInfoWithStorage[127.0.0.1:38668,DS-bdf3f632-028d-41c4-8598-783ebd2cb8ba,DISK], DatanodeInfoWithStorage[127.0.0.1:36437,DS-42725512-4675-40e0-bb3a-881b1c8d4c67,DISK], DatanodeInfoWithStorage[127.0.0.1:40733,DS-a14c0231-a230-47e2-acd3-f2c70c0b3af3,DISK], DatanodeInfoWithStorage[127.0.0.1:42447,DS-189f6732-e904-4d0b-8f10-309d8635d06b,DISK], DatanodeInfoWithStorage[127.0.0.1:42245,DS-04c91363-19de-4ca2-8d7a-1e3d35be5bae,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.considerLoad
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-188880630-172.17.0.18-1598137163437:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37406,DS-8701f0a8-0ecd-45b0-bcc5-1fb774af8dab,DISK], DatanodeInfoWithStorage[127.0.0.1:37605,DS-e84353a7-fb65-4222-acdd-ee1ebe71ba96,DISK], DatanodeInfoWithStorage[127.0.0.1:37463,DS-c883cffc-04dc-484d-bca9-5b6d199d0793,DISK], DatanodeInfoWithStorage[127.0.0.1:37599,DS-5527a127-71e4-4ac8-bf2e-b9f3e405006e,DISK], DatanodeInfoWithStorage[127.0.0.1:43349,DS-af3dc7d8-885a-4569-918e-f5625f8027bc,DISK], DatanodeInfoWithStorage[127.0.0.1:34372,DS-46ab94e7-74df-42f3-a8b2-4a6ff7f28af1,DISK], DatanodeInfoWithStorage[127.0.0.1:43843,DS-f8b34e57-5fa4-40c4-8167-0f81e0227f03,DISK], DatanodeInfoWithStorage[127.0.0.1:46525,DS-f4912b43-b80c-4582-9414-6a84d2f86534,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-188880630-172.17.0.18-1598137163437:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37406,DS-8701f0a8-0ecd-45b0-bcc5-1fb774af8dab,DISK], DatanodeInfoWithStorage[127.0.0.1:37605,DS-e84353a7-fb65-4222-acdd-ee1ebe71ba96,DISK], DatanodeInfoWithStorage[127.0.0.1:37463,DS-c883cffc-04dc-484d-bca9-5b6d199d0793,DISK], DatanodeInfoWithStorage[127.0.0.1:37599,DS-5527a127-71e4-4ac8-bf2e-b9f3e405006e,DISK], DatanodeInfoWithStorage[127.0.0.1:43349,DS-af3dc7d8-885a-4569-918e-f5625f8027bc,DISK], DatanodeInfoWithStorage[127.0.0.1:34372,DS-46ab94e7-74df-42f3-a8b2-4a6ff7f28af1,DISK], DatanodeInfoWithStorage[127.0.0.1:43843,DS-f8b34e57-5fa4-40c4-8167-0f81e0227f03,DISK], DatanodeInfoWithStorage[127.0.0.1:46525,DS-f4912b43-b80c-4582-9414-6a84d2f86534,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.considerLoad
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-238017846-172.17.0.18-1598137234846:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44636,DS-82cf224f-fb3c-43f7-9132-05ac4ef7ba4e,DISK], DatanodeInfoWithStorage[127.0.0.1:44685,DS-c3fbe7ae-5c67-476d-87cb-d7ce3e336c8e,DISK], DatanodeInfoWithStorage[127.0.0.1:42105,DS-161a1a1e-e010-4024-8418-1e9427be5045,DISK], DatanodeInfoWithStorage[127.0.0.1:44312,DS-9eecce98-c651-4624-a6f2-fd36a2c29589,DISK], DatanodeInfoWithStorage[127.0.0.1:43674,DS-603d0b4e-ca42-49c2-8faf-a879aab1a639,DISK], DatanodeInfoWithStorage[127.0.0.1:40227,DS-730ec6dc-3086-4131-8472-35dcf63c1cc7,DISK], DatanodeInfoWithStorage[127.0.0.1:41396,DS-eb6756e1-5081-417a-a587-4adddb1134ef,DISK], DatanodeInfoWithStorage[127.0.0.1:36130,DS-bb542f79-2fc4-4a64-90f5-fa8d13559cd6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-238017846-172.17.0.18-1598137234846:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44636,DS-82cf224f-fb3c-43f7-9132-05ac4ef7ba4e,DISK], DatanodeInfoWithStorage[127.0.0.1:44685,DS-c3fbe7ae-5c67-476d-87cb-d7ce3e336c8e,DISK], DatanodeInfoWithStorage[127.0.0.1:42105,DS-161a1a1e-e010-4024-8418-1e9427be5045,DISK], DatanodeInfoWithStorage[127.0.0.1:44312,DS-9eecce98-c651-4624-a6f2-fd36a2c29589,DISK], DatanodeInfoWithStorage[127.0.0.1:43674,DS-603d0b4e-ca42-49c2-8faf-a879aab1a639,DISK], DatanodeInfoWithStorage[127.0.0.1:40227,DS-730ec6dc-3086-4131-8472-35dcf63c1cc7,DISK], DatanodeInfoWithStorage[127.0.0.1:41396,DS-eb6756e1-5081-417a-a587-4adddb1134ef,DISK], DatanodeInfoWithStorage[127.0.0.1:36130,DS-bb542f79-2fc4-4a64-90f5-fa8d13559cd6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.considerLoad
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-950232483-172.17.0.18-1598137272915:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45787,DS-b837f6d8-fb33-4793-b195-274b4f783789,DISK], DatanodeInfoWithStorage[127.0.0.1:37371,DS-033ec3b7-00d4-4ce6-8a32-22617a703cbb,DISK], DatanodeInfoWithStorage[127.0.0.1:45520,DS-9bb780a3-132c-4260-b8a5-57636ce9441d,DISK], DatanodeInfoWithStorage[127.0.0.1:36033,DS-b61b64a9-aef8-4b5a-96a6-f3cfbd0382af,DISK], DatanodeInfoWithStorage[127.0.0.1:41506,DS-83750bb9-7649-4b4f-bb98-6cf6c8047844,DISK], DatanodeInfoWithStorage[127.0.0.1:46076,DS-6ad164e4-9021-4e1e-8928-179f342785c3,DISK], DatanodeInfoWithStorage[127.0.0.1:42851,DS-cac97602-453b-4a76-86eb-ba0bbca3ac70,DISK], DatanodeInfoWithStorage[127.0.0.1:45832,DS-a0897943-54b7-4368-bb7c-791c96f5d588,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-950232483-172.17.0.18-1598137272915:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45787,DS-b837f6d8-fb33-4793-b195-274b4f783789,DISK], DatanodeInfoWithStorage[127.0.0.1:37371,DS-033ec3b7-00d4-4ce6-8a32-22617a703cbb,DISK], DatanodeInfoWithStorage[127.0.0.1:45520,DS-9bb780a3-132c-4260-b8a5-57636ce9441d,DISK], DatanodeInfoWithStorage[127.0.0.1:36033,DS-b61b64a9-aef8-4b5a-96a6-f3cfbd0382af,DISK], DatanodeInfoWithStorage[127.0.0.1:41506,DS-83750bb9-7649-4b4f-bb98-6cf6c8047844,DISK], DatanodeInfoWithStorage[127.0.0.1:46076,DS-6ad164e4-9021-4e1e-8928-179f342785c3,DISK], DatanodeInfoWithStorage[127.0.0.1:42851,DS-cac97602-453b-4a76-86eb-ba0bbca3ac70,DISK], DatanodeInfoWithStorage[127.0.0.1:45832,DS-a0897943-54b7-4368-bb7c-791c96f5d588,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.considerLoad
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1242109721-172.17.0.18-1598137503940:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39234,DS-3d2867d1-72cc-494f-8b3b-c4f27c8f74c1,DISK], DatanodeInfoWithStorage[127.0.0.1:38518,DS-3042a824-2594-466e-922f-0764473bb0eb,DISK], DatanodeInfoWithStorage[127.0.0.1:44906,DS-4b4e68f3-6035-44af-acbd-3330663468dd,DISK], DatanodeInfoWithStorage[127.0.0.1:41550,DS-37c35385-2a24-4972-ac3b-7d0da1ba37d8,DISK], DatanodeInfoWithStorage[127.0.0.1:43618,DS-dd24fa6e-22df-4251-bf6f-59286c89e6f4,DISK], DatanodeInfoWithStorage[127.0.0.1:40485,DS-e60b7d0e-de78-4a8a-bf78-87bba64e3165,DISK], DatanodeInfoWithStorage[127.0.0.1:37416,DS-654ce93f-feb8-4283-aa15-3d0714a23285,DISK], DatanodeInfoWithStorage[127.0.0.1:33716,DS-633f7809-4f9e-4fa7-9328-4f9434bb1719,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1242109721-172.17.0.18-1598137503940:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39234,DS-3d2867d1-72cc-494f-8b3b-c4f27c8f74c1,DISK], DatanodeInfoWithStorage[127.0.0.1:38518,DS-3042a824-2594-466e-922f-0764473bb0eb,DISK], DatanodeInfoWithStorage[127.0.0.1:44906,DS-4b4e68f3-6035-44af-acbd-3330663468dd,DISK], DatanodeInfoWithStorage[127.0.0.1:41550,DS-37c35385-2a24-4972-ac3b-7d0da1ba37d8,DISK], DatanodeInfoWithStorage[127.0.0.1:43618,DS-dd24fa6e-22df-4251-bf6f-59286c89e6f4,DISK], DatanodeInfoWithStorage[127.0.0.1:40485,DS-e60b7d0e-de78-4a8a-bf78-87bba64e3165,DISK], DatanodeInfoWithStorage[127.0.0.1:37416,DS-654ce93f-feb8-4283-aa15-3d0714a23285,DISK], DatanodeInfoWithStorage[127.0.0.1:33716,DS-633f7809-4f9e-4fa7-9328-4f9434bb1719,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.considerLoad
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1365721128-172.17.0.18-1598137575047:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34411,DS-144960d0-2036-44de-b2a3-6b9b1373698f,DISK], DatanodeInfoWithStorage[127.0.0.1:46753,DS-b1f6db27-547f-4194-acea-e067ea718525,DISK], DatanodeInfoWithStorage[127.0.0.1:42859,DS-8622c898-087c-4fb5-be0b-08b4e21e8c2a,DISK], DatanodeInfoWithStorage[127.0.0.1:42969,DS-e521d132-8bf1-4f32-9ea9-07d30935fc4e,DISK], DatanodeInfoWithStorage[127.0.0.1:44930,DS-a3d8e294-7935-45a8-95fd-de25dea3f9e4,DISK], DatanodeInfoWithStorage[127.0.0.1:32769,DS-ca4c1bc6-c5dd-4dc7-865f-0ff979a02f84,DISK], DatanodeInfoWithStorage[127.0.0.1:41200,DS-ec94242c-c647-473f-bf96-4b0857aa7352,DISK], DatanodeInfoWithStorage[127.0.0.1:46614,DS-69d06153-49a9-43dc-9660-3970be2f887d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1365721128-172.17.0.18-1598137575047:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34411,DS-144960d0-2036-44de-b2a3-6b9b1373698f,DISK], DatanodeInfoWithStorage[127.0.0.1:46753,DS-b1f6db27-547f-4194-acea-e067ea718525,DISK], DatanodeInfoWithStorage[127.0.0.1:42859,DS-8622c898-087c-4fb5-be0b-08b4e21e8c2a,DISK], DatanodeInfoWithStorage[127.0.0.1:42969,DS-e521d132-8bf1-4f32-9ea9-07d30935fc4e,DISK], DatanodeInfoWithStorage[127.0.0.1:44930,DS-a3d8e294-7935-45a8-95fd-de25dea3f9e4,DISK], DatanodeInfoWithStorage[127.0.0.1:32769,DS-ca4c1bc6-c5dd-4dc7-865f-0ff979a02f84,DISK], DatanodeInfoWithStorage[127.0.0.1:41200,DS-ec94242c-c647-473f-bf96-4b0857aa7352,DISK], DatanodeInfoWithStorage[127.0.0.1:46614,DS-69d06153-49a9-43dc-9660-3970be2f887d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.considerLoad
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-759205076-172.17.0.18-1598137786475:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36995,DS-3bd82090-63d0-47f2-82c0-efeaa5a13f8c,DISK], DatanodeInfoWithStorage[127.0.0.1:35344,DS-fb0c27a0-bf35-44c4-a0c6-089c25d5c212,DISK], DatanodeInfoWithStorage[127.0.0.1:44205,DS-41df91c4-cee0-490c-9208-ec043c9b0930,DISK], DatanodeInfoWithStorage[127.0.0.1:42138,DS-5e40dddb-7cfe-4a3c-8de5-5c9a0792d1a8,DISK], DatanodeInfoWithStorage[127.0.0.1:35775,DS-37c8daa5-b7a9-46d4-884b-30516258b6ef,DISK], DatanodeInfoWithStorage[127.0.0.1:38214,DS-54d4fc5e-6061-4f48-963d-90fb0f87b6ef,DISK], DatanodeInfoWithStorage[127.0.0.1:38061,DS-053a8552-8f25-4cb0-a3af-1cef88729556,DISK], DatanodeInfoWithStorage[127.0.0.1:40207,DS-f4b233e8-f60a-41c1-af09-027391515522,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-759205076-172.17.0.18-1598137786475:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36995,DS-3bd82090-63d0-47f2-82c0-efeaa5a13f8c,DISK], DatanodeInfoWithStorage[127.0.0.1:35344,DS-fb0c27a0-bf35-44c4-a0c6-089c25d5c212,DISK], DatanodeInfoWithStorage[127.0.0.1:44205,DS-41df91c4-cee0-490c-9208-ec043c9b0930,DISK], DatanodeInfoWithStorage[127.0.0.1:42138,DS-5e40dddb-7cfe-4a3c-8de5-5c9a0792d1a8,DISK], DatanodeInfoWithStorage[127.0.0.1:35775,DS-37c8daa5-b7a9-46d4-884b-30516258b6ef,DISK], DatanodeInfoWithStorage[127.0.0.1:38214,DS-54d4fc5e-6061-4f48-963d-90fb0f87b6ef,DISK], DatanodeInfoWithStorage[127.0.0.1:38061,DS-053a8552-8f25-4cb0-a3af-1cef88729556,DISK], DatanodeInfoWithStorage[127.0.0.1:40207,DS-f4b233e8-f60a-41c1-af09-027391515522,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.considerLoad
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-4377871-172.17.0.18-1598138137331:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41411,DS-ebd6df8d-14ea-4434-8ddf-cac5551b7411,DISK], DatanodeInfoWithStorage[127.0.0.1:33130,DS-e22d0741-2e66-4365-8ca2-fdcca4b64115,DISK], DatanodeInfoWithStorage[127.0.0.1:42622,DS-c3956cec-bcf2-47c5-8f32-4a3e2ad510e5,DISK], DatanodeInfoWithStorage[127.0.0.1:40170,DS-088e23a7-01e1-4adc-8720-4ecf7fc4ac46,DISK], DatanodeInfoWithStorage[127.0.0.1:36613,DS-bfd3d10b-9f80-4074-9b28-4149209c0285,DISK], DatanodeInfoWithStorage[127.0.0.1:38859,DS-fd722dd3-d458-43f4-83c8-0889c5558efc,DISK], DatanodeInfoWithStorage[127.0.0.1:36197,DS-6438c083-ff17-4914-a7be-aed0c538add7,DISK], DatanodeInfoWithStorage[127.0.0.1:35403,DS-7a1a2f96-fe7a-4113-a7c3-991d9012a57a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-4377871-172.17.0.18-1598138137331:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41411,DS-ebd6df8d-14ea-4434-8ddf-cac5551b7411,DISK], DatanodeInfoWithStorage[127.0.0.1:33130,DS-e22d0741-2e66-4365-8ca2-fdcca4b64115,DISK], DatanodeInfoWithStorage[127.0.0.1:42622,DS-c3956cec-bcf2-47c5-8f32-4a3e2ad510e5,DISK], DatanodeInfoWithStorage[127.0.0.1:40170,DS-088e23a7-01e1-4adc-8720-4ecf7fc4ac46,DISK], DatanodeInfoWithStorage[127.0.0.1:36613,DS-bfd3d10b-9f80-4074-9b28-4149209c0285,DISK], DatanodeInfoWithStorage[127.0.0.1:38859,DS-fd722dd3-d458-43f4-83c8-0889c5558efc,DISK], DatanodeInfoWithStorage[127.0.0.1:36197,DS-6438c083-ff17-4914-a7be-aed0c538add7,DISK], DatanodeInfoWithStorage[127.0.0.1:35403,DS-7a1a2f96-fe7a-4113-a7c3-991d9012a57a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.considerLoad
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-392664068-172.17.0.18-1598138866484:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38580,DS-134f2ec7-1512-4cb9-973f-faba2efeba2c,DISK], DatanodeInfoWithStorage[127.0.0.1:36897,DS-f0314d59-0c43-4ad3-905e-3539719aaa9e,DISK], DatanodeInfoWithStorage[127.0.0.1:44286,DS-704b74ec-5fc2-4f6f-9184-6ccc9c8885fd,DISK], DatanodeInfoWithStorage[127.0.0.1:38310,DS-6b41ab67-a41a-41b0-b5b8-19d1bff98941,DISK], DatanodeInfoWithStorage[127.0.0.1:34061,DS-442d7add-2ef7-46be-b90c-4fbf06ef7126,DISK], DatanodeInfoWithStorage[127.0.0.1:44295,DS-b52c6d6b-af66-4ea2-8dd4-f1cc8c1a2fd5,DISK], DatanodeInfoWithStorage[127.0.0.1:38218,DS-32d76c19-164d-4fb6-9676-e72d6df8df80,DISK], DatanodeInfoWithStorage[127.0.0.1:32865,DS-b06c15e6-ebae-4bef-bf89-4dc379a166ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-392664068-172.17.0.18-1598138866484:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38580,DS-134f2ec7-1512-4cb9-973f-faba2efeba2c,DISK], DatanodeInfoWithStorage[127.0.0.1:36897,DS-f0314d59-0c43-4ad3-905e-3539719aaa9e,DISK], DatanodeInfoWithStorage[127.0.0.1:44286,DS-704b74ec-5fc2-4f6f-9184-6ccc9c8885fd,DISK], DatanodeInfoWithStorage[127.0.0.1:38310,DS-6b41ab67-a41a-41b0-b5b8-19d1bff98941,DISK], DatanodeInfoWithStorage[127.0.0.1:34061,DS-442d7add-2ef7-46be-b90c-4fbf06ef7126,DISK], DatanodeInfoWithStorage[127.0.0.1:44295,DS-b52c6d6b-af66-4ea2-8dd4-f1cc8c1a2fd5,DISK], DatanodeInfoWithStorage[127.0.0.1:38218,DS-32d76c19-164d-4fb6-9676-e72d6df8df80,DISK], DatanodeInfoWithStorage[127.0.0.1:32865,DS-b06c15e6-ebae-4bef-bf89-4dc379a166ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.considerLoad
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-267960470-172.17.0.18-1598138904400:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44238,DS-26aaff96-2118-4b71-883f-2bbab64f46da,DISK], DatanodeInfoWithStorage[127.0.0.1:42228,DS-799a7784-ef7b-45db-93ed-226c394413f7,DISK], DatanodeInfoWithStorage[127.0.0.1:39595,DS-088f247d-877a-4608-84e7-e9b9b6455288,DISK], DatanodeInfoWithStorage[127.0.0.1:41926,DS-cec49f15-3c40-4b0f-8896-fe5d9eefc311,DISK], DatanodeInfoWithStorage[127.0.0.1:45565,DS-48e7b7f9-8cf0-4992-84e4-83e80846a9af,DISK], DatanodeInfoWithStorage[127.0.0.1:38472,DS-e6e541eb-73c8-4ca9-8b02-4389d77f4d9e,DISK], DatanodeInfoWithStorage[127.0.0.1:38503,DS-89f59379-bf8a-4944-a084-ee2b02a254dd,DISK], DatanodeInfoWithStorage[127.0.0.1:39266,DS-c2b689f1-bee1-4c4f-89a7-8acf760822d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-267960470-172.17.0.18-1598138904400:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44238,DS-26aaff96-2118-4b71-883f-2bbab64f46da,DISK], DatanodeInfoWithStorage[127.0.0.1:42228,DS-799a7784-ef7b-45db-93ed-226c394413f7,DISK], DatanodeInfoWithStorage[127.0.0.1:39595,DS-088f247d-877a-4608-84e7-e9b9b6455288,DISK], DatanodeInfoWithStorage[127.0.0.1:41926,DS-cec49f15-3c40-4b0f-8896-fe5d9eefc311,DISK], DatanodeInfoWithStorage[127.0.0.1:45565,DS-48e7b7f9-8cf0-4992-84e4-83e80846a9af,DISK], DatanodeInfoWithStorage[127.0.0.1:38472,DS-e6e541eb-73c8-4ca9-8b02-4389d77f4d9e,DISK], DatanodeInfoWithStorage[127.0.0.1:38503,DS-89f59379-bf8a-4944-a084-ee2b02a254dd,DISK], DatanodeInfoWithStorage[127.0.0.1:39266,DS-c2b689f1-bee1-4c4f-89a7-8acf760822d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.considerLoad
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1024853524-172.17.0.18-1598139702969:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34955,DS-1aa722a7-77df-490f-b5f3-59b9123f0931,DISK], DatanodeInfoWithStorage[127.0.0.1:40576,DS-d114c9a3-5e26-4e47-8d26-4e5374af3b02,DISK], DatanodeInfoWithStorage[127.0.0.1:36288,DS-1d797a4c-bd43-434d-af47-c928633e0fa5,DISK], DatanodeInfoWithStorage[127.0.0.1:43358,DS-1b023a00-8be0-403e-8519-61013d6e0933,DISK], DatanodeInfoWithStorage[127.0.0.1:38697,DS-5558c5cd-9dad-4705-9379-6b91224bc98e,DISK], DatanodeInfoWithStorage[127.0.0.1:34029,DS-10c7d8a0-a5d4-499a-9fc3-d39e7237f08c,DISK], DatanodeInfoWithStorage[127.0.0.1:44903,DS-cb66712e-d28c-4aa5-bfdf-d7b22d04742e,DISK], DatanodeInfoWithStorage[127.0.0.1:45852,DS-c8988f8a-dcc6-44d2-983b-ba4b000b2750,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1024853524-172.17.0.18-1598139702969:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34955,DS-1aa722a7-77df-490f-b5f3-59b9123f0931,DISK], DatanodeInfoWithStorage[127.0.0.1:40576,DS-d114c9a3-5e26-4e47-8d26-4e5374af3b02,DISK], DatanodeInfoWithStorage[127.0.0.1:36288,DS-1d797a4c-bd43-434d-af47-c928633e0fa5,DISK], DatanodeInfoWithStorage[127.0.0.1:43358,DS-1b023a00-8be0-403e-8519-61013d6e0933,DISK], DatanodeInfoWithStorage[127.0.0.1:38697,DS-5558c5cd-9dad-4705-9379-6b91224bc98e,DISK], DatanodeInfoWithStorage[127.0.0.1:34029,DS-10c7d8a0-a5d4-499a-9fc3-d39e7237f08c,DISK], DatanodeInfoWithStorage[127.0.0.1:44903,DS-cb66712e-d28c-4aa5-bfdf-d7b22d04742e,DISK], DatanodeInfoWithStorage[127.0.0.1:45852,DS-c8988f8a-dcc6-44d2-983b-ba4b000b2750,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.considerLoad
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-656700053-172.17.0.18-1598139787749:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43703,DS-12d453ff-0370-4c65-b1ea-662f01faa616,DISK], DatanodeInfoWithStorage[127.0.0.1:42559,DS-7ed01abf-6084-41c5-868a-44e8ecc1255e,DISK], DatanodeInfoWithStorage[127.0.0.1:35225,DS-723962cd-2feb-44c0-b4a7-f6bc6a0d629b,DISK], DatanodeInfoWithStorage[127.0.0.1:44700,DS-0ef394a6-6c00-4e9f-928b-9367d8391306,DISK], DatanodeInfoWithStorage[127.0.0.1:42501,DS-2e264e19-0413-4e30-8b76-be3f6b06a138,DISK], DatanodeInfoWithStorage[127.0.0.1:45981,DS-03c2f516-47ee-4546-8953-9701b19a1f99,DISK], DatanodeInfoWithStorage[127.0.0.1:40784,DS-ec31db89-8c3e-4b1a-9716-283353ea82e5,DISK], DatanodeInfoWithStorage[127.0.0.1:40898,DS-1f16bc0b-f145-4ed4-9d76-deba89f7b782,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-656700053-172.17.0.18-1598139787749:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43703,DS-12d453ff-0370-4c65-b1ea-662f01faa616,DISK], DatanodeInfoWithStorage[127.0.0.1:42559,DS-7ed01abf-6084-41c5-868a-44e8ecc1255e,DISK], DatanodeInfoWithStorage[127.0.0.1:35225,DS-723962cd-2feb-44c0-b4a7-f6bc6a0d629b,DISK], DatanodeInfoWithStorage[127.0.0.1:44700,DS-0ef394a6-6c00-4e9f-928b-9367d8391306,DISK], DatanodeInfoWithStorage[127.0.0.1:42501,DS-2e264e19-0413-4e30-8b76-be3f6b06a138,DISK], DatanodeInfoWithStorage[127.0.0.1:45981,DS-03c2f516-47ee-4546-8953-9701b19a1f99,DISK], DatanodeInfoWithStorage[127.0.0.1:40784,DS-ec31db89-8c3e-4b1a-9716-283353ea82e5,DISK], DatanodeInfoWithStorage[127.0.0.1:40898,DS-1f16bc0b-f145-4ed4-9d76-deba89f7b782,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.considerLoad
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1446130242-172.17.0.18-1598140175720:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39688,DS-f04831b2-6c8e-450e-ab9f-edad6779cc14,DISK], DatanodeInfoWithStorage[127.0.0.1:36128,DS-faeeb0b8-11fd-49bc-8f8f-6a11f5cc18a9,DISK], DatanodeInfoWithStorage[127.0.0.1:33912,DS-ed9dfd19-0624-41b1-94c6-813a62892c63,DISK], DatanodeInfoWithStorage[127.0.0.1:39319,DS-814d54cd-b9af-4e87-b648-250676c44527,DISK], DatanodeInfoWithStorage[127.0.0.1:41657,DS-f0244d65-f798-419c-9ce1-d710951faed7,DISK], DatanodeInfoWithStorage[127.0.0.1:44309,DS-1662b202-60e6-4a00-8453-fecb99fe74e2,DISK], DatanodeInfoWithStorage[127.0.0.1:38816,DS-ac38cf0b-6719-4a0c-91b4-1eb3c170c725,DISK], DatanodeInfoWithStorage[127.0.0.1:40466,DS-0dcf7dbe-8c93-47d2-a851-159c9908c0b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1446130242-172.17.0.18-1598140175720:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39688,DS-f04831b2-6c8e-450e-ab9f-edad6779cc14,DISK], DatanodeInfoWithStorage[127.0.0.1:36128,DS-faeeb0b8-11fd-49bc-8f8f-6a11f5cc18a9,DISK], DatanodeInfoWithStorage[127.0.0.1:33912,DS-ed9dfd19-0624-41b1-94c6-813a62892c63,DISK], DatanodeInfoWithStorage[127.0.0.1:39319,DS-814d54cd-b9af-4e87-b648-250676c44527,DISK], DatanodeInfoWithStorage[127.0.0.1:41657,DS-f0244d65-f798-419c-9ce1-d710951faed7,DISK], DatanodeInfoWithStorage[127.0.0.1:44309,DS-1662b202-60e6-4a00-8453-fecb99fe74e2,DISK], DatanodeInfoWithStorage[127.0.0.1:38816,DS-ac38cf0b-6719-4a0c-91b4-1eb3c170c725,DISK], DatanodeInfoWithStorage[127.0.0.1:40466,DS-0dcf7dbe-8c93-47d2-a851-159c9908c0b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 11 out of 50
v1v1v2v2 failed with probability 14 out of 50
result: false positive !!!
Total execution time in seconds : 5571
