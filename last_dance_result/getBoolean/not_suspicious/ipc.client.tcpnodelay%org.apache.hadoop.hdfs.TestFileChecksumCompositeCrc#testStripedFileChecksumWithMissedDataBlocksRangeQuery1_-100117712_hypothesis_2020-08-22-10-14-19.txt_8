reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1488833033-172.17.0.10-1598091946831:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45079,DS-116094cb-0848-4438-9d36-e1e76289be41,DISK], DatanodeInfoWithStorage[127.0.0.1:42518,DS-204baef2-1ac3-4f40-b482-211a79667859,DISK], DatanodeInfoWithStorage[127.0.0.1:39625,DS-abb074c6-725e-4a78-b1da-5a5548fbeb89,DISK], DatanodeInfoWithStorage[127.0.0.1:46688,DS-5ea0067a-854c-43d1-9675-8b9b51df8e9a,DISK], DatanodeInfoWithStorage[127.0.0.1:38009,DS-a7c85948-9417-4329-88e5-28ab95282edd,DISK], DatanodeInfoWithStorage[127.0.0.1:41907,DS-cbd8ed4a-f340-41b7-ba90-bdb6dbdc8010,DISK], DatanodeInfoWithStorage[127.0.0.1:41542,DS-64b75060-58b1-4f79-a7e3-1b56df0c94a3,DISK], DatanodeInfoWithStorage[127.0.0.1:44266,DS-a2f413d8-1229-4a42-9bd0-df4677dcf5ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1488833033-172.17.0.10-1598091946831:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45079,DS-116094cb-0848-4438-9d36-e1e76289be41,DISK], DatanodeInfoWithStorage[127.0.0.1:42518,DS-204baef2-1ac3-4f40-b482-211a79667859,DISK], DatanodeInfoWithStorage[127.0.0.1:39625,DS-abb074c6-725e-4a78-b1da-5a5548fbeb89,DISK], DatanodeInfoWithStorage[127.0.0.1:46688,DS-5ea0067a-854c-43d1-9675-8b9b51df8e9a,DISK], DatanodeInfoWithStorage[127.0.0.1:38009,DS-a7c85948-9417-4329-88e5-28ab95282edd,DISK], DatanodeInfoWithStorage[127.0.0.1:41907,DS-cbd8ed4a-f340-41b7-ba90-bdb6dbdc8010,DISK], DatanodeInfoWithStorage[127.0.0.1:41542,DS-64b75060-58b1-4f79-a7e3-1b56df0c94a3,DISK], DatanodeInfoWithStorage[127.0.0.1:44266,DS-a2f413d8-1229-4a42-9bd0-df4677dcf5ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1219628636-172.17.0.10-1598092181330:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43526,DS-29d310b7-8bf4-459b-99ee-21aa5e28ab72,DISK], DatanodeInfoWithStorage[127.0.0.1:38342,DS-2c4c78e2-8871-4da8-b431-39a50d6d1ce6,DISK], DatanodeInfoWithStorage[127.0.0.1:33515,DS-a0e25f60-d954-4ecb-a06e-0a46f9f4c2ea,DISK], DatanodeInfoWithStorage[127.0.0.1:43134,DS-43fd2a5f-e3f1-4d76-9071-d52590688d10,DISK], DatanodeInfoWithStorage[127.0.0.1:41623,DS-f7069e82-059f-4583-8edc-939257bd6019,DISK], DatanodeInfoWithStorage[127.0.0.1:43441,DS-140f52e8-4314-4247-9df1-fec3ae002fa1,DISK], DatanodeInfoWithStorage[127.0.0.1:44557,DS-20d8ee1f-6bab-48fe-bb4f-f2047735b15a,DISK], DatanodeInfoWithStorage[127.0.0.1:39347,DS-02d811d4-c733-4deb-8911-775e848d4a9b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1219628636-172.17.0.10-1598092181330:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43526,DS-29d310b7-8bf4-459b-99ee-21aa5e28ab72,DISK], DatanodeInfoWithStorage[127.0.0.1:38342,DS-2c4c78e2-8871-4da8-b431-39a50d6d1ce6,DISK], DatanodeInfoWithStorage[127.0.0.1:33515,DS-a0e25f60-d954-4ecb-a06e-0a46f9f4c2ea,DISK], DatanodeInfoWithStorage[127.0.0.1:43134,DS-43fd2a5f-e3f1-4d76-9071-d52590688d10,DISK], DatanodeInfoWithStorage[127.0.0.1:41623,DS-f7069e82-059f-4583-8edc-939257bd6019,DISK], DatanodeInfoWithStorage[127.0.0.1:43441,DS-140f52e8-4314-4247-9df1-fec3ae002fa1,DISK], DatanodeInfoWithStorage[127.0.0.1:44557,DS-20d8ee1f-6bab-48fe-bb4f-f2047735b15a,DISK], DatanodeInfoWithStorage[127.0.0.1:39347,DS-02d811d4-c733-4deb-8911-775e848d4a9b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-788447454-172.17.0.10-1598092259173:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39905,DS-2f104bf8-ff35-4768-a6ac-2e84671aabeb,DISK], DatanodeInfoWithStorage[127.0.0.1:40348,DS-6c0a2996-700f-4fad-be75-1a25098fc9ae,DISK], DatanodeInfoWithStorage[127.0.0.1:40462,DS-bbbfb449-1038-4136-8b1c-b70bede22d96,DISK], DatanodeInfoWithStorage[127.0.0.1:34970,DS-0afedba9-67ff-4d55-ad07-104aec00a825,DISK], DatanodeInfoWithStorage[127.0.0.1:42096,DS-bb6983d5-3a69-4d9b-8840-910e7d3610ca,DISK], DatanodeInfoWithStorage[127.0.0.1:34690,DS-56fc941e-3ea4-4284-890a-f223bff06a29,DISK], DatanodeInfoWithStorage[127.0.0.1:40973,DS-12140f9b-5243-4ce7-bef6-1f5b43c8296b,DISK], DatanodeInfoWithStorage[127.0.0.1:37455,DS-4f8c123e-69f5-45a6-8a49-edb715dd2a77,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-788447454-172.17.0.10-1598092259173:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39905,DS-2f104bf8-ff35-4768-a6ac-2e84671aabeb,DISK], DatanodeInfoWithStorage[127.0.0.1:40348,DS-6c0a2996-700f-4fad-be75-1a25098fc9ae,DISK], DatanodeInfoWithStorage[127.0.0.1:40462,DS-bbbfb449-1038-4136-8b1c-b70bede22d96,DISK], DatanodeInfoWithStorage[127.0.0.1:34970,DS-0afedba9-67ff-4d55-ad07-104aec00a825,DISK], DatanodeInfoWithStorage[127.0.0.1:42096,DS-bb6983d5-3a69-4d9b-8840-910e7d3610ca,DISK], DatanodeInfoWithStorage[127.0.0.1:34690,DS-56fc941e-3ea4-4284-890a-f223bff06a29,DISK], DatanodeInfoWithStorage[127.0.0.1:40973,DS-12140f9b-5243-4ce7-bef6-1f5b43c8296b,DISK], DatanodeInfoWithStorage[127.0.0.1:37455,DS-4f8c123e-69f5-45a6-8a49-edb715dd2a77,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-699613555-172.17.0.10-1598092372478:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46759,DS-bc9f2587-c6d0-4665-af27-aad154eef3fc,DISK], DatanodeInfoWithStorage[127.0.0.1:40420,DS-af0126cc-8f15-4d62-b15f-5e61d72e1b62,DISK], DatanodeInfoWithStorage[127.0.0.1:35010,DS-ac1f4318-9e96-4fe5-a997-cf2ae206620b,DISK], DatanodeInfoWithStorage[127.0.0.1:34264,DS-9c343e1d-0c0b-43b1-bd6d-5f52e2266fd4,DISK], DatanodeInfoWithStorage[127.0.0.1:37226,DS-d056f19a-9b2f-4fee-a048-9f100ddc3acd,DISK], DatanodeInfoWithStorage[127.0.0.1:43179,DS-06a27256-add9-40ab-b712-a55ff98d44d8,DISK], DatanodeInfoWithStorage[127.0.0.1:39387,DS-f1d8765f-77a3-4dbe-9b99-1a4ce62127e1,DISK], DatanodeInfoWithStorage[127.0.0.1:34077,DS-f006d295-b26d-4a8b-957a-5e8d4d7aebc5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-699613555-172.17.0.10-1598092372478:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46759,DS-bc9f2587-c6d0-4665-af27-aad154eef3fc,DISK], DatanodeInfoWithStorage[127.0.0.1:40420,DS-af0126cc-8f15-4d62-b15f-5e61d72e1b62,DISK], DatanodeInfoWithStorage[127.0.0.1:35010,DS-ac1f4318-9e96-4fe5-a997-cf2ae206620b,DISK], DatanodeInfoWithStorage[127.0.0.1:34264,DS-9c343e1d-0c0b-43b1-bd6d-5f52e2266fd4,DISK], DatanodeInfoWithStorage[127.0.0.1:37226,DS-d056f19a-9b2f-4fee-a048-9f100ddc3acd,DISK], DatanodeInfoWithStorage[127.0.0.1:43179,DS-06a27256-add9-40ab-b712-a55ff98d44d8,DISK], DatanodeInfoWithStorage[127.0.0.1:39387,DS-f1d8765f-77a3-4dbe-9b99-1a4ce62127e1,DISK], DatanodeInfoWithStorage[127.0.0.1:34077,DS-f006d295-b26d-4a8b-957a-5e8d4d7aebc5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-696157010-172.17.0.10-1598093258923:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36349,DS-df773114-5397-47ba-bb20-24935735fd1f,DISK], DatanodeInfoWithStorage[127.0.0.1:38265,DS-ed5050e2-d520-44fc-a64b-805830ffb0dc,DISK], DatanodeInfoWithStorage[127.0.0.1:37723,DS-4df68b3a-a312-4bb8-b962-5457a19c31e3,DISK], DatanodeInfoWithStorage[127.0.0.1:37708,DS-2c19ef59-ca2b-4c3a-8b32-77925ac72023,DISK], DatanodeInfoWithStorage[127.0.0.1:35291,DS-d1db4a76-e8a9-49d5-8733-f1f50803ae7e,DISK], DatanodeInfoWithStorage[127.0.0.1:40992,DS-49ef29a8-1f91-4e1e-88b3-44fa7051fd46,DISK], DatanodeInfoWithStorage[127.0.0.1:43518,DS-c6d75c69-bfdc-4a45-bffc-a720795a903d,DISK], DatanodeInfoWithStorage[127.0.0.1:42274,DS-d6cc5205-1971-4e09-ba2b-ec4119e803fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-696157010-172.17.0.10-1598093258923:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36349,DS-df773114-5397-47ba-bb20-24935735fd1f,DISK], DatanodeInfoWithStorage[127.0.0.1:38265,DS-ed5050e2-d520-44fc-a64b-805830ffb0dc,DISK], DatanodeInfoWithStorage[127.0.0.1:37723,DS-4df68b3a-a312-4bb8-b962-5457a19c31e3,DISK], DatanodeInfoWithStorage[127.0.0.1:37708,DS-2c19ef59-ca2b-4c3a-8b32-77925ac72023,DISK], DatanodeInfoWithStorage[127.0.0.1:35291,DS-d1db4a76-e8a9-49d5-8733-f1f50803ae7e,DISK], DatanodeInfoWithStorage[127.0.0.1:40992,DS-49ef29a8-1f91-4e1e-88b3-44fa7051fd46,DISK], DatanodeInfoWithStorage[127.0.0.1:43518,DS-c6d75c69-bfdc-4a45-bffc-a720795a903d,DISK], DatanodeInfoWithStorage[127.0.0.1:42274,DS-d6cc5205-1971-4e09-ba2b-ec4119e803fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1816573866-172.17.0.10-1598094436835:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38881,DS-ee5bf176-3067-4853-a1c8-e0e706515e41,DISK], DatanodeInfoWithStorage[127.0.0.1:33009,DS-a34a6b69-4224-4935-8daf-a2de19225ead,DISK], DatanodeInfoWithStorage[127.0.0.1:43542,DS-c9842276-a58b-4428-af21-704e3c28c92a,DISK], DatanodeInfoWithStorage[127.0.0.1:45921,DS-0e77979d-2f6f-4808-9bb7-1bc422d573ec,DISK], DatanodeInfoWithStorage[127.0.0.1:37497,DS-626a52db-0056-4bb8-aeca-984f76c9b9ca,DISK], DatanodeInfoWithStorage[127.0.0.1:44882,DS-2ffe988f-e15b-4137-a239-87f481db2abb,DISK], DatanodeInfoWithStorage[127.0.0.1:44855,DS-e1f1d3f5-4446-42e6-9c0b-cc66062ae140,DISK], DatanodeInfoWithStorage[127.0.0.1:38919,DS-b74b83ab-aed5-4b63-8155-64129ac5c863,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1816573866-172.17.0.10-1598094436835:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38881,DS-ee5bf176-3067-4853-a1c8-e0e706515e41,DISK], DatanodeInfoWithStorage[127.0.0.1:33009,DS-a34a6b69-4224-4935-8daf-a2de19225ead,DISK], DatanodeInfoWithStorage[127.0.0.1:43542,DS-c9842276-a58b-4428-af21-704e3c28c92a,DISK], DatanodeInfoWithStorage[127.0.0.1:45921,DS-0e77979d-2f6f-4808-9bb7-1bc422d573ec,DISK], DatanodeInfoWithStorage[127.0.0.1:37497,DS-626a52db-0056-4bb8-aeca-984f76c9b9ca,DISK], DatanodeInfoWithStorage[127.0.0.1:44882,DS-2ffe988f-e15b-4137-a239-87f481db2abb,DISK], DatanodeInfoWithStorage[127.0.0.1:44855,DS-e1f1d3f5-4446-42e6-9c0b-cc66062ae140,DISK], DatanodeInfoWithStorage[127.0.0.1:38919,DS-b74b83ab-aed5-4b63-8155-64129ac5c863,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1587609761-172.17.0.10-1598094731414:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39208,DS-d3c1dc57-5135-4a46-a8a3-e4ff95bfa4b9,DISK], DatanodeInfoWithStorage[127.0.0.1:35483,DS-995167c2-fd11-4786-9e7c-25e1de8d7c60,DISK], DatanodeInfoWithStorage[127.0.0.1:40894,DS-86ec0728-56c1-4752-926e-e782d1e4d63d,DISK], DatanodeInfoWithStorage[127.0.0.1:37465,DS-64d02043-c1b7-4638-a9c9-ad3a73c795d0,DISK], DatanodeInfoWithStorage[127.0.0.1:42487,DS-3d86cfc3-eab3-4b17-8f68-a20a486a1719,DISK], DatanodeInfoWithStorage[127.0.0.1:33842,DS-f68bb1dc-fb04-4e28-b5ce-ba3fbbe395a2,DISK], DatanodeInfoWithStorage[127.0.0.1:46318,DS-3edfae18-6ca2-4e94-a8b9-53c0a3feb8f7,DISK], DatanodeInfoWithStorage[127.0.0.1:41599,DS-c6056139-0ad6-461b-95a8-9c57697807fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1587609761-172.17.0.10-1598094731414:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39208,DS-d3c1dc57-5135-4a46-a8a3-e4ff95bfa4b9,DISK], DatanodeInfoWithStorage[127.0.0.1:35483,DS-995167c2-fd11-4786-9e7c-25e1de8d7c60,DISK], DatanodeInfoWithStorage[127.0.0.1:40894,DS-86ec0728-56c1-4752-926e-e782d1e4d63d,DISK], DatanodeInfoWithStorage[127.0.0.1:37465,DS-64d02043-c1b7-4638-a9c9-ad3a73c795d0,DISK], DatanodeInfoWithStorage[127.0.0.1:42487,DS-3d86cfc3-eab3-4b17-8f68-a20a486a1719,DISK], DatanodeInfoWithStorage[127.0.0.1:33842,DS-f68bb1dc-fb04-4e28-b5ce-ba3fbbe395a2,DISK], DatanodeInfoWithStorage[127.0.0.1:46318,DS-3edfae18-6ca2-4e94-a8b9-53c0a3feb8f7,DISK], DatanodeInfoWithStorage[127.0.0.1:41599,DS-c6056139-0ad6-461b-95a8-9c57697807fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2064848632-172.17.0.10-1598095075268:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46530,DS-88ca7415-091f-478f-9afe-6c0b306d1733,DISK], DatanodeInfoWithStorage[127.0.0.1:37237,DS-63968e5c-b079-42fe-954e-52eda52f8e49,DISK], DatanodeInfoWithStorage[127.0.0.1:39125,DS-effad0b2-9894-433a-b3d4-a7d349fb908c,DISK], DatanodeInfoWithStorage[127.0.0.1:44859,DS-87f1d2e1-a51a-4e2d-a506-efd3334154c9,DISK], DatanodeInfoWithStorage[127.0.0.1:42716,DS-31ae4d0f-6324-451d-8fe2-332c8d1aed48,DISK], DatanodeInfoWithStorage[127.0.0.1:45833,DS-58a8430d-bb41-4c9e-b639-5cb1a8521c5a,DISK], DatanodeInfoWithStorage[127.0.0.1:44735,DS-48790ba5-1528-45ca-a3be-a8670127c21e,DISK], DatanodeInfoWithStorage[127.0.0.1:43458,DS-19921a21-033d-489a-8b5a-53cb7a2cf312,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2064848632-172.17.0.10-1598095075268:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46530,DS-88ca7415-091f-478f-9afe-6c0b306d1733,DISK], DatanodeInfoWithStorage[127.0.0.1:37237,DS-63968e5c-b079-42fe-954e-52eda52f8e49,DISK], DatanodeInfoWithStorage[127.0.0.1:39125,DS-effad0b2-9894-433a-b3d4-a7d349fb908c,DISK], DatanodeInfoWithStorage[127.0.0.1:44859,DS-87f1d2e1-a51a-4e2d-a506-efd3334154c9,DISK], DatanodeInfoWithStorage[127.0.0.1:42716,DS-31ae4d0f-6324-451d-8fe2-332c8d1aed48,DISK], DatanodeInfoWithStorage[127.0.0.1:45833,DS-58a8430d-bb41-4c9e-b639-5cb1a8521c5a,DISK], DatanodeInfoWithStorage[127.0.0.1:44735,DS-48790ba5-1528-45ca-a3be-a8670127c21e,DISK], DatanodeInfoWithStorage[127.0.0.1:43458,DS-19921a21-033d-489a-8b5a-53cb7a2cf312,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2040329907-172.17.0.10-1598095109729:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39667,DS-1db115fc-1609-4c69-8031-c0c247215a80,DISK], DatanodeInfoWithStorage[127.0.0.1:37062,DS-7a51c19b-2653-462f-9cfe-17cde595e93d,DISK], DatanodeInfoWithStorage[127.0.0.1:41618,DS-f6d41d0a-c293-45d2-bbd8-a6ba0af4e019,DISK], DatanodeInfoWithStorage[127.0.0.1:41167,DS-71a0674f-1767-4a50-b3e5-3f70ccf46459,DISK], DatanodeInfoWithStorage[127.0.0.1:34200,DS-2ebcdeac-1145-4230-b4d7-c0e7c292df1f,DISK], DatanodeInfoWithStorage[127.0.0.1:38869,DS-2366467f-c0f6-4e9f-83ea-309bb23f2787,DISK], DatanodeInfoWithStorage[127.0.0.1:42515,DS-f8e021c8-dfec-4701-82b5-46a98bc6aa8d,DISK], DatanodeInfoWithStorage[127.0.0.1:40137,DS-fb8262a7-e9f7-4e3c-9df9-ff516412f928,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2040329907-172.17.0.10-1598095109729:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39667,DS-1db115fc-1609-4c69-8031-c0c247215a80,DISK], DatanodeInfoWithStorage[127.0.0.1:37062,DS-7a51c19b-2653-462f-9cfe-17cde595e93d,DISK], DatanodeInfoWithStorage[127.0.0.1:41618,DS-f6d41d0a-c293-45d2-bbd8-a6ba0af4e019,DISK], DatanodeInfoWithStorage[127.0.0.1:41167,DS-71a0674f-1767-4a50-b3e5-3f70ccf46459,DISK], DatanodeInfoWithStorage[127.0.0.1:34200,DS-2ebcdeac-1145-4230-b4d7-c0e7c292df1f,DISK], DatanodeInfoWithStorage[127.0.0.1:38869,DS-2366467f-c0f6-4e9f-83ea-309bb23f2787,DISK], DatanodeInfoWithStorage[127.0.0.1:42515,DS-f8e021c8-dfec-4701-82b5-46a98bc6aa8d,DISK], DatanodeInfoWithStorage[127.0.0.1:40137,DS-fb8262a7-e9f7-4e3c-9df9-ff516412f928,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-152241056-172.17.0.10-1598095177497:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38500,DS-68d74f68-a2b4-4b94-8e02-71c146449d6c,DISK], DatanodeInfoWithStorage[127.0.0.1:40637,DS-132f8cc5-ac6d-442e-bc8f-2d47d13dcbe3,DISK], DatanodeInfoWithStorage[127.0.0.1:40501,DS-d0a808a8-20f7-4aad-a626-40b5ad45c8f9,DISK], DatanodeInfoWithStorage[127.0.0.1:38637,DS-913714be-3673-41e4-88c0-12cae4bb9361,DISK], DatanodeInfoWithStorage[127.0.0.1:38404,DS-dac0ea13-d979-4a58-9d4d-d2f20af6dc32,DISK], DatanodeInfoWithStorage[127.0.0.1:34785,DS-1c77f66c-1b27-4e70-91d1-01d27b04f6dd,DISK], DatanodeInfoWithStorage[127.0.0.1:41978,DS-7eed52a4-6e6f-422d-97d4-0ac197971787,DISK], DatanodeInfoWithStorage[127.0.0.1:42917,DS-64a28351-5f3c-40eb-b497-174dc1f587b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-152241056-172.17.0.10-1598095177497:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38500,DS-68d74f68-a2b4-4b94-8e02-71c146449d6c,DISK], DatanodeInfoWithStorage[127.0.0.1:40637,DS-132f8cc5-ac6d-442e-bc8f-2d47d13dcbe3,DISK], DatanodeInfoWithStorage[127.0.0.1:40501,DS-d0a808a8-20f7-4aad-a626-40b5ad45c8f9,DISK], DatanodeInfoWithStorage[127.0.0.1:38637,DS-913714be-3673-41e4-88c0-12cae4bb9361,DISK], DatanodeInfoWithStorage[127.0.0.1:38404,DS-dac0ea13-d979-4a58-9d4d-d2f20af6dc32,DISK], DatanodeInfoWithStorage[127.0.0.1:34785,DS-1c77f66c-1b27-4e70-91d1-01d27b04f6dd,DISK], DatanodeInfoWithStorage[127.0.0.1:41978,DS-7eed52a4-6e6f-422d-97d4-0ac197971787,DISK], DatanodeInfoWithStorage[127.0.0.1:42917,DS-64a28351-5f3c-40eb-b497-174dc1f587b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-341083330-172.17.0.10-1598095359221:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45494,DS-708c51c3-4070-4ae7-afd3-60bbb17c8347,DISK], DatanodeInfoWithStorage[127.0.0.1:35712,DS-2c33b653-5190-4cae-9c5b-6059378062f7,DISK], DatanodeInfoWithStorage[127.0.0.1:40477,DS-70b2fdf5-d370-4b5d-ad00-e169dffa29ab,DISK], DatanodeInfoWithStorage[127.0.0.1:41901,DS-189eab1a-f9f9-4570-b98e-c3a0c3443bfc,DISK], DatanodeInfoWithStorage[127.0.0.1:45006,DS-4aa03cd1-b911-45ae-8ba7-1e3588ce3567,DISK], DatanodeInfoWithStorage[127.0.0.1:35079,DS-c09e0fd0-19c2-4c2b-826b-8761416b5f50,DISK], DatanodeInfoWithStorage[127.0.0.1:36526,DS-2bcd46dc-becf-4074-aea0-48e8f501bc45,DISK], DatanodeInfoWithStorage[127.0.0.1:33837,DS-581171f9-c65c-4e72-88c4-cbe9ec998ad9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-341083330-172.17.0.10-1598095359221:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45494,DS-708c51c3-4070-4ae7-afd3-60bbb17c8347,DISK], DatanodeInfoWithStorage[127.0.0.1:35712,DS-2c33b653-5190-4cae-9c5b-6059378062f7,DISK], DatanodeInfoWithStorage[127.0.0.1:40477,DS-70b2fdf5-d370-4b5d-ad00-e169dffa29ab,DISK], DatanodeInfoWithStorage[127.0.0.1:41901,DS-189eab1a-f9f9-4570-b98e-c3a0c3443bfc,DISK], DatanodeInfoWithStorage[127.0.0.1:45006,DS-4aa03cd1-b911-45ae-8ba7-1e3588ce3567,DISK], DatanodeInfoWithStorage[127.0.0.1:35079,DS-c09e0fd0-19c2-4c2b-826b-8761416b5f50,DISK], DatanodeInfoWithStorage[127.0.0.1:36526,DS-2bcd46dc-becf-4074-aea0-48e8f501bc45,DISK], DatanodeInfoWithStorage[127.0.0.1:33837,DS-581171f9-c65c-4e72-88c4-cbe9ec998ad9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-430455652-172.17.0.10-1598095576279:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39112,DS-e968a748-bfbf-4826-9d3e-790643198b0d,DISK], DatanodeInfoWithStorage[127.0.0.1:37919,DS-0a8a0ef2-b1ec-4d05-b194-64f39737263b,DISK], DatanodeInfoWithStorage[127.0.0.1:33435,DS-9a384468-fe8f-4283-b289-11e1fc15fa2b,DISK], DatanodeInfoWithStorage[127.0.0.1:36438,DS-f242df9f-b3db-49e7-9d47-0691c0d91cf8,DISK], DatanodeInfoWithStorage[127.0.0.1:45643,DS-0e8afd42-ac52-45a3-802f-8254e656073e,DISK], DatanodeInfoWithStorage[127.0.0.1:36227,DS-72f04a7c-f471-41ea-9a29-710a9a16a2c3,DISK], DatanodeInfoWithStorage[127.0.0.1:44589,DS-36734aab-5854-4d1d-b9cc-44f017abb89b,DISK], DatanodeInfoWithStorage[127.0.0.1:35441,DS-7d45945e-d03b-43ac-8a19-c2b897571796,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-430455652-172.17.0.10-1598095576279:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39112,DS-e968a748-bfbf-4826-9d3e-790643198b0d,DISK], DatanodeInfoWithStorage[127.0.0.1:37919,DS-0a8a0ef2-b1ec-4d05-b194-64f39737263b,DISK], DatanodeInfoWithStorage[127.0.0.1:33435,DS-9a384468-fe8f-4283-b289-11e1fc15fa2b,DISK], DatanodeInfoWithStorage[127.0.0.1:36438,DS-f242df9f-b3db-49e7-9d47-0691c0d91cf8,DISK], DatanodeInfoWithStorage[127.0.0.1:45643,DS-0e8afd42-ac52-45a3-802f-8254e656073e,DISK], DatanodeInfoWithStorage[127.0.0.1:36227,DS-72f04a7c-f471-41ea-9a29-710a9a16a2c3,DISK], DatanodeInfoWithStorage[127.0.0.1:44589,DS-36734aab-5854-4d1d-b9cc-44f017abb89b,DISK], DatanodeInfoWithStorage[127.0.0.1:35441,DS-7d45945e-d03b-43ac-8a19-c2b897571796,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-638433377-172.17.0.10-1598095624140:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39991,DS-bff1508d-6e50-4060-b625-529ee90ab372,DISK], DatanodeInfoWithStorage[127.0.0.1:37371,DS-d9ab75c8-b9b9-406a-9a74-7eb13a01a12e,DISK], DatanodeInfoWithStorage[127.0.0.1:37444,DS-49b64146-d247-4d64-827f-df5a34737785,DISK], DatanodeInfoWithStorage[127.0.0.1:36184,DS-020231bd-9fb8-4dd7-9576-56484edb1eb3,DISK], DatanodeInfoWithStorage[127.0.0.1:46196,DS-9d2baf13-5260-484d-a48d-d2d0804de707,DISK], DatanodeInfoWithStorage[127.0.0.1:35120,DS-b82ab7f7-ad83-4129-a56f-6274db4c1739,DISK], DatanodeInfoWithStorage[127.0.0.1:41615,DS-f47db6c3-299a-48a9-ae90-f688cd239932,DISK], DatanodeInfoWithStorage[127.0.0.1:38984,DS-242ccfba-7354-4f2b-bee3-439d85458560,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-638433377-172.17.0.10-1598095624140:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39991,DS-bff1508d-6e50-4060-b625-529ee90ab372,DISK], DatanodeInfoWithStorage[127.0.0.1:37371,DS-d9ab75c8-b9b9-406a-9a74-7eb13a01a12e,DISK], DatanodeInfoWithStorage[127.0.0.1:37444,DS-49b64146-d247-4d64-827f-df5a34737785,DISK], DatanodeInfoWithStorage[127.0.0.1:36184,DS-020231bd-9fb8-4dd7-9576-56484edb1eb3,DISK], DatanodeInfoWithStorage[127.0.0.1:46196,DS-9d2baf13-5260-484d-a48d-d2d0804de707,DISK], DatanodeInfoWithStorage[127.0.0.1:35120,DS-b82ab7f7-ad83-4129-a56f-6274db4c1739,DISK], DatanodeInfoWithStorage[127.0.0.1:41615,DS-f47db6c3-299a-48a9-ae90-f688cd239932,DISK], DatanodeInfoWithStorage[127.0.0.1:38984,DS-242ccfba-7354-4f2b-bee3-439d85458560,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-850024428-172.17.0.10-1598096034272:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37358,DS-5a7a2b99-0ce4-4861-b04a-8582beb257db,DISK], DatanodeInfoWithStorage[127.0.0.1:40881,DS-c24a232f-bf74-4f18-a8c1-7fcdea5d55d6,DISK], DatanodeInfoWithStorage[127.0.0.1:40285,DS-522a0088-01cd-46aa-a96c-29b64c4ae973,DISK], DatanodeInfoWithStorage[127.0.0.1:35128,DS-f8de8b30-116a-4faa-8864-8a728d918d09,DISK], DatanodeInfoWithStorage[127.0.0.1:33054,DS-4ac02e69-6be0-41e7-94db-514e6223c851,DISK], DatanodeInfoWithStorage[127.0.0.1:35165,DS-e0ca3110-e078-4874-93fb-8a89ebb42e5e,DISK], DatanodeInfoWithStorage[127.0.0.1:46552,DS-46155c1c-9259-4a78-b3ee-3f157c774dde,DISK], DatanodeInfoWithStorage[127.0.0.1:40043,DS-6c056799-7ba8-41a1-95ed-df5571a07409,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-850024428-172.17.0.10-1598096034272:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37358,DS-5a7a2b99-0ce4-4861-b04a-8582beb257db,DISK], DatanodeInfoWithStorage[127.0.0.1:40881,DS-c24a232f-bf74-4f18-a8c1-7fcdea5d55d6,DISK], DatanodeInfoWithStorage[127.0.0.1:40285,DS-522a0088-01cd-46aa-a96c-29b64c4ae973,DISK], DatanodeInfoWithStorage[127.0.0.1:35128,DS-f8de8b30-116a-4faa-8864-8a728d918d09,DISK], DatanodeInfoWithStorage[127.0.0.1:33054,DS-4ac02e69-6be0-41e7-94db-514e6223c851,DISK], DatanodeInfoWithStorage[127.0.0.1:35165,DS-e0ca3110-e078-4874-93fb-8a89ebb42e5e,DISK], DatanodeInfoWithStorage[127.0.0.1:46552,DS-46155c1c-9259-4a78-b3ee-3f157c774dde,DISK], DatanodeInfoWithStorage[127.0.0.1:40043,DS-6c056799-7ba8-41a1-95ed-df5571a07409,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-12689389-172.17.0.10-1598096293159:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41626,DS-47a45d86-447d-417c-97c7-a09da06263d1,DISK], DatanodeInfoWithStorage[127.0.0.1:42972,DS-71015cee-aead-4126-b037-98d899b3f63f,DISK], DatanodeInfoWithStorage[127.0.0.1:43384,DS-7589b14d-0ac7-464f-8a5d-a6c1e2c2dd03,DISK], DatanodeInfoWithStorage[127.0.0.1:45320,DS-f54726d5-8c69-4e8c-b83d-e8c2eb83b981,DISK], DatanodeInfoWithStorage[127.0.0.1:44380,DS-71f17de6-cd4a-4e84-8cee-1c51cb8ccd15,DISK], DatanodeInfoWithStorage[127.0.0.1:40370,DS-4ccdc2bf-62fe-45a0-b188-30d38d6dd6e9,DISK], DatanodeInfoWithStorage[127.0.0.1:40435,DS-7e40be21-100a-4a9f-9aba-520d6b650de9,DISK], DatanodeInfoWithStorage[127.0.0.1:40984,DS-d0d307e3-3225-4bf8-88b5-725de4136c8c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-12689389-172.17.0.10-1598096293159:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41626,DS-47a45d86-447d-417c-97c7-a09da06263d1,DISK], DatanodeInfoWithStorage[127.0.0.1:42972,DS-71015cee-aead-4126-b037-98d899b3f63f,DISK], DatanodeInfoWithStorage[127.0.0.1:43384,DS-7589b14d-0ac7-464f-8a5d-a6c1e2c2dd03,DISK], DatanodeInfoWithStorage[127.0.0.1:45320,DS-f54726d5-8c69-4e8c-b83d-e8c2eb83b981,DISK], DatanodeInfoWithStorage[127.0.0.1:44380,DS-71f17de6-cd4a-4e84-8cee-1c51cb8ccd15,DISK], DatanodeInfoWithStorage[127.0.0.1:40370,DS-4ccdc2bf-62fe-45a0-b188-30d38d6dd6e9,DISK], DatanodeInfoWithStorage[127.0.0.1:40435,DS-7e40be21-100a-4a9f-9aba-520d6b650de9,DISK], DatanodeInfoWithStorage[127.0.0.1:40984,DS-d0d307e3-3225-4bf8-88b5-725de4136c8c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5246
