reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1152117606-172.17.0.3-1598469677896:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38283,DS-01e9f5c0-1a92-452c-9028-cf33dc348d29,DISK], DatanodeInfoWithStorage[127.0.0.1:38941,DS-6e9b7848-277a-45be-941d-74d9d7897253,DISK], DatanodeInfoWithStorage[127.0.0.1:37994,DS-e530eaff-6b4b-438a-8236-8409ef662bfd,DISK], DatanodeInfoWithStorage[127.0.0.1:41570,DS-053bdb8c-7449-4375-9007-9b3137861ea5,DISK], DatanodeInfoWithStorage[127.0.0.1:35576,DS-3e6f727d-bbb4-4c7d-8460-c8ece4a8e735,DISK], DatanodeInfoWithStorage[127.0.0.1:40009,DS-cf0a9304-338f-4694-a822-e39b5ad5b2f7,DISK], DatanodeInfoWithStorage[127.0.0.1:43324,DS-5af77f11-cdb6-4bb8-b7a0-7cd2a5cb30f8,DISK], DatanodeInfoWithStorage[127.0.0.1:32910,DS-a3e20215-3a59-4506-87df-76df1bcd871e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1152117606-172.17.0.3-1598469677896:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38283,DS-01e9f5c0-1a92-452c-9028-cf33dc348d29,DISK], DatanodeInfoWithStorage[127.0.0.1:38941,DS-6e9b7848-277a-45be-941d-74d9d7897253,DISK], DatanodeInfoWithStorage[127.0.0.1:37994,DS-e530eaff-6b4b-438a-8236-8409ef662bfd,DISK], DatanodeInfoWithStorage[127.0.0.1:41570,DS-053bdb8c-7449-4375-9007-9b3137861ea5,DISK], DatanodeInfoWithStorage[127.0.0.1:35576,DS-3e6f727d-bbb4-4c7d-8460-c8ece4a8e735,DISK], DatanodeInfoWithStorage[127.0.0.1:40009,DS-cf0a9304-338f-4694-a822-e39b5ad5b2f7,DISK], DatanodeInfoWithStorage[127.0.0.1:43324,DS-5af77f11-cdb6-4bb8-b7a0-7cd2a5cb30f8,DISK], DatanodeInfoWithStorage[127.0.0.1:32910,DS-a3e20215-3a59-4506-87df-76df1bcd871e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1585992357-172.17.0.3-1598469864185:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38888,DS-3b5daff4-3dda-4f8e-906f-e8088d70f62e,DISK], DatanodeInfoWithStorage[127.0.0.1:33341,DS-b712e2b3-763d-4f7b-b0c7-2f4485ce0c0a,DISK], DatanodeInfoWithStorage[127.0.0.1:43763,DS-653b8263-7c0b-4714-af1f-a3a301f6665f,DISK], DatanodeInfoWithStorage[127.0.0.1:42922,DS-43e0cb24-d6b9-44e1-9114-ce20545f59ad,DISK], DatanodeInfoWithStorage[127.0.0.1:41860,DS-1f1f7d73-fd58-4ed7-843c-c12774df130e,DISK], DatanodeInfoWithStorage[127.0.0.1:42500,DS-da6e261c-593a-46ca-8e01-17cddd3ddcb4,DISK], DatanodeInfoWithStorage[127.0.0.1:44122,DS-8fda916e-32a7-42f5-9443-a658503f7964,DISK], DatanodeInfoWithStorage[127.0.0.1:39792,DS-4d2a39e8-423a-4dc6-afd2-7d303a887681,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1585992357-172.17.0.3-1598469864185:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38888,DS-3b5daff4-3dda-4f8e-906f-e8088d70f62e,DISK], DatanodeInfoWithStorage[127.0.0.1:33341,DS-b712e2b3-763d-4f7b-b0c7-2f4485ce0c0a,DISK], DatanodeInfoWithStorage[127.0.0.1:43763,DS-653b8263-7c0b-4714-af1f-a3a301f6665f,DISK], DatanodeInfoWithStorage[127.0.0.1:42922,DS-43e0cb24-d6b9-44e1-9114-ce20545f59ad,DISK], DatanodeInfoWithStorage[127.0.0.1:41860,DS-1f1f7d73-fd58-4ed7-843c-c12774df130e,DISK], DatanodeInfoWithStorage[127.0.0.1:42500,DS-da6e261c-593a-46ca-8e01-17cddd3ddcb4,DISK], DatanodeInfoWithStorage[127.0.0.1:44122,DS-8fda916e-32a7-42f5-9443-a658503f7964,DISK], DatanodeInfoWithStorage[127.0.0.1:39792,DS-4d2a39e8-423a-4dc6-afd2-7d303a887681,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1080659096-172.17.0.3-1598470225349:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44366,DS-d2368b7d-89c7-4331-be58-9e20dbcdf061,DISK], DatanodeInfoWithStorage[127.0.0.1:45552,DS-e6a7060a-7bf1-4ae6-b3bc-65bdfbd2c449,DISK], DatanodeInfoWithStorage[127.0.0.1:37498,DS-cb16bf95-e12e-470f-a40a-0e8275c87509,DISK], DatanodeInfoWithStorage[127.0.0.1:42711,DS-5365a2c5-4b05-4163-b089-47cf9f765aec,DISK], DatanodeInfoWithStorage[127.0.0.1:44600,DS-ca98d3d4-a31d-4448-8100-25addfaeb163,DISK], DatanodeInfoWithStorage[127.0.0.1:34724,DS-849ef474-7bc5-4fcf-9fd5-4b6b76db40e4,DISK], DatanodeInfoWithStorage[127.0.0.1:42112,DS-3410e5df-ee0a-427a-82a7-f877c46f52cf,DISK], DatanodeInfoWithStorage[127.0.0.1:35216,DS-cdbcfbd0-99dc-466a-bd22-792b58e38d6b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1080659096-172.17.0.3-1598470225349:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44366,DS-d2368b7d-89c7-4331-be58-9e20dbcdf061,DISK], DatanodeInfoWithStorage[127.0.0.1:45552,DS-e6a7060a-7bf1-4ae6-b3bc-65bdfbd2c449,DISK], DatanodeInfoWithStorage[127.0.0.1:37498,DS-cb16bf95-e12e-470f-a40a-0e8275c87509,DISK], DatanodeInfoWithStorage[127.0.0.1:42711,DS-5365a2c5-4b05-4163-b089-47cf9f765aec,DISK], DatanodeInfoWithStorage[127.0.0.1:44600,DS-ca98d3d4-a31d-4448-8100-25addfaeb163,DISK], DatanodeInfoWithStorage[127.0.0.1:34724,DS-849ef474-7bc5-4fcf-9fd5-4b6b76db40e4,DISK], DatanodeInfoWithStorage[127.0.0.1:42112,DS-3410e5df-ee0a-427a-82a7-f877c46f52cf,DISK], DatanodeInfoWithStorage[127.0.0.1:35216,DS-cdbcfbd0-99dc-466a-bd22-792b58e38d6b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-320965568-172.17.0.3-1598470897268:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35786,DS-1ddb5578-32d1-4566-9869-783a0f0795fa,DISK], DatanodeInfoWithStorage[127.0.0.1:43821,DS-40d0c3c2-33b6-44f4-bcd6-db77c0773bf8,DISK], DatanodeInfoWithStorage[127.0.0.1:33475,DS-cad5f916-4019-4139-9d6e-a7430d2d3e46,DISK], DatanodeInfoWithStorage[127.0.0.1:36912,DS-4523aca4-fca8-4282-9277-f0c5d4005ee4,DISK], DatanodeInfoWithStorage[127.0.0.1:33724,DS-5713989a-837f-402e-a1da-5f5cc19cb00e,DISK], DatanodeInfoWithStorage[127.0.0.1:41615,DS-c2a7fc1d-e582-4d24-a660-87e88a2c3fb6,DISK], DatanodeInfoWithStorage[127.0.0.1:34239,DS-c39bb47e-348f-49fe-9599-9bce72d323cc,DISK], DatanodeInfoWithStorage[127.0.0.1:40052,DS-ca4c4528-ac0b-49d9-91f4-798881cc5206,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-320965568-172.17.0.3-1598470897268:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35786,DS-1ddb5578-32d1-4566-9869-783a0f0795fa,DISK], DatanodeInfoWithStorage[127.0.0.1:43821,DS-40d0c3c2-33b6-44f4-bcd6-db77c0773bf8,DISK], DatanodeInfoWithStorage[127.0.0.1:33475,DS-cad5f916-4019-4139-9d6e-a7430d2d3e46,DISK], DatanodeInfoWithStorage[127.0.0.1:36912,DS-4523aca4-fca8-4282-9277-f0c5d4005ee4,DISK], DatanodeInfoWithStorage[127.0.0.1:33724,DS-5713989a-837f-402e-a1da-5f5cc19cb00e,DISK], DatanodeInfoWithStorage[127.0.0.1:41615,DS-c2a7fc1d-e582-4d24-a660-87e88a2c3fb6,DISK], DatanodeInfoWithStorage[127.0.0.1:34239,DS-c39bb47e-348f-49fe-9599-9bce72d323cc,DISK], DatanodeInfoWithStorage[127.0.0.1:40052,DS-ca4c4528-ac0b-49d9-91f4-798881cc5206,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1379947474-172.17.0.3-1598470946038:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39594,DS-c5d84fb4-c7e6-4fad-8205-9454e4ba99c0,DISK], DatanodeInfoWithStorage[127.0.0.1:44819,DS-60cadd62-f6af-41ee-98de-5115fd98436b,DISK], DatanodeInfoWithStorage[127.0.0.1:42836,DS-8d935396-d962-4386-832f-fb6053fe6934,DISK], DatanodeInfoWithStorage[127.0.0.1:45051,DS-ad74705d-c529-484c-903b-2dfb18412a7c,DISK], DatanodeInfoWithStorage[127.0.0.1:39003,DS-984f703f-ef8a-4bc8-a97c-8a090434ee98,DISK], DatanodeInfoWithStorage[127.0.0.1:39441,DS-434e8217-7a94-44ee-8660-beaef335de4d,DISK], DatanodeInfoWithStorage[127.0.0.1:37611,DS-be979994-35a7-4f2a-a061-f205adb8a0dd,DISK], DatanodeInfoWithStorage[127.0.0.1:36494,DS-8623b73d-0740-4d2e-bf88-9b3a0ae91c96,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1379947474-172.17.0.3-1598470946038:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39594,DS-c5d84fb4-c7e6-4fad-8205-9454e4ba99c0,DISK], DatanodeInfoWithStorage[127.0.0.1:44819,DS-60cadd62-f6af-41ee-98de-5115fd98436b,DISK], DatanodeInfoWithStorage[127.0.0.1:42836,DS-8d935396-d962-4386-832f-fb6053fe6934,DISK], DatanodeInfoWithStorage[127.0.0.1:45051,DS-ad74705d-c529-484c-903b-2dfb18412a7c,DISK], DatanodeInfoWithStorage[127.0.0.1:39003,DS-984f703f-ef8a-4bc8-a97c-8a090434ee98,DISK], DatanodeInfoWithStorage[127.0.0.1:39441,DS-434e8217-7a94-44ee-8660-beaef335de4d,DISK], DatanodeInfoWithStorage[127.0.0.1:37611,DS-be979994-35a7-4f2a-a061-f205adb8a0dd,DISK], DatanodeInfoWithStorage[127.0.0.1:36494,DS-8623b73d-0740-4d2e-bf88-9b3a0ae91c96,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1748785073-172.17.0.3-1598471012511:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41677,DS-27bfb2b7-c756-49ed-8fb1-b510edcfd6d3,DISK], DatanodeInfoWithStorage[127.0.0.1:33712,DS-e82d1565-db74-4ae9-80da-d760592d12e9,DISK], DatanodeInfoWithStorage[127.0.0.1:34649,DS-da931f07-fcfc-4cf8-85d9-2f1ca4f76f0c,DISK], DatanodeInfoWithStorage[127.0.0.1:40837,DS-79be2cb6-f16c-49dd-bbe5-2d72af228df1,DISK], DatanodeInfoWithStorage[127.0.0.1:38507,DS-be0fa064-3f98-4414-b3c9-da64101f99a2,DISK], DatanodeInfoWithStorage[127.0.0.1:36177,DS-ec0b0104-4a97-4e10-8b11-136a67f66ebf,DISK], DatanodeInfoWithStorage[127.0.0.1:45054,DS-cd8d98d2-34c4-4954-846e-d4b3ee728717,DISK], DatanodeInfoWithStorage[127.0.0.1:39895,DS-500a9380-4d2d-4aeb-a00d-45940cb38679,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1748785073-172.17.0.3-1598471012511:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41677,DS-27bfb2b7-c756-49ed-8fb1-b510edcfd6d3,DISK], DatanodeInfoWithStorage[127.0.0.1:33712,DS-e82d1565-db74-4ae9-80da-d760592d12e9,DISK], DatanodeInfoWithStorage[127.0.0.1:34649,DS-da931f07-fcfc-4cf8-85d9-2f1ca4f76f0c,DISK], DatanodeInfoWithStorage[127.0.0.1:40837,DS-79be2cb6-f16c-49dd-bbe5-2d72af228df1,DISK], DatanodeInfoWithStorage[127.0.0.1:38507,DS-be0fa064-3f98-4414-b3c9-da64101f99a2,DISK], DatanodeInfoWithStorage[127.0.0.1:36177,DS-ec0b0104-4a97-4e10-8b11-136a67f66ebf,DISK], DatanodeInfoWithStorage[127.0.0.1:45054,DS-cd8d98d2-34c4-4954-846e-d4b3ee728717,DISK], DatanodeInfoWithStorage[127.0.0.1:39895,DS-500a9380-4d2d-4aeb-a00d-45940cb38679,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1041615361-172.17.0.3-1598471028952:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40400,DS-347de93d-b531-4fb1-9bf4-efdf5c530b5e,DISK], DatanodeInfoWithStorage[127.0.0.1:41433,DS-241be298-a970-45ef-9f7f-7df96f24a513,DISK], DatanodeInfoWithStorage[127.0.0.1:46792,DS-2b691a37-16b9-4aba-b5d5-7c17d5cc411f,DISK], DatanodeInfoWithStorage[127.0.0.1:43450,DS-4309e23f-7e66-43bd-9e5e-ad6276be03c5,DISK], DatanodeInfoWithStorage[127.0.0.1:36754,DS-1e90f68e-7319-4a93-b563-73d19ea198f5,DISK], DatanodeInfoWithStorage[127.0.0.1:34516,DS-33cb5462-aa65-4976-9a66-0ebb273e026a,DISK], DatanodeInfoWithStorage[127.0.0.1:41073,DS-6163eb08-f4c6-4758-96ec-0583a1fadc2b,DISK], DatanodeInfoWithStorage[127.0.0.1:41373,DS-ea294ce5-6325-414f-8634-eabb58cc3aaf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1041615361-172.17.0.3-1598471028952:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40400,DS-347de93d-b531-4fb1-9bf4-efdf5c530b5e,DISK], DatanodeInfoWithStorage[127.0.0.1:41433,DS-241be298-a970-45ef-9f7f-7df96f24a513,DISK], DatanodeInfoWithStorage[127.0.0.1:46792,DS-2b691a37-16b9-4aba-b5d5-7c17d5cc411f,DISK], DatanodeInfoWithStorage[127.0.0.1:43450,DS-4309e23f-7e66-43bd-9e5e-ad6276be03c5,DISK], DatanodeInfoWithStorage[127.0.0.1:36754,DS-1e90f68e-7319-4a93-b563-73d19ea198f5,DISK], DatanodeInfoWithStorage[127.0.0.1:34516,DS-33cb5462-aa65-4976-9a66-0ebb273e026a,DISK], DatanodeInfoWithStorage[127.0.0.1:41073,DS-6163eb08-f4c6-4758-96ec-0583a1fadc2b,DISK], DatanodeInfoWithStorage[127.0.0.1:41373,DS-ea294ce5-6325-414f-8634-eabb58cc3aaf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1033474666-172.17.0.3-1598471459088:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40136,DS-9cacfc4e-ba34-4fb0-af35-4d8e86ae8fac,DISK], DatanodeInfoWithStorage[127.0.0.1:44392,DS-bfd28e19-260e-4f98-9576-2745c62a7e38,DISK], DatanodeInfoWithStorage[127.0.0.1:33497,DS-44a2d2f9-711d-4967-8cbe-020eaa8332cb,DISK], DatanodeInfoWithStorage[127.0.0.1:34306,DS-7973f987-6f88-484b-ad01-3d35fdf01746,DISK], DatanodeInfoWithStorage[127.0.0.1:46243,DS-5d34eebb-2be7-4346-a68b-a055bcdbea57,DISK], DatanodeInfoWithStorage[127.0.0.1:33159,DS-a1ed4243-f8b5-4718-862f-e0ecc41e8516,DISK], DatanodeInfoWithStorage[127.0.0.1:39490,DS-3eb1bdba-2271-402f-93c8-3c2488bb9b55,DISK], DatanodeInfoWithStorage[127.0.0.1:42029,DS-dc2c30f0-8e53-44da-9f27-5c607ab6ca34,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1033474666-172.17.0.3-1598471459088:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40136,DS-9cacfc4e-ba34-4fb0-af35-4d8e86ae8fac,DISK], DatanodeInfoWithStorage[127.0.0.1:44392,DS-bfd28e19-260e-4f98-9576-2745c62a7e38,DISK], DatanodeInfoWithStorage[127.0.0.1:33497,DS-44a2d2f9-711d-4967-8cbe-020eaa8332cb,DISK], DatanodeInfoWithStorage[127.0.0.1:34306,DS-7973f987-6f88-484b-ad01-3d35fdf01746,DISK], DatanodeInfoWithStorage[127.0.0.1:46243,DS-5d34eebb-2be7-4346-a68b-a055bcdbea57,DISK], DatanodeInfoWithStorage[127.0.0.1:33159,DS-a1ed4243-f8b5-4718-862f-e0ecc41e8516,DISK], DatanodeInfoWithStorage[127.0.0.1:39490,DS-3eb1bdba-2271-402f-93c8-3c2488bb9b55,DISK], DatanodeInfoWithStorage[127.0.0.1:42029,DS-dc2c30f0-8e53-44da-9f27-5c607ab6ca34,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-631465402-172.17.0.3-1598471688711:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45862,DS-ef988591-0a2b-4c98-b0dd-e06c28345d5d,DISK], DatanodeInfoWithStorage[127.0.0.1:43270,DS-79a8f0c9-8fe9-44d0-9847-ef2812b47bae,DISK], DatanodeInfoWithStorage[127.0.0.1:43578,DS-9dd57a3f-c927-487b-9487-34f6d10bc6b8,DISK], DatanodeInfoWithStorage[127.0.0.1:33675,DS-3e2538ec-51da-4783-96a9-92b654a8c7d9,DISK], DatanodeInfoWithStorage[127.0.0.1:44275,DS-13f4f7b9-3df8-4257-b6df-486e40cbafb8,DISK], DatanodeInfoWithStorage[127.0.0.1:34737,DS-dd2dc79d-a6bf-4d40-b78e-945cb85838b4,DISK], DatanodeInfoWithStorage[127.0.0.1:36087,DS-8d2e89f9-f6bd-4d8d-9612-d7af9ed9d80c,DISK], DatanodeInfoWithStorage[127.0.0.1:45653,DS-b11d430a-92b1-4d94-a836-c915c49dae82,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-631465402-172.17.0.3-1598471688711:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45862,DS-ef988591-0a2b-4c98-b0dd-e06c28345d5d,DISK], DatanodeInfoWithStorage[127.0.0.1:43270,DS-79a8f0c9-8fe9-44d0-9847-ef2812b47bae,DISK], DatanodeInfoWithStorage[127.0.0.1:43578,DS-9dd57a3f-c927-487b-9487-34f6d10bc6b8,DISK], DatanodeInfoWithStorage[127.0.0.1:33675,DS-3e2538ec-51da-4783-96a9-92b654a8c7d9,DISK], DatanodeInfoWithStorage[127.0.0.1:44275,DS-13f4f7b9-3df8-4257-b6df-486e40cbafb8,DISK], DatanodeInfoWithStorage[127.0.0.1:34737,DS-dd2dc79d-a6bf-4d40-b78e-945cb85838b4,DISK], DatanodeInfoWithStorage[127.0.0.1:36087,DS-8d2e89f9-f6bd-4d8d-9612-d7af9ed9d80c,DISK], DatanodeInfoWithStorage[127.0.0.1:45653,DS-b11d430a-92b1-4d94-a836-c915c49dae82,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1366665477-172.17.0.3-1598471705307:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44257,DS-36b652e6-600b-40cb-b7f6-0fe7303dccaf,DISK], DatanodeInfoWithStorage[127.0.0.1:44452,DS-86e4d92f-2d55-413f-94c0-bbddefcb0bcf,DISK], DatanodeInfoWithStorage[127.0.0.1:38651,DS-c6973dc3-10d0-432d-a3b1-c0903baadf54,DISK], DatanodeInfoWithStorage[127.0.0.1:41208,DS-6a9d1d41-7870-44dc-8992-96605bdbb7a7,DISK], DatanodeInfoWithStorage[127.0.0.1:36020,DS-1a562e24-50f9-417f-925d-60702077be36,DISK], DatanodeInfoWithStorage[127.0.0.1:33903,DS-187650a8-b0fc-47f7-8098-1c7cdfe8f323,DISK], DatanodeInfoWithStorage[127.0.0.1:37652,DS-fc958faa-8602-4486-a182-ffe6a81ceb24,DISK], DatanodeInfoWithStorage[127.0.0.1:34793,DS-b74eb9b2-9769-44bc-b820-d34811efffe9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1366665477-172.17.0.3-1598471705307:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44257,DS-36b652e6-600b-40cb-b7f6-0fe7303dccaf,DISK], DatanodeInfoWithStorage[127.0.0.1:44452,DS-86e4d92f-2d55-413f-94c0-bbddefcb0bcf,DISK], DatanodeInfoWithStorage[127.0.0.1:38651,DS-c6973dc3-10d0-432d-a3b1-c0903baadf54,DISK], DatanodeInfoWithStorage[127.0.0.1:41208,DS-6a9d1d41-7870-44dc-8992-96605bdbb7a7,DISK], DatanodeInfoWithStorage[127.0.0.1:36020,DS-1a562e24-50f9-417f-925d-60702077be36,DISK], DatanodeInfoWithStorage[127.0.0.1:33903,DS-187650a8-b0fc-47f7-8098-1c7cdfe8f323,DISK], DatanodeInfoWithStorage[127.0.0.1:37652,DS-fc958faa-8602-4486-a182-ffe6a81ceb24,DISK], DatanodeInfoWithStorage[127.0.0.1:34793,DS-b74eb9b2-9769-44bc-b820-d34811efffe9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1260415413-172.17.0.3-1598471721292:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35524,DS-fd9f58a3-8739-4171-b7f2-cca58b1468d3,DISK], DatanodeInfoWithStorage[127.0.0.1:43143,DS-3a7e643d-eccb-41fa-8a5c-3d5f238f45dd,DISK], DatanodeInfoWithStorage[127.0.0.1:33029,DS-9bbc2bc8-657c-4808-8fad-e15da115023f,DISK], DatanodeInfoWithStorage[127.0.0.1:45891,DS-e48ee846-56e8-434b-836f-caa9647df19e,DISK], DatanodeInfoWithStorage[127.0.0.1:43745,DS-184da49b-554c-4bf7-af05-1aab16462c70,DISK], DatanodeInfoWithStorage[127.0.0.1:45990,DS-a4931675-026f-498c-9010-1ab1fa83e35c,DISK], DatanodeInfoWithStorage[127.0.0.1:35072,DS-df88b310-5156-4768-8fbe-80536ec1c3cf,DISK], DatanodeInfoWithStorage[127.0.0.1:46646,DS-923fd1ba-abb9-40a5-8ef5-87bdeee3b34d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1260415413-172.17.0.3-1598471721292:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35524,DS-fd9f58a3-8739-4171-b7f2-cca58b1468d3,DISK], DatanodeInfoWithStorage[127.0.0.1:43143,DS-3a7e643d-eccb-41fa-8a5c-3d5f238f45dd,DISK], DatanodeInfoWithStorage[127.0.0.1:33029,DS-9bbc2bc8-657c-4808-8fad-e15da115023f,DISK], DatanodeInfoWithStorage[127.0.0.1:45891,DS-e48ee846-56e8-434b-836f-caa9647df19e,DISK], DatanodeInfoWithStorage[127.0.0.1:43745,DS-184da49b-554c-4bf7-af05-1aab16462c70,DISK], DatanodeInfoWithStorage[127.0.0.1:45990,DS-a4931675-026f-498c-9010-1ab1fa83e35c,DISK], DatanodeInfoWithStorage[127.0.0.1:35072,DS-df88b310-5156-4768-8fbe-80536ec1c3cf,DISK], DatanodeInfoWithStorage[127.0.0.1:46646,DS-923fd1ba-abb9-40a5-8ef5-87bdeee3b34d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1510594219-172.17.0.3-1598471852541:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44093,DS-70d0f2db-4a57-45b1-98e4-8ed0021791f7,DISK], DatanodeInfoWithStorage[127.0.0.1:36948,DS-99580105-251e-4190-815c-6d8f6c1b5b0c,DISK], DatanodeInfoWithStorage[127.0.0.1:34800,DS-16cd8915-b7e7-47ea-aeb5-c75053eeb77d,DISK], DatanodeInfoWithStorage[127.0.0.1:43978,DS-9934a5ba-d20b-4dbb-b080-69284a386900,DISK], DatanodeInfoWithStorage[127.0.0.1:46345,DS-06408c22-7d2c-4538-9788-0f9ddaeef49a,DISK], DatanodeInfoWithStorage[127.0.0.1:35022,DS-97c50bea-1c39-4452-9fb6-4a95296e98f2,DISK], DatanodeInfoWithStorage[127.0.0.1:38132,DS-e785aaea-a222-44b2-875b-d4e45521fb02,DISK], DatanodeInfoWithStorage[127.0.0.1:40767,DS-bb1c280c-3bcc-4720-9fa8-ac31b58136c5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1510594219-172.17.0.3-1598471852541:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44093,DS-70d0f2db-4a57-45b1-98e4-8ed0021791f7,DISK], DatanodeInfoWithStorage[127.0.0.1:36948,DS-99580105-251e-4190-815c-6d8f6c1b5b0c,DISK], DatanodeInfoWithStorage[127.0.0.1:34800,DS-16cd8915-b7e7-47ea-aeb5-c75053eeb77d,DISK], DatanodeInfoWithStorage[127.0.0.1:43978,DS-9934a5ba-d20b-4dbb-b080-69284a386900,DISK], DatanodeInfoWithStorage[127.0.0.1:46345,DS-06408c22-7d2c-4538-9788-0f9ddaeef49a,DISK], DatanodeInfoWithStorage[127.0.0.1:35022,DS-97c50bea-1c39-4452-9fb6-4a95296e98f2,DISK], DatanodeInfoWithStorage[127.0.0.1:38132,DS-e785aaea-a222-44b2-875b-d4e45521fb02,DISK], DatanodeInfoWithStorage[127.0.0.1:40767,DS-bb1c280c-3bcc-4720-9fa8-ac31b58136c5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1861273676-172.17.0.3-1598471918584:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41035,DS-595f1bff-66fc-49c1-9479-f308b83b20f3,DISK], DatanodeInfoWithStorage[127.0.0.1:46297,DS-bd0c9fb2-5817-464f-a317-50217a53f7fb,DISK], DatanodeInfoWithStorage[127.0.0.1:35226,DS-591cb95e-ddea-419d-8d83-98b48874de44,DISK], DatanodeInfoWithStorage[127.0.0.1:34109,DS-56c3dffa-7301-437f-b88a-353989c55dcd,DISK], DatanodeInfoWithStorage[127.0.0.1:36551,DS-a5960dac-4cdd-455c-8c00-6ea3c44bfc60,DISK], DatanodeInfoWithStorage[127.0.0.1:39327,DS-8de1da10-eb3b-4b1b-8510-51671bf9aec8,DISK], DatanodeInfoWithStorage[127.0.0.1:36373,DS-6cb19745-c30c-4069-bf6b-8bd16d4ca7a2,DISK], DatanodeInfoWithStorage[127.0.0.1:43540,DS-797bbc88-af77-404d-8721-1372dbabf285,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1861273676-172.17.0.3-1598471918584:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41035,DS-595f1bff-66fc-49c1-9479-f308b83b20f3,DISK], DatanodeInfoWithStorage[127.0.0.1:46297,DS-bd0c9fb2-5817-464f-a317-50217a53f7fb,DISK], DatanodeInfoWithStorage[127.0.0.1:35226,DS-591cb95e-ddea-419d-8d83-98b48874de44,DISK], DatanodeInfoWithStorage[127.0.0.1:34109,DS-56c3dffa-7301-437f-b88a-353989c55dcd,DISK], DatanodeInfoWithStorage[127.0.0.1:36551,DS-a5960dac-4cdd-455c-8c00-6ea3c44bfc60,DISK], DatanodeInfoWithStorage[127.0.0.1:39327,DS-8de1da10-eb3b-4b1b-8510-51671bf9aec8,DISK], DatanodeInfoWithStorage[127.0.0.1:36373,DS-6cb19745-c30c-4069-bf6b-8bd16d4ca7a2,DISK], DatanodeInfoWithStorage[127.0.0.1:43540,DS-797bbc88-af77-404d-8721-1372dbabf285,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-826735325-172.17.0.3-1598471968001:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35014,DS-42032880-eeb4-4dd0-a1de-bccbf56109ad,DISK], DatanodeInfoWithStorage[127.0.0.1:45821,DS-89950799-a12f-496d-9212-cac0f035f36c,DISK], DatanodeInfoWithStorage[127.0.0.1:38334,DS-2ea88058-7208-49d2-880e-edddc20e4194,DISK], DatanodeInfoWithStorage[127.0.0.1:39277,DS-382955d3-7016-4fbf-ae4e-325fc1e07c5b,DISK], DatanodeInfoWithStorage[127.0.0.1:32801,DS-f2d8fa3d-bc4e-4f34-a16e-37b0b5e0a8fc,DISK], DatanodeInfoWithStorage[127.0.0.1:43281,DS-89041379-0457-4a33-8d42-a81d55a6c5d5,DISK], DatanodeInfoWithStorage[127.0.0.1:44906,DS-a59edc47-588f-4451-bb3e-26372eedf952,DISK], DatanodeInfoWithStorage[127.0.0.1:34116,DS-62359be4-ff35-4b07-a889-f52a827985d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-826735325-172.17.0.3-1598471968001:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35014,DS-42032880-eeb4-4dd0-a1de-bccbf56109ad,DISK], DatanodeInfoWithStorage[127.0.0.1:45821,DS-89950799-a12f-496d-9212-cac0f035f36c,DISK], DatanodeInfoWithStorage[127.0.0.1:38334,DS-2ea88058-7208-49d2-880e-edddc20e4194,DISK], DatanodeInfoWithStorage[127.0.0.1:39277,DS-382955d3-7016-4fbf-ae4e-325fc1e07c5b,DISK], DatanodeInfoWithStorage[127.0.0.1:32801,DS-f2d8fa3d-bc4e-4f34-a16e-37b0b5e0a8fc,DISK], DatanodeInfoWithStorage[127.0.0.1:43281,DS-89041379-0457-4a33-8d42-a81d55a6c5d5,DISK], DatanodeInfoWithStorage[127.0.0.1:44906,DS-a59edc47-588f-4451-bb3e-26372eedf952,DISK], DatanodeInfoWithStorage[127.0.0.1:34116,DS-62359be4-ff35-4b07-a889-f52a827985d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 2621
