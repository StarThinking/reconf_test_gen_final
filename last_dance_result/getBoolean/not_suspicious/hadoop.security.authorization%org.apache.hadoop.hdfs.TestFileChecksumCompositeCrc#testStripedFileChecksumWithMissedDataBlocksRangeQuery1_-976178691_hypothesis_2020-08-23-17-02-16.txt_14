reconf_parameter: hadoop.security.authorization
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2128292346-172.17.0.2-1598202255580:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40945,DS-1015533c-af56-40d8-a098-e4d5bab42f40,DISK], DatanodeInfoWithStorage[127.0.0.1:38325,DS-c42b2cba-1c71-4a64-acee-9ee94e2354d3,DISK], DatanodeInfoWithStorage[127.0.0.1:43777,DS-1eb464bb-92e2-479d-a459-25b295d3496c,DISK], DatanodeInfoWithStorage[127.0.0.1:33388,DS-2daf6391-5323-4761-a0ca-eb1fa8e55869,DISK], DatanodeInfoWithStorage[127.0.0.1:33092,DS-15e73ce8-e39d-4bbb-acdd-773348529e38,DISK], DatanodeInfoWithStorage[127.0.0.1:43483,DS-e46c61b8-a7ce-4708-97ab-6256e29f0e8c,DISK], DatanodeInfoWithStorage[127.0.0.1:33310,DS-4f731b29-6603-4cd9-8796-c35835edbeb7,DISK], DatanodeInfoWithStorage[127.0.0.1:43150,DS-eec570cb-54c2-4c15-82ab-c9b270b1f6ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2128292346-172.17.0.2-1598202255580:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40945,DS-1015533c-af56-40d8-a098-e4d5bab42f40,DISK], DatanodeInfoWithStorage[127.0.0.1:38325,DS-c42b2cba-1c71-4a64-acee-9ee94e2354d3,DISK], DatanodeInfoWithStorage[127.0.0.1:43777,DS-1eb464bb-92e2-479d-a459-25b295d3496c,DISK], DatanodeInfoWithStorage[127.0.0.1:33388,DS-2daf6391-5323-4761-a0ca-eb1fa8e55869,DISK], DatanodeInfoWithStorage[127.0.0.1:33092,DS-15e73ce8-e39d-4bbb-acdd-773348529e38,DISK], DatanodeInfoWithStorage[127.0.0.1:43483,DS-e46c61b8-a7ce-4708-97ab-6256e29f0e8c,DISK], DatanodeInfoWithStorage[127.0.0.1:33310,DS-4f731b29-6603-4cd9-8796-c35835edbeb7,DISK], DatanodeInfoWithStorage[127.0.0.1:43150,DS-eec570cb-54c2-4c15-82ab-c9b270b1f6ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-492344557-172.17.0.2-1598202567600:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45042,DS-e85f3196-d945-40cc-9087-33e618764943,DISK], DatanodeInfoWithStorage[127.0.0.1:44180,DS-2aa75319-e572-41d4-a60f-a123e56dfdb1,DISK], DatanodeInfoWithStorage[127.0.0.1:43213,DS-57a7e316-ec65-450e-86b7-5f4cf2c5780a,DISK], DatanodeInfoWithStorage[127.0.0.1:33525,DS-a91cf1da-6393-4d70-aa25-75440a39956c,DISK], DatanodeInfoWithStorage[127.0.0.1:37200,DS-66817afd-e11d-4219-8c17-786a319e0736,DISK], DatanodeInfoWithStorage[127.0.0.1:39993,DS-c6d9fefe-377d-46e7-854d-df0d79f2c3f1,DISK], DatanodeInfoWithStorage[127.0.0.1:35610,DS-42cabb9a-1170-43cc-bd15-821c0d360b54,DISK], DatanodeInfoWithStorage[127.0.0.1:35917,DS-852e1f3c-9d95-40ab-9041-cc5d7e479344,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-492344557-172.17.0.2-1598202567600:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45042,DS-e85f3196-d945-40cc-9087-33e618764943,DISK], DatanodeInfoWithStorage[127.0.0.1:44180,DS-2aa75319-e572-41d4-a60f-a123e56dfdb1,DISK], DatanodeInfoWithStorage[127.0.0.1:43213,DS-57a7e316-ec65-450e-86b7-5f4cf2c5780a,DISK], DatanodeInfoWithStorage[127.0.0.1:33525,DS-a91cf1da-6393-4d70-aa25-75440a39956c,DISK], DatanodeInfoWithStorage[127.0.0.1:37200,DS-66817afd-e11d-4219-8c17-786a319e0736,DISK], DatanodeInfoWithStorage[127.0.0.1:39993,DS-c6d9fefe-377d-46e7-854d-df0d79f2c3f1,DISK], DatanodeInfoWithStorage[127.0.0.1:35610,DS-42cabb9a-1170-43cc-bd15-821c0d360b54,DISK], DatanodeInfoWithStorage[127.0.0.1:35917,DS-852e1f3c-9d95-40ab-9041-cc5d7e479344,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-790034778-172.17.0.2-1598202864164:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39501,DS-0ba9bfaa-5c62-46f6-a2e8-d3e90f54ca87,DISK], DatanodeInfoWithStorage[127.0.0.1:42493,DS-8d9ba84d-3dfd-47cb-95f3-0271dbcc49d8,DISK], DatanodeInfoWithStorage[127.0.0.1:35518,DS-b56b5a8c-7f69-48d1-aace-5f0255a4f93e,DISK], DatanodeInfoWithStorage[127.0.0.1:44753,DS-cd9ab8b1-6851-4247-862a-31db007c7967,DISK], DatanodeInfoWithStorage[127.0.0.1:36425,DS-2087f583-932a-4968-8e21-9d1dd791db4d,DISK], DatanodeInfoWithStorage[127.0.0.1:44145,DS-f0088ece-e1f0-4e47-82d5-1270e1bfb1ef,DISK], DatanodeInfoWithStorage[127.0.0.1:45448,DS-c227cf7a-f0c4-4bf6-8107-547a2c918980,DISK], DatanodeInfoWithStorage[127.0.0.1:46650,DS-f1b18633-cea3-4f61-94b6-91c6662ff830,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-790034778-172.17.0.2-1598202864164:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39501,DS-0ba9bfaa-5c62-46f6-a2e8-d3e90f54ca87,DISK], DatanodeInfoWithStorage[127.0.0.1:42493,DS-8d9ba84d-3dfd-47cb-95f3-0271dbcc49d8,DISK], DatanodeInfoWithStorage[127.0.0.1:35518,DS-b56b5a8c-7f69-48d1-aace-5f0255a4f93e,DISK], DatanodeInfoWithStorage[127.0.0.1:44753,DS-cd9ab8b1-6851-4247-862a-31db007c7967,DISK], DatanodeInfoWithStorage[127.0.0.1:36425,DS-2087f583-932a-4968-8e21-9d1dd791db4d,DISK], DatanodeInfoWithStorage[127.0.0.1:44145,DS-f0088ece-e1f0-4e47-82d5-1270e1bfb1ef,DISK], DatanodeInfoWithStorage[127.0.0.1:45448,DS-c227cf7a-f0c4-4bf6-8107-547a2c918980,DISK], DatanodeInfoWithStorage[127.0.0.1:46650,DS-f1b18633-cea3-4f61-94b6-91c6662ff830,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-827419932-172.17.0.2-1598203213403:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36016,DS-895faa8c-08d5-4c0c-bf2c-ab4ba7334ba9,DISK], DatanodeInfoWithStorage[127.0.0.1:41873,DS-c92e0d87-a2f4-4850-8856-75c4cebf795f,DISK], DatanodeInfoWithStorage[127.0.0.1:40306,DS-53de8a31-6a9b-4b90-9ac1-c27702ba4146,DISK], DatanodeInfoWithStorage[127.0.0.1:35308,DS-4877f132-ba7e-438d-9dd6-192049892726,DISK], DatanodeInfoWithStorage[127.0.0.1:36967,DS-d02ce693-2dbc-497a-8be6-aa6ae0ec1de4,DISK], DatanodeInfoWithStorage[127.0.0.1:40656,DS-00446f8e-a597-4fe6-a9a9-187b82434dbe,DISK], DatanodeInfoWithStorage[127.0.0.1:45912,DS-48e0ddb9-b966-4d78-bae9-a15f766ae8e2,DISK], DatanodeInfoWithStorage[127.0.0.1:36547,DS-f0d38e96-7e69-4292-88da-bee4e14faa8b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-827419932-172.17.0.2-1598203213403:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36016,DS-895faa8c-08d5-4c0c-bf2c-ab4ba7334ba9,DISK], DatanodeInfoWithStorage[127.0.0.1:41873,DS-c92e0d87-a2f4-4850-8856-75c4cebf795f,DISK], DatanodeInfoWithStorage[127.0.0.1:40306,DS-53de8a31-6a9b-4b90-9ac1-c27702ba4146,DISK], DatanodeInfoWithStorage[127.0.0.1:35308,DS-4877f132-ba7e-438d-9dd6-192049892726,DISK], DatanodeInfoWithStorage[127.0.0.1:36967,DS-d02ce693-2dbc-497a-8be6-aa6ae0ec1de4,DISK], DatanodeInfoWithStorage[127.0.0.1:40656,DS-00446f8e-a597-4fe6-a9a9-187b82434dbe,DISK], DatanodeInfoWithStorage[127.0.0.1:45912,DS-48e0ddb9-b966-4d78-bae9-a15f766ae8e2,DISK], DatanodeInfoWithStorage[127.0.0.1:36547,DS-f0d38e96-7e69-4292-88da-bee4e14faa8b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-175156951-172.17.0.2-1598203263346:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41275,DS-f260f489-4d10-42c3-bb73-00561fc61e88,DISK], DatanodeInfoWithStorage[127.0.0.1:46054,DS-3648385a-004e-4537-abe0-0f66b04eb71d,DISK], DatanodeInfoWithStorage[127.0.0.1:36485,DS-93dee616-1852-444d-b0bc-6a4ddf534846,DISK], DatanodeInfoWithStorage[127.0.0.1:36708,DS-857d59a1-7601-44d8-b9aa-c6d8264d46cd,DISK], DatanodeInfoWithStorage[127.0.0.1:39605,DS-87ecc987-814c-4eb2-98f0-804ef197559b,DISK], DatanodeInfoWithStorage[127.0.0.1:45420,DS-71f899c9-f677-46b1-982a-2dc9dee43bb9,DISK], DatanodeInfoWithStorage[127.0.0.1:46867,DS-1014bb48-f1a5-48cf-b19f-f45ff42084bc,DISK], DatanodeInfoWithStorage[127.0.0.1:34621,DS-ca7c56e1-a77b-4a93-a523-a472e6fc01a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-175156951-172.17.0.2-1598203263346:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41275,DS-f260f489-4d10-42c3-bb73-00561fc61e88,DISK], DatanodeInfoWithStorage[127.0.0.1:46054,DS-3648385a-004e-4537-abe0-0f66b04eb71d,DISK], DatanodeInfoWithStorage[127.0.0.1:36485,DS-93dee616-1852-444d-b0bc-6a4ddf534846,DISK], DatanodeInfoWithStorage[127.0.0.1:36708,DS-857d59a1-7601-44d8-b9aa-c6d8264d46cd,DISK], DatanodeInfoWithStorage[127.0.0.1:39605,DS-87ecc987-814c-4eb2-98f0-804ef197559b,DISK], DatanodeInfoWithStorage[127.0.0.1:45420,DS-71f899c9-f677-46b1-982a-2dc9dee43bb9,DISK], DatanodeInfoWithStorage[127.0.0.1:46867,DS-1014bb48-f1a5-48cf-b19f-f45ff42084bc,DISK], DatanodeInfoWithStorage[127.0.0.1:34621,DS-ca7c56e1-a77b-4a93-a523-a472e6fc01a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-346570600-172.17.0.2-1598204236262:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35867,DS-b7e3eae1-44be-4772-abf8-0baa43cdd018,DISK], DatanodeInfoWithStorage[127.0.0.1:46103,DS-0a24601c-355a-432c-8502-9208a5686537,DISK], DatanodeInfoWithStorage[127.0.0.1:39873,DS-3261a69d-2e18-4f3e-bda2-85fb0c2aaaec,DISK], DatanodeInfoWithStorage[127.0.0.1:45365,DS-7537969c-a028-4a33-bcb7-a09b39f676a0,DISK], DatanodeInfoWithStorage[127.0.0.1:37466,DS-390fa798-df0a-4d07-9820-62735d901b92,DISK], DatanodeInfoWithStorage[127.0.0.1:46704,DS-5b3b376e-691b-4867-9e1b-f45941665e81,DISK], DatanodeInfoWithStorage[127.0.0.1:46440,DS-93fb7abc-fdab-4192-b757-6dda290c7577,DISK], DatanodeInfoWithStorage[127.0.0.1:44296,DS-3e961f7a-d245-46c9-b825-cc49d52fd31a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-346570600-172.17.0.2-1598204236262:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35867,DS-b7e3eae1-44be-4772-abf8-0baa43cdd018,DISK], DatanodeInfoWithStorage[127.0.0.1:46103,DS-0a24601c-355a-432c-8502-9208a5686537,DISK], DatanodeInfoWithStorage[127.0.0.1:39873,DS-3261a69d-2e18-4f3e-bda2-85fb0c2aaaec,DISK], DatanodeInfoWithStorage[127.0.0.1:45365,DS-7537969c-a028-4a33-bcb7-a09b39f676a0,DISK], DatanodeInfoWithStorage[127.0.0.1:37466,DS-390fa798-df0a-4d07-9820-62735d901b92,DISK], DatanodeInfoWithStorage[127.0.0.1:46704,DS-5b3b376e-691b-4867-9e1b-f45941665e81,DISK], DatanodeInfoWithStorage[127.0.0.1:46440,DS-93fb7abc-fdab-4192-b757-6dda290c7577,DISK], DatanodeInfoWithStorage[127.0.0.1:44296,DS-3e961f7a-d245-46c9-b825-cc49d52fd31a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-496223802-172.17.0.2-1598204535276:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34253,DS-5bea473b-220a-4175-a8ee-8fc983b7038a,DISK], DatanodeInfoWithStorage[127.0.0.1:37620,DS-af87b29c-0fc2-426d-bc3a-8cf6680fa829,DISK], DatanodeInfoWithStorage[127.0.0.1:45924,DS-68edaf0f-5f9d-4d76-bbdb-915599947d4c,DISK], DatanodeInfoWithStorage[127.0.0.1:37615,DS-f89d5610-e027-4be2-944a-afc32942c0bb,DISK], DatanodeInfoWithStorage[127.0.0.1:39789,DS-0b049b32-73ea-4c6e-b672-ec6450fb10de,DISK], DatanodeInfoWithStorage[127.0.0.1:41882,DS-e4c984b4-98c0-41d4-9e93-ef2923fd06a8,DISK], DatanodeInfoWithStorage[127.0.0.1:45380,DS-5abb583a-7f20-44e3-82ff-8a61b84b3964,DISK], DatanodeInfoWithStorage[127.0.0.1:44565,DS-27e802c1-2135-486a-8a53-3f149cd838a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-496223802-172.17.0.2-1598204535276:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34253,DS-5bea473b-220a-4175-a8ee-8fc983b7038a,DISK], DatanodeInfoWithStorage[127.0.0.1:37620,DS-af87b29c-0fc2-426d-bc3a-8cf6680fa829,DISK], DatanodeInfoWithStorage[127.0.0.1:45924,DS-68edaf0f-5f9d-4d76-bbdb-915599947d4c,DISK], DatanodeInfoWithStorage[127.0.0.1:37615,DS-f89d5610-e027-4be2-944a-afc32942c0bb,DISK], DatanodeInfoWithStorage[127.0.0.1:39789,DS-0b049b32-73ea-4c6e-b672-ec6450fb10de,DISK], DatanodeInfoWithStorage[127.0.0.1:41882,DS-e4c984b4-98c0-41d4-9e93-ef2923fd06a8,DISK], DatanodeInfoWithStorage[127.0.0.1:45380,DS-5abb583a-7f20-44e3-82ff-8a61b84b3964,DISK], DatanodeInfoWithStorage[127.0.0.1:44565,DS-27e802c1-2135-486a-8a53-3f149cd838a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-210019017-172.17.0.2-1598204826251:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45088,DS-63272c7b-b4e1-4991-b91d-91f9fc8df11b,DISK], DatanodeInfoWithStorage[127.0.0.1:36628,DS-702a6151-1d54-4952-8bb1-afd021ddde26,DISK], DatanodeInfoWithStorage[127.0.0.1:38038,DS-81a84900-b0fc-4b47-82ca-2db25d9de87b,DISK], DatanodeInfoWithStorage[127.0.0.1:35519,DS-7c2d68a2-973c-46d1-b8de-bc705aa45321,DISK], DatanodeInfoWithStorage[127.0.0.1:46732,DS-d57cfe81-f842-458b-ac07-53b4d7ed3477,DISK], DatanodeInfoWithStorage[127.0.0.1:36165,DS-e41b34b1-968b-434b-808d-b875314f78b7,DISK], DatanodeInfoWithStorage[127.0.0.1:44680,DS-ae58e766-0809-4939-b74b-20962ecfa573,DISK], DatanodeInfoWithStorage[127.0.0.1:46253,DS-dc22c01e-3f1d-4fc3-be36-0e2fe93d6e6f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-210019017-172.17.0.2-1598204826251:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45088,DS-63272c7b-b4e1-4991-b91d-91f9fc8df11b,DISK], DatanodeInfoWithStorage[127.0.0.1:36628,DS-702a6151-1d54-4952-8bb1-afd021ddde26,DISK], DatanodeInfoWithStorage[127.0.0.1:38038,DS-81a84900-b0fc-4b47-82ca-2db25d9de87b,DISK], DatanodeInfoWithStorage[127.0.0.1:35519,DS-7c2d68a2-973c-46d1-b8de-bc705aa45321,DISK], DatanodeInfoWithStorage[127.0.0.1:46732,DS-d57cfe81-f842-458b-ac07-53b4d7ed3477,DISK], DatanodeInfoWithStorage[127.0.0.1:36165,DS-e41b34b1-968b-434b-808d-b875314f78b7,DISK], DatanodeInfoWithStorage[127.0.0.1:44680,DS-ae58e766-0809-4939-b74b-20962ecfa573,DISK], DatanodeInfoWithStorage[127.0.0.1:46253,DS-dc22c01e-3f1d-4fc3-be36-0e2fe93d6e6f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1643225975-172.17.0.2-1598206275184:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39907,DS-cc605265-6845-4e48-ad9a-2fd8493efe33,DISK], DatanodeInfoWithStorage[127.0.0.1:40742,DS-1824ae1f-4c43-4487-99aa-4e25cc9bd69d,DISK], DatanodeInfoWithStorage[127.0.0.1:40409,DS-ba6c4487-aa92-482c-af33-35966cd4f4ca,DISK], DatanodeInfoWithStorage[127.0.0.1:42044,DS-9f339c3e-2d19-4ecf-a16e-e2d097f9c87e,DISK], DatanodeInfoWithStorage[127.0.0.1:45669,DS-7e61b89f-3711-4163-beac-767eecf2189a,DISK], DatanodeInfoWithStorage[127.0.0.1:35080,DS-20cbb866-9f13-4336-90a8-df7ac517f912,DISK], DatanodeInfoWithStorage[127.0.0.1:32916,DS-21b3662a-c16d-4eb4-be39-18c6dfe79cb2,DISK], DatanodeInfoWithStorage[127.0.0.1:41074,DS-159ff183-d705-4663-b310-76aac8676d95,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1643225975-172.17.0.2-1598206275184:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39907,DS-cc605265-6845-4e48-ad9a-2fd8493efe33,DISK], DatanodeInfoWithStorage[127.0.0.1:40742,DS-1824ae1f-4c43-4487-99aa-4e25cc9bd69d,DISK], DatanodeInfoWithStorage[127.0.0.1:40409,DS-ba6c4487-aa92-482c-af33-35966cd4f4ca,DISK], DatanodeInfoWithStorage[127.0.0.1:42044,DS-9f339c3e-2d19-4ecf-a16e-e2d097f9c87e,DISK], DatanodeInfoWithStorage[127.0.0.1:45669,DS-7e61b89f-3711-4163-beac-767eecf2189a,DISK], DatanodeInfoWithStorage[127.0.0.1:35080,DS-20cbb866-9f13-4336-90a8-df7ac517f912,DISK], DatanodeInfoWithStorage[127.0.0.1:32916,DS-21b3662a-c16d-4eb4-be39-18c6dfe79cb2,DISK], DatanodeInfoWithStorage[127.0.0.1:41074,DS-159ff183-d705-4663-b310-76aac8676d95,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1220151899-172.17.0.2-1598206530401:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35953,DS-59460a5f-0f18-42e4-a9ad-e9b1ad808d4b,DISK], DatanodeInfoWithStorage[127.0.0.1:42790,DS-6543c0db-b28c-420e-8d72-2b5262c8e826,DISK], DatanodeInfoWithStorage[127.0.0.1:41412,DS-5ed17a38-6ffa-40cf-a0b7-f08aa54fe7ab,DISK], DatanodeInfoWithStorage[127.0.0.1:34264,DS-aa0eeffe-dc98-477f-9606-9fe8bc7c5bb2,DISK], DatanodeInfoWithStorage[127.0.0.1:42085,DS-f96c02ca-0f85-4e27-9a64-7da56b58ce6f,DISK], DatanodeInfoWithStorage[127.0.0.1:35717,DS-4f683662-266e-463d-9bd3-0eb76bdf6661,DISK], DatanodeInfoWithStorage[127.0.0.1:33164,DS-e98e34b2-62ab-4767-b56a-2037faf64fd9,DISK], DatanodeInfoWithStorage[127.0.0.1:46224,DS-236a6b11-41dd-4d4c-b964-c57e3472b31b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1220151899-172.17.0.2-1598206530401:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35953,DS-59460a5f-0f18-42e4-a9ad-e9b1ad808d4b,DISK], DatanodeInfoWithStorage[127.0.0.1:42790,DS-6543c0db-b28c-420e-8d72-2b5262c8e826,DISK], DatanodeInfoWithStorage[127.0.0.1:41412,DS-5ed17a38-6ffa-40cf-a0b7-f08aa54fe7ab,DISK], DatanodeInfoWithStorage[127.0.0.1:34264,DS-aa0eeffe-dc98-477f-9606-9fe8bc7c5bb2,DISK], DatanodeInfoWithStorage[127.0.0.1:42085,DS-f96c02ca-0f85-4e27-9a64-7da56b58ce6f,DISK], DatanodeInfoWithStorage[127.0.0.1:35717,DS-4f683662-266e-463d-9bd3-0eb76bdf6661,DISK], DatanodeInfoWithStorage[127.0.0.1:33164,DS-e98e34b2-62ab-4767-b56a-2037faf64fd9,DISK], DatanodeInfoWithStorage[127.0.0.1:46224,DS-236a6b11-41dd-4d4c-b964-c57e3472b31b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-143934517-172.17.0.2-1598206718264:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46361,DS-cd1cc526-964c-4b4d-a85e-8afee9475316,DISK], DatanodeInfoWithStorage[127.0.0.1:38161,DS-e9547f7c-af6c-490d-9b80-90d0ee748065,DISK], DatanodeInfoWithStorage[127.0.0.1:35274,DS-a75d2d08-41b0-46d9-aa0d-adbd8faf1944,DISK], DatanodeInfoWithStorage[127.0.0.1:42764,DS-f8b63fc8-16e0-429f-a72e-3eb48f96df3e,DISK], DatanodeInfoWithStorage[127.0.0.1:40003,DS-04c187fe-2665-486f-99f6-6ae21f615809,DISK], DatanodeInfoWithStorage[127.0.0.1:43986,DS-97fa70a4-8cf7-45dc-93e8-4cb4294bc707,DISK], DatanodeInfoWithStorage[127.0.0.1:39891,DS-e0267898-1a19-4af8-87ee-9e67a31775c6,DISK], DatanodeInfoWithStorage[127.0.0.1:42235,DS-8e49201d-7db1-45db-a6d9-395957be6635,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-143934517-172.17.0.2-1598206718264:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46361,DS-cd1cc526-964c-4b4d-a85e-8afee9475316,DISK], DatanodeInfoWithStorage[127.0.0.1:38161,DS-e9547f7c-af6c-490d-9b80-90d0ee748065,DISK], DatanodeInfoWithStorage[127.0.0.1:35274,DS-a75d2d08-41b0-46d9-aa0d-adbd8faf1944,DISK], DatanodeInfoWithStorage[127.0.0.1:42764,DS-f8b63fc8-16e0-429f-a72e-3eb48f96df3e,DISK], DatanodeInfoWithStorage[127.0.0.1:40003,DS-04c187fe-2665-486f-99f6-6ae21f615809,DISK], DatanodeInfoWithStorage[127.0.0.1:43986,DS-97fa70a4-8cf7-45dc-93e8-4cb4294bc707,DISK], DatanodeInfoWithStorage[127.0.0.1:39891,DS-e0267898-1a19-4af8-87ee-9e67a31775c6,DISK], DatanodeInfoWithStorage[127.0.0.1:42235,DS-8e49201d-7db1-45db-a6d9-395957be6635,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1569448295-172.17.0.2-1598207660036:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46218,DS-ef63c8be-178d-45bb-a296-92838f3af7e4,DISK], DatanodeInfoWithStorage[127.0.0.1:44297,DS-8f24ff36-8948-4e5e-89ba-2155f9384afd,DISK], DatanodeInfoWithStorage[127.0.0.1:44204,DS-9358278b-d315-402f-8335-682c58a6199a,DISK], DatanodeInfoWithStorage[127.0.0.1:41614,DS-adefa358-e9c9-4e5b-bc3c-8b0687f6ba13,DISK], DatanodeInfoWithStorage[127.0.0.1:45991,DS-62cdbc27-6a1a-472c-b700-b42efd6718c5,DISK], DatanodeInfoWithStorage[127.0.0.1:42781,DS-07a02593-8836-4564-928f-2f59f56501d6,DISK], DatanodeInfoWithStorage[127.0.0.1:44144,DS-b6abe0a7-b1e5-4b7f-bba9-7bc070b501c6,DISK], DatanodeInfoWithStorage[127.0.0.1:46856,DS-26118278-12d2-4b4b-86ed-386c1b8b68c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1569448295-172.17.0.2-1598207660036:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46218,DS-ef63c8be-178d-45bb-a296-92838f3af7e4,DISK], DatanodeInfoWithStorage[127.0.0.1:44297,DS-8f24ff36-8948-4e5e-89ba-2155f9384afd,DISK], DatanodeInfoWithStorage[127.0.0.1:44204,DS-9358278b-d315-402f-8335-682c58a6199a,DISK], DatanodeInfoWithStorage[127.0.0.1:41614,DS-adefa358-e9c9-4e5b-bc3c-8b0687f6ba13,DISK], DatanodeInfoWithStorage[127.0.0.1:45991,DS-62cdbc27-6a1a-472c-b700-b42efd6718c5,DISK], DatanodeInfoWithStorage[127.0.0.1:42781,DS-07a02593-8836-4564-928f-2f59f56501d6,DISK], DatanodeInfoWithStorage[127.0.0.1:44144,DS-b6abe0a7-b1e5-4b7f-bba9-7bc070b501c6,DISK], DatanodeInfoWithStorage[127.0.0.1:46856,DS-26118278-12d2-4b4b-86ed-386c1b8b68c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-302676430-172.17.0.2-1598207740730:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36840,DS-9cbee9ec-5d91-4ee4-82b9-58d15d320e8b,DISK], DatanodeInfoWithStorage[127.0.0.1:33563,DS-6b9a7b08-a126-4f95-b28b-8b30069eb907,DISK], DatanodeInfoWithStorage[127.0.0.1:33565,DS-370f9ab1-0d82-46dd-b97b-46ef9b9f4d7c,DISK], DatanodeInfoWithStorage[127.0.0.1:44109,DS-b1c35ea7-450a-4ddf-a3f9-c5d9a77cfbb7,DISK], DatanodeInfoWithStorage[127.0.0.1:39773,DS-a84fb7fc-51ad-4907-8101-1bdca5588c17,DISK], DatanodeInfoWithStorage[127.0.0.1:41054,DS-5df279fa-d34b-40b1-acd5-52961f2a0c98,DISK], DatanodeInfoWithStorage[127.0.0.1:41007,DS-be27f9f2-cbe8-4a31-b2f8-d7e7a7452b2f,DISK], DatanodeInfoWithStorage[127.0.0.1:33295,DS-89cab6e5-242e-432d-8666-f9a58af1f2ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-302676430-172.17.0.2-1598207740730:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36840,DS-9cbee9ec-5d91-4ee4-82b9-58d15d320e8b,DISK], DatanodeInfoWithStorage[127.0.0.1:33563,DS-6b9a7b08-a126-4f95-b28b-8b30069eb907,DISK], DatanodeInfoWithStorage[127.0.0.1:33565,DS-370f9ab1-0d82-46dd-b97b-46ef9b9f4d7c,DISK], DatanodeInfoWithStorage[127.0.0.1:44109,DS-b1c35ea7-450a-4ddf-a3f9-c5d9a77cfbb7,DISK], DatanodeInfoWithStorage[127.0.0.1:39773,DS-a84fb7fc-51ad-4907-8101-1bdca5588c17,DISK], DatanodeInfoWithStorage[127.0.0.1:41054,DS-5df279fa-d34b-40b1-acd5-52961f2a0c98,DISK], DatanodeInfoWithStorage[127.0.0.1:41007,DS-be27f9f2-cbe8-4a31-b2f8-d7e7a7452b2f,DISK], DatanodeInfoWithStorage[127.0.0.1:33295,DS-89cab6e5-242e-432d-8666-f9a58af1f2ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2024622263-172.17.0.2-1598207918552:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38094,DS-79120052-7249-4e1e-b608-5fa865bf259b,DISK], DatanodeInfoWithStorage[127.0.0.1:35334,DS-5032bb9c-12b1-4d4a-94a7-a03c1c4e4715,DISK], DatanodeInfoWithStorage[127.0.0.1:40788,DS-05db3976-c8d5-4083-bec2-373e7935ba9b,DISK], DatanodeInfoWithStorage[127.0.0.1:44536,DS-bc30002c-03cd-4cb5-b8e0-5e353329821e,DISK], DatanodeInfoWithStorage[127.0.0.1:42170,DS-fac738a3-c4be-401b-a0fd-3e5d8e7717d7,DISK], DatanodeInfoWithStorage[127.0.0.1:37435,DS-44933149-99ab-43b7-b604-de2a61c380db,DISK], DatanodeInfoWithStorage[127.0.0.1:36083,DS-ffc1a5ee-3db9-432a-b7f4-57cf730dbffe,DISK], DatanodeInfoWithStorage[127.0.0.1:39373,DS-e0014ea0-651c-4413-8436-500e2ac1501f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2024622263-172.17.0.2-1598207918552:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38094,DS-79120052-7249-4e1e-b608-5fa865bf259b,DISK], DatanodeInfoWithStorage[127.0.0.1:35334,DS-5032bb9c-12b1-4d4a-94a7-a03c1c4e4715,DISK], DatanodeInfoWithStorage[127.0.0.1:40788,DS-05db3976-c8d5-4083-bec2-373e7935ba9b,DISK], DatanodeInfoWithStorage[127.0.0.1:44536,DS-bc30002c-03cd-4cb5-b8e0-5e353329821e,DISK], DatanodeInfoWithStorage[127.0.0.1:42170,DS-fac738a3-c4be-401b-a0fd-3e5d8e7717d7,DISK], DatanodeInfoWithStorage[127.0.0.1:37435,DS-44933149-99ab-43b7-b604-de2a61c380db,DISK], DatanodeInfoWithStorage[127.0.0.1:36083,DS-ffc1a5ee-3db9-432a-b7f4-57cf730dbffe,DISK], DatanodeInfoWithStorage[127.0.0.1:39373,DS-e0014ea0-651c-4413-8436-500e2ac1501f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-72865390-172.17.0.2-1598208218008:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46357,DS-3547fd9b-2ff3-4a8d-b3a9-d1b90b03862f,DISK], DatanodeInfoWithStorage[127.0.0.1:46331,DS-c0fd6944-15a5-4999-a596-3b1795e82591,DISK], DatanodeInfoWithStorage[127.0.0.1:45436,DS-73e8f097-1add-4e67-a1b7-c34b642b07d3,DISK], DatanodeInfoWithStorage[127.0.0.1:46662,DS-810c1e3b-a049-4586-b496-afdb3fb8947b,DISK], DatanodeInfoWithStorage[127.0.0.1:36685,DS-9d9f8111-c998-4736-a86f-6e8c7096dd13,DISK], DatanodeInfoWithStorage[127.0.0.1:45162,DS-eab9bf52-1384-47bb-b37f-e12a59aad7d9,DISK], DatanodeInfoWithStorage[127.0.0.1:43012,DS-2c4ae2f7-522a-4c5a-b964-adc46c735f52,DISK], DatanodeInfoWithStorage[127.0.0.1:35399,DS-f258e19b-3c3e-4dd7-b916-d21d6969c38b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-72865390-172.17.0.2-1598208218008:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46357,DS-3547fd9b-2ff3-4a8d-b3a9-d1b90b03862f,DISK], DatanodeInfoWithStorage[127.0.0.1:46331,DS-c0fd6944-15a5-4999-a596-3b1795e82591,DISK], DatanodeInfoWithStorage[127.0.0.1:45436,DS-73e8f097-1add-4e67-a1b7-c34b642b07d3,DISK], DatanodeInfoWithStorage[127.0.0.1:46662,DS-810c1e3b-a049-4586-b496-afdb3fb8947b,DISK], DatanodeInfoWithStorage[127.0.0.1:36685,DS-9d9f8111-c998-4736-a86f-6e8c7096dd13,DISK], DatanodeInfoWithStorage[127.0.0.1:45162,DS-eab9bf52-1384-47bb-b37f-e12a59aad7d9,DISK], DatanodeInfoWithStorage[127.0.0.1:43012,DS-2c4ae2f7-522a-4c5a-b964-adc46c735f52,DISK], DatanodeInfoWithStorage[127.0.0.1:35399,DS-f258e19b-3c3e-4dd7-b916-d21d6969c38b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: hadoop.security.authorization
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1006833745-172.17.0.2-1598208240991:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39969,DS-b1a18cef-0799-4377-98d8-6e8e147d91a9,DISK], DatanodeInfoWithStorage[127.0.0.1:35207,DS-b995f50a-99a1-422d-91c8-ca7259d3b794,DISK], DatanodeInfoWithStorage[127.0.0.1:43556,DS-3b705f00-799c-45e7-beaa-b51e6cadb2eb,DISK], DatanodeInfoWithStorage[127.0.0.1:40214,DS-0e55c5f8-d9e5-4a53-af6c-45758d5f5c4d,DISK], DatanodeInfoWithStorage[127.0.0.1:37929,DS-ba58017a-4ecb-4871-8ad9-02d6328971dc,DISK], DatanodeInfoWithStorage[127.0.0.1:44566,DS-59d5d5df-4420-4248-abd0-25f8ae5289ae,DISK], DatanodeInfoWithStorage[127.0.0.1:36066,DS-fdb151a8-7270-4f49-9197-a15c69ee729e,DISK], DatanodeInfoWithStorage[127.0.0.1:38674,DS-2bdba9c4-f1f0-4826-ac57-61d1ce578f5d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1006833745-172.17.0.2-1598208240991:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39969,DS-b1a18cef-0799-4377-98d8-6e8e147d91a9,DISK], DatanodeInfoWithStorage[127.0.0.1:35207,DS-b995f50a-99a1-422d-91c8-ca7259d3b794,DISK], DatanodeInfoWithStorage[127.0.0.1:43556,DS-3b705f00-799c-45e7-beaa-b51e6cadb2eb,DISK], DatanodeInfoWithStorage[127.0.0.1:40214,DS-0e55c5f8-d9e5-4a53-af6c-45758d5f5c4d,DISK], DatanodeInfoWithStorage[127.0.0.1:37929,DS-ba58017a-4ecb-4871-8ad9-02d6328971dc,DISK], DatanodeInfoWithStorage[127.0.0.1:44566,DS-59d5d5df-4420-4248-abd0-25f8ae5289ae,DISK], DatanodeInfoWithStorage[127.0.0.1:36066,DS-fdb151a8-7270-4f49-9197-a15c69ee729e,DISK], DatanodeInfoWithStorage[127.0.0.1:38674,DS-2bdba9c4-f1f0-4826-ac57-61d1ce578f5d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-73081187-172.17.0.2-1598208358094:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37397,DS-f02428b6-0fb3-42d6-8e4d-de6e979fc4aa,DISK], DatanodeInfoWithStorage[127.0.0.1:42045,DS-d0c85096-45fe-4925-9337-c86637b98889,DISK], DatanodeInfoWithStorage[127.0.0.1:39752,DS-356e7692-319a-4743-a21b-837deefaa055,DISK], DatanodeInfoWithStorage[127.0.0.1:40234,DS-f496094f-0aa1-423c-b0c3-91d09e4b539e,DISK], DatanodeInfoWithStorage[127.0.0.1:43965,DS-ce98bc8b-7ce8-47c9-9e15-789cf837a707,DISK], DatanodeInfoWithStorage[127.0.0.1:39104,DS-da97af48-dcef-4ccf-8f27-87c9bc706b12,DISK], DatanodeInfoWithStorage[127.0.0.1:42909,DS-de539a12-f960-4a19-bb80-c7685f8c1920,DISK], DatanodeInfoWithStorage[127.0.0.1:46335,DS-63125887-bed7-4f9f-82c2-2695ff7c22cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-73081187-172.17.0.2-1598208358094:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37397,DS-f02428b6-0fb3-42d6-8e4d-de6e979fc4aa,DISK], DatanodeInfoWithStorage[127.0.0.1:42045,DS-d0c85096-45fe-4925-9337-c86637b98889,DISK], DatanodeInfoWithStorage[127.0.0.1:39752,DS-356e7692-319a-4743-a21b-837deefaa055,DISK], DatanodeInfoWithStorage[127.0.0.1:40234,DS-f496094f-0aa1-423c-b0c3-91d09e4b539e,DISK], DatanodeInfoWithStorage[127.0.0.1:43965,DS-ce98bc8b-7ce8-47c9-9e15-789cf837a707,DISK], DatanodeInfoWithStorage[127.0.0.1:39104,DS-da97af48-dcef-4ccf-8f27-87c9bc706b12,DISK], DatanodeInfoWithStorage[127.0.0.1:42909,DS-de539a12-f960-4a19-bb80-c7685f8c1920,DISK], DatanodeInfoWithStorage[127.0.0.1:46335,DS-63125887-bed7-4f9f-82c2-2695ff7c22cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 6258
