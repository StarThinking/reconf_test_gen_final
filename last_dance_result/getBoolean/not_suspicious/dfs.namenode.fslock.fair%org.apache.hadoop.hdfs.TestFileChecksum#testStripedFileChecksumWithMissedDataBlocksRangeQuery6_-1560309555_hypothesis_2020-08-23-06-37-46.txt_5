reconf_parameter: dfs.namenode.fslock.fair
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fslock.fair
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-491139883-172.17.0.6-1598164824124:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33263,DS-76f93d2e-7fad-421d-92df-34486ca20e33,DISK], DatanodeInfoWithStorage[127.0.0.1:34976,DS-165fdc0c-42bd-452a-a686-c28bd1499978,DISK], DatanodeInfoWithStorage[127.0.0.1:39515,DS-bfb78864-0957-41f7-b079-a470bf5eb751,DISK], DatanodeInfoWithStorage[127.0.0.1:35114,DS-177064b8-6a0b-4251-ba13-fc096a66db6d,DISK], DatanodeInfoWithStorage[127.0.0.1:35374,DS-afd15ae5-a29d-456b-af01-32e1bcd40339,DISK], DatanodeInfoWithStorage[127.0.0.1:38637,DS-d5f07fb2-27a1-4185-8d13-7a31e432f099,DISK], DatanodeInfoWithStorage[127.0.0.1:44494,DS-8f790388-3622-4b99-ac96-eccf42a179cb,DISK], DatanodeInfoWithStorage[127.0.0.1:45585,DS-762f4fc5-0bf6-42af-ab5d-ffbbd1c720b4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-491139883-172.17.0.6-1598164824124:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33263,DS-76f93d2e-7fad-421d-92df-34486ca20e33,DISK], DatanodeInfoWithStorage[127.0.0.1:34976,DS-165fdc0c-42bd-452a-a686-c28bd1499978,DISK], DatanodeInfoWithStorage[127.0.0.1:39515,DS-bfb78864-0957-41f7-b079-a470bf5eb751,DISK], DatanodeInfoWithStorage[127.0.0.1:35114,DS-177064b8-6a0b-4251-ba13-fc096a66db6d,DISK], DatanodeInfoWithStorage[127.0.0.1:35374,DS-afd15ae5-a29d-456b-af01-32e1bcd40339,DISK], DatanodeInfoWithStorage[127.0.0.1:38637,DS-d5f07fb2-27a1-4185-8d13-7a31e432f099,DISK], DatanodeInfoWithStorage[127.0.0.1:44494,DS-8f790388-3622-4b99-ac96-eccf42a179cb,DISK], DatanodeInfoWithStorage[127.0.0.1:45585,DS-762f4fc5-0bf6-42af-ab5d-ffbbd1c720b4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.fslock.fair
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-54169306-172.17.0.6-1598164859140:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40789,DS-aba6e04e-812a-417d-8df0-5c6b610f37d5,DISK], DatanodeInfoWithStorage[127.0.0.1:45194,DS-31d2b055-b003-49dd-b630-ece682012533,DISK], DatanodeInfoWithStorage[127.0.0.1:42078,DS-192cc551-2e85-4ef7-b516-183d72baff2c,DISK], DatanodeInfoWithStorage[127.0.0.1:37237,DS-e35db0d4-e6b5-4297-9ed1-1378142684e6,DISK], DatanodeInfoWithStorage[127.0.0.1:44114,DS-821a4fc2-26ca-4108-823d-aa9994f26488,DISK], DatanodeInfoWithStorage[127.0.0.1:41495,DS-d1bf0620-eb7b-4d26-95c0-6b6cd76974b2,DISK], DatanodeInfoWithStorage[127.0.0.1:36867,DS-89357881-4ef9-4d3d-bef2-8a9f66db1d77,DISK], DatanodeInfoWithStorage[127.0.0.1:41544,DS-896c0fc4-67f7-4e1a-b332-bb210d05832d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-54169306-172.17.0.6-1598164859140:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40789,DS-aba6e04e-812a-417d-8df0-5c6b610f37d5,DISK], DatanodeInfoWithStorage[127.0.0.1:45194,DS-31d2b055-b003-49dd-b630-ece682012533,DISK], DatanodeInfoWithStorage[127.0.0.1:42078,DS-192cc551-2e85-4ef7-b516-183d72baff2c,DISK], DatanodeInfoWithStorage[127.0.0.1:37237,DS-e35db0d4-e6b5-4297-9ed1-1378142684e6,DISK], DatanodeInfoWithStorage[127.0.0.1:44114,DS-821a4fc2-26ca-4108-823d-aa9994f26488,DISK], DatanodeInfoWithStorage[127.0.0.1:41495,DS-d1bf0620-eb7b-4d26-95c0-6b6cd76974b2,DISK], DatanodeInfoWithStorage[127.0.0.1:36867,DS-89357881-4ef9-4d3d-bef2-8a9f66db1d77,DISK], DatanodeInfoWithStorage[127.0.0.1:41544,DS-896c0fc4-67f7-4e1a-b332-bb210d05832d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fslock.fair
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1695533925-172.17.0.6-1598164900659:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45488,DS-2f7d4da5-43bc-45a5-b7b7-8f2328028710,DISK], DatanodeInfoWithStorage[127.0.0.1:33266,DS-5add2f82-d94a-400d-9ad2-0262fe0efe1a,DISK], DatanodeInfoWithStorage[127.0.0.1:45770,DS-65b654ec-8694-42af-9633-15de78ceb33d,DISK], DatanodeInfoWithStorage[127.0.0.1:40760,DS-213c305e-5ccd-419a-873b-cfad1b36abdb,DISK], DatanodeInfoWithStorage[127.0.0.1:44309,DS-248812f9-69ef-4a6f-8c54-af165c8a5fcc,DISK], DatanodeInfoWithStorage[127.0.0.1:43652,DS-b28a10d9-5dd2-4277-8ae6-74d5735adf31,DISK], DatanodeInfoWithStorage[127.0.0.1:36639,DS-a2aa9faa-e281-47eb-98ed-a20e83b1c5be,DISK], DatanodeInfoWithStorage[127.0.0.1:40805,DS-968a4d53-2cf0-493c-8a34-fbb064362402,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1695533925-172.17.0.6-1598164900659:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45488,DS-2f7d4da5-43bc-45a5-b7b7-8f2328028710,DISK], DatanodeInfoWithStorage[127.0.0.1:33266,DS-5add2f82-d94a-400d-9ad2-0262fe0efe1a,DISK], DatanodeInfoWithStorage[127.0.0.1:45770,DS-65b654ec-8694-42af-9633-15de78ceb33d,DISK], DatanodeInfoWithStorage[127.0.0.1:40760,DS-213c305e-5ccd-419a-873b-cfad1b36abdb,DISK], DatanodeInfoWithStorage[127.0.0.1:44309,DS-248812f9-69ef-4a6f-8c54-af165c8a5fcc,DISK], DatanodeInfoWithStorage[127.0.0.1:43652,DS-b28a10d9-5dd2-4277-8ae6-74d5735adf31,DISK], DatanodeInfoWithStorage[127.0.0.1:36639,DS-a2aa9faa-e281-47eb-98ed-a20e83b1c5be,DISK], DatanodeInfoWithStorage[127.0.0.1:40805,DS-968a4d53-2cf0-493c-8a34-fbb064362402,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fslock.fair
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1812092215-172.17.0.6-1598165304658:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34730,DS-dce2c4d9-6032-4fd4-8d4e-d049143eab3b,DISK], DatanodeInfoWithStorage[127.0.0.1:34500,DS-ae87842e-8c51-415d-9242-b903ee96918d,DISK], DatanodeInfoWithStorage[127.0.0.1:40596,DS-95206200-f4e7-4ece-ae8b-4ac9a0144c3b,DISK], DatanodeInfoWithStorage[127.0.0.1:42078,DS-a16253be-d559-4844-ae15-eb4c420278ce,DISK], DatanodeInfoWithStorage[127.0.0.1:34323,DS-e99ac8c5-4d60-4f91-9182-fa1f4d0c8649,DISK], DatanodeInfoWithStorage[127.0.0.1:46542,DS-06b74567-353a-4458-9a36-57037dfb8aab,DISK], DatanodeInfoWithStorage[127.0.0.1:43066,DS-67534a07-04c9-4ac8-9d2a-7ee6fe76d31a,DISK], DatanodeInfoWithStorage[127.0.0.1:38881,DS-024ab28c-6a24-443f-b6ed-abd82a3fd019,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1812092215-172.17.0.6-1598165304658:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34730,DS-dce2c4d9-6032-4fd4-8d4e-d049143eab3b,DISK], DatanodeInfoWithStorage[127.0.0.1:34500,DS-ae87842e-8c51-415d-9242-b903ee96918d,DISK], DatanodeInfoWithStorage[127.0.0.1:40596,DS-95206200-f4e7-4ece-ae8b-4ac9a0144c3b,DISK], DatanodeInfoWithStorage[127.0.0.1:42078,DS-a16253be-d559-4844-ae15-eb4c420278ce,DISK], DatanodeInfoWithStorage[127.0.0.1:34323,DS-e99ac8c5-4d60-4f91-9182-fa1f4d0c8649,DISK], DatanodeInfoWithStorage[127.0.0.1:46542,DS-06b74567-353a-4458-9a36-57037dfb8aab,DISK], DatanodeInfoWithStorage[127.0.0.1:43066,DS-67534a07-04c9-4ac8-9d2a-7ee6fe76d31a,DISK], DatanodeInfoWithStorage[127.0.0.1:38881,DS-024ab28c-6a24-443f-b6ed-abd82a3fd019,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fslock.fair
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1578341886-172.17.0.6-1598165595411:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42092,DS-c30623c4-79af-4dca-a7b1-7187710e703f,DISK], DatanodeInfoWithStorage[127.0.0.1:37255,DS-53f87efd-45c8-45d9-ac9e-f26649ec2176,DISK], DatanodeInfoWithStorage[127.0.0.1:44510,DS-9deecba3-0408-4184-8bc2-117aaa1bbead,DISK], DatanodeInfoWithStorage[127.0.0.1:45653,DS-9fd3370c-4c96-4597-b9ec-fde24266e2b2,DISK], DatanodeInfoWithStorage[127.0.0.1:41535,DS-08647bc7-885e-41b6-b30c-330a412ff0c4,DISK], DatanodeInfoWithStorage[127.0.0.1:43608,DS-70e43931-51d1-4f95-ab4d-6a5fa1428ea5,DISK], DatanodeInfoWithStorage[127.0.0.1:46149,DS-82ef80f0-ab31-41c1-bd3e-dc964c9970d6,DISK], DatanodeInfoWithStorage[127.0.0.1:46758,DS-ca09b8b2-e83e-429c-9de6-618773364f63,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1578341886-172.17.0.6-1598165595411:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42092,DS-c30623c4-79af-4dca-a7b1-7187710e703f,DISK], DatanodeInfoWithStorage[127.0.0.1:37255,DS-53f87efd-45c8-45d9-ac9e-f26649ec2176,DISK], DatanodeInfoWithStorage[127.0.0.1:44510,DS-9deecba3-0408-4184-8bc2-117aaa1bbead,DISK], DatanodeInfoWithStorage[127.0.0.1:45653,DS-9fd3370c-4c96-4597-b9ec-fde24266e2b2,DISK], DatanodeInfoWithStorage[127.0.0.1:41535,DS-08647bc7-885e-41b6-b30c-330a412ff0c4,DISK], DatanodeInfoWithStorage[127.0.0.1:43608,DS-70e43931-51d1-4f95-ab4d-6a5fa1428ea5,DISK], DatanodeInfoWithStorage[127.0.0.1:46149,DS-82ef80f0-ab31-41c1-bd3e-dc964c9970d6,DISK], DatanodeInfoWithStorage[127.0.0.1:46758,DS-ca09b8b2-e83e-429c-9de6-618773364f63,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.fslock.fair
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1407149635-172.17.0.6-1598165629357:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41815,DS-9566ef8b-54be-4f7c-b87c-9a6bba310546,DISK], DatanodeInfoWithStorage[127.0.0.1:41997,DS-0aed206c-d031-46e7-999a-ffb9a874a3d1,DISK], DatanodeInfoWithStorage[127.0.0.1:46491,DS-d92f6e9a-1f0d-4065-a5ad-b6e5fd69e5fe,DISK], DatanodeInfoWithStorage[127.0.0.1:36096,DS-0167a827-ee84-481d-9722-dfcaebfb83e8,DISK], DatanodeInfoWithStorage[127.0.0.1:34302,DS-3125422b-88f3-4a6c-a002-b8dc17eaa130,DISK], DatanodeInfoWithStorage[127.0.0.1:46005,DS-d98b7e6c-c651-4cc8-b0ec-923269651ec0,DISK], DatanodeInfoWithStorage[127.0.0.1:36229,DS-47a2e82c-ceda-4d2b-bc89-45167b589d68,DISK], DatanodeInfoWithStorage[127.0.0.1:43184,DS-8377c2b1-7a7f-43e2-b66a-0adaa16ef1ee,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1407149635-172.17.0.6-1598165629357:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41815,DS-9566ef8b-54be-4f7c-b87c-9a6bba310546,DISK], DatanodeInfoWithStorage[127.0.0.1:41997,DS-0aed206c-d031-46e7-999a-ffb9a874a3d1,DISK], DatanodeInfoWithStorage[127.0.0.1:46491,DS-d92f6e9a-1f0d-4065-a5ad-b6e5fd69e5fe,DISK], DatanodeInfoWithStorage[127.0.0.1:36096,DS-0167a827-ee84-481d-9722-dfcaebfb83e8,DISK], DatanodeInfoWithStorage[127.0.0.1:34302,DS-3125422b-88f3-4a6c-a002-b8dc17eaa130,DISK], DatanodeInfoWithStorage[127.0.0.1:46005,DS-d98b7e6c-c651-4cc8-b0ec-923269651ec0,DISK], DatanodeInfoWithStorage[127.0.0.1:36229,DS-47a2e82c-ceda-4d2b-bc89-45167b589d68,DISK], DatanodeInfoWithStorage[127.0.0.1:43184,DS-8377c2b1-7a7f-43e2-b66a-0adaa16ef1ee,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fslock.fair
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1342905505-172.17.0.6-1598165806882:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41528,DS-35d53aa8-b26b-48be-abfd-d5d37fe70513,DISK], DatanodeInfoWithStorage[127.0.0.1:39336,DS-ebb3a8ac-7e9e-421b-9148-98ec740f9986,DISK], DatanodeInfoWithStorage[127.0.0.1:44220,DS-024143a1-6cf5-4622-98ee-1d37cd648856,DISK], DatanodeInfoWithStorage[127.0.0.1:40524,DS-defc1eeb-5dad-4164-a2ad-64123d4233c1,DISK], DatanodeInfoWithStorage[127.0.0.1:38867,DS-3cb87387-7679-4cba-9fd5-a9644bf2a26a,DISK], DatanodeInfoWithStorage[127.0.0.1:39002,DS-e870e034-2904-47ab-b66a-1dda0aca6467,DISK], DatanodeInfoWithStorage[127.0.0.1:45376,DS-7a3529e5-70d0-4bb2-be83-11b9359ccc6d,DISK], DatanodeInfoWithStorage[127.0.0.1:36523,DS-d7dac051-eea7-42f8-aeb1-788d6f72843c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1342905505-172.17.0.6-1598165806882:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41528,DS-35d53aa8-b26b-48be-abfd-d5d37fe70513,DISK], DatanodeInfoWithStorage[127.0.0.1:39336,DS-ebb3a8ac-7e9e-421b-9148-98ec740f9986,DISK], DatanodeInfoWithStorage[127.0.0.1:44220,DS-024143a1-6cf5-4622-98ee-1d37cd648856,DISK], DatanodeInfoWithStorage[127.0.0.1:40524,DS-defc1eeb-5dad-4164-a2ad-64123d4233c1,DISK], DatanodeInfoWithStorage[127.0.0.1:38867,DS-3cb87387-7679-4cba-9fd5-a9644bf2a26a,DISK], DatanodeInfoWithStorage[127.0.0.1:39002,DS-e870e034-2904-47ab-b66a-1dda0aca6467,DISK], DatanodeInfoWithStorage[127.0.0.1:45376,DS-7a3529e5-70d0-4bb2-be83-11b9359ccc6d,DISK], DatanodeInfoWithStorage[127.0.0.1:36523,DS-d7dac051-eea7-42f8-aeb1-788d6f72843c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fslock.fair
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1314528250-172.17.0.6-1598165991862:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46278,DS-e4ee1731-38ff-4992-8a7b-b2dd5d10d8c5,DISK], DatanodeInfoWithStorage[127.0.0.1:45188,DS-6137e6a8-73d0-4179-ba50-265240a62110,DISK], DatanodeInfoWithStorage[127.0.0.1:42873,DS-281d266c-91fe-427b-8beb-c1ab71bf4611,DISK], DatanodeInfoWithStorage[127.0.0.1:42328,DS-ee643d7c-3de5-4690-9056-a1224083e96d,DISK], DatanodeInfoWithStorage[127.0.0.1:41372,DS-64cf04f4-ddce-4ecb-9bab-02651e7d4079,DISK], DatanodeInfoWithStorage[127.0.0.1:37282,DS-0b59097d-5282-456f-8fe6-7050e7eae5f9,DISK], DatanodeInfoWithStorage[127.0.0.1:36532,DS-d1f91146-266b-49e8-a5ff-268f4a416117,DISK], DatanodeInfoWithStorage[127.0.0.1:33786,DS-96e10e3a-04ba-4d6b-9855-a49db613784a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1314528250-172.17.0.6-1598165991862:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46278,DS-e4ee1731-38ff-4992-8a7b-b2dd5d10d8c5,DISK], DatanodeInfoWithStorage[127.0.0.1:45188,DS-6137e6a8-73d0-4179-ba50-265240a62110,DISK], DatanodeInfoWithStorage[127.0.0.1:42873,DS-281d266c-91fe-427b-8beb-c1ab71bf4611,DISK], DatanodeInfoWithStorage[127.0.0.1:42328,DS-ee643d7c-3de5-4690-9056-a1224083e96d,DISK], DatanodeInfoWithStorage[127.0.0.1:41372,DS-64cf04f4-ddce-4ecb-9bab-02651e7d4079,DISK], DatanodeInfoWithStorage[127.0.0.1:37282,DS-0b59097d-5282-456f-8fe6-7050e7eae5f9,DISK], DatanodeInfoWithStorage[127.0.0.1:36532,DS-d1f91146-266b-49e8-a5ff-268f4a416117,DISK], DatanodeInfoWithStorage[127.0.0.1:33786,DS-96e10e3a-04ba-4d6b-9855-a49db613784a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fslock.fair
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1635145764-172.17.0.6-1598166059546:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40686,DS-4a13cc70-7eb1-4920-a594-85a70dc259ab,DISK], DatanodeInfoWithStorage[127.0.0.1:35898,DS-436361cc-8b5f-450a-887a-452757ccdc0d,DISK], DatanodeInfoWithStorage[127.0.0.1:40738,DS-cda05b8a-b43f-4f07-9859-634c318ff8e4,DISK], DatanodeInfoWithStorage[127.0.0.1:39584,DS-a9014205-9215-48f3-9414-0e9253256bcf,DISK], DatanodeInfoWithStorage[127.0.0.1:45144,DS-6f5e2513-72d4-440f-8940-e3231000a0b3,DISK], DatanodeInfoWithStorage[127.0.0.1:39490,DS-8aac6da1-d0b6-40f4-9558-9af569c8bcd0,DISK], DatanodeInfoWithStorage[127.0.0.1:40186,DS-612238ce-e891-4963-8184-47d7fbfd0aac,DISK], DatanodeInfoWithStorage[127.0.0.1:38832,DS-1fbed48c-57ee-4623-a516-a8dfc9eb5fe0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1635145764-172.17.0.6-1598166059546:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40686,DS-4a13cc70-7eb1-4920-a594-85a70dc259ab,DISK], DatanodeInfoWithStorage[127.0.0.1:35898,DS-436361cc-8b5f-450a-887a-452757ccdc0d,DISK], DatanodeInfoWithStorage[127.0.0.1:40738,DS-cda05b8a-b43f-4f07-9859-634c318ff8e4,DISK], DatanodeInfoWithStorage[127.0.0.1:39584,DS-a9014205-9215-48f3-9414-0e9253256bcf,DISK], DatanodeInfoWithStorage[127.0.0.1:45144,DS-6f5e2513-72d4-440f-8940-e3231000a0b3,DISK], DatanodeInfoWithStorage[127.0.0.1:39490,DS-8aac6da1-d0b6-40f4-9558-9af569c8bcd0,DISK], DatanodeInfoWithStorage[127.0.0.1:40186,DS-612238ce-e891-4963-8184-47d7fbfd0aac,DISK], DatanodeInfoWithStorage[127.0.0.1:38832,DS-1fbed48c-57ee-4623-a516-a8dfc9eb5fe0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fslock.fair
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1338367212-172.17.0.6-1598166203060:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36801,DS-7a8554f0-0098-4d12-8af2-ae0883b9dfff,DISK], DatanodeInfoWithStorage[127.0.0.1:42687,DS-b2cc7fbd-68ff-415b-819a-a3c52fde7822,DISK], DatanodeInfoWithStorage[127.0.0.1:43665,DS-ca679601-5c9e-401e-b3f1-55dc08f66eec,DISK], DatanodeInfoWithStorage[127.0.0.1:41367,DS-d8ab93aa-56d0-49a4-87a3-964b741a068e,DISK], DatanodeInfoWithStorage[127.0.0.1:34518,DS-e0ee844e-a6d0-4321-bd52-6db115d42718,DISK], DatanodeInfoWithStorage[127.0.0.1:33554,DS-088a1ece-3329-4254-b0b3-a300b650651c,DISK], DatanodeInfoWithStorage[127.0.0.1:42191,DS-def94e97-3303-4c23-9888-6efa676c4124,DISK], DatanodeInfoWithStorage[127.0.0.1:33784,DS-08948048-3920-4111-8819-077efd26b766,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1338367212-172.17.0.6-1598166203060:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36801,DS-7a8554f0-0098-4d12-8af2-ae0883b9dfff,DISK], DatanodeInfoWithStorage[127.0.0.1:42687,DS-b2cc7fbd-68ff-415b-819a-a3c52fde7822,DISK], DatanodeInfoWithStorage[127.0.0.1:43665,DS-ca679601-5c9e-401e-b3f1-55dc08f66eec,DISK], DatanodeInfoWithStorage[127.0.0.1:41367,DS-d8ab93aa-56d0-49a4-87a3-964b741a068e,DISK], DatanodeInfoWithStorage[127.0.0.1:34518,DS-e0ee844e-a6d0-4321-bd52-6db115d42718,DISK], DatanodeInfoWithStorage[127.0.0.1:33554,DS-088a1ece-3329-4254-b0b3-a300b650651c,DISK], DatanodeInfoWithStorage[127.0.0.1:42191,DS-def94e97-3303-4c23-9888-6efa676c4124,DISK], DatanodeInfoWithStorage[127.0.0.1:33784,DS-08948048-3920-4111-8819-077efd26b766,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fslock.fair
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2066552229-172.17.0.6-1598166547398:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43310,DS-e391587e-b1a3-484b-afab-a43ec26e9532,DISK], DatanodeInfoWithStorage[127.0.0.1:45401,DS-130a96ad-f4e6-4961-ae4d-2883d604ce8c,DISK], DatanodeInfoWithStorage[127.0.0.1:45116,DS-23ab57d9-94eb-4e6e-87fc-3b4269bb05e5,DISK], DatanodeInfoWithStorage[127.0.0.1:40625,DS-32051c60-802e-4546-9f0c-433553c94d94,DISK], DatanodeInfoWithStorage[127.0.0.1:41853,DS-3d785a7a-268d-4734-80d7-a81f5a697123,DISK], DatanodeInfoWithStorage[127.0.0.1:37114,DS-653dcaf2-62d3-4be4-b5a7-a4056539eafe,DISK], DatanodeInfoWithStorage[127.0.0.1:37588,DS-8b25f7db-e3ad-4ba6-8338-62f759fc112b,DISK], DatanodeInfoWithStorage[127.0.0.1:43682,DS-d5ca4db4-6648-432d-8cbc-249408acec90,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2066552229-172.17.0.6-1598166547398:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43310,DS-e391587e-b1a3-484b-afab-a43ec26e9532,DISK], DatanodeInfoWithStorage[127.0.0.1:45401,DS-130a96ad-f4e6-4961-ae4d-2883d604ce8c,DISK], DatanodeInfoWithStorage[127.0.0.1:45116,DS-23ab57d9-94eb-4e6e-87fc-3b4269bb05e5,DISK], DatanodeInfoWithStorage[127.0.0.1:40625,DS-32051c60-802e-4546-9f0c-433553c94d94,DISK], DatanodeInfoWithStorage[127.0.0.1:41853,DS-3d785a7a-268d-4734-80d7-a81f5a697123,DISK], DatanodeInfoWithStorage[127.0.0.1:37114,DS-653dcaf2-62d3-4be4-b5a7-a4056539eafe,DISK], DatanodeInfoWithStorage[127.0.0.1:37588,DS-8b25f7db-e3ad-4ba6-8338-62f759fc112b,DISK], DatanodeInfoWithStorage[127.0.0.1:43682,DS-d5ca4db4-6648-432d-8cbc-249408acec90,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fslock.fair
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-121454-172.17.0.6-1598166927202:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42270,DS-c1011073-e07e-4a97-b9e0-d49fec0a4024,DISK], DatanodeInfoWithStorage[127.0.0.1:43292,DS-5c99b95e-29f9-49c7-868a-f758c3d8cd04,DISK], DatanodeInfoWithStorage[127.0.0.1:38848,DS-40759a5f-cf65-4bc4-9777-64eb3735c981,DISK], DatanodeInfoWithStorage[127.0.0.1:39488,DS-3d400af9-d373-4af8-9bd7-8bc23983daf2,DISK], DatanodeInfoWithStorage[127.0.0.1:41145,DS-7e03fb4e-afad-4eb9-b75f-822d113fa120,DISK], DatanodeInfoWithStorage[127.0.0.1:43798,DS-812cb06d-64cb-44e2-b004-de88cd8e88b0,DISK], DatanodeInfoWithStorage[127.0.0.1:39843,DS-67318f2b-c3e3-44e7-95ba-7025a9b0c386,DISK], DatanodeInfoWithStorage[127.0.0.1:40942,DS-f3201125-c4cd-4011-8cb6-aa1a970887b4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-121454-172.17.0.6-1598166927202:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42270,DS-c1011073-e07e-4a97-b9e0-d49fec0a4024,DISK], DatanodeInfoWithStorage[127.0.0.1:43292,DS-5c99b95e-29f9-49c7-868a-f758c3d8cd04,DISK], DatanodeInfoWithStorage[127.0.0.1:38848,DS-40759a5f-cf65-4bc4-9777-64eb3735c981,DISK], DatanodeInfoWithStorage[127.0.0.1:39488,DS-3d400af9-d373-4af8-9bd7-8bc23983daf2,DISK], DatanodeInfoWithStorage[127.0.0.1:41145,DS-7e03fb4e-afad-4eb9-b75f-822d113fa120,DISK], DatanodeInfoWithStorage[127.0.0.1:43798,DS-812cb06d-64cb-44e2-b004-de88cd8e88b0,DISK], DatanodeInfoWithStorage[127.0.0.1:39843,DS-67318f2b-c3e3-44e7-95ba-7025a9b0c386,DISK], DatanodeInfoWithStorage[127.0.0.1:40942,DS-f3201125-c4cd-4011-8cb6-aa1a970887b4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fslock.fair
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-561251270-172.17.0.6-1598166999597:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38066,DS-d431c0d0-ef2d-4d63-9caa-605c2ac7f664,DISK], DatanodeInfoWithStorage[127.0.0.1:40862,DS-8e14f723-20fe-4a32-9da2-8bd869949fe7,DISK], DatanodeInfoWithStorage[127.0.0.1:34933,DS-dc1b401c-fdcb-4243-8553-5cd2b4665837,DISK], DatanodeInfoWithStorage[127.0.0.1:45730,DS-0b55e040-ea88-4ccf-a4e2-5f46596efe71,DISK], DatanodeInfoWithStorage[127.0.0.1:40784,DS-39bc5aef-aec4-4b84-bd21-38dcced3acd7,DISK], DatanodeInfoWithStorage[127.0.0.1:35951,DS-bdbc06fa-425d-47c6-a261-541da5ef5fd3,DISK], DatanodeInfoWithStorage[127.0.0.1:40581,DS-2f25e485-8017-4b99-8895-a235de3fa99f,DISK], DatanodeInfoWithStorage[127.0.0.1:38533,DS-c099325c-2b42-4857-8ba3-5dca643f8312,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-561251270-172.17.0.6-1598166999597:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38066,DS-d431c0d0-ef2d-4d63-9caa-605c2ac7f664,DISK], DatanodeInfoWithStorage[127.0.0.1:40862,DS-8e14f723-20fe-4a32-9da2-8bd869949fe7,DISK], DatanodeInfoWithStorage[127.0.0.1:34933,DS-dc1b401c-fdcb-4243-8553-5cd2b4665837,DISK], DatanodeInfoWithStorage[127.0.0.1:45730,DS-0b55e040-ea88-4ccf-a4e2-5f46596efe71,DISK], DatanodeInfoWithStorage[127.0.0.1:40784,DS-39bc5aef-aec4-4b84-bd21-38dcced3acd7,DISK], DatanodeInfoWithStorage[127.0.0.1:35951,DS-bdbc06fa-425d-47c6-a261-541da5ef5fd3,DISK], DatanodeInfoWithStorage[127.0.0.1:40581,DS-2f25e485-8017-4b99-8895-a235de3fa99f,DISK], DatanodeInfoWithStorage[127.0.0.1:38533,DS-c099325c-2b42-4857-8ba3-5dca643f8312,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fslock.fair
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1892038640-172.17.0.6-1598167036290:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43590,DS-aea809b9-8f14-4bdb-ad84-7cd522e8e883,DISK], DatanodeInfoWithStorage[127.0.0.1:44634,DS-9b1d14ec-c7a6-4064-b9f3-ae5e232761e5,DISK], DatanodeInfoWithStorage[127.0.0.1:34409,DS-465c7153-bc30-4577-8f37-690fcd3f9937,DISK], DatanodeInfoWithStorage[127.0.0.1:36297,DS-f5a674e4-3885-49a9-bfc0-da557dcbebe9,DISK], DatanodeInfoWithStorage[127.0.0.1:42548,DS-8eb588a2-e018-417c-a94e-3568f555e5bc,DISK], DatanodeInfoWithStorage[127.0.0.1:33241,DS-5437c64e-625f-40ac-a7ad-5392f3cb0ba1,DISK], DatanodeInfoWithStorage[127.0.0.1:35351,DS-0f4cd2cc-a2ab-42c1-8bf9-cde51c201061,DISK], DatanodeInfoWithStorage[127.0.0.1:46006,DS-cfa39f57-9b1d-4d1e-b8a6-64bac16d82fe,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1892038640-172.17.0.6-1598167036290:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43590,DS-aea809b9-8f14-4bdb-ad84-7cd522e8e883,DISK], DatanodeInfoWithStorage[127.0.0.1:44634,DS-9b1d14ec-c7a6-4064-b9f3-ae5e232761e5,DISK], DatanodeInfoWithStorage[127.0.0.1:34409,DS-465c7153-bc30-4577-8f37-690fcd3f9937,DISK], DatanodeInfoWithStorage[127.0.0.1:36297,DS-f5a674e4-3885-49a9-bfc0-da557dcbebe9,DISK], DatanodeInfoWithStorage[127.0.0.1:42548,DS-8eb588a2-e018-417c-a94e-3568f555e5bc,DISK], DatanodeInfoWithStorage[127.0.0.1:33241,DS-5437c64e-625f-40ac-a7ad-5392f3cb0ba1,DISK], DatanodeInfoWithStorage[127.0.0.1:35351,DS-0f4cd2cc-a2ab-42c1-8bf9-cde51c201061,DISK], DatanodeInfoWithStorage[127.0.0.1:46006,DS-cfa39f57-9b1d-4d1e-b8a6-64bac16d82fe,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fslock.fair
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1999942881-172.17.0.6-1598167206498:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32842,DS-c0d16392-2073-48aa-96b6-d67fdee21dee,DISK], DatanodeInfoWithStorage[127.0.0.1:33271,DS-a8c60188-38da-4aeb-abc1-da44874d874c,DISK], DatanodeInfoWithStorage[127.0.0.1:45363,DS-5f387222-d8c9-4fb4-aaaa-0231785b0701,DISK], DatanodeInfoWithStorage[127.0.0.1:44884,DS-839d0afd-f2ea-4140-a595-a0c2c6a9fe15,DISK], DatanodeInfoWithStorage[127.0.0.1:42006,DS-d485e25c-7fbf-4aa6-a80d-ea8ec2c6fb94,DISK], DatanodeInfoWithStorage[127.0.0.1:45666,DS-8aa97343-085a-43ff-a1e4-19268747a81e,DISK], DatanodeInfoWithStorage[127.0.0.1:33436,DS-afabb24a-6b6f-43cb-90e8-8a98b1b9058c,DISK], DatanodeInfoWithStorage[127.0.0.1:41478,DS-c6f55068-72cc-476d-88ee-37fb476e39ca,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1999942881-172.17.0.6-1598167206498:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32842,DS-c0d16392-2073-48aa-96b6-d67fdee21dee,DISK], DatanodeInfoWithStorage[127.0.0.1:33271,DS-a8c60188-38da-4aeb-abc1-da44874d874c,DISK], DatanodeInfoWithStorage[127.0.0.1:45363,DS-5f387222-d8c9-4fb4-aaaa-0231785b0701,DISK], DatanodeInfoWithStorage[127.0.0.1:44884,DS-839d0afd-f2ea-4140-a595-a0c2c6a9fe15,DISK], DatanodeInfoWithStorage[127.0.0.1:42006,DS-d485e25c-7fbf-4aa6-a80d-ea8ec2c6fb94,DISK], DatanodeInfoWithStorage[127.0.0.1:45666,DS-8aa97343-085a-43ff-a1e4-19268747a81e,DISK], DatanodeInfoWithStorage[127.0.0.1:33436,DS-afabb24a-6b6f-43cb-90e8-8a98b1b9058c,DISK], DatanodeInfoWithStorage[127.0.0.1:41478,DS-c6f55068-72cc-476d-88ee-37fb476e39ca,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fslock.fair
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-233497965-172.17.0.6-1598167901186:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33052,DS-d80bfb3c-3262-496c-a0e2-9068803d1efb,DISK], DatanodeInfoWithStorage[127.0.0.1:40496,DS-7124a53c-060d-43d5-b30c-f79fd0430f1f,DISK], DatanodeInfoWithStorage[127.0.0.1:40622,DS-6baff0f8-43fb-4f37-8767-28da9e09307e,DISK], DatanodeInfoWithStorage[127.0.0.1:42139,DS-d13ee518-fd51-448f-aef8-25409b2159c2,DISK], DatanodeInfoWithStorage[127.0.0.1:41734,DS-c45869a5-9626-4032-b971-1d483309d525,DISK], DatanodeInfoWithStorage[127.0.0.1:33825,DS-f57fb1b5-a0f5-47b4-b32f-d692a7e14843,DISK], DatanodeInfoWithStorage[127.0.0.1:45275,DS-4c89b9b0-272b-48f0-98e2-78930a3f5d4a,DISK], DatanodeInfoWithStorage[127.0.0.1:42661,DS-3e421c89-b384-41db-9675-81ef0524738d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-233497965-172.17.0.6-1598167901186:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33052,DS-d80bfb3c-3262-496c-a0e2-9068803d1efb,DISK], DatanodeInfoWithStorage[127.0.0.1:40496,DS-7124a53c-060d-43d5-b30c-f79fd0430f1f,DISK], DatanodeInfoWithStorage[127.0.0.1:40622,DS-6baff0f8-43fb-4f37-8767-28da9e09307e,DISK], DatanodeInfoWithStorage[127.0.0.1:42139,DS-d13ee518-fd51-448f-aef8-25409b2159c2,DISK], DatanodeInfoWithStorage[127.0.0.1:41734,DS-c45869a5-9626-4032-b971-1d483309d525,DISK], DatanodeInfoWithStorage[127.0.0.1:33825,DS-f57fb1b5-a0f5-47b4-b32f-d692a7e14843,DISK], DatanodeInfoWithStorage[127.0.0.1:45275,DS-4c89b9b0-272b-48f0-98e2-78930a3f5d4a,DISK], DatanodeInfoWithStorage[127.0.0.1:42661,DS-3e421c89-b384-41db-9675-81ef0524738d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fslock.fair
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1668108004-172.17.0.6-1598167934136:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39097,DS-1070b345-be55-4dbb-832f-40c513dc5f2e,DISK], DatanodeInfoWithStorage[127.0.0.1:41529,DS-c480b8e7-7cb8-4f08-9b28-2f7a2b8d5c31,DISK], DatanodeInfoWithStorage[127.0.0.1:33120,DS-69d18edf-b4cf-4fbf-9e78-251221d791bc,DISK], DatanodeInfoWithStorage[127.0.0.1:37093,DS-e3ef2e0a-6853-48b9-9242-8c713b807e26,DISK], DatanodeInfoWithStorage[127.0.0.1:36755,DS-e3197c53-f61a-4721-a07b-81250eea2ac2,DISK], DatanodeInfoWithStorage[127.0.0.1:41061,DS-81e7cde9-7d49-4f2b-ac33-d08c7e28a59e,DISK], DatanodeInfoWithStorage[127.0.0.1:35479,DS-8976a25a-632d-4d6c-8d53-ce6e9fd3b14d,DISK], DatanodeInfoWithStorage[127.0.0.1:33705,DS-69cd2a5d-a959-4c77-ae84-cf25ed27278f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1668108004-172.17.0.6-1598167934136:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39097,DS-1070b345-be55-4dbb-832f-40c513dc5f2e,DISK], DatanodeInfoWithStorage[127.0.0.1:41529,DS-c480b8e7-7cb8-4f08-9b28-2f7a2b8d5c31,DISK], DatanodeInfoWithStorage[127.0.0.1:33120,DS-69d18edf-b4cf-4fbf-9e78-251221d791bc,DISK], DatanodeInfoWithStorage[127.0.0.1:37093,DS-e3ef2e0a-6853-48b9-9242-8c713b807e26,DISK], DatanodeInfoWithStorage[127.0.0.1:36755,DS-e3197c53-f61a-4721-a07b-81250eea2ac2,DISK], DatanodeInfoWithStorage[127.0.0.1:41061,DS-81e7cde9-7d49-4f2b-ac33-d08c7e28a59e,DISK], DatanodeInfoWithStorage[127.0.0.1:35479,DS-8976a25a-632d-4d6c-8d53-ce6e9fd3b14d,DISK], DatanodeInfoWithStorage[127.0.0.1:33705,DS-69cd2a5d-a959-4c77-ae84-cf25ed27278f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fslock.fair
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-476202523-172.17.0.6-1598168197068:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46407,DS-cebd2cff-5774-4613-ba6a-1a377234afb1,DISK], DatanodeInfoWithStorage[127.0.0.1:38100,DS-fa6ee137-a367-45d8-adae-344747fa7d35,DISK], DatanodeInfoWithStorage[127.0.0.1:44873,DS-77e1c454-3462-46fe-9d58-721f9fecf979,DISK], DatanodeInfoWithStorage[127.0.0.1:38445,DS-892a8d69-e43d-4690-823b-588a59e153df,DISK], DatanodeInfoWithStorage[127.0.0.1:42082,DS-a7c0913e-2529-4cc3-82a4-ed667a145fd6,DISK], DatanodeInfoWithStorage[127.0.0.1:33216,DS-51a50e76-86ad-463c-b761-1ea38596bd57,DISK], DatanodeInfoWithStorage[127.0.0.1:41059,DS-061d9cea-0aef-478f-8747-88f53a659cfe,DISK], DatanodeInfoWithStorage[127.0.0.1:37477,DS-5afa447e-1ed8-4382-8161-2244fedf18c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-476202523-172.17.0.6-1598168197068:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46407,DS-cebd2cff-5774-4613-ba6a-1a377234afb1,DISK], DatanodeInfoWithStorage[127.0.0.1:38100,DS-fa6ee137-a367-45d8-adae-344747fa7d35,DISK], DatanodeInfoWithStorage[127.0.0.1:44873,DS-77e1c454-3462-46fe-9d58-721f9fecf979,DISK], DatanodeInfoWithStorage[127.0.0.1:38445,DS-892a8d69-e43d-4690-823b-588a59e153df,DISK], DatanodeInfoWithStorage[127.0.0.1:42082,DS-a7c0913e-2529-4cc3-82a4-ed667a145fd6,DISK], DatanodeInfoWithStorage[127.0.0.1:33216,DS-51a50e76-86ad-463c-b761-1ea38596bd57,DISK], DatanodeInfoWithStorage[127.0.0.1:41059,DS-061d9cea-0aef-478f-8747-88f53a659cfe,DISK], DatanodeInfoWithStorage[127.0.0.1:37477,DS-5afa447e-1ed8-4382-8161-2244fedf18c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fslock.fair
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2131654333-172.17.0.6-1598168266198:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34038,DS-66ad0345-68c1-46ba-aee2-62dbbab00a69,DISK], DatanodeInfoWithStorage[127.0.0.1:42872,DS-5d85c80c-a374-482f-8924-50c521bccf80,DISK], DatanodeInfoWithStorage[127.0.0.1:36187,DS-fad61c55-d58a-4aac-aab1-b30f5bcfb9b4,DISK], DatanodeInfoWithStorage[127.0.0.1:39256,DS-44c2db91-7762-49b0-b9a2-246408f0ab38,DISK], DatanodeInfoWithStorage[127.0.0.1:44249,DS-ac321723-c5b8-49b9-81ff-b8dad7d5d615,DISK], DatanodeInfoWithStorage[127.0.0.1:43135,DS-153769a1-1945-45d7-b616-8a7684c073fd,DISK], DatanodeInfoWithStorage[127.0.0.1:44862,DS-497f1ed8-40d9-445e-8d9a-52d7239c0da5,DISK], DatanodeInfoWithStorage[127.0.0.1:34817,DS-aa828f8a-9d9f-4d40-b7aa-988dcf170e05,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2131654333-172.17.0.6-1598168266198:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34038,DS-66ad0345-68c1-46ba-aee2-62dbbab00a69,DISK], DatanodeInfoWithStorage[127.0.0.1:42872,DS-5d85c80c-a374-482f-8924-50c521bccf80,DISK], DatanodeInfoWithStorage[127.0.0.1:36187,DS-fad61c55-d58a-4aac-aab1-b30f5bcfb9b4,DISK], DatanodeInfoWithStorage[127.0.0.1:39256,DS-44c2db91-7762-49b0-b9a2-246408f0ab38,DISK], DatanodeInfoWithStorage[127.0.0.1:44249,DS-ac321723-c5b8-49b9-81ff-b8dad7d5d615,DISK], DatanodeInfoWithStorage[127.0.0.1:43135,DS-153769a1-1945-45d7-b616-8a7684c073fd,DISK], DatanodeInfoWithStorage[127.0.0.1:44862,DS-497f1ed8-40d9-445e-8d9a-52d7239c0da5,DISK], DatanodeInfoWithStorage[127.0.0.1:34817,DS-aa828f8a-9d9f-4d40-b7aa-988dcf170e05,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fslock.fair
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1224798403-172.17.0.6-1598168430749:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46735,DS-f616482b-96b7-464c-ad05-c00868dcc4b8,DISK], DatanodeInfoWithStorage[127.0.0.1:35145,DS-fbdb708a-6118-4d61-9363-ee69f51ed60f,DISK], DatanodeInfoWithStorage[127.0.0.1:36062,DS-65421069-1194-4521-85e4-56828916fef2,DISK], DatanodeInfoWithStorage[127.0.0.1:46687,DS-8b5d3b25-3d57-4a10-bdde-a17a6183391a,DISK], DatanodeInfoWithStorage[127.0.0.1:34805,DS-deccea61-0cbf-4cb4-ae5e-d2a47144c620,DISK], DatanodeInfoWithStorage[127.0.0.1:39075,DS-a2c15240-8217-493d-a878-6daf7b2fe782,DISK], DatanodeInfoWithStorage[127.0.0.1:35519,DS-294a5094-3265-4fca-87fa-33c6ee2187d5,DISK], DatanodeInfoWithStorage[127.0.0.1:46205,DS-e8f9cba8-5d95-4500-9a3c-6445595f4630,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1224798403-172.17.0.6-1598168430749:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46735,DS-f616482b-96b7-464c-ad05-c00868dcc4b8,DISK], DatanodeInfoWithStorage[127.0.0.1:35145,DS-fbdb708a-6118-4d61-9363-ee69f51ed60f,DISK], DatanodeInfoWithStorage[127.0.0.1:36062,DS-65421069-1194-4521-85e4-56828916fef2,DISK], DatanodeInfoWithStorage[127.0.0.1:46687,DS-8b5d3b25-3d57-4a10-bdde-a17a6183391a,DISK], DatanodeInfoWithStorage[127.0.0.1:34805,DS-deccea61-0cbf-4cb4-ae5e-d2a47144c620,DISK], DatanodeInfoWithStorage[127.0.0.1:39075,DS-a2c15240-8217-493d-a878-6daf7b2fe782,DISK], DatanodeInfoWithStorage[127.0.0.1:35519,DS-294a5094-3265-4fca-87fa-33c6ee2187d5,DISK], DatanodeInfoWithStorage[127.0.0.1:46205,DS-e8f9cba8-5d95-4500-9a3c-6445595f4630,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fslock.fair
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-247929104-172.17.0.6-1598168529660:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33939,DS-b7ccf303-2fa2-4614-87e3-8a78d4e9d7f1,DISK], DatanodeInfoWithStorage[127.0.0.1:44211,DS-650cb54e-c167-4a18-947b-597831565a6d,DISK], DatanodeInfoWithStorage[127.0.0.1:46444,DS-09b79627-2180-43de-9739-16e89bb64e59,DISK], DatanodeInfoWithStorage[127.0.0.1:41361,DS-8dbc1cc3-c356-4a26-885a-26f95e5ced32,DISK], DatanodeInfoWithStorage[127.0.0.1:46052,DS-45389378-4c21-4fcf-b9c7-8254b04e2b05,DISK], DatanodeInfoWithStorage[127.0.0.1:42122,DS-407da8a2-fba3-4961-92ab-721e91bcf30d,DISK], DatanodeInfoWithStorage[127.0.0.1:41270,DS-4e202cf5-d7d8-49f7-ad4f-49567de00867,DISK], DatanodeInfoWithStorage[127.0.0.1:44203,DS-10ac01b5-92a8-44db-b8e6-a1cf7cac9d1a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-247929104-172.17.0.6-1598168529660:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33939,DS-b7ccf303-2fa2-4614-87e3-8a78d4e9d7f1,DISK], DatanodeInfoWithStorage[127.0.0.1:44211,DS-650cb54e-c167-4a18-947b-597831565a6d,DISK], DatanodeInfoWithStorage[127.0.0.1:46444,DS-09b79627-2180-43de-9739-16e89bb64e59,DISK], DatanodeInfoWithStorage[127.0.0.1:41361,DS-8dbc1cc3-c356-4a26-885a-26f95e5ced32,DISK], DatanodeInfoWithStorage[127.0.0.1:46052,DS-45389378-4c21-4fcf-b9c7-8254b04e2b05,DISK], DatanodeInfoWithStorage[127.0.0.1:42122,DS-407da8a2-fba3-4961-92ab-721e91bcf30d,DISK], DatanodeInfoWithStorage[127.0.0.1:41270,DS-4e202cf5-d7d8-49f7-ad4f-49567de00867,DISK], DatanodeInfoWithStorage[127.0.0.1:44203,DS-10ac01b5-92a8-44db-b8e6-a1cf7cac9d1a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fslock.fair
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2146148534-172.17.0.6-1598168559724:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44124,DS-184a5dec-795b-47c6-9648-196453f77cff,DISK], DatanodeInfoWithStorage[127.0.0.1:42326,DS-75e127f9-32a9-4d70-b16c-a30d2968b4c5,DISK], DatanodeInfoWithStorage[127.0.0.1:36010,DS-287b8d6f-1ab2-41e0-91ed-945c6598030f,DISK], DatanodeInfoWithStorage[127.0.0.1:44106,DS-bd5a08b5-8fbe-4b6d-a65e-75a54a7c127e,DISK], DatanodeInfoWithStorage[127.0.0.1:41646,DS-ce824aee-ba0f-4104-9b4d-0729e8b6c042,DISK], DatanodeInfoWithStorage[127.0.0.1:39599,DS-3c5566e8-2e30-46d0-8f7b-26950c2f7aff,DISK], DatanodeInfoWithStorage[127.0.0.1:35975,DS-5e8046bd-f538-48a5-b443-14e6a7fabfb5,DISK], DatanodeInfoWithStorage[127.0.0.1:45822,DS-d8a98fe4-a7ab-4730-b830-e5ee685b70b3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2146148534-172.17.0.6-1598168559724:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44124,DS-184a5dec-795b-47c6-9648-196453f77cff,DISK], DatanodeInfoWithStorage[127.0.0.1:42326,DS-75e127f9-32a9-4d70-b16c-a30d2968b4c5,DISK], DatanodeInfoWithStorage[127.0.0.1:36010,DS-287b8d6f-1ab2-41e0-91ed-945c6598030f,DISK], DatanodeInfoWithStorage[127.0.0.1:44106,DS-bd5a08b5-8fbe-4b6d-a65e-75a54a7c127e,DISK], DatanodeInfoWithStorage[127.0.0.1:41646,DS-ce824aee-ba0f-4104-9b4d-0729e8b6c042,DISK], DatanodeInfoWithStorage[127.0.0.1:39599,DS-3c5566e8-2e30-46d0-8f7b-26950c2f7aff,DISK], DatanodeInfoWithStorage[127.0.0.1:35975,DS-5e8046bd-f538-48a5-b443-14e6a7fabfb5,DISK], DatanodeInfoWithStorage[127.0.0.1:45822,DS-d8a98fe4-a7ab-4730-b830-e5ee685b70b3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.fslock.fair
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1329143200-172.17.0.6-1598168590477:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45833,DS-857712aa-6a60-42f2-85f5-f972b7393667,DISK], DatanodeInfoWithStorage[127.0.0.1:44914,DS-ccdf59d1-d492-44d1-a320-a29ea628aa94,DISK], DatanodeInfoWithStorage[127.0.0.1:39150,DS-562fa2f9-6bb4-48e6-9650-211765175d0e,DISK], DatanodeInfoWithStorage[127.0.0.1:46131,DS-f3c0f7c6-3859-462e-bc83-41536d593916,DISK], DatanodeInfoWithStorage[127.0.0.1:41510,DS-2295a61e-2bc5-4a54-8e80-a802403f3a10,DISK], DatanodeInfoWithStorage[127.0.0.1:45378,DS-850ee9e9-67be-4a9f-9bc1-89c390b47f06,DISK], DatanodeInfoWithStorage[127.0.0.1:33925,DS-141fd5e6-a73e-4e67-938c-70b5aa9826d7,DISK], DatanodeInfoWithStorage[127.0.0.1:39948,DS-fb2b5b79-853b-4f74-8e61-22e904824169,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1329143200-172.17.0.6-1598168590477:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45833,DS-857712aa-6a60-42f2-85f5-f972b7393667,DISK], DatanodeInfoWithStorage[127.0.0.1:44914,DS-ccdf59d1-d492-44d1-a320-a29ea628aa94,DISK], DatanodeInfoWithStorage[127.0.0.1:39150,DS-562fa2f9-6bb4-48e6-9650-211765175d0e,DISK], DatanodeInfoWithStorage[127.0.0.1:46131,DS-f3c0f7c6-3859-462e-bc83-41536d593916,DISK], DatanodeInfoWithStorage[127.0.0.1:41510,DS-2295a61e-2bc5-4a54-8e80-a802403f3a10,DISK], DatanodeInfoWithStorage[127.0.0.1:45378,DS-850ee9e9-67be-4a9f-9bc1-89c390b47f06,DISK], DatanodeInfoWithStorage[127.0.0.1:33925,DS-141fd5e6-a73e-4e67-938c-70b5aa9826d7,DISK], DatanodeInfoWithStorage[127.0.0.1:39948,DS-fb2b5b79-853b-4f74-8e61-22e904824169,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fslock.fair
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1988811358-172.17.0.6-1598168623784:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37736,DS-7e7ec16b-c159-4b99-9083-5a63db2ddcee,DISK], DatanodeInfoWithStorage[127.0.0.1:41720,DS-fdd5e14c-20a4-4ef9-8a83-d85ebc2af6cf,DISK], DatanodeInfoWithStorage[127.0.0.1:46280,DS-5cf5e979-c47d-449e-b95d-d72daea326ff,DISK], DatanodeInfoWithStorage[127.0.0.1:37039,DS-e8beb9ef-51ec-4526-9c28-70ee02a1f3ad,DISK], DatanodeInfoWithStorage[127.0.0.1:41310,DS-b28d12cd-7c7e-4a5c-8096-21c57f859cdb,DISK], DatanodeInfoWithStorage[127.0.0.1:41862,DS-ad58ac2a-ff37-4765-92d0-d722633c7593,DISK], DatanodeInfoWithStorage[127.0.0.1:35581,DS-6b6b34b4-9404-4571-b5f4-e63c61ebcfd8,DISK], DatanodeInfoWithStorage[127.0.0.1:39352,DS-b1be1607-013d-47dd-b8be-833b3e62ca0e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1988811358-172.17.0.6-1598168623784:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37736,DS-7e7ec16b-c159-4b99-9083-5a63db2ddcee,DISK], DatanodeInfoWithStorage[127.0.0.1:41720,DS-fdd5e14c-20a4-4ef9-8a83-d85ebc2af6cf,DISK], DatanodeInfoWithStorage[127.0.0.1:46280,DS-5cf5e979-c47d-449e-b95d-d72daea326ff,DISK], DatanodeInfoWithStorage[127.0.0.1:37039,DS-e8beb9ef-51ec-4526-9c28-70ee02a1f3ad,DISK], DatanodeInfoWithStorage[127.0.0.1:41310,DS-b28d12cd-7c7e-4a5c-8096-21c57f859cdb,DISK], DatanodeInfoWithStorage[127.0.0.1:41862,DS-ad58ac2a-ff37-4765-92d0-d722633c7593,DISK], DatanodeInfoWithStorage[127.0.0.1:35581,DS-6b6b34b4-9404-4571-b5f4-e63c61ebcfd8,DISK], DatanodeInfoWithStorage[127.0.0.1:39352,DS-b1be1607-013d-47dd-b8be-833b3e62ca0e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fslock.fair
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-150431041-172.17.0.6-1598168881786:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33614,DS-fd7c998a-ab36-4c49-91f7-ff2ed2a1b162,DISK], DatanodeInfoWithStorage[127.0.0.1:42096,DS-365ec0ad-e0ab-4f81-86b6-93b14dad8c78,DISK], DatanodeInfoWithStorage[127.0.0.1:45193,DS-f3ebe768-743e-492a-a291-f16b6dd1f967,DISK], DatanodeInfoWithStorage[127.0.0.1:39972,DS-f001d769-c655-4883-b478-5e07b63582c5,DISK], DatanodeInfoWithStorage[127.0.0.1:45301,DS-a2d88d67-0f23-4c1c-9b6d-d2d5ccfa6bba,DISK], DatanodeInfoWithStorage[127.0.0.1:38972,DS-ba397db4-2c9c-41c9-aed9-b733e3741555,DISK], DatanodeInfoWithStorage[127.0.0.1:42967,DS-68fbcd0f-8bf1-42e1-b3ef-54de593f1d95,DISK], DatanodeInfoWithStorage[127.0.0.1:35146,DS-3cc46678-366e-4330-b53c-13ff6ddc157d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-150431041-172.17.0.6-1598168881786:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33614,DS-fd7c998a-ab36-4c49-91f7-ff2ed2a1b162,DISK], DatanodeInfoWithStorage[127.0.0.1:42096,DS-365ec0ad-e0ab-4f81-86b6-93b14dad8c78,DISK], DatanodeInfoWithStorage[127.0.0.1:45193,DS-f3ebe768-743e-492a-a291-f16b6dd1f967,DISK], DatanodeInfoWithStorage[127.0.0.1:39972,DS-f001d769-c655-4883-b478-5e07b63582c5,DISK], DatanodeInfoWithStorage[127.0.0.1:45301,DS-a2d88d67-0f23-4c1c-9b6d-d2d5ccfa6bba,DISK], DatanodeInfoWithStorage[127.0.0.1:38972,DS-ba397db4-2c9c-41c9-aed9-b733e3741555,DISK], DatanodeInfoWithStorage[127.0.0.1:42967,DS-68fbcd0f-8bf1-42e1-b3ef-54de593f1d95,DISK], DatanodeInfoWithStorage[127.0.0.1:35146,DS-3cc46678-366e-4330-b53c-13ff6ddc157d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.fslock.fair
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1553374216-172.17.0.6-1598168912066:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38472,DS-da497ec1-a630-406b-97f2-f280b655c6b9,DISK], DatanodeInfoWithStorage[127.0.0.1:36188,DS-14fbb93f-6078-4099-be6a-e78344feaf38,DISK], DatanodeInfoWithStorage[127.0.0.1:46255,DS-b8d9083f-bc11-4724-a0a0-7ca373a5082f,DISK], DatanodeInfoWithStorage[127.0.0.1:44247,DS-5c95c18d-cf97-4c53-b173-6dc221f00db6,DISK], DatanodeInfoWithStorage[127.0.0.1:39699,DS-b8b863a3-5599-4526-ab58-fd1f37696598,DISK], DatanodeInfoWithStorage[127.0.0.1:36015,DS-cbda23c7-7ba5-4020-b5bf-ce144180e49b,DISK], DatanodeInfoWithStorage[127.0.0.1:37723,DS-a5ebd9f7-57ac-4cc1-af72-2020c814a24d,DISK], DatanodeInfoWithStorage[127.0.0.1:36995,DS-51db991f-688c-4d53-aaf0-573a47fbb04b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1553374216-172.17.0.6-1598168912066:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38472,DS-da497ec1-a630-406b-97f2-f280b655c6b9,DISK], DatanodeInfoWithStorage[127.0.0.1:36188,DS-14fbb93f-6078-4099-be6a-e78344feaf38,DISK], DatanodeInfoWithStorage[127.0.0.1:46255,DS-b8d9083f-bc11-4724-a0a0-7ca373a5082f,DISK], DatanodeInfoWithStorage[127.0.0.1:44247,DS-5c95c18d-cf97-4c53-b173-6dc221f00db6,DISK], DatanodeInfoWithStorage[127.0.0.1:39699,DS-b8b863a3-5599-4526-ab58-fd1f37696598,DISK], DatanodeInfoWithStorage[127.0.0.1:36015,DS-cbda23c7-7ba5-4020-b5bf-ce144180e49b,DISK], DatanodeInfoWithStorage[127.0.0.1:37723,DS-a5ebd9f7-57ac-4cc1-af72-2020c814a24d,DISK], DatanodeInfoWithStorage[127.0.0.1:36995,DS-51db991f-688c-4d53-aaf0-573a47fbb04b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fslock.fair
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-316964485-172.17.0.6-1598168949005:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34954,DS-34562afa-c609-483e-aa2f-31ce931dd789,DISK], DatanodeInfoWithStorage[127.0.0.1:40698,DS-2155c399-d9ea-4fb1-a612-7fce2f55d068,DISK], DatanodeInfoWithStorage[127.0.0.1:43919,DS-c10d1e2b-9b1e-4162-86dc-aa6328210c52,DISK], DatanodeInfoWithStorage[127.0.0.1:38083,DS-6d4fba4c-5da9-4dd6-b436-865aec263377,DISK], DatanodeInfoWithStorage[127.0.0.1:44290,DS-da700d8a-59b7-49e7-80e8-866916d7f01a,DISK], DatanodeInfoWithStorage[127.0.0.1:42476,DS-3eb242f0-2bbf-418f-aec0-154fc6dd2436,DISK], DatanodeInfoWithStorage[127.0.0.1:34398,DS-b5d95abf-7e7e-4cec-9696-7dd446d5229c,DISK], DatanodeInfoWithStorage[127.0.0.1:42968,DS-c1412705-d52e-4e1f-b0a6-1f6e73df8dd2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-316964485-172.17.0.6-1598168949005:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34954,DS-34562afa-c609-483e-aa2f-31ce931dd789,DISK], DatanodeInfoWithStorage[127.0.0.1:40698,DS-2155c399-d9ea-4fb1-a612-7fce2f55d068,DISK], DatanodeInfoWithStorage[127.0.0.1:43919,DS-c10d1e2b-9b1e-4162-86dc-aa6328210c52,DISK], DatanodeInfoWithStorage[127.0.0.1:38083,DS-6d4fba4c-5da9-4dd6-b436-865aec263377,DISK], DatanodeInfoWithStorage[127.0.0.1:44290,DS-da700d8a-59b7-49e7-80e8-866916d7f01a,DISK], DatanodeInfoWithStorage[127.0.0.1:42476,DS-3eb242f0-2bbf-418f-aec0-154fc6dd2436,DISK], DatanodeInfoWithStorage[127.0.0.1:34398,DS-b5d95abf-7e7e-4cec-9696-7dd446d5229c,DISK], DatanodeInfoWithStorage[127.0.0.1:42968,DS-c1412705-d52e-4e1f-b0a6-1f6e73df8dd2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fslock.fair
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-335347649-172.17.0.6-1598168979193:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33380,DS-c4905045-2670-48c2-98f3-c9e06f19e1d2,DISK], DatanodeInfoWithStorage[127.0.0.1:42654,DS-7b334db8-b0b7-4140-ae9d-3f8fb945ac50,DISK], DatanodeInfoWithStorage[127.0.0.1:34450,DS-ae356f8b-c3dc-45af-8b25-e9245ed33a62,DISK], DatanodeInfoWithStorage[127.0.0.1:37935,DS-2d014674-0290-433f-807a-015a30eee456,DISK], DatanodeInfoWithStorage[127.0.0.1:44806,DS-18966912-1465-42c2-818b-d89c615e29e4,DISK], DatanodeInfoWithStorage[127.0.0.1:41825,DS-70954c2b-0985-46d0-ae2e-de3f85fb740e,DISK], DatanodeInfoWithStorage[127.0.0.1:44568,DS-d08d4810-ad01-401b-8204-11cb808e57e5,DISK], DatanodeInfoWithStorage[127.0.0.1:43775,DS-d905695c-c42a-41b3-abea-da7d542cbc10,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-335347649-172.17.0.6-1598168979193:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33380,DS-c4905045-2670-48c2-98f3-c9e06f19e1d2,DISK], DatanodeInfoWithStorage[127.0.0.1:42654,DS-7b334db8-b0b7-4140-ae9d-3f8fb945ac50,DISK], DatanodeInfoWithStorage[127.0.0.1:34450,DS-ae356f8b-c3dc-45af-8b25-e9245ed33a62,DISK], DatanodeInfoWithStorage[127.0.0.1:37935,DS-2d014674-0290-433f-807a-015a30eee456,DISK], DatanodeInfoWithStorage[127.0.0.1:44806,DS-18966912-1465-42c2-818b-d89c615e29e4,DISK], DatanodeInfoWithStorage[127.0.0.1:41825,DS-70954c2b-0985-46d0-ae2e-de3f85fb740e,DISK], DatanodeInfoWithStorage[127.0.0.1:44568,DS-d08d4810-ad01-401b-8204-11cb808e57e5,DISK], DatanodeInfoWithStorage[127.0.0.1:43775,DS-d905695c-c42a-41b3-abea-da7d542cbc10,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fslock.fair
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-850401205-172.17.0.6-1598169038238:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38062,DS-17fe466a-f1c1-41b6-8042-3988c5314840,DISK], DatanodeInfoWithStorage[127.0.0.1:40938,DS-1cccd0b2-bcb2-4b6d-8ae1-4fdd4da3ed35,DISK], DatanodeInfoWithStorage[127.0.0.1:36059,DS-e6a3695f-3bb2-41e4-8e5b-6ae6e648fbb0,DISK], DatanodeInfoWithStorage[127.0.0.1:38444,DS-e3f6a5c7-f373-4221-b634-35645a9b6b20,DISK], DatanodeInfoWithStorage[127.0.0.1:40863,DS-f97a85b2-53b4-4e0e-93e2-49584b9d9666,DISK], DatanodeInfoWithStorage[127.0.0.1:34169,DS-9611e8ce-cd01-489b-82f4-1f1822958b73,DISK], DatanodeInfoWithStorage[127.0.0.1:34476,DS-1f76279e-7398-41b6-aecc-1fe98a083e10,DISK], DatanodeInfoWithStorage[127.0.0.1:33916,DS-90865bf6-1f7a-4682-821b-5cdcb0cc9a41,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-850401205-172.17.0.6-1598169038238:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38062,DS-17fe466a-f1c1-41b6-8042-3988c5314840,DISK], DatanodeInfoWithStorage[127.0.0.1:40938,DS-1cccd0b2-bcb2-4b6d-8ae1-4fdd4da3ed35,DISK], DatanodeInfoWithStorage[127.0.0.1:36059,DS-e6a3695f-3bb2-41e4-8e5b-6ae6e648fbb0,DISK], DatanodeInfoWithStorage[127.0.0.1:38444,DS-e3f6a5c7-f373-4221-b634-35645a9b6b20,DISK], DatanodeInfoWithStorage[127.0.0.1:40863,DS-f97a85b2-53b4-4e0e-93e2-49584b9d9666,DISK], DatanodeInfoWithStorage[127.0.0.1:34169,DS-9611e8ce-cd01-489b-82f4-1f1822958b73,DISK], DatanodeInfoWithStorage[127.0.0.1:34476,DS-1f76279e-7398-41b6-aecc-1fe98a083e10,DISK], DatanodeInfoWithStorage[127.0.0.1:33916,DS-90865bf6-1f7a-4682-821b-5cdcb0cc9a41,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fslock.fair
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2127348486-172.17.0.6-1598169076888:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44602,DS-bebf3f53-f289-455a-9efb-cd3447590412,DISK], DatanodeInfoWithStorage[127.0.0.1:45328,DS-116fa346-ce3f-469d-8ac1-4393bdb4cc8d,DISK], DatanodeInfoWithStorage[127.0.0.1:37531,DS-23607681-de3c-432f-8f67-f30184265b86,DISK], DatanodeInfoWithStorage[127.0.0.1:42712,DS-b31faace-9582-4f53-87ea-9aea33ee6025,DISK], DatanodeInfoWithStorage[127.0.0.1:42417,DS-ce7f5ae2-7329-4f99-9446-b43705008211,DISK], DatanodeInfoWithStorage[127.0.0.1:39253,DS-0bd32815-b1a7-49e0-87e4-52aef73b74ed,DISK], DatanodeInfoWithStorage[127.0.0.1:42014,DS-598b9701-6205-42b8-ad67-4d6048c4199a,DISK], DatanodeInfoWithStorage[127.0.0.1:43623,DS-0fef69cd-26fc-4967-bfa0-a3f41e26cf0b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2127348486-172.17.0.6-1598169076888:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44602,DS-bebf3f53-f289-455a-9efb-cd3447590412,DISK], DatanodeInfoWithStorage[127.0.0.1:45328,DS-116fa346-ce3f-469d-8ac1-4393bdb4cc8d,DISK], DatanodeInfoWithStorage[127.0.0.1:37531,DS-23607681-de3c-432f-8f67-f30184265b86,DISK], DatanodeInfoWithStorage[127.0.0.1:42712,DS-b31faace-9582-4f53-87ea-9aea33ee6025,DISK], DatanodeInfoWithStorage[127.0.0.1:42417,DS-ce7f5ae2-7329-4f99-9446-b43705008211,DISK], DatanodeInfoWithStorage[127.0.0.1:39253,DS-0bd32815-b1a7-49e0-87e4-52aef73b74ed,DISK], DatanodeInfoWithStorage[127.0.0.1:42014,DS-598b9701-6205-42b8-ad67-4d6048c4199a,DISK], DatanodeInfoWithStorage[127.0.0.1:43623,DS-0fef69cd-26fc-4967-bfa0-a3f41e26cf0b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fslock.fair
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1203043847-172.17.0.6-1598169383174:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46124,DS-b1ec9e1d-55a4-4ed4-a8e5-38702ebfd1d3,DISK], DatanodeInfoWithStorage[127.0.0.1:36091,DS-bf60c08e-c17b-4e4b-a2cd-0f7e0daa50a8,DISK], DatanodeInfoWithStorage[127.0.0.1:41756,DS-383eb464-7932-45b5-bd04-9004f109097c,DISK], DatanodeInfoWithStorage[127.0.0.1:42995,DS-3608b0b2-11f4-4700-a6dd-0b7c8d353911,DISK], DatanodeInfoWithStorage[127.0.0.1:42392,DS-5adb4d3f-e590-4e15-ae8f-206ac9cb0c15,DISK], DatanodeInfoWithStorage[127.0.0.1:42676,DS-d784ba18-80b0-4d2c-8dd3-c1295d6969f9,DISK], DatanodeInfoWithStorage[127.0.0.1:34592,DS-f4922137-bb0e-43ed-803f-d741e9b43c2a,DISK], DatanodeInfoWithStorage[127.0.0.1:42162,DS-08e09e67-f4a2-4134-9676-88c526e30219,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1203043847-172.17.0.6-1598169383174:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46124,DS-b1ec9e1d-55a4-4ed4-a8e5-38702ebfd1d3,DISK], DatanodeInfoWithStorage[127.0.0.1:36091,DS-bf60c08e-c17b-4e4b-a2cd-0f7e0daa50a8,DISK], DatanodeInfoWithStorage[127.0.0.1:41756,DS-383eb464-7932-45b5-bd04-9004f109097c,DISK], DatanodeInfoWithStorage[127.0.0.1:42995,DS-3608b0b2-11f4-4700-a6dd-0b7c8d353911,DISK], DatanodeInfoWithStorage[127.0.0.1:42392,DS-5adb4d3f-e590-4e15-ae8f-206ac9cb0c15,DISK], DatanodeInfoWithStorage[127.0.0.1:42676,DS-d784ba18-80b0-4d2c-8dd3-c1295d6969f9,DISK], DatanodeInfoWithStorage[127.0.0.1:34592,DS-f4922137-bb0e-43ed-803f-d741e9b43c2a,DISK], DatanodeInfoWithStorage[127.0.0.1:42162,DS-08e09e67-f4a2-4134-9676-88c526e30219,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.fslock.fair
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1853670590-172.17.0.6-1598169421220:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39062,DS-a5caa111-3a47-4027-b338-5c05bb9a0e39,DISK], DatanodeInfoWithStorage[127.0.0.1:45177,DS-13117a6b-9c49-4f33-9e5f-d482f8d38e51,DISK], DatanodeInfoWithStorage[127.0.0.1:34399,DS-dc1dc4dd-9d7c-4c09-aa0c-4c857ee5d237,DISK], DatanodeInfoWithStorage[127.0.0.1:34994,DS-5555f399-927b-48f1-a240-6a83d46c645b,DISK], DatanodeInfoWithStorage[127.0.0.1:36466,DS-a68db665-39d0-4450-95de-1da2c7f7a549,DISK], DatanodeInfoWithStorage[127.0.0.1:36121,DS-8b56bfe3-e1db-445d-99dd-945364587969,DISK], DatanodeInfoWithStorage[127.0.0.1:41875,DS-451532d1-9e16-46d0-9ec5-5f1da92500a5,DISK], DatanodeInfoWithStorage[127.0.0.1:40780,DS-062d20a2-3ce1-46d4-bbc6-49951cd5d052,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1853670590-172.17.0.6-1598169421220:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39062,DS-a5caa111-3a47-4027-b338-5c05bb9a0e39,DISK], DatanodeInfoWithStorage[127.0.0.1:45177,DS-13117a6b-9c49-4f33-9e5f-d482f8d38e51,DISK], DatanodeInfoWithStorage[127.0.0.1:34399,DS-dc1dc4dd-9d7c-4c09-aa0c-4c857ee5d237,DISK], DatanodeInfoWithStorage[127.0.0.1:34994,DS-5555f399-927b-48f1-a240-6a83d46c645b,DISK], DatanodeInfoWithStorage[127.0.0.1:36466,DS-a68db665-39d0-4450-95de-1da2c7f7a549,DISK], DatanodeInfoWithStorage[127.0.0.1:36121,DS-8b56bfe3-e1db-445d-99dd-945364587969,DISK], DatanodeInfoWithStorage[127.0.0.1:41875,DS-451532d1-9e16-46d0-9ec5-5f1da92500a5,DISK], DatanodeInfoWithStorage[127.0.0.1:40780,DS-062d20a2-3ce1-46d4-bbc6-49951cd5d052,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fslock.fair
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1434198732-172.17.0.6-1598169687457:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36806,DS-0a879293-d41a-4b58-ac12-28f3606004f9,DISK], DatanodeInfoWithStorage[127.0.0.1:34460,DS-c276d850-9ccd-4f05-a07b-64fdd727b53d,DISK], DatanodeInfoWithStorage[127.0.0.1:37810,DS-e42a0309-7bcc-4ac4-b9a7-c625b4a2aa04,DISK], DatanodeInfoWithStorage[127.0.0.1:44425,DS-ecca0fd8-80e9-4349-8185-f2902f0659e6,DISK], DatanodeInfoWithStorage[127.0.0.1:40800,DS-8e37e2fd-f45e-4cc3-8d27-5ce6025b42c7,DISK], DatanodeInfoWithStorage[127.0.0.1:45862,DS-c09ec83e-95d4-4b66-9921-c710eebdaaa9,DISK], DatanodeInfoWithStorage[127.0.0.1:40860,DS-41b806ab-0977-4a90-9781-f82740b56ac2,DISK], DatanodeInfoWithStorage[127.0.0.1:44655,DS-ab8e7c08-bc56-40e0-b7b8-4a0592317f19,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1434198732-172.17.0.6-1598169687457:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36806,DS-0a879293-d41a-4b58-ac12-28f3606004f9,DISK], DatanodeInfoWithStorage[127.0.0.1:34460,DS-c276d850-9ccd-4f05-a07b-64fdd727b53d,DISK], DatanodeInfoWithStorage[127.0.0.1:37810,DS-e42a0309-7bcc-4ac4-b9a7-c625b4a2aa04,DISK], DatanodeInfoWithStorage[127.0.0.1:44425,DS-ecca0fd8-80e9-4349-8185-f2902f0659e6,DISK], DatanodeInfoWithStorage[127.0.0.1:40800,DS-8e37e2fd-f45e-4cc3-8d27-5ce6025b42c7,DISK], DatanodeInfoWithStorage[127.0.0.1:45862,DS-c09ec83e-95d4-4b66-9921-c710eebdaaa9,DISK], DatanodeInfoWithStorage[127.0.0.1:40860,DS-41b806ab-0977-4a90-9781-f82740b56ac2,DISK], DatanodeInfoWithStorage[127.0.0.1:44655,DS-ab8e7c08-bc56-40e0-b7b8-4a0592317f19,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.fslock.fair
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1896123387-172.17.0.6-1598169720262:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33255,DS-7e8a735f-d018-46ec-9895-20fb605d2c64,DISK], DatanodeInfoWithStorage[127.0.0.1:41493,DS-da59488c-616f-4d44-9cb0-6e76830021c3,DISK], DatanodeInfoWithStorage[127.0.0.1:42904,DS-a090f6e4-f5a2-4417-b60d-f1195b0772dd,DISK], DatanodeInfoWithStorage[127.0.0.1:44302,DS-ac02c087-6090-4644-8667-7a56abb642c1,DISK], DatanodeInfoWithStorage[127.0.0.1:36532,DS-701c4541-dc4b-4751-88d6-947f373fec3a,DISK], DatanodeInfoWithStorage[127.0.0.1:37760,DS-2873a251-dcf8-49e4-86ea-0112b605be4e,DISK], DatanodeInfoWithStorage[127.0.0.1:38801,DS-125e79d2-c7c1-417c-93ff-3934890551b2,DISK], DatanodeInfoWithStorage[127.0.0.1:37352,DS-f93a690a-74cc-4bfe-9919-dc979dd7d861,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1896123387-172.17.0.6-1598169720262:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33255,DS-7e8a735f-d018-46ec-9895-20fb605d2c64,DISK], DatanodeInfoWithStorage[127.0.0.1:41493,DS-da59488c-616f-4d44-9cb0-6e76830021c3,DISK], DatanodeInfoWithStorage[127.0.0.1:42904,DS-a090f6e4-f5a2-4417-b60d-f1195b0772dd,DISK], DatanodeInfoWithStorage[127.0.0.1:44302,DS-ac02c087-6090-4644-8667-7a56abb642c1,DISK], DatanodeInfoWithStorage[127.0.0.1:36532,DS-701c4541-dc4b-4751-88d6-947f373fec3a,DISK], DatanodeInfoWithStorage[127.0.0.1:37760,DS-2873a251-dcf8-49e4-86ea-0112b605be4e,DISK], DatanodeInfoWithStorage[127.0.0.1:38801,DS-125e79d2-c7c1-417c-93ff-3934890551b2,DISK], DatanodeInfoWithStorage[127.0.0.1:37352,DS-f93a690a-74cc-4bfe-9919-dc979dd7d861,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 11 out of 50
v1v1v2v2 failed with probability 17 out of 50
result: false positive !!!
Total execution time in seconds : 5162
