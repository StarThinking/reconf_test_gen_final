reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-517262761-172.17.0.20-1598382970946:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39937,DS-ea0945bd-d3c1-4823-9c83-563d611b492c,DISK], DatanodeInfoWithStorage[127.0.0.1:35133,DS-dbea378e-3faf-4a40-bfbe-008f16e98530,DISK], DatanodeInfoWithStorage[127.0.0.1:37982,DS-abf1b1f2-d136-4e92-adce-f2eef0369ad7,DISK], DatanodeInfoWithStorage[127.0.0.1:36668,DS-3421b523-d89d-47ff-894e-8ccf8b9896fb,DISK], DatanodeInfoWithStorage[127.0.0.1:36563,DS-bb530d6f-37a2-47c4-8b7b-2ea66c48383d,DISK], DatanodeInfoWithStorage[127.0.0.1:45929,DS-39af0d8b-fa2f-4cd5-9cfd-ec2046ea7f7d,DISK], DatanodeInfoWithStorage[127.0.0.1:39291,DS-7f452c61-4334-4f83-94fd-34b14a2b83b2,DISK], DatanodeInfoWithStorage[127.0.0.1:34539,DS-9eac9910-b5dd-40b3-ae4c-cf0f23173867,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-517262761-172.17.0.20-1598382970946:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39937,DS-ea0945bd-d3c1-4823-9c83-563d611b492c,DISK], DatanodeInfoWithStorage[127.0.0.1:35133,DS-dbea378e-3faf-4a40-bfbe-008f16e98530,DISK], DatanodeInfoWithStorage[127.0.0.1:37982,DS-abf1b1f2-d136-4e92-adce-f2eef0369ad7,DISK], DatanodeInfoWithStorage[127.0.0.1:36668,DS-3421b523-d89d-47ff-894e-8ccf8b9896fb,DISK], DatanodeInfoWithStorage[127.0.0.1:36563,DS-bb530d6f-37a2-47c4-8b7b-2ea66c48383d,DISK], DatanodeInfoWithStorage[127.0.0.1:45929,DS-39af0d8b-fa2f-4cd5-9cfd-ec2046ea7f7d,DISK], DatanodeInfoWithStorage[127.0.0.1:39291,DS-7f452c61-4334-4f83-94fd-34b14a2b83b2,DISK], DatanodeInfoWithStorage[127.0.0.1:34539,DS-9eac9910-b5dd-40b3-ae4c-cf0f23173867,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1948288440-172.17.0.20-1598383242730:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37440,DS-4d3d65fe-4568-4d5c-ae5d-b6d02faa0d9c,DISK], DatanodeInfoWithStorage[127.0.0.1:40324,DS-c4db27f8-0d83-413a-ac32-f5fbd0e9f635,DISK], DatanodeInfoWithStorage[127.0.0.1:45294,DS-abe83d48-4d3c-4d80-9942-f9abbe5f93e2,DISK], DatanodeInfoWithStorage[127.0.0.1:39564,DS-89f3b394-676d-47ef-abb5-efce1c1fe197,DISK], DatanodeInfoWithStorage[127.0.0.1:36361,DS-b9628e42-7aab-47b7-81ff-d4ae0f5d46cb,DISK], DatanodeInfoWithStorage[127.0.0.1:40673,DS-f8034bd5-8d29-46d7-8edf-276d412bea20,DISK], DatanodeInfoWithStorage[127.0.0.1:34147,DS-13089759-e0a7-4cfa-adc5-ed2fc4ff9520,DISK], DatanodeInfoWithStorage[127.0.0.1:34232,DS-08d384e9-297a-4d10-9d9e-5a267c859489,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1948288440-172.17.0.20-1598383242730:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37440,DS-4d3d65fe-4568-4d5c-ae5d-b6d02faa0d9c,DISK], DatanodeInfoWithStorage[127.0.0.1:40324,DS-c4db27f8-0d83-413a-ac32-f5fbd0e9f635,DISK], DatanodeInfoWithStorage[127.0.0.1:45294,DS-abe83d48-4d3c-4d80-9942-f9abbe5f93e2,DISK], DatanodeInfoWithStorage[127.0.0.1:39564,DS-89f3b394-676d-47ef-abb5-efce1c1fe197,DISK], DatanodeInfoWithStorage[127.0.0.1:36361,DS-b9628e42-7aab-47b7-81ff-d4ae0f5d46cb,DISK], DatanodeInfoWithStorage[127.0.0.1:40673,DS-f8034bd5-8d29-46d7-8edf-276d412bea20,DISK], DatanodeInfoWithStorage[127.0.0.1:34147,DS-13089759-e0a7-4cfa-adc5-ed2fc4ff9520,DISK], DatanodeInfoWithStorage[127.0.0.1:34232,DS-08d384e9-297a-4d10-9d9e-5a267c859489,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1225841865-172.17.0.20-1598383437574:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33341,DS-8059d3b7-d89d-405b-91ed-01509b4f5c4c,DISK], DatanodeInfoWithStorage[127.0.0.1:36076,DS-6cc52ab2-04d8-4909-8de7-315187f1018d,DISK], DatanodeInfoWithStorage[127.0.0.1:33650,DS-0d5f6029-953a-42f5-a999-875ece125056,DISK], DatanodeInfoWithStorage[127.0.0.1:33228,DS-3715ab30-0afe-465c-af51-79c3d04281a0,DISK], DatanodeInfoWithStorage[127.0.0.1:46348,DS-d9dcb216-2529-46d5-a109-06b60eb3c232,DISK], DatanodeInfoWithStorage[127.0.0.1:43381,DS-63ae46fc-08ff-4959-b231-baa3d13fe705,DISK], DatanodeInfoWithStorage[127.0.0.1:37852,DS-e5f07c95-1bcd-4425-9c36-ba961969997a,DISK], DatanodeInfoWithStorage[127.0.0.1:34935,DS-96a0a1c3-c371-4d57-be19-3adda35775ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1225841865-172.17.0.20-1598383437574:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33341,DS-8059d3b7-d89d-405b-91ed-01509b4f5c4c,DISK], DatanodeInfoWithStorage[127.0.0.1:36076,DS-6cc52ab2-04d8-4909-8de7-315187f1018d,DISK], DatanodeInfoWithStorage[127.0.0.1:33650,DS-0d5f6029-953a-42f5-a999-875ece125056,DISK], DatanodeInfoWithStorage[127.0.0.1:33228,DS-3715ab30-0afe-465c-af51-79c3d04281a0,DISK], DatanodeInfoWithStorage[127.0.0.1:46348,DS-d9dcb216-2529-46d5-a109-06b60eb3c232,DISK], DatanodeInfoWithStorage[127.0.0.1:43381,DS-63ae46fc-08ff-4959-b231-baa3d13fe705,DISK], DatanodeInfoWithStorage[127.0.0.1:37852,DS-e5f07c95-1bcd-4425-9c36-ba961969997a,DISK], DatanodeInfoWithStorage[127.0.0.1:34935,DS-96a0a1c3-c371-4d57-be19-3adda35775ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-398025118-172.17.0.20-1598383463403:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37549,DS-ecc3cd08-093f-44f0-9b93-7ef891f3db09,DISK], DatanodeInfoWithStorage[127.0.0.1:41286,DS-095b4994-5f90-4766-bb5c-eeabdc9a0705,DISK], DatanodeInfoWithStorage[127.0.0.1:32827,DS-cc28e836-a304-498c-81c1-8cceaee1dee3,DISK], DatanodeInfoWithStorage[127.0.0.1:33010,DS-030e9abc-b8a6-4dbf-b1c6-56c1fb6c8cf8,DISK], DatanodeInfoWithStorage[127.0.0.1:36558,DS-05752b67-dad3-4d3e-ae40-1ac84acbf628,DISK], DatanodeInfoWithStorage[127.0.0.1:43003,DS-01866c58-a5db-47a2-812e-a51cd14fa7d5,DISK], DatanodeInfoWithStorage[127.0.0.1:33977,DS-a8a6b456-91b7-497f-9eb5-ce3b4ee94d6c,DISK], DatanodeInfoWithStorage[127.0.0.1:35260,DS-348dc368-442b-458d-8218-e11724ca36ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-398025118-172.17.0.20-1598383463403:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37549,DS-ecc3cd08-093f-44f0-9b93-7ef891f3db09,DISK], DatanodeInfoWithStorage[127.0.0.1:41286,DS-095b4994-5f90-4766-bb5c-eeabdc9a0705,DISK], DatanodeInfoWithStorage[127.0.0.1:32827,DS-cc28e836-a304-498c-81c1-8cceaee1dee3,DISK], DatanodeInfoWithStorage[127.0.0.1:33010,DS-030e9abc-b8a6-4dbf-b1c6-56c1fb6c8cf8,DISK], DatanodeInfoWithStorage[127.0.0.1:36558,DS-05752b67-dad3-4d3e-ae40-1ac84acbf628,DISK], DatanodeInfoWithStorage[127.0.0.1:43003,DS-01866c58-a5db-47a2-812e-a51cd14fa7d5,DISK], DatanodeInfoWithStorage[127.0.0.1:33977,DS-a8a6b456-91b7-497f-9eb5-ce3b4ee94d6c,DISK], DatanodeInfoWithStorage[127.0.0.1:35260,DS-348dc368-442b-458d-8218-e11724ca36ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1389185999-172.17.0.20-1598383789307:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42727,DS-3dec9fe7-ab75-4e1a-9194-7e3bbfacf66a,DISK], DatanodeInfoWithStorage[127.0.0.1:44993,DS-4f9199d9-8603-414e-b579-904eb9178bca,DISK], DatanodeInfoWithStorage[127.0.0.1:43098,DS-e90623dd-af2f-449c-8f48-b129faba7650,DISK], DatanodeInfoWithStorage[127.0.0.1:44516,DS-d1bab43d-5e44-4032-b767-0c6632bd0262,DISK], DatanodeInfoWithStorage[127.0.0.1:38515,DS-3e0661c1-9ba8-4af1-83d8-16f377399f39,DISK], DatanodeInfoWithStorage[127.0.0.1:38709,DS-1301a768-c73c-4f9a-87bc-510d983314b8,DISK], DatanodeInfoWithStorage[127.0.0.1:42140,DS-97817355-7c7f-4c73-ae53-357a7c00b0b6,DISK], DatanodeInfoWithStorage[127.0.0.1:42146,DS-d26f0b06-c936-4bd8-b1ba-0ee0e80a80e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1389185999-172.17.0.20-1598383789307:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42727,DS-3dec9fe7-ab75-4e1a-9194-7e3bbfacf66a,DISK], DatanodeInfoWithStorage[127.0.0.1:44993,DS-4f9199d9-8603-414e-b579-904eb9178bca,DISK], DatanodeInfoWithStorage[127.0.0.1:43098,DS-e90623dd-af2f-449c-8f48-b129faba7650,DISK], DatanodeInfoWithStorage[127.0.0.1:44516,DS-d1bab43d-5e44-4032-b767-0c6632bd0262,DISK], DatanodeInfoWithStorage[127.0.0.1:38515,DS-3e0661c1-9ba8-4af1-83d8-16f377399f39,DISK], DatanodeInfoWithStorage[127.0.0.1:38709,DS-1301a768-c73c-4f9a-87bc-510d983314b8,DISK], DatanodeInfoWithStorage[127.0.0.1:42140,DS-97817355-7c7f-4c73-ae53-357a7c00b0b6,DISK], DatanodeInfoWithStorage[127.0.0.1:42146,DS-d26f0b06-c936-4bd8-b1ba-0ee0e80a80e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1606240925-172.17.0.20-1598384054113:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45485,DS-460d715c-479c-4878-9a75-2e1c6cedecae,DISK], DatanodeInfoWithStorage[127.0.0.1:35865,DS-80110fa8-bb11-4d95-a58f-f83cbaf53191,DISK], DatanodeInfoWithStorage[127.0.0.1:33438,DS-14d426de-0d60-4ae3-afd2-913c4f1b33b1,DISK], DatanodeInfoWithStorage[127.0.0.1:39462,DS-8f9ba387-3681-4dcf-8bfc-335e591fef71,DISK], DatanodeInfoWithStorage[127.0.0.1:41227,DS-bef900bd-14b2-49fd-ba7a-5e15e2478e81,DISK], DatanodeInfoWithStorage[127.0.0.1:33504,DS-b5687dfa-76ff-4d26-8c3c-2dea677895b7,DISK], DatanodeInfoWithStorage[127.0.0.1:40569,DS-3d4982cc-26b2-4872-9126-5ba17c6998ad,DISK], DatanodeInfoWithStorage[127.0.0.1:32866,DS-6eb7b560-d5c5-44f5-964b-1b7f942a3d63,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1606240925-172.17.0.20-1598384054113:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45485,DS-460d715c-479c-4878-9a75-2e1c6cedecae,DISK], DatanodeInfoWithStorage[127.0.0.1:35865,DS-80110fa8-bb11-4d95-a58f-f83cbaf53191,DISK], DatanodeInfoWithStorage[127.0.0.1:33438,DS-14d426de-0d60-4ae3-afd2-913c4f1b33b1,DISK], DatanodeInfoWithStorage[127.0.0.1:39462,DS-8f9ba387-3681-4dcf-8bfc-335e591fef71,DISK], DatanodeInfoWithStorage[127.0.0.1:41227,DS-bef900bd-14b2-49fd-ba7a-5e15e2478e81,DISK], DatanodeInfoWithStorage[127.0.0.1:33504,DS-b5687dfa-76ff-4d26-8c3c-2dea677895b7,DISK], DatanodeInfoWithStorage[127.0.0.1:40569,DS-3d4982cc-26b2-4872-9126-5ba17c6998ad,DISK], DatanodeInfoWithStorage[127.0.0.1:32866,DS-6eb7b560-d5c5-44f5-964b-1b7f942a3d63,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-692425512-172.17.0.20-1598384486611:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33301,DS-8ea37a9a-d781-44ac-95bb-0cc165f0a110,DISK], DatanodeInfoWithStorage[127.0.0.1:46326,DS-ee338e0d-e954-49bb-8ac5-b3bf790eda1d,DISK], DatanodeInfoWithStorage[127.0.0.1:41592,DS-68a5cb45-5d6f-4563-94e3-fe08b1695129,DISK], DatanodeInfoWithStorage[127.0.0.1:35063,DS-10234f39-052c-4034-9242-6cd6a3c3b3f6,DISK], DatanodeInfoWithStorage[127.0.0.1:40852,DS-5380a63a-735e-4f7c-8fb1-7eec06405444,DISK], DatanodeInfoWithStorage[127.0.0.1:41159,DS-f52cd633-c419-46d7-9956-5c3a6328747c,DISK], DatanodeInfoWithStorage[127.0.0.1:36145,DS-27546d4c-319b-4605-a9ee-370ab9af2a61,DISK], DatanodeInfoWithStorage[127.0.0.1:44682,DS-60d060c9-4da3-48e6-92b8-9dd98a004473,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-692425512-172.17.0.20-1598384486611:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33301,DS-8ea37a9a-d781-44ac-95bb-0cc165f0a110,DISK], DatanodeInfoWithStorage[127.0.0.1:46326,DS-ee338e0d-e954-49bb-8ac5-b3bf790eda1d,DISK], DatanodeInfoWithStorage[127.0.0.1:41592,DS-68a5cb45-5d6f-4563-94e3-fe08b1695129,DISK], DatanodeInfoWithStorage[127.0.0.1:35063,DS-10234f39-052c-4034-9242-6cd6a3c3b3f6,DISK], DatanodeInfoWithStorage[127.0.0.1:40852,DS-5380a63a-735e-4f7c-8fb1-7eec06405444,DISK], DatanodeInfoWithStorage[127.0.0.1:41159,DS-f52cd633-c419-46d7-9956-5c3a6328747c,DISK], DatanodeInfoWithStorage[127.0.0.1:36145,DS-27546d4c-319b-4605-a9ee-370ab9af2a61,DISK], DatanodeInfoWithStorage[127.0.0.1:44682,DS-60d060c9-4da3-48e6-92b8-9dd98a004473,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-900820832-172.17.0.20-1598385036298:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42628,DS-b4c3b219-096f-4cd0-a479-57eac246fd88,DISK], DatanodeInfoWithStorage[127.0.0.1:37041,DS-3ead73fd-3d6a-4ed3-b0ef-655efd4c3466,DISK], DatanodeInfoWithStorage[127.0.0.1:42246,DS-e992c91a-64a6-494c-b370-6b3a4bbf89cf,DISK], DatanodeInfoWithStorage[127.0.0.1:37475,DS-06cd3a51-0a6f-499f-b606-eff0995a6eac,DISK], DatanodeInfoWithStorage[127.0.0.1:34258,DS-1e22d335-64af-49e9-bab2-07227772e2ab,DISK], DatanodeInfoWithStorage[127.0.0.1:37346,DS-52915677-0306-40f0-82ed-6bc7c6dc3972,DISK], DatanodeInfoWithStorage[127.0.0.1:40963,DS-28eb3893-5ce7-4a92-99b2-deea300428c2,DISK], DatanodeInfoWithStorage[127.0.0.1:38935,DS-25ceb191-1f35-42d0-b6e6-a84be099774c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-900820832-172.17.0.20-1598385036298:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42628,DS-b4c3b219-096f-4cd0-a479-57eac246fd88,DISK], DatanodeInfoWithStorage[127.0.0.1:37041,DS-3ead73fd-3d6a-4ed3-b0ef-655efd4c3466,DISK], DatanodeInfoWithStorage[127.0.0.1:42246,DS-e992c91a-64a6-494c-b370-6b3a4bbf89cf,DISK], DatanodeInfoWithStorage[127.0.0.1:37475,DS-06cd3a51-0a6f-499f-b606-eff0995a6eac,DISK], DatanodeInfoWithStorage[127.0.0.1:34258,DS-1e22d335-64af-49e9-bab2-07227772e2ab,DISK], DatanodeInfoWithStorage[127.0.0.1:37346,DS-52915677-0306-40f0-82ed-6bc7c6dc3972,DISK], DatanodeInfoWithStorage[127.0.0.1:40963,DS-28eb3893-5ce7-4a92-99b2-deea300428c2,DISK], DatanodeInfoWithStorage[127.0.0.1:38935,DS-25ceb191-1f35-42d0-b6e6-a84be099774c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-818988064-172.17.0.20-1598385510058:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44676,DS-4f1d2baa-1307-409e-ac82-c38d9ad7bb1d,DISK], DatanodeInfoWithStorage[127.0.0.1:33371,DS-66fa055f-d3db-4e40-ac4e-b8264dde8ae4,DISK], DatanodeInfoWithStorage[127.0.0.1:41799,DS-47a8bc07-9daa-4f4c-b98f-755030f94895,DISK], DatanodeInfoWithStorage[127.0.0.1:37303,DS-db0f67b4-7c9c-4efa-ac0c-29e593a095ad,DISK], DatanodeInfoWithStorage[127.0.0.1:42962,DS-22b0821c-67ae-4b58-a89c-829a7429a607,DISK], DatanodeInfoWithStorage[127.0.0.1:44219,DS-0b7eb2bc-6014-42d6-92b1-7b09d9e56ada,DISK], DatanodeInfoWithStorage[127.0.0.1:39216,DS-85d24c5c-6c71-4e29-a11a-36dd143a8a43,DISK], DatanodeInfoWithStorage[127.0.0.1:32786,DS-798bce2c-866f-4464-8b07-dedc03303a88,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-818988064-172.17.0.20-1598385510058:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44676,DS-4f1d2baa-1307-409e-ac82-c38d9ad7bb1d,DISK], DatanodeInfoWithStorage[127.0.0.1:33371,DS-66fa055f-d3db-4e40-ac4e-b8264dde8ae4,DISK], DatanodeInfoWithStorage[127.0.0.1:41799,DS-47a8bc07-9daa-4f4c-b98f-755030f94895,DISK], DatanodeInfoWithStorage[127.0.0.1:37303,DS-db0f67b4-7c9c-4efa-ac0c-29e593a095ad,DISK], DatanodeInfoWithStorage[127.0.0.1:42962,DS-22b0821c-67ae-4b58-a89c-829a7429a607,DISK], DatanodeInfoWithStorage[127.0.0.1:44219,DS-0b7eb2bc-6014-42d6-92b1-7b09d9e56ada,DISK], DatanodeInfoWithStorage[127.0.0.1:39216,DS-85d24c5c-6c71-4e29-a11a-36dd143a8a43,DISK], DatanodeInfoWithStorage[127.0.0.1:32786,DS-798bce2c-866f-4464-8b07-dedc03303a88,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1051253395-172.17.0.20-1598385641761:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41460,DS-2671d830-00fa-425f-ad69-9aac92bda35c,DISK], DatanodeInfoWithStorage[127.0.0.1:33994,DS-da17daf8-a56a-4658-81c4-2b4e0ea7ea5a,DISK], DatanodeInfoWithStorage[127.0.0.1:41608,DS-a26f32f5-e776-4b95-b984-e29bfdb014a3,DISK], DatanodeInfoWithStorage[127.0.0.1:46620,DS-2af2fe05-4572-4fba-bb38-8ffb6318c3a2,DISK], DatanodeInfoWithStorage[127.0.0.1:44808,DS-ba0dcd0e-0453-445a-86d6-1f9172bf30ca,DISK], DatanodeInfoWithStorage[127.0.0.1:39650,DS-059e0f5b-d4fd-417d-9363-beb16442bc9f,DISK], DatanodeInfoWithStorage[127.0.0.1:41466,DS-657d1fb0-9c78-4ccf-9331-f6cdaa865788,DISK], DatanodeInfoWithStorage[127.0.0.1:34977,DS-c5cd6af3-5777-45c5-a7d5-4522c9c89ce7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1051253395-172.17.0.20-1598385641761:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41460,DS-2671d830-00fa-425f-ad69-9aac92bda35c,DISK], DatanodeInfoWithStorage[127.0.0.1:33994,DS-da17daf8-a56a-4658-81c4-2b4e0ea7ea5a,DISK], DatanodeInfoWithStorage[127.0.0.1:41608,DS-a26f32f5-e776-4b95-b984-e29bfdb014a3,DISK], DatanodeInfoWithStorage[127.0.0.1:46620,DS-2af2fe05-4572-4fba-bb38-8ffb6318c3a2,DISK], DatanodeInfoWithStorage[127.0.0.1:44808,DS-ba0dcd0e-0453-445a-86d6-1f9172bf30ca,DISK], DatanodeInfoWithStorage[127.0.0.1:39650,DS-059e0f5b-d4fd-417d-9363-beb16442bc9f,DISK], DatanodeInfoWithStorage[127.0.0.1:41466,DS-657d1fb0-9c78-4ccf-9331-f6cdaa865788,DISK], DatanodeInfoWithStorage[127.0.0.1:34977,DS-c5cd6af3-5777-45c5-a7d5-4522c9c89ce7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-505421388-172.17.0.20-1598385932390:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45684,DS-d43b1a43-81f5-4b57-9d92-569b2970acda,DISK], DatanodeInfoWithStorage[127.0.0.1:46340,DS-fb9571c0-d2f1-4dcb-a2bd-f8c516bd855e,DISK], DatanodeInfoWithStorage[127.0.0.1:38439,DS-420a687e-b6fe-4f1a-8761-ccc3d8963267,DISK], DatanodeInfoWithStorage[127.0.0.1:44725,DS-804d2183-1b4f-46fd-accf-0d7e462ea6bb,DISK], DatanodeInfoWithStorage[127.0.0.1:33474,DS-fe6757c4-c7d7-4939-8c4d-4b225dd353c2,DISK], DatanodeInfoWithStorage[127.0.0.1:44643,DS-9c9a4990-f761-401e-b816-0139a0e34dd4,DISK], DatanodeInfoWithStorage[127.0.0.1:44876,DS-2bff4584-c02d-4b93-a089-7b435baeb325,DISK], DatanodeInfoWithStorage[127.0.0.1:34943,DS-ba5e4d24-22dd-4e92-a68e-63204c2991e9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-505421388-172.17.0.20-1598385932390:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45684,DS-d43b1a43-81f5-4b57-9d92-569b2970acda,DISK], DatanodeInfoWithStorage[127.0.0.1:46340,DS-fb9571c0-d2f1-4dcb-a2bd-f8c516bd855e,DISK], DatanodeInfoWithStorage[127.0.0.1:38439,DS-420a687e-b6fe-4f1a-8761-ccc3d8963267,DISK], DatanodeInfoWithStorage[127.0.0.1:44725,DS-804d2183-1b4f-46fd-accf-0d7e462ea6bb,DISK], DatanodeInfoWithStorage[127.0.0.1:33474,DS-fe6757c4-c7d7-4939-8c4d-4b225dd353c2,DISK], DatanodeInfoWithStorage[127.0.0.1:44643,DS-9c9a4990-f761-401e-b816-0139a0e34dd4,DISK], DatanodeInfoWithStorage[127.0.0.1:44876,DS-2bff4584-c02d-4b93-a089-7b435baeb325,DISK], DatanodeInfoWithStorage[127.0.0.1:34943,DS-ba5e4d24-22dd-4e92-a68e-63204c2991e9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1432010408-172.17.0.20-1598386083158:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33835,DS-01a267eb-edd2-4f9e-bf87-f378a3565940,DISK], DatanodeInfoWithStorage[127.0.0.1:41444,DS-e10915da-0a05-4ba9-8a43-a5ba4a483244,DISK], DatanodeInfoWithStorage[127.0.0.1:33915,DS-8c5b6461-0b1c-4f8e-b1e4-a49d04dadc17,DISK], DatanodeInfoWithStorage[127.0.0.1:35701,DS-caea866d-882d-4958-9d65-78148664dc24,DISK], DatanodeInfoWithStorage[127.0.0.1:41834,DS-2c71ed56-8d0b-469b-b0b9-a6d12ec68dd2,DISK], DatanodeInfoWithStorage[127.0.0.1:32833,DS-daab0446-8ac6-449f-907b-69c00f1702d6,DISK], DatanodeInfoWithStorage[127.0.0.1:43992,DS-8f1ef80d-70fe-45da-be18-796c6d2f9af3,DISK], DatanodeInfoWithStorage[127.0.0.1:39252,DS-1ee417c4-a3e1-4c4b-82c8-1b1c4fceb8dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1432010408-172.17.0.20-1598386083158:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33835,DS-01a267eb-edd2-4f9e-bf87-f378a3565940,DISK], DatanodeInfoWithStorage[127.0.0.1:41444,DS-e10915da-0a05-4ba9-8a43-a5ba4a483244,DISK], DatanodeInfoWithStorage[127.0.0.1:33915,DS-8c5b6461-0b1c-4f8e-b1e4-a49d04dadc17,DISK], DatanodeInfoWithStorage[127.0.0.1:35701,DS-caea866d-882d-4958-9d65-78148664dc24,DISK], DatanodeInfoWithStorage[127.0.0.1:41834,DS-2c71ed56-8d0b-469b-b0b9-a6d12ec68dd2,DISK], DatanodeInfoWithStorage[127.0.0.1:32833,DS-daab0446-8ac6-449f-907b-69c00f1702d6,DISK], DatanodeInfoWithStorage[127.0.0.1:43992,DS-8f1ef80d-70fe-45da-be18-796c6d2f9af3,DISK], DatanodeInfoWithStorage[127.0.0.1:39252,DS-1ee417c4-a3e1-4c4b-82c8-1b1c4fceb8dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-252065175-172.17.0.20-1598386701177:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41241,DS-bb3abd68-77d0-475e-ba76-6a272b070abb,DISK], DatanodeInfoWithStorage[127.0.0.1:37396,DS-355c8bb1-64ba-4f75-956b-67943c006253,DISK], DatanodeInfoWithStorage[127.0.0.1:45604,DS-618f30ae-c2d1-4f34-a5e5-960cf398a151,DISK], DatanodeInfoWithStorage[127.0.0.1:41647,DS-48930500-39f1-44ff-b30c-bfe7466408f6,DISK], DatanodeInfoWithStorage[127.0.0.1:37707,DS-b4a12166-42f8-4612-bf82-a1c6bf76c1df,DISK], DatanodeInfoWithStorage[127.0.0.1:35010,DS-e53f0432-da04-4a01-9395-2a1045fb9120,DISK], DatanodeInfoWithStorage[127.0.0.1:44901,DS-d3dfcf8f-e9e1-4f45-9a6d-4a5d7ce4ecfb,DISK], DatanodeInfoWithStorage[127.0.0.1:46722,DS-0715118a-c068-43ce-9dd9-dc9196f5504b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-252065175-172.17.0.20-1598386701177:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41241,DS-bb3abd68-77d0-475e-ba76-6a272b070abb,DISK], DatanodeInfoWithStorage[127.0.0.1:37396,DS-355c8bb1-64ba-4f75-956b-67943c006253,DISK], DatanodeInfoWithStorage[127.0.0.1:45604,DS-618f30ae-c2d1-4f34-a5e5-960cf398a151,DISK], DatanodeInfoWithStorage[127.0.0.1:41647,DS-48930500-39f1-44ff-b30c-bfe7466408f6,DISK], DatanodeInfoWithStorage[127.0.0.1:37707,DS-b4a12166-42f8-4612-bf82-a1c6bf76c1df,DISK], DatanodeInfoWithStorage[127.0.0.1:35010,DS-e53f0432-da04-4a01-9395-2a1045fb9120,DISK], DatanodeInfoWithStorage[127.0.0.1:44901,DS-d3dfcf8f-e9e1-4f45-9a6d-4a5d7ce4ecfb,DISK], DatanodeInfoWithStorage[127.0.0.1:46722,DS-0715118a-c068-43ce-9dd9-dc9196f5504b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-188834500-172.17.0.20-1598386772173:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38492,DS-eadff6dd-7b5b-44ab-99e4-d40dbf5696dc,DISK], DatanodeInfoWithStorage[127.0.0.1:43490,DS-884c7178-7e74-4544-8dde-3fc511a99508,DISK], DatanodeInfoWithStorage[127.0.0.1:34628,DS-f3e2a01e-89a8-4e60-b214-3391c0be4856,DISK], DatanodeInfoWithStorage[127.0.0.1:39156,DS-a6ad1143-7d4f-4760-9bd4-b0a325bc0245,DISK], DatanodeInfoWithStorage[127.0.0.1:32789,DS-a16737f7-7474-4381-9528-e95a1deed98e,DISK], DatanodeInfoWithStorage[127.0.0.1:39764,DS-3f087c76-3cf1-437a-a550-69931850f038,DISK], DatanodeInfoWithStorage[127.0.0.1:39402,DS-06420e5a-172b-4dce-b13e-d0c110d05e75,DISK], DatanodeInfoWithStorage[127.0.0.1:36740,DS-3ef4afe3-f4a8-4731-9dd0-4bc3aff1cdbe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-188834500-172.17.0.20-1598386772173:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38492,DS-eadff6dd-7b5b-44ab-99e4-d40dbf5696dc,DISK], DatanodeInfoWithStorage[127.0.0.1:43490,DS-884c7178-7e74-4544-8dde-3fc511a99508,DISK], DatanodeInfoWithStorage[127.0.0.1:34628,DS-f3e2a01e-89a8-4e60-b214-3391c0be4856,DISK], DatanodeInfoWithStorage[127.0.0.1:39156,DS-a6ad1143-7d4f-4760-9bd4-b0a325bc0245,DISK], DatanodeInfoWithStorage[127.0.0.1:32789,DS-a16737f7-7474-4381-9528-e95a1deed98e,DISK], DatanodeInfoWithStorage[127.0.0.1:39764,DS-3f087c76-3cf1-437a-a550-69931850f038,DISK], DatanodeInfoWithStorage[127.0.0.1:39402,DS-06420e5a-172b-4dce-b13e-d0c110d05e75,DISK], DatanodeInfoWithStorage[127.0.0.1:36740,DS-3ef4afe3-f4a8-4731-9dd0-4bc3aff1cdbe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-124887513-172.17.0.20-1598386877163:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35084,DS-8a9346ec-9134-4da2-80c5-ea49405668d1,DISK], DatanodeInfoWithStorage[127.0.0.1:40372,DS-1a49058e-02c9-4f19-a968-7c99b83f48d2,DISK], DatanodeInfoWithStorage[127.0.0.1:32957,DS-f09acbfd-59da-41c6-9bce-945002e65aa2,DISK], DatanodeInfoWithStorage[127.0.0.1:43629,DS-5a9b1df4-39a5-40fb-8bea-0b10090ec1a2,DISK], DatanodeInfoWithStorage[127.0.0.1:42028,DS-4ec57567-8dbc-4717-a578-8138c9a692bf,DISK], DatanodeInfoWithStorage[127.0.0.1:33414,DS-d7b51d84-4f07-4815-be38-9a755887b47e,DISK], DatanodeInfoWithStorage[127.0.0.1:43307,DS-2993082b-c399-458f-910c-19fced447a68,DISK], DatanodeInfoWithStorage[127.0.0.1:40425,DS-04699948-8809-4d5e-9d01-f98baf694639,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-124887513-172.17.0.20-1598386877163:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35084,DS-8a9346ec-9134-4da2-80c5-ea49405668d1,DISK], DatanodeInfoWithStorage[127.0.0.1:40372,DS-1a49058e-02c9-4f19-a968-7c99b83f48d2,DISK], DatanodeInfoWithStorage[127.0.0.1:32957,DS-f09acbfd-59da-41c6-9bce-945002e65aa2,DISK], DatanodeInfoWithStorage[127.0.0.1:43629,DS-5a9b1df4-39a5-40fb-8bea-0b10090ec1a2,DISK], DatanodeInfoWithStorage[127.0.0.1:42028,DS-4ec57567-8dbc-4717-a578-8138c9a692bf,DISK], DatanodeInfoWithStorage[127.0.0.1:33414,DS-d7b51d84-4f07-4815-be38-9a755887b47e,DISK], DatanodeInfoWithStorage[127.0.0.1:43307,DS-2993082b-c399-458f-910c-19fced447a68,DISK], DatanodeInfoWithStorage[127.0.0.1:40425,DS-04699948-8809-4d5e-9d01-f98baf694639,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1078237556-172.17.0.20-1598387013883:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32934,DS-2a103bb2-3538-4e78-9392-4fdbb08afb74,DISK], DatanodeInfoWithStorage[127.0.0.1:33689,DS-b4bb22ac-a508-4646-ac31-9f3b5378df91,DISK], DatanodeInfoWithStorage[127.0.0.1:44954,DS-48c3acd7-ed87-44f1-acbd-e4a3ed11ac25,DISK], DatanodeInfoWithStorage[127.0.0.1:43673,DS-da797e31-63f6-4bd0-a57a-df01ff842f92,DISK], DatanodeInfoWithStorage[127.0.0.1:37748,DS-8d56b709-d130-4753-ae6f-6816569bdd4c,DISK], DatanodeInfoWithStorage[127.0.0.1:34370,DS-cca01588-6ffb-4f75-9485-a55b933752b5,DISK], DatanodeInfoWithStorage[127.0.0.1:42242,DS-440f81f4-507b-48bc-b585-da792767f399,DISK], DatanodeInfoWithStorage[127.0.0.1:42982,DS-afc68147-c0ee-4dc6-8444-ff750047215e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1078237556-172.17.0.20-1598387013883:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32934,DS-2a103bb2-3538-4e78-9392-4fdbb08afb74,DISK], DatanodeInfoWithStorage[127.0.0.1:33689,DS-b4bb22ac-a508-4646-ac31-9f3b5378df91,DISK], DatanodeInfoWithStorage[127.0.0.1:44954,DS-48c3acd7-ed87-44f1-acbd-e4a3ed11ac25,DISK], DatanodeInfoWithStorage[127.0.0.1:43673,DS-da797e31-63f6-4bd0-a57a-df01ff842f92,DISK], DatanodeInfoWithStorage[127.0.0.1:37748,DS-8d56b709-d130-4753-ae6f-6816569bdd4c,DISK], DatanodeInfoWithStorage[127.0.0.1:34370,DS-cca01588-6ffb-4f75-9485-a55b933752b5,DISK], DatanodeInfoWithStorage[127.0.0.1:42242,DS-440f81f4-507b-48bc-b585-da792767f399,DISK], DatanodeInfoWithStorage[127.0.0.1:42982,DS-afc68147-c0ee-4dc6-8444-ff750047215e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-633959501-172.17.0.20-1598387458023:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39052,DS-4f8962dc-f06e-4143-8349-ff72abdc3d9b,DISK], DatanodeInfoWithStorage[127.0.0.1:37863,DS-2747963e-4b68-4c68-94c4-5bed252855f3,DISK], DatanodeInfoWithStorage[127.0.0.1:40827,DS-0da097c5-a31c-4c9f-8e08-7e85eceda38f,DISK], DatanodeInfoWithStorage[127.0.0.1:39682,DS-510b7af5-68e0-41ef-85f7-8470a230fca8,DISK], DatanodeInfoWithStorage[127.0.0.1:37444,DS-12770c1c-a699-44ca-9120-83a72c0c6288,DISK], DatanodeInfoWithStorage[127.0.0.1:38730,DS-5687e69c-7f6a-4518-8b21-2f47134f01bf,DISK], DatanodeInfoWithStorage[127.0.0.1:35129,DS-a4e70205-5e64-40dc-9d13-4a3142eb85a4,DISK], DatanodeInfoWithStorage[127.0.0.1:43539,DS-aaf0003c-2b16-4b1d-9676-747aaeec198a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-633959501-172.17.0.20-1598387458023:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39052,DS-4f8962dc-f06e-4143-8349-ff72abdc3d9b,DISK], DatanodeInfoWithStorage[127.0.0.1:37863,DS-2747963e-4b68-4c68-94c4-5bed252855f3,DISK], DatanodeInfoWithStorage[127.0.0.1:40827,DS-0da097c5-a31c-4c9f-8e08-7e85eceda38f,DISK], DatanodeInfoWithStorage[127.0.0.1:39682,DS-510b7af5-68e0-41ef-85f7-8470a230fca8,DISK], DatanodeInfoWithStorage[127.0.0.1:37444,DS-12770c1c-a699-44ca-9120-83a72c0c6288,DISK], DatanodeInfoWithStorage[127.0.0.1:38730,DS-5687e69c-7f6a-4518-8b21-2f47134f01bf,DISK], DatanodeInfoWithStorage[127.0.0.1:35129,DS-a4e70205-5e64-40dc-9d13-4a3142eb85a4,DISK], DatanodeInfoWithStorage[127.0.0.1:43539,DS-aaf0003c-2b16-4b1d-9676-747aaeec198a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5105
