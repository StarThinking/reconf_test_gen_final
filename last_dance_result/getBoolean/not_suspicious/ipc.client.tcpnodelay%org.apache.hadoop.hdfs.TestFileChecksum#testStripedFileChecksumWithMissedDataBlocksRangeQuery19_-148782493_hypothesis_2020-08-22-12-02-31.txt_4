reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1111745205-172.17.0.2-1598098181876:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43051,DS-ff415d4c-6cf7-4580-94ce-92e1c96be7eb,DISK], DatanodeInfoWithStorage[127.0.0.1:46711,DS-e60de82b-2f35-462c-bb32-fa189529423e,DISK], DatanodeInfoWithStorage[127.0.0.1:43547,DS-1e307f06-08ce-43fc-b5a1-f5c31700a8db,DISK], DatanodeInfoWithStorage[127.0.0.1:36915,DS-41ba1edf-2fdc-4b58-a947-f7a0969a623a,DISK], DatanodeInfoWithStorage[127.0.0.1:45046,DS-30dd6d94-9eaf-4d1b-add0-8b788e858f09,DISK], DatanodeInfoWithStorage[127.0.0.1:38353,DS-3f318a76-d709-483e-9256-2d4d92a26559,DISK], DatanodeInfoWithStorage[127.0.0.1:36515,DS-3e76d48b-2f8d-4b89-8588-5c5ae9a320f1,DISK], DatanodeInfoWithStorage[127.0.0.1:43020,DS-b8431b58-8689-4d82-86b0-9aff35ae6818,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1111745205-172.17.0.2-1598098181876:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43051,DS-ff415d4c-6cf7-4580-94ce-92e1c96be7eb,DISK], DatanodeInfoWithStorage[127.0.0.1:46711,DS-e60de82b-2f35-462c-bb32-fa189529423e,DISK], DatanodeInfoWithStorage[127.0.0.1:43547,DS-1e307f06-08ce-43fc-b5a1-f5c31700a8db,DISK], DatanodeInfoWithStorage[127.0.0.1:36915,DS-41ba1edf-2fdc-4b58-a947-f7a0969a623a,DISK], DatanodeInfoWithStorage[127.0.0.1:45046,DS-30dd6d94-9eaf-4d1b-add0-8b788e858f09,DISK], DatanodeInfoWithStorage[127.0.0.1:38353,DS-3f318a76-d709-483e-9256-2d4d92a26559,DISK], DatanodeInfoWithStorage[127.0.0.1:36515,DS-3e76d48b-2f8d-4b89-8588-5c5ae9a320f1,DISK], DatanodeInfoWithStorage[127.0.0.1:43020,DS-b8431b58-8689-4d82-86b0-9aff35ae6818,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-509056682-172.17.0.2-1598099175082:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33610,DS-ecf7984e-664e-428e-8283-4ff4ee933233,DISK], DatanodeInfoWithStorage[127.0.0.1:40228,DS-f5d5a23e-21ba-432f-bb6e-6dfb38075238,DISK], DatanodeInfoWithStorage[127.0.0.1:35025,DS-2fa53d96-1785-4011-90b1-db532b6ea012,DISK], DatanodeInfoWithStorage[127.0.0.1:36453,DS-7d2a1724-dc93-4ace-9a11-a1093c4fbed5,DISK], DatanodeInfoWithStorage[127.0.0.1:45221,DS-9b43f5a9-02b5-4135-a833-02d99b7084aa,DISK], DatanodeInfoWithStorage[127.0.0.1:38524,DS-e3b02600-f9c3-4581-98c7-478dfbdb96b5,DISK], DatanodeInfoWithStorage[127.0.0.1:35388,DS-6fd2704e-91c4-421f-8bf3-a8a856e255f1,DISK], DatanodeInfoWithStorage[127.0.0.1:34696,DS-be479a37-d5d1-4f70-94a4-8bd2a025c79b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-509056682-172.17.0.2-1598099175082:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33610,DS-ecf7984e-664e-428e-8283-4ff4ee933233,DISK], DatanodeInfoWithStorage[127.0.0.1:40228,DS-f5d5a23e-21ba-432f-bb6e-6dfb38075238,DISK], DatanodeInfoWithStorage[127.0.0.1:35025,DS-2fa53d96-1785-4011-90b1-db532b6ea012,DISK], DatanodeInfoWithStorage[127.0.0.1:36453,DS-7d2a1724-dc93-4ace-9a11-a1093c4fbed5,DISK], DatanodeInfoWithStorage[127.0.0.1:45221,DS-9b43f5a9-02b5-4135-a833-02d99b7084aa,DISK], DatanodeInfoWithStorage[127.0.0.1:38524,DS-e3b02600-f9c3-4581-98c7-478dfbdb96b5,DISK], DatanodeInfoWithStorage[127.0.0.1:35388,DS-6fd2704e-91c4-421f-8bf3-a8a856e255f1,DISK], DatanodeInfoWithStorage[127.0.0.1:34696,DS-be479a37-d5d1-4f70-94a4-8bd2a025c79b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2033683262-172.17.0.2-1598099206322:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35667,DS-9085ebe2-7b44-4193-b19f-1abf56cf0ac9,DISK], DatanodeInfoWithStorage[127.0.0.1:46847,DS-689208ff-103f-48a4-b14a-8ae58936a9a2,DISK], DatanodeInfoWithStorage[127.0.0.1:34871,DS-fd47ec7a-708c-4c53-824f-b3c66e771dcc,DISK], DatanodeInfoWithStorage[127.0.0.1:37848,DS-2f6bd61d-06d3-4a35-bcbe-514d64702dfb,DISK], DatanodeInfoWithStorage[127.0.0.1:33585,DS-4a7e0d3b-04aa-4d74-bd3a-badaff1d3ee7,DISK], DatanodeInfoWithStorage[127.0.0.1:33616,DS-9b03fc4b-aa7d-4e55-ae20-77e05df8619b,DISK], DatanodeInfoWithStorage[127.0.0.1:38216,DS-18bc2cca-892b-4a78-8516-9199c112b319,DISK], DatanodeInfoWithStorage[127.0.0.1:40407,DS-cf2821c4-f2e4-47e3-975c-8afba303713c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2033683262-172.17.0.2-1598099206322:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35667,DS-9085ebe2-7b44-4193-b19f-1abf56cf0ac9,DISK], DatanodeInfoWithStorage[127.0.0.1:46847,DS-689208ff-103f-48a4-b14a-8ae58936a9a2,DISK], DatanodeInfoWithStorage[127.0.0.1:34871,DS-fd47ec7a-708c-4c53-824f-b3c66e771dcc,DISK], DatanodeInfoWithStorage[127.0.0.1:37848,DS-2f6bd61d-06d3-4a35-bcbe-514d64702dfb,DISK], DatanodeInfoWithStorage[127.0.0.1:33585,DS-4a7e0d3b-04aa-4d74-bd3a-badaff1d3ee7,DISK], DatanodeInfoWithStorage[127.0.0.1:33616,DS-9b03fc4b-aa7d-4e55-ae20-77e05df8619b,DISK], DatanodeInfoWithStorage[127.0.0.1:38216,DS-18bc2cca-892b-4a78-8516-9199c112b319,DISK], DatanodeInfoWithStorage[127.0.0.1:40407,DS-cf2821c4-f2e4-47e3-975c-8afba303713c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-159236456-172.17.0.2-1598100064571:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43251,DS-4d3b2c55-047c-4c08-8890-c33e7e2656c3,DISK], DatanodeInfoWithStorage[127.0.0.1:42249,DS-df272839-81f1-4f7c-a59d-54c9c95c7693,DISK], DatanodeInfoWithStorage[127.0.0.1:45513,DS-1edc4c70-48c6-49bf-9057-54b2eb0c3cf7,DISK], DatanodeInfoWithStorage[127.0.0.1:35565,DS-6504cf75-6d17-445b-8717-65146a7394e3,DISK], DatanodeInfoWithStorage[127.0.0.1:42442,DS-7d610f86-646c-4798-ba03-ce1572ed3fdd,DISK], DatanodeInfoWithStorage[127.0.0.1:44539,DS-e6f1c410-31d1-419e-83e9-30bb54f1e940,DISK], DatanodeInfoWithStorage[127.0.0.1:41180,DS-e5e3574a-e874-4c55-bc0e-c1527021e333,DISK], DatanodeInfoWithStorage[127.0.0.1:46053,DS-f40a5a4c-6536-4d35-8af4-d6ae84a048a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-159236456-172.17.0.2-1598100064571:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43251,DS-4d3b2c55-047c-4c08-8890-c33e7e2656c3,DISK], DatanodeInfoWithStorage[127.0.0.1:42249,DS-df272839-81f1-4f7c-a59d-54c9c95c7693,DISK], DatanodeInfoWithStorage[127.0.0.1:45513,DS-1edc4c70-48c6-49bf-9057-54b2eb0c3cf7,DISK], DatanodeInfoWithStorage[127.0.0.1:35565,DS-6504cf75-6d17-445b-8717-65146a7394e3,DISK], DatanodeInfoWithStorage[127.0.0.1:42442,DS-7d610f86-646c-4798-ba03-ce1572ed3fdd,DISK], DatanodeInfoWithStorage[127.0.0.1:44539,DS-e6f1c410-31d1-419e-83e9-30bb54f1e940,DISK], DatanodeInfoWithStorage[127.0.0.1:41180,DS-e5e3574a-e874-4c55-bc0e-c1527021e333,DISK], DatanodeInfoWithStorage[127.0.0.1:46053,DS-f40a5a4c-6536-4d35-8af4-d6ae84a048a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1232371802-172.17.0.2-1598100505579:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34505,DS-9f27d19d-1851-44c8-8c91-b889593b1a0b,DISK], DatanodeInfoWithStorage[127.0.0.1:38997,DS-be402186-cb91-41a6-8496-97e090f6ff62,DISK], DatanodeInfoWithStorage[127.0.0.1:39373,DS-e9e5db39-e29a-4516-a7b1-881dc0a11b08,DISK], DatanodeInfoWithStorage[127.0.0.1:34276,DS-9e2555dd-5340-4d08-915e-f7cec34eab13,DISK], DatanodeInfoWithStorage[127.0.0.1:46613,DS-db261a77-9027-4749-855d-46cf7a333742,DISK], DatanodeInfoWithStorage[127.0.0.1:36383,DS-e03cdd0f-681e-409c-bf0d-85b8f853003f,DISK], DatanodeInfoWithStorage[127.0.0.1:43857,DS-649e9d21-2d03-4d5b-bb08-edfc74b86f25,DISK], DatanodeInfoWithStorage[127.0.0.1:42711,DS-66b0fd20-273b-4dd4-9b04-c767706ba90d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1232371802-172.17.0.2-1598100505579:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34505,DS-9f27d19d-1851-44c8-8c91-b889593b1a0b,DISK], DatanodeInfoWithStorage[127.0.0.1:38997,DS-be402186-cb91-41a6-8496-97e090f6ff62,DISK], DatanodeInfoWithStorage[127.0.0.1:39373,DS-e9e5db39-e29a-4516-a7b1-881dc0a11b08,DISK], DatanodeInfoWithStorage[127.0.0.1:34276,DS-9e2555dd-5340-4d08-915e-f7cec34eab13,DISK], DatanodeInfoWithStorage[127.0.0.1:46613,DS-db261a77-9027-4749-855d-46cf7a333742,DISK], DatanodeInfoWithStorage[127.0.0.1:36383,DS-e03cdd0f-681e-409c-bf0d-85b8f853003f,DISK], DatanodeInfoWithStorage[127.0.0.1:43857,DS-649e9d21-2d03-4d5b-bb08-edfc74b86f25,DISK], DatanodeInfoWithStorage[127.0.0.1:42711,DS-66b0fd20-273b-4dd4-9b04-c767706ba90d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-557873629-172.17.0.2-1598100540843:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43378,DS-9944736f-cacc-4826-802d-31fd7eaa3c22,DISK], DatanodeInfoWithStorage[127.0.0.1:37104,DS-3e9b7720-2e04-420f-aca6-0832e09df9b9,DISK], DatanodeInfoWithStorage[127.0.0.1:41415,DS-51b94b55-5cf8-46ff-83b2-96a67aac3517,DISK], DatanodeInfoWithStorage[127.0.0.1:46828,DS-47a51f0c-fd0b-4e98-aea5-574a4d5d8097,DISK], DatanodeInfoWithStorage[127.0.0.1:33502,DS-bf209d6f-5ad0-48b0-a468-f21fc5e0d52a,DISK], DatanodeInfoWithStorage[127.0.0.1:41333,DS-58ff657e-3001-4dff-8275-e867183e6796,DISK], DatanodeInfoWithStorage[127.0.0.1:45928,DS-98b79085-2432-4fd0-8ca1-f9d428999e59,DISK], DatanodeInfoWithStorage[127.0.0.1:44519,DS-285dee8b-f581-4eaa-8f13-76812e85036a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-557873629-172.17.0.2-1598100540843:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43378,DS-9944736f-cacc-4826-802d-31fd7eaa3c22,DISK], DatanodeInfoWithStorage[127.0.0.1:37104,DS-3e9b7720-2e04-420f-aca6-0832e09df9b9,DISK], DatanodeInfoWithStorage[127.0.0.1:41415,DS-51b94b55-5cf8-46ff-83b2-96a67aac3517,DISK], DatanodeInfoWithStorage[127.0.0.1:46828,DS-47a51f0c-fd0b-4e98-aea5-574a4d5d8097,DISK], DatanodeInfoWithStorage[127.0.0.1:33502,DS-bf209d6f-5ad0-48b0-a468-f21fc5e0d52a,DISK], DatanodeInfoWithStorage[127.0.0.1:41333,DS-58ff657e-3001-4dff-8275-e867183e6796,DISK], DatanodeInfoWithStorage[127.0.0.1:45928,DS-98b79085-2432-4fd0-8ca1-f9d428999e59,DISK], DatanodeInfoWithStorage[127.0.0.1:44519,DS-285dee8b-f581-4eaa-8f13-76812e85036a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2092133670-172.17.0.2-1598101183063:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32993,DS-fd071b40-2333-45ea-a710-9a38d43b462e,DISK], DatanodeInfoWithStorage[127.0.0.1:37738,DS-2e777728-a85e-4f65-b61f-ee3fcb55d2db,DISK], DatanodeInfoWithStorage[127.0.0.1:43269,DS-c1db139b-5440-4396-b54d-eb10218b0e81,DISK], DatanodeInfoWithStorage[127.0.0.1:41979,DS-82683458-5784-4b40-843f-5d0ac7255223,DISK], DatanodeInfoWithStorage[127.0.0.1:44258,DS-9b6d4468-1c35-4cd8-8b00-ff334e8c8aa4,DISK], DatanodeInfoWithStorage[127.0.0.1:38005,DS-1f073a9b-1e37-4fd9-b880-705442e3b622,DISK], DatanodeInfoWithStorage[127.0.0.1:45210,DS-95870486-4bec-41d1-bc95-3e2c666d22df,DISK], DatanodeInfoWithStorage[127.0.0.1:36530,DS-6939747c-d05a-456a-b6ab-c4119f0601da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2092133670-172.17.0.2-1598101183063:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32993,DS-fd071b40-2333-45ea-a710-9a38d43b462e,DISK], DatanodeInfoWithStorage[127.0.0.1:37738,DS-2e777728-a85e-4f65-b61f-ee3fcb55d2db,DISK], DatanodeInfoWithStorage[127.0.0.1:43269,DS-c1db139b-5440-4396-b54d-eb10218b0e81,DISK], DatanodeInfoWithStorage[127.0.0.1:41979,DS-82683458-5784-4b40-843f-5d0ac7255223,DISK], DatanodeInfoWithStorage[127.0.0.1:44258,DS-9b6d4468-1c35-4cd8-8b00-ff334e8c8aa4,DISK], DatanodeInfoWithStorage[127.0.0.1:38005,DS-1f073a9b-1e37-4fd9-b880-705442e3b622,DISK], DatanodeInfoWithStorage[127.0.0.1:45210,DS-95870486-4bec-41d1-bc95-3e2c666d22df,DISK], DatanodeInfoWithStorage[127.0.0.1:36530,DS-6939747c-d05a-456a-b6ab-c4119f0601da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1931572707-172.17.0.2-1598101774035:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34296,DS-b0cdb681-0e42-4bc5-875d-65c58ec863f2,DISK], DatanodeInfoWithStorage[127.0.0.1:37338,DS-601e946f-d6ac-45bd-8de8-66d54f84a5f9,DISK], DatanodeInfoWithStorage[127.0.0.1:34446,DS-df3cb395-85e9-43d5-984e-62b58a0fa8d6,DISK], DatanodeInfoWithStorage[127.0.0.1:41611,DS-9b152c90-8d9b-4605-8815-91d976611a20,DISK], DatanodeInfoWithStorage[127.0.0.1:33052,DS-2e52851e-af15-4e4a-993b-eeef9b9fc3cb,DISK], DatanodeInfoWithStorage[127.0.0.1:38424,DS-814b93ba-bf04-4394-b35e-66de44b5943b,DISK], DatanodeInfoWithStorage[127.0.0.1:45307,DS-a35cf7ff-35af-4172-a338-6f3e6edcbe0e,DISK], DatanodeInfoWithStorage[127.0.0.1:37822,DS-3ded3d59-1a43-4aae-862e-60a9040482ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1931572707-172.17.0.2-1598101774035:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34296,DS-b0cdb681-0e42-4bc5-875d-65c58ec863f2,DISK], DatanodeInfoWithStorage[127.0.0.1:37338,DS-601e946f-d6ac-45bd-8de8-66d54f84a5f9,DISK], DatanodeInfoWithStorage[127.0.0.1:34446,DS-df3cb395-85e9-43d5-984e-62b58a0fa8d6,DISK], DatanodeInfoWithStorage[127.0.0.1:41611,DS-9b152c90-8d9b-4605-8815-91d976611a20,DISK], DatanodeInfoWithStorage[127.0.0.1:33052,DS-2e52851e-af15-4e4a-993b-eeef9b9fc3cb,DISK], DatanodeInfoWithStorage[127.0.0.1:38424,DS-814b93ba-bf04-4394-b35e-66de44b5943b,DISK], DatanodeInfoWithStorage[127.0.0.1:45307,DS-a35cf7ff-35af-4172-a338-6f3e6edcbe0e,DISK], DatanodeInfoWithStorage[127.0.0.1:37822,DS-3ded3d59-1a43-4aae-862e-60a9040482ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-386565780-172.17.0.2-1598102392495:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43794,DS-3805bf2d-9877-4741-ba43-fade421007c1,DISK], DatanodeInfoWithStorage[127.0.0.1:32801,DS-c2413d78-7605-451e-a223-9f14d2ac62af,DISK], DatanodeInfoWithStorage[127.0.0.1:41096,DS-c1765a04-ee2c-4188-88f2-754c2759e127,DISK], DatanodeInfoWithStorage[127.0.0.1:33682,DS-e8ad6fd1-e6e1-4446-a4f2-b335d4289829,DISK], DatanodeInfoWithStorage[127.0.0.1:42634,DS-058b25d9-b1f6-491f-8a09-a08be27b3b81,DISK], DatanodeInfoWithStorage[127.0.0.1:35494,DS-295707d5-120d-4b0f-98eb-911c0734dab8,DISK], DatanodeInfoWithStorage[127.0.0.1:42540,DS-6f168fb8-3e1b-44e5-9b55-bbf6ae60df7b,DISK], DatanodeInfoWithStorage[127.0.0.1:43406,DS-3d7d3492-3945-497b-b6a5-79070b6929d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-386565780-172.17.0.2-1598102392495:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43794,DS-3805bf2d-9877-4741-ba43-fade421007c1,DISK], DatanodeInfoWithStorage[127.0.0.1:32801,DS-c2413d78-7605-451e-a223-9f14d2ac62af,DISK], DatanodeInfoWithStorage[127.0.0.1:41096,DS-c1765a04-ee2c-4188-88f2-754c2759e127,DISK], DatanodeInfoWithStorage[127.0.0.1:33682,DS-e8ad6fd1-e6e1-4446-a4f2-b335d4289829,DISK], DatanodeInfoWithStorage[127.0.0.1:42634,DS-058b25d9-b1f6-491f-8a09-a08be27b3b81,DISK], DatanodeInfoWithStorage[127.0.0.1:35494,DS-295707d5-120d-4b0f-98eb-911c0734dab8,DISK], DatanodeInfoWithStorage[127.0.0.1:42540,DS-6f168fb8-3e1b-44e5-9b55-bbf6ae60df7b,DISK], DatanodeInfoWithStorage[127.0.0.1:43406,DS-3d7d3492-3945-497b-b6a5-79070b6929d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1012479564-172.17.0.2-1598102424076:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36326,DS-d565088e-3ec2-4b3f-a308-575d5864c150,DISK], DatanodeInfoWithStorage[127.0.0.1:44258,DS-5b392914-4c78-410a-a358-28d774ae3a53,DISK], DatanodeInfoWithStorage[127.0.0.1:46834,DS-01cd061e-d70d-48bb-b6b5-0cdd8bbd7b28,DISK], DatanodeInfoWithStorage[127.0.0.1:37554,DS-319568bf-81a9-4dd1-99b2-013709a8cade,DISK], DatanodeInfoWithStorage[127.0.0.1:36691,DS-ec9a4909-8c26-43bd-92d4-28ef7373b2b4,DISK], DatanodeInfoWithStorage[127.0.0.1:37004,DS-ef5f5bbd-8100-4114-af71-b595a363eed2,DISK], DatanodeInfoWithStorage[127.0.0.1:38416,DS-6348510c-df89-439e-adad-e018dfe0206d,DISK], DatanodeInfoWithStorage[127.0.0.1:43059,DS-26951896-ded9-4d81-b60f-c90b32ba8cbb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1012479564-172.17.0.2-1598102424076:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36326,DS-d565088e-3ec2-4b3f-a308-575d5864c150,DISK], DatanodeInfoWithStorage[127.0.0.1:44258,DS-5b392914-4c78-410a-a358-28d774ae3a53,DISK], DatanodeInfoWithStorage[127.0.0.1:46834,DS-01cd061e-d70d-48bb-b6b5-0cdd8bbd7b28,DISK], DatanodeInfoWithStorage[127.0.0.1:37554,DS-319568bf-81a9-4dd1-99b2-013709a8cade,DISK], DatanodeInfoWithStorage[127.0.0.1:36691,DS-ec9a4909-8c26-43bd-92d4-28ef7373b2b4,DISK], DatanodeInfoWithStorage[127.0.0.1:37004,DS-ef5f5bbd-8100-4114-af71-b595a363eed2,DISK], DatanodeInfoWithStorage[127.0.0.1:38416,DS-6348510c-df89-439e-adad-e018dfe0206d,DISK], DatanodeInfoWithStorage[127.0.0.1:43059,DS-26951896-ded9-4d81-b60f-c90b32ba8cbb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1177966255-172.17.0.2-1598102724146:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44981,DS-e6de7b1b-c730-43b4-ab52-ac415be7ea99,DISK], DatanodeInfoWithStorage[127.0.0.1:36118,DS-192c5aec-928a-42be-a19d-974696bf876e,DISK], DatanodeInfoWithStorage[127.0.0.1:45800,DS-05edb1c5-54fb-486c-87be-0a26175155d9,DISK], DatanodeInfoWithStorage[127.0.0.1:38923,DS-51cafd93-2816-45e3-8c34-3e9914b4dfbe,DISK], DatanodeInfoWithStorage[127.0.0.1:34827,DS-b8c32bb1-b86f-4d8b-9ac1-adb91d98a520,DISK], DatanodeInfoWithStorage[127.0.0.1:39743,DS-8534203d-3bb7-4c63-ae39-3805c868209b,DISK], DatanodeInfoWithStorage[127.0.0.1:41880,DS-df38dc5e-b8b3-4849-98cd-d84c95e05461,DISK], DatanodeInfoWithStorage[127.0.0.1:42837,DS-c33fe146-448b-4272-af22-b4415bc723b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1177966255-172.17.0.2-1598102724146:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44981,DS-e6de7b1b-c730-43b4-ab52-ac415be7ea99,DISK], DatanodeInfoWithStorage[127.0.0.1:36118,DS-192c5aec-928a-42be-a19d-974696bf876e,DISK], DatanodeInfoWithStorage[127.0.0.1:45800,DS-05edb1c5-54fb-486c-87be-0a26175155d9,DISK], DatanodeInfoWithStorage[127.0.0.1:38923,DS-51cafd93-2816-45e3-8c34-3e9914b4dfbe,DISK], DatanodeInfoWithStorage[127.0.0.1:34827,DS-b8c32bb1-b86f-4d8b-9ac1-adb91d98a520,DISK], DatanodeInfoWithStorage[127.0.0.1:39743,DS-8534203d-3bb7-4c63-ae39-3805c868209b,DISK], DatanodeInfoWithStorage[127.0.0.1:41880,DS-df38dc5e-b8b3-4849-98cd-d84c95e05461,DISK], DatanodeInfoWithStorage[127.0.0.1:42837,DS-c33fe146-448b-4272-af22-b4415bc723b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 6 out of 50
result: false positive !!!
Total execution time in seconds : 5027
