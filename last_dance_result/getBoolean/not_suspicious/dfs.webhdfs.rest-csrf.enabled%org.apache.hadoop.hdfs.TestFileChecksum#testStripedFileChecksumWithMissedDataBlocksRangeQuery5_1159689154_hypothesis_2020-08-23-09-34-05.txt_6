reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-841325189-172.17.0.19-1598175379702:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40562,DS-f0d85538-20bf-4408-97ca-919b661ed0c1,DISK], DatanodeInfoWithStorage[127.0.0.1:36085,DS-2d3457e3-2e5e-437d-92b4-0bf67d9f8bc9,DISK], DatanodeInfoWithStorage[127.0.0.1:33268,DS-c70469a9-59fe-47c2-824b-54e434a4f6ba,DISK], DatanodeInfoWithStorage[127.0.0.1:39538,DS-49e4e405-11b3-48f5-b190-8bb134acac22,DISK], DatanodeInfoWithStorage[127.0.0.1:40938,DS-9245adbe-4e86-4826-a650-f500ac222c20,DISK], DatanodeInfoWithStorage[127.0.0.1:34428,DS-603e5a6f-9fa7-4d52-a4c7-71e890aae669,DISK], DatanodeInfoWithStorage[127.0.0.1:46400,DS-cc65bfca-c106-4604-838f-f2fa17ace60e,DISK], DatanodeInfoWithStorage[127.0.0.1:34151,DS-8df0ac5f-f9b3-4f6b-8aeb-b9212b34e805,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-841325189-172.17.0.19-1598175379702:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40562,DS-f0d85538-20bf-4408-97ca-919b661ed0c1,DISK], DatanodeInfoWithStorage[127.0.0.1:36085,DS-2d3457e3-2e5e-437d-92b4-0bf67d9f8bc9,DISK], DatanodeInfoWithStorage[127.0.0.1:33268,DS-c70469a9-59fe-47c2-824b-54e434a4f6ba,DISK], DatanodeInfoWithStorage[127.0.0.1:39538,DS-49e4e405-11b3-48f5-b190-8bb134acac22,DISK], DatanodeInfoWithStorage[127.0.0.1:40938,DS-9245adbe-4e86-4826-a650-f500ac222c20,DISK], DatanodeInfoWithStorage[127.0.0.1:34428,DS-603e5a6f-9fa7-4d52-a4c7-71e890aae669,DISK], DatanodeInfoWithStorage[127.0.0.1:46400,DS-cc65bfca-c106-4604-838f-f2fa17ace60e,DISK], DatanodeInfoWithStorage[127.0.0.1:34151,DS-8df0ac5f-f9b3-4f6b-8aeb-b9212b34e805,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1202902360-172.17.0.19-1598175757308:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45883,DS-2f6a9aec-fafc-49e3-9916-9275ffe7e629,DISK], DatanodeInfoWithStorage[127.0.0.1:34766,DS-b8e4b4d1-e96e-4b33-ae5b-4d6b025831e5,DISK], DatanodeInfoWithStorage[127.0.0.1:33123,DS-e7700c38-3f2f-4a84-afe5-85e8ebcb36d9,DISK], DatanodeInfoWithStorage[127.0.0.1:40703,DS-6c406ce6-0fe8-4556-871d-87781a402e2b,DISK], DatanodeInfoWithStorage[127.0.0.1:41980,DS-53b6133d-293a-401e-9127-ff9be92ab047,DISK], DatanodeInfoWithStorage[127.0.0.1:43157,DS-03bd50e3-4a0a-4120-8b71-ab9ff4fe80b5,DISK], DatanodeInfoWithStorage[127.0.0.1:37661,DS-80e9903b-20b0-484d-a8e3-f2e3b9fd753f,DISK], DatanodeInfoWithStorage[127.0.0.1:40966,DS-679fcfb3-ea83-4d87-982b-522968f234ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1202902360-172.17.0.19-1598175757308:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45883,DS-2f6a9aec-fafc-49e3-9916-9275ffe7e629,DISK], DatanodeInfoWithStorage[127.0.0.1:34766,DS-b8e4b4d1-e96e-4b33-ae5b-4d6b025831e5,DISK], DatanodeInfoWithStorage[127.0.0.1:33123,DS-e7700c38-3f2f-4a84-afe5-85e8ebcb36d9,DISK], DatanodeInfoWithStorage[127.0.0.1:40703,DS-6c406ce6-0fe8-4556-871d-87781a402e2b,DISK], DatanodeInfoWithStorage[127.0.0.1:41980,DS-53b6133d-293a-401e-9127-ff9be92ab047,DISK], DatanodeInfoWithStorage[127.0.0.1:43157,DS-03bd50e3-4a0a-4120-8b71-ab9ff4fe80b5,DISK], DatanodeInfoWithStorage[127.0.0.1:37661,DS-80e9903b-20b0-484d-a8e3-f2e3b9fd753f,DISK], DatanodeInfoWithStorage[127.0.0.1:40966,DS-679fcfb3-ea83-4d87-982b-522968f234ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-817766386-172.17.0.19-1598176310501:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40809,DS-3c06473c-efe9-4e41-9a97-9b47439ab34f,DISK], DatanodeInfoWithStorage[127.0.0.1:32964,DS-1ea6be92-80fb-4a22-8aed-bea977e7f54d,DISK], DatanodeInfoWithStorage[127.0.0.1:40413,DS-07c7c79c-cd90-4f06-83d9-2a304575ac71,DISK], DatanodeInfoWithStorage[127.0.0.1:39724,DS-ca246de5-da1a-4a89-9f90-96c1a93936a1,DISK], DatanodeInfoWithStorage[127.0.0.1:39323,DS-407df34e-be78-4e71-86a6-669fecb8787a,DISK], DatanodeInfoWithStorage[127.0.0.1:40167,DS-9acf6afc-1d11-420f-80a5-1a40f5f6ce34,DISK], DatanodeInfoWithStorage[127.0.0.1:42256,DS-071abc84-1f88-42a0-83ec-6db18fb18376,DISK], DatanodeInfoWithStorage[127.0.0.1:41541,DS-26d8bdf4-6d99-41a6-965b-71df8a971158,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-817766386-172.17.0.19-1598176310501:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40809,DS-3c06473c-efe9-4e41-9a97-9b47439ab34f,DISK], DatanodeInfoWithStorage[127.0.0.1:32964,DS-1ea6be92-80fb-4a22-8aed-bea977e7f54d,DISK], DatanodeInfoWithStorage[127.0.0.1:40413,DS-07c7c79c-cd90-4f06-83d9-2a304575ac71,DISK], DatanodeInfoWithStorage[127.0.0.1:39724,DS-ca246de5-da1a-4a89-9f90-96c1a93936a1,DISK], DatanodeInfoWithStorage[127.0.0.1:39323,DS-407df34e-be78-4e71-86a6-669fecb8787a,DISK], DatanodeInfoWithStorage[127.0.0.1:40167,DS-9acf6afc-1d11-420f-80a5-1a40f5f6ce34,DISK], DatanodeInfoWithStorage[127.0.0.1:42256,DS-071abc84-1f88-42a0-83ec-6db18fb18376,DISK], DatanodeInfoWithStorage[127.0.0.1:41541,DS-26d8bdf4-6d99-41a6-965b-71df8a971158,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2109225563-172.17.0.19-1598176393638:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45152,DS-14b698b7-e211-4123-961d-1afdfbcfbbd8,DISK], DatanodeInfoWithStorage[127.0.0.1:34213,DS-447d49ee-8ae2-4ee0-8658-49eefb675edc,DISK], DatanodeInfoWithStorage[127.0.0.1:44188,DS-eb225c0c-90e3-4864-9ed6-9a1d498d7534,DISK], DatanodeInfoWithStorage[127.0.0.1:36932,DS-0385cd8e-df19-4501-8874-8b9b3ee4d3aa,DISK], DatanodeInfoWithStorage[127.0.0.1:38825,DS-fe6a7b07-aff8-4617-8c33-f159b66f2b7f,DISK], DatanodeInfoWithStorage[127.0.0.1:33299,DS-8044bba7-bacd-49e1-bc66-482928373b85,DISK], DatanodeInfoWithStorage[127.0.0.1:40810,DS-0aeac95c-550c-44af-8090-89bacf0cf783,DISK], DatanodeInfoWithStorage[127.0.0.1:43583,DS-25fcf4f6-f092-4612-afd4-265991eb2ff1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2109225563-172.17.0.19-1598176393638:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45152,DS-14b698b7-e211-4123-961d-1afdfbcfbbd8,DISK], DatanodeInfoWithStorage[127.0.0.1:34213,DS-447d49ee-8ae2-4ee0-8658-49eefb675edc,DISK], DatanodeInfoWithStorage[127.0.0.1:44188,DS-eb225c0c-90e3-4864-9ed6-9a1d498d7534,DISK], DatanodeInfoWithStorage[127.0.0.1:36932,DS-0385cd8e-df19-4501-8874-8b9b3ee4d3aa,DISK], DatanodeInfoWithStorage[127.0.0.1:38825,DS-fe6a7b07-aff8-4617-8c33-f159b66f2b7f,DISK], DatanodeInfoWithStorage[127.0.0.1:33299,DS-8044bba7-bacd-49e1-bc66-482928373b85,DISK], DatanodeInfoWithStorage[127.0.0.1:40810,DS-0aeac95c-550c-44af-8090-89bacf0cf783,DISK], DatanodeInfoWithStorage[127.0.0.1:43583,DS-25fcf4f6-f092-4612-afd4-265991eb2ff1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-947613716-172.17.0.19-1598176937747:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34459,DS-db85bf96-65ee-472d-be9f-7fe603b21a05,DISK], DatanodeInfoWithStorage[127.0.0.1:41661,DS-dc39458d-c7ad-4613-976e-b73f04fb063c,DISK], DatanodeInfoWithStorage[127.0.0.1:33986,DS-cd0ec05d-9acd-40a0-8c5d-55dcd7875c6d,DISK], DatanodeInfoWithStorage[127.0.0.1:37521,DS-ded15b27-eac0-4820-ac74-6133e7d471d2,DISK], DatanodeInfoWithStorage[127.0.0.1:40737,DS-3f0961f0-1be0-421a-949f-f7df887c78a4,DISK], DatanodeInfoWithStorage[127.0.0.1:46596,DS-15518323-ab32-4fc2-be53-fe917173b430,DISK], DatanodeInfoWithStorage[127.0.0.1:35316,DS-4a48e7be-56ce-4ce1-b692-aacd9c09a409,DISK], DatanodeInfoWithStorage[127.0.0.1:41363,DS-b7d2e579-9ad5-4fda-a159-95c436a3a8ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-947613716-172.17.0.19-1598176937747:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34459,DS-db85bf96-65ee-472d-be9f-7fe603b21a05,DISK], DatanodeInfoWithStorage[127.0.0.1:41661,DS-dc39458d-c7ad-4613-976e-b73f04fb063c,DISK], DatanodeInfoWithStorage[127.0.0.1:33986,DS-cd0ec05d-9acd-40a0-8c5d-55dcd7875c6d,DISK], DatanodeInfoWithStorage[127.0.0.1:37521,DS-ded15b27-eac0-4820-ac74-6133e7d471d2,DISK], DatanodeInfoWithStorage[127.0.0.1:40737,DS-3f0961f0-1be0-421a-949f-f7df887c78a4,DISK], DatanodeInfoWithStorage[127.0.0.1:46596,DS-15518323-ab32-4fc2-be53-fe917173b430,DISK], DatanodeInfoWithStorage[127.0.0.1:35316,DS-4a48e7be-56ce-4ce1-b692-aacd9c09a409,DISK], DatanodeInfoWithStorage[127.0.0.1:41363,DS-b7d2e579-9ad5-4fda-a159-95c436a3a8ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1391011071-172.17.0.19-1598177747322:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37437,DS-f54a90d1-e569-419a-ac34-784b780aa85d,DISK], DatanodeInfoWithStorage[127.0.0.1:34634,DS-f5a5ba43-d90c-4f53-8cf5-d8b6b60580a9,DISK], DatanodeInfoWithStorage[127.0.0.1:45159,DS-791c9114-839a-4835-971b-94dd662a4ac0,DISK], DatanodeInfoWithStorage[127.0.0.1:43030,DS-140f6713-daf7-4994-82ba-b7a4c084062d,DISK], DatanodeInfoWithStorage[127.0.0.1:38202,DS-8d06b255-041e-4152-a82a-325bd7c475fc,DISK], DatanodeInfoWithStorage[127.0.0.1:40515,DS-11459e15-4d5c-4719-9ccc-de91f69d6b7b,DISK], DatanodeInfoWithStorage[127.0.0.1:38852,DS-0c757a5c-4e2e-4394-8e81-01feb662944b,DISK], DatanodeInfoWithStorage[127.0.0.1:42675,DS-148aeb1a-244a-45fd-9955-89fbea9e1942,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1391011071-172.17.0.19-1598177747322:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37437,DS-f54a90d1-e569-419a-ac34-784b780aa85d,DISK], DatanodeInfoWithStorage[127.0.0.1:34634,DS-f5a5ba43-d90c-4f53-8cf5-d8b6b60580a9,DISK], DatanodeInfoWithStorage[127.0.0.1:45159,DS-791c9114-839a-4835-971b-94dd662a4ac0,DISK], DatanodeInfoWithStorage[127.0.0.1:43030,DS-140f6713-daf7-4994-82ba-b7a4c084062d,DISK], DatanodeInfoWithStorage[127.0.0.1:38202,DS-8d06b255-041e-4152-a82a-325bd7c475fc,DISK], DatanodeInfoWithStorage[127.0.0.1:40515,DS-11459e15-4d5c-4719-9ccc-de91f69d6b7b,DISK], DatanodeInfoWithStorage[127.0.0.1:38852,DS-0c757a5c-4e2e-4394-8e81-01feb662944b,DISK], DatanodeInfoWithStorage[127.0.0.1:42675,DS-148aeb1a-244a-45fd-9955-89fbea9e1942,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2017618823-172.17.0.19-1598178402791:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41715,DS-62a198fc-495b-4398-9621-7a9680397574,DISK], DatanodeInfoWithStorage[127.0.0.1:41654,DS-cdf58d4d-c502-4302-8dce-8c6698e1499c,DISK], DatanodeInfoWithStorage[127.0.0.1:34308,DS-7ecaf0e1-d5bc-407a-8af0-437bdca25330,DISK], DatanodeInfoWithStorage[127.0.0.1:35642,DS-69689f07-0d3c-4bfc-8ebd-b1f2f8b838ea,DISK], DatanodeInfoWithStorage[127.0.0.1:42807,DS-fd687d8b-01dc-4a82-ac36-34cda58e1499,DISK], DatanodeInfoWithStorage[127.0.0.1:39007,DS-cc30878d-6419-4c50-aa50-a27b498b4069,DISK], DatanodeInfoWithStorage[127.0.0.1:33679,DS-82e1b60b-2629-43a6-9e19-f1f2f6df775b,DISK], DatanodeInfoWithStorage[127.0.0.1:36360,DS-e0b8863d-81be-43ce-908b-57d0a524e093,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2017618823-172.17.0.19-1598178402791:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41715,DS-62a198fc-495b-4398-9621-7a9680397574,DISK], DatanodeInfoWithStorage[127.0.0.1:41654,DS-cdf58d4d-c502-4302-8dce-8c6698e1499c,DISK], DatanodeInfoWithStorage[127.0.0.1:34308,DS-7ecaf0e1-d5bc-407a-8af0-437bdca25330,DISK], DatanodeInfoWithStorage[127.0.0.1:35642,DS-69689f07-0d3c-4bfc-8ebd-b1f2f8b838ea,DISK], DatanodeInfoWithStorage[127.0.0.1:42807,DS-fd687d8b-01dc-4a82-ac36-34cda58e1499,DISK], DatanodeInfoWithStorage[127.0.0.1:39007,DS-cc30878d-6419-4c50-aa50-a27b498b4069,DISK], DatanodeInfoWithStorage[127.0.0.1:33679,DS-82e1b60b-2629-43a6-9e19-f1f2f6df775b,DISK], DatanodeInfoWithStorage[127.0.0.1:36360,DS-e0b8863d-81be-43ce-908b-57d0a524e093,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1893779394-172.17.0.19-1598178668263:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34860,DS-045c1ea1-1b2f-48ff-afb7-819215e75a1c,DISK], DatanodeInfoWithStorage[127.0.0.1:42990,DS-8d912ba6-5aaa-46e6-b2cc-62db7ab2d3b4,DISK], DatanodeInfoWithStorage[127.0.0.1:32939,DS-792d53f0-2fb4-4c52-8d00-d1bb09641b15,DISK], DatanodeInfoWithStorage[127.0.0.1:41243,DS-c7d483fb-6f3b-49da-8b72-4e05ceb12ab7,DISK], DatanodeInfoWithStorage[127.0.0.1:36978,DS-25be734b-14e7-4607-b755-3dc864f73ee2,DISK], DatanodeInfoWithStorage[127.0.0.1:39382,DS-57f1b5f6-4207-4d39-beb1-80845114069a,DISK], DatanodeInfoWithStorage[127.0.0.1:39086,DS-fa86e2b1-79f4-4d4c-8ebb-6315b32fa57a,DISK], DatanodeInfoWithStorage[127.0.0.1:43601,DS-978cd528-a160-460b-a823-5950518aea1b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1893779394-172.17.0.19-1598178668263:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34860,DS-045c1ea1-1b2f-48ff-afb7-819215e75a1c,DISK], DatanodeInfoWithStorage[127.0.0.1:42990,DS-8d912ba6-5aaa-46e6-b2cc-62db7ab2d3b4,DISK], DatanodeInfoWithStorage[127.0.0.1:32939,DS-792d53f0-2fb4-4c52-8d00-d1bb09641b15,DISK], DatanodeInfoWithStorage[127.0.0.1:41243,DS-c7d483fb-6f3b-49da-8b72-4e05ceb12ab7,DISK], DatanodeInfoWithStorage[127.0.0.1:36978,DS-25be734b-14e7-4607-b755-3dc864f73ee2,DISK], DatanodeInfoWithStorage[127.0.0.1:39382,DS-57f1b5f6-4207-4d39-beb1-80845114069a,DISK], DatanodeInfoWithStorage[127.0.0.1:39086,DS-fa86e2b1-79f4-4d4c-8ebb-6315b32fa57a,DISK], DatanodeInfoWithStorage[127.0.0.1:43601,DS-978cd528-a160-460b-a823-5950518aea1b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-284618341-172.17.0.19-1598178807661:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36954,DS-b3e6f7d8-e446-4c37-8831-f08a27e9e48f,DISK], DatanodeInfoWithStorage[127.0.0.1:36159,DS-2e4b5f57-65de-4673-9f45-dd67cca79024,DISK], DatanodeInfoWithStorage[127.0.0.1:34912,DS-94004b92-b5a0-4868-9280-aa512bd1ffaa,DISK], DatanodeInfoWithStorage[127.0.0.1:33117,DS-279fcbd9-f5ac-403a-9294-dbd172294771,DISK], DatanodeInfoWithStorage[127.0.0.1:38386,DS-eae0563b-61af-41bd-9382-dec91adff5a9,DISK], DatanodeInfoWithStorage[127.0.0.1:45195,DS-1d8df350-7b93-44e9-ae12-c37e34161572,DISK], DatanodeInfoWithStorage[127.0.0.1:44923,DS-f4006377-5d5c-41c6-9fa0-103f22de2384,DISK], DatanodeInfoWithStorage[127.0.0.1:42993,DS-b1744370-5cce-456e-b9fe-a9d4c5ce69d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-284618341-172.17.0.19-1598178807661:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36954,DS-b3e6f7d8-e446-4c37-8831-f08a27e9e48f,DISK], DatanodeInfoWithStorage[127.0.0.1:36159,DS-2e4b5f57-65de-4673-9f45-dd67cca79024,DISK], DatanodeInfoWithStorage[127.0.0.1:34912,DS-94004b92-b5a0-4868-9280-aa512bd1ffaa,DISK], DatanodeInfoWithStorage[127.0.0.1:33117,DS-279fcbd9-f5ac-403a-9294-dbd172294771,DISK], DatanodeInfoWithStorage[127.0.0.1:38386,DS-eae0563b-61af-41bd-9382-dec91adff5a9,DISK], DatanodeInfoWithStorage[127.0.0.1:45195,DS-1d8df350-7b93-44e9-ae12-c37e34161572,DISK], DatanodeInfoWithStorage[127.0.0.1:44923,DS-f4006377-5d5c-41c6-9fa0-103f22de2384,DISK], DatanodeInfoWithStorage[127.0.0.1:42993,DS-b1744370-5cce-456e-b9fe-a9d4c5ce69d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1210157365-172.17.0.19-1598179189815:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45893,DS-fb18eba0-89e8-4da0-8820-40158863a0e6,DISK], DatanodeInfoWithStorage[127.0.0.1:41883,DS-021af54a-bbdf-4acf-9265-26ca8b5bf5aa,DISK], DatanodeInfoWithStorage[127.0.0.1:38736,DS-70d963a7-6cf2-4324-8f74-744052774576,DISK], DatanodeInfoWithStorage[127.0.0.1:34014,DS-7316a853-5bb5-4932-bf78-d351bc2b1025,DISK], DatanodeInfoWithStorage[127.0.0.1:36359,DS-5ce9926d-ac26-4479-8f3e-829d3e3415a4,DISK], DatanodeInfoWithStorage[127.0.0.1:37425,DS-8f7f0f57-e6c3-42a8-848b-e98e3847855f,DISK], DatanodeInfoWithStorage[127.0.0.1:43133,DS-0fb77cd7-2f28-466b-b095-d94268cc1d76,DISK], DatanodeInfoWithStorage[127.0.0.1:38258,DS-1d18cd23-c364-4ba8-b1d0-0cd5125a8859,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1210157365-172.17.0.19-1598179189815:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45893,DS-fb18eba0-89e8-4da0-8820-40158863a0e6,DISK], DatanodeInfoWithStorage[127.0.0.1:41883,DS-021af54a-bbdf-4acf-9265-26ca8b5bf5aa,DISK], DatanodeInfoWithStorage[127.0.0.1:38736,DS-70d963a7-6cf2-4324-8f74-744052774576,DISK], DatanodeInfoWithStorage[127.0.0.1:34014,DS-7316a853-5bb5-4932-bf78-d351bc2b1025,DISK], DatanodeInfoWithStorage[127.0.0.1:36359,DS-5ce9926d-ac26-4479-8f3e-829d3e3415a4,DISK], DatanodeInfoWithStorage[127.0.0.1:37425,DS-8f7f0f57-e6c3-42a8-848b-e98e3847855f,DISK], DatanodeInfoWithStorage[127.0.0.1:43133,DS-0fb77cd7-2f28-466b-b095-d94268cc1d76,DISK], DatanodeInfoWithStorage[127.0.0.1:38258,DS-1d18cd23-c364-4ba8-b1d0-0cd5125a8859,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-869635745-172.17.0.19-1598179273460:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34245,DS-25c79123-b15f-4e0f-b44b-3d3e73c43dc6,DISK], DatanodeInfoWithStorage[127.0.0.1:37991,DS-3e9fd047-d0f7-4c35-a111-697de2e2936a,DISK], DatanodeInfoWithStorage[127.0.0.1:46508,DS-d19b1bc7-dc53-4c89-8a3b-aecb2967011b,DISK], DatanodeInfoWithStorage[127.0.0.1:41897,DS-d511b7ad-6bf7-41f1-812c-4a3ca35ab92d,DISK], DatanodeInfoWithStorage[127.0.0.1:36664,DS-e10bef25-01c1-4439-87b5-ed0f47227e0d,DISK], DatanodeInfoWithStorage[127.0.0.1:33722,DS-731a0f8e-d138-4f51-8f2d-bcb911624bd7,DISK], DatanodeInfoWithStorage[127.0.0.1:42526,DS-aed06585-be5a-4b64-9144-9415038478f4,DISK], DatanodeInfoWithStorage[127.0.0.1:38298,DS-8bb68824-4b03-439c-a352-f07359b78330,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-869635745-172.17.0.19-1598179273460:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34245,DS-25c79123-b15f-4e0f-b44b-3d3e73c43dc6,DISK], DatanodeInfoWithStorage[127.0.0.1:37991,DS-3e9fd047-d0f7-4c35-a111-697de2e2936a,DISK], DatanodeInfoWithStorage[127.0.0.1:46508,DS-d19b1bc7-dc53-4c89-8a3b-aecb2967011b,DISK], DatanodeInfoWithStorage[127.0.0.1:41897,DS-d511b7ad-6bf7-41f1-812c-4a3ca35ab92d,DISK], DatanodeInfoWithStorage[127.0.0.1:36664,DS-e10bef25-01c1-4439-87b5-ed0f47227e0d,DISK], DatanodeInfoWithStorage[127.0.0.1:33722,DS-731a0f8e-d138-4f51-8f2d-bcb911624bd7,DISK], DatanodeInfoWithStorage[127.0.0.1:42526,DS-aed06585-be5a-4b64-9144-9415038478f4,DISK], DatanodeInfoWithStorage[127.0.0.1:38298,DS-8bb68824-4b03-439c-a352-f07359b78330,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1908911411-172.17.0.19-1598179403057:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45422,DS-ec54868e-ca22-486a-a035-6db7a2c0ff8c,DISK], DatanodeInfoWithStorage[127.0.0.1:34152,DS-7902a41d-d250-482a-ad7e-9ec633a520cc,DISK], DatanodeInfoWithStorage[127.0.0.1:35493,DS-47a8263f-f5f1-4a08-9a79-be0c43547199,DISK], DatanodeInfoWithStorage[127.0.0.1:33376,DS-1183d373-62e6-4eff-967b-6c3edefe0a54,DISK], DatanodeInfoWithStorage[127.0.0.1:43221,DS-4583818c-6cbc-430f-9062-aec7d18d084c,DISK], DatanodeInfoWithStorage[127.0.0.1:34771,DS-6c526f73-aad6-4234-b6f7-bd1cb61632e9,DISK], DatanodeInfoWithStorage[127.0.0.1:45527,DS-577df8b6-bffc-4c69-b719-18fe91f80f93,DISK], DatanodeInfoWithStorage[127.0.0.1:37800,DS-d6e0ed02-ae87-43f5-8963-f9b10d59b923,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1908911411-172.17.0.19-1598179403057:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45422,DS-ec54868e-ca22-486a-a035-6db7a2c0ff8c,DISK], DatanodeInfoWithStorage[127.0.0.1:34152,DS-7902a41d-d250-482a-ad7e-9ec633a520cc,DISK], DatanodeInfoWithStorage[127.0.0.1:35493,DS-47a8263f-f5f1-4a08-9a79-be0c43547199,DISK], DatanodeInfoWithStorage[127.0.0.1:33376,DS-1183d373-62e6-4eff-967b-6c3edefe0a54,DISK], DatanodeInfoWithStorage[127.0.0.1:43221,DS-4583818c-6cbc-430f-9062-aec7d18d084c,DISK], DatanodeInfoWithStorage[127.0.0.1:34771,DS-6c526f73-aad6-4234-b6f7-bd1cb61632e9,DISK], DatanodeInfoWithStorage[127.0.0.1:45527,DS-577df8b6-bffc-4c69-b719-18fe91f80f93,DISK], DatanodeInfoWithStorage[127.0.0.1:37800,DS-d6e0ed02-ae87-43f5-8963-f9b10d59b923,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-192941917-172.17.0.19-1598179441710:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34322,DS-ece77819-4ffd-49f5-b7eb-faf85d3bda66,DISK], DatanodeInfoWithStorage[127.0.0.1:43959,DS-9c716bde-3f11-4a8e-9f61-b40a9c957feb,DISK], DatanodeInfoWithStorage[127.0.0.1:37423,DS-ececac43-61d8-44dc-8a64-1c17b6529e99,DISK], DatanodeInfoWithStorage[127.0.0.1:34255,DS-7355baea-7ebe-4a7f-8ea5-deb4d1522b25,DISK], DatanodeInfoWithStorage[127.0.0.1:36384,DS-447003f2-8d2b-45a2-ad4b-534f84216706,DISK], DatanodeInfoWithStorage[127.0.0.1:39501,DS-6912999b-a9f8-49bc-a64a-a1d1f88069a5,DISK], DatanodeInfoWithStorage[127.0.0.1:36992,DS-ad079240-542b-48fa-ac39-8085df2f5081,DISK], DatanodeInfoWithStorage[127.0.0.1:37769,DS-902c582b-fd13-4d30-8a63-600caaca003e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-192941917-172.17.0.19-1598179441710:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34322,DS-ece77819-4ffd-49f5-b7eb-faf85d3bda66,DISK], DatanodeInfoWithStorage[127.0.0.1:43959,DS-9c716bde-3f11-4a8e-9f61-b40a9c957feb,DISK], DatanodeInfoWithStorage[127.0.0.1:37423,DS-ececac43-61d8-44dc-8a64-1c17b6529e99,DISK], DatanodeInfoWithStorage[127.0.0.1:34255,DS-7355baea-7ebe-4a7f-8ea5-deb4d1522b25,DISK], DatanodeInfoWithStorage[127.0.0.1:36384,DS-447003f2-8d2b-45a2-ad4b-534f84216706,DISK], DatanodeInfoWithStorage[127.0.0.1:39501,DS-6912999b-a9f8-49bc-a64a-a1d1f88069a5,DISK], DatanodeInfoWithStorage[127.0.0.1:36992,DS-ad079240-542b-48fa-ac39-8085df2f5081,DISK], DatanodeInfoWithStorage[127.0.0.1:37769,DS-902c582b-fd13-4d30-8a63-600caaca003e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-505143924-172.17.0.19-1598179661316:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38591,DS-39838dfa-30a3-48be-bda5-ee8f6b1ca95b,DISK], DatanodeInfoWithStorage[127.0.0.1:33518,DS-f9dec8a5-6b92-4709-9a0c-ac8559b47352,DISK], DatanodeInfoWithStorage[127.0.0.1:45995,DS-3b5ab7e4-45df-45a3-84cc-3416bf2ed445,DISK], DatanodeInfoWithStorage[127.0.0.1:36067,DS-a2597050-f3c6-482e-a256-78ef3c1fb4df,DISK], DatanodeInfoWithStorage[127.0.0.1:33816,DS-5c92c262-b911-4ea5-8a6c-8993680f3b08,DISK], DatanodeInfoWithStorage[127.0.0.1:38468,DS-b3384cab-cccf-4827-b3f2-24000355657b,DISK], DatanodeInfoWithStorage[127.0.0.1:33237,DS-93749bbf-ddd7-4601-99d6-3072307da211,DISK], DatanodeInfoWithStorage[127.0.0.1:37398,DS-21ee86b3-fb67-45d9-8856-2261b82e6360,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-505143924-172.17.0.19-1598179661316:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38591,DS-39838dfa-30a3-48be-bda5-ee8f6b1ca95b,DISK], DatanodeInfoWithStorage[127.0.0.1:33518,DS-f9dec8a5-6b92-4709-9a0c-ac8559b47352,DISK], DatanodeInfoWithStorage[127.0.0.1:45995,DS-3b5ab7e4-45df-45a3-84cc-3416bf2ed445,DISK], DatanodeInfoWithStorage[127.0.0.1:36067,DS-a2597050-f3c6-482e-a256-78ef3c1fb4df,DISK], DatanodeInfoWithStorage[127.0.0.1:33816,DS-5c92c262-b911-4ea5-8a6c-8993680f3b08,DISK], DatanodeInfoWithStorage[127.0.0.1:38468,DS-b3384cab-cccf-4827-b3f2-24000355657b,DISK], DatanodeInfoWithStorage[127.0.0.1:33237,DS-93749bbf-ddd7-4601-99d6-3072307da211,DISK], DatanodeInfoWithStorage[127.0.0.1:37398,DS-21ee86b3-fb67-45d9-8856-2261b82e6360,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-360399834-172.17.0.19-1598179952809:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45438,DS-46881d65-45b2-4a5b-809e-c5b141686fe8,DISK], DatanodeInfoWithStorage[127.0.0.1:44521,DS-97f6523d-77fb-4785-ac74-11b778a8524d,DISK], DatanodeInfoWithStorage[127.0.0.1:33770,DS-3684d5a1-b196-4202-bec8-3b5d1caa3e01,DISK], DatanodeInfoWithStorage[127.0.0.1:44558,DS-131a1e9a-88df-4645-95d4-6816422d743b,DISK], DatanodeInfoWithStorage[127.0.0.1:41489,DS-828a1a77-9e98-456a-aa9f-7ae6fdf82f16,DISK], DatanodeInfoWithStorage[127.0.0.1:44493,DS-447a474a-4498-4402-ac47-a9789f9fa8fa,DISK], DatanodeInfoWithStorage[127.0.0.1:37290,DS-7fd0e5c2-e879-41c0-a3c5-542fe27aa811,DISK], DatanodeInfoWithStorage[127.0.0.1:34186,DS-5990d004-213e-44bb-bad6-81cf3dd4bce2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-360399834-172.17.0.19-1598179952809:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45438,DS-46881d65-45b2-4a5b-809e-c5b141686fe8,DISK], DatanodeInfoWithStorage[127.0.0.1:44521,DS-97f6523d-77fb-4785-ac74-11b778a8524d,DISK], DatanodeInfoWithStorage[127.0.0.1:33770,DS-3684d5a1-b196-4202-bec8-3b5d1caa3e01,DISK], DatanodeInfoWithStorage[127.0.0.1:44558,DS-131a1e9a-88df-4645-95d4-6816422d743b,DISK], DatanodeInfoWithStorage[127.0.0.1:41489,DS-828a1a77-9e98-456a-aa9f-7ae6fdf82f16,DISK], DatanodeInfoWithStorage[127.0.0.1:44493,DS-447a474a-4498-4402-ac47-a9789f9fa8fa,DISK], DatanodeInfoWithStorage[127.0.0.1:37290,DS-7fd0e5c2-e879-41c0-a3c5-542fe27aa811,DISK], DatanodeInfoWithStorage[127.0.0.1:34186,DS-5990d004-213e-44bb-bad6-81cf3dd4bce2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-833090576-172.17.0.19-1598180090807:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41792,DS-89dbc49d-e75c-45a9-9065-e8f27c6a573d,DISK], DatanodeInfoWithStorage[127.0.0.1:37949,DS-16ca6f9b-5e16-4ea2-9e84-c0be71770270,DISK], DatanodeInfoWithStorage[127.0.0.1:35091,DS-e5df6f89-d244-4abb-b057-08903d94fda9,DISK], DatanodeInfoWithStorage[127.0.0.1:42200,DS-59c7c8f6-803a-4baa-867f-c48db0280577,DISK], DatanodeInfoWithStorage[127.0.0.1:38350,DS-410c2ef1-174a-47a3-bc9e-d38d236585db,DISK], DatanodeInfoWithStorage[127.0.0.1:45977,DS-0348e19b-421a-4b27-89de-3572e74210f3,DISK], DatanodeInfoWithStorage[127.0.0.1:36992,DS-a92f3db7-dcaf-4b0d-9724-3e9b6c8cd324,DISK], DatanodeInfoWithStorage[127.0.0.1:45362,DS-ee3d853b-9da5-4c2a-8a2e-b846d71756b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-833090576-172.17.0.19-1598180090807:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41792,DS-89dbc49d-e75c-45a9-9065-e8f27c6a573d,DISK], DatanodeInfoWithStorage[127.0.0.1:37949,DS-16ca6f9b-5e16-4ea2-9e84-c0be71770270,DISK], DatanodeInfoWithStorage[127.0.0.1:35091,DS-e5df6f89-d244-4abb-b057-08903d94fda9,DISK], DatanodeInfoWithStorage[127.0.0.1:42200,DS-59c7c8f6-803a-4baa-867f-c48db0280577,DISK], DatanodeInfoWithStorage[127.0.0.1:38350,DS-410c2ef1-174a-47a3-bc9e-d38d236585db,DISK], DatanodeInfoWithStorage[127.0.0.1:45977,DS-0348e19b-421a-4b27-89de-3572e74210f3,DISK], DatanodeInfoWithStorage[127.0.0.1:36992,DS-a92f3db7-dcaf-4b0d-9724-3e9b6c8cd324,DISK], DatanodeInfoWithStorage[127.0.0.1:45362,DS-ee3d853b-9da5-4c2a-8a2e-b846d71756b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2126212365-172.17.0.19-1598180386096:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45456,DS-5b4b36fc-5ded-4ca0-9d8e-3a68faf5b9c8,DISK], DatanodeInfoWithStorage[127.0.0.1:33058,DS-4d6ca11d-5d51-4f61-83f6-205ff2034d67,DISK], DatanodeInfoWithStorage[127.0.0.1:40767,DS-9541cefc-ee09-46c5-b6bc-b73b2ee5747f,DISK], DatanodeInfoWithStorage[127.0.0.1:39201,DS-b7106fe1-32e8-48cf-8494-55d714fd3050,DISK], DatanodeInfoWithStorage[127.0.0.1:40444,DS-fda2de17-f261-43b1-b5f5-67eb3b09c49e,DISK], DatanodeInfoWithStorage[127.0.0.1:46530,DS-46a9e5a6-ca4b-40a6-a848-1de2674942f5,DISK], DatanodeInfoWithStorage[127.0.0.1:36499,DS-25bae2d8-4ac0-498d-bab9-46ec484f63b2,DISK], DatanodeInfoWithStorage[127.0.0.1:42543,DS-011fe7aa-830d-48ba-be35-69d29236a1ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2126212365-172.17.0.19-1598180386096:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45456,DS-5b4b36fc-5ded-4ca0-9d8e-3a68faf5b9c8,DISK], DatanodeInfoWithStorage[127.0.0.1:33058,DS-4d6ca11d-5d51-4f61-83f6-205ff2034d67,DISK], DatanodeInfoWithStorage[127.0.0.1:40767,DS-9541cefc-ee09-46c5-b6bc-b73b2ee5747f,DISK], DatanodeInfoWithStorage[127.0.0.1:39201,DS-b7106fe1-32e8-48cf-8494-55d714fd3050,DISK], DatanodeInfoWithStorage[127.0.0.1:40444,DS-fda2de17-f261-43b1-b5f5-67eb3b09c49e,DISK], DatanodeInfoWithStorage[127.0.0.1:46530,DS-46a9e5a6-ca4b-40a6-a848-1de2674942f5,DISK], DatanodeInfoWithStorage[127.0.0.1:36499,DS-25bae2d8-4ac0-498d-bab9-46ec484f63b2,DISK], DatanodeInfoWithStorage[127.0.0.1:42543,DS-011fe7aa-830d-48ba-be35-69d29236a1ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-198898949-172.17.0.19-1598180454569:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42062,DS-9c9e5672-c7fe-441d-84a6-10b5ed90c51e,DISK], DatanodeInfoWithStorage[127.0.0.1:36939,DS-009dc247-b1b1-4b4e-83ca-72d2dee1c3d0,DISK], DatanodeInfoWithStorage[127.0.0.1:33726,DS-cfb86132-2375-402b-b724-fe18e171ca61,DISK], DatanodeInfoWithStorage[127.0.0.1:44316,DS-b9f04366-7395-4319-b1cd-68dd3ab16732,DISK], DatanodeInfoWithStorage[127.0.0.1:38032,DS-0872a2d0-8a44-4bfa-8e3f-b3d3d8168722,DISK], DatanodeInfoWithStorage[127.0.0.1:35443,DS-2b0e3223-4dc8-46a3-90eb-246350b61855,DISK], DatanodeInfoWithStorage[127.0.0.1:39611,DS-84dbb7d7-f17d-42d6-b5fd-803f6caa65b2,DISK], DatanodeInfoWithStorage[127.0.0.1:34518,DS-2f6a0d17-37ff-46be-8e58-c401298dd315,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-198898949-172.17.0.19-1598180454569:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42062,DS-9c9e5672-c7fe-441d-84a6-10b5ed90c51e,DISK], DatanodeInfoWithStorage[127.0.0.1:36939,DS-009dc247-b1b1-4b4e-83ca-72d2dee1c3d0,DISK], DatanodeInfoWithStorage[127.0.0.1:33726,DS-cfb86132-2375-402b-b724-fe18e171ca61,DISK], DatanodeInfoWithStorage[127.0.0.1:44316,DS-b9f04366-7395-4319-b1cd-68dd3ab16732,DISK], DatanodeInfoWithStorage[127.0.0.1:38032,DS-0872a2d0-8a44-4bfa-8e3f-b3d3d8168722,DISK], DatanodeInfoWithStorage[127.0.0.1:35443,DS-2b0e3223-4dc8-46a3-90eb-246350b61855,DISK], DatanodeInfoWithStorage[127.0.0.1:39611,DS-84dbb7d7-f17d-42d6-b5fd-803f6caa65b2,DISK], DatanodeInfoWithStorage[127.0.0.1:34518,DS-2f6a0d17-37ff-46be-8e58-c401298dd315,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 5613
