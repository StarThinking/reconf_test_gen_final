reconf_parameter: ipc.client.ping
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1860725225-172.17.0.8-1598153155048:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44897,DS-d24d1623-b21d-4e91-b4fd-a2c54faa1dbf,DISK], DatanodeInfoWithStorage[127.0.0.1:33442,DS-491883a6-17a4-40c0-92b3-7e118f9b458a,DISK], DatanodeInfoWithStorage[127.0.0.1:45553,DS-302176cf-3735-4360-87bf-3ec3233155a6,DISK], DatanodeInfoWithStorage[127.0.0.1:37798,DS-d068e762-2580-41b0-b400-6a05b075d3fc,DISK], DatanodeInfoWithStorage[127.0.0.1:44783,DS-58564fc2-a886-4f1d-9cc1-159d35a5cb14,DISK], DatanodeInfoWithStorage[127.0.0.1:36855,DS-b1142fc4-0d09-4028-82f5-da4bd902b97d,DISK], DatanodeInfoWithStorage[127.0.0.1:43161,DS-679dd995-4c44-46a4-b9ff-738db7389e07,DISK], DatanodeInfoWithStorage[127.0.0.1:34745,DS-4c35844e-dc28-4b97-98c3-0c74babb05f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1860725225-172.17.0.8-1598153155048:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44897,DS-d24d1623-b21d-4e91-b4fd-a2c54faa1dbf,DISK], DatanodeInfoWithStorage[127.0.0.1:33442,DS-491883a6-17a4-40c0-92b3-7e118f9b458a,DISK], DatanodeInfoWithStorage[127.0.0.1:45553,DS-302176cf-3735-4360-87bf-3ec3233155a6,DISK], DatanodeInfoWithStorage[127.0.0.1:37798,DS-d068e762-2580-41b0-b400-6a05b075d3fc,DISK], DatanodeInfoWithStorage[127.0.0.1:44783,DS-58564fc2-a886-4f1d-9cc1-159d35a5cb14,DISK], DatanodeInfoWithStorage[127.0.0.1:36855,DS-b1142fc4-0d09-4028-82f5-da4bd902b97d,DISK], DatanodeInfoWithStorage[127.0.0.1:43161,DS-679dd995-4c44-46a4-b9ff-738db7389e07,DISK], DatanodeInfoWithStorage[127.0.0.1:34745,DS-4c35844e-dc28-4b97-98c3-0c74babb05f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1829357178-172.17.0.8-1598153769273:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35277,DS-ec93b59c-7bdf-4dab-95cf-6b3ac670d39c,DISK], DatanodeInfoWithStorage[127.0.0.1:43665,DS-44d340d7-fb65-4539-b6c9-17c476cad68d,DISK], DatanodeInfoWithStorage[127.0.0.1:38826,DS-82bcc1c0-a852-40ea-bd5e-006b04bf610a,DISK], DatanodeInfoWithStorage[127.0.0.1:40416,DS-943688ac-7ef9-49a4-be53-166550e504ca,DISK], DatanodeInfoWithStorage[127.0.0.1:46337,DS-b11af0d1-9aba-4157-a411-9b16c3a5f0d9,DISK], DatanodeInfoWithStorage[127.0.0.1:38317,DS-0762e60c-2f91-4155-afd7-14c2a23199e5,DISK], DatanodeInfoWithStorage[127.0.0.1:36490,DS-6dd4535a-2ac1-4efb-aa7f-94f3640999bf,DISK], DatanodeInfoWithStorage[127.0.0.1:43010,DS-e79c743b-8178-4d32-b935-816ffe1a2aeb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1829357178-172.17.0.8-1598153769273:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35277,DS-ec93b59c-7bdf-4dab-95cf-6b3ac670d39c,DISK], DatanodeInfoWithStorage[127.0.0.1:43665,DS-44d340d7-fb65-4539-b6c9-17c476cad68d,DISK], DatanodeInfoWithStorage[127.0.0.1:38826,DS-82bcc1c0-a852-40ea-bd5e-006b04bf610a,DISK], DatanodeInfoWithStorage[127.0.0.1:40416,DS-943688ac-7ef9-49a4-be53-166550e504ca,DISK], DatanodeInfoWithStorage[127.0.0.1:46337,DS-b11af0d1-9aba-4157-a411-9b16c3a5f0d9,DISK], DatanodeInfoWithStorage[127.0.0.1:38317,DS-0762e60c-2f91-4155-afd7-14c2a23199e5,DISK], DatanodeInfoWithStorage[127.0.0.1:36490,DS-6dd4535a-2ac1-4efb-aa7f-94f3640999bf,DISK], DatanodeInfoWithStorage[127.0.0.1:43010,DS-e79c743b-8178-4d32-b935-816ffe1a2aeb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.client.ping
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-760415327-172.17.0.8-1598153809088:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36788,DS-20ed5340-0f30-4b70-bfbe-48c02e5cc12f,DISK], DatanodeInfoWithStorage[127.0.0.1:33229,DS-b3cd6292-1817-40af-bf45-d18ab79a39b6,DISK], DatanodeInfoWithStorage[127.0.0.1:35958,DS-41db2991-908a-4f53-87dc-96131c102b4a,DISK], DatanodeInfoWithStorage[127.0.0.1:42031,DS-2bcac476-a76c-40d6-938b-dc4e45a7f2b3,DISK], DatanodeInfoWithStorage[127.0.0.1:44273,DS-50c0bac1-2644-4010-aa4c-67c69f773bcc,DISK], DatanodeInfoWithStorage[127.0.0.1:41767,DS-fe32ab31-ce68-4e70-9901-755265c8ad27,DISK], DatanodeInfoWithStorage[127.0.0.1:39660,DS-b9e45d0a-6a9e-4bd1-975b-5a00b5f32d76,DISK], DatanodeInfoWithStorage[127.0.0.1:34059,DS-ca44b805-d0c9-4683-8784-4ba65cd0a685,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-760415327-172.17.0.8-1598153809088:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36788,DS-20ed5340-0f30-4b70-bfbe-48c02e5cc12f,DISK], DatanodeInfoWithStorage[127.0.0.1:33229,DS-b3cd6292-1817-40af-bf45-d18ab79a39b6,DISK], DatanodeInfoWithStorage[127.0.0.1:35958,DS-41db2991-908a-4f53-87dc-96131c102b4a,DISK], DatanodeInfoWithStorage[127.0.0.1:42031,DS-2bcac476-a76c-40d6-938b-dc4e45a7f2b3,DISK], DatanodeInfoWithStorage[127.0.0.1:44273,DS-50c0bac1-2644-4010-aa4c-67c69f773bcc,DISK], DatanodeInfoWithStorage[127.0.0.1:41767,DS-fe32ab31-ce68-4e70-9901-755265c8ad27,DISK], DatanodeInfoWithStorage[127.0.0.1:39660,DS-b9e45d0a-6a9e-4bd1-975b-5a00b5f32d76,DISK], DatanodeInfoWithStorage[127.0.0.1:34059,DS-ca44b805-d0c9-4683-8784-4ba65cd0a685,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-551303390-172.17.0.8-1598154099828:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46128,DS-69dcad9d-71ee-40a0-a54e-c649f83a7729,DISK], DatanodeInfoWithStorage[127.0.0.1:34064,DS-4b6e169b-6155-4ca3-9b5c-482f841534ff,DISK], DatanodeInfoWithStorage[127.0.0.1:45890,DS-5c1fca1d-f292-4910-89b1-8990babdb864,DISK], DatanodeInfoWithStorage[127.0.0.1:39168,DS-cb2a2182-9c0c-4f69-8300-4972bf2b0887,DISK], DatanodeInfoWithStorage[127.0.0.1:42400,DS-d464909f-9746-4089-997a-a8690babffcd,DISK], DatanodeInfoWithStorage[127.0.0.1:35692,DS-60b53504-510b-4052-bd69-0050be38bf4f,DISK], DatanodeInfoWithStorage[127.0.0.1:45456,DS-1e794a05-d238-4b52-a8d2-ddc9f3655036,DISK], DatanodeInfoWithStorage[127.0.0.1:42918,DS-ee44d6f9-3988-4a98-99d6-19eb6f0ea52a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-551303390-172.17.0.8-1598154099828:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46128,DS-69dcad9d-71ee-40a0-a54e-c649f83a7729,DISK], DatanodeInfoWithStorage[127.0.0.1:34064,DS-4b6e169b-6155-4ca3-9b5c-482f841534ff,DISK], DatanodeInfoWithStorage[127.0.0.1:45890,DS-5c1fca1d-f292-4910-89b1-8990babdb864,DISK], DatanodeInfoWithStorage[127.0.0.1:39168,DS-cb2a2182-9c0c-4f69-8300-4972bf2b0887,DISK], DatanodeInfoWithStorage[127.0.0.1:42400,DS-d464909f-9746-4089-997a-a8690babffcd,DISK], DatanodeInfoWithStorage[127.0.0.1:35692,DS-60b53504-510b-4052-bd69-0050be38bf4f,DISK], DatanodeInfoWithStorage[127.0.0.1:45456,DS-1e794a05-d238-4b52-a8d2-ddc9f3655036,DISK], DatanodeInfoWithStorage[127.0.0.1:42918,DS-ee44d6f9-3988-4a98-99d6-19eb6f0ea52a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-488952251-172.17.0.8-1598154241562:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33196,DS-24cbcc08-1593-4ce1-9184-1442c6ecfadf,DISK], DatanodeInfoWithStorage[127.0.0.1:45100,DS-6a45c747-407a-436f-85ad-6899d9dee9f1,DISK], DatanodeInfoWithStorage[127.0.0.1:37337,DS-d50b8ebc-9044-4ce8-878c-77165043efe3,DISK], DatanodeInfoWithStorage[127.0.0.1:34130,DS-bf69a743-c55e-421f-af7f-2f44610bdb65,DISK], DatanodeInfoWithStorage[127.0.0.1:43940,DS-190fad37-bd8c-4600-9b2f-9656e481c2ee,DISK], DatanodeInfoWithStorage[127.0.0.1:41916,DS-cfe357ce-4c46-4222-a062-4027077f1e65,DISK], DatanodeInfoWithStorage[127.0.0.1:46355,DS-80c0b5c4-d0fe-4257-bc18-bc74b9ced7e4,DISK], DatanodeInfoWithStorage[127.0.0.1:39003,DS-de8b7b93-2e88-4626-9caf-63d324bfa63c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-488952251-172.17.0.8-1598154241562:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33196,DS-24cbcc08-1593-4ce1-9184-1442c6ecfadf,DISK], DatanodeInfoWithStorage[127.0.0.1:45100,DS-6a45c747-407a-436f-85ad-6899d9dee9f1,DISK], DatanodeInfoWithStorage[127.0.0.1:37337,DS-d50b8ebc-9044-4ce8-878c-77165043efe3,DISK], DatanodeInfoWithStorage[127.0.0.1:34130,DS-bf69a743-c55e-421f-af7f-2f44610bdb65,DISK], DatanodeInfoWithStorage[127.0.0.1:43940,DS-190fad37-bd8c-4600-9b2f-9656e481c2ee,DISK], DatanodeInfoWithStorage[127.0.0.1:41916,DS-cfe357ce-4c46-4222-a062-4027077f1e65,DISK], DatanodeInfoWithStorage[127.0.0.1:46355,DS-80c0b5c4-d0fe-4257-bc18-bc74b9ced7e4,DISK], DatanodeInfoWithStorage[127.0.0.1:39003,DS-de8b7b93-2e88-4626-9caf-63d324bfa63c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1980910919-172.17.0.8-1598154354131:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36728,DS-3ed31436-3c3b-4e83-97cd-b3268f3b133e,DISK], DatanodeInfoWithStorage[127.0.0.1:41484,DS-8d34c7bf-d479-409b-93d0-480a3609698b,DISK], DatanodeInfoWithStorage[127.0.0.1:32779,DS-5148f455-8497-4b04-8923-2b1233b78927,DISK], DatanodeInfoWithStorage[127.0.0.1:35669,DS-ccfc14c9-e891-4711-ab39-a4897600b609,DISK], DatanodeInfoWithStorage[127.0.0.1:32968,DS-c0daac03-8166-40b1-88be-ba2b6b8ff092,DISK], DatanodeInfoWithStorage[127.0.0.1:42715,DS-34df1c9b-5cb6-45fa-bc36-d233d8310113,DISK], DatanodeInfoWithStorage[127.0.0.1:45821,DS-36df7cc3-8010-4a1f-afc6-7938f058d600,DISK], DatanodeInfoWithStorage[127.0.0.1:36118,DS-ddd7df41-befc-44be-b91f-9e617750df6f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1980910919-172.17.0.8-1598154354131:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36728,DS-3ed31436-3c3b-4e83-97cd-b3268f3b133e,DISK], DatanodeInfoWithStorage[127.0.0.1:41484,DS-8d34c7bf-d479-409b-93d0-480a3609698b,DISK], DatanodeInfoWithStorage[127.0.0.1:32779,DS-5148f455-8497-4b04-8923-2b1233b78927,DISK], DatanodeInfoWithStorage[127.0.0.1:35669,DS-ccfc14c9-e891-4711-ab39-a4897600b609,DISK], DatanodeInfoWithStorage[127.0.0.1:32968,DS-c0daac03-8166-40b1-88be-ba2b6b8ff092,DISK], DatanodeInfoWithStorage[127.0.0.1:42715,DS-34df1c9b-5cb6-45fa-bc36-d233d8310113,DISK], DatanodeInfoWithStorage[127.0.0.1:45821,DS-36df7cc3-8010-4a1f-afc6-7938f058d600,DISK], DatanodeInfoWithStorage[127.0.0.1:36118,DS-ddd7df41-befc-44be-b91f-9e617750df6f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1150443726-172.17.0.8-1598155111389:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33048,DS-5ff8318f-b98f-4308-aa75-3c9f9c5e4574,DISK], DatanodeInfoWithStorage[127.0.0.1:38105,DS-812e43b6-d489-49f6-83bd-7d1f11138756,DISK], DatanodeInfoWithStorage[127.0.0.1:45168,DS-029fdd58-595a-4e68-8029-8bab6c57e7fc,DISK], DatanodeInfoWithStorage[127.0.0.1:35300,DS-e2569891-498f-4669-84ed-b52ce9724d90,DISK], DatanodeInfoWithStorage[127.0.0.1:45878,DS-1c0263c1-eb9b-42c9-9910-37dffa2751e3,DISK], DatanodeInfoWithStorage[127.0.0.1:41006,DS-d2e96c4c-2141-49ff-8151-91d0052bf51c,DISK], DatanodeInfoWithStorage[127.0.0.1:36876,DS-3037ec9f-f9ff-41e3-a8f5-1235c15f1491,DISK], DatanodeInfoWithStorage[127.0.0.1:35449,DS-ffe15094-db5f-4838-8e40-84c0f3b055f2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1150443726-172.17.0.8-1598155111389:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33048,DS-5ff8318f-b98f-4308-aa75-3c9f9c5e4574,DISK], DatanodeInfoWithStorage[127.0.0.1:38105,DS-812e43b6-d489-49f6-83bd-7d1f11138756,DISK], DatanodeInfoWithStorage[127.0.0.1:45168,DS-029fdd58-595a-4e68-8029-8bab6c57e7fc,DISK], DatanodeInfoWithStorage[127.0.0.1:35300,DS-e2569891-498f-4669-84ed-b52ce9724d90,DISK], DatanodeInfoWithStorage[127.0.0.1:45878,DS-1c0263c1-eb9b-42c9-9910-37dffa2751e3,DISK], DatanodeInfoWithStorage[127.0.0.1:41006,DS-d2e96c4c-2141-49ff-8151-91d0052bf51c,DISK], DatanodeInfoWithStorage[127.0.0.1:36876,DS-3037ec9f-f9ff-41e3-a8f5-1235c15f1491,DISK], DatanodeInfoWithStorage[127.0.0.1:35449,DS-ffe15094-db5f-4838-8e40-84c0f3b055f2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1568980604-172.17.0.8-1598155434786:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34675,DS-35e5bd30-50b0-4a75-8a1b-221fc09d0985,DISK], DatanodeInfoWithStorage[127.0.0.1:43691,DS-ee4d8ba9-ce63-4499-b71c-ca8c40f63f35,DISK], DatanodeInfoWithStorage[127.0.0.1:36195,DS-bfda18d6-8915-46a3-adaa-05afa5073743,DISK], DatanodeInfoWithStorage[127.0.0.1:38719,DS-c9dd7a11-fb3d-476e-9953-9cab963be9d3,DISK], DatanodeInfoWithStorage[127.0.0.1:42415,DS-d70730e2-3549-448f-b380-c3fab3b3cffb,DISK], DatanodeInfoWithStorage[127.0.0.1:45734,DS-6e5fd9ad-bfab-460c-bded-44bdc098af85,DISK], DatanodeInfoWithStorage[127.0.0.1:38790,DS-289fe8e1-2815-412d-a8ce-0904fa390f39,DISK], DatanodeInfoWithStorage[127.0.0.1:40256,DS-5d60a2f8-c722-4740-9e51-31ad7b6c10d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1568980604-172.17.0.8-1598155434786:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34675,DS-35e5bd30-50b0-4a75-8a1b-221fc09d0985,DISK], DatanodeInfoWithStorage[127.0.0.1:43691,DS-ee4d8ba9-ce63-4499-b71c-ca8c40f63f35,DISK], DatanodeInfoWithStorage[127.0.0.1:36195,DS-bfda18d6-8915-46a3-adaa-05afa5073743,DISK], DatanodeInfoWithStorage[127.0.0.1:38719,DS-c9dd7a11-fb3d-476e-9953-9cab963be9d3,DISK], DatanodeInfoWithStorage[127.0.0.1:42415,DS-d70730e2-3549-448f-b380-c3fab3b3cffb,DISK], DatanodeInfoWithStorage[127.0.0.1:45734,DS-6e5fd9ad-bfab-460c-bded-44bdc098af85,DISK], DatanodeInfoWithStorage[127.0.0.1:38790,DS-289fe8e1-2815-412d-a8ce-0904fa390f39,DISK], DatanodeInfoWithStorage[127.0.0.1:40256,DS-5d60a2f8-c722-4740-9e51-31ad7b6c10d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-742824852-172.17.0.8-1598155615592:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36470,DS-83b01279-d0de-4724-b527-36d759ade59c,DISK], DatanodeInfoWithStorage[127.0.0.1:40116,DS-3b66709f-7c39-4321-b09f-7e8ffd96baec,DISK], DatanodeInfoWithStorage[127.0.0.1:45262,DS-17b6f485-933d-4457-95bf-4fa636d00a98,DISK], DatanodeInfoWithStorage[127.0.0.1:37989,DS-71a5f328-9c1e-4fe5-ba78-61210e24914c,DISK], DatanodeInfoWithStorage[127.0.0.1:42990,DS-58554449-6361-4221-a877-6231bcf1659c,DISK], DatanodeInfoWithStorage[127.0.0.1:41208,DS-c5449e96-3e81-4ad5-acf8-b7e9f57d003e,DISK], DatanodeInfoWithStorage[127.0.0.1:44200,DS-9303c85b-7d96-4863-a45c-2256682bcbfa,DISK], DatanodeInfoWithStorage[127.0.0.1:33113,DS-9b582b6e-87f1-4197-a5d8-87076e65c301,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-742824852-172.17.0.8-1598155615592:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36470,DS-83b01279-d0de-4724-b527-36d759ade59c,DISK], DatanodeInfoWithStorage[127.0.0.1:40116,DS-3b66709f-7c39-4321-b09f-7e8ffd96baec,DISK], DatanodeInfoWithStorage[127.0.0.1:45262,DS-17b6f485-933d-4457-95bf-4fa636d00a98,DISK], DatanodeInfoWithStorage[127.0.0.1:37989,DS-71a5f328-9c1e-4fe5-ba78-61210e24914c,DISK], DatanodeInfoWithStorage[127.0.0.1:42990,DS-58554449-6361-4221-a877-6231bcf1659c,DISK], DatanodeInfoWithStorage[127.0.0.1:41208,DS-c5449e96-3e81-4ad5-acf8-b7e9f57d003e,DISK], DatanodeInfoWithStorage[127.0.0.1:44200,DS-9303c85b-7d96-4863-a45c-2256682bcbfa,DISK], DatanodeInfoWithStorage[127.0.0.1:33113,DS-9b582b6e-87f1-4197-a5d8-87076e65c301,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-702363288-172.17.0.8-1598156386091:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32851,DS-2e127f8b-c93c-479f-b482-50c2faee4535,DISK], DatanodeInfoWithStorage[127.0.0.1:35212,DS-8e7a9039-11d4-4725-86f5-951042f87901,DISK], DatanodeInfoWithStorage[127.0.0.1:38607,DS-fef269cb-be25-4674-9837-7f045dfe1f2e,DISK], DatanodeInfoWithStorage[127.0.0.1:33275,DS-c7272fae-47e2-40b5-a055-fab3492d07e4,DISK], DatanodeInfoWithStorage[127.0.0.1:37694,DS-32bed1e1-ac7f-44ff-a977-2c62df8fda52,DISK], DatanodeInfoWithStorage[127.0.0.1:40293,DS-fa83f7e8-f9f8-408c-bbe5-3de94cee8ad1,DISK], DatanodeInfoWithStorage[127.0.0.1:33076,DS-e22b46f1-8fbb-41bd-8972-c1e42b1b18b8,DISK], DatanodeInfoWithStorage[127.0.0.1:46283,DS-9e2aeacd-3d6c-4429-8828-2a0c9025df31,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-702363288-172.17.0.8-1598156386091:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32851,DS-2e127f8b-c93c-479f-b482-50c2faee4535,DISK], DatanodeInfoWithStorage[127.0.0.1:35212,DS-8e7a9039-11d4-4725-86f5-951042f87901,DISK], DatanodeInfoWithStorage[127.0.0.1:38607,DS-fef269cb-be25-4674-9837-7f045dfe1f2e,DISK], DatanodeInfoWithStorage[127.0.0.1:33275,DS-c7272fae-47e2-40b5-a055-fab3492d07e4,DISK], DatanodeInfoWithStorage[127.0.0.1:37694,DS-32bed1e1-ac7f-44ff-a977-2c62df8fda52,DISK], DatanodeInfoWithStorage[127.0.0.1:40293,DS-fa83f7e8-f9f8-408c-bbe5-3de94cee8ad1,DISK], DatanodeInfoWithStorage[127.0.0.1:33076,DS-e22b46f1-8fbb-41bd-8972-c1e42b1b18b8,DISK], DatanodeInfoWithStorage[127.0.0.1:46283,DS-9e2aeacd-3d6c-4429-8828-2a0c9025df31,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-694473055-172.17.0.8-1598156530239:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41127,DS-05ebd028-afc1-48aa-a96a-3267136b5186,DISK], DatanodeInfoWithStorage[127.0.0.1:39725,DS-8a015ebe-57fd-446e-9b39-7cfd2a327398,DISK], DatanodeInfoWithStorage[127.0.0.1:42429,DS-398b2b00-65b1-4f2a-a9c1-14753fa76c8c,DISK], DatanodeInfoWithStorage[127.0.0.1:38737,DS-f4ca7edf-237f-44df-bacc-a94b7a2a66f0,DISK], DatanodeInfoWithStorage[127.0.0.1:42276,DS-ffa5096d-75d2-4432-b06f-9de1ee701e02,DISK], DatanodeInfoWithStorage[127.0.0.1:42963,DS-a63b9c05-c8e7-4384-8060-ebf2e3394c1b,DISK], DatanodeInfoWithStorage[127.0.0.1:44083,DS-9418c9b0-9c55-4683-88c2-de706a6b1bdd,DISK], DatanodeInfoWithStorage[127.0.0.1:38977,DS-462bf2bd-a298-4b4d-8281-baacd3053a88,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-694473055-172.17.0.8-1598156530239:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41127,DS-05ebd028-afc1-48aa-a96a-3267136b5186,DISK], DatanodeInfoWithStorage[127.0.0.1:39725,DS-8a015ebe-57fd-446e-9b39-7cfd2a327398,DISK], DatanodeInfoWithStorage[127.0.0.1:42429,DS-398b2b00-65b1-4f2a-a9c1-14753fa76c8c,DISK], DatanodeInfoWithStorage[127.0.0.1:38737,DS-f4ca7edf-237f-44df-bacc-a94b7a2a66f0,DISK], DatanodeInfoWithStorage[127.0.0.1:42276,DS-ffa5096d-75d2-4432-b06f-9de1ee701e02,DISK], DatanodeInfoWithStorage[127.0.0.1:42963,DS-a63b9c05-c8e7-4384-8060-ebf2e3394c1b,DISK], DatanodeInfoWithStorage[127.0.0.1:44083,DS-9418c9b0-9c55-4683-88c2-de706a6b1bdd,DISK], DatanodeInfoWithStorage[127.0.0.1:38977,DS-462bf2bd-a298-4b4d-8281-baacd3053a88,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1690963519-172.17.0.8-1598156604962:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32851,DS-70054083-9bed-4a39-abfe-ea3694577a46,DISK], DatanodeInfoWithStorage[127.0.0.1:34334,DS-739bebe2-82ba-4a7a-8967-f2921fcf5770,DISK], DatanodeInfoWithStorage[127.0.0.1:41034,DS-8e7c5d44-ef49-4532-adbd-121e0e5db720,DISK], DatanodeInfoWithStorage[127.0.0.1:34516,DS-d8692bcd-3153-4b6a-ab6a-7ac4d1451e7a,DISK], DatanodeInfoWithStorage[127.0.0.1:35464,DS-e3d79042-5f17-4f08-b5b8-3e7dc7d25f55,DISK], DatanodeInfoWithStorage[127.0.0.1:44838,DS-92f5d3cd-e4e0-41e0-a283-a968f5190636,DISK], DatanodeInfoWithStorage[127.0.0.1:44355,DS-7e80be2a-bf1a-4b43-98b0-e9109363173f,DISK], DatanodeInfoWithStorage[127.0.0.1:41942,DS-2a8a9351-d185-4752-af8f-95c11b0416fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1690963519-172.17.0.8-1598156604962:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32851,DS-70054083-9bed-4a39-abfe-ea3694577a46,DISK], DatanodeInfoWithStorage[127.0.0.1:34334,DS-739bebe2-82ba-4a7a-8967-f2921fcf5770,DISK], DatanodeInfoWithStorage[127.0.0.1:41034,DS-8e7c5d44-ef49-4532-adbd-121e0e5db720,DISK], DatanodeInfoWithStorage[127.0.0.1:34516,DS-d8692bcd-3153-4b6a-ab6a-7ac4d1451e7a,DISK], DatanodeInfoWithStorage[127.0.0.1:35464,DS-e3d79042-5f17-4f08-b5b8-3e7dc7d25f55,DISK], DatanodeInfoWithStorage[127.0.0.1:44838,DS-92f5d3cd-e4e0-41e0-a283-a968f5190636,DISK], DatanodeInfoWithStorage[127.0.0.1:44355,DS-7e80be2a-bf1a-4b43-98b0-e9109363173f,DISK], DatanodeInfoWithStorage[127.0.0.1:41942,DS-2a8a9351-d185-4752-af8f-95c11b0416fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-611470711-172.17.0.8-1598156851860:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41677,DS-dc429d43-3af0-49b5-9146-1ae877e61286,DISK], DatanodeInfoWithStorage[127.0.0.1:42429,DS-ef76f5d4-10b4-4d76-8044-3618d4d6dc60,DISK], DatanodeInfoWithStorage[127.0.0.1:39043,DS-710b3bf8-896b-450b-b48a-260fa1645500,DISK], DatanodeInfoWithStorage[127.0.0.1:35046,DS-dd4ffa5f-387e-468d-a045-2de10a5257a7,DISK], DatanodeInfoWithStorage[127.0.0.1:41874,DS-749282f1-76bb-4034-8df0-1c6848d06af4,DISK], DatanodeInfoWithStorage[127.0.0.1:36163,DS-d1ee3906-5c62-4562-a962-520fa906acfc,DISK], DatanodeInfoWithStorage[127.0.0.1:46207,DS-60182a14-51ec-459d-bc69-d200e8758088,DISK], DatanodeInfoWithStorage[127.0.0.1:42545,DS-dd6c546f-01c3-47ff-a772-47a14cfb2fd8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-611470711-172.17.0.8-1598156851860:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41677,DS-dc429d43-3af0-49b5-9146-1ae877e61286,DISK], DatanodeInfoWithStorage[127.0.0.1:42429,DS-ef76f5d4-10b4-4d76-8044-3618d4d6dc60,DISK], DatanodeInfoWithStorage[127.0.0.1:39043,DS-710b3bf8-896b-450b-b48a-260fa1645500,DISK], DatanodeInfoWithStorage[127.0.0.1:35046,DS-dd4ffa5f-387e-468d-a045-2de10a5257a7,DISK], DatanodeInfoWithStorage[127.0.0.1:41874,DS-749282f1-76bb-4034-8df0-1c6848d06af4,DISK], DatanodeInfoWithStorage[127.0.0.1:36163,DS-d1ee3906-5c62-4562-a962-520fa906acfc,DISK], DatanodeInfoWithStorage[127.0.0.1:46207,DS-60182a14-51ec-459d-bc69-d200e8758088,DISK], DatanodeInfoWithStorage[127.0.0.1:42545,DS-dd6c546f-01c3-47ff-a772-47a14cfb2fd8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1244868924-172.17.0.8-1598157029678:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39457,DS-3f1a0c3e-9d2e-4b56-be66-b478c5c5a56a,DISK], DatanodeInfoWithStorage[127.0.0.1:38533,DS-e722b2cc-3a37-47c6-bfa0-c17a2ee09b16,DISK], DatanodeInfoWithStorage[127.0.0.1:34693,DS-d54e8a20-ea0f-42a4-a1a8-4b9fec80a121,DISK], DatanodeInfoWithStorage[127.0.0.1:36863,DS-c4ae7a02-ecb7-4a86-8adb-9f4b2054adc0,DISK], DatanodeInfoWithStorage[127.0.0.1:36370,DS-58523239-d5ea-42a0-93c8-67b4209bc985,DISK], DatanodeInfoWithStorage[127.0.0.1:39501,DS-e48830f6-31ca-41a7-833a-ed46d9f30294,DISK], DatanodeInfoWithStorage[127.0.0.1:33704,DS-3de932aa-11b6-4c17-81b6-efa14d557ef0,DISK], DatanodeInfoWithStorage[127.0.0.1:35276,DS-3e66eaed-1a6e-4f49-9c43-97ee1862a017,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1244868924-172.17.0.8-1598157029678:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39457,DS-3f1a0c3e-9d2e-4b56-be66-b478c5c5a56a,DISK], DatanodeInfoWithStorage[127.0.0.1:38533,DS-e722b2cc-3a37-47c6-bfa0-c17a2ee09b16,DISK], DatanodeInfoWithStorage[127.0.0.1:34693,DS-d54e8a20-ea0f-42a4-a1a8-4b9fec80a121,DISK], DatanodeInfoWithStorage[127.0.0.1:36863,DS-c4ae7a02-ecb7-4a86-8adb-9f4b2054adc0,DISK], DatanodeInfoWithStorage[127.0.0.1:36370,DS-58523239-d5ea-42a0-93c8-67b4209bc985,DISK], DatanodeInfoWithStorage[127.0.0.1:39501,DS-e48830f6-31ca-41a7-833a-ed46d9f30294,DISK], DatanodeInfoWithStorage[127.0.0.1:33704,DS-3de932aa-11b6-4c17-81b6-efa14d557ef0,DISK], DatanodeInfoWithStorage[127.0.0.1:35276,DS-3e66eaed-1a6e-4f49-9c43-97ee1862a017,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2138139343-172.17.0.8-1598157934101:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39943,DS-9642ab5a-36ab-4898-bbc2-07cf0c26cc73,DISK], DatanodeInfoWithStorage[127.0.0.1:43471,DS-49a710ca-730a-4261-bb7c-45056e3d5b4b,DISK], DatanodeInfoWithStorage[127.0.0.1:41951,DS-1ef07586-ceea-4270-a5f8-5adc363984e0,DISK], DatanodeInfoWithStorage[127.0.0.1:40655,DS-12d88f91-e8b2-41e2-b0d8-3e4fc6c5b516,DISK], DatanodeInfoWithStorage[127.0.0.1:33781,DS-3eabdf22-3018-40d7-bc6d-1128ed4e9cef,DISK], DatanodeInfoWithStorage[127.0.0.1:42361,DS-f4b83a53-d926-45f3-bc08-aadff4634307,DISK], DatanodeInfoWithStorage[127.0.0.1:45193,DS-e4382516-e863-427b-9b12-eb93e5d18d57,DISK], DatanodeInfoWithStorage[127.0.0.1:46011,DS-32f38c8e-ce5b-47b6-a6bf-50f8cc6aaa43,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2138139343-172.17.0.8-1598157934101:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39943,DS-9642ab5a-36ab-4898-bbc2-07cf0c26cc73,DISK], DatanodeInfoWithStorage[127.0.0.1:43471,DS-49a710ca-730a-4261-bb7c-45056e3d5b4b,DISK], DatanodeInfoWithStorage[127.0.0.1:41951,DS-1ef07586-ceea-4270-a5f8-5adc363984e0,DISK], DatanodeInfoWithStorage[127.0.0.1:40655,DS-12d88f91-e8b2-41e2-b0d8-3e4fc6c5b516,DISK], DatanodeInfoWithStorage[127.0.0.1:33781,DS-3eabdf22-3018-40d7-bc6d-1128ed4e9cef,DISK], DatanodeInfoWithStorage[127.0.0.1:42361,DS-f4b83a53-d926-45f3-bc08-aadff4634307,DISK], DatanodeInfoWithStorage[127.0.0.1:45193,DS-e4382516-e863-427b-9b12-eb93e5d18d57,DISK], DatanodeInfoWithStorage[127.0.0.1:46011,DS-32f38c8e-ce5b-47b6-a6bf-50f8cc6aaa43,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1846356656-172.17.0.8-1598158360729:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38468,DS-4bc9b331-ade7-4aec-8924-c17d12a302c9,DISK], DatanodeInfoWithStorage[127.0.0.1:38109,DS-3b5f06c1-1239-45ca-9c06-505949aaaa23,DISK], DatanodeInfoWithStorage[127.0.0.1:39700,DS-b7b6451e-c1bb-4057-abb3-4fdfbb9b41b2,DISK], DatanodeInfoWithStorage[127.0.0.1:41917,DS-4be33122-49a1-4240-80a7-92601987e4fc,DISK], DatanodeInfoWithStorage[127.0.0.1:46402,DS-76268e65-2fb7-4ed1-a511-95f7c0c22f8d,DISK], DatanodeInfoWithStorage[127.0.0.1:35996,DS-f5c99426-159f-4a42-a211-b1ba5d1d2b43,DISK], DatanodeInfoWithStorage[127.0.0.1:32904,DS-1821090c-6bec-4b09-9214-d4dd85f87445,DISK], DatanodeInfoWithStorage[127.0.0.1:36880,DS-b319ff72-758b-4bcd-8dde-c67684f3eec1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1846356656-172.17.0.8-1598158360729:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38468,DS-4bc9b331-ade7-4aec-8924-c17d12a302c9,DISK], DatanodeInfoWithStorage[127.0.0.1:38109,DS-3b5f06c1-1239-45ca-9c06-505949aaaa23,DISK], DatanodeInfoWithStorage[127.0.0.1:39700,DS-b7b6451e-c1bb-4057-abb3-4fdfbb9b41b2,DISK], DatanodeInfoWithStorage[127.0.0.1:41917,DS-4be33122-49a1-4240-80a7-92601987e4fc,DISK], DatanodeInfoWithStorage[127.0.0.1:46402,DS-76268e65-2fb7-4ed1-a511-95f7c0c22f8d,DISK], DatanodeInfoWithStorage[127.0.0.1:35996,DS-f5c99426-159f-4a42-a211-b1ba5d1d2b43,DISK], DatanodeInfoWithStorage[127.0.0.1:32904,DS-1821090c-6bec-4b09-9214-d4dd85f87445,DISK], DatanodeInfoWithStorage[127.0.0.1:36880,DS-b319ff72-758b-4bcd-8dde-c67684f3eec1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5278
