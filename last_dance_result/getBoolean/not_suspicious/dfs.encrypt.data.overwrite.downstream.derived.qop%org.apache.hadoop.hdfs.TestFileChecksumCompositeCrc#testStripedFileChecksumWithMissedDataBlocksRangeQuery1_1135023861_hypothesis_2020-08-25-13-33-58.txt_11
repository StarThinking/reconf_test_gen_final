reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-499638923-172.17.0.3-1598362457641:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46227,DS-63184189-7646-44f6-afad-60d7abd20032,DISK], DatanodeInfoWithStorage[127.0.0.1:32860,DS-a35d99a9-5dc2-497f-b26d-266d200cf98d,DISK], DatanodeInfoWithStorage[127.0.0.1:40736,DS-4ee45a29-33af-4f3e-b0b0-6405f7157f85,DISK], DatanodeInfoWithStorage[127.0.0.1:44599,DS-0af39c80-82dc-4698-ba80-f650b1d95ade,DISK], DatanodeInfoWithStorage[127.0.0.1:45221,DS-12197c76-3233-4a05-9187-0311defa4fdb,DISK], DatanodeInfoWithStorage[127.0.0.1:38707,DS-364c5828-f831-49cd-ae70-21cd2cde9d2b,DISK], DatanodeInfoWithStorage[127.0.0.1:41585,DS-b39c5d57-2197-49cd-9701-2181d77c9246,DISK], DatanodeInfoWithStorage[127.0.0.1:41169,DS-e0dae553-842c-475a-b0ee-398f426cdc05,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-499638923-172.17.0.3-1598362457641:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46227,DS-63184189-7646-44f6-afad-60d7abd20032,DISK], DatanodeInfoWithStorage[127.0.0.1:32860,DS-a35d99a9-5dc2-497f-b26d-266d200cf98d,DISK], DatanodeInfoWithStorage[127.0.0.1:40736,DS-4ee45a29-33af-4f3e-b0b0-6405f7157f85,DISK], DatanodeInfoWithStorage[127.0.0.1:44599,DS-0af39c80-82dc-4698-ba80-f650b1d95ade,DISK], DatanodeInfoWithStorage[127.0.0.1:45221,DS-12197c76-3233-4a05-9187-0311defa4fdb,DISK], DatanodeInfoWithStorage[127.0.0.1:38707,DS-364c5828-f831-49cd-ae70-21cd2cde9d2b,DISK], DatanodeInfoWithStorage[127.0.0.1:41585,DS-b39c5d57-2197-49cd-9701-2181d77c9246,DISK], DatanodeInfoWithStorage[127.0.0.1:41169,DS-e0dae553-842c-475a-b0ee-398f426cdc05,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1988727213-172.17.0.3-1598363386984:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38186,DS-4dd32aa1-210c-4f24-b3fe-9ccfb95258b2,DISK], DatanodeInfoWithStorage[127.0.0.1:42064,DS-b3fd31ba-3199-4f87-998e-82311de19956,DISK], DatanodeInfoWithStorage[127.0.0.1:41998,DS-fd944779-7a01-42e3-b109-8f439831a340,DISK], DatanodeInfoWithStorage[127.0.0.1:36017,DS-5b8353d3-d76c-4d1a-a1bc-27149fb8d1e5,DISK], DatanodeInfoWithStorage[127.0.0.1:41973,DS-13fd65a9-d823-4bf4-a1d2-d4bbc20003e5,DISK], DatanodeInfoWithStorage[127.0.0.1:40646,DS-efb43da6-d764-451f-b944-489d0f58f12f,DISK], DatanodeInfoWithStorage[127.0.0.1:41164,DS-46084bac-03b0-4d8c-acf3-a6fb23469ef6,DISK], DatanodeInfoWithStorage[127.0.0.1:34301,DS-a3436c01-83b1-4ae8-8f07-91e6fa01adf7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1988727213-172.17.0.3-1598363386984:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38186,DS-4dd32aa1-210c-4f24-b3fe-9ccfb95258b2,DISK], DatanodeInfoWithStorage[127.0.0.1:42064,DS-b3fd31ba-3199-4f87-998e-82311de19956,DISK], DatanodeInfoWithStorage[127.0.0.1:41998,DS-fd944779-7a01-42e3-b109-8f439831a340,DISK], DatanodeInfoWithStorage[127.0.0.1:36017,DS-5b8353d3-d76c-4d1a-a1bc-27149fb8d1e5,DISK], DatanodeInfoWithStorage[127.0.0.1:41973,DS-13fd65a9-d823-4bf4-a1d2-d4bbc20003e5,DISK], DatanodeInfoWithStorage[127.0.0.1:40646,DS-efb43da6-d764-451f-b944-489d0f58f12f,DISK], DatanodeInfoWithStorage[127.0.0.1:41164,DS-46084bac-03b0-4d8c-acf3-a6fb23469ef6,DISK], DatanodeInfoWithStorage[127.0.0.1:34301,DS-a3436c01-83b1-4ae8-8f07-91e6fa01adf7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1418447949-172.17.0.3-1598364114328:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33401,DS-0d177f9b-9a87-43fa-87ca-b0fd8475197b,DISK], DatanodeInfoWithStorage[127.0.0.1:37368,DS-2f7be2e5-db00-4c05-b748-8fd16a3aad81,DISK], DatanodeInfoWithStorage[127.0.0.1:44396,DS-c25f6d24-edc8-49dc-ac9c-a603c9dbce35,DISK], DatanodeInfoWithStorage[127.0.0.1:38356,DS-7c87976f-f928-4d5e-a733-6dc470d9295f,DISK], DatanodeInfoWithStorage[127.0.0.1:44256,DS-38c65956-b00a-4600-a959-1fa6f4b1d119,DISK], DatanodeInfoWithStorage[127.0.0.1:34448,DS-98cc4bcc-5ad8-4ae4-8d69-a5540e8dfbb5,DISK], DatanodeInfoWithStorage[127.0.0.1:39398,DS-0329aaee-0081-4fbb-aecb-d3831a8752c7,DISK], DatanodeInfoWithStorage[127.0.0.1:33157,DS-0faa2f1a-5f3c-4da2-85cb-6b988b3e6999,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1418447949-172.17.0.3-1598364114328:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33401,DS-0d177f9b-9a87-43fa-87ca-b0fd8475197b,DISK], DatanodeInfoWithStorage[127.0.0.1:37368,DS-2f7be2e5-db00-4c05-b748-8fd16a3aad81,DISK], DatanodeInfoWithStorage[127.0.0.1:44396,DS-c25f6d24-edc8-49dc-ac9c-a603c9dbce35,DISK], DatanodeInfoWithStorage[127.0.0.1:38356,DS-7c87976f-f928-4d5e-a733-6dc470d9295f,DISK], DatanodeInfoWithStorage[127.0.0.1:44256,DS-38c65956-b00a-4600-a959-1fa6f4b1d119,DISK], DatanodeInfoWithStorage[127.0.0.1:34448,DS-98cc4bcc-5ad8-4ae4-8d69-a5540e8dfbb5,DISK], DatanodeInfoWithStorage[127.0.0.1:39398,DS-0329aaee-0081-4fbb-aecb-d3831a8752c7,DISK], DatanodeInfoWithStorage[127.0.0.1:33157,DS-0faa2f1a-5f3c-4da2-85cb-6b988b3e6999,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-831236445-172.17.0.3-1598364660225:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34327,DS-c14d2db8-f4b7-4189-b696-4d1d6d8cd00e,DISK], DatanodeInfoWithStorage[127.0.0.1:42489,DS-c69d49e1-bfa3-4c55-b457-9e15e20980f6,DISK], DatanodeInfoWithStorage[127.0.0.1:42442,DS-fe0dc85e-6d24-466d-aa48-d61b6995871c,DISK], DatanodeInfoWithStorage[127.0.0.1:46878,DS-3bdbdc57-7b8d-4d4e-b1a9-63f2d595c4bf,DISK], DatanodeInfoWithStorage[127.0.0.1:41334,DS-e3c2d1da-7461-4bf4-abf6-9fd68b136370,DISK], DatanodeInfoWithStorage[127.0.0.1:43428,DS-9cbc4dca-1299-46e0-823a-91a617231a85,DISK], DatanodeInfoWithStorage[127.0.0.1:44556,DS-8661e103-d9cd-4ed4-a308-a170ed267085,DISK], DatanodeInfoWithStorage[127.0.0.1:38768,DS-b62caf67-0c16-4607-b138-93dd5df68fbd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-831236445-172.17.0.3-1598364660225:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34327,DS-c14d2db8-f4b7-4189-b696-4d1d6d8cd00e,DISK], DatanodeInfoWithStorage[127.0.0.1:42489,DS-c69d49e1-bfa3-4c55-b457-9e15e20980f6,DISK], DatanodeInfoWithStorage[127.0.0.1:42442,DS-fe0dc85e-6d24-466d-aa48-d61b6995871c,DISK], DatanodeInfoWithStorage[127.0.0.1:46878,DS-3bdbdc57-7b8d-4d4e-b1a9-63f2d595c4bf,DISK], DatanodeInfoWithStorage[127.0.0.1:41334,DS-e3c2d1da-7461-4bf4-abf6-9fd68b136370,DISK], DatanodeInfoWithStorage[127.0.0.1:43428,DS-9cbc4dca-1299-46e0-823a-91a617231a85,DISK], DatanodeInfoWithStorage[127.0.0.1:44556,DS-8661e103-d9cd-4ed4-a308-a170ed267085,DISK], DatanodeInfoWithStorage[127.0.0.1:38768,DS-b62caf67-0c16-4607-b138-93dd5df68fbd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-88230100-172.17.0.3-1598364774974:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43978,DS-a76230d2-cef1-4586-a873-05f57df06281,DISK], DatanodeInfoWithStorage[127.0.0.1:42864,DS-fa67cf20-cb83-4735-a7a0-70bc8568ccfd,DISK], DatanodeInfoWithStorage[127.0.0.1:36821,DS-805cd365-3109-4672-b6ad-2526550a2a54,DISK], DatanodeInfoWithStorage[127.0.0.1:41016,DS-4437a8fc-c783-4f9e-aec2-0fa8406f1c0d,DISK], DatanodeInfoWithStorage[127.0.0.1:38272,DS-7b3468fc-e618-4f56-9368-9cc130cf8ce6,DISK], DatanodeInfoWithStorage[127.0.0.1:34727,DS-13863afe-f635-4ac8-8fca-c5ee478cbd83,DISK], DatanodeInfoWithStorage[127.0.0.1:34017,DS-3257650b-ecc9-42c4-846c-7f3ea9449938,DISK], DatanodeInfoWithStorage[127.0.0.1:33544,DS-574fcc68-6a1b-4cb4-8eb2-6b6d4101ccb1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-88230100-172.17.0.3-1598364774974:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43978,DS-a76230d2-cef1-4586-a873-05f57df06281,DISK], DatanodeInfoWithStorage[127.0.0.1:42864,DS-fa67cf20-cb83-4735-a7a0-70bc8568ccfd,DISK], DatanodeInfoWithStorage[127.0.0.1:36821,DS-805cd365-3109-4672-b6ad-2526550a2a54,DISK], DatanodeInfoWithStorage[127.0.0.1:41016,DS-4437a8fc-c783-4f9e-aec2-0fa8406f1c0d,DISK], DatanodeInfoWithStorage[127.0.0.1:38272,DS-7b3468fc-e618-4f56-9368-9cc130cf8ce6,DISK], DatanodeInfoWithStorage[127.0.0.1:34727,DS-13863afe-f635-4ac8-8fca-c5ee478cbd83,DISK], DatanodeInfoWithStorage[127.0.0.1:34017,DS-3257650b-ecc9-42c4-846c-7f3ea9449938,DISK], DatanodeInfoWithStorage[127.0.0.1:33544,DS-574fcc68-6a1b-4cb4-8eb2-6b6d4101ccb1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1161048147-172.17.0.3-1598364938013:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35066,DS-b0ab2c4f-ea1f-4a73-a00b-547db0cfbd20,DISK], DatanodeInfoWithStorage[127.0.0.1:34811,DS-a40a84da-0683-480b-9a03-27f3fcf5d235,DISK], DatanodeInfoWithStorage[127.0.0.1:46771,DS-108d7d9a-71c8-40db-832d-2c0c97e5ad27,DISK], DatanodeInfoWithStorage[127.0.0.1:40991,DS-9f353e2c-741e-4e3d-b020-a682ff4a79f5,DISK], DatanodeInfoWithStorage[127.0.0.1:36121,DS-c7b99a58-cf1c-4cc6-8c66-b115bceda836,DISK], DatanodeInfoWithStorage[127.0.0.1:35548,DS-0fe4f856-85a1-4d0f-9c1b-e834232e4b60,DISK], DatanodeInfoWithStorage[127.0.0.1:42552,DS-8cb6462f-5000-4a05-a1eb-c182906abdcd,DISK], DatanodeInfoWithStorage[127.0.0.1:39746,DS-f1e911b9-bbf3-42b2-8806-9e3c882aa993,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1161048147-172.17.0.3-1598364938013:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35066,DS-b0ab2c4f-ea1f-4a73-a00b-547db0cfbd20,DISK], DatanodeInfoWithStorage[127.0.0.1:34811,DS-a40a84da-0683-480b-9a03-27f3fcf5d235,DISK], DatanodeInfoWithStorage[127.0.0.1:46771,DS-108d7d9a-71c8-40db-832d-2c0c97e5ad27,DISK], DatanodeInfoWithStorage[127.0.0.1:40991,DS-9f353e2c-741e-4e3d-b020-a682ff4a79f5,DISK], DatanodeInfoWithStorage[127.0.0.1:36121,DS-c7b99a58-cf1c-4cc6-8c66-b115bceda836,DISK], DatanodeInfoWithStorage[127.0.0.1:35548,DS-0fe4f856-85a1-4d0f-9c1b-e834232e4b60,DISK], DatanodeInfoWithStorage[127.0.0.1:42552,DS-8cb6462f-5000-4a05-a1eb-c182906abdcd,DISK], DatanodeInfoWithStorage[127.0.0.1:39746,DS-f1e911b9-bbf3-42b2-8806-9e3c882aa993,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-633254116-172.17.0.3-1598365146449:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34563,DS-aca66f73-9dd3-4698-9531-eb35f4cbc96d,DISK], DatanodeInfoWithStorage[127.0.0.1:34618,DS-f5c90809-1aa9-4ae2-a3dd-a9c14ac1bc6a,DISK], DatanodeInfoWithStorage[127.0.0.1:38455,DS-1dc6a969-9cc5-4a7a-a800-fa473c0b6838,DISK], DatanodeInfoWithStorage[127.0.0.1:39589,DS-12e50fa0-de97-45b7-b48d-8e98a213d629,DISK], DatanodeInfoWithStorage[127.0.0.1:40411,DS-ffc7a4eb-5959-4ead-ac40-6e316d473e4e,DISK], DatanodeInfoWithStorage[127.0.0.1:37661,DS-14c3fdeb-7cee-4fa8-9b6a-4302c2d9efa2,DISK], DatanodeInfoWithStorage[127.0.0.1:38395,DS-1ed22606-d66d-4716-9d67-25e07cae20ee,DISK], DatanodeInfoWithStorage[127.0.0.1:36749,DS-72e23442-43db-4172-a8d0-e531671363b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-633254116-172.17.0.3-1598365146449:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34563,DS-aca66f73-9dd3-4698-9531-eb35f4cbc96d,DISK], DatanodeInfoWithStorage[127.0.0.1:34618,DS-f5c90809-1aa9-4ae2-a3dd-a9c14ac1bc6a,DISK], DatanodeInfoWithStorage[127.0.0.1:38455,DS-1dc6a969-9cc5-4a7a-a800-fa473c0b6838,DISK], DatanodeInfoWithStorage[127.0.0.1:39589,DS-12e50fa0-de97-45b7-b48d-8e98a213d629,DISK], DatanodeInfoWithStorage[127.0.0.1:40411,DS-ffc7a4eb-5959-4ead-ac40-6e316d473e4e,DISK], DatanodeInfoWithStorage[127.0.0.1:37661,DS-14c3fdeb-7cee-4fa8-9b6a-4302c2d9efa2,DISK], DatanodeInfoWithStorage[127.0.0.1:38395,DS-1ed22606-d66d-4716-9d67-25e07cae20ee,DISK], DatanodeInfoWithStorage[127.0.0.1:36749,DS-72e23442-43db-4172-a8d0-e531671363b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2118714851-172.17.0.3-1598365617632:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43493,DS-ea6a087b-eca3-45e4-ad41-b422ea6aeec0,DISK], DatanodeInfoWithStorage[127.0.0.1:46580,DS-da66bc85-2de6-4d5f-9db5-994c953891e5,DISK], DatanodeInfoWithStorage[127.0.0.1:44128,DS-dc46ad1b-5f06-4ec6-b99a-eff30f55664d,DISK], DatanodeInfoWithStorage[127.0.0.1:35618,DS-a36e8451-0579-47d4-b4e3-d09b8688c98a,DISK], DatanodeInfoWithStorage[127.0.0.1:45872,DS-700c1201-acdd-44d0-a1cd-c34235f419fd,DISK], DatanodeInfoWithStorage[127.0.0.1:34524,DS-2e196f36-ede0-4193-a9bf-ed6a8a3c9847,DISK], DatanodeInfoWithStorage[127.0.0.1:39171,DS-4afa869d-8e91-41e9-a634-2b2347cdec4e,DISK], DatanodeInfoWithStorage[127.0.0.1:42287,DS-3f52cb32-895b-475d-9931-86e4b6793f63,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2118714851-172.17.0.3-1598365617632:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43493,DS-ea6a087b-eca3-45e4-ad41-b422ea6aeec0,DISK], DatanodeInfoWithStorage[127.0.0.1:46580,DS-da66bc85-2de6-4d5f-9db5-994c953891e5,DISK], DatanodeInfoWithStorage[127.0.0.1:44128,DS-dc46ad1b-5f06-4ec6-b99a-eff30f55664d,DISK], DatanodeInfoWithStorage[127.0.0.1:35618,DS-a36e8451-0579-47d4-b4e3-d09b8688c98a,DISK], DatanodeInfoWithStorage[127.0.0.1:45872,DS-700c1201-acdd-44d0-a1cd-c34235f419fd,DISK], DatanodeInfoWithStorage[127.0.0.1:34524,DS-2e196f36-ede0-4193-a9bf-ed6a8a3c9847,DISK], DatanodeInfoWithStorage[127.0.0.1:39171,DS-4afa869d-8e91-41e9-a634-2b2347cdec4e,DISK], DatanodeInfoWithStorage[127.0.0.1:42287,DS-3f52cb32-895b-475d-9931-86e4b6793f63,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-330961389-172.17.0.3-1598365765212:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38088,DS-3609abc1-0463-46ab-9260-5f2d9cb0fe12,DISK], DatanodeInfoWithStorage[127.0.0.1:39921,DS-4f7c08f7-53d1-4279-9db7-ec44ef364791,DISK], DatanodeInfoWithStorage[127.0.0.1:36122,DS-55f16408-c551-4d6b-8552-ea34a5524bd9,DISK], DatanodeInfoWithStorage[127.0.0.1:39746,DS-325a17e4-63db-4b08-8ecb-511254e15ab1,DISK], DatanodeInfoWithStorage[127.0.0.1:41892,DS-4be6dc92-4d8a-4b63-ad46-735ab75c9292,DISK], DatanodeInfoWithStorage[127.0.0.1:43850,DS-1a1000c8-b7c8-444a-a598-a1b433fbe162,DISK], DatanodeInfoWithStorage[127.0.0.1:46110,DS-b3b012b4-8d14-4b52-968b-fc88413c6718,DISK], DatanodeInfoWithStorage[127.0.0.1:34798,DS-2c559677-2d62-40da-b7bb-dd8e5d1183c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-330961389-172.17.0.3-1598365765212:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38088,DS-3609abc1-0463-46ab-9260-5f2d9cb0fe12,DISK], DatanodeInfoWithStorage[127.0.0.1:39921,DS-4f7c08f7-53d1-4279-9db7-ec44ef364791,DISK], DatanodeInfoWithStorage[127.0.0.1:36122,DS-55f16408-c551-4d6b-8552-ea34a5524bd9,DISK], DatanodeInfoWithStorage[127.0.0.1:39746,DS-325a17e4-63db-4b08-8ecb-511254e15ab1,DISK], DatanodeInfoWithStorage[127.0.0.1:41892,DS-4be6dc92-4d8a-4b63-ad46-735ab75c9292,DISK], DatanodeInfoWithStorage[127.0.0.1:43850,DS-1a1000c8-b7c8-444a-a598-a1b433fbe162,DISK], DatanodeInfoWithStorage[127.0.0.1:46110,DS-b3b012b4-8d14-4b52-968b-fc88413c6718,DISK], DatanodeInfoWithStorage[127.0.0.1:34798,DS-2c559677-2d62-40da-b7bb-dd8e5d1183c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1347211160-172.17.0.3-1598366742052:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43250,DS-ae2cea41-8dc6-4a86-bee1-db522f686001,DISK], DatanodeInfoWithStorage[127.0.0.1:36466,DS-7a01132f-afd8-4d35-b660-6e1656010aca,DISK], DatanodeInfoWithStorage[127.0.0.1:33175,DS-1d57bcad-d5c3-4a83-af12-5d50e9a614cf,DISK], DatanodeInfoWithStorage[127.0.0.1:39137,DS-ae59d50f-4b7d-409f-a2a5-0a6716460efa,DISK], DatanodeInfoWithStorage[127.0.0.1:33676,DS-a78526d0-e245-4508-945d-abc42c4d3267,DISK], DatanodeInfoWithStorage[127.0.0.1:39380,DS-19bebe37-b3c7-45ff-ad12-e2f5f60cf8b7,DISK], DatanodeInfoWithStorage[127.0.0.1:44337,DS-0a5435bf-55e1-4997-bf28-bd118c89b45d,DISK], DatanodeInfoWithStorage[127.0.0.1:38141,DS-86d91429-b2e9-4909-8d30-d5b8e8f5b8b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1347211160-172.17.0.3-1598366742052:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43250,DS-ae2cea41-8dc6-4a86-bee1-db522f686001,DISK], DatanodeInfoWithStorage[127.0.0.1:36466,DS-7a01132f-afd8-4d35-b660-6e1656010aca,DISK], DatanodeInfoWithStorage[127.0.0.1:33175,DS-1d57bcad-d5c3-4a83-af12-5d50e9a614cf,DISK], DatanodeInfoWithStorage[127.0.0.1:39137,DS-ae59d50f-4b7d-409f-a2a5-0a6716460efa,DISK], DatanodeInfoWithStorage[127.0.0.1:33676,DS-a78526d0-e245-4508-945d-abc42c4d3267,DISK], DatanodeInfoWithStorage[127.0.0.1:39380,DS-19bebe37-b3c7-45ff-ad12-e2f5f60cf8b7,DISK], DatanodeInfoWithStorage[127.0.0.1:44337,DS-0a5435bf-55e1-4997-bf28-bd118c89b45d,DISK], DatanodeInfoWithStorage[127.0.0.1:38141,DS-86d91429-b2e9-4909-8d30-d5b8e8f5b8b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-761696930-172.17.0.3-1598367600897:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36872,DS-58dfc978-673c-45db-8831-1ad00d4e9213,DISK], DatanodeInfoWithStorage[127.0.0.1:43199,DS-03954349-627a-4623-9ad5-d5ce4cec506c,DISK], DatanodeInfoWithStorage[127.0.0.1:35569,DS-5ac64d58-71a7-448c-9ecf-858061203056,DISK], DatanodeInfoWithStorage[127.0.0.1:43622,DS-54b97f9a-41b4-4ba5-9d17-4f2c74db5eb9,DISK], DatanodeInfoWithStorage[127.0.0.1:38316,DS-189c9d3b-af59-41e4-ac5d-78d01cb8efbe,DISK], DatanodeInfoWithStorage[127.0.0.1:46685,DS-c412924b-f1fb-4857-a114-f4562c373310,DISK], DatanodeInfoWithStorage[127.0.0.1:35413,DS-6bec75bb-7962-45fc-a44e-43883a9f9f2d,DISK], DatanodeInfoWithStorage[127.0.0.1:33191,DS-dd605b14-e1ae-477c-863e-b332a8020026,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-761696930-172.17.0.3-1598367600897:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36872,DS-58dfc978-673c-45db-8831-1ad00d4e9213,DISK], DatanodeInfoWithStorage[127.0.0.1:43199,DS-03954349-627a-4623-9ad5-d5ce4cec506c,DISK], DatanodeInfoWithStorage[127.0.0.1:35569,DS-5ac64d58-71a7-448c-9ecf-858061203056,DISK], DatanodeInfoWithStorage[127.0.0.1:43622,DS-54b97f9a-41b4-4ba5-9d17-4f2c74db5eb9,DISK], DatanodeInfoWithStorage[127.0.0.1:38316,DS-189c9d3b-af59-41e4-ac5d-78d01cb8efbe,DISK], DatanodeInfoWithStorage[127.0.0.1:46685,DS-c412924b-f1fb-4857-a114-f4562c373310,DISK], DatanodeInfoWithStorage[127.0.0.1:35413,DS-6bec75bb-7962-45fc-a44e-43883a9f9f2d,DISK], DatanodeInfoWithStorage[127.0.0.1:33191,DS-dd605b14-e1ae-477c-863e-b332a8020026,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 5401
