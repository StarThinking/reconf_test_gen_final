reconf_parameter: dfs.quota.by.storage.type.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.quota.by.storage.type.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-568292631-172.17.0.5-1598185075563:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37002,DS-c6dc65f9-6ed4-4265-a3c3-9e51a010d796,DISK], DatanodeInfoWithStorage[127.0.0.1:42734,DS-6ee08250-e6e6-4dab-a742-504f7c6a4e09,DISK], DatanodeInfoWithStorage[127.0.0.1:35279,DS-70e0abe9-a454-4429-a917-7f3a0c0859e7,DISK], DatanodeInfoWithStorage[127.0.0.1:43241,DS-f241901a-6a43-414f-b809-4dde8cfd31cb,DISK], DatanodeInfoWithStorage[127.0.0.1:40399,DS-1ebffcb4-ef23-4b9d-8ffa-744a9f7cd672,DISK], DatanodeInfoWithStorage[127.0.0.1:37748,DS-8d4260f7-f593-4d60-ac59-4adc3be26c1c,DISK], DatanodeInfoWithStorage[127.0.0.1:46829,DS-2ddf17c6-9a3f-4108-9fd3-7c38895f0811,DISK], DatanodeInfoWithStorage[127.0.0.1:36256,DS-1075270c-a4ea-4f0c-a76a-2e77a027365b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-568292631-172.17.0.5-1598185075563:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37002,DS-c6dc65f9-6ed4-4265-a3c3-9e51a010d796,DISK], DatanodeInfoWithStorage[127.0.0.1:42734,DS-6ee08250-e6e6-4dab-a742-504f7c6a4e09,DISK], DatanodeInfoWithStorage[127.0.0.1:35279,DS-70e0abe9-a454-4429-a917-7f3a0c0859e7,DISK], DatanodeInfoWithStorage[127.0.0.1:43241,DS-f241901a-6a43-414f-b809-4dde8cfd31cb,DISK], DatanodeInfoWithStorage[127.0.0.1:40399,DS-1ebffcb4-ef23-4b9d-8ffa-744a9f7cd672,DISK], DatanodeInfoWithStorage[127.0.0.1:37748,DS-8d4260f7-f593-4d60-ac59-4adc3be26c1c,DISK], DatanodeInfoWithStorage[127.0.0.1:46829,DS-2ddf17c6-9a3f-4108-9fd3-7c38895f0811,DISK], DatanodeInfoWithStorage[127.0.0.1:36256,DS-1075270c-a4ea-4f0c-a76a-2e77a027365b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.quota.by.storage.type.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2130994850-172.17.0.5-1598185672665:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33772,DS-f6b2407a-cd64-46dc-b406-cebc2672c740,DISK], DatanodeInfoWithStorage[127.0.0.1:36395,DS-55915e9a-242d-4261-b443-714470c4af42,DISK], DatanodeInfoWithStorage[127.0.0.1:33995,DS-3d1406e3-0fbe-4449-a4f1-c0af8966fce1,DISK], DatanodeInfoWithStorage[127.0.0.1:34803,DS-862902e2-d09f-404f-a266-3f6aab7c275e,DISK], DatanodeInfoWithStorage[127.0.0.1:38271,DS-aa0aa99a-60c1-401e-9ab6-c7adab4deb78,DISK], DatanodeInfoWithStorage[127.0.0.1:43704,DS-a47a0c80-6db7-45db-a137-a2eed95f92ec,DISK], DatanodeInfoWithStorage[127.0.0.1:41052,DS-e46109ea-2d3d-4f23-9f2d-478329898841,DISK], DatanodeInfoWithStorage[127.0.0.1:42454,DS-73d857f6-f44f-4e33-9128-73ba6d729868,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2130994850-172.17.0.5-1598185672665:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33772,DS-f6b2407a-cd64-46dc-b406-cebc2672c740,DISK], DatanodeInfoWithStorage[127.0.0.1:36395,DS-55915e9a-242d-4261-b443-714470c4af42,DISK], DatanodeInfoWithStorage[127.0.0.1:33995,DS-3d1406e3-0fbe-4449-a4f1-c0af8966fce1,DISK], DatanodeInfoWithStorage[127.0.0.1:34803,DS-862902e2-d09f-404f-a266-3f6aab7c275e,DISK], DatanodeInfoWithStorage[127.0.0.1:38271,DS-aa0aa99a-60c1-401e-9ab6-c7adab4deb78,DISK], DatanodeInfoWithStorage[127.0.0.1:43704,DS-a47a0c80-6db7-45db-a137-a2eed95f92ec,DISK], DatanodeInfoWithStorage[127.0.0.1:41052,DS-e46109ea-2d3d-4f23-9f2d-478329898841,DISK], DatanodeInfoWithStorage[127.0.0.1:42454,DS-73d857f6-f44f-4e33-9128-73ba6d729868,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.quota.by.storage.type.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-167110585-172.17.0.5-1598185756635:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45770,DS-954f093b-3e84-43cb-99a3-fbfec701c961,DISK], DatanodeInfoWithStorage[127.0.0.1:35801,DS-a43acee2-8088-4f3c-9b94-70dee48a3270,DISK], DatanodeInfoWithStorage[127.0.0.1:41661,DS-7ab08601-6dbc-4e34-9627-b4c768f6121c,DISK], DatanodeInfoWithStorage[127.0.0.1:45207,DS-9fd833e7-f3b0-49b6-9e2c-53ecab77d95c,DISK], DatanodeInfoWithStorage[127.0.0.1:32867,DS-9fe27db2-672e-47e4-aac3-e55a05cab308,DISK], DatanodeInfoWithStorage[127.0.0.1:40024,DS-3aa92cfc-0d11-4192-8ff2-fd4086fbbe9a,DISK], DatanodeInfoWithStorage[127.0.0.1:44882,DS-a185db74-752c-4421-909a-b01c69b08962,DISK], DatanodeInfoWithStorage[127.0.0.1:32942,DS-668f2a64-ca79-43aa-b2de-7041cada5938,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-167110585-172.17.0.5-1598185756635:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45770,DS-954f093b-3e84-43cb-99a3-fbfec701c961,DISK], DatanodeInfoWithStorage[127.0.0.1:35801,DS-a43acee2-8088-4f3c-9b94-70dee48a3270,DISK], DatanodeInfoWithStorage[127.0.0.1:41661,DS-7ab08601-6dbc-4e34-9627-b4c768f6121c,DISK], DatanodeInfoWithStorage[127.0.0.1:45207,DS-9fd833e7-f3b0-49b6-9e2c-53ecab77d95c,DISK], DatanodeInfoWithStorage[127.0.0.1:32867,DS-9fe27db2-672e-47e4-aac3-e55a05cab308,DISK], DatanodeInfoWithStorage[127.0.0.1:40024,DS-3aa92cfc-0d11-4192-8ff2-fd4086fbbe9a,DISK], DatanodeInfoWithStorage[127.0.0.1:44882,DS-a185db74-752c-4421-909a-b01c69b08962,DISK], DatanodeInfoWithStorage[127.0.0.1:32942,DS-668f2a64-ca79-43aa-b2de-7041cada5938,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.quota.by.storage.type.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1244196516-172.17.0.5-1598185910917:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33361,DS-896ce4b6-4fdf-423c-98df-5484e99e4f12,DISK], DatanodeInfoWithStorage[127.0.0.1:44313,DS-1baab4e2-6687-4a54-b7bb-2ad7415f29df,DISK], DatanodeInfoWithStorage[127.0.0.1:39474,DS-81e3cf57-8241-401e-b57a-128097ac9ff6,DISK], DatanodeInfoWithStorage[127.0.0.1:35181,DS-fd94cdd1-b608-47d6-a437-b44c425bceeb,DISK], DatanodeInfoWithStorage[127.0.0.1:45765,DS-0cafa34f-a68e-4215-960d-743ce0eb1ace,DISK], DatanodeInfoWithStorage[127.0.0.1:44268,DS-7263bb65-d392-4d68-8cbf-bb4fc1e78e46,DISK], DatanodeInfoWithStorage[127.0.0.1:44402,DS-e5df7ed3-6f8b-4ae0-acfc-c980b56294e0,DISK], DatanodeInfoWithStorage[127.0.0.1:46880,DS-dba3c627-a083-4313-bf98-9ddcab2d21c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1244196516-172.17.0.5-1598185910917:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33361,DS-896ce4b6-4fdf-423c-98df-5484e99e4f12,DISK], DatanodeInfoWithStorage[127.0.0.1:44313,DS-1baab4e2-6687-4a54-b7bb-2ad7415f29df,DISK], DatanodeInfoWithStorage[127.0.0.1:39474,DS-81e3cf57-8241-401e-b57a-128097ac9ff6,DISK], DatanodeInfoWithStorage[127.0.0.1:35181,DS-fd94cdd1-b608-47d6-a437-b44c425bceeb,DISK], DatanodeInfoWithStorage[127.0.0.1:45765,DS-0cafa34f-a68e-4215-960d-743ce0eb1ace,DISK], DatanodeInfoWithStorage[127.0.0.1:44268,DS-7263bb65-d392-4d68-8cbf-bb4fc1e78e46,DISK], DatanodeInfoWithStorage[127.0.0.1:44402,DS-e5df7ed3-6f8b-4ae0-acfc-c980b56294e0,DISK], DatanodeInfoWithStorage[127.0.0.1:46880,DS-dba3c627-a083-4313-bf98-9ddcab2d21c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.quota.by.storage.type.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1019451341-172.17.0.5-1598185979456:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42602,DS-0fb9a455-ae33-4661-8b92-d3cc772b31d8,DISK], DatanodeInfoWithStorage[127.0.0.1:45286,DS-8bbf52ff-f7f5-476e-80b0-9e65c0ba618d,DISK], DatanodeInfoWithStorage[127.0.0.1:37353,DS-1512f4c5-9438-4122-9d25-3e6d9e0ff9a1,DISK], DatanodeInfoWithStorage[127.0.0.1:46450,DS-d74e2aa5-65bb-423d-b50d-de19f35b2a39,DISK], DatanodeInfoWithStorage[127.0.0.1:44243,DS-3395c57a-60a8-4f5b-b486-eb4169519a73,DISK], DatanodeInfoWithStorage[127.0.0.1:34697,DS-22f300d9-b4a8-4ff1-a1de-ee8f0e41fbed,DISK], DatanodeInfoWithStorage[127.0.0.1:35746,DS-e8304186-b902-4faf-bfe0-234b0ed3656f,DISK], DatanodeInfoWithStorage[127.0.0.1:41668,DS-d7d0fbae-eaca-448d-bdc3-c5a6b2f7a475,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1019451341-172.17.0.5-1598185979456:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42602,DS-0fb9a455-ae33-4661-8b92-d3cc772b31d8,DISK], DatanodeInfoWithStorage[127.0.0.1:45286,DS-8bbf52ff-f7f5-476e-80b0-9e65c0ba618d,DISK], DatanodeInfoWithStorage[127.0.0.1:37353,DS-1512f4c5-9438-4122-9d25-3e6d9e0ff9a1,DISK], DatanodeInfoWithStorage[127.0.0.1:46450,DS-d74e2aa5-65bb-423d-b50d-de19f35b2a39,DISK], DatanodeInfoWithStorage[127.0.0.1:44243,DS-3395c57a-60a8-4f5b-b486-eb4169519a73,DISK], DatanodeInfoWithStorage[127.0.0.1:34697,DS-22f300d9-b4a8-4ff1-a1de-ee8f0e41fbed,DISK], DatanodeInfoWithStorage[127.0.0.1:35746,DS-e8304186-b902-4faf-bfe0-234b0ed3656f,DISK], DatanodeInfoWithStorage[127.0.0.1:41668,DS-d7d0fbae-eaca-448d-bdc3-c5a6b2f7a475,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.quota.by.storage.type.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1157920542-172.17.0.5-1598186263001:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37878,DS-3f4ce668-a544-4114-8ff4-6ba3427a482d,DISK], DatanodeInfoWithStorage[127.0.0.1:34795,DS-4a70e3c9-aa87-485f-b8ba-9e9e5bb22fe2,DISK], DatanodeInfoWithStorage[127.0.0.1:41231,DS-ccdee439-1d2f-4b20-83b0-3b2e2b1f5fa0,DISK], DatanodeInfoWithStorage[127.0.0.1:38368,DS-8636f752-244c-4c6b-aa74-ec57d824ae97,DISK], DatanodeInfoWithStorage[127.0.0.1:36970,DS-e11c328a-142c-48bb-bd86-7b8aea289c9a,DISK], DatanodeInfoWithStorage[127.0.0.1:44587,DS-fa689867-6189-4a71-bed7-d030ae9017e2,DISK], DatanodeInfoWithStorage[127.0.0.1:36777,DS-38605f44-6360-437b-a75f-9e7e43748349,DISK], DatanodeInfoWithStorage[127.0.0.1:45083,DS-cdbe3555-4aff-4f22-9d1c-7789a3dc9fc4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1157920542-172.17.0.5-1598186263001:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37878,DS-3f4ce668-a544-4114-8ff4-6ba3427a482d,DISK], DatanodeInfoWithStorage[127.0.0.1:34795,DS-4a70e3c9-aa87-485f-b8ba-9e9e5bb22fe2,DISK], DatanodeInfoWithStorage[127.0.0.1:41231,DS-ccdee439-1d2f-4b20-83b0-3b2e2b1f5fa0,DISK], DatanodeInfoWithStorage[127.0.0.1:38368,DS-8636f752-244c-4c6b-aa74-ec57d824ae97,DISK], DatanodeInfoWithStorage[127.0.0.1:36970,DS-e11c328a-142c-48bb-bd86-7b8aea289c9a,DISK], DatanodeInfoWithStorage[127.0.0.1:44587,DS-fa689867-6189-4a71-bed7-d030ae9017e2,DISK], DatanodeInfoWithStorage[127.0.0.1:36777,DS-38605f44-6360-437b-a75f-9e7e43748349,DISK], DatanodeInfoWithStorage[127.0.0.1:45083,DS-cdbe3555-4aff-4f22-9d1c-7789a3dc9fc4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.quota.by.storage.type.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-652345081-172.17.0.5-1598186303662:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44608,DS-14adb1ca-6fee-4eda-9ba5-4e64fa287499,DISK], DatanodeInfoWithStorage[127.0.0.1:45985,DS-ed57e4db-264f-4b5b-bb2f-80098e93904f,DISK], DatanodeInfoWithStorage[127.0.0.1:43429,DS-cedf9be6-e4ed-454e-aac0-ff3627a18df1,DISK], DatanodeInfoWithStorage[127.0.0.1:39516,DS-c982d521-546a-44f3-b7e7-5504e416b24a,DISK], DatanodeInfoWithStorage[127.0.0.1:43592,DS-d79dd132-0572-459e-bfe2-b2c120a64660,DISK], DatanodeInfoWithStorage[127.0.0.1:42331,DS-0b1a04d4-c116-465d-bd01-14a4be270c91,DISK], DatanodeInfoWithStorage[127.0.0.1:35184,DS-93129d2d-496a-4ea4-b9c0-c10a422fb57f,DISK], DatanodeInfoWithStorage[127.0.0.1:35574,DS-f606cf44-cc44-4d3f-a5aa-809f13146b4e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-652345081-172.17.0.5-1598186303662:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44608,DS-14adb1ca-6fee-4eda-9ba5-4e64fa287499,DISK], DatanodeInfoWithStorage[127.0.0.1:45985,DS-ed57e4db-264f-4b5b-bb2f-80098e93904f,DISK], DatanodeInfoWithStorage[127.0.0.1:43429,DS-cedf9be6-e4ed-454e-aac0-ff3627a18df1,DISK], DatanodeInfoWithStorage[127.0.0.1:39516,DS-c982d521-546a-44f3-b7e7-5504e416b24a,DISK], DatanodeInfoWithStorage[127.0.0.1:43592,DS-d79dd132-0572-459e-bfe2-b2c120a64660,DISK], DatanodeInfoWithStorage[127.0.0.1:42331,DS-0b1a04d4-c116-465d-bd01-14a4be270c91,DISK], DatanodeInfoWithStorage[127.0.0.1:35184,DS-93129d2d-496a-4ea4-b9c0-c10a422fb57f,DISK], DatanodeInfoWithStorage[127.0.0.1:35574,DS-f606cf44-cc44-4d3f-a5aa-809f13146b4e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.quota.by.storage.type.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-512406148-172.17.0.5-1598186375390:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44607,DS-e9b743cf-e338-4930-bd9c-26f65ac283b0,DISK], DatanodeInfoWithStorage[127.0.0.1:36899,DS-7ea3e4e3-d54f-4b07-b8ab-9986696a96fe,DISK], DatanodeInfoWithStorage[127.0.0.1:41410,DS-26be70ee-faf8-4aa2-9d10-10e1078fc873,DISK], DatanodeInfoWithStorage[127.0.0.1:42552,DS-59b8ba5e-2f3f-437e-af67-37186335ddd6,DISK], DatanodeInfoWithStorage[127.0.0.1:35519,DS-8077ddf0-12a9-4d0b-9d46-a007a48933f2,DISK], DatanodeInfoWithStorage[127.0.0.1:34703,DS-e3a62f13-cd4b-4cdc-bb25-0915e8a39d88,DISK], DatanodeInfoWithStorage[127.0.0.1:46218,DS-d86c87c9-240b-40c9-979b-efa76bd138d1,DISK], DatanodeInfoWithStorage[127.0.0.1:42062,DS-8b6c3d29-6aa9-4a68-a8a5-b089141fad88,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-512406148-172.17.0.5-1598186375390:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44607,DS-e9b743cf-e338-4930-bd9c-26f65ac283b0,DISK], DatanodeInfoWithStorage[127.0.0.1:36899,DS-7ea3e4e3-d54f-4b07-b8ab-9986696a96fe,DISK], DatanodeInfoWithStorage[127.0.0.1:41410,DS-26be70ee-faf8-4aa2-9d10-10e1078fc873,DISK], DatanodeInfoWithStorage[127.0.0.1:42552,DS-59b8ba5e-2f3f-437e-af67-37186335ddd6,DISK], DatanodeInfoWithStorage[127.0.0.1:35519,DS-8077ddf0-12a9-4d0b-9d46-a007a48933f2,DISK], DatanodeInfoWithStorage[127.0.0.1:34703,DS-e3a62f13-cd4b-4cdc-bb25-0915e8a39d88,DISK], DatanodeInfoWithStorage[127.0.0.1:46218,DS-d86c87c9-240b-40c9-979b-efa76bd138d1,DISK], DatanodeInfoWithStorage[127.0.0.1:42062,DS-8b6c3d29-6aa9-4a68-a8a5-b089141fad88,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.quota.by.storage.type.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1856271166-172.17.0.5-1598186760826:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37265,DS-2c4a2504-6091-4dbd-be93-7ad1d737ef76,DISK], DatanodeInfoWithStorage[127.0.0.1:43315,DS-62c8e05d-5316-46ff-b81b-90211012f50c,DISK], DatanodeInfoWithStorage[127.0.0.1:42765,DS-991d0108-b36a-47d2-9f75-5ce346317fd7,DISK], DatanodeInfoWithStorage[127.0.0.1:33217,DS-b79f4a7f-1019-49db-8a23-b8f3d24331bf,DISK], DatanodeInfoWithStorage[127.0.0.1:37839,DS-f9d46a83-b986-41ee-b638-d2ef5108ada4,DISK], DatanodeInfoWithStorage[127.0.0.1:42725,DS-cee2e57c-4ef9-4868-8b20-c12ff5d892e6,DISK], DatanodeInfoWithStorage[127.0.0.1:33485,DS-09d5a692-c1b3-4b6b-9622-05d6f9a40a7f,DISK], DatanodeInfoWithStorage[127.0.0.1:37875,DS-290821b2-8268-4ea6-923b-c8840cfab61c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1856271166-172.17.0.5-1598186760826:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37265,DS-2c4a2504-6091-4dbd-be93-7ad1d737ef76,DISK], DatanodeInfoWithStorage[127.0.0.1:43315,DS-62c8e05d-5316-46ff-b81b-90211012f50c,DISK], DatanodeInfoWithStorage[127.0.0.1:42765,DS-991d0108-b36a-47d2-9f75-5ce346317fd7,DISK], DatanodeInfoWithStorage[127.0.0.1:33217,DS-b79f4a7f-1019-49db-8a23-b8f3d24331bf,DISK], DatanodeInfoWithStorage[127.0.0.1:37839,DS-f9d46a83-b986-41ee-b638-d2ef5108ada4,DISK], DatanodeInfoWithStorage[127.0.0.1:42725,DS-cee2e57c-4ef9-4868-8b20-c12ff5d892e6,DISK], DatanodeInfoWithStorage[127.0.0.1:33485,DS-09d5a692-c1b3-4b6b-9622-05d6f9a40a7f,DISK], DatanodeInfoWithStorage[127.0.0.1:37875,DS-290821b2-8268-4ea6-923b-c8840cfab61c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.quota.by.storage.type.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1241844273-172.17.0.5-1598186965767:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38651,DS-5f17fa71-9add-45b6-aef0-939c96d43029,DISK], DatanodeInfoWithStorage[127.0.0.1:40435,DS-ea607b40-910b-475e-ab7c-4a66717fda47,DISK], DatanodeInfoWithStorage[127.0.0.1:36009,DS-220f1e26-8f92-4839-8087-75d199fa2c37,DISK], DatanodeInfoWithStorage[127.0.0.1:39096,DS-f5112a4c-9b60-493b-8011-55e8d8fa55f6,DISK], DatanodeInfoWithStorage[127.0.0.1:32902,DS-9f723bd5-3920-4062-86a4-45d626da3859,DISK], DatanodeInfoWithStorage[127.0.0.1:34931,DS-c5242c98-e33a-4d3a-9b73-88d2a19a18f7,DISK], DatanodeInfoWithStorage[127.0.0.1:42674,DS-bb22d0d7-ce85-4294-be92-1834506df39e,DISK], DatanodeInfoWithStorage[127.0.0.1:43391,DS-6a85996f-9ab6-4a7d-82e4-149c43e85d9c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1241844273-172.17.0.5-1598186965767:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38651,DS-5f17fa71-9add-45b6-aef0-939c96d43029,DISK], DatanodeInfoWithStorage[127.0.0.1:40435,DS-ea607b40-910b-475e-ab7c-4a66717fda47,DISK], DatanodeInfoWithStorage[127.0.0.1:36009,DS-220f1e26-8f92-4839-8087-75d199fa2c37,DISK], DatanodeInfoWithStorage[127.0.0.1:39096,DS-f5112a4c-9b60-493b-8011-55e8d8fa55f6,DISK], DatanodeInfoWithStorage[127.0.0.1:32902,DS-9f723bd5-3920-4062-86a4-45d626da3859,DISK], DatanodeInfoWithStorage[127.0.0.1:34931,DS-c5242c98-e33a-4d3a-9b73-88d2a19a18f7,DISK], DatanodeInfoWithStorage[127.0.0.1:42674,DS-bb22d0d7-ce85-4294-be92-1834506df39e,DISK], DatanodeInfoWithStorage[127.0.0.1:43391,DS-6a85996f-9ab6-4a7d-82e4-149c43e85d9c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.quota.by.storage.type.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-148398776-172.17.0.5-1598187430156:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32799,DS-64a3fa31-8890-4fd9-b97f-080fbeaddb1e,DISK], DatanodeInfoWithStorage[127.0.0.1:37364,DS-9192d174-8706-4d75-9d5d-ee09d05e50e3,DISK], DatanodeInfoWithStorage[127.0.0.1:37045,DS-f10fb98a-0812-4375-9e4a-9c119abd0182,DISK], DatanodeInfoWithStorage[127.0.0.1:38529,DS-767d7727-b241-4536-8b6f-376499869f36,DISK], DatanodeInfoWithStorage[127.0.0.1:45695,DS-a8d2bcad-ebfb-4e92-8b1d-94e893c86a03,DISK], DatanodeInfoWithStorage[127.0.0.1:34255,DS-1f843bf3-2766-459c-a95b-4395c4b72480,DISK], DatanodeInfoWithStorage[127.0.0.1:42877,DS-d5fa08fe-2ba0-4d27-89a5-92a87900f6be,DISK], DatanodeInfoWithStorage[127.0.0.1:34201,DS-ced21d29-2699-4d39-a699-dfa0a5f45c81,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-148398776-172.17.0.5-1598187430156:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32799,DS-64a3fa31-8890-4fd9-b97f-080fbeaddb1e,DISK], DatanodeInfoWithStorage[127.0.0.1:37364,DS-9192d174-8706-4d75-9d5d-ee09d05e50e3,DISK], DatanodeInfoWithStorage[127.0.0.1:37045,DS-f10fb98a-0812-4375-9e4a-9c119abd0182,DISK], DatanodeInfoWithStorage[127.0.0.1:38529,DS-767d7727-b241-4536-8b6f-376499869f36,DISK], DatanodeInfoWithStorage[127.0.0.1:45695,DS-a8d2bcad-ebfb-4e92-8b1d-94e893c86a03,DISK], DatanodeInfoWithStorage[127.0.0.1:34255,DS-1f843bf3-2766-459c-a95b-4395c4b72480,DISK], DatanodeInfoWithStorage[127.0.0.1:42877,DS-d5fa08fe-2ba0-4d27-89a5-92a87900f6be,DISK], DatanodeInfoWithStorage[127.0.0.1:34201,DS-ced21d29-2699-4d39-a699-dfa0a5f45c81,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.quota.by.storage.type.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1791040764-172.17.0.5-1598187707481:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43239,DS-f35e362a-e766-4866-8c37-aa7001563095,DISK], DatanodeInfoWithStorage[127.0.0.1:40782,DS-6501891a-d97e-4e57-afb8-a44b3fb9462d,DISK], DatanodeInfoWithStorage[127.0.0.1:33139,DS-b23ad033-59e7-4bb4-a1d3-e9e9a3428ff6,DISK], DatanodeInfoWithStorage[127.0.0.1:46621,DS-8d67ddd4-681e-42d3-be19-75d53e05dc66,DISK], DatanodeInfoWithStorage[127.0.0.1:34766,DS-1cb375be-fb91-4311-a5f0-586965238def,DISK], DatanodeInfoWithStorage[127.0.0.1:36492,DS-3efa4ec4-5051-41af-aac2-e60432b9e803,DISK], DatanodeInfoWithStorage[127.0.0.1:45619,DS-b8f2d8a3-bfc6-41e0-a423-c6c604bf1cf1,DISK], DatanodeInfoWithStorage[127.0.0.1:37798,DS-6957d1b5-ad2d-4971-a3a6-c5058ab3c06b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1791040764-172.17.0.5-1598187707481:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43239,DS-f35e362a-e766-4866-8c37-aa7001563095,DISK], DatanodeInfoWithStorage[127.0.0.1:40782,DS-6501891a-d97e-4e57-afb8-a44b3fb9462d,DISK], DatanodeInfoWithStorage[127.0.0.1:33139,DS-b23ad033-59e7-4bb4-a1d3-e9e9a3428ff6,DISK], DatanodeInfoWithStorage[127.0.0.1:46621,DS-8d67ddd4-681e-42d3-be19-75d53e05dc66,DISK], DatanodeInfoWithStorage[127.0.0.1:34766,DS-1cb375be-fb91-4311-a5f0-586965238def,DISK], DatanodeInfoWithStorage[127.0.0.1:36492,DS-3efa4ec4-5051-41af-aac2-e60432b9e803,DISK], DatanodeInfoWithStorage[127.0.0.1:45619,DS-b8f2d8a3-bfc6-41e0-a423-c6c604bf1cf1,DISK], DatanodeInfoWithStorage[127.0.0.1:37798,DS-6957d1b5-ad2d-4971-a3a6-c5058ab3c06b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.quota.by.storage.type.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1354461639-172.17.0.5-1598187782980:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43139,DS-ab93fdcc-cecd-4e76-90ad-a14b65de3b08,DISK], DatanodeInfoWithStorage[127.0.0.1:40602,DS-d6dabc48-c11d-46ee-86df-532fb3470d80,DISK], DatanodeInfoWithStorage[127.0.0.1:40702,DS-f75272db-9349-42ac-9642-fb864f84b8fa,DISK], DatanodeInfoWithStorage[127.0.0.1:45287,DS-7cf7678d-f31b-452b-92e8-b65df8b54ab5,DISK], DatanodeInfoWithStorage[127.0.0.1:33729,DS-a7c7aef9-626c-4ae1-9a7b-8dea03f923d8,DISK], DatanodeInfoWithStorage[127.0.0.1:33931,DS-ea111010-aa6d-4ff9-b1ac-b6264257ebe5,DISK], DatanodeInfoWithStorage[127.0.0.1:41773,DS-71396499-dd43-4f1a-be75-c87b0b66c48a,DISK], DatanodeInfoWithStorage[127.0.0.1:40858,DS-db6bcaca-70e4-48fb-b17d-f985da1f733f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1354461639-172.17.0.5-1598187782980:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43139,DS-ab93fdcc-cecd-4e76-90ad-a14b65de3b08,DISK], DatanodeInfoWithStorage[127.0.0.1:40602,DS-d6dabc48-c11d-46ee-86df-532fb3470d80,DISK], DatanodeInfoWithStorage[127.0.0.1:40702,DS-f75272db-9349-42ac-9642-fb864f84b8fa,DISK], DatanodeInfoWithStorage[127.0.0.1:45287,DS-7cf7678d-f31b-452b-92e8-b65df8b54ab5,DISK], DatanodeInfoWithStorage[127.0.0.1:33729,DS-a7c7aef9-626c-4ae1-9a7b-8dea03f923d8,DISK], DatanodeInfoWithStorage[127.0.0.1:33931,DS-ea111010-aa6d-4ff9-b1ac-b6264257ebe5,DISK], DatanodeInfoWithStorage[127.0.0.1:41773,DS-71396499-dd43-4f1a-be75-c87b0b66c48a,DISK], DatanodeInfoWithStorage[127.0.0.1:40858,DS-db6bcaca-70e4-48fb-b17d-f985da1f733f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.quota.by.storage.type.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1934578228-172.17.0.5-1598188564191:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34398,DS-5ed759ad-1146-4e41-8524-c3a7a37a7a65,DISK], DatanodeInfoWithStorage[127.0.0.1:45290,DS-b750a3f8-f8f7-45d9-a31e-9b9ce37c38c2,DISK], DatanodeInfoWithStorage[127.0.0.1:41169,DS-37277093-3a2e-40a5-8a7a-dbce4c52815b,DISK], DatanodeInfoWithStorage[127.0.0.1:38586,DS-ab7b6d6d-03cd-44eb-b24d-608851d5a7cb,DISK], DatanodeInfoWithStorage[127.0.0.1:33886,DS-c7293d19-2fb1-4ecb-af46-cb9ca90f366e,DISK], DatanodeInfoWithStorage[127.0.0.1:41259,DS-bd0fe090-61c4-47c8-aecb-d2821e97988c,DISK], DatanodeInfoWithStorage[127.0.0.1:36421,DS-1e3ca6a2-f09b-48f4-b9d1-27f6d33e08e9,DISK], DatanodeInfoWithStorage[127.0.0.1:43029,DS-f855366c-8eb2-4a4a-9218-8e502b60c060,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1934578228-172.17.0.5-1598188564191:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34398,DS-5ed759ad-1146-4e41-8524-c3a7a37a7a65,DISK], DatanodeInfoWithStorage[127.0.0.1:45290,DS-b750a3f8-f8f7-45d9-a31e-9b9ce37c38c2,DISK], DatanodeInfoWithStorage[127.0.0.1:41169,DS-37277093-3a2e-40a5-8a7a-dbce4c52815b,DISK], DatanodeInfoWithStorage[127.0.0.1:38586,DS-ab7b6d6d-03cd-44eb-b24d-608851d5a7cb,DISK], DatanodeInfoWithStorage[127.0.0.1:33886,DS-c7293d19-2fb1-4ecb-af46-cb9ca90f366e,DISK], DatanodeInfoWithStorage[127.0.0.1:41259,DS-bd0fe090-61c4-47c8-aecb-d2821e97988c,DISK], DatanodeInfoWithStorage[127.0.0.1:36421,DS-1e3ca6a2-f09b-48f4-b9d1-27f6d33e08e9,DISK], DatanodeInfoWithStorage[127.0.0.1:43029,DS-f855366c-8eb2-4a4a-9218-8e502b60c060,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.quota.by.storage.type.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1639106138-172.17.0.5-1598188678039:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35429,DS-3d47bfb3-9242-4412-9115-8b224a6a0bf0,DISK], DatanodeInfoWithStorage[127.0.0.1:42893,DS-4408c31b-a676-4ecc-ae61-1a59b2a2036f,DISK], DatanodeInfoWithStorage[127.0.0.1:38017,DS-f03b8711-d042-4245-9ca9-f5c9192c97dc,DISK], DatanodeInfoWithStorage[127.0.0.1:37330,DS-b7df71f6-de64-42d4-9423-10454956c90c,DISK], DatanodeInfoWithStorage[127.0.0.1:41670,DS-ae41b070-a38e-4a33-95c9-90cb483b9434,DISK], DatanodeInfoWithStorage[127.0.0.1:43739,DS-0d06c07a-8678-4658-a4d2-ed67e54badf5,DISK], DatanodeInfoWithStorage[127.0.0.1:41748,DS-fa7bfafc-b720-404c-a232-fea2e811c058,DISK], DatanodeInfoWithStorage[127.0.0.1:38522,DS-eebd016e-388b-4a24-b77b-9c1b6f40d829,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1639106138-172.17.0.5-1598188678039:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35429,DS-3d47bfb3-9242-4412-9115-8b224a6a0bf0,DISK], DatanodeInfoWithStorage[127.0.0.1:42893,DS-4408c31b-a676-4ecc-ae61-1a59b2a2036f,DISK], DatanodeInfoWithStorage[127.0.0.1:38017,DS-f03b8711-d042-4245-9ca9-f5c9192c97dc,DISK], DatanodeInfoWithStorage[127.0.0.1:37330,DS-b7df71f6-de64-42d4-9423-10454956c90c,DISK], DatanodeInfoWithStorage[127.0.0.1:41670,DS-ae41b070-a38e-4a33-95c9-90cb483b9434,DISK], DatanodeInfoWithStorage[127.0.0.1:43739,DS-0d06c07a-8678-4658-a4d2-ed67e54badf5,DISK], DatanodeInfoWithStorage[127.0.0.1:41748,DS-fa7bfafc-b720-404c-a232-fea2e811c058,DISK], DatanodeInfoWithStorage[127.0.0.1:38522,DS-eebd016e-388b-4a24-b77b-9c1b6f40d829,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.quota.by.storage.type.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1127828616-172.17.0.5-1598188888552:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36510,DS-4cbd109e-6722-42f8-b299-58a290533414,DISK], DatanodeInfoWithStorage[127.0.0.1:40707,DS-1da8e413-9d83-4b05-a57c-45dc51393d97,DISK], DatanodeInfoWithStorage[127.0.0.1:34567,DS-a3b42d9e-e464-4941-9788-ef4cc4e0c88f,DISK], DatanodeInfoWithStorage[127.0.0.1:38839,DS-50b9668e-edac-476c-bcef-63682ef50d67,DISK], DatanodeInfoWithStorage[127.0.0.1:42026,DS-1d6a5c7c-571d-4e1c-a032-693273a12b81,DISK], DatanodeInfoWithStorage[127.0.0.1:33774,DS-c7b9c97b-d63b-4e26-bf2c-edeff2717931,DISK], DatanodeInfoWithStorage[127.0.0.1:32964,DS-bdb3c7e1-25bf-4a53-b1f1-9bb7fbdcd495,DISK], DatanodeInfoWithStorage[127.0.0.1:43041,DS-4f432e08-c7cc-4515-8b17-b4615f989912,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1127828616-172.17.0.5-1598188888552:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36510,DS-4cbd109e-6722-42f8-b299-58a290533414,DISK], DatanodeInfoWithStorage[127.0.0.1:40707,DS-1da8e413-9d83-4b05-a57c-45dc51393d97,DISK], DatanodeInfoWithStorage[127.0.0.1:34567,DS-a3b42d9e-e464-4941-9788-ef4cc4e0c88f,DISK], DatanodeInfoWithStorage[127.0.0.1:38839,DS-50b9668e-edac-476c-bcef-63682ef50d67,DISK], DatanodeInfoWithStorage[127.0.0.1:42026,DS-1d6a5c7c-571d-4e1c-a032-693273a12b81,DISK], DatanodeInfoWithStorage[127.0.0.1:33774,DS-c7b9c97b-d63b-4e26-bf2c-edeff2717931,DISK], DatanodeInfoWithStorage[127.0.0.1:32964,DS-bdb3c7e1-25bf-4a53-b1f1-9bb7fbdcd495,DISK], DatanodeInfoWithStorage[127.0.0.1:43041,DS-4f432e08-c7cc-4515-8b17-b4615f989912,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.quota.by.storage.type.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-293641265-172.17.0.5-1598188922968:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34669,DS-da90be55-b952-4b2d-b2cb-8c0ec6311ab9,DISK], DatanodeInfoWithStorage[127.0.0.1:32795,DS-4ba5b1ec-507e-419d-9567-d65abe802566,DISK], DatanodeInfoWithStorage[127.0.0.1:37784,DS-b3692f65-54b7-48d2-ab33-56230a327326,DISK], DatanodeInfoWithStorage[127.0.0.1:42001,DS-1c0c7458-77de-4b0d-a1bc-a4a32c206eb3,DISK], DatanodeInfoWithStorage[127.0.0.1:41300,DS-60cd7079-6696-4366-961d-7d45bd3aec82,DISK], DatanodeInfoWithStorage[127.0.0.1:36079,DS-79d3f039-413a-4215-aff0-299b6f4d7e6c,DISK], DatanodeInfoWithStorage[127.0.0.1:33873,DS-35af38ca-8125-4fb3-a81d-32a0661fab11,DISK], DatanodeInfoWithStorage[127.0.0.1:37467,DS-88e4465d-2f8a-4b71-bdb9-7384c2a6d5bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-293641265-172.17.0.5-1598188922968:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34669,DS-da90be55-b952-4b2d-b2cb-8c0ec6311ab9,DISK], DatanodeInfoWithStorage[127.0.0.1:32795,DS-4ba5b1ec-507e-419d-9567-d65abe802566,DISK], DatanodeInfoWithStorage[127.0.0.1:37784,DS-b3692f65-54b7-48d2-ab33-56230a327326,DISK], DatanodeInfoWithStorage[127.0.0.1:42001,DS-1c0c7458-77de-4b0d-a1bc-a4a32c206eb3,DISK], DatanodeInfoWithStorage[127.0.0.1:41300,DS-60cd7079-6696-4366-961d-7d45bd3aec82,DISK], DatanodeInfoWithStorage[127.0.0.1:36079,DS-79d3f039-413a-4215-aff0-299b6f4d7e6c,DISK], DatanodeInfoWithStorage[127.0.0.1:33873,DS-35af38ca-8125-4fb3-a81d-32a0661fab11,DISK], DatanodeInfoWithStorage[127.0.0.1:37467,DS-88e4465d-2f8a-4b71-bdb9-7384c2a6d5bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.quota.by.storage.type.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1183745353-172.17.0.5-1598189112785:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35146,DS-9005540a-5354-48d9-9b2d-b8ee9776cb95,DISK], DatanodeInfoWithStorage[127.0.0.1:45273,DS-ec436ef4-2cd1-4864-afeb-5d45137fe603,DISK], DatanodeInfoWithStorage[127.0.0.1:34370,DS-2862d495-7176-4c2c-8edf-b6bb82f0c39a,DISK], DatanodeInfoWithStorage[127.0.0.1:44712,DS-400f80eb-fb60-46eb-8db8-3bd88e73cb97,DISK], DatanodeInfoWithStorage[127.0.0.1:41702,DS-0c2fbdf3-c94e-4c31-9946-bc3009a304dc,DISK], DatanodeInfoWithStorage[127.0.0.1:43069,DS-18f67c09-c804-40d9-bbf5-2e99cfd7d3f9,DISK], DatanodeInfoWithStorage[127.0.0.1:36306,DS-c830b030-c8e2-46cb-8e44-ae8a9faccfba,DISK], DatanodeInfoWithStorage[127.0.0.1:36390,DS-bbacff6c-ee05-4d43-a5fe-6eda998d323a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1183745353-172.17.0.5-1598189112785:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35146,DS-9005540a-5354-48d9-9b2d-b8ee9776cb95,DISK], DatanodeInfoWithStorage[127.0.0.1:45273,DS-ec436ef4-2cd1-4864-afeb-5d45137fe603,DISK], DatanodeInfoWithStorage[127.0.0.1:34370,DS-2862d495-7176-4c2c-8edf-b6bb82f0c39a,DISK], DatanodeInfoWithStorage[127.0.0.1:44712,DS-400f80eb-fb60-46eb-8db8-3bd88e73cb97,DISK], DatanodeInfoWithStorage[127.0.0.1:41702,DS-0c2fbdf3-c94e-4c31-9946-bc3009a304dc,DISK], DatanodeInfoWithStorage[127.0.0.1:43069,DS-18f67c09-c804-40d9-bbf5-2e99cfd7d3f9,DISK], DatanodeInfoWithStorage[127.0.0.1:36306,DS-c830b030-c8e2-46cb-8e44-ae8a9faccfba,DISK], DatanodeInfoWithStorage[127.0.0.1:36390,DS-bbacff6c-ee05-4d43-a5fe-6eda998d323a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.quota.by.storage.type.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2023584954-172.17.0.5-1598189317947:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42223,DS-8f68bf40-d396-42cc-b550-26beb23553b1,DISK], DatanodeInfoWithStorage[127.0.0.1:40271,DS-fd77adff-4a4e-4e33-967a-3d147c7b1676,DISK], DatanodeInfoWithStorage[127.0.0.1:45312,DS-78cb09bf-e1ad-416d-83f7-a99a88795f25,DISK], DatanodeInfoWithStorage[127.0.0.1:46264,DS-da5ae237-63b5-428b-851e-7d6e5b6a52a7,DISK], DatanodeInfoWithStorage[127.0.0.1:35380,DS-4a9bd659-290d-4460-b29c-a0b2f0ee5e2b,DISK], DatanodeInfoWithStorage[127.0.0.1:34846,DS-1d47d5f3-df14-4cad-84e5-fee2bd107cfa,DISK], DatanodeInfoWithStorage[127.0.0.1:41963,DS-167e8c3a-793f-4572-895b-e4589af2f1a1,DISK], DatanodeInfoWithStorage[127.0.0.1:35132,DS-4d332d02-7eba-4e20-95c6-a086efdcbcf0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2023584954-172.17.0.5-1598189317947:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42223,DS-8f68bf40-d396-42cc-b550-26beb23553b1,DISK], DatanodeInfoWithStorage[127.0.0.1:40271,DS-fd77adff-4a4e-4e33-967a-3d147c7b1676,DISK], DatanodeInfoWithStorage[127.0.0.1:45312,DS-78cb09bf-e1ad-416d-83f7-a99a88795f25,DISK], DatanodeInfoWithStorage[127.0.0.1:46264,DS-da5ae237-63b5-428b-851e-7d6e5b6a52a7,DISK], DatanodeInfoWithStorage[127.0.0.1:35380,DS-4a9bd659-290d-4460-b29c-a0b2f0ee5e2b,DISK], DatanodeInfoWithStorage[127.0.0.1:34846,DS-1d47d5f3-df14-4cad-84e5-fee2bd107cfa,DISK], DatanodeInfoWithStorage[127.0.0.1:41963,DS-167e8c3a-793f-4572-895b-e4589af2f1a1,DISK], DatanodeInfoWithStorage[127.0.0.1:35132,DS-4d332d02-7eba-4e20-95c6-a086efdcbcf0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.quota.by.storage.type.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-693947146-172.17.0.5-1598189354404:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42972,DS-2f92e96d-ca23-4645-9695-f1fcf205723e,DISK], DatanodeInfoWithStorage[127.0.0.1:46346,DS-ab7cf804-d0c1-42ac-b0d5-f06ba6366e85,DISK], DatanodeInfoWithStorage[127.0.0.1:38928,DS-54826489-a17a-41a0-9998-9bf665d479ff,DISK], DatanodeInfoWithStorage[127.0.0.1:42718,DS-919df4d3-fe69-4cd6-8ef8-11fcb0bba290,DISK], DatanodeInfoWithStorage[127.0.0.1:41915,DS-ca22202c-a838-42ef-b814-1467f985fb99,DISK], DatanodeInfoWithStorage[127.0.0.1:34828,DS-18d617f8-62cd-4b0f-9948-1c9f3e9a42de,DISK], DatanodeInfoWithStorage[127.0.0.1:36308,DS-002dead6-549f-4bea-946a-92607d738d3d,DISK], DatanodeInfoWithStorage[127.0.0.1:46674,DS-fb850d22-a2f6-4143-8bd4-3ed725f0e75b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-693947146-172.17.0.5-1598189354404:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42972,DS-2f92e96d-ca23-4645-9695-f1fcf205723e,DISK], DatanodeInfoWithStorage[127.0.0.1:46346,DS-ab7cf804-d0c1-42ac-b0d5-f06ba6366e85,DISK], DatanodeInfoWithStorage[127.0.0.1:38928,DS-54826489-a17a-41a0-9998-9bf665d479ff,DISK], DatanodeInfoWithStorage[127.0.0.1:42718,DS-919df4d3-fe69-4cd6-8ef8-11fcb0bba290,DISK], DatanodeInfoWithStorage[127.0.0.1:41915,DS-ca22202c-a838-42ef-b814-1467f985fb99,DISK], DatanodeInfoWithStorage[127.0.0.1:34828,DS-18d617f8-62cd-4b0f-9948-1c9f3e9a42de,DISK], DatanodeInfoWithStorage[127.0.0.1:36308,DS-002dead6-549f-4bea-946a-92607d738d3d,DISK], DatanodeInfoWithStorage[127.0.0.1:46674,DS-fb850d22-a2f6-4143-8bd4-3ed725f0e75b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.quota.by.storage.type.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-796340392-172.17.0.5-1598189622026:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43911,DS-125ed73e-d168-46af-b1d7-ae05e622ad3d,DISK], DatanodeInfoWithStorage[127.0.0.1:39468,DS-7dd23cc1-162d-41e9-83ea-c18be4aa6091,DISK], DatanodeInfoWithStorage[127.0.0.1:35923,DS-e4fb6845-5487-4bd4-978f-261aff57cd3e,DISK], DatanodeInfoWithStorage[127.0.0.1:44965,DS-20fbdd80-5757-4cbd-865e-95914fa68954,DISK], DatanodeInfoWithStorage[127.0.0.1:34492,DS-33d5fb02-8383-493d-a69b-13fed9bb5d84,DISK], DatanodeInfoWithStorage[127.0.0.1:46048,DS-bceb6f85-4eaa-4264-806c-fd10c76d2e71,DISK], DatanodeInfoWithStorage[127.0.0.1:39901,DS-b0c654f5-47b7-472c-aed3-864508f19a7a,DISK], DatanodeInfoWithStorage[127.0.0.1:36907,DS-8190ad46-4b81-4aa4-85c2-fb8c4a9ed53f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-796340392-172.17.0.5-1598189622026:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43911,DS-125ed73e-d168-46af-b1d7-ae05e622ad3d,DISK], DatanodeInfoWithStorage[127.0.0.1:39468,DS-7dd23cc1-162d-41e9-83ea-c18be4aa6091,DISK], DatanodeInfoWithStorage[127.0.0.1:35923,DS-e4fb6845-5487-4bd4-978f-261aff57cd3e,DISK], DatanodeInfoWithStorage[127.0.0.1:44965,DS-20fbdd80-5757-4cbd-865e-95914fa68954,DISK], DatanodeInfoWithStorage[127.0.0.1:34492,DS-33d5fb02-8383-493d-a69b-13fed9bb5d84,DISK], DatanodeInfoWithStorage[127.0.0.1:46048,DS-bceb6f85-4eaa-4264-806c-fd10c76d2e71,DISK], DatanodeInfoWithStorage[127.0.0.1:39901,DS-b0c654f5-47b7-472c-aed3-864508f19a7a,DISK], DatanodeInfoWithStorage[127.0.0.1:36907,DS-8190ad46-4b81-4aa4-85c2-fb8c4a9ed53f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.quota.by.storage.type.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-494360660-172.17.0.5-1598189947913:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36898,DS-4fb057fe-7530-4290-8e3e-167029732a2d,DISK], DatanodeInfoWithStorage[127.0.0.1:33443,DS-87bdd89d-b174-4253-8de6-76b42cd15d33,DISK], DatanodeInfoWithStorage[127.0.0.1:35367,DS-08a87a82-cf54-4778-96e4-66d9ca276795,DISK], DatanodeInfoWithStorage[127.0.0.1:39228,DS-85d36e92-f05a-4931-831b-b37203fb12a2,DISK], DatanodeInfoWithStorage[127.0.0.1:36426,DS-c38f5731-eae0-464e-b936-b116c140211a,DISK], DatanodeInfoWithStorage[127.0.0.1:33260,DS-bfbe56d4-90ef-4cb6-ad6b-deebd3c5ad1c,DISK], DatanodeInfoWithStorage[127.0.0.1:37765,DS-cb151393-a736-4b10-96f2-a8127701870a,DISK], DatanodeInfoWithStorage[127.0.0.1:41414,DS-26a42775-86b9-4c8c-8b1b-c0ea9e225a65,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-494360660-172.17.0.5-1598189947913:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36898,DS-4fb057fe-7530-4290-8e3e-167029732a2d,DISK], DatanodeInfoWithStorage[127.0.0.1:33443,DS-87bdd89d-b174-4253-8de6-76b42cd15d33,DISK], DatanodeInfoWithStorage[127.0.0.1:35367,DS-08a87a82-cf54-4778-96e4-66d9ca276795,DISK], DatanodeInfoWithStorage[127.0.0.1:39228,DS-85d36e92-f05a-4931-831b-b37203fb12a2,DISK], DatanodeInfoWithStorage[127.0.0.1:36426,DS-c38f5731-eae0-464e-b936-b116c140211a,DISK], DatanodeInfoWithStorage[127.0.0.1:33260,DS-bfbe56d4-90ef-4cb6-ad6b-deebd3c5ad1c,DISK], DatanodeInfoWithStorage[127.0.0.1:37765,DS-cb151393-a736-4b10-96f2-a8127701870a,DISK], DatanodeInfoWithStorage[127.0.0.1:41414,DS-26a42775-86b9-4c8c-8b1b-c0ea9e225a65,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.quota.by.storage.type.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-607394302-172.17.0.5-1598190018112:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44052,DS-4291ccd6-b796-4f6d-b35a-39e6db2282c9,DISK], DatanodeInfoWithStorage[127.0.0.1:37261,DS-30691502-c319-4819-a97c-555850ef8904,DISK], DatanodeInfoWithStorage[127.0.0.1:37562,DS-8eff206c-792f-4cf7-9850-da27bf4a5d53,DISK], DatanodeInfoWithStorage[127.0.0.1:38074,DS-1961dce1-d8e0-4475-9a35-544287b6aafe,DISK], DatanodeInfoWithStorage[127.0.0.1:35589,DS-55265d9d-b36b-41ff-b516-53ff8dd9e4eb,DISK], DatanodeInfoWithStorage[127.0.0.1:40759,DS-30d5ec0d-1bb7-46a2-9a6d-1da7b7635711,DISK], DatanodeInfoWithStorage[127.0.0.1:42607,DS-12f899dc-32ec-4a54-a1fc-eebcb5b54e08,DISK], DatanodeInfoWithStorage[127.0.0.1:35812,DS-3e496579-8e11-4dc1-9352-bbb0445ec1bd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-607394302-172.17.0.5-1598190018112:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44052,DS-4291ccd6-b796-4f6d-b35a-39e6db2282c9,DISK], DatanodeInfoWithStorage[127.0.0.1:37261,DS-30691502-c319-4819-a97c-555850ef8904,DISK], DatanodeInfoWithStorage[127.0.0.1:37562,DS-8eff206c-792f-4cf7-9850-da27bf4a5d53,DISK], DatanodeInfoWithStorage[127.0.0.1:38074,DS-1961dce1-d8e0-4475-9a35-544287b6aafe,DISK], DatanodeInfoWithStorage[127.0.0.1:35589,DS-55265d9d-b36b-41ff-b516-53ff8dd9e4eb,DISK], DatanodeInfoWithStorage[127.0.0.1:40759,DS-30d5ec0d-1bb7-46a2-9a6d-1da7b7635711,DISK], DatanodeInfoWithStorage[127.0.0.1:42607,DS-12f899dc-32ec-4a54-a1fc-eebcb5b54e08,DISK], DatanodeInfoWithStorage[127.0.0.1:35812,DS-3e496579-8e11-4dc1-9352-bbb0445ec1bd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 16 out of 50
result: false positive !!!
Total execution time in seconds : 5688
