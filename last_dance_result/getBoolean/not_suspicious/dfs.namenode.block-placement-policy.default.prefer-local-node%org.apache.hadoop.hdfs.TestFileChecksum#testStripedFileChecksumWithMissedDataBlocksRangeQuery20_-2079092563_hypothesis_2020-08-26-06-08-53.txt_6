reconf_parameter: dfs.namenode.block-placement-policy.default.prefer-local-node
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.block-placement-policy.default.prefer-local-node
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-451571162-172.17.0.14-1598422375189:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40680,DS-9c959935-761a-4764-a384-cd02574fec28,DISK], DatanodeInfoWithStorage[127.0.0.1:44186,DS-c9fa5cfb-1fc9-4825-ad2b-a7ae9e7d8c2b,DISK], DatanodeInfoWithStorage[127.0.0.1:45661,DS-4832c66b-dbd2-409d-b96f-311618de1dcf,DISK], DatanodeInfoWithStorage[127.0.0.1:43071,DS-7496229b-e0b6-41a1-9a61-3864a8014ccc,DISK], DatanodeInfoWithStorage[127.0.0.1:43540,DS-0da10e3a-d8eb-4263-b781-39e4a1ee49b4,DISK], DatanodeInfoWithStorage[127.0.0.1:46632,DS-7eee0f73-3486-4a90-b226-97f47204d9e3,DISK], DatanodeInfoWithStorage[127.0.0.1:34640,DS-2b4cc512-41b9-4458-85c2-09ccba61a2af,DISK], DatanodeInfoWithStorage[127.0.0.1:38980,DS-ae27652d-a38a-45db-927e-c77bb4abc82d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-451571162-172.17.0.14-1598422375189:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40680,DS-9c959935-761a-4764-a384-cd02574fec28,DISK], DatanodeInfoWithStorage[127.0.0.1:44186,DS-c9fa5cfb-1fc9-4825-ad2b-a7ae9e7d8c2b,DISK], DatanodeInfoWithStorage[127.0.0.1:45661,DS-4832c66b-dbd2-409d-b96f-311618de1dcf,DISK], DatanodeInfoWithStorage[127.0.0.1:43071,DS-7496229b-e0b6-41a1-9a61-3864a8014ccc,DISK], DatanodeInfoWithStorage[127.0.0.1:43540,DS-0da10e3a-d8eb-4263-b781-39e4a1ee49b4,DISK], DatanodeInfoWithStorage[127.0.0.1:46632,DS-7eee0f73-3486-4a90-b226-97f47204d9e3,DISK], DatanodeInfoWithStorage[127.0.0.1:34640,DS-2b4cc512-41b9-4458-85c2-09ccba61a2af,DISK], DatanodeInfoWithStorage[127.0.0.1:38980,DS-ae27652d-a38a-45db-927e-c77bb4abc82d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.block-placement-policy.default.prefer-local-node
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1161668324-172.17.0.14-1598422625990:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36697,DS-52500822-db9c-4b0a-9b33-c74f3fc5cadf,DISK], DatanodeInfoWithStorage[127.0.0.1:40992,DS-b3a41209-bf66-40a3-9227-6778926ff42a,DISK], DatanodeInfoWithStorage[127.0.0.1:33927,DS-2e5d2d5b-e551-4474-82a3-5755005c75dd,DISK], DatanodeInfoWithStorage[127.0.0.1:33047,DS-63103f1e-311a-4465-9197-2d71470b7dda,DISK], DatanodeInfoWithStorage[127.0.0.1:43088,DS-89e18ba3-a883-4304-a0b4-b0fc61a29666,DISK], DatanodeInfoWithStorage[127.0.0.1:42005,DS-a4cd043e-f428-4156-9dfb-67e085d91503,DISK], DatanodeInfoWithStorage[127.0.0.1:43306,DS-402790a8-42ef-41b1-b8c5-c15622e80cb8,DISK], DatanodeInfoWithStorage[127.0.0.1:46728,DS-4ff249bc-302e-4298-a028-e25c2f73b934,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1161668324-172.17.0.14-1598422625990:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36697,DS-52500822-db9c-4b0a-9b33-c74f3fc5cadf,DISK], DatanodeInfoWithStorage[127.0.0.1:40992,DS-b3a41209-bf66-40a3-9227-6778926ff42a,DISK], DatanodeInfoWithStorage[127.0.0.1:33927,DS-2e5d2d5b-e551-4474-82a3-5755005c75dd,DISK], DatanodeInfoWithStorage[127.0.0.1:33047,DS-63103f1e-311a-4465-9197-2d71470b7dda,DISK], DatanodeInfoWithStorage[127.0.0.1:43088,DS-89e18ba3-a883-4304-a0b4-b0fc61a29666,DISK], DatanodeInfoWithStorage[127.0.0.1:42005,DS-a4cd043e-f428-4156-9dfb-67e085d91503,DISK], DatanodeInfoWithStorage[127.0.0.1:43306,DS-402790a8-42ef-41b1-b8c5-c15622e80cb8,DISK], DatanodeInfoWithStorage[127.0.0.1:46728,DS-4ff249bc-302e-4298-a028-e25c2f73b934,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.block-placement-policy.default.prefer-local-node
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-503816000-172.17.0.14-1598423442069:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45951,DS-3460cabe-bb57-49a9-b798-79456b6bde60,DISK], DatanodeInfoWithStorage[127.0.0.1:43691,DS-3458c3ab-24fb-477d-b49c-b44f8f255309,DISK], DatanodeInfoWithStorage[127.0.0.1:45698,DS-20f877c2-410e-4339-ba02-c429120253a7,DISK], DatanodeInfoWithStorage[127.0.0.1:40681,DS-fd849525-65ad-4c3e-aa67-9dd8a53c71fe,DISK], DatanodeInfoWithStorage[127.0.0.1:34418,DS-a00e5e02-ea0a-4a3d-b1c0-105d85361593,DISK], DatanodeInfoWithStorage[127.0.0.1:34255,DS-9f180c6b-79b6-4dc2-a783-f9e8a647a5d9,DISK], DatanodeInfoWithStorage[127.0.0.1:37881,DS-370504cc-a0b8-4e7f-83f1-5b3fddcf80ca,DISK], DatanodeInfoWithStorage[127.0.0.1:34074,DS-ea42d1f2-d528-461d-a36e-4d1ea2af4018,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-503816000-172.17.0.14-1598423442069:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45951,DS-3460cabe-bb57-49a9-b798-79456b6bde60,DISK], DatanodeInfoWithStorage[127.0.0.1:43691,DS-3458c3ab-24fb-477d-b49c-b44f8f255309,DISK], DatanodeInfoWithStorage[127.0.0.1:45698,DS-20f877c2-410e-4339-ba02-c429120253a7,DISK], DatanodeInfoWithStorage[127.0.0.1:40681,DS-fd849525-65ad-4c3e-aa67-9dd8a53c71fe,DISK], DatanodeInfoWithStorage[127.0.0.1:34418,DS-a00e5e02-ea0a-4a3d-b1c0-105d85361593,DISK], DatanodeInfoWithStorage[127.0.0.1:34255,DS-9f180c6b-79b6-4dc2-a783-f9e8a647a5d9,DISK], DatanodeInfoWithStorage[127.0.0.1:37881,DS-370504cc-a0b8-4e7f-83f1-5b3fddcf80ca,DISK], DatanodeInfoWithStorage[127.0.0.1:34074,DS-ea42d1f2-d528-461d-a36e-4d1ea2af4018,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.block-placement-policy.default.prefer-local-node
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1456863784-172.17.0.14-1598423476372:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44408,DS-a69c6442-5357-44e1-bbf3-bd5ae4f56e7a,DISK], DatanodeInfoWithStorage[127.0.0.1:45604,DS-c820838e-3ce2-4e51-8cc8-dff9070d38da,DISK], DatanodeInfoWithStorage[127.0.0.1:34124,DS-787eb755-597d-444b-989f-72858b3c8c47,DISK], DatanodeInfoWithStorage[127.0.0.1:44562,DS-12920769-ab9f-4ddc-b2bd-8b9b2ab16c22,DISK], DatanodeInfoWithStorage[127.0.0.1:40843,DS-03bc9fc3-1f8c-41d9-8c8a-914dfbf41a93,DISK], DatanodeInfoWithStorage[127.0.0.1:41720,DS-eb7d4b5f-f3c7-4934-b1b8-7d603a40e65e,DISK], DatanodeInfoWithStorage[127.0.0.1:34520,DS-95c60c83-f369-4067-ae6f-2d189baa92aa,DISK], DatanodeInfoWithStorage[127.0.0.1:43098,DS-aabf1fef-324c-4d40-8ebc-c9d4070fb18e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1456863784-172.17.0.14-1598423476372:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44408,DS-a69c6442-5357-44e1-bbf3-bd5ae4f56e7a,DISK], DatanodeInfoWithStorage[127.0.0.1:45604,DS-c820838e-3ce2-4e51-8cc8-dff9070d38da,DISK], DatanodeInfoWithStorage[127.0.0.1:34124,DS-787eb755-597d-444b-989f-72858b3c8c47,DISK], DatanodeInfoWithStorage[127.0.0.1:44562,DS-12920769-ab9f-4ddc-b2bd-8b9b2ab16c22,DISK], DatanodeInfoWithStorage[127.0.0.1:40843,DS-03bc9fc3-1f8c-41d9-8c8a-914dfbf41a93,DISK], DatanodeInfoWithStorage[127.0.0.1:41720,DS-eb7d4b5f-f3c7-4934-b1b8-7d603a40e65e,DISK], DatanodeInfoWithStorage[127.0.0.1:34520,DS-95c60c83-f369-4067-ae6f-2d189baa92aa,DISK], DatanodeInfoWithStorage[127.0.0.1:43098,DS-aabf1fef-324c-4d40-8ebc-c9d4070fb18e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.block-placement-policy.default.prefer-local-node
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-498579765-172.17.0.14-1598423886013:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41358,DS-db42d98e-f49c-4903-93f7-8ae9c07475df,DISK], DatanodeInfoWithStorage[127.0.0.1:40611,DS-6f389231-ff4d-475e-9a28-81d85a7884a9,DISK], DatanodeInfoWithStorage[127.0.0.1:36637,DS-66426a97-4d1c-481c-b1f1-edf5c7ea68ee,DISK], DatanodeInfoWithStorage[127.0.0.1:33128,DS-83630045-7cd0-4b06-92fb-8a6597677dfa,DISK], DatanodeInfoWithStorage[127.0.0.1:34434,DS-83b9ea12-03b0-4849-939e-ed44d8a16d4b,DISK], DatanodeInfoWithStorage[127.0.0.1:42334,DS-0e007a1e-989f-45a8-a241-5bc7a9e9cda4,DISK], DatanodeInfoWithStorage[127.0.0.1:43870,DS-83cbf41b-9f8b-4136-b604-70dea729c080,DISK], DatanodeInfoWithStorage[127.0.0.1:35504,DS-8053e01d-88d7-45e8-9ae9-6fb43f10c12c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-498579765-172.17.0.14-1598423886013:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41358,DS-db42d98e-f49c-4903-93f7-8ae9c07475df,DISK], DatanodeInfoWithStorage[127.0.0.1:40611,DS-6f389231-ff4d-475e-9a28-81d85a7884a9,DISK], DatanodeInfoWithStorage[127.0.0.1:36637,DS-66426a97-4d1c-481c-b1f1-edf5c7ea68ee,DISK], DatanodeInfoWithStorage[127.0.0.1:33128,DS-83630045-7cd0-4b06-92fb-8a6597677dfa,DISK], DatanodeInfoWithStorage[127.0.0.1:34434,DS-83b9ea12-03b0-4849-939e-ed44d8a16d4b,DISK], DatanodeInfoWithStorage[127.0.0.1:42334,DS-0e007a1e-989f-45a8-a241-5bc7a9e9cda4,DISK], DatanodeInfoWithStorage[127.0.0.1:43870,DS-83cbf41b-9f8b-4136-b604-70dea729c080,DISK], DatanodeInfoWithStorage[127.0.0.1:35504,DS-8053e01d-88d7-45e8-9ae9-6fb43f10c12c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.block-placement-policy.default.prefer-local-node
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1252480941-172.17.0.14-1598423915413:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41158,DS-3bf77782-b2c4-42da-9f95-9b1f8557e5f8,DISK], DatanodeInfoWithStorage[127.0.0.1:40890,DS-95e18fde-8a76-494b-a099-bbf1af9668ed,DISK], DatanodeInfoWithStorage[127.0.0.1:38185,DS-058cc1aa-4fda-4f14-828c-dac8cc6d35cb,DISK], DatanodeInfoWithStorage[127.0.0.1:42849,DS-db48b009-f64b-4b7f-99a9-1b8aa03e34a7,DISK], DatanodeInfoWithStorage[127.0.0.1:35654,DS-80e9a859-8f4c-4dc3-b111-004ac5a5d1ac,DISK], DatanodeInfoWithStorage[127.0.0.1:37493,DS-aec6e5c5-0d8a-4df7-a145-fa2ee2270a90,DISK], DatanodeInfoWithStorage[127.0.0.1:40843,DS-d68877e7-ae2d-4b96-8119-bf4df6023846,DISK], DatanodeInfoWithStorage[127.0.0.1:34024,DS-e773739b-5274-4ddb-9099-251a3adf3039,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1252480941-172.17.0.14-1598423915413:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41158,DS-3bf77782-b2c4-42da-9f95-9b1f8557e5f8,DISK], DatanodeInfoWithStorage[127.0.0.1:40890,DS-95e18fde-8a76-494b-a099-bbf1af9668ed,DISK], DatanodeInfoWithStorage[127.0.0.1:38185,DS-058cc1aa-4fda-4f14-828c-dac8cc6d35cb,DISK], DatanodeInfoWithStorage[127.0.0.1:42849,DS-db48b009-f64b-4b7f-99a9-1b8aa03e34a7,DISK], DatanodeInfoWithStorage[127.0.0.1:35654,DS-80e9a859-8f4c-4dc3-b111-004ac5a5d1ac,DISK], DatanodeInfoWithStorage[127.0.0.1:37493,DS-aec6e5c5-0d8a-4df7-a145-fa2ee2270a90,DISK], DatanodeInfoWithStorage[127.0.0.1:40843,DS-d68877e7-ae2d-4b96-8119-bf4df6023846,DISK], DatanodeInfoWithStorage[127.0.0.1:34024,DS-e773739b-5274-4ddb-9099-251a3adf3039,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.block-placement-policy.default.prefer-local-node
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-125411658-172.17.0.14-1598424092781:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46718,DS-4067493e-7037-4948-b5c3-5bc73865f77b,DISK], DatanodeInfoWithStorage[127.0.0.1:40179,DS-9fc5cbef-fe1b-4d1b-88b1-8e0821258446,DISK], DatanodeInfoWithStorage[127.0.0.1:34644,DS-c0189716-11f1-4a54-bca9-d5b27004733d,DISK], DatanodeInfoWithStorage[127.0.0.1:44965,DS-56700b5e-3788-42a3-b943-7b4a7bf680e6,DISK], DatanodeInfoWithStorage[127.0.0.1:38399,DS-42b667cd-4d88-4f0c-8e9b-9f8698f947c4,DISK], DatanodeInfoWithStorage[127.0.0.1:41231,DS-957d36d1-ccc7-44b1-a80b-72f9853b4c51,DISK], DatanodeInfoWithStorage[127.0.0.1:34855,DS-b1e2a24f-b6ab-4a10-8368-cb03c7b2168f,DISK], DatanodeInfoWithStorage[127.0.0.1:44260,DS-a316169c-dfce-4306-b00f-5dc9eebb7c27,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-125411658-172.17.0.14-1598424092781:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46718,DS-4067493e-7037-4948-b5c3-5bc73865f77b,DISK], DatanodeInfoWithStorage[127.0.0.1:40179,DS-9fc5cbef-fe1b-4d1b-88b1-8e0821258446,DISK], DatanodeInfoWithStorage[127.0.0.1:34644,DS-c0189716-11f1-4a54-bca9-d5b27004733d,DISK], DatanodeInfoWithStorage[127.0.0.1:44965,DS-56700b5e-3788-42a3-b943-7b4a7bf680e6,DISK], DatanodeInfoWithStorage[127.0.0.1:38399,DS-42b667cd-4d88-4f0c-8e9b-9f8698f947c4,DISK], DatanodeInfoWithStorage[127.0.0.1:41231,DS-957d36d1-ccc7-44b1-a80b-72f9853b4c51,DISK], DatanodeInfoWithStorage[127.0.0.1:34855,DS-b1e2a24f-b6ab-4a10-8368-cb03c7b2168f,DISK], DatanodeInfoWithStorage[127.0.0.1:44260,DS-a316169c-dfce-4306-b00f-5dc9eebb7c27,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.block-placement-policy.default.prefer-local-node
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1255002382-172.17.0.14-1598424640879:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39473,DS-e5bc977d-c34d-4243-a89e-ccc06a59c8b7,DISK], DatanodeInfoWithStorage[127.0.0.1:45623,DS-1065afa9-3b76-402e-a500-d0b830260cb0,DISK], DatanodeInfoWithStorage[127.0.0.1:41640,DS-ded1d777-b52a-4d02-a2c0-aca2d34a3ce5,DISK], DatanodeInfoWithStorage[127.0.0.1:33638,DS-9fdc031c-730f-4ceb-a8a4-4a9e54d4525f,DISK], DatanodeInfoWithStorage[127.0.0.1:37674,DS-ae60e82c-ca49-4a33-99a5-29e30cd523fa,DISK], DatanodeInfoWithStorage[127.0.0.1:42353,DS-28edad52-c6ac-43ed-a1e8-94707c855071,DISK], DatanodeInfoWithStorage[127.0.0.1:41501,DS-788d670a-0267-4512-8d91-c8836b58b257,DISK], DatanodeInfoWithStorage[127.0.0.1:36096,DS-6cf3b0ec-872b-4dcd-9e3f-0e64957a9995,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1255002382-172.17.0.14-1598424640879:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39473,DS-e5bc977d-c34d-4243-a89e-ccc06a59c8b7,DISK], DatanodeInfoWithStorage[127.0.0.1:45623,DS-1065afa9-3b76-402e-a500-d0b830260cb0,DISK], DatanodeInfoWithStorage[127.0.0.1:41640,DS-ded1d777-b52a-4d02-a2c0-aca2d34a3ce5,DISK], DatanodeInfoWithStorage[127.0.0.1:33638,DS-9fdc031c-730f-4ceb-a8a4-4a9e54d4525f,DISK], DatanodeInfoWithStorage[127.0.0.1:37674,DS-ae60e82c-ca49-4a33-99a5-29e30cd523fa,DISK], DatanodeInfoWithStorage[127.0.0.1:42353,DS-28edad52-c6ac-43ed-a1e8-94707c855071,DISK], DatanodeInfoWithStorage[127.0.0.1:41501,DS-788d670a-0267-4512-8d91-c8836b58b257,DISK], DatanodeInfoWithStorage[127.0.0.1:36096,DS-6cf3b0ec-872b-4dcd-9e3f-0e64957a9995,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.block-placement-policy.default.prefer-local-node
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-554064517-172.17.0.14-1598424952065:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43195,DS-db5598c2-4c0b-475b-befe-76a1661a489a,DISK], DatanodeInfoWithStorage[127.0.0.1:35831,DS-4892410a-4421-4134-96c5-98fb5979de6c,DISK], DatanodeInfoWithStorage[127.0.0.1:34879,DS-58f45f51-d69e-4108-aaba-e2d7e7bde5a1,DISK], DatanodeInfoWithStorage[127.0.0.1:45005,DS-d2a3bd6c-4bbc-4754-9d38-2bf2815ffbd1,DISK], DatanodeInfoWithStorage[127.0.0.1:33026,DS-cbe9b583-77b1-4a25-a115-95d44fe76fb8,DISK], DatanodeInfoWithStorage[127.0.0.1:40001,DS-4391acd7-6d3a-42b4-89dc-98b0409abf52,DISK], DatanodeInfoWithStorage[127.0.0.1:34034,DS-e19365b3-1206-4ffe-a046-0efa18a86080,DISK], DatanodeInfoWithStorage[127.0.0.1:33390,DS-a6ebae8f-3538-48c0-ad67-b6c47640720a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-554064517-172.17.0.14-1598424952065:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43195,DS-db5598c2-4c0b-475b-befe-76a1661a489a,DISK], DatanodeInfoWithStorage[127.0.0.1:35831,DS-4892410a-4421-4134-96c5-98fb5979de6c,DISK], DatanodeInfoWithStorage[127.0.0.1:34879,DS-58f45f51-d69e-4108-aaba-e2d7e7bde5a1,DISK], DatanodeInfoWithStorage[127.0.0.1:45005,DS-d2a3bd6c-4bbc-4754-9d38-2bf2815ffbd1,DISK], DatanodeInfoWithStorage[127.0.0.1:33026,DS-cbe9b583-77b1-4a25-a115-95d44fe76fb8,DISK], DatanodeInfoWithStorage[127.0.0.1:40001,DS-4391acd7-6d3a-42b4-89dc-98b0409abf52,DISK], DatanodeInfoWithStorage[127.0.0.1:34034,DS-e19365b3-1206-4ffe-a046-0efa18a86080,DISK], DatanodeInfoWithStorage[127.0.0.1:33390,DS-a6ebae8f-3538-48c0-ad67-b6c47640720a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.block-placement-policy.default.prefer-local-node
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1145256416-172.17.0.14-1598424988627:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45638,DS-91eef5b5-910a-416f-83a7-e2de270b7d5f,DISK], DatanodeInfoWithStorage[127.0.0.1:35642,DS-27023b51-abaa-4d9b-8d1a-842b07fd05a8,DISK], DatanodeInfoWithStorage[127.0.0.1:41661,DS-0ebce08c-9f14-4e42-b438-218126a25704,DISK], DatanodeInfoWithStorage[127.0.0.1:37866,DS-1b5ccd3c-b675-4d21-b4a7-ec38350d70ed,DISK], DatanodeInfoWithStorage[127.0.0.1:33827,DS-4bc35b71-33e8-4408-a51c-d6a52b59c535,DISK], DatanodeInfoWithStorage[127.0.0.1:33759,DS-fce4e8c8-df40-4aae-9879-2da2bbf53310,DISK], DatanodeInfoWithStorage[127.0.0.1:46723,DS-8a08bfaa-28c4-490e-87ba-7042ecc20f92,DISK], DatanodeInfoWithStorage[127.0.0.1:33443,DS-de0f1b33-f125-4d30-8fd7-ed2b031d964e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1145256416-172.17.0.14-1598424988627:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45638,DS-91eef5b5-910a-416f-83a7-e2de270b7d5f,DISK], DatanodeInfoWithStorage[127.0.0.1:35642,DS-27023b51-abaa-4d9b-8d1a-842b07fd05a8,DISK], DatanodeInfoWithStorage[127.0.0.1:41661,DS-0ebce08c-9f14-4e42-b438-218126a25704,DISK], DatanodeInfoWithStorage[127.0.0.1:37866,DS-1b5ccd3c-b675-4d21-b4a7-ec38350d70ed,DISK], DatanodeInfoWithStorage[127.0.0.1:33827,DS-4bc35b71-33e8-4408-a51c-d6a52b59c535,DISK], DatanodeInfoWithStorage[127.0.0.1:33759,DS-fce4e8c8-df40-4aae-9879-2da2bbf53310,DISK], DatanodeInfoWithStorage[127.0.0.1:46723,DS-8a08bfaa-28c4-490e-87ba-7042ecc20f92,DISK], DatanodeInfoWithStorage[127.0.0.1:33443,DS-de0f1b33-f125-4d30-8fd7-ed2b031d964e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.block-placement-policy.default.prefer-local-node
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-861375056-172.17.0.14-1598425061247:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45256,DS-94efb189-a7c3-49d6-a42e-a7690791c395,DISK], DatanodeInfoWithStorage[127.0.0.1:33597,DS-d5afa6d5-6fea-4371-873c-6a2458f00e70,DISK], DatanodeInfoWithStorage[127.0.0.1:34513,DS-24b41de0-e4c6-47bf-9985-50e7fd4709ed,DISK], DatanodeInfoWithStorage[127.0.0.1:36632,DS-f63fec7c-6e57-4cc7-9c43-eff6869d6335,DISK], DatanodeInfoWithStorage[127.0.0.1:37826,DS-d33b6c73-217f-4f51-a9bf-986aa8adb989,DISK], DatanodeInfoWithStorage[127.0.0.1:40676,DS-b337d5f0-f250-4c3b-89b7-2b34027a8e1a,DISK], DatanodeInfoWithStorage[127.0.0.1:35010,DS-da777e79-b969-4ea7-9612-e889c1502559,DISK], DatanodeInfoWithStorage[127.0.0.1:39823,DS-191c6c7b-e5ac-453e-8655-e9d59f2c5289,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-861375056-172.17.0.14-1598425061247:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45256,DS-94efb189-a7c3-49d6-a42e-a7690791c395,DISK], DatanodeInfoWithStorage[127.0.0.1:33597,DS-d5afa6d5-6fea-4371-873c-6a2458f00e70,DISK], DatanodeInfoWithStorage[127.0.0.1:34513,DS-24b41de0-e4c6-47bf-9985-50e7fd4709ed,DISK], DatanodeInfoWithStorage[127.0.0.1:36632,DS-f63fec7c-6e57-4cc7-9c43-eff6869d6335,DISK], DatanodeInfoWithStorage[127.0.0.1:37826,DS-d33b6c73-217f-4f51-a9bf-986aa8adb989,DISK], DatanodeInfoWithStorage[127.0.0.1:40676,DS-b337d5f0-f250-4c3b-89b7-2b34027a8e1a,DISK], DatanodeInfoWithStorage[127.0.0.1:35010,DS-da777e79-b969-4ea7-9612-e889c1502559,DISK], DatanodeInfoWithStorage[127.0.0.1:39823,DS-191c6c7b-e5ac-453e-8655-e9d59f2c5289,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.block-placement-policy.default.prefer-local-node
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1795626026-172.17.0.14-1598425095660:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41301,DS-590149b2-2d0d-44ac-b968-86f5cf2c32d2,DISK], DatanodeInfoWithStorage[127.0.0.1:40094,DS-c7f4d586-1901-4555-8eac-7daa1d0258c1,DISK], DatanodeInfoWithStorage[127.0.0.1:38261,DS-c2b8de2b-e1f5-4163-ae70-b7747baf4ec7,DISK], DatanodeInfoWithStorage[127.0.0.1:37530,DS-a2644b8d-f841-4082-b4cd-663260d99023,DISK], DatanodeInfoWithStorage[127.0.0.1:33080,DS-c2c4b725-37bd-4778-a53c-af8cf3f13436,DISK], DatanodeInfoWithStorage[127.0.0.1:46876,DS-edf71b15-90c7-4882-936e-d717934abb66,DISK], DatanodeInfoWithStorage[127.0.0.1:38876,DS-5dd7d53c-5f4b-4ac5-9876-a2b8030319e8,DISK], DatanodeInfoWithStorage[127.0.0.1:44245,DS-701718f9-64ce-4add-b566-321af19923f9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1795626026-172.17.0.14-1598425095660:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41301,DS-590149b2-2d0d-44ac-b968-86f5cf2c32d2,DISK], DatanodeInfoWithStorage[127.0.0.1:40094,DS-c7f4d586-1901-4555-8eac-7daa1d0258c1,DISK], DatanodeInfoWithStorage[127.0.0.1:38261,DS-c2b8de2b-e1f5-4163-ae70-b7747baf4ec7,DISK], DatanodeInfoWithStorage[127.0.0.1:37530,DS-a2644b8d-f841-4082-b4cd-663260d99023,DISK], DatanodeInfoWithStorage[127.0.0.1:33080,DS-c2c4b725-37bd-4778-a53c-af8cf3f13436,DISK], DatanodeInfoWithStorage[127.0.0.1:46876,DS-edf71b15-90c7-4882-936e-d717934abb66,DISK], DatanodeInfoWithStorage[127.0.0.1:38876,DS-5dd7d53c-5f4b-4ac5-9876-a2b8030319e8,DISK], DatanodeInfoWithStorage[127.0.0.1:44245,DS-701718f9-64ce-4add-b566-321af19923f9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.block-placement-policy.default.prefer-local-node
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-767710930-172.17.0.14-1598425362291:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40280,DS-d3934443-7b47-45f0-8870-920b2ae28835,DISK], DatanodeInfoWithStorage[127.0.0.1:41999,DS-0b6401e9-b5c6-4326-9383-4f5092182212,DISK], DatanodeInfoWithStorage[127.0.0.1:37826,DS-2949d6e8-fe46-4c71-b409-135c5d247273,DISK], DatanodeInfoWithStorage[127.0.0.1:43598,DS-9a9ec749-d8d3-439f-b917-3ef67265515e,DISK], DatanodeInfoWithStorage[127.0.0.1:45789,DS-dc5fc83d-e9a0-4f66-8fc4-b768d0d15d91,DISK], DatanodeInfoWithStorage[127.0.0.1:37172,DS-31c689d4-241d-42c5-b8bf-f677c3b20127,DISK], DatanodeInfoWithStorage[127.0.0.1:43802,DS-241b6436-39d1-403f-85ad-d118cdf7598d,DISK], DatanodeInfoWithStorage[127.0.0.1:34596,DS-b192961a-f832-44a9-812d-cfe8aced7de0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-767710930-172.17.0.14-1598425362291:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40280,DS-d3934443-7b47-45f0-8870-920b2ae28835,DISK], DatanodeInfoWithStorage[127.0.0.1:41999,DS-0b6401e9-b5c6-4326-9383-4f5092182212,DISK], DatanodeInfoWithStorage[127.0.0.1:37826,DS-2949d6e8-fe46-4c71-b409-135c5d247273,DISK], DatanodeInfoWithStorage[127.0.0.1:43598,DS-9a9ec749-d8d3-439f-b917-3ef67265515e,DISK], DatanodeInfoWithStorage[127.0.0.1:45789,DS-dc5fc83d-e9a0-4f66-8fc4-b768d0d15d91,DISK], DatanodeInfoWithStorage[127.0.0.1:37172,DS-31c689d4-241d-42c5-b8bf-f677c3b20127,DISK], DatanodeInfoWithStorage[127.0.0.1:43802,DS-241b6436-39d1-403f-85ad-d118cdf7598d,DISK], DatanodeInfoWithStorage[127.0.0.1:34596,DS-b192961a-f832-44a9-812d-cfe8aced7de0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.block-placement-policy.default.prefer-local-node
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-233530536-172.17.0.14-1598425879111:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39762,DS-79e55ede-a33f-4935-8fcd-4eaff03eca08,DISK], DatanodeInfoWithStorage[127.0.0.1:41260,DS-f72cb65b-439d-487b-9360-2a34daff9e12,DISK], DatanodeInfoWithStorage[127.0.0.1:34577,DS-41241863-3199-4e30-a2b2-1d471ae2b73f,DISK], DatanodeInfoWithStorage[127.0.0.1:35147,DS-27450f45-0e6f-41fd-917f-cfa114385ce7,DISK], DatanodeInfoWithStorage[127.0.0.1:35202,DS-ca09497f-c0d5-4577-bd17-50bb1f1508d1,DISK], DatanodeInfoWithStorage[127.0.0.1:44225,DS-ad27fc52-995d-43c1-b717-28fa14fb71b1,DISK], DatanodeInfoWithStorage[127.0.0.1:35070,DS-083b7725-6335-4999-bb4f-3c5191da3fe0,DISK], DatanodeInfoWithStorage[127.0.0.1:38501,DS-9ec8f1bc-795b-4d8b-9491-93fae4c2b4f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-233530536-172.17.0.14-1598425879111:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39762,DS-79e55ede-a33f-4935-8fcd-4eaff03eca08,DISK], DatanodeInfoWithStorage[127.0.0.1:41260,DS-f72cb65b-439d-487b-9360-2a34daff9e12,DISK], DatanodeInfoWithStorage[127.0.0.1:34577,DS-41241863-3199-4e30-a2b2-1d471ae2b73f,DISK], DatanodeInfoWithStorage[127.0.0.1:35147,DS-27450f45-0e6f-41fd-917f-cfa114385ce7,DISK], DatanodeInfoWithStorage[127.0.0.1:35202,DS-ca09497f-c0d5-4577-bd17-50bb1f1508d1,DISK], DatanodeInfoWithStorage[127.0.0.1:44225,DS-ad27fc52-995d-43c1-b717-28fa14fb71b1,DISK], DatanodeInfoWithStorage[127.0.0.1:35070,DS-083b7725-6335-4999-bb4f-3c5191da3fe0,DISK], DatanodeInfoWithStorage[127.0.0.1:38501,DS-9ec8f1bc-795b-4d8b-9491-93fae4c2b4f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.block-placement-policy.default.prefer-local-node
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1500698548-172.17.0.14-1598426158999:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45587,DS-5330257b-33aa-4e65-8380-e39ff98c430a,DISK], DatanodeInfoWithStorage[127.0.0.1:42827,DS-3cf932b5-6745-4945-be64-1de382871153,DISK], DatanodeInfoWithStorage[127.0.0.1:42878,DS-401fc44b-2228-4ecb-875f-9ff39332b555,DISK], DatanodeInfoWithStorage[127.0.0.1:33986,DS-941cbb6a-05df-4a52-92cc-957e6cf07e8a,DISK], DatanodeInfoWithStorage[127.0.0.1:42530,DS-4548af15-f004-4c3c-aac9-120895bcf23e,DISK], DatanodeInfoWithStorage[127.0.0.1:42164,DS-cdf31ade-cc07-44a2-91e6-f6e6837ecf10,DISK], DatanodeInfoWithStorage[127.0.0.1:40608,DS-8e2d2126-1fba-42ce-a788-d55c8fc2ef98,DISK], DatanodeInfoWithStorage[127.0.0.1:43610,DS-45f8ed59-5f93-4444-8a66-5450e31d32c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1500698548-172.17.0.14-1598426158999:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45587,DS-5330257b-33aa-4e65-8380-e39ff98c430a,DISK], DatanodeInfoWithStorage[127.0.0.1:42827,DS-3cf932b5-6745-4945-be64-1de382871153,DISK], DatanodeInfoWithStorage[127.0.0.1:42878,DS-401fc44b-2228-4ecb-875f-9ff39332b555,DISK], DatanodeInfoWithStorage[127.0.0.1:33986,DS-941cbb6a-05df-4a52-92cc-957e6cf07e8a,DISK], DatanodeInfoWithStorage[127.0.0.1:42530,DS-4548af15-f004-4c3c-aac9-120895bcf23e,DISK], DatanodeInfoWithStorage[127.0.0.1:42164,DS-cdf31ade-cc07-44a2-91e6-f6e6837ecf10,DISK], DatanodeInfoWithStorage[127.0.0.1:40608,DS-8e2d2126-1fba-42ce-a788-d55c8fc2ef98,DISK], DatanodeInfoWithStorage[127.0.0.1:43610,DS-45f8ed59-5f93-4444-8a66-5450e31d32c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.block-placement-policy.default.prefer-local-node
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1061866910-172.17.0.14-1598426230189:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45703,DS-a956c06f-9ab1-4305-a810-38e73d665d49,DISK], DatanodeInfoWithStorage[127.0.0.1:35540,DS-766b337e-09cc-4655-afec-0f9db3c1c897,DISK], DatanodeInfoWithStorage[127.0.0.1:36464,DS-431bdc0f-7209-4c1e-aee9-6c98c604b92c,DISK], DatanodeInfoWithStorage[127.0.0.1:40624,DS-119f4651-4910-4be8-904b-4feb4fb8cccd,DISK], DatanodeInfoWithStorage[127.0.0.1:45116,DS-8c237ceb-a83a-43bb-b711-ed56133b21f6,DISK], DatanodeInfoWithStorage[127.0.0.1:38088,DS-eee2b6b5-b12e-4e88-9c71-61732340d852,DISK], DatanodeInfoWithStorage[127.0.0.1:45933,DS-8de26d3d-bb9d-4988-a482-b6ceaf5c938c,DISK], DatanodeInfoWithStorage[127.0.0.1:37077,DS-6ca99e75-b5db-4c56-a209-cab161560414,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1061866910-172.17.0.14-1598426230189:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45703,DS-a956c06f-9ab1-4305-a810-38e73d665d49,DISK], DatanodeInfoWithStorage[127.0.0.1:35540,DS-766b337e-09cc-4655-afec-0f9db3c1c897,DISK], DatanodeInfoWithStorage[127.0.0.1:36464,DS-431bdc0f-7209-4c1e-aee9-6c98c604b92c,DISK], DatanodeInfoWithStorage[127.0.0.1:40624,DS-119f4651-4910-4be8-904b-4feb4fb8cccd,DISK], DatanodeInfoWithStorage[127.0.0.1:45116,DS-8c237ceb-a83a-43bb-b711-ed56133b21f6,DISK], DatanodeInfoWithStorage[127.0.0.1:38088,DS-eee2b6b5-b12e-4e88-9c71-61732340d852,DISK], DatanodeInfoWithStorage[127.0.0.1:45933,DS-8de26d3d-bb9d-4988-a482-b6ceaf5c938c,DISK], DatanodeInfoWithStorage[127.0.0.1:37077,DS-6ca99e75-b5db-4c56-a209-cab161560414,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.block-placement-policy.default.prefer-local-node
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1961785724-172.17.0.14-1598426637238:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33346,DS-edf0ef1b-e62d-46b4-b0fc-70b88d824400,DISK], DatanodeInfoWithStorage[127.0.0.1:36037,DS-746838fa-fa77-4a18-9080-91cde0cf5024,DISK], DatanodeInfoWithStorage[127.0.0.1:33270,DS-6ec6736d-f7f6-433e-9c2d-f0ee5876d142,DISK], DatanodeInfoWithStorage[127.0.0.1:35388,DS-f4eae9af-b209-45a0-8128-bd5aab7eeb1c,DISK], DatanodeInfoWithStorage[127.0.0.1:35971,DS-cfec8635-b20b-48f3-8f4f-30251c0dd624,DISK], DatanodeInfoWithStorage[127.0.0.1:38790,DS-347c934e-e665-4fa7-93c3-dd9029bf3d86,DISK], DatanodeInfoWithStorage[127.0.0.1:44727,DS-40db6d3d-cbff-4043-a772-2ca9cd44876f,DISK], DatanodeInfoWithStorage[127.0.0.1:39788,DS-00c0a93f-1f2f-4e64-89c6-ae6348f48041,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1961785724-172.17.0.14-1598426637238:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33346,DS-edf0ef1b-e62d-46b4-b0fc-70b88d824400,DISK], DatanodeInfoWithStorage[127.0.0.1:36037,DS-746838fa-fa77-4a18-9080-91cde0cf5024,DISK], DatanodeInfoWithStorage[127.0.0.1:33270,DS-6ec6736d-f7f6-433e-9c2d-f0ee5876d142,DISK], DatanodeInfoWithStorage[127.0.0.1:35388,DS-f4eae9af-b209-45a0-8128-bd5aab7eeb1c,DISK], DatanodeInfoWithStorage[127.0.0.1:35971,DS-cfec8635-b20b-48f3-8f4f-30251c0dd624,DISK], DatanodeInfoWithStorage[127.0.0.1:38790,DS-347c934e-e665-4fa7-93c3-dd9029bf3d86,DISK], DatanodeInfoWithStorage[127.0.0.1:44727,DS-40db6d3d-cbff-4043-a772-2ca9cd44876f,DISK], DatanodeInfoWithStorage[127.0.0.1:39788,DS-00c0a93f-1f2f-4e64-89c6-ae6348f48041,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.block-placement-policy.default.prefer-local-node
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2045525123-172.17.0.14-1598426845148:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43496,DS-b3842c3f-3574-4863-bd59-0b032581bfb0,DISK], DatanodeInfoWithStorage[127.0.0.1:37661,DS-6ea7b626-f1b1-4c63-8a23-e2b69c6cba1a,DISK], DatanodeInfoWithStorage[127.0.0.1:39056,DS-78d58574-564b-4e72-b72a-ac95d17c4d56,DISK], DatanodeInfoWithStorage[127.0.0.1:40903,DS-ffc7e63c-c4d6-4f42-90d6-69d6ff2fd3f1,DISK], DatanodeInfoWithStorage[127.0.0.1:36734,DS-8ff4e1a6-211c-435e-a76f-f8696b99c5d5,DISK], DatanodeInfoWithStorage[127.0.0.1:39549,DS-96c94cbd-848a-48d9-b7c5-5f422d491bf5,DISK], DatanodeInfoWithStorage[127.0.0.1:42245,DS-a3ef4257-047f-4645-91c5-c619ec5b47e5,DISK], DatanodeInfoWithStorage[127.0.0.1:35694,DS-5f523b55-9f92-488e-93e5-23c1c782c4e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2045525123-172.17.0.14-1598426845148:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43496,DS-b3842c3f-3574-4863-bd59-0b032581bfb0,DISK], DatanodeInfoWithStorage[127.0.0.1:37661,DS-6ea7b626-f1b1-4c63-8a23-e2b69c6cba1a,DISK], DatanodeInfoWithStorage[127.0.0.1:39056,DS-78d58574-564b-4e72-b72a-ac95d17c4d56,DISK], DatanodeInfoWithStorage[127.0.0.1:40903,DS-ffc7e63c-c4d6-4f42-90d6-69d6ff2fd3f1,DISK], DatanodeInfoWithStorage[127.0.0.1:36734,DS-8ff4e1a6-211c-435e-a76f-f8696b99c5d5,DISK], DatanodeInfoWithStorage[127.0.0.1:39549,DS-96c94cbd-848a-48d9-b7c5-5f422d491bf5,DISK], DatanodeInfoWithStorage[127.0.0.1:42245,DS-a3ef4257-047f-4645-91c5-c619ec5b47e5,DISK], DatanodeInfoWithStorage[127.0.0.1:35694,DS-5f523b55-9f92-488e-93e5-23c1c782c4e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.block-placement-policy.default.prefer-local-node
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1382759822-172.17.0.14-1598426924038:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38391,DS-3cc65f46-9ee9-421c-b8e6-d1d45112eb6d,DISK], DatanodeInfoWithStorage[127.0.0.1:37723,DS-da08ab19-7844-4ebd-985b-455ed84360ef,DISK], DatanodeInfoWithStorage[127.0.0.1:36293,DS-c4c917eb-9104-4a88-8f2c-aae9d47ddbaf,DISK], DatanodeInfoWithStorage[127.0.0.1:39374,DS-e9e7e837-2828-445b-a157-2ed48cdff8f7,DISK], DatanodeInfoWithStorage[127.0.0.1:33969,DS-520d42e4-4703-4972-84e6-30d8c9f341a3,DISK], DatanodeInfoWithStorage[127.0.0.1:35003,DS-770ae5f4-e53c-4764-9bcc-994450e8713c,DISK], DatanodeInfoWithStorage[127.0.0.1:43964,DS-2b67bfa7-4e4f-4718-a27e-461670185568,DISK], DatanodeInfoWithStorage[127.0.0.1:42642,DS-1cc0d7ce-8fc1-4dbe-aaa5-cf906e55ddab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1382759822-172.17.0.14-1598426924038:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38391,DS-3cc65f46-9ee9-421c-b8e6-d1d45112eb6d,DISK], DatanodeInfoWithStorage[127.0.0.1:37723,DS-da08ab19-7844-4ebd-985b-455ed84360ef,DISK], DatanodeInfoWithStorage[127.0.0.1:36293,DS-c4c917eb-9104-4a88-8f2c-aae9d47ddbaf,DISK], DatanodeInfoWithStorage[127.0.0.1:39374,DS-e9e7e837-2828-445b-a157-2ed48cdff8f7,DISK], DatanodeInfoWithStorage[127.0.0.1:33969,DS-520d42e4-4703-4972-84e6-30d8c9f341a3,DISK], DatanodeInfoWithStorage[127.0.0.1:35003,DS-770ae5f4-e53c-4764-9bcc-994450e8713c,DISK], DatanodeInfoWithStorage[127.0.0.1:43964,DS-2b67bfa7-4e4f-4718-a27e-461670185568,DISK], DatanodeInfoWithStorage[127.0.0.1:42642,DS-1cc0d7ce-8fc1-4dbe-aaa5-cf906e55ddab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.block-placement-policy.default.prefer-local-node
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-534617671-172.17.0.14-1598427144689:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43289,DS-df558d58-6660-4f55-b88a-2d55b40fbcaf,DISK], DatanodeInfoWithStorage[127.0.0.1:36348,DS-2db46775-97ed-4c9e-b5f1-352e3b25a04e,DISK], DatanodeInfoWithStorage[127.0.0.1:33795,DS-bc9e7bcb-533b-45bd-8fa7-aaa5e83bb792,DISK], DatanodeInfoWithStorage[127.0.0.1:36397,DS-88b0662f-ce72-4e45-8cb9-5b2aabd064e3,DISK], DatanodeInfoWithStorage[127.0.0.1:38265,DS-418325c9-1b0c-42c9-a32c-e7e8cb04832e,DISK], DatanodeInfoWithStorage[127.0.0.1:44623,DS-c59bc386-8bb9-4e70-b7ed-e77f41aa8a54,DISK], DatanodeInfoWithStorage[127.0.0.1:36213,DS-babbc39c-e6d5-460c-bfc6-fa6312a4bfcd,DISK], DatanodeInfoWithStorage[127.0.0.1:39142,DS-735189fa-34b8-4a24-a4ee-70e3fea6f272,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-534617671-172.17.0.14-1598427144689:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43289,DS-df558d58-6660-4f55-b88a-2d55b40fbcaf,DISK], DatanodeInfoWithStorage[127.0.0.1:36348,DS-2db46775-97ed-4c9e-b5f1-352e3b25a04e,DISK], DatanodeInfoWithStorage[127.0.0.1:33795,DS-bc9e7bcb-533b-45bd-8fa7-aaa5e83bb792,DISK], DatanodeInfoWithStorage[127.0.0.1:36397,DS-88b0662f-ce72-4e45-8cb9-5b2aabd064e3,DISK], DatanodeInfoWithStorage[127.0.0.1:38265,DS-418325c9-1b0c-42c9-a32c-e7e8cb04832e,DISK], DatanodeInfoWithStorage[127.0.0.1:44623,DS-c59bc386-8bb9-4e70-b7ed-e77f41aa8a54,DISK], DatanodeInfoWithStorage[127.0.0.1:36213,DS-babbc39c-e6d5-460c-bfc6-fa6312a4bfcd,DISK], DatanodeInfoWithStorage[127.0.0.1:39142,DS-735189fa-34b8-4a24-a4ee-70e3fea6f272,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 14 out of 50
result: false positive !!!
Total execution time in seconds : 5277
