reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1092500293-172.17.0.13-1598322314229:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42996,DS-d65299eb-e61a-4a30-bc06-363926308069,DISK], DatanodeInfoWithStorage[127.0.0.1:40789,DS-1763cc4e-8bf9-4905-8069-47e4739e6168,DISK], DatanodeInfoWithStorage[127.0.0.1:42044,DS-29d4c60c-0de5-462e-8f19-85caad4dec14,DISK], DatanodeInfoWithStorage[127.0.0.1:33345,DS-66192aa2-3f4f-412f-8b57-d4d8b3dd55dd,DISK], DatanodeInfoWithStorage[127.0.0.1:42404,DS-9f78427a-f7c8-4e73-9ead-3fe43a033569,DISK], DatanodeInfoWithStorage[127.0.0.1:33760,DS-5479aae4-0461-4bc8-925d-119ac14dbd83,DISK], DatanodeInfoWithStorage[127.0.0.1:38635,DS-08414302-48f5-4211-8f57-55eaa930ec5e,DISK], DatanodeInfoWithStorage[127.0.0.1:44904,DS-b7048fec-96f9-4165-b6ea-bec8c9e6281c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1092500293-172.17.0.13-1598322314229:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42996,DS-d65299eb-e61a-4a30-bc06-363926308069,DISK], DatanodeInfoWithStorage[127.0.0.1:40789,DS-1763cc4e-8bf9-4905-8069-47e4739e6168,DISK], DatanodeInfoWithStorage[127.0.0.1:42044,DS-29d4c60c-0de5-462e-8f19-85caad4dec14,DISK], DatanodeInfoWithStorage[127.0.0.1:33345,DS-66192aa2-3f4f-412f-8b57-d4d8b3dd55dd,DISK], DatanodeInfoWithStorage[127.0.0.1:42404,DS-9f78427a-f7c8-4e73-9ead-3fe43a033569,DISK], DatanodeInfoWithStorage[127.0.0.1:33760,DS-5479aae4-0461-4bc8-925d-119ac14dbd83,DISK], DatanodeInfoWithStorage[127.0.0.1:38635,DS-08414302-48f5-4211-8f57-55eaa930ec5e,DISK], DatanodeInfoWithStorage[127.0.0.1:44904,DS-b7048fec-96f9-4165-b6ea-bec8c9e6281c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1253356904-172.17.0.13-1598323188200:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41581,DS-6d2a6eb6-bc5b-481d-a74e-3e05eb7122a4,DISK], DatanodeInfoWithStorage[127.0.0.1:35991,DS-a17bbf68-236a-4457-8420-3eee81ed9f24,DISK], DatanodeInfoWithStorage[127.0.0.1:36929,DS-cd0c5aaf-d1d4-4809-ad0a-b5d7984138c6,DISK], DatanodeInfoWithStorage[127.0.0.1:37687,DS-2bd318d4-24a5-493c-b946-db1f30aa1c19,DISK], DatanodeInfoWithStorage[127.0.0.1:34601,DS-6dcd2417-47b3-466e-915b-888ec0d3431e,DISK], DatanodeInfoWithStorage[127.0.0.1:35707,DS-25d6e0c5-9f6a-4699-b436-f1df25622ff1,DISK], DatanodeInfoWithStorage[127.0.0.1:35025,DS-ad5849a4-27fe-4f98-b80e-3e09f9a75b34,DISK], DatanodeInfoWithStorage[127.0.0.1:44851,DS-60c2df6e-6b6f-4a65-8c9d-232edf52a574,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1253356904-172.17.0.13-1598323188200:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41581,DS-6d2a6eb6-bc5b-481d-a74e-3e05eb7122a4,DISK], DatanodeInfoWithStorage[127.0.0.1:35991,DS-a17bbf68-236a-4457-8420-3eee81ed9f24,DISK], DatanodeInfoWithStorage[127.0.0.1:36929,DS-cd0c5aaf-d1d4-4809-ad0a-b5d7984138c6,DISK], DatanodeInfoWithStorage[127.0.0.1:37687,DS-2bd318d4-24a5-493c-b946-db1f30aa1c19,DISK], DatanodeInfoWithStorage[127.0.0.1:34601,DS-6dcd2417-47b3-466e-915b-888ec0d3431e,DISK], DatanodeInfoWithStorage[127.0.0.1:35707,DS-25d6e0c5-9f6a-4699-b436-f1df25622ff1,DISK], DatanodeInfoWithStorage[127.0.0.1:35025,DS-ad5849a4-27fe-4f98-b80e-3e09f9a75b34,DISK], DatanodeInfoWithStorage[127.0.0.1:44851,DS-60c2df6e-6b6f-4a65-8c9d-232edf52a574,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-823753011-172.17.0.13-1598323398219:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38189,DS-1a50f342-3931-4b69-b5d9-e9658a5e8749,DISK], DatanodeInfoWithStorage[127.0.0.1:34917,DS-f5ffb7e4-8839-40b5-a73c-0f2e6d7fa87c,DISK], DatanodeInfoWithStorage[127.0.0.1:36207,DS-8b8d7eb5-b675-4a1d-9290-5c19c56b1992,DISK], DatanodeInfoWithStorage[127.0.0.1:45022,DS-fcd1c9d7-ebe4-4c3d-b5e0-bd16581fe433,DISK], DatanodeInfoWithStorage[127.0.0.1:43210,DS-9c9b7e8c-cbb0-48b8-b8b8-520285c66172,DISK], DatanodeInfoWithStorage[127.0.0.1:33538,DS-d4c82941-88cb-4c13-bfd8-7e1b72128920,DISK], DatanodeInfoWithStorage[127.0.0.1:37282,DS-9bcab856-fac5-42f6-98b7-2c13a1dc468c,DISK], DatanodeInfoWithStorage[127.0.0.1:33861,DS-2eb3592d-1089-4aab-9a4a-e87bd91be34d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-823753011-172.17.0.13-1598323398219:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38189,DS-1a50f342-3931-4b69-b5d9-e9658a5e8749,DISK], DatanodeInfoWithStorage[127.0.0.1:34917,DS-f5ffb7e4-8839-40b5-a73c-0f2e6d7fa87c,DISK], DatanodeInfoWithStorage[127.0.0.1:36207,DS-8b8d7eb5-b675-4a1d-9290-5c19c56b1992,DISK], DatanodeInfoWithStorage[127.0.0.1:45022,DS-fcd1c9d7-ebe4-4c3d-b5e0-bd16581fe433,DISK], DatanodeInfoWithStorage[127.0.0.1:43210,DS-9c9b7e8c-cbb0-48b8-b8b8-520285c66172,DISK], DatanodeInfoWithStorage[127.0.0.1:33538,DS-d4c82941-88cb-4c13-bfd8-7e1b72128920,DISK], DatanodeInfoWithStorage[127.0.0.1:37282,DS-9bcab856-fac5-42f6-98b7-2c13a1dc468c,DISK], DatanodeInfoWithStorage[127.0.0.1:33861,DS-2eb3592d-1089-4aab-9a4a-e87bd91be34d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1433075011-172.17.0.13-1598323547638:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45507,DS-d9d821fb-e3cc-4156-afd5-31147033935b,DISK], DatanodeInfoWithStorage[127.0.0.1:35455,DS-4d8cdca2-990a-44fc-815f-6e1b03209f33,DISK], DatanodeInfoWithStorage[127.0.0.1:45812,DS-84c9cbc5-2d4e-43b3-b9ae-3bbbc56ea25e,DISK], DatanodeInfoWithStorage[127.0.0.1:46753,DS-8e943924-1b90-4f88-9a40-970330ba0fc7,DISK], DatanodeInfoWithStorage[127.0.0.1:37071,DS-6207cb8f-4cb1-434e-9ffa-eefa3a99a362,DISK], DatanodeInfoWithStorage[127.0.0.1:33269,DS-f466f3ef-f1ef-4598-93b6-b9951cb2da88,DISK], DatanodeInfoWithStorage[127.0.0.1:41782,DS-e2b24849-6d5c-4f28-98b1-0accc6b1152e,DISK], DatanodeInfoWithStorage[127.0.0.1:43320,DS-cd332ab5-8724-498b-afc9-345f1f8e2687,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1433075011-172.17.0.13-1598323547638:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45507,DS-d9d821fb-e3cc-4156-afd5-31147033935b,DISK], DatanodeInfoWithStorage[127.0.0.1:35455,DS-4d8cdca2-990a-44fc-815f-6e1b03209f33,DISK], DatanodeInfoWithStorage[127.0.0.1:45812,DS-84c9cbc5-2d4e-43b3-b9ae-3bbbc56ea25e,DISK], DatanodeInfoWithStorage[127.0.0.1:46753,DS-8e943924-1b90-4f88-9a40-970330ba0fc7,DISK], DatanodeInfoWithStorage[127.0.0.1:37071,DS-6207cb8f-4cb1-434e-9ffa-eefa3a99a362,DISK], DatanodeInfoWithStorage[127.0.0.1:33269,DS-f466f3ef-f1ef-4598-93b6-b9951cb2da88,DISK], DatanodeInfoWithStorage[127.0.0.1:41782,DS-e2b24849-6d5c-4f28-98b1-0accc6b1152e,DISK], DatanodeInfoWithStorage[127.0.0.1:43320,DS-cd332ab5-8724-498b-afc9-345f1f8e2687,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-178293041-172.17.0.13-1598323940643:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41776,DS-0a547207-a0e9-4b26-af16-198bb74737ba,DISK], DatanodeInfoWithStorage[127.0.0.1:37688,DS-33cec212-75fc-45e8-9dbe-b48cb2039846,DISK], DatanodeInfoWithStorage[127.0.0.1:39846,DS-b831eb60-db5e-4cd6-8fd5-675025925787,DISK], DatanodeInfoWithStorage[127.0.0.1:38440,DS-c7cf6579-9bd7-447f-88e5-39f440375c0b,DISK], DatanodeInfoWithStorage[127.0.0.1:38499,DS-ba0ee9c1-ac48-4ed3-b50c-c8e3ac2868f0,DISK], DatanodeInfoWithStorage[127.0.0.1:46721,DS-da67e510-8976-4091-a03b-1fa593453690,DISK], DatanodeInfoWithStorage[127.0.0.1:41093,DS-53132299-0c5e-4b55-a307-750d8c9c308f,DISK], DatanodeInfoWithStorage[127.0.0.1:44215,DS-2cce9285-7fe4-49bc-a06f-bdd8bf970a4a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-178293041-172.17.0.13-1598323940643:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41776,DS-0a547207-a0e9-4b26-af16-198bb74737ba,DISK], DatanodeInfoWithStorage[127.0.0.1:37688,DS-33cec212-75fc-45e8-9dbe-b48cb2039846,DISK], DatanodeInfoWithStorage[127.0.0.1:39846,DS-b831eb60-db5e-4cd6-8fd5-675025925787,DISK], DatanodeInfoWithStorage[127.0.0.1:38440,DS-c7cf6579-9bd7-447f-88e5-39f440375c0b,DISK], DatanodeInfoWithStorage[127.0.0.1:38499,DS-ba0ee9c1-ac48-4ed3-b50c-c8e3ac2868f0,DISK], DatanodeInfoWithStorage[127.0.0.1:46721,DS-da67e510-8976-4091-a03b-1fa593453690,DISK], DatanodeInfoWithStorage[127.0.0.1:41093,DS-53132299-0c5e-4b55-a307-750d8c9c308f,DISK], DatanodeInfoWithStorage[127.0.0.1:44215,DS-2cce9285-7fe4-49bc-a06f-bdd8bf970a4a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1004035123-172.17.0.13-1598324009561:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42471,DS-7f7f169e-af3c-47fa-8fd9-7d8f6f2be80b,DISK], DatanodeInfoWithStorage[127.0.0.1:45858,DS-0d43c2a9-1783-47ad-85c1-278739885f24,DISK], DatanodeInfoWithStorage[127.0.0.1:35914,DS-5c2c7ef9-3fb8-4a01-9aa2-d4178f86665b,DISK], DatanodeInfoWithStorage[127.0.0.1:40377,DS-96355067-5b7f-4fb9-9dc7-ae74f5551c7f,DISK], DatanodeInfoWithStorage[127.0.0.1:35254,DS-b20a3d23-609c-4fce-ac97-cf7164c6eba5,DISK], DatanodeInfoWithStorage[127.0.0.1:37355,DS-1ef241d4-506c-4a37-93ec-d0ba818eaaed,DISK], DatanodeInfoWithStorage[127.0.0.1:37870,DS-add1a864-2b24-425e-b417-7824e7b1bde4,DISK], DatanodeInfoWithStorage[127.0.0.1:37365,DS-fcd8ab14-cb5b-4cec-9c00-d3877a320501,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1004035123-172.17.0.13-1598324009561:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42471,DS-7f7f169e-af3c-47fa-8fd9-7d8f6f2be80b,DISK], DatanodeInfoWithStorage[127.0.0.1:45858,DS-0d43c2a9-1783-47ad-85c1-278739885f24,DISK], DatanodeInfoWithStorage[127.0.0.1:35914,DS-5c2c7ef9-3fb8-4a01-9aa2-d4178f86665b,DISK], DatanodeInfoWithStorage[127.0.0.1:40377,DS-96355067-5b7f-4fb9-9dc7-ae74f5551c7f,DISK], DatanodeInfoWithStorage[127.0.0.1:35254,DS-b20a3d23-609c-4fce-ac97-cf7164c6eba5,DISK], DatanodeInfoWithStorage[127.0.0.1:37355,DS-1ef241d4-506c-4a37-93ec-d0ba818eaaed,DISK], DatanodeInfoWithStorage[127.0.0.1:37870,DS-add1a864-2b24-425e-b417-7824e7b1bde4,DISK], DatanodeInfoWithStorage[127.0.0.1:37365,DS-fcd8ab14-cb5b-4cec-9c00-d3877a320501,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1595562714-172.17.0.13-1598324232580:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39715,DS-477d7221-4233-492e-9260-8a109ab3dbb4,DISK], DatanodeInfoWithStorage[127.0.0.1:40620,DS-fd712bc7-5db7-4631-9798-7f00e10ac080,DISK], DatanodeInfoWithStorage[127.0.0.1:40699,DS-e4742c2a-25f3-44e4-8442-1ac61d43a472,DISK], DatanodeInfoWithStorage[127.0.0.1:41355,DS-2fca2757-9566-42a9-ae36-4e669e61d130,DISK], DatanodeInfoWithStorage[127.0.0.1:40451,DS-c464ec3b-5b13-4633-bd90-555fd9ec30d6,DISK], DatanodeInfoWithStorage[127.0.0.1:33702,DS-1097a865-d85b-4ed0-b73c-c1097152d40b,DISK], DatanodeInfoWithStorage[127.0.0.1:39811,DS-90a2fc82-243b-473d-9964-f090f4675098,DISK], DatanodeInfoWithStorage[127.0.0.1:42354,DS-917c94db-fdea-4fca-b494-b0f2d7fa2a28,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1595562714-172.17.0.13-1598324232580:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39715,DS-477d7221-4233-492e-9260-8a109ab3dbb4,DISK], DatanodeInfoWithStorage[127.0.0.1:40620,DS-fd712bc7-5db7-4631-9798-7f00e10ac080,DISK], DatanodeInfoWithStorage[127.0.0.1:40699,DS-e4742c2a-25f3-44e4-8442-1ac61d43a472,DISK], DatanodeInfoWithStorage[127.0.0.1:41355,DS-2fca2757-9566-42a9-ae36-4e669e61d130,DISK], DatanodeInfoWithStorage[127.0.0.1:40451,DS-c464ec3b-5b13-4633-bd90-555fd9ec30d6,DISK], DatanodeInfoWithStorage[127.0.0.1:33702,DS-1097a865-d85b-4ed0-b73c-c1097152d40b,DISK], DatanodeInfoWithStorage[127.0.0.1:39811,DS-90a2fc82-243b-473d-9964-f090f4675098,DISK], DatanodeInfoWithStorage[127.0.0.1:42354,DS-917c94db-fdea-4fca-b494-b0f2d7fa2a28,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1818641161-172.17.0.13-1598324268697:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43835,DS-922bbc88-ae5a-4ae3-8825-7b043e77953d,DISK], DatanodeInfoWithStorage[127.0.0.1:46107,DS-39561bc9-7b67-426f-a52c-23d756cca3de,DISK], DatanodeInfoWithStorage[127.0.0.1:39684,DS-76dba15a-c81f-43ee-891b-f7743576f15a,DISK], DatanodeInfoWithStorage[127.0.0.1:44366,DS-5aa87d9f-6903-49f3-ae12-153a9dcfae33,DISK], DatanodeInfoWithStorage[127.0.0.1:34822,DS-646480dc-fdf2-4853-ac4e-1969cd18d00e,DISK], DatanodeInfoWithStorage[127.0.0.1:34326,DS-3684532e-f091-44ab-9683-31ce7f18b540,DISK], DatanodeInfoWithStorage[127.0.0.1:35183,DS-e89cf572-f25c-4dc0-825d-c3a6d5fec816,DISK], DatanodeInfoWithStorage[127.0.0.1:41633,DS-8c08a92e-230d-4e79-bd7b-92ebf0c556c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1818641161-172.17.0.13-1598324268697:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43835,DS-922bbc88-ae5a-4ae3-8825-7b043e77953d,DISK], DatanodeInfoWithStorage[127.0.0.1:46107,DS-39561bc9-7b67-426f-a52c-23d756cca3de,DISK], DatanodeInfoWithStorage[127.0.0.1:39684,DS-76dba15a-c81f-43ee-891b-f7743576f15a,DISK], DatanodeInfoWithStorage[127.0.0.1:44366,DS-5aa87d9f-6903-49f3-ae12-153a9dcfae33,DISK], DatanodeInfoWithStorage[127.0.0.1:34822,DS-646480dc-fdf2-4853-ac4e-1969cd18d00e,DISK], DatanodeInfoWithStorage[127.0.0.1:34326,DS-3684532e-f091-44ab-9683-31ce7f18b540,DISK], DatanodeInfoWithStorage[127.0.0.1:35183,DS-e89cf572-f25c-4dc0-825d-c3a6d5fec816,DISK], DatanodeInfoWithStorage[127.0.0.1:41633,DS-8c08a92e-230d-4e79-bd7b-92ebf0c556c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-302045540-172.17.0.13-1598324824354:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46087,DS-b7961c68-2c61-4637-bd54-561d24d81095,DISK], DatanodeInfoWithStorage[127.0.0.1:35575,DS-8665448e-4ab6-43aa-add5-da622e2519d6,DISK], DatanodeInfoWithStorage[127.0.0.1:41973,DS-3831efe0-a572-47d5-9fe8-2db64ffe5bf0,DISK], DatanodeInfoWithStorage[127.0.0.1:33535,DS-ca45141f-ad86-48e2-800e-3bb1baf9e494,DISK], DatanodeInfoWithStorage[127.0.0.1:36630,DS-0a4e6c0f-5cf7-428d-a461-02ad20dc15c7,DISK], DatanodeInfoWithStorage[127.0.0.1:43881,DS-582eced0-4cf3-40c4-aad1-67a9e00f23d9,DISK], DatanodeInfoWithStorage[127.0.0.1:34650,DS-d1cf19e7-7e35-46cb-8434-4b7d9eeac018,DISK], DatanodeInfoWithStorage[127.0.0.1:41084,DS-eabe38a9-9d53-4faf-bd10-e51fb1177fd4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-302045540-172.17.0.13-1598324824354:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46087,DS-b7961c68-2c61-4637-bd54-561d24d81095,DISK], DatanodeInfoWithStorage[127.0.0.1:35575,DS-8665448e-4ab6-43aa-add5-da622e2519d6,DISK], DatanodeInfoWithStorage[127.0.0.1:41973,DS-3831efe0-a572-47d5-9fe8-2db64ffe5bf0,DISK], DatanodeInfoWithStorage[127.0.0.1:33535,DS-ca45141f-ad86-48e2-800e-3bb1baf9e494,DISK], DatanodeInfoWithStorage[127.0.0.1:36630,DS-0a4e6c0f-5cf7-428d-a461-02ad20dc15c7,DISK], DatanodeInfoWithStorage[127.0.0.1:43881,DS-582eced0-4cf3-40c4-aad1-67a9e00f23d9,DISK], DatanodeInfoWithStorage[127.0.0.1:34650,DS-d1cf19e7-7e35-46cb-8434-4b7d9eeac018,DISK], DatanodeInfoWithStorage[127.0.0.1:41084,DS-eabe38a9-9d53-4faf-bd10-e51fb1177fd4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-268364647-172.17.0.13-1598325196298:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40373,DS-94095b57-5457-4395-a1b7-63376e0b6462,DISK], DatanodeInfoWithStorage[127.0.0.1:33861,DS-0f0a7a5e-aa9d-4efb-b521-54bcbde7ae12,DISK], DatanodeInfoWithStorage[127.0.0.1:44983,DS-e6e616e4-7202-4a3d-bd39-0a3554936841,DISK], DatanodeInfoWithStorage[127.0.0.1:37848,DS-1cadc1a5-405f-4609-82e4-60932cedb66a,DISK], DatanodeInfoWithStorage[127.0.0.1:43920,DS-079832ee-7573-4974-bfff-be54d93cb6a5,DISK], DatanodeInfoWithStorage[127.0.0.1:34751,DS-a107560d-fe73-4a7a-870e-13de7296ff94,DISK], DatanodeInfoWithStorage[127.0.0.1:32887,DS-91002e31-d1e3-4401-9770-7926b5fd30ea,DISK], DatanodeInfoWithStorage[127.0.0.1:39860,DS-4d647607-340e-465a-818d-35077917f14b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-268364647-172.17.0.13-1598325196298:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40373,DS-94095b57-5457-4395-a1b7-63376e0b6462,DISK], DatanodeInfoWithStorage[127.0.0.1:33861,DS-0f0a7a5e-aa9d-4efb-b521-54bcbde7ae12,DISK], DatanodeInfoWithStorage[127.0.0.1:44983,DS-e6e616e4-7202-4a3d-bd39-0a3554936841,DISK], DatanodeInfoWithStorage[127.0.0.1:37848,DS-1cadc1a5-405f-4609-82e4-60932cedb66a,DISK], DatanodeInfoWithStorage[127.0.0.1:43920,DS-079832ee-7573-4974-bfff-be54d93cb6a5,DISK], DatanodeInfoWithStorage[127.0.0.1:34751,DS-a107560d-fe73-4a7a-870e-13de7296ff94,DISK], DatanodeInfoWithStorage[127.0.0.1:32887,DS-91002e31-d1e3-4401-9770-7926b5fd30ea,DISK], DatanodeInfoWithStorage[127.0.0.1:39860,DS-4d647607-340e-465a-818d-35077917f14b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-418459830-172.17.0.13-1598325683517:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44579,DS-ef8fa337-d102-4b74-bb80-9ca58180dc18,DISK], DatanodeInfoWithStorage[127.0.0.1:36994,DS-221e861e-4abb-4529-85da-b4df5305aef4,DISK], DatanodeInfoWithStorage[127.0.0.1:39130,DS-0d9aa48d-d965-4c6e-82df-25474b2f3baf,DISK], DatanodeInfoWithStorage[127.0.0.1:33356,DS-d68ce640-589a-4b74-9fb2-83977435859c,DISK], DatanodeInfoWithStorage[127.0.0.1:42252,DS-e7f6dc1a-3086-4187-ae30-85b491c52744,DISK], DatanodeInfoWithStorage[127.0.0.1:43112,DS-e0456106-9331-46a9-8011-4ced29a7d89f,DISK], DatanodeInfoWithStorage[127.0.0.1:44495,DS-c516d5fd-5ce3-4417-8982-14f0a91b70e1,DISK], DatanodeInfoWithStorage[127.0.0.1:35642,DS-a25b9315-f30b-4917-9300-0a6c38def0e9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-418459830-172.17.0.13-1598325683517:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44579,DS-ef8fa337-d102-4b74-bb80-9ca58180dc18,DISK], DatanodeInfoWithStorage[127.0.0.1:36994,DS-221e861e-4abb-4529-85da-b4df5305aef4,DISK], DatanodeInfoWithStorage[127.0.0.1:39130,DS-0d9aa48d-d965-4c6e-82df-25474b2f3baf,DISK], DatanodeInfoWithStorage[127.0.0.1:33356,DS-d68ce640-589a-4b74-9fb2-83977435859c,DISK], DatanodeInfoWithStorage[127.0.0.1:42252,DS-e7f6dc1a-3086-4187-ae30-85b491c52744,DISK], DatanodeInfoWithStorage[127.0.0.1:43112,DS-e0456106-9331-46a9-8011-4ced29a7d89f,DISK], DatanodeInfoWithStorage[127.0.0.1:44495,DS-c516d5fd-5ce3-4417-8982-14f0a91b70e1,DISK], DatanodeInfoWithStorage[127.0.0.1:35642,DS-a25b9315-f30b-4917-9300-0a6c38def0e9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1388496731-172.17.0.13-1598326227057:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37711,DS-445623b3-1cfd-4f30-b77d-8793a806ed29,DISK], DatanodeInfoWithStorage[127.0.0.1:40349,DS-ec7b5ce3-e924-475c-8d8e-cf1c146eff1a,DISK], DatanodeInfoWithStorage[127.0.0.1:43093,DS-e38ec17b-c35a-4906-8061-bdd9d117a1e0,DISK], DatanodeInfoWithStorage[127.0.0.1:41902,DS-46c21b4d-2314-45d5-b517-12b042820c2a,DISK], DatanodeInfoWithStorage[127.0.0.1:46493,DS-71a99b62-f51f-4fb6-abd0-8aaaf9b9482e,DISK], DatanodeInfoWithStorage[127.0.0.1:44662,DS-4d40075d-05f5-483f-ad01-d1735f040063,DISK], DatanodeInfoWithStorage[127.0.0.1:38084,DS-7541a532-c15e-4128-8335-aa981efb0e40,DISK], DatanodeInfoWithStorage[127.0.0.1:41185,DS-81168e87-c8c4-4d81-a2bf-fe162e8f4eef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1388496731-172.17.0.13-1598326227057:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37711,DS-445623b3-1cfd-4f30-b77d-8793a806ed29,DISK], DatanodeInfoWithStorage[127.0.0.1:40349,DS-ec7b5ce3-e924-475c-8d8e-cf1c146eff1a,DISK], DatanodeInfoWithStorage[127.0.0.1:43093,DS-e38ec17b-c35a-4906-8061-bdd9d117a1e0,DISK], DatanodeInfoWithStorage[127.0.0.1:41902,DS-46c21b4d-2314-45d5-b517-12b042820c2a,DISK], DatanodeInfoWithStorage[127.0.0.1:46493,DS-71a99b62-f51f-4fb6-abd0-8aaaf9b9482e,DISK], DatanodeInfoWithStorage[127.0.0.1:44662,DS-4d40075d-05f5-483f-ad01-d1735f040063,DISK], DatanodeInfoWithStorage[127.0.0.1:38084,DS-7541a532-c15e-4128-8335-aa981efb0e40,DISK], DatanodeInfoWithStorage[127.0.0.1:41185,DS-81168e87-c8c4-4d81-a2bf-fe162e8f4eef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-556095328-172.17.0.13-1598326729305:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42204,DS-8f59c4fa-85f4-4e92-b745-c4c886475263,DISK], DatanodeInfoWithStorage[127.0.0.1:33845,DS-21392726-ad80-4450-bf6e-c9719a3b0de1,DISK], DatanodeInfoWithStorage[127.0.0.1:44226,DS-31b15410-4a95-4162-aa6c-a06522c7a4d5,DISK], DatanodeInfoWithStorage[127.0.0.1:46672,DS-761893ce-44e4-45d0-900b-6f0db628283b,DISK], DatanodeInfoWithStorage[127.0.0.1:41024,DS-3896612d-3850-4763-b224-6c6f3a9cb45d,DISK], DatanodeInfoWithStorage[127.0.0.1:44922,DS-0886b4c1-3e05-4c54-be42-0ef1e4b6cf05,DISK], DatanodeInfoWithStorage[127.0.0.1:40943,DS-d50f041f-5db8-4668-b199-ed230f85fc15,DISK], DatanodeInfoWithStorage[127.0.0.1:34215,DS-83a20f6f-153e-47a8-882d-a2dadd713c15,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-556095328-172.17.0.13-1598326729305:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42204,DS-8f59c4fa-85f4-4e92-b745-c4c886475263,DISK], DatanodeInfoWithStorage[127.0.0.1:33845,DS-21392726-ad80-4450-bf6e-c9719a3b0de1,DISK], DatanodeInfoWithStorage[127.0.0.1:44226,DS-31b15410-4a95-4162-aa6c-a06522c7a4d5,DISK], DatanodeInfoWithStorage[127.0.0.1:46672,DS-761893ce-44e4-45d0-900b-6f0db628283b,DISK], DatanodeInfoWithStorage[127.0.0.1:41024,DS-3896612d-3850-4763-b224-6c6f3a9cb45d,DISK], DatanodeInfoWithStorage[127.0.0.1:44922,DS-0886b4c1-3e05-4c54-be42-0ef1e4b6cf05,DISK], DatanodeInfoWithStorage[127.0.0.1:40943,DS-d50f041f-5db8-4668-b199-ed230f85fc15,DISK], DatanodeInfoWithStorage[127.0.0.1:34215,DS-83a20f6f-153e-47a8-882d-a2dadd713c15,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-512822081-172.17.0.13-1598327013889:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45298,DS-bf26b939-48c2-4eff-a70e-f5232d7d5715,DISK], DatanodeInfoWithStorage[127.0.0.1:38149,DS-05efa1c3-df68-431a-99a3-b0e17b0b8c8c,DISK], DatanodeInfoWithStorage[127.0.0.1:37318,DS-b53beb71-768c-4bc5-a5af-8dae371c7d09,DISK], DatanodeInfoWithStorage[127.0.0.1:34003,DS-cf0cd4e1-79ba-4d3d-b317-9b61da853973,DISK], DatanodeInfoWithStorage[127.0.0.1:45989,DS-0d042925-00ba-42fc-9130-4d2258f7eb1f,DISK], DatanodeInfoWithStorage[127.0.0.1:43218,DS-da34e6c5-42f4-47da-a01a-eefb37febf6d,DISK], DatanodeInfoWithStorage[127.0.0.1:42453,DS-d5c4a83d-804c-4c67-9c27-b9b3822ed8eb,DISK], DatanodeInfoWithStorage[127.0.0.1:38441,DS-63ce3f49-f205-4079-b22f-fd55aad5312a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-512822081-172.17.0.13-1598327013889:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45298,DS-bf26b939-48c2-4eff-a70e-f5232d7d5715,DISK], DatanodeInfoWithStorage[127.0.0.1:38149,DS-05efa1c3-df68-431a-99a3-b0e17b0b8c8c,DISK], DatanodeInfoWithStorage[127.0.0.1:37318,DS-b53beb71-768c-4bc5-a5af-8dae371c7d09,DISK], DatanodeInfoWithStorage[127.0.0.1:34003,DS-cf0cd4e1-79ba-4d3d-b317-9b61da853973,DISK], DatanodeInfoWithStorage[127.0.0.1:45989,DS-0d042925-00ba-42fc-9130-4d2258f7eb1f,DISK], DatanodeInfoWithStorage[127.0.0.1:43218,DS-da34e6c5-42f4-47da-a01a-eefb37febf6d,DISK], DatanodeInfoWithStorage[127.0.0.1:42453,DS-d5c4a83d-804c-4c67-9c27-b9b3822ed8eb,DISK], DatanodeInfoWithStorage[127.0.0.1:38441,DS-63ce3f49-f205-4079-b22f-fd55aad5312a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1221151169-172.17.0.13-1598327275126:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45547,DS-80b3f10d-485b-4465-a7d2-5ea97f312cd9,DISK], DatanodeInfoWithStorage[127.0.0.1:46251,DS-5c4a0115-1798-4804-8fe4-ba2357d9333e,DISK], DatanodeInfoWithStorage[127.0.0.1:32958,DS-945d0713-25c7-4fab-8059-9ebaadebf246,DISK], DatanodeInfoWithStorage[127.0.0.1:35601,DS-7c03aa51-ad70-4902-b20f-51e8bd23f390,DISK], DatanodeInfoWithStorage[127.0.0.1:40632,DS-fe3ddd11-6d32-4c20-9770-5150524c61ba,DISK], DatanodeInfoWithStorage[127.0.0.1:38717,DS-e823dcf3-c3ea-4223-8565-164583f96db5,DISK], DatanodeInfoWithStorage[127.0.0.1:39064,DS-0b941aa3-5db8-4bb1-8e17-c959de767cdc,DISK], DatanodeInfoWithStorage[127.0.0.1:46515,DS-0f05dbb2-a7b4-4bea-9a99-29a9db9370cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1221151169-172.17.0.13-1598327275126:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45547,DS-80b3f10d-485b-4465-a7d2-5ea97f312cd9,DISK], DatanodeInfoWithStorage[127.0.0.1:46251,DS-5c4a0115-1798-4804-8fe4-ba2357d9333e,DISK], DatanodeInfoWithStorage[127.0.0.1:32958,DS-945d0713-25c7-4fab-8059-9ebaadebf246,DISK], DatanodeInfoWithStorage[127.0.0.1:35601,DS-7c03aa51-ad70-4902-b20f-51e8bd23f390,DISK], DatanodeInfoWithStorage[127.0.0.1:40632,DS-fe3ddd11-6d32-4c20-9770-5150524c61ba,DISK], DatanodeInfoWithStorage[127.0.0.1:38717,DS-e823dcf3-c3ea-4223-8565-164583f96db5,DISK], DatanodeInfoWithStorage[127.0.0.1:39064,DS-0b941aa3-5db8-4bb1-8e17-c959de767cdc,DISK], DatanodeInfoWithStorage[127.0.0.1:46515,DS-0f05dbb2-a7b4-4bea-9a99-29a9db9370cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5294
