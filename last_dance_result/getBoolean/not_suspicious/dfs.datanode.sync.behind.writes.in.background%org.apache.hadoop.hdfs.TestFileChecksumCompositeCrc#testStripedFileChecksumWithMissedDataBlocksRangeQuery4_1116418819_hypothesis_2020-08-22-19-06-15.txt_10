reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-804107075-172.17.0.13-1598123560703:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41244,DS-b27c6b78-8a6d-4071-8de5-9bdc0bc3b1d5,DISK], DatanodeInfoWithStorage[127.0.0.1:35757,DS-f9d7fe90-4b00-4b4f-847b-b8e490041017,DISK], DatanodeInfoWithStorage[127.0.0.1:44395,DS-3313496f-e200-43c3-bfee-8d2e0eb11065,DISK], DatanodeInfoWithStorage[127.0.0.1:40695,DS-0b2ae155-8067-43ad-9a78-e082b689fb61,DISK], DatanodeInfoWithStorage[127.0.0.1:40239,DS-4e739de0-c30c-435a-b3f2-137571fd21e6,DISK], DatanodeInfoWithStorage[127.0.0.1:33770,DS-1f776309-7128-46b0-9b64-0e0fb9ed99a3,DISK], DatanodeInfoWithStorage[127.0.0.1:44029,DS-9d981386-5a70-425b-905e-ae0558f9dd9c,DISK], DatanodeInfoWithStorage[127.0.0.1:38319,DS-d3902b20-170c-4501-af98-3edec0e9e01c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-804107075-172.17.0.13-1598123560703:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41244,DS-b27c6b78-8a6d-4071-8de5-9bdc0bc3b1d5,DISK], DatanodeInfoWithStorage[127.0.0.1:35757,DS-f9d7fe90-4b00-4b4f-847b-b8e490041017,DISK], DatanodeInfoWithStorage[127.0.0.1:44395,DS-3313496f-e200-43c3-bfee-8d2e0eb11065,DISK], DatanodeInfoWithStorage[127.0.0.1:40695,DS-0b2ae155-8067-43ad-9a78-e082b689fb61,DISK], DatanodeInfoWithStorage[127.0.0.1:40239,DS-4e739de0-c30c-435a-b3f2-137571fd21e6,DISK], DatanodeInfoWithStorage[127.0.0.1:33770,DS-1f776309-7128-46b0-9b64-0e0fb9ed99a3,DISK], DatanodeInfoWithStorage[127.0.0.1:44029,DS-9d981386-5a70-425b-905e-ae0558f9dd9c,DISK], DatanodeInfoWithStorage[127.0.0.1:38319,DS-d3902b20-170c-4501-af98-3edec0e9e01c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1753721765-172.17.0.13-1598123874809:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46161,DS-38d47cb5-a4da-48d8-92e4-a88a6452a11f,DISK], DatanodeInfoWithStorage[127.0.0.1:42462,DS-aa1e3c31-f954-4fd8-b74a-df79d21daa4c,DISK], DatanodeInfoWithStorage[127.0.0.1:43494,DS-5cb387af-f2c3-4f8f-8368-53b2e88ae6b8,DISK], DatanodeInfoWithStorage[127.0.0.1:42552,DS-e3cc21fe-af52-4036-a784-01daa226e3e1,DISK], DatanodeInfoWithStorage[127.0.0.1:44367,DS-ac112834-82a6-48fb-a707-a2043dcb2848,DISK], DatanodeInfoWithStorage[127.0.0.1:35210,DS-cc6d04f5-92c6-445e-ae3b-f6324e993288,DISK], DatanodeInfoWithStorage[127.0.0.1:44113,DS-6520d79c-2c50-4b4d-ad10-0ad813edee62,DISK], DatanodeInfoWithStorage[127.0.0.1:45693,DS-a37e7df1-0328-4708-9f42-30045987312b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1753721765-172.17.0.13-1598123874809:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46161,DS-38d47cb5-a4da-48d8-92e4-a88a6452a11f,DISK], DatanodeInfoWithStorage[127.0.0.1:42462,DS-aa1e3c31-f954-4fd8-b74a-df79d21daa4c,DISK], DatanodeInfoWithStorage[127.0.0.1:43494,DS-5cb387af-f2c3-4f8f-8368-53b2e88ae6b8,DISK], DatanodeInfoWithStorage[127.0.0.1:42552,DS-e3cc21fe-af52-4036-a784-01daa226e3e1,DISK], DatanodeInfoWithStorage[127.0.0.1:44367,DS-ac112834-82a6-48fb-a707-a2043dcb2848,DISK], DatanodeInfoWithStorage[127.0.0.1:35210,DS-cc6d04f5-92c6-445e-ae3b-f6324e993288,DISK], DatanodeInfoWithStorage[127.0.0.1:44113,DS-6520d79c-2c50-4b4d-ad10-0ad813edee62,DISK], DatanodeInfoWithStorage[127.0.0.1:45693,DS-a37e7df1-0328-4708-9f42-30045987312b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-787177909-172.17.0.13-1598124587580:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35830,DS-01921ad3-0abd-4987-82aa-6095bc1a8b10,DISK], DatanodeInfoWithStorage[127.0.0.1:44816,DS-5bd4ba03-4c04-4ea4-a974-25d1e3402e6e,DISK], DatanodeInfoWithStorage[127.0.0.1:34948,DS-cadddeb0-4628-4809-919f-562c7f04349e,DISK], DatanodeInfoWithStorage[127.0.0.1:45555,DS-be135bee-3943-4eb1-a82b-d0859324ca8b,DISK], DatanodeInfoWithStorage[127.0.0.1:45888,DS-20d2f62a-310c-4b24-b97e-865bfb9b8ff6,DISK], DatanodeInfoWithStorage[127.0.0.1:43307,DS-49f15544-2a3e-48e9-9a6f-1f975a76d446,DISK], DatanodeInfoWithStorage[127.0.0.1:45462,DS-2213fef4-6e2c-4f6b-9534-f941589503c5,DISK], DatanodeInfoWithStorage[127.0.0.1:39546,DS-e8290407-a8e1-4b85-98b1-84406e39a11a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-787177909-172.17.0.13-1598124587580:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35830,DS-01921ad3-0abd-4987-82aa-6095bc1a8b10,DISK], DatanodeInfoWithStorage[127.0.0.1:44816,DS-5bd4ba03-4c04-4ea4-a974-25d1e3402e6e,DISK], DatanodeInfoWithStorage[127.0.0.1:34948,DS-cadddeb0-4628-4809-919f-562c7f04349e,DISK], DatanodeInfoWithStorage[127.0.0.1:45555,DS-be135bee-3943-4eb1-a82b-d0859324ca8b,DISK], DatanodeInfoWithStorage[127.0.0.1:45888,DS-20d2f62a-310c-4b24-b97e-865bfb9b8ff6,DISK], DatanodeInfoWithStorage[127.0.0.1:43307,DS-49f15544-2a3e-48e9-9a6f-1f975a76d446,DISK], DatanodeInfoWithStorage[127.0.0.1:45462,DS-2213fef4-6e2c-4f6b-9534-f941589503c5,DISK], DatanodeInfoWithStorage[127.0.0.1:39546,DS-e8290407-a8e1-4b85-98b1-84406e39a11a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1491466416-172.17.0.13-1598124876848:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39142,DS-287c1053-f801-4be2-9653-60b6f63aafc3,DISK], DatanodeInfoWithStorage[127.0.0.1:44215,DS-2583b58e-bbc4-414e-a751-79f5ec7c3978,DISK], DatanodeInfoWithStorage[127.0.0.1:44630,DS-1c3f3472-3fc6-45c3-948f-d8c316de1b6f,DISK], DatanodeInfoWithStorage[127.0.0.1:37471,DS-a0b43b14-1619-4e1d-a81f-70d21ee1db50,DISK], DatanodeInfoWithStorage[127.0.0.1:36261,DS-7c024454-4ff1-466b-9331-4517a39db041,DISK], DatanodeInfoWithStorage[127.0.0.1:43168,DS-7985c8b4-5999-4331-a8a7-41fc87b78d79,DISK], DatanodeInfoWithStorage[127.0.0.1:41902,DS-fa9d5bb0-7053-4e17-8f18-b4702065bab9,DISK], DatanodeInfoWithStorage[127.0.0.1:37622,DS-94451723-5755-4305-957c-df87d1651c5d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1491466416-172.17.0.13-1598124876848:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39142,DS-287c1053-f801-4be2-9653-60b6f63aafc3,DISK], DatanodeInfoWithStorage[127.0.0.1:44215,DS-2583b58e-bbc4-414e-a751-79f5ec7c3978,DISK], DatanodeInfoWithStorage[127.0.0.1:44630,DS-1c3f3472-3fc6-45c3-948f-d8c316de1b6f,DISK], DatanodeInfoWithStorage[127.0.0.1:37471,DS-a0b43b14-1619-4e1d-a81f-70d21ee1db50,DISK], DatanodeInfoWithStorage[127.0.0.1:36261,DS-7c024454-4ff1-466b-9331-4517a39db041,DISK], DatanodeInfoWithStorage[127.0.0.1:43168,DS-7985c8b4-5999-4331-a8a7-41fc87b78d79,DISK], DatanodeInfoWithStorage[127.0.0.1:41902,DS-fa9d5bb0-7053-4e17-8f18-b4702065bab9,DISK], DatanodeInfoWithStorage[127.0.0.1:37622,DS-94451723-5755-4305-957c-df87d1651c5d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2024238579-172.17.0.13-1598125413336:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33724,DS-e45a650e-bfb1-4f7f-bc96-4349b65bc54b,DISK], DatanodeInfoWithStorage[127.0.0.1:38179,DS-94e96086-3619-49d3-9628-c0cd1c07537a,DISK], DatanodeInfoWithStorage[127.0.0.1:44817,DS-9776bffe-9bbc-4406-9881-f4c920770b4a,DISK], DatanodeInfoWithStorage[127.0.0.1:44842,DS-3f0cffbc-6fe4-4b92-8b64-51cdf27a5e45,DISK], DatanodeInfoWithStorage[127.0.0.1:43027,DS-46489d66-2fc0-4438-8a33-4d21d2a83c0a,DISK], DatanodeInfoWithStorage[127.0.0.1:39570,DS-e0ed39a7-d7e9-4949-bec2-b06f2ede5bca,DISK], DatanodeInfoWithStorage[127.0.0.1:37298,DS-b57d7d49-f525-47b6-a255-fab9b6ae7fd4,DISK], DatanodeInfoWithStorage[127.0.0.1:34341,DS-6dfd61b0-cfdc-4434-ba88-b6c0d589bead,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2024238579-172.17.0.13-1598125413336:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33724,DS-e45a650e-bfb1-4f7f-bc96-4349b65bc54b,DISK], DatanodeInfoWithStorage[127.0.0.1:38179,DS-94e96086-3619-49d3-9628-c0cd1c07537a,DISK], DatanodeInfoWithStorage[127.0.0.1:44817,DS-9776bffe-9bbc-4406-9881-f4c920770b4a,DISK], DatanodeInfoWithStorage[127.0.0.1:44842,DS-3f0cffbc-6fe4-4b92-8b64-51cdf27a5e45,DISK], DatanodeInfoWithStorage[127.0.0.1:43027,DS-46489d66-2fc0-4438-8a33-4d21d2a83c0a,DISK], DatanodeInfoWithStorage[127.0.0.1:39570,DS-e0ed39a7-d7e9-4949-bec2-b06f2ede5bca,DISK], DatanodeInfoWithStorage[127.0.0.1:37298,DS-b57d7d49-f525-47b6-a255-fab9b6ae7fd4,DISK], DatanodeInfoWithStorage[127.0.0.1:34341,DS-6dfd61b0-cfdc-4434-ba88-b6c0d589bead,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-607826526-172.17.0.13-1598126068092:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35127,DS-202d0cd8-fa68-4b09-af4b-822d6cb4d867,DISK], DatanodeInfoWithStorage[127.0.0.1:45413,DS-0849d269-1eac-4c78-810e-e13bf52df2f3,DISK], DatanodeInfoWithStorage[127.0.0.1:36877,DS-59b5aee4-74d6-4aa5-a795-bdbedc411195,DISK], DatanodeInfoWithStorage[127.0.0.1:36042,DS-ebabe9c5-4210-4ef3-b7b7-7db49025c9f4,DISK], DatanodeInfoWithStorage[127.0.0.1:41201,DS-ce86e95d-73b0-46fa-8a8f-6fe2ab9b68ac,DISK], DatanodeInfoWithStorage[127.0.0.1:44033,DS-de8bd501-0d11-4dc5-9834-2c8042492a09,DISK], DatanodeInfoWithStorage[127.0.0.1:35609,DS-18881750-596e-4215-b462-b57da1d676c3,DISK], DatanodeInfoWithStorage[127.0.0.1:44713,DS-a7775f67-d6fb-4304-b343-bc5b2ea566be,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-607826526-172.17.0.13-1598126068092:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35127,DS-202d0cd8-fa68-4b09-af4b-822d6cb4d867,DISK], DatanodeInfoWithStorage[127.0.0.1:45413,DS-0849d269-1eac-4c78-810e-e13bf52df2f3,DISK], DatanodeInfoWithStorage[127.0.0.1:36877,DS-59b5aee4-74d6-4aa5-a795-bdbedc411195,DISK], DatanodeInfoWithStorage[127.0.0.1:36042,DS-ebabe9c5-4210-4ef3-b7b7-7db49025c9f4,DISK], DatanodeInfoWithStorage[127.0.0.1:41201,DS-ce86e95d-73b0-46fa-8a8f-6fe2ab9b68ac,DISK], DatanodeInfoWithStorage[127.0.0.1:44033,DS-de8bd501-0d11-4dc5-9834-2c8042492a09,DISK], DatanodeInfoWithStorage[127.0.0.1:35609,DS-18881750-596e-4215-b462-b57da1d676c3,DISK], DatanodeInfoWithStorage[127.0.0.1:44713,DS-a7775f67-d6fb-4304-b343-bc5b2ea566be,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1551098354-172.17.0.13-1598126107743:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39336,DS-89f499de-eaa7-45b3-b32d-7fcdab868dcb,DISK], DatanodeInfoWithStorage[127.0.0.1:39486,DS-be141af0-42d1-4a2f-965f-f083d79afef9,DISK], DatanodeInfoWithStorage[127.0.0.1:35162,DS-5797acc5-cacf-4ded-b105-bf757590f35d,DISK], DatanodeInfoWithStorage[127.0.0.1:42251,DS-b95276bb-6854-478a-820a-17bdc3098533,DISK], DatanodeInfoWithStorage[127.0.0.1:44831,DS-1e0e5694-2ca3-4645-bfe7-c03e1efcd830,DISK], DatanodeInfoWithStorage[127.0.0.1:46154,DS-f4a63aaa-f3fc-4902-be2f-065dc4a8a246,DISK], DatanodeInfoWithStorage[127.0.0.1:33659,DS-874723b8-ef94-4707-ad89-b7c9ea462e81,DISK], DatanodeInfoWithStorage[127.0.0.1:34996,DS-fb974619-cd63-416f-abe6-9ca9eb35dcac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1551098354-172.17.0.13-1598126107743:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39336,DS-89f499de-eaa7-45b3-b32d-7fcdab868dcb,DISK], DatanodeInfoWithStorage[127.0.0.1:39486,DS-be141af0-42d1-4a2f-965f-f083d79afef9,DISK], DatanodeInfoWithStorage[127.0.0.1:35162,DS-5797acc5-cacf-4ded-b105-bf757590f35d,DISK], DatanodeInfoWithStorage[127.0.0.1:42251,DS-b95276bb-6854-478a-820a-17bdc3098533,DISK], DatanodeInfoWithStorage[127.0.0.1:44831,DS-1e0e5694-2ca3-4645-bfe7-c03e1efcd830,DISK], DatanodeInfoWithStorage[127.0.0.1:46154,DS-f4a63aaa-f3fc-4902-be2f-065dc4a8a246,DISK], DatanodeInfoWithStorage[127.0.0.1:33659,DS-874723b8-ef94-4707-ad89-b7c9ea462e81,DISK], DatanodeInfoWithStorage[127.0.0.1:34996,DS-fb974619-cd63-416f-abe6-9ca9eb35dcac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1703691676-172.17.0.13-1598126320843:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41392,DS-9d8e16bc-0202-4b28-9a47-040cadea16d2,DISK], DatanodeInfoWithStorage[127.0.0.1:44546,DS-d9d62e48-0560-4d57-8798-23a3cfefb388,DISK], DatanodeInfoWithStorage[127.0.0.1:40840,DS-7ecbd189-c2fe-4c83-a5ec-adba6476dbb6,DISK], DatanodeInfoWithStorage[127.0.0.1:44857,DS-cafc430e-19f0-41ee-b033-b84b9474da55,DISK], DatanodeInfoWithStorage[127.0.0.1:41040,DS-3b7f9a00-3ed2-43e5-8c15-d25c504a4855,DISK], DatanodeInfoWithStorage[127.0.0.1:40139,DS-5aaef501-edc0-4c30-bb0a-abb6373754bc,DISK], DatanodeInfoWithStorage[127.0.0.1:37286,DS-b41cbdab-bcf5-47f3-b63e-53515011a338,DISK], DatanodeInfoWithStorage[127.0.0.1:44799,DS-42e0b4f0-c60a-4f99-8d0a-dab67302757c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1703691676-172.17.0.13-1598126320843:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41392,DS-9d8e16bc-0202-4b28-9a47-040cadea16d2,DISK], DatanodeInfoWithStorage[127.0.0.1:44546,DS-d9d62e48-0560-4d57-8798-23a3cfefb388,DISK], DatanodeInfoWithStorage[127.0.0.1:40840,DS-7ecbd189-c2fe-4c83-a5ec-adba6476dbb6,DISK], DatanodeInfoWithStorage[127.0.0.1:44857,DS-cafc430e-19f0-41ee-b033-b84b9474da55,DISK], DatanodeInfoWithStorage[127.0.0.1:41040,DS-3b7f9a00-3ed2-43e5-8c15-d25c504a4855,DISK], DatanodeInfoWithStorage[127.0.0.1:40139,DS-5aaef501-edc0-4c30-bb0a-abb6373754bc,DISK], DatanodeInfoWithStorage[127.0.0.1:37286,DS-b41cbdab-bcf5-47f3-b63e-53515011a338,DISK], DatanodeInfoWithStorage[127.0.0.1:44799,DS-42e0b4f0-c60a-4f99-8d0a-dab67302757c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-933529258-172.17.0.13-1598126356617:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46314,DS-926a9bb7-14b1-4011-b78c-6b09b8713966,DISK], DatanodeInfoWithStorage[127.0.0.1:37336,DS-f32df6fa-5722-4754-a0fd-4c23d92eec17,DISK], DatanodeInfoWithStorage[127.0.0.1:40271,DS-efbbbc3f-0a03-4cd5-8576-495dd6809c2a,DISK], DatanodeInfoWithStorage[127.0.0.1:41058,DS-5432f56d-de0b-4bec-9041-42aed525479a,DISK], DatanodeInfoWithStorage[127.0.0.1:36086,DS-0b6555fc-eced-4fc7-937d-b372aceeeb14,DISK], DatanodeInfoWithStorage[127.0.0.1:41652,DS-29cdc5f5-ed25-4e46-b2a5-24bd516fe0c8,DISK], DatanodeInfoWithStorage[127.0.0.1:45436,DS-4beb0c06-6c6b-4de0-8d68-ced4ce1233bf,DISK], DatanodeInfoWithStorage[127.0.0.1:46799,DS-d437b4b8-ec52-43c2-915d-6bec6ab8738b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-933529258-172.17.0.13-1598126356617:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46314,DS-926a9bb7-14b1-4011-b78c-6b09b8713966,DISK], DatanodeInfoWithStorage[127.0.0.1:37336,DS-f32df6fa-5722-4754-a0fd-4c23d92eec17,DISK], DatanodeInfoWithStorage[127.0.0.1:40271,DS-efbbbc3f-0a03-4cd5-8576-495dd6809c2a,DISK], DatanodeInfoWithStorage[127.0.0.1:41058,DS-5432f56d-de0b-4bec-9041-42aed525479a,DISK], DatanodeInfoWithStorage[127.0.0.1:36086,DS-0b6555fc-eced-4fc7-937d-b372aceeeb14,DISK], DatanodeInfoWithStorage[127.0.0.1:41652,DS-29cdc5f5-ed25-4e46-b2a5-24bd516fe0c8,DISK], DatanodeInfoWithStorage[127.0.0.1:45436,DS-4beb0c06-6c6b-4de0-8d68-ced4ce1233bf,DISK], DatanodeInfoWithStorage[127.0.0.1:46799,DS-d437b4b8-ec52-43c2-915d-6bec6ab8738b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1957834395-172.17.0.13-1598126393514:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46565,DS-bfa3eb58-6993-4c67-97ce-fddf70042bd8,DISK], DatanodeInfoWithStorage[127.0.0.1:41650,DS-d72e7e6a-bc5d-4d9e-a549-03902a11a0d0,DISK], DatanodeInfoWithStorage[127.0.0.1:46704,DS-16178119-a193-4cdf-bd75-8d2f203e9b3d,DISK], DatanodeInfoWithStorage[127.0.0.1:44080,DS-e8d34100-5c43-402e-bc63-9fc65946c48b,DISK], DatanodeInfoWithStorage[127.0.0.1:41133,DS-6e064eef-f672-4502-81d0-ddfce9e683c9,DISK], DatanodeInfoWithStorage[127.0.0.1:46377,DS-e039ffa3-cd91-47d4-8404-7ea4e4c90c63,DISK], DatanodeInfoWithStorage[127.0.0.1:36231,DS-0ee458fb-6a8c-4fe0-bac7-a950bafd5882,DISK], DatanodeInfoWithStorage[127.0.0.1:43042,DS-4b89dde9-add7-4301-b1d6-3dca4dbdb8a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1957834395-172.17.0.13-1598126393514:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46565,DS-bfa3eb58-6993-4c67-97ce-fddf70042bd8,DISK], DatanodeInfoWithStorage[127.0.0.1:41650,DS-d72e7e6a-bc5d-4d9e-a549-03902a11a0d0,DISK], DatanodeInfoWithStorage[127.0.0.1:46704,DS-16178119-a193-4cdf-bd75-8d2f203e9b3d,DISK], DatanodeInfoWithStorage[127.0.0.1:44080,DS-e8d34100-5c43-402e-bc63-9fc65946c48b,DISK], DatanodeInfoWithStorage[127.0.0.1:41133,DS-6e064eef-f672-4502-81d0-ddfce9e683c9,DISK], DatanodeInfoWithStorage[127.0.0.1:46377,DS-e039ffa3-cd91-47d4-8404-7ea4e4c90c63,DISK], DatanodeInfoWithStorage[127.0.0.1:36231,DS-0ee458fb-6a8c-4fe0-bac7-a950bafd5882,DISK], DatanodeInfoWithStorage[127.0.0.1:43042,DS-4b89dde9-add7-4301-b1d6-3dca4dbdb8a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-689219505-172.17.0.13-1598126929895:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35376,DS-17ba7901-1279-4ae5-ac77-4924f3c7207d,DISK], DatanodeInfoWithStorage[127.0.0.1:39078,DS-68d6fc64-1244-431c-b8af-94ab0e26fd0c,DISK], DatanodeInfoWithStorage[127.0.0.1:41641,DS-40008d1b-2ed5-4e26-913e-56423d21ab22,DISK], DatanodeInfoWithStorage[127.0.0.1:41434,DS-3c7337d5-e11c-497f-ba32-3bcaa6bac17c,DISK], DatanodeInfoWithStorage[127.0.0.1:36658,DS-b5bb58ac-e65d-4785-b989-c91794b7961c,DISK], DatanodeInfoWithStorage[127.0.0.1:38463,DS-ba36a8bb-d654-4c26-a04d-62f11bfc0a53,DISK], DatanodeInfoWithStorage[127.0.0.1:33384,DS-23291624-1eef-4fb3-9d40-989cb2917663,DISK], DatanodeInfoWithStorage[127.0.0.1:38209,DS-5a93baef-f168-4ba8-984a-15035131de0d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-689219505-172.17.0.13-1598126929895:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35376,DS-17ba7901-1279-4ae5-ac77-4924f3c7207d,DISK], DatanodeInfoWithStorage[127.0.0.1:39078,DS-68d6fc64-1244-431c-b8af-94ab0e26fd0c,DISK], DatanodeInfoWithStorage[127.0.0.1:41641,DS-40008d1b-2ed5-4e26-913e-56423d21ab22,DISK], DatanodeInfoWithStorage[127.0.0.1:41434,DS-3c7337d5-e11c-497f-ba32-3bcaa6bac17c,DISK], DatanodeInfoWithStorage[127.0.0.1:36658,DS-b5bb58ac-e65d-4785-b989-c91794b7961c,DISK], DatanodeInfoWithStorage[127.0.0.1:38463,DS-ba36a8bb-d654-4c26-a04d-62f11bfc0a53,DISK], DatanodeInfoWithStorage[127.0.0.1:33384,DS-23291624-1eef-4fb3-9d40-989cb2917663,DISK], DatanodeInfoWithStorage[127.0.0.1:38209,DS-5a93baef-f168-4ba8-984a-15035131de0d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-321217635-172.17.0.13-1598128214884:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34398,DS-1fa124c3-efb1-4cf3-9b28-fa804c0744cc,DISK], DatanodeInfoWithStorage[127.0.0.1:35711,DS-3a27e54a-3755-445f-aebd-d455174175f1,DISK], DatanodeInfoWithStorage[127.0.0.1:38085,DS-0abd9ca1-295a-400a-9411-e5783e142631,DISK], DatanodeInfoWithStorage[127.0.0.1:35208,DS-5318570b-ebf0-467f-a1b4-730b2646427f,DISK], DatanodeInfoWithStorage[127.0.0.1:34831,DS-df349779-9057-441c-987b-5c6a278fc0ab,DISK], DatanodeInfoWithStorage[127.0.0.1:42583,DS-10b96415-e4e3-4167-8ac3-9e53bedcae8b,DISK], DatanodeInfoWithStorage[127.0.0.1:40863,DS-8280581e-30b1-485e-9de2-68d0c1288efb,DISK], DatanodeInfoWithStorage[127.0.0.1:42854,DS-0cc8be84-7441-44e6-bb45-fb4d32ddb7a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-321217635-172.17.0.13-1598128214884:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34398,DS-1fa124c3-efb1-4cf3-9b28-fa804c0744cc,DISK], DatanodeInfoWithStorage[127.0.0.1:35711,DS-3a27e54a-3755-445f-aebd-d455174175f1,DISK], DatanodeInfoWithStorage[127.0.0.1:38085,DS-0abd9ca1-295a-400a-9411-e5783e142631,DISK], DatanodeInfoWithStorage[127.0.0.1:35208,DS-5318570b-ebf0-467f-a1b4-730b2646427f,DISK], DatanodeInfoWithStorage[127.0.0.1:34831,DS-df349779-9057-441c-987b-5c6a278fc0ab,DISK], DatanodeInfoWithStorage[127.0.0.1:42583,DS-10b96415-e4e3-4167-8ac3-9e53bedcae8b,DISK], DatanodeInfoWithStorage[127.0.0.1:40863,DS-8280581e-30b1-485e-9de2-68d0c1288efb,DISK], DatanodeInfoWithStorage[127.0.0.1:42854,DS-0cc8be84-7441-44e6-bb45-fb4d32ddb7a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 7 out of 50
result: false positive !!!
Total execution time in seconds : 5132
