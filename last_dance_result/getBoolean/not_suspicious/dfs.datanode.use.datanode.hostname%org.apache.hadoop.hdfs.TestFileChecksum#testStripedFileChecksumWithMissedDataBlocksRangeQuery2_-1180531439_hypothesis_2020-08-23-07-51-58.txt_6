reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-53081456-172.17.0.4-1598169456517:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35254,DS-44cae1b4-ff23-4882-a700-ac1a5e8f5ee7,DISK], DatanodeInfoWithStorage[127.0.0.1:34488,DS-f9458954-e26f-41cb-a07c-cff686ebea8c,DISK], DatanodeInfoWithStorage[127.0.0.1:44249,DS-12bfa9ce-1380-4fec-8003-f225c016258d,DISK], DatanodeInfoWithStorage[127.0.0.1:44223,DS-6149b66a-8aca-4d25-af85-87c666b0317a,DISK], DatanodeInfoWithStorage[127.0.0.1:41785,DS-140da5e6-3abb-474c-a501-5d7ab50d3df2,DISK], DatanodeInfoWithStorage[127.0.0.1:45330,DS-3f9b321c-200b-46be-85ee-2737afa75fce,DISK], DatanodeInfoWithStorage[127.0.0.1:45966,DS-e42c66af-5ce6-45a6-8996-7332ff78fbfa,DISK], DatanodeInfoWithStorage[127.0.0.1:44407,DS-57df70c7-9a3a-4300-aaab-4ad30b42dcf5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-53081456-172.17.0.4-1598169456517:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35254,DS-44cae1b4-ff23-4882-a700-ac1a5e8f5ee7,DISK], DatanodeInfoWithStorage[127.0.0.1:34488,DS-f9458954-e26f-41cb-a07c-cff686ebea8c,DISK], DatanodeInfoWithStorage[127.0.0.1:44249,DS-12bfa9ce-1380-4fec-8003-f225c016258d,DISK], DatanodeInfoWithStorage[127.0.0.1:44223,DS-6149b66a-8aca-4d25-af85-87c666b0317a,DISK], DatanodeInfoWithStorage[127.0.0.1:41785,DS-140da5e6-3abb-474c-a501-5d7ab50d3df2,DISK], DatanodeInfoWithStorage[127.0.0.1:45330,DS-3f9b321c-200b-46be-85ee-2737afa75fce,DISK], DatanodeInfoWithStorage[127.0.0.1:45966,DS-e42c66af-5ce6-45a6-8996-7332ff78fbfa,DISK], DatanodeInfoWithStorage[127.0.0.1:44407,DS-57df70c7-9a3a-4300-aaab-4ad30b42dcf5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1296129527-172.17.0.4-1598169871438:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40190,DS-1343fc16-7328-41c8-9755-6fa387cb6f7d,DISK], DatanodeInfoWithStorage[127.0.0.1:42069,DS-e850906b-914d-4b12-9670-935368d9f34b,DISK], DatanodeInfoWithStorage[127.0.0.1:39752,DS-76188176-303e-4e09-904a-04d88c78a781,DISK], DatanodeInfoWithStorage[127.0.0.1:46847,DS-ac2403ba-85eb-4753-a4cf-189876e57506,DISK], DatanodeInfoWithStorage[127.0.0.1:33971,DS-d95f2f38-8d80-4f34-a4b5-455a37058452,DISK], DatanodeInfoWithStorage[127.0.0.1:44506,DS-279ad5c1-a50d-4095-8141-d5585323a149,DISK], DatanodeInfoWithStorage[127.0.0.1:45209,DS-93f6a8b2-3169-425f-a69f-03bd5f02c38a,DISK], DatanodeInfoWithStorage[127.0.0.1:34800,DS-dfa258fe-6ab0-48d4-ae15-0162f3bdb4ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1296129527-172.17.0.4-1598169871438:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40190,DS-1343fc16-7328-41c8-9755-6fa387cb6f7d,DISK], DatanodeInfoWithStorage[127.0.0.1:42069,DS-e850906b-914d-4b12-9670-935368d9f34b,DISK], DatanodeInfoWithStorage[127.0.0.1:39752,DS-76188176-303e-4e09-904a-04d88c78a781,DISK], DatanodeInfoWithStorage[127.0.0.1:46847,DS-ac2403ba-85eb-4753-a4cf-189876e57506,DISK], DatanodeInfoWithStorage[127.0.0.1:33971,DS-d95f2f38-8d80-4f34-a4b5-455a37058452,DISK], DatanodeInfoWithStorage[127.0.0.1:44506,DS-279ad5c1-a50d-4095-8141-d5585323a149,DISK], DatanodeInfoWithStorage[127.0.0.1:45209,DS-93f6a8b2-3169-425f-a69f-03bd5f02c38a,DISK], DatanodeInfoWithStorage[127.0.0.1:34800,DS-dfa258fe-6ab0-48d4-ae15-0162f3bdb4ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1654978144-172.17.0.4-1598170195647:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32878,DS-3c9b239c-032c-4171-bb5e-a6227a977e76,DISK], DatanodeInfoWithStorage[127.0.0.1:41190,DS-61f2a27c-0455-43ec-b597-1d0b235e6b0c,DISK], DatanodeInfoWithStorage[127.0.0.1:35736,DS-c8e20e32-0395-480a-8a27-66cba620ce9a,DISK], DatanodeInfoWithStorage[127.0.0.1:41659,DS-76553e07-08c7-45ea-8c85-117437794ec4,DISK], DatanodeInfoWithStorage[127.0.0.1:37607,DS-7fefe785-6ec3-4c13-86ea-bee23c50abb3,DISK], DatanodeInfoWithStorage[127.0.0.1:40142,DS-b8c26afb-380d-4bbb-bd57-40afe7e6a82d,DISK], DatanodeInfoWithStorage[127.0.0.1:32905,DS-eaf822da-4ca3-4eb2-bbbf-ae7e9ea20f3d,DISK], DatanodeInfoWithStorage[127.0.0.1:40710,DS-136afa6c-316b-4eb4-8a41-09503d2f3f74,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1654978144-172.17.0.4-1598170195647:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32878,DS-3c9b239c-032c-4171-bb5e-a6227a977e76,DISK], DatanodeInfoWithStorage[127.0.0.1:41190,DS-61f2a27c-0455-43ec-b597-1d0b235e6b0c,DISK], DatanodeInfoWithStorage[127.0.0.1:35736,DS-c8e20e32-0395-480a-8a27-66cba620ce9a,DISK], DatanodeInfoWithStorage[127.0.0.1:41659,DS-76553e07-08c7-45ea-8c85-117437794ec4,DISK], DatanodeInfoWithStorage[127.0.0.1:37607,DS-7fefe785-6ec3-4c13-86ea-bee23c50abb3,DISK], DatanodeInfoWithStorage[127.0.0.1:40142,DS-b8c26afb-380d-4bbb-bd57-40afe7e6a82d,DISK], DatanodeInfoWithStorage[127.0.0.1:32905,DS-eaf822da-4ca3-4eb2-bbbf-ae7e9ea20f3d,DISK], DatanodeInfoWithStorage[127.0.0.1:40710,DS-136afa6c-316b-4eb4-8a41-09503d2f3f74,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-660220633-172.17.0.4-1598170616468:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36218,DS-78c24772-815e-4530-a2c4-14e3a6c9a647,DISK], DatanodeInfoWithStorage[127.0.0.1:35274,DS-fab111fe-c7cd-40a1-bf99-fc14ed281983,DISK], DatanodeInfoWithStorage[127.0.0.1:43077,DS-f8a73f15-ab31-475d-bc8b-69b27aa65873,DISK], DatanodeInfoWithStorage[127.0.0.1:45984,DS-acd98708-d75d-4f67-8ca6-df505e61c227,DISK], DatanodeInfoWithStorage[127.0.0.1:39220,DS-476fd8a2-29f1-4f70-b0da-43447c30f169,DISK], DatanodeInfoWithStorage[127.0.0.1:36633,DS-beee1816-4228-4cd1-a76f-da04f065eb49,DISK], DatanodeInfoWithStorage[127.0.0.1:41995,DS-008313bf-2ffd-46a2-919e-01d4635a2193,DISK], DatanodeInfoWithStorage[127.0.0.1:44752,DS-4fdf45fc-8c5e-43fc-8577-3a8cd1226334,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-660220633-172.17.0.4-1598170616468:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36218,DS-78c24772-815e-4530-a2c4-14e3a6c9a647,DISK], DatanodeInfoWithStorage[127.0.0.1:35274,DS-fab111fe-c7cd-40a1-bf99-fc14ed281983,DISK], DatanodeInfoWithStorage[127.0.0.1:43077,DS-f8a73f15-ab31-475d-bc8b-69b27aa65873,DISK], DatanodeInfoWithStorage[127.0.0.1:45984,DS-acd98708-d75d-4f67-8ca6-df505e61c227,DISK], DatanodeInfoWithStorage[127.0.0.1:39220,DS-476fd8a2-29f1-4f70-b0da-43447c30f169,DISK], DatanodeInfoWithStorage[127.0.0.1:36633,DS-beee1816-4228-4cd1-a76f-da04f065eb49,DISK], DatanodeInfoWithStorage[127.0.0.1:41995,DS-008313bf-2ffd-46a2-919e-01d4635a2193,DISK], DatanodeInfoWithStorage[127.0.0.1:44752,DS-4fdf45fc-8c5e-43fc-8577-3a8cd1226334,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1931436757-172.17.0.4-1598170692133:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36513,DS-213fabb7-99f2-485c-b249-8ece72ad6754,DISK], DatanodeInfoWithStorage[127.0.0.1:33965,DS-3c8fb7b5-1f17-4503-855c-a3ae4ed93f39,DISK], DatanodeInfoWithStorage[127.0.0.1:45204,DS-d54d48fe-afd7-4976-a9a3-4d25082c5b31,DISK], DatanodeInfoWithStorage[127.0.0.1:41366,DS-756f5631-193f-4970-888d-2abc39a3d179,DISK], DatanodeInfoWithStorage[127.0.0.1:36196,DS-3d6b2831-961d-4175-a4af-20670dea46d2,DISK], DatanodeInfoWithStorage[127.0.0.1:38194,DS-68c56d1b-7c52-4867-9b97-66f1c6476c90,DISK], DatanodeInfoWithStorage[127.0.0.1:42722,DS-8613c50b-be8e-4f3d-b2ba-93f4bb505e38,DISK], DatanodeInfoWithStorage[127.0.0.1:34387,DS-365f0bfe-5bb7-4c29-9612-52d8efb2e2ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1931436757-172.17.0.4-1598170692133:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36513,DS-213fabb7-99f2-485c-b249-8ece72ad6754,DISK], DatanodeInfoWithStorage[127.0.0.1:33965,DS-3c8fb7b5-1f17-4503-855c-a3ae4ed93f39,DISK], DatanodeInfoWithStorage[127.0.0.1:45204,DS-d54d48fe-afd7-4976-a9a3-4d25082c5b31,DISK], DatanodeInfoWithStorage[127.0.0.1:41366,DS-756f5631-193f-4970-888d-2abc39a3d179,DISK], DatanodeInfoWithStorage[127.0.0.1:36196,DS-3d6b2831-961d-4175-a4af-20670dea46d2,DISK], DatanodeInfoWithStorage[127.0.0.1:38194,DS-68c56d1b-7c52-4867-9b97-66f1c6476c90,DISK], DatanodeInfoWithStorage[127.0.0.1:42722,DS-8613c50b-be8e-4f3d-b2ba-93f4bb505e38,DISK], DatanodeInfoWithStorage[127.0.0.1:34387,DS-365f0bfe-5bb7-4c29-9612-52d8efb2e2ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-511269632-172.17.0.4-1598170797791:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38669,DS-7d4d2e28-9d00-4209-8d2b-9f873435378b,DISK], DatanodeInfoWithStorage[127.0.0.1:33384,DS-7779bac3-c7a0-4e7c-b2d7-cfea375caef7,DISK], DatanodeInfoWithStorage[127.0.0.1:40779,DS-adb7495f-b437-4947-92be-c187f3d93bd4,DISK], DatanodeInfoWithStorage[127.0.0.1:46574,DS-0e5fc12b-a872-47cb-ba0c-0f6f25cc265c,DISK], DatanodeInfoWithStorage[127.0.0.1:45366,DS-31e28bf0-4303-4f73-966e-cb0274fd2e3f,DISK], DatanodeInfoWithStorage[127.0.0.1:36498,DS-ff38258c-10e6-42e3-8f21-0f802133e221,DISK], DatanodeInfoWithStorage[127.0.0.1:38158,DS-5a244f28-da8a-4696-bfb5-750441fc28b0,DISK], DatanodeInfoWithStorage[127.0.0.1:37788,DS-e2579361-df33-477e-9a50-0f1197fc4576,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-511269632-172.17.0.4-1598170797791:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38669,DS-7d4d2e28-9d00-4209-8d2b-9f873435378b,DISK], DatanodeInfoWithStorage[127.0.0.1:33384,DS-7779bac3-c7a0-4e7c-b2d7-cfea375caef7,DISK], DatanodeInfoWithStorage[127.0.0.1:40779,DS-adb7495f-b437-4947-92be-c187f3d93bd4,DISK], DatanodeInfoWithStorage[127.0.0.1:46574,DS-0e5fc12b-a872-47cb-ba0c-0f6f25cc265c,DISK], DatanodeInfoWithStorage[127.0.0.1:45366,DS-31e28bf0-4303-4f73-966e-cb0274fd2e3f,DISK], DatanodeInfoWithStorage[127.0.0.1:36498,DS-ff38258c-10e6-42e3-8f21-0f802133e221,DISK], DatanodeInfoWithStorage[127.0.0.1:38158,DS-5a244f28-da8a-4696-bfb5-750441fc28b0,DISK], DatanodeInfoWithStorage[127.0.0.1:37788,DS-e2579361-df33-477e-9a50-0f1197fc4576,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-885500721-172.17.0.4-1598171023125:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37977,DS-582dca8f-af7e-43e1-b7b2-bb346b26b8c4,DISK], DatanodeInfoWithStorage[127.0.0.1:41721,DS-ae783078-bca3-43fe-991b-272269b4d528,DISK], DatanodeInfoWithStorage[127.0.0.1:42047,DS-7190b2ed-5d84-4ff6-a636-24719e2c7d20,DISK], DatanodeInfoWithStorage[127.0.0.1:35493,DS-656e802d-b81e-4e1f-b990-5a7804faa3cd,DISK], DatanodeInfoWithStorage[127.0.0.1:43653,DS-32d80249-5ae2-43ad-bb47-da07479377c1,DISK], DatanodeInfoWithStorage[127.0.0.1:37441,DS-5385b591-52e8-4a23-9bb5-747928148dcd,DISK], DatanodeInfoWithStorage[127.0.0.1:42758,DS-053a85fc-5804-4fb4-a80e-d4c91928fe0f,DISK], DatanodeInfoWithStorage[127.0.0.1:45092,DS-d068d92a-dccf-4b5e-86c4-08233f2d0dc7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-885500721-172.17.0.4-1598171023125:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37977,DS-582dca8f-af7e-43e1-b7b2-bb346b26b8c4,DISK], DatanodeInfoWithStorage[127.0.0.1:41721,DS-ae783078-bca3-43fe-991b-272269b4d528,DISK], DatanodeInfoWithStorage[127.0.0.1:42047,DS-7190b2ed-5d84-4ff6-a636-24719e2c7d20,DISK], DatanodeInfoWithStorage[127.0.0.1:35493,DS-656e802d-b81e-4e1f-b990-5a7804faa3cd,DISK], DatanodeInfoWithStorage[127.0.0.1:43653,DS-32d80249-5ae2-43ad-bb47-da07479377c1,DISK], DatanodeInfoWithStorage[127.0.0.1:37441,DS-5385b591-52e8-4a23-9bb5-747928148dcd,DISK], DatanodeInfoWithStorage[127.0.0.1:42758,DS-053a85fc-5804-4fb4-a80e-d4c91928fe0f,DISK], DatanodeInfoWithStorage[127.0.0.1:45092,DS-d068d92a-dccf-4b5e-86c4-08233f2d0dc7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1879784268-172.17.0.4-1598171162362:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43285,DS-dbcc9017-71c7-4696-aae0-7c34ffcb1f09,DISK], DatanodeInfoWithStorage[127.0.0.1:37468,DS-c91bcad6-d842-4806-b7e8-7182f235d833,DISK], DatanodeInfoWithStorage[127.0.0.1:41331,DS-9abdf37b-4af8-4685-97de-b861af28d460,DISK], DatanodeInfoWithStorage[127.0.0.1:34503,DS-c01d0977-4f68-47c2-bb8e-3aa8aa6ab7b5,DISK], DatanodeInfoWithStorage[127.0.0.1:35419,DS-48a6a47f-b957-4dcc-87a3-918dd81181b5,DISK], DatanodeInfoWithStorage[127.0.0.1:41572,DS-5754d5e0-9e4b-407a-b59d-b25465abb70f,DISK], DatanodeInfoWithStorage[127.0.0.1:36503,DS-bfaa79b9-21ef-43cf-b054-6d0cc8842a6c,DISK], DatanodeInfoWithStorage[127.0.0.1:39622,DS-43175cc4-9801-4cc0-aa7f-a6b4b3189e77,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1879784268-172.17.0.4-1598171162362:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43285,DS-dbcc9017-71c7-4696-aae0-7c34ffcb1f09,DISK], DatanodeInfoWithStorage[127.0.0.1:37468,DS-c91bcad6-d842-4806-b7e8-7182f235d833,DISK], DatanodeInfoWithStorage[127.0.0.1:41331,DS-9abdf37b-4af8-4685-97de-b861af28d460,DISK], DatanodeInfoWithStorage[127.0.0.1:34503,DS-c01d0977-4f68-47c2-bb8e-3aa8aa6ab7b5,DISK], DatanodeInfoWithStorage[127.0.0.1:35419,DS-48a6a47f-b957-4dcc-87a3-918dd81181b5,DISK], DatanodeInfoWithStorage[127.0.0.1:41572,DS-5754d5e0-9e4b-407a-b59d-b25465abb70f,DISK], DatanodeInfoWithStorage[127.0.0.1:36503,DS-bfaa79b9-21ef-43cf-b054-6d0cc8842a6c,DISK], DatanodeInfoWithStorage[127.0.0.1:39622,DS-43175cc4-9801-4cc0-aa7f-a6b4b3189e77,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-817758344-172.17.0.4-1598172018746:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38055,DS-7db06495-f507-4cac-a11d-a9b0ba276050,DISK], DatanodeInfoWithStorage[127.0.0.1:41581,DS-5678448a-c26c-4f82-a0df-304ef62b9683,DISK], DatanodeInfoWithStorage[127.0.0.1:40810,DS-b6e2b8d9-4194-4f3f-9c74-4504de3f30ab,DISK], DatanodeInfoWithStorage[127.0.0.1:33582,DS-f6edb7ea-2f93-4ac6-bfcb-75824ad4e2f9,DISK], DatanodeInfoWithStorage[127.0.0.1:36544,DS-938b19a9-4f4b-45d3-93f2-cd4ffd764e1f,DISK], DatanodeInfoWithStorage[127.0.0.1:34264,DS-85e7fbb8-08cf-4f04-b65a-2d13eee3696a,DISK], DatanodeInfoWithStorage[127.0.0.1:35277,DS-830e3034-c721-4aa3-90c6-c0570ab6c157,DISK], DatanodeInfoWithStorage[127.0.0.1:41305,DS-868cdd51-73e6-4f7e-83c8-0130b1c9243e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-817758344-172.17.0.4-1598172018746:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38055,DS-7db06495-f507-4cac-a11d-a9b0ba276050,DISK], DatanodeInfoWithStorage[127.0.0.1:41581,DS-5678448a-c26c-4f82-a0df-304ef62b9683,DISK], DatanodeInfoWithStorage[127.0.0.1:40810,DS-b6e2b8d9-4194-4f3f-9c74-4504de3f30ab,DISK], DatanodeInfoWithStorage[127.0.0.1:33582,DS-f6edb7ea-2f93-4ac6-bfcb-75824ad4e2f9,DISK], DatanodeInfoWithStorage[127.0.0.1:36544,DS-938b19a9-4f4b-45d3-93f2-cd4ffd764e1f,DISK], DatanodeInfoWithStorage[127.0.0.1:34264,DS-85e7fbb8-08cf-4f04-b65a-2d13eee3696a,DISK], DatanodeInfoWithStorage[127.0.0.1:35277,DS-830e3034-c721-4aa3-90c6-c0570ab6c157,DISK], DatanodeInfoWithStorage[127.0.0.1:41305,DS-868cdd51-73e6-4f7e-83c8-0130b1c9243e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1227465253-172.17.0.4-1598173316176:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33759,DS-c2240473-2d3a-4534-b489-95f549a8c00a,DISK], DatanodeInfoWithStorage[127.0.0.1:43972,DS-90cd91ef-609f-4569-bbc0-7cda5e703f69,DISK], DatanodeInfoWithStorage[127.0.0.1:36423,DS-a2d2d1c8-6c18-4171-83b2-77fe3258746f,DISK], DatanodeInfoWithStorage[127.0.0.1:44167,DS-7d75c4ce-4605-4af6-904f-67d4e3bcbef9,DISK], DatanodeInfoWithStorage[127.0.0.1:39886,DS-d9c65947-ed44-4fad-877e-62f020ae66a4,DISK], DatanodeInfoWithStorage[127.0.0.1:34176,DS-24347a46-8ce8-46f9-9f43-9f80d3515711,DISK], DatanodeInfoWithStorage[127.0.0.1:39690,DS-30a4fb74-7c75-46c1-ac5a-ddb0c3168e90,DISK], DatanodeInfoWithStorage[127.0.0.1:44832,DS-35e9abb1-391b-4c67-8970-03bd791856ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1227465253-172.17.0.4-1598173316176:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33759,DS-c2240473-2d3a-4534-b489-95f549a8c00a,DISK], DatanodeInfoWithStorage[127.0.0.1:43972,DS-90cd91ef-609f-4569-bbc0-7cda5e703f69,DISK], DatanodeInfoWithStorage[127.0.0.1:36423,DS-a2d2d1c8-6c18-4171-83b2-77fe3258746f,DISK], DatanodeInfoWithStorage[127.0.0.1:44167,DS-7d75c4ce-4605-4af6-904f-67d4e3bcbef9,DISK], DatanodeInfoWithStorage[127.0.0.1:39886,DS-d9c65947-ed44-4fad-877e-62f020ae66a4,DISK], DatanodeInfoWithStorage[127.0.0.1:34176,DS-24347a46-8ce8-46f9-9f43-9f80d3515711,DISK], DatanodeInfoWithStorage[127.0.0.1:39690,DS-30a4fb74-7c75-46c1-ac5a-ddb0c3168e90,DISK], DatanodeInfoWithStorage[127.0.0.1:44832,DS-35e9abb1-391b-4c67-8970-03bd791856ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-907587314-172.17.0.4-1598173392566:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33445,DS-a336ebc9-95d2-4474-b4a9-92cd80a96860,DISK], DatanodeInfoWithStorage[127.0.0.1:42874,DS-7e864464-00a7-43b7-b051-44834adfdad5,DISK], DatanodeInfoWithStorage[127.0.0.1:38087,DS-19e085c9-ffa5-413c-b218-31149c9ea208,DISK], DatanodeInfoWithStorage[127.0.0.1:35477,DS-d5b44447-0f8f-46df-ba4e-61e8694a0c8c,DISK], DatanodeInfoWithStorage[127.0.0.1:36057,DS-58e3c319-94e4-4561-b931-45530426dfb1,DISK], DatanodeInfoWithStorage[127.0.0.1:33027,DS-88acf5cf-9f5d-4739-8d35-5c8bbcef5401,DISK], DatanodeInfoWithStorage[127.0.0.1:37040,DS-4d82c911-0754-4938-8208-658556765f35,DISK], DatanodeInfoWithStorage[127.0.0.1:34533,DS-834d5d4d-4ebd-4812-bcf1-3a6da3380f74,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-907587314-172.17.0.4-1598173392566:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33445,DS-a336ebc9-95d2-4474-b4a9-92cd80a96860,DISK], DatanodeInfoWithStorage[127.0.0.1:42874,DS-7e864464-00a7-43b7-b051-44834adfdad5,DISK], DatanodeInfoWithStorage[127.0.0.1:38087,DS-19e085c9-ffa5-413c-b218-31149c9ea208,DISK], DatanodeInfoWithStorage[127.0.0.1:35477,DS-d5b44447-0f8f-46df-ba4e-61e8694a0c8c,DISK], DatanodeInfoWithStorage[127.0.0.1:36057,DS-58e3c319-94e4-4561-b931-45530426dfb1,DISK], DatanodeInfoWithStorage[127.0.0.1:33027,DS-88acf5cf-9f5d-4739-8d35-5c8bbcef5401,DISK], DatanodeInfoWithStorage[127.0.0.1:37040,DS-4d82c911-0754-4938-8208-658556765f35,DISK], DatanodeInfoWithStorage[127.0.0.1:34533,DS-834d5d4d-4ebd-4812-bcf1-3a6da3380f74,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1132696702-172.17.0.4-1598173911814:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42810,DS-72d1c564-8ca3-4e95-8551-bceac8b15750,DISK], DatanodeInfoWithStorage[127.0.0.1:38469,DS-8dac06cb-5e15-4d12-8776-76ff24add0cd,DISK], DatanodeInfoWithStorage[127.0.0.1:33884,DS-fa1d7a6d-8858-489e-9a02-d9b72cb7508e,DISK], DatanodeInfoWithStorage[127.0.0.1:38910,DS-e74ff084-f63b-4fc5-8c82-f1c5a04d40ce,DISK], DatanodeInfoWithStorage[127.0.0.1:41103,DS-8cb1fafa-9e0c-4f80-8b51-735e8acda95a,DISK], DatanodeInfoWithStorage[127.0.0.1:32779,DS-ca8d16fb-18d2-4b68-807c-a27901af74d3,DISK], DatanodeInfoWithStorage[127.0.0.1:33313,DS-47f60555-4c53-4be8-a1f5-ce3fb633a3e0,DISK], DatanodeInfoWithStorage[127.0.0.1:40657,DS-08f663e7-796e-4b42-a4ff-f2a7bae8cf8f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1132696702-172.17.0.4-1598173911814:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42810,DS-72d1c564-8ca3-4e95-8551-bceac8b15750,DISK], DatanodeInfoWithStorage[127.0.0.1:38469,DS-8dac06cb-5e15-4d12-8776-76ff24add0cd,DISK], DatanodeInfoWithStorage[127.0.0.1:33884,DS-fa1d7a6d-8858-489e-9a02-d9b72cb7508e,DISK], DatanodeInfoWithStorage[127.0.0.1:38910,DS-e74ff084-f63b-4fc5-8c82-f1c5a04d40ce,DISK], DatanodeInfoWithStorage[127.0.0.1:41103,DS-8cb1fafa-9e0c-4f80-8b51-735e8acda95a,DISK], DatanodeInfoWithStorage[127.0.0.1:32779,DS-ca8d16fb-18d2-4b68-807c-a27901af74d3,DISK], DatanodeInfoWithStorage[127.0.0.1:33313,DS-47f60555-4c53-4be8-a1f5-ce3fb633a3e0,DISK], DatanodeInfoWithStorage[127.0.0.1:40657,DS-08f663e7-796e-4b42-a4ff-f2a7bae8cf8f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-727792301-172.17.0.4-1598174309603:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41729,DS-5805060c-5273-4151-bb87-d6229255b66b,DISK], DatanodeInfoWithStorage[127.0.0.1:40981,DS-4c2c464a-1bb8-44fa-a335-025d0c4a47a1,DISK], DatanodeInfoWithStorage[127.0.0.1:33864,DS-bc8c3eae-e38b-4ea9-969f-fb64e8da8532,DISK], DatanodeInfoWithStorage[127.0.0.1:36630,DS-d138c1f0-15a1-4a7c-a583-56b68fb39190,DISK], DatanodeInfoWithStorage[127.0.0.1:37245,DS-cfae491a-04c0-49d3-81d6-f74ef6f800e2,DISK], DatanodeInfoWithStorage[127.0.0.1:34327,DS-8e6e5696-1b8e-499e-ab31-0cc9afb35633,DISK], DatanodeInfoWithStorage[127.0.0.1:32892,DS-fd9f5310-3382-4827-9c9b-dcd5f02b6134,DISK], DatanodeInfoWithStorage[127.0.0.1:41923,DS-9695928f-2243-4ea4-a708-cb7289f826a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-727792301-172.17.0.4-1598174309603:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41729,DS-5805060c-5273-4151-bb87-d6229255b66b,DISK], DatanodeInfoWithStorage[127.0.0.1:40981,DS-4c2c464a-1bb8-44fa-a335-025d0c4a47a1,DISK], DatanodeInfoWithStorage[127.0.0.1:33864,DS-bc8c3eae-e38b-4ea9-969f-fb64e8da8532,DISK], DatanodeInfoWithStorage[127.0.0.1:36630,DS-d138c1f0-15a1-4a7c-a583-56b68fb39190,DISK], DatanodeInfoWithStorage[127.0.0.1:37245,DS-cfae491a-04c0-49d3-81d6-f74ef6f800e2,DISK], DatanodeInfoWithStorage[127.0.0.1:34327,DS-8e6e5696-1b8e-499e-ab31-0cc9afb35633,DISK], DatanodeInfoWithStorage[127.0.0.1:32892,DS-fd9f5310-3382-4827-9c9b-dcd5f02b6134,DISK], DatanodeInfoWithStorage[127.0.0.1:41923,DS-9695928f-2243-4ea4-a708-cb7289f826a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-396713195-172.17.0.4-1598174466138:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42997,DS-7e5117b1-d72f-47ba-aa50-548c342b18c3,DISK], DatanodeInfoWithStorage[127.0.0.1:46492,DS-d2ebe951-32c6-488a-b7fc-3c094b8fb554,DISK], DatanodeInfoWithStorage[127.0.0.1:44531,DS-22f421f8-8738-49d9-b3eb-adfb769cdba6,DISK], DatanodeInfoWithStorage[127.0.0.1:46420,DS-879ef346-6b9f-45fd-a79f-aa07ecd69b23,DISK], DatanodeInfoWithStorage[127.0.0.1:41368,DS-041bc594-92ab-4afc-9208-aedb60420d5a,DISK], DatanodeInfoWithStorage[127.0.0.1:38850,DS-db575c1f-3803-458e-9b9a-b658457cfd77,DISK], DatanodeInfoWithStorage[127.0.0.1:42902,DS-c4c0bcdc-94ee-498b-b7bf-ab518bfdb69c,DISK], DatanodeInfoWithStorage[127.0.0.1:44991,DS-cb872886-bc44-445b-8b10-d862d83da8e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-396713195-172.17.0.4-1598174466138:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42997,DS-7e5117b1-d72f-47ba-aa50-548c342b18c3,DISK], DatanodeInfoWithStorage[127.0.0.1:46492,DS-d2ebe951-32c6-488a-b7fc-3c094b8fb554,DISK], DatanodeInfoWithStorage[127.0.0.1:44531,DS-22f421f8-8738-49d9-b3eb-adfb769cdba6,DISK], DatanodeInfoWithStorage[127.0.0.1:46420,DS-879ef346-6b9f-45fd-a79f-aa07ecd69b23,DISK], DatanodeInfoWithStorage[127.0.0.1:41368,DS-041bc594-92ab-4afc-9208-aedb60420d5a,DISK], DatanodeInfoWithStorage[127.0.0.1:38850,DS-db575c1f-3803-458e-9b9a-b658457cfd77,DISK], DatanodeInfoWithStorage[127.0.0.1:42902,DS-c4c0bcdc-94ee-498b-b7bf-ab518bfdb69c,DISK], DatanodeInfoWithStorage[127.0.0.1:44991,DS-cb872886-bc44-445b-8b10-d862d83da8e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-782954335-172.17.0.4-1598174504694:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34206,DS-a21eed47-485d-4dda-9c7f-906a48ad164b,DISK], DatanodeInfoWithStorage[127.0.0.1:45769,DS-195ffa23-e105-44f1-9919-d0b69a556c9a,DISK], DatanodeInfoWithStorage[127.0.0.1:35021,DS-634c1ac7-87fd-4f19-802c-cc95796cd4a2,DISK], DatanodeInfoWithStorage[127.0.0.1:37709,DS-aa8e59f7-e3b0-42ab-9a8a-849c3ad203ad,DISK], DatanodeInfoWithStorage[127.0.0.1:45344,DS-cbd2f3fb-0ecd-461c-92c9-d07dfe3513eb,DISK], DatanodeInfoWithStorage[127.0.0.1:37484,DS-f867e412-d9fe-48b6-8d41-e7ccb42d6103,DISK], DatanodeInfoWithStorage[127.0.0.1:46801,DS-cd4006f0-3b51-4434-9693-ace6cf701646,DISK], DatanodeInfoWithStorage[127.0.0.1:35564,DS-e9ae8432-7bf9-4ce1-9434-ba5c88b22c00,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-782954335-172.17.0.4-1598174504694:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34206,DS-a21eed47-485d-4dda-9c7f-906a48ad164b,DISK], DatanodeInfoWithStorage[127.0.0.1:45769,DS-195ffa23-e105-44f1-9919-d0b69a556c9a,DISK], DatanodeInfoWithStorage[127.0.0.1:35021,DS-634c1ac7-87fd-4f19-802c-cc95796cd4a2,DISK], DatanodeInfoWithStorage[127.0.0.1:37709,DS-aa8e59f7-e3b0-42ab-9a8a-849c3ad203ad,DISK], DatanodeInfoWithStorage[127.0.0.1:45344,DS-cbd2f3fb-0ecd-461c-92c9-d07dfe3513eb,DISK], DatanodeInfoWithStorage[127.0.0.1:37484,DS-f867e412-d9fe-48b6-8d41-e7ccb42d6103,DISK], DatanodeInfoWithStorage[127.0.0.1:46801,DS-cd4006f0-3b51-4434-9693-ace6cf701646,DISK], DatanodeInfoWithStorage[127.0.0.1:35564,DS-e9ae8432-7bf9-4ce1-9434-ba5c88b22c00,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5621
