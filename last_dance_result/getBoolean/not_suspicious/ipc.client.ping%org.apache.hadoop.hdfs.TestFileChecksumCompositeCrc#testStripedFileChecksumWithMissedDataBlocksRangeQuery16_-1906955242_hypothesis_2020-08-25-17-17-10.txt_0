reconf_parameter: ipc.client.ping
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1808200603-172.17.0.12-1598377189366:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36378,DS-00ca3ec5-6a9d-42a1-bb89-6379c44cc6c3,DISK], DatanodeInfoWithStorage[127.0.0.1:41067,DS-3afa2287-303b-4387-8b8a-dd7edb455f95,DISK], DatanodeInfoWithStorage[127.0.0.1:33242,DS-9b11b395-aec9-46a6-82d4-f9f925cdee69,DISK], DatanodeInfoWithStorage[127.0.0.1:36693,DS-a7c89c59-962d-4f8b-8725-06fd2893da0b,DISK], DatanodeInfoWithStorage[127.0.0.1:46357,DS-8d4f5db9-73e5-4e18-895b-571fc9773228,DISK], DatanodeInfoWithStorage[127.0.0.1:34808,DS-75021925-6712-4f02-9daf-5e07b3041bdd,DISK], DatanodeInfoWithStorage[127.0.0.1:34828,DS-91ad50db-029b-402e-8a8a-895220e36c0f,DISK], DatanodeInfoWithStorage[127.0.0.1:43777,DS-a173207f-21bb-4b3d-84e0-e554cbf1cad5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1808200603-172.17.0.12-1598377189366:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36378,DS-00ca3ec5-6a9d-42a1-bb89-6379c44cc6c3,DISK], DatanodeInfoWithStorage[127.0.0.1:41067,DS-3afa2287-303b-4387-8b8a-dd7edb455f95,DISK], DatanodeInfoWithStorage[127.0.0.1:33242,DS-9b11b395-aec9-46a6-82d4-f9f925cdee69,DISK], DatanodeInfoWithStorage[127.0.0.1:36693,DS-a7c89c59-962d-4f8b-8725-06fd2893da0b,DISK], DatanodeInfoWithStorage[127.0.0.1:46357,DS-8d4f5db9-73e5-4e18-895b-571fc9773228,DISK], DatanodeInfoWithStorage[127.0.0.1:34808,DS-75021925-6712-4f02-9daf-5e07b3041bdd,DISK], DatanodeInfoWithStorage[127.0.0.1:34828,DS-91ad50db-029b-402e-8a8a-895220e36c0f,DISK], DatanodeInfoWithStorage[127.0.0.1:43777,DS-a173207f-21bb-4b3d-84e0-e554cbf1cad5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-850594246-172.17.0.12-1598377976218:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46739,DS-a88776e2-0116-4121-979f-47c6791017b0,DISK], DatanodeInfoWithStorage[127.0.0.1:41919,DS-5c6ee8bf-2334-48fd-8dc0-b8ef46cc797f,DISK], DatanodeInfoWithStorage[127.0.0.1:40380,DS-beb80031-c6ed-47e7-ba35-2f3efd7b6bfd,DISK], DatanodeInfoWithStorage[127.0.0.1:42313,DS-a6e41aba-0675-4540-a735-e6e9b0279f3a,DISK], DatanodeInfoWithStorage[127.0.0.1:33771,DS-32db0cc0-57b8-40a9-8214-5ea39bb56dd5,DISK], DatanodeInfoWithStorage[127.0.0.1:40636,DS-55ed8006-d2f7-4c4d-80a6-c440f8654091,DISK], DatanodeInfoWithStorage[127.0.0.1:45801,DS-7bfc47bb-3b4a-4ce5-b6a9-cee4082337f8,DISK], DatanodeInfoWithStorage[127.0.0.1:39983,DS-6022367e-0069-49ec-ad77-571067415890,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-850594246-172.17.0.12-1598377976218:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46739,DS-a88776e2-0116-4121-979f-47c6791017b0,DISK], DatanodeInfoWithStorage[127.0.0.1:41919,DS-5c6ee8bf-2334-48fd-8dc0-b8ef46cc797f,DISK], DatanodeInfoWithStorage[127.0.0.1:40380,DS-beb80031-c6ed-47e7-ba35-2f3efd7b6bfd,DISK], DatanodeInfoWithStorage[127.0.0.1:42313,DS-a6e41aba-0675-4540-a735-e6e9b0279f3a,DISK], DatanodeInfoWithStorage[127.0.0.1:33771,DS-32db0cc0-57b8-40a9-8214-5ea39bb56dd5,DISK], DatanodeInfoWithStorage[127.0.0.1:40636,DS-55ed8006-d2f7-4c4d-80a6-c440f8654091,DISK], DatanodeInfoWithStorage[127.0.0.1:45801,DS-7bfc47bb-3b4a-4ce5-b6a9-cee4082337f8,DISK], DatanodeInfoWithStorage[127.0.0.1:39983,DS-6022367e-0069-49ec-ad77-571067415890,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1010420067-172.17.0.12-1598378524516:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45215,DS-342a2e42-e4a7-4308-9431-06f0ba4002a6,DISK], DatanodeInfoWithStorage[127.0.0.1:35831,DS-a9378be3-30bb-4ba6-89a8-4fbb7abb01db,DISK], DatanodeInfoWithStorage[127.0.0.1:45181,DS-aaaa16a0-f452-4e8a-8741-87b10799cf8b,DISK], DatanodeInfoWithStorage[127.0.0.1:41873,DS-4ba30e71-72eb-4bf7-b690-8d1361a3ee9a,DISK], DatanodeInfoWithStorage[127.0.0.1:44364,DS-b58792b9-572c-4dc5-9e93-1c30b83310af,DISK], DatanodeInfoWithStorage[127.0.0.1:45372,DS-f71500d0-bca2-4c56-8c25-b80f420c9295,DISK], DatanodeInfoWithStorage[127.0.0.1:46400,DS-2748055b-0348-4255-9806-612c4b2a3714,DISK], DatanodeInfoWithStorage[127.0.0.1:37501,DS-ddfe15f4-755f-45bb-94d3-38b66919d788,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1010420067-172.17.0.12-1598378524516:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45215,DS-342a2e42-e4a7-4308-9431-06f0ba4002a6,DISK], DatanodeInfoWithStorage[127.0.0.1:35831,DS-a9378be3-30bb-4ba6-89a8-4fbb7abb01db,DISK], DatanodeInfoWithStorage[127.0.0.1:45181,DS-aaaa16a0-f452-4e8a-8741-87b10799cf8b,DISK], DatanodeInfoWithStorage[127.0.0.1:41873,DS-4ba30e71-72eb-4bf7-b690-8d1361a3ee9a,DISK], DatanodeInfoWithStorage[127.0.0.1:44364,DS-b58792b9-572c-4dc5-9e93-1c30b83310af,DISK], DatanodeInfoWithStorage[127.0.0.1:45372,DS-f71500d0-bca2-4c56-8c25-b80f420c9295,DISK], DatanodeInfoWithStorage[127.0.0.1:46400,DS-2748055b-0348-4255-9806-612c4b2a3714,DISK], DatanodeInfoWithStorage[127.0.0.1:37501,DS-ddfe15f4-755f-45bb-94d3-38b66919d788,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-186379042-172.17.0.12-1598378716993:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43283,DS-7408bac1-28bc-41c6-a465-5ae8f1bb6dc2,DISK], DatanodeInfoWithStorage[127.0.0.1:39377,DS-ffd2b21e-5afa-4cc0-bd03-1a216d0bb06f,DISK], DatanodeInfoWithStorage[127.0.0.1:35290,DS-3ed22a03-fdad-42b0-95ce-dbd3a680c041,DISK], DatanodeInfoWithStorage[127.0.0.1:46622,DS-c9104345-1e4f-46ac-80b5-1eac2a5ce50b,DISK], DatanodeInfoWithStorage[127.0.0.1:44303,DS-2b3e8229-9269-403e-a187-fc9657744a65,DISK], DatanodeInfoWithStorage[127.0.0.1:38109,DS-11ef0fa9-c4fd-4687-bcb7-c1886c3624bc,DISK], DatanodeInfoWithStorage[127.0.0.1:33187,DS-b947e49b-13a4-4c53-ba65-9ca92c6f3337,DISK], DatanodeInfoWithStorage[127.0.0.1:38212,DS-1d88c0bc-a580-456f-9dbe-57f4da449a53,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-186379042-172.17.0.12-1598378716993:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43283,DS-7408bac1-28bc-41c6-a465-5ae8f1bb6dc2,DISK], DatanodeInfoWithStorage[127.0.0.1:39377,DS-ffd2b21e-5afa-4cc0-bd03-1a216d0bb06f,DISK], DatanodeInfoWithStorage[127.0.0.1:35290,DS-3ed22a03-fdad-42b0-95ce-dbd3a680c041,DISK], DatanodeInfoWithStorage[127.0.0.1:46622,DS-c9104345-1e4f-46ac-80b5-1eac2a5ce50b,DISK], DatanodeInfoWithStorage[127.0.0.1:44303,DS-2b3e8229-9269-403e-a187-fc9657744a65,DISK], DatanodeInfoWithStorage[127.0.0.1:38109,DS-11ef0fa9-c4fd-4687-bcb7-c1886c3624bc,DISK], DatanodeInfoWithStorage[127.0.0.1:33187,DS-b947e49b-13a4-4c53-ba65-9ca92c6f3337,DISK], DatanodeInfoWithStorage[127.0.0.1:38212,DS-1d88c0bc-a580-456f-9dbe-57f4da449a53,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1921113389-172.17.0.12-1598379240949:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37690,DS-20dfda85-b6f0-4d88-a5b4-4e55cae28eef,DISK], DatanodeInfoWithStorage[127.0.0.1:44238,DS-432cbed4-2bba-4da3-b1da-43dc5b9dc928,DISK], DatanodeInfoWithStorage[127.0.0.1:34851,DS-9dd180c5-cd0d-4df7-bc4f-adeb1b87c8f3,DISK], DatanodeInfoWithStorage[127.0.0.1:34270,DS-750eb126-d63a-4f80-ae51-b201d0c254f6,DISK], DatanodeInfoWithStorage[127.0.0.1:38878,DS-f47a6084-d8f8-4965-a9a3-cd22e7d768c6,DISK], DatanodeInfoWithStorage[127.0.0.1:42021,DS-cff9a98e-9643-40a4-a57e-b8439be05f08,DISK], DatanodeInfoWithStorage[127.0.0.1:40832,DS-35144a4d-6e76-421c-86c0-20a30b02046a,DISK], DatanodeInfoWithStorage[127.0.0.1:33366,DS-b8874af8-b809-4161-8180-54cec3e93d0e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1921113389-172.17.0.12-1598379240949:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37690,DS-20dfda85-b6f0-4d88-a5b4-4e55cae28eef,DISK], DatanodeInfoWithStorage[127.0.0.1:44238,DS-432cbed4-2bba-4da3-b1da-43dc5b9dc928,DISK], DatanodeInfoWithStorage[127.0.0.1:34851,DS-9dd180c5-cd0d-4df7-bc4f-adeb1b87c8f3,DISK], DatanodeInfoWithStorage[127.0.0.1:34270,DS-750eb126-d63a-4f80-ae51-b201d0c254f6,DISK], DatanodeInfoWithStorage[127.0.0.1:38878,DS-f47a6084-d8f8-4965-a9a3-cd22e7d768c6,DISK], DatanodeInfoWithStorage[127.0.0.1:42021,DS-cff9a98e-9643-40a4-a57e-b8439be05f08,DISK], DatanodeInfoWithStorage[127.0.0.1:40832,DS-35144a4d-6e76-421c-86c0-20a30b02046a,DISK], DatanodeInfoWithStorage[127.0.0.1:33366,DS-b8874af8-b809-4161-8180-54cec3e93d0e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1472939212-172.17.0.12-1598379378508:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40086,DS-d57fa00d-fa61-4aed-8dbc-4399d38df5fa,DISK], DatanodeInfoWithStorage[127.0.0.1:42796,DS-1b46fa5f-a34e-4b1f-8632-89a70a92cf0d,DISK], DatanodeInfoWithStorage[127.0.0.1:37342,DS-e910b30e-6a1e-4132-bb73-efe2caad29b8,DISK], DatanodeInfoWithStorage[127.0.0.1:46215,DS-cdb6c8ac-4c3e-487e-9f1d-418bdd974c48,DISK], DatanodeInfoWithStorage[127.0.0.1:39709,DS-f9d7f86d-8958-45ad-8ed9-3ea1a5f86c0d,DISK], DatanodeInfoWithStorage[127.0.0.1:42708,DS-c640dc22-dd62-4abe-86d5-2ea537bb21c6,DISK], DatanodeInfoWithStorage[127.0.0.1:40341,DS-f3c2c24f-0b1c-4566-aa53-643152feae6c,DISK], DatanodeInfoWithStorage[127.0.0.1:37703,DS-3a655df9-46ec-45b9-89af-10584de78a58,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1472939212-172.17.0.12-1598379378508:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40086,DS-d57fa00d-fa61-4aed-8dbc-4399d38df5fa,DISK], DatanodeInfoWithStorage[127.0.0.1:42796,DS-1b46fa5f-a34e-4b1f-8632-89a70a92cf0d,DISK], DatanodeInfoWithStorage[127.0.0.1:37342,DS-e910b30e-6a1e-4132-bb73-efe2caad29b8,DISK], DatanodeInfoWithStorage[127.0.0.1:46215,DS-cdb6c8ac-4c3e-487e-9f1d-418bdd974c48,DISK], DatanodeInfoWithStorage[127.0.0.1:39709,DS-f9d7f86d-8958-45ad-8ed9-3ea1a5f86c0d,DISK], DatanodeInfoWithStorage[127.0.0.1:42708,DS-c640dc22-dd62-4abe-86d5-2ea537bb21c6,DISK], DatanodeInfoWithStorage[127.0.0.1:40341,DS-f3c2c24f-0b1c-4566-aa53-643152feae6c,DISK], DatanodeInfoWithStorage[127.0.0.1:37703,DS-3a655df9-46ec-45b9-89af-10584de78a58,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-682060464-172.17.0.12-1598379968664:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36989,DS-b1751c5b-9219-426f-822d-060638363306,DISK], DatanodeInfoWithStorage[127.0.0.1:43247,DS-e3aca10a-c500-4e45-8c6e-b6a3ed874d4f,DISK], DatanodeInfoWithStorage[127.0.0.1:45613,DS-953c02ff-a45b-4a76-b1ae-1a1b00e54025,DISK], DatanodeInfoWithStorage[127.0.0.1:35095,DS-3555f2cb-c297-4e8a-b9aa-097ee3a24411,DISK], DatanodeInfoWithStorage[127.0.0.1:33281,DS-07e58774-84d5-4b82-9815-696157db847c,DISK], DatanodeInfoWithStorage[127.0.0.1:41852,DS-9de4ab15-b8ff-46bc-8ab6-8ec1cd217563,DISK], DatanodeInfoWithStorage[127.0.0.1:46487,DS-6816b111-9ff0-4146-a944-7c6daa8ac36f,DISK], DatanodeInfoWithStorage[127.0.0.1:45583,DS-96000605-c4cf-4441-93b9-c72b2ba25cbd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-682060464-172.17.0.12-1598379968664:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36989,DS-b1751c5b-9219-426f-822d-060638363306,DISK], DatanodeInfoWithStorage[127.0.0.1:43247,DS-e3aca10a-c500-4e45-8c6e-b6a3ed874d4f,DISK], DatanodeInfoWithStorage[127.0.0.1:45613,DS-953c02ff-a45b-4a76-b1ae-1a1b00e54025,DISK], DatanodeInfoWithStorage[127.0.0.1:35095,DS-3555f2cb-c297-4e8a-b9aa-097ee3a24411,DISK], DatanodeInfoWithStorage[127.0.0.1:33281,DS-07e58774-84d5-4b82-9815-696157db847c,DISK], DatanodeInfoWithStorage[127.0.0.1:41852,DS-9de4ab15-b8ff-46bc-8ab6-8ec1cd217563,DISK], DatanodeInfoWithStorage[127.0.0.1:46487,DS-6816b111-9ff0-4146-a944-7c6daa8ac36f,DISK], DatanodeInfoWithStorage[127.0.0.1:45583,DS-96000605-c4cf-4441-93b9-c72b2ba25cbd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-668077612-172.17.0.12-1598380037298:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34804,DS-edd26303-802a-4086-b69b-7fd319905b7c,DISK], DatanodeInfoWithStorage[127.0.0.1:40629,DS-54dd1e73-f4e6-4618-a873-d0d534e88480,DISK], DatanodeInfoWithStorage[127.0.0.1:35488,DS-93754343-04b4-49c9-8506-a43e5dd22a83,DISK], DatanodeInfoWithStorage[127.0.0.1:36366,DS-6efb7127-5369-4dd3-a65a-210ff420d3f3,DISK], DatanodeInfoWithStorage[127.0.0.1:37514,DS-582285fe-0448-4b99-add5-7ac56609ca71,DISK], DatanodeInfoWithStorage[127.0.0.1:46374,DS-4a5072fa-5fcf-4d58-87d0-35d6752852ea,DISK], DatanodeInfoWithStorage[127.0.0.1:34069,DS-a5399c06-a678-4ef5-8cf1-bd1a736acc4f,DISK], DatanodeInfoWithStorage[127.0.0.1:35843,DS-a9cf9609-07d4-40a6-a730-afebb7a48252,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-668077612-172.17.0.12-1598380037298:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34804,DS-edd26303-802a-4086-b69b-7fd319905b7c,DISK], DatanodeInfoWithStorage[127.0.0.1:40629,DS-54dd1e73-f4e6-4618-a873-d0d534e88480,DISK], DatanodeInfoWithStorage[127.0.0.1:35488,DS-93754343-04b4-49c9-8506-a43e5dd22a83,DISK], DatanodeInfoWithStorage[127.0.0.1:36366,DS-6efb7127-5369-4dd3-a65a-210ff420d3f3,DISK], DatanodeInfoWithStorage[127.0.0.1:37514,DS-582285fe-0448-4b99-add5-7ac56609ca71,DISK], DatanodeInfoWithStorage[127.0.0.1:46374,DS-4a5072fa-5fcf-4d58-87d0-35d6752852ea,DISK], DatanodeInfoWithStorage[127.0.0.1:34069,DS-a5399c06-a678-4ef5-8cf1-bd1a736acc4f,DISK], DatanodeInfoWithStorage[127.0.0.1:35843,DS-a9cf9609-07d4-40a6-a730-afebb7a48252,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-298533603-172.17.0.12-1598380369283:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36258,DS-ebb97306-9dac-4b0f-910c-ba36e59b7b4b,DISK], DatanodeInfoWithStorage[127.0.0.1:38888,DS-fc1f2b92-9163-4e6a-a273-da60896c28d8,DISK], DatanodeInfoWithStorage[127.0.0.1:37450,DS-89713da1-d745-4619-b489-bedb87f20be0,DISK], DatanodeInfoWithStorage[127.0.0.1:37701,DS-933ac969-c78b-4d6d-ba1d-b5ba7f0e37c3,DISK], DatanodeInfoWithStorage[127.0.0.1:38213,DS-627b4eda-c3c4-433a-8d7b-034fc8408ce1,DISK], DatanodeInfoWithStorage[127.0.0.1:36751,DS-4ac5dafe-43ab-41fa-8dd2-921f5efc1025,DISK], DatanodeInfoWithStorage[127.0.0.1:35108,DS-c6591005-8582-4214-89e6-466e92e61cbc,DISK], DatanodeInfoWithStorage[127.0.0.1:32805,DS-4debe552-d1ec-4257-a436-96c5670630fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-298533603-172.17.0.12-1598380369283:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36258,DS-ebb97306-9dac-4b0f-910c-ba36e59b7b4b,DISK], DatanodeInfoWithStorage[127.0.0.1:38888,DS-fc1f2b92-9163-4e6a-a273-da60896c28d8,DISK], DatanodeInfoWithStorage[127.0.0.1:37450,DS-89713da1-d745-4619-b489-bedb87f20be0,DISK], DatanodeInfoWithStorage[127.0.0.1:37701,DS-933ac969-c78b-4d6d-ba1d-b5ba7f0e37c3,DISK], DatanodeInfoWithStorage[127.0.0.1:38213,DS-627b4eda-c3c4-433a-8d7b-034fc8408ce1,DISK], DatanodeInfoWithStorage[127.0.0.1:36751,DS-4ac5dafe-43ab-41fa-8dd2-921f5efc1025,DISK], DatanodeInfoWithStorage[127.0.0.1:35108,DS-c6591005-8582-4214-89e6-466e92e61cbc,DISK], DatanodeInfoWithStorage[127.0.0.1:32805,DS-4debe552-d1ec-4257-a436-96c5670630fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-135229479-172.17.0.12-1598380653817:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33888,DS-6475046a-e8ee-40c7-b9f1-ae3d07e3d67f,DISK], DatanodeInfoWithStorage[127.0.0.1:38651,DS-f0034c67-cf3d-470e-96b2-b8c9bdf141dc,DISK], DatanodeInfoWithStorage[127.0.0.1:35838,DS-aa4bab47-8f3c-427d-99bc-4cffdd35caf7,DISK], DatanodeInfoWithStorage[127.0.0.1:35819,DS-4e7d7720-d142-4378-8407-7d3a20db09da,DISK], DatanodeInfoWithStorage[127.0.0.1:42857,DS-d864ae68-cc4b-4ff7-9609-b6b912662543,DISK], DatanodeInfoWithStorage[127.0.0.1:43028,DS-2e08a948-6222-4ab7-8ea3-778ab3093cfb,DISK], DatanodeInfoWithStorage[127.0.0.1:40989,DS-72db1752-c50f-47cc-8d87-801c3300f5f4,DISK], DatanodeInfoWithStorage[127.0.0.1:43636,DS-455bdd23-f257-44f9-a59a-24a3fd6287db,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-135229479-172.17.0.12-1598380653817:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33888,DS-6475046a-e8ee-40c7-b9f1-ae3d07e3d67f,DISK], DatanodeInfoWithStorage[127.0.0.1:38651,DS-f0034c67-cf3d-470e-96b2-b8c9bdf141dc,DISK], DatanodeInfoWithStorage[127.0.0.1:35838,DS-aa4bab47-8f3c-427d-99bc-4cffdd35caf7,DISK], DatanodeInfoWithStorage[127.0.0.1:35819,DS-4e7d7720-d142-4378-8407-7d3a20db09da,DISK], DatanodeInfoWithStorage[127.0.0.1:42857,DS-d864ae68-cc4b-4ff7-9609-b6b912662543,DISK], DatanodeInfoWithStorage[127.0.0.1:43028,DS-2e08a948-6222-4ab7-8ea3-778ab3093cfb,DISK], DatanodeInfoWithStorage[127.0.0.1:40989,DS-72db1752-c50f-47cc-8d87-801c3300f5f4,DISK], DatanodeInfoWithStorage[127.0.0.1:43636,DS-455bdd23-f257-44f9-a59a-24a3fd6287db,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1250856170-172.17.0.12-1598380679803:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41767,DS-f37742bb-13e1-4931-9b27-060a9909fdc1,DISK], DatanodeInfoWithStorage[127.0.0.1:40686,DS-3296fc81-8375-4e92-9330-c1b95aff050e,DISK], DatanodeInfoWithStorage[127.0.0.1:40637,DS-a54f2217-b8d6-4224-a558-3d8b6f691d8a,DISK], DatanodeInfoWithStorage[127.0.0.1:42448,DS-8594e3ed-714e-4a88-bd03-e323de6f636a,DISK], DatanodeInfoWithStorage[127.0.0.1:45103,DS-643611b1-5d94-442a-bbb0-1348805c0fd2,DISK], DatanodeInfoWithStorage[127.0.0.1:35821,DS-5917b0ff-22b6-4b64-a864-d09c851f04e5,DISK], DatanodeInfoWithStorage[127.0.0.1:36929,DS-6de27ef3-2877-4c6d-8bea-2a132e707579,DISK], DatanodeInfoWithStorage[127.0.0.1:33741,DS-50126d38-f436-4296-b2b6-7e0bd85f0237,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1250856170-172.17.0.12-1598380679803:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41767,DS-f37742bb-13e1-4931-9b27-060a9909fdc1,DISK], DatanodeInfoWithStorage[127.0.0.1:40686,DS-3296fc81-8375-4e92-9330-c1b95aff050e,DISK], DatanodeInfoWithStorage[127.0.0.1:40637,DS-a54f2217-b8d6-4224-a558-3d8b6f691d8a,DISK], DatanodeInfoWithStorage[127.0.0.1:42448,DS-8594e3ed-714e-4a88-bd03-e323de6f636a,DISK], DatanodeInfoWithStorage[127.0.0.1:45103,DS-643611b1-5d94-442a-bbb0-1348805c0fd2,DISK], DatanodeInfoWithStorage[127.0.0.1:35821,DS-5917b0ff-22b6-4b64-a864-d09c851f04e5,DISK], DatanodeInfoWithStorage[127.0.0.1:36929,DS-6de27ef3-2877-4c6d-8bea-2a132e707579,DISK], DatanodeInfoWithStorage[127.0.0.1:33741,DS-50126d38-f436-4296-b2b6-7e0bd85f0237,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 7 out of 50
result: false positive !!!
Total execution time in seconds : 5006
