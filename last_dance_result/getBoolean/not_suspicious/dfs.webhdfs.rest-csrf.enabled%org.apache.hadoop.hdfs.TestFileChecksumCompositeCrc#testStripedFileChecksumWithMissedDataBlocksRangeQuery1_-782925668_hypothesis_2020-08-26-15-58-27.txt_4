reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1243286219-172.17.0.4-1598457664314:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37001,DS-e11139d6-b79d-4a9a-a1f4-ab3bcd740628,DISK], DatanodeInfoWithStorage[127.0.0.1:45701,DS-bbd30a7d-50de-491f-a0dd-abb0fa734301,DISK], DatanodeInfoWithStorage[127.0.0.1:33425,DS-2b70e2c8-7aa3-4a5f-95ad-6c49232ae106,DISK], DatanodeInfoWithStorage[127.0.0.1:38502,DS-c3735669-2fcb-4104-ab6f-4c79205b9995,DISK], DatanodeInfoWithStorage[127.0.0.1:40552,DS-217bf1bb-0b75-4866-9c0b-90b363a89101,DISK], DatanodeInfoWithStorage[127.0.0.1:41740,DS-aa10605b-d05a-47e3-a0bf-6dbf84a21a94,DISK], DatanodeInfoWithStorage[127.0.0.1:46024,DS-089b14e9-7efb-4004-8668-64487a9e77fa,DISK], DatanodeInfoWithStorage[127.0.0.1:36862,DS-4d974aea-15f3-40f5-a857-ea335b87ff04,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1243286219-172.17.0.4-1598457664314:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37001,DS-e11139d6-b79d-4a9a-a1f4-ab3bcd740628,DISK], DatanodeInfoWithStorage[127.0.0.1:45701,DS-bbd30a7d-50de-491f-a0dd-abb0fa734301,DISK], DatanodeInfoWithStorage[127.0.0.1:33425,DS-2b70e2c8-7aa3-4a5f-95ad-6c49232ae106,DISK], DatanodeInfoWithStorage[127.0.0.1:38502,DS-c3735669-2fcb-4104-ab6f-4c79205b9995,DISK], DatanodeInfoWithStorage[127.0.0.1:40552,DS-217bf1bb-0b75-4866-9c0b-90b363a89101,DISK], DatanodeInfoWithStorage[127.0.0.1:41740,DS-aa10605b-d05a-47e3-a0bf-6dbf84a21a94,DISK], DatanodeInfoWithStorage[127.0.0.1:46024,DS-089b14e9-7efb-4004-8668-64487a9e77fa,DISK], DatanodeInfoWithStorage[127.0.0.1:36862,DS-4d974aea-15f3-40f5-a857-ea335b87ff04,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-643006146-172.17.0.4-1598457858189:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38154,DS-99b98150-ebc3-4fa1-870d-b69e89b625e1,DISK], DatanodeInfoWithStorage[127.0.0.1:36113,DS-5a448e2c-fc14-4015-bcda-b123db3103c4,DISK], DatanodeInfoWithStorage[127.0.0.1:37009,DS-4813e0fc-c558-4ef9-8f28-4df32fd68ea6,DISK], DatanodeInfoWithStorage[127.0.0.1:37439,DS-a047573f-7268-4449-ad1e-035e46902269,DISK], DatanodeInfoWithStorage[127.0.0.1:38608,DS-b8fe2347-c3d2-4415-9cde-874301180fc8,DISK], DatanodeInfoWithStorage[127.0.0.1:39750,DS-6347bdf2-7164-47ac-bb8c-4acc12f87490,DISK], DatanodeInfoWithStorage[127.0.0.1:45815,DS-0dd05eff-f590-4e23-bd71-8511ffdd2a5d,DISK], DatanodeInfoWithStorage[127.0.0.1:35578,DS-53db1ffd-7323-475d-a181-579aadf61b2b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-643006146-172.17.0.4-1598457858189:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38154,DS-99b98150-ebc3-4fa1-870d-b69e89b625e1,DISK], DatanodeInfoWithStorage[127.0.0.1:36113,DS-5a448e2c-fc14-4015-bcda-b123db3103c4,DISK], DatanodeInfoWithStorage[127.0.0.1:37009,DS-4813e0fc-c558-4ef9-8f28-4df32fd68ea6,DISK], DatanodeInfoWithStorage[127.0.0.1:37439,DS-a047573f-7268-4449-ad1e-035e46902269,DISK], DatanodeInfoWithStorage[127.0.0.1:38608,DS-b8fe2347-c3d2-4415-9cde-874301180fc8,DISK], DatanodeInfoWithStorage[127.0.0.1:39750,DS-6347bdf2-7164-47ac-bb8c-4acc12f87490,DISK], DatanodeInfoWithStorage[127.0.0.1:45815,DS-0dd05eff-f590-4e23-bd71-8511ffdd2a5d,DISK], DatanodeInfoWithStorage[127.0.0.1:35578,DS-53db1ffd-7323-475d-a181-579aadf61b2b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-607606809-172.17.0.4-1598457897562:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37730,DS-e3e79045-89bc-4c91-88f7-28aefbb9d57b,DISK], DatanodeInfoWithStorage[127.0.0.1:40496,DS-25529f2f-1671-4e5f-922b-f54c869a7e57,DISK], DatanodeInfoWithStorage[127.0.0.1:46516,DS-13ea7770-fe59-4e8a-ae5b-d66bb0f45764,DISK], DatanodeInfoWithStorage[127.0.0.1:36254,DS-51480c38-d097-4eb8-b94d-73e88150c157,DISK], DatanodeInfoWithStorage[127.0.0.1:38531,DS-fd45547b-079a-4366-87fb-e9c04ac43823,DISK], DatanodeInfoWithStorage[127.0.0.1:42257,DS-1641df7f-d6dd-4523-88ed-8d5476978957,DISK], DatanodeInfoWithStorage[127.0.0.1:41933,DS-54f1fd90-2a9f-43a1-a146-536f232bb8db,DISK], DatanodeInfoWithStorage[127.0.0.1:45301,DS-9c397aaf-ab6f-4e5d-b011-55f1b88bcbaa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-607606809-172.17.0.4-1598457897562:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37730,DS-e3e79045-89bc-4c91-88f7-28aefbb9d57b,DISK], DatanodeInfoWithStorage[127.0.0.1:40496,DS-25529f2f-1671-4e5f-922b-f54c869a7e57,DISK], DatanodeInfoWithStorage[127.0.0.1:46516,DS-13ea7770-fe59-4e8a-ae5b-d66bb0f45764,DISK], DatanodeInfoWithStorage[127.0.0.1:36254,DS-51480c38-d097-4eb8-b94d-73e88150c157,DISK], DatanodeInfoWithStorage[127.0.0.1:38531,DS-fd45547b-079a-4366-87fb-e9c04ac43823,DISK], DatanodeInfoWithStorage[127.0.0.1:42257,DS-1641df7f-d6dd-4523-88ed-8d5476978957,DISK], DatanodeInfoWithStorage[127.0.0.1:41933,DS-54f1fd90-2a9f-43a1-a146-536f232bb8db,DISK], DatanodeInfoWithStorage[127.0.0.1:45301,DS-9c397aaf-ab6f-4e5d-b011-55f1b88bcbaa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1256910686-172.17.0.4-1598458010247:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42306,DS-095445b2-10f5-494d-82ea-23398aacb10b,DISK], DatanodeInfoWithStorage[127.0.0.1:41348,DS-a51b46e4-5e32-42ce-8095-2f7860870240,DISK], DatanodeInfoWithStorage[127.0.0.1:38508,DS-6cfc0674-eac9-4e62-9aca-2ea6267c13e2,DISK], DatanodeInfoWithStorage[127.0.0.1:34031,DS-de4ba0f6-5234-4d7c-8c58-4a2533065bce,DISK], DatanodeInfoWithStorage[127.0.0.1:43534,DS-e4f87aca-3933-4171-8ac6-14958c618d64,DISK], DatanodeInfoWithStorage[127.0.0.1:40016,DS-ab94718a-f109-4d5f-a6ef-327c9f0cd934,DISK], DatanodeInfoWithStorage[127.0.0.1:33116,DS-bb0a4cb9-9b82-47ab-b10f-899dae704dcd,DISK], DatanodeInfoWithStorage[127.0.0.1:37342,DS-6e474f64-eaa7-4f24-8365-fb46d61db7b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1256910686-172.17.0.4-1598458010247:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42306,DS-095445b2-10f5-494d-82ea-23398aacb10b,DISK], DatanodeInfoWithStorage[127.0.0.1:41348,DS-a51b46e4-5e32-42ce-8095-2f7860870240,DISK], DatanodeInfoWithStorage[127.0.0.1:38508,DS-6cfc0674-eac9-4e62-9aca-2ea6267c13e2,DISK], DatanodeInfoWithStorage[127.0.0.1:34031,DS-de4ba0f6-5234-4d7c-8c58-4a2533065bce,DISK], DatanodeInfoWithStorage[127.0.0.1:43534,DS-e4f87aca-3933-4171-8ac6-14958c618d64,DISK], DatanodeInfoWithStorage[127.0.0.1:40016,DS-ab94718a-f109-4d5f-a6ef-327c9f0cd934,DISK], DatanodeInfoWithStorage[127.0.0.1:33116,DS-bb0a4cb9-9b82-47ab-b10f-899dae704dcd,DISK], DatanodeInfoWithStorage[127.0.0.1:37342,DS-6e474f64-eaa7-4f24-8365-fb46d61db7b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-950525744-172.17.0.4-1598458825762:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41154,DS-cafc900a-0025-458d-b407-c9f1b090fdf7,DISK], DatanodeInfoWithStorage[127.0.0.1:41062,DS-10cda96c-0f9e-45a4-8dbf-9b8418f9723f,DISK], DatanodeInfoWithStorage[127.0.0.1:46352,DS-8009c677-ecda-416f-a244-e3a9b678d188,DISK], DatanodeInfoWithStorage[127.0.0.1:32794,DS-4c8239ce-a333-4355-bc32-bcf91c006649,DISK], DatanodeInfoWithStorage[127.0.0.1:39760,DS-a34bcb4a-fe6a-4a46-a0fc-e75f0b2c5a7d,DISK], DatanodeInfoWithStorage[127.0.0.1:45032,DS-915f3963-d5a9-458d-84f6-fbbf81ed97c3,DISK], DatanodeInfoWithStorage[127.0.0.1:44417,DS-30b7916a-01be-4315-b162-fd20d531e7b7,DISK], DatanodeInfoWithStorage[127.0.0.1:33925,DS-6b6473be-1094-42dc-841e-1a370a7c5e64,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-950525744-172.17.0.4-1598458825762:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41154,DS-cafc900a-0025-458d-b407-c9f1b090fdf7,DISK], DatanodeInfoWithStorage[127.0.0.1:41062,DS-10cda96c-0f9e-45a4-8dbf-9b8418f9723f,DISK], DatanodeInfoWithStorage[127.0.0.1:46352,DS-8009c677-ecda-416f-a244-e3a9b678d188,DISK], DatanodeInfoWithStorage[127.0.0.1:32794,DS-4c8239ce-a333-4355-bc32-bcf91c006649,DISK], DatanodeInfoWithStorage[127.0.0.1:39760,DS-a34bcb4a-fe6a-4a46-a0fc-e75f0b2c5a7d,DISK], DatanodeInfoWithStorage[127.0.0.1:45032,DS-915f3963-d5a9-458d-84f6-fbbf81ed97c3,DISK], DatanodeInfoWithStorage[127.0.0.1:44417,DS-30b7916a-01be-4315-b162-fd20d531e7b7,DISK], DatanodeInfoWithStorage[127.0.0.1:33925,DS-6b6473be-1094-42dc-841e-1a370a7c5e64,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2038391753-172.17.0.4-1598459245440:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41940,DS-e7f0bc84-d098-4fe0-a1d0-a335a667e045,DISK], DatanodeInfoWithStorage[127.0.0.1:45830,DS-74fcda59-cd6c-4dfe-b948-f88838cc989f,DISK], DatanodeInfoWithStorage[127.0.0.1:42856,DS-07f523f3-fbcd-4621-ae2a-1bd5071f0a23,DISK], DatanodeInfoWithStorage[127.0.0.1:35597,DS-862f47a4-7996-46ee-a6b7-3f92a7044abf,DISK], DatanodeInfoWithStorage[127.0.0.1:38138,DS-83f2509c-0c3e-48a9-982c-d5a4867f308b,DISK], DatanodeInfoWithStorage[127.0.0.1:34262,DS-b91c21d6-b8c5-4f02-a655-8d191dc90389,DISK], DatanodeInfoWithStorage[127.0.0.1:44267,DS-73932833-184c-4f99-b816-b71069c38240,DISK], DatanodeInfoWithStorage[127.0.0.1:40227,DS-3536206c-f964-4f9a-a956-8b431358a80a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2038391753-172.17.0.4-1598459245440:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41940,DS-e7f0bc84-d098-4fe0-a1d0-a335a667e045,DISK], DatanodeInfoWithStorage[127.0.0.1:45830,DS-74fcda59-cd6c-4dfe-b948-f88838cc989f,DISK], DatanodeInfoWithStorage[127.0.0.1:42856,DS-07f523f3-fbcd-4621-ae2a-1bd5071f0a23,DISK], DatanodeInfoWithStorage[127.0.0.1:35597,DS-862f47a4-7996-46ee-a6b7-3f92a7044abf,DISK], DatanodeInfoWithStorage[127.0.0.1:38138,DS-83f2509c-0c3e-48a9-982c-d5a4867f308b,DISK], DatanodeInfoWithStorage[127.0.0.1:34262,DS-b91c21d6-b8c5-4f02-a655-8d191dc90389,DISK], DatanodeInfoWithStorage[127.0.0.1:44267,DS-73932833-184c-4f99-b816-b71069c38240,DISK], DatanodeInfoWithStorage[127.0.0.1:40227,DS-3536206c-f964-4f9a-a956-8b431358a80a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-709244571-172.17.0.4-1598459773394:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45652,DS-3e5d54fc-bf4e-4de4-a206-809b889b3cbc,DISK], DatanodeInfoWithStorage[127.0.0.1:39342,DS-215f0256-e9b6-4d28-bf35-1ed0bf89cc0a,DISK], DatanodeInfoWithStorage[127.0.0.1:44361,DS-186f9939-1fac-4cbf-b4d6-fa9f48f5e1c2,DISK], DatanodeInfoWithStorage[127.0.0.1:38919,DS-7b977207-1bce-4917-9fc4-29c47c114334,DISK], DatanodeInfoWithStorage[127.0.0.1:39870,DS-edcaa98f-614d-41da-9fcd-572395cec665,DISK], DatanodeInfoWithStorage[127.0.0.1:36787,DS-c0d70083-3565-48af-b218-07a2716ced13,DISK], DatanodeInfoWithStorage[127.0.0.1:38159,DS-b8d5f25f-25f0-4ace-9452-fc42c4e7f6d7,DISK], DatanodeInfoWithStorage[127.0.0.1:37134,DS-c5bc820b-b0ee-44be-8adc-2e2b18abf11e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-709244571-172.17.0.4-1598459773394:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45652,DS-3e5d54fc-bf4e-4de4-a206-809b889b3cbc,DISK], DatanodeInfoWithStorage[127.0.0.1:39342,DS-215f0256-e9b6-4d28-bf35-1ed0bf89cc0a,DISK], DatanodeInfoWithStorage[127.0.0.1:44361,DS-186f9939-1fac-4cbf-b4d6-fa9f48f5e1c2,DISK], DatanodeInfoWithStorage[127.0.0.1:38919,DS-7b977207-1bce-4917-9fc4-29c47c114334,DISK], DatanodeInfoWithStorage[127.0.0.1:39870,DS-edcaa98f-614d-41da-9fcd-572395cec665,DISK], DatanodeInfoWithStorage[127.0.0.1:36787,DS-c0d70083-3565-48af-b218-07a2716ced13,DISK], DatanodeInfoWithStorage[127.0.0.1:38159,DS-b8d5f25f-25f0-4ace-9452-fc42c4e7f6d7,DISK], DatanodeInfoWithStorage[127.0.0.1:37134,DS-c5bc820b-b0ee-44be-8adc-2e2b18abf11e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-846997685-172.17.0.4-1598459910085:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41630,DS-0a1edef0-4fd6-4619-b23c-feb1fb61c835,DISK], DatanodeInfoWithStorage[127.0.0.1:37071,DS-1f8c5a4a-a23a-42f0-a8b4-91ff15d3dd43,DISK], DatanodeInfoWithStorage[127.0.0.1:44142,DS-5f06e5c2-c5e2-4c44-b221-d4136693d309,DISK], DatanodeInfoWithStorage[127.0.0.1:37028,DS-1fadf4aa-dd2c-42bc-8eae-aab27966abf0,DISK], DatanodeInfoWithStorage[127.0.0.1:34266,DS-a831a898-0d99-4699-ab9f-1816d07f7b43,DISK], DatanodeInfoWithStorage[127.0.0.1:41107,DS-ca670461-80bb-4861-bc81-01b243eb077e,DISK], DatanodeInfoWithStorage[127.0.0.1:40774,DS-523b757b-f634-431e-a164-adbc06ddadea,DISK], DatanodeInfoWithStorage[127.0.0.1:43983,DS-a05baebd-536b-43e3-b44e-033f0a9e466d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-846997685-172.17.0.4-1598459910085:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41630,DS-0a1edef0-4fd6-4619-b23c-feb1fb61c835,DISK], DatanodeInfoWithStorage[127.0.0.1:37071,DS-1f8c5a4a-a23a-42f0-a8b4-91ff15d3dd43,DISK], DatanodeInfoWithStorage[127.0.0.1:44142,DS-5f06e5c2-c5e2-4c44-b221-d4136693d309,DISK], DatanodeInfoWithStorage[127.0.0.1:37028,DS-1fadf4aa-dd2c-42bc-8eae-aab27966abf0,DISK], DatanodeInfoWithStorage[127.0.0.1:34266,DS-a831a898-0d99-4699-ab9f-1816d07f7b43,DISK], DatanodeInfoWithStorage[127.0.0.1:41107,DS-ca670461-80bb-4861-bc81-01b243eb077e,DISK], DatanodeInfoWithStorage[127.0.0.1:40774,DS-523b757b-f634-431e-a164-adbc06ddadea,DISK], DatanodeInfoWithStorage[127.0.0.1:43983,DS-a05baebd-536b-43e3-b44e-033f0a9e466d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-553376724-172.17.0.4-1598461423709:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40661,DS-50128e97-cd0a-4ac3-b8c3-765ddb8028bb,DISK], DatanodeInfoWithStorage[127.0.0.1:43428,DS-f8647b6b-f940-475d-b728-6d2beeeb6d9b,DISK], DatanodeInfoWithStorage[127.0.0.1:35415,DS-c764591b-280d-4418-a642-53b97cafe575,DISK], DatanodeInfoWithStorage[127.0.0.1:46125,DS-00c9d6ea-46c0-4908-933a-159a71b43139,DISK], DatanodeInfoWithStorage[127.0.0.1:35157,DS-71a51786-6fbf-4944-8b03-94294aeec41b,DISK], DatanodeInfoWithStorage[127.0.0.1:45393,DS-54f419e8-930e-49fa-9711-1d47c38cc18b,DISK], DatanodeInfoWithStorage[127.0.0.1:41902,DS-b45cd397-3498-453f-b97b-893ff317a50e,DISK], DatanodeInfoWithStorage[127.0.0.1:33088,DS-d35e5910-0b25-402c-85eb-fcd0a1936485,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-553376724-172.17.0.4-1598461423709:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40661,DS-50128e97-cd0a-4ac3-b8c3-765ddb8028bb,DISK], DatanodeInfoWithStorage[127.0.0.1:43428,DS-f8647b6b-f940-475d-b728-6d2beeeb6d9b,DISK], DatanodeInfoWithStorage[127.0.0.1:35415,DS-c764591b-280d-4418-a642-53b97cafe575,DISK], DatanodeInfoWithStorage[127.0.0.1:46125,DS-00c9d6ea-46c0-4908-933a-159a71b43139,DISK], DatanodeInfoWithStorage[127.0.0.1:35157,DS-71a51786-6fbf-4944-8b03-94294aeec41b,DISK], DatanodeInfoWithStorage[127.0.0.1:45393,DS-54f419e8-930e-49fa-9711-1d47c38cc18b,DISK], DatanodeInfoWithStorage[127.0.0.1:41902,DS-b45cd397-3498-453f-b97b-893ff317a50e,DISK], DatanodeInfoWithStorage[127.0.0.1:33088,DS-d35e5910-0b25-402c-85eb-fcd0a1936485,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1902843124-172.17.0.4-1598461466317:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41818,DS-d72c26e9-261a-468a-9193-d728e438059f,DISK], DatanodeInfoWithStorage[127.0.0.1:36872,DS-8e998abd-28bb-4aa9-adab-8de58a657d15,DISK], DatanodeInfoWithStorage[127.0.0.1:37317,DS-2487b640-5050-4703-80d2-4a160d75367a,DISK], DatanodeInfoWithStorage[127.0.0.1:37727,DS-60f6f972-234b-47c8-9cf8-08ff53b7a8f2,DISK], DatanodeInfoWithStorage[127.0.0.1:34415,DS-e6433b41-8fdf-4007-a9b4-14d8098d7e3a,DISK], DatanodeInfoWithStorage[127.0.0.1:42085,DS-9d88f240-dd16-4146-ac00-d620dc0bd9a2,DISK], DatanodeInfoWithStorage[127.0.0.1:45562,DS-cbb9fc23-5ef3-4f84-ab54-2e59313faf06,DISK], DatanodeInfoWithStorage[127.0.0.1:41515,DS-968d1b73-e178-43b1-9c92-176faab1931d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1902843124-172.17.0.4-1598461466317:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41818,DS-d72c26e9-261a-468a-9193-d728e438059f,DISK], DatanodeInfoWithStorage[127.0.0.1:36872,DS-8e998abd-28bb-4aa9-adab-8de58a657d15,DISK], DatanodeInfoWithStorage[127.0.0.1:37317,DS-2487b640-5050-4703-80d2-4a160d75367a,DISK], DatanodeInfoWithStorage[127.0.0.1:37727,DS-60f6f972-234b-47c8-9cf8-08ff53b7a8f2,DISK], DatanodeInfoWithStorage[127.0.0.1:34415,DS-e6433b41-8fdf-4007-a9b4-14d8098d7e3a,DISK], DatanodeInfoWithStorage[127.0.0.1:42085,DS-9d88f240-dd16-4146-ac00-d620dc0bd9a2,DISK], DatanodeInfoWithStorage[127.0.0.1:45562,DS-cbb9fc23-5ef3-4f84-ab54-2e59313faf06,DISK], DatanodeInfoWithStorage[127.0.0.1:41515,DS-968d1b73-e178-43b1-9c92-176faab1931d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1645399934-172.17.0.4-1598462185551:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45572,DS-228fef59-5b71-45ba-b00f-1aecbd5dd5f2,DISK], DatanodeInfoWithStorage[127.0.0.1:41599,DS-d6d42cdd-9318-4a24-82ac-7ac966897aea,DISK], DatanodeInfoWithStorage[127.0.0.1:35636,DS-9e3db195-ac57-445f-b9df-74e1d71a814f,DISK], DatanodeInfoWithStorage[127.0.0.1:36167,DS-e44cda61-faf4-47dc-9cd3-5e160c3b16c4,DISK], DatanodeInfoWithStorage[127.0.0.1:36480,DS-72e85d65-6473-4c9f-bf77-d1bf2dfdfb69,DISK], DatanodeInfoWithStorage[127.0.0.1:37148,DS-e9161902-fe12-4502-8b65-5617cef92fbf,DISK], DatanodeInfoWithStorage[127.0.0.1:40678,DS-130c3e20-5916-4ec2-a008-73c9fa402d1b,DISK], DatanodeInfoWithStorage[127.0.0.1:35395,DS-8800c381-87c2-4037-bb28-ed397bc5ddee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1645399934-172.17.0.4-1598462185551:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45572,DS-228fef59-5b71-45ba-b00f-1aecbd5dd5f2,DISK], DatanodeInfoWithStorage[127.0.0.1:41599,DS-d6d42cdd-9318-4a24-82ac-7ac966897aea,DISK], DatanodeInfoWithStorage[127.0.0.1:35636,DS-9e3db195-ac57-445f-b9df-74e1d71a814f,DISK], DatanodeInfoWithStorage[127.0.0.1:36167,DS-e44cda61-faf4-47dc-9cd3-5e160c3b16c4,DISK], DatanodeInfoWithStorage[127.0.0.1:36480,DS-72e85d65-6473-4c9f-bf77-d1bf2dfdfb69,DISK], DatanodeInfoWithStorage[127.0.0.1:37148,DS-e9161902-fe12-4502-8b65-5617cef92fbf,DISK], DatanodeInfoWithStorage[127.0.0.1:40678,DS-130c3e20-5916-4ec2-a008-73c9fa402d1b,DISK], DatanodeInfoWithStorage[127.0.0.1:35395,DS-8800c381-87c2-4037-bb28-ed397bc5ddee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-410789400-172.17.0.4-1598462432332:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37611,DS-f62d5e49-ddf7-4f79-9626-b22b6a71608f,DISK], DatanodeInfoWithStorage[127.0.0.1:37697,DS-5c2c470b-1ad5-406d-8579-925454631d14,DISK], DatanodeInfoWithStorage[127.0.0.1:45153,DS-db47cd14-81eb-4bd8-a142-02234c40da10,DISK], DatanodeInfoWithStorage[127.0.0.1:40980,DS-293a6852-14ee-4755-80c7-56efdb2dce1d,DISK], DatanodeInfoWithStorage[127.0.0.1:37974,DS-ed893c89-1e4c-4284-a55c-09ad03e8eb78,DISK], DatanodeInfoWithStorage[127.0.0.1:40045,DS-af2bedf5-374b-4f45-a863-b5e21a86ad91,DISK], DatanodeInfoWithStorage[127.0.0.1:44246,DS-05769071-c4dc-4312-bfbb-6b26835daed7,DISK], DatanodeInfoWithStorage[127.0.0.1:35657,DS-acba0e48-35b7-48b3-aa39-325252a303c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-410789400-172.17.0.4-1598462432332:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37611,DS-f62d5e49-ddf7-4f79-9626-b22b6a71608f,DISK], DatanodeInfoWithStorage[127.0.0.1:37697,DS-5c2c470b-1ad5-406d-8579-925454631d14,DISK], DatanodeInfoWithStorage[127.0.0.1:45153,DS-db47cd14-81eb-4bd8-a142-02234c40da10,DISK], DatanodeInfoWithStorage[127.0.0.1:40980,DS-293a6852-14ee-4755-80c7-56efdb2dce1d,DISK], DatanodeInfoWithStorage[127.0.0.1:37974,DS-ed893c89-1e4c-4284-a55c-09ad03e8eb78,DISK], DatanodeInfoWithStorage[127.0.0.1:40045,DS-af2bedf5-374b-4f45-a863-b5e21a86ad91,DISK], DatanodeInfoWithStorage[127.0.0.1:44246,DS-05769071-c4dc-4312-bfbb-6b26835daed7,DISK], DatanodeInfoWithStorage[127.0.0.1:35657,DS-acba0e48-35b7-48b3-aa39-325252a303c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-145611253-172.17.0.4-1598462768063:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44968,DS-2f44c8a2-8c06-4081-825e-3f478bd212d3,DISK], DatanodeInfoWithStorage[127.0.0.1:40697,DS-4eabaeb3-97cd-44be-b6fc-f034251d08b5,DISK], DatanodeInfoWithStorage[127.0.0.1:37559,DS-8a07b354-1cd4-457d-be86-553d2b271b90,DISK], DatanodeInfoWithStorage[127.0.0.1:45048,DS-269c4199-b519-4f80-b38d-d187ac6c162c,DISK], DatanodeInfoWithStorage[127.0.0.1:45427,DS-6538d954-2a43-47df-961d-72a1659f2409,DISK], DatanodeInfoWithStorage[127.0.0.1:39458,DS-d8083be9-d6a7-432f-beeb-e0619adfb76a,DISK], DatanodeInfoWithStorage[127.0.0.1:33084,DS-3ecde974-2301-4eda-b0c8-d4a110b57d1c,DISK], DatanodeInfoWithStorage[127.0.0.1:34166,DS-f2a04b41-f60e-45b0-9576-cc9282d66179,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-145611253-172.17.0.4-1598462768063:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44968,DS-2f44c8a2-8c06-4081-825e-3f478bd212d3,DISK], DatanodeInfoWithStorage[127.0.0.1:40697,DS-4eabaeb3-97cd-44be-b6fc-f034251d08b5,DISK], DatanodeInfoWithStorage[127.0.0.1:37559,DS-8a07b354-1cd4-457d-be86-553d2b271b90,DISK], DatanodeInfoWithStorage[127.0.0.1:45048,DS-269c4199-b519-4f80-b38d-d187ac6c162c,DISK], DatanodeInfoWithStorage[127.0.0.1:45427,DS-6538d954-2a43-47df-961d-72a1659f2409,DISK], DatanodeInfoWithStorage[127.0.0.1:39458,DS-d8083be9-d6a7-432f-beeb-e0619adfb76a,DISK], DatanodeInfoWithStorage[127.0.0.1:33084,DS-3ecde974-2301-4eda-b0c8-d4a110b57d1c,DISK], DatanodeInfoWithStorage[127.0.0.1:34166,DS-f2a04b41-f60e-45b0-9576-cc9282d66179,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 1 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5526
