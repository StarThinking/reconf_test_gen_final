reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2113736830-172.17.0.8-1598420103916:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35949,DS-9476b936-f911-4a1e-be5f-97c81006452f,DISK], DatanodeInfoWithStorage[127.0.0.1:34198,DS-aa4da827-08ca-4f34-a65f-263aa5089a81,DISK], DatanodeInfoWithStorage[127.0.0.1:37020,DS-90926b73-7d1e-40f3-a8cb-b8f523e6749e,DISK], DatanodeInfoWithStorage[127.0.0.1:38099,DS-b3c8aa93-1a87-411a-b838-cab7c6f2591a,DISK], DatanodeInfoWithStorage[127.0.0.1:33132,DS-b4524e03-112b-429f-814a-78ce2b50e325,DISK], DatanodeInfoWithStorage[127.0.0.1:46368,DS-8d9770ec-4123-4941-895d-b28d522ff2bf,DISK], DatanodeInfoWithStorage[127.0.0.1:41259,DS-7476e7c4-7514-437f-9cfa-1cd90a8fc407,DISK], DatanodeInfoWithStorage[127.0.0.1:36048,DS-e99983c0-ec22-4c62-86f3-79ac3d6b2381,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2113736830-172.17.0.8-1598420103916:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35949,DS-9476b936-f911-4a1e-be5f-97c81006452f,DISK], DatanodeInfoWithStorage[127.0.0.1:34198,DS-aa4da827-08ca-4f34-a65f-263aa5089a81,DISK], DatanodeInfoWithStorage[127.0.0.1:37020,DS-90926b73-7d1e-40f3-a8cb-b8f523e6749e,DISK], DatanodeInfoWithStorage[127.0.0.1:38099,DS-b3c8aa93-1a87-411a-b838-cab7c6f2591a,DISK], DatanodeInfoWithStorage[127.0.0.1:33132,DS-b4524e03-112b-429f-814a-78ce2b50e325,DISK], DatanodeInfoWithStorage[127.0.0.1:46368,DS-8d9770ec-4123-4941-895d-b28d522ff2bf,DISK], DatanodeInfoWithStorage[127.0.0.1:41259,DS-7476e7c4-7514-437f-9cfa-1cd90a8fc407,DISK], DatanodeInfoWithStorage[127.0.0.1:36048,DS-e99983c0-ec22-4c62-86f3-79ac3d6b2381,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1890348263-172.17.0.8-1598420500917:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38222,DS-31b07182-935d-44f0-9554-9cb6c3f1944c,DISK], DatanodeInfoWithStorage[127.0.0.1:42629,DS-097b0740-1786-4088-9644-2022e819c515,DISK], DatanodeInfoWithStorage[127.0.0.1:45220,DS-3a6343eb-710b-4689-9230-7797a5cc80b7,DISK], DatanodeInfoWithStorage[127.0.0.1:34001,DS-c953a1b8-0b36-4aec-a8ab-af613f10adbb,DISK], DatanodeInfoWithStorage[127.0.0.1:42430,DS-89dea62d-5e76-449a-81e5-76074c1500e3,DISK], DatanodeInfoWithStorage[127.0.0.1:40698,DS-172ab93b-f4f2-4c3a-b3a1-ef0af26ab5aa,DISK], DatanodeInfoWithStorage[127.0.0.1:33928,DS-0d5e4bef-5855-420b-8df7-ba168cba825c,DISK], DatanodeInfoWithStorage[127.0.0.1:33857,DS-f6dfe89a-838c-4d8a-b998-bd3a69fa23e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1890348263-172.17.0.8-1598420500917:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38222,DS-31b07182-935d-44f0-9554-9cb6c3f1944c,DISK], DatanodeInfoWithStorage[127.0.0.1:42629,DS-097b0740-1786-4088-9644-2022e819c515,DISK], DatanodeInfoWithStorage[127.0.0.1:45220,DS-3a6343eb-710b-4689-9230-7797a5cc80b7,DISK], DatanodeInfoWithStorage[127.0.0.1:34001,DS-c953a1b8-0b36-4aec-a8ab-af613f10adbb,DISK], DatanodeInfoWithStorage[127.0.0.1:42430,DS-89dea62d-5e76-449a-81e5-76074c1500e3,DISK], DatanodeInfoWithStorage[127.0.0.1:40698,DS-172ab93b-f4f2-4c3a-b3a1-ef0af26ab5aa,DISK], DatanodeInfoWithStorage[127.0.0.1:33928,DS-0d5e4bef-5855-420b-8df7-ba168cba825c,DISK], DatanodeInfoWithStorage[127.0.0.1:33857,DS-f6dfe89a-838c-4d8a-b998-bd3a69fa23e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-500783078-172.17.0.8-1598421399339:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44511,DS-87470dd4-b8df-4cc0-808c-36d015d6c3e7,DISK], DatanodeInfoWithStorage[127.0.0.1:36697,DS-bbd90f6e-a551-4a12-998e-2c50528aad67,DISK], DatanodeInfoWithStorage[127.0.0.1:36655,DS-e712a1ef-37e5-41a3-99d7-e777129ed736,DISK], DatanodeInfoWithStorage[127.0.0.1:40435,DS-a68675f4-0317-4d7e-9632-ada8f505e319,DISK], DatanodeInfoWithStorage[127.0.0.1:38000,DS-8939f795-d9f6-42bb-88b8-31d767165d4e,DISK], DatanodeInfoWithStorage[127.0.0.1:35236,DS-e6dde2f1-dfd7-44f2-9633-13ad65ebe1bc,DISK], DatanodeInfoWithStorage[127.0.0.1:37580,DS-b61fbf27-3727-4ea7-9efe-f348c910e396,DISK], DatanodeInfoWithStorage[127.0.0.1:37273,DS-aae4a051-2a71-45df-a815-29981a99b998,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-500783078-172.17.0.8-1598421399339:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44511,DS-87470dd4-b8df-4cc0-808c-36d015d6c3e7,DISK], DatanodeInfoWithStorage[127.0.0.1:36697,DS-bbd90f6e-a551-4a12-998e-2c50528aad67,DISK], DatanodeInfoWithStorage[127.0.0.1:36655,DS-e712a1ef-37e5-41a3-99d7-e777129ed736,DISK], DatanodeInfoWithStorage[127.0.0.1:40435,DS-a68675f4-0317-4d7e-9632-ada8f505e319,DISK], DatanodeInfoWithStorage[127.0.0.1:38000,DS-8939f795-d9f6-42bb-88b8-31d767165d4e,DISK], DatanodeInfoWithStorage[127.0.0.1:35236,DS-e6dde2f1-dfd7-44f2-9633-13ad65ebe1bc,DISK], DatanodeInfoWithStorage[127.0.0.1:37580,DS-b61fbf27-3727-4ea7-9efe-f348c910e396,DISK], DatanodeInfoWithStorage[127.0.0.1:37273,DS-aae4a051-2a71-45df-a815-29981a99b998,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1511086986-172.17.0.8-1598421616716:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44117,DS-bc9c7d83-17f9-4e1d-995f-09288c244cc8,DISK], DatanodeInfoWithStorage[127.0.0.1:37439,DS-9d8e7b62-2217-4bcb-bfda-7c3ec1521310,DISK], DatanodeInfoWithStorage[127.0.0.1:37253,DS-c7d98737-54a2-4bbe-aa3e-41613f1ece75,DISK], DatanodeInfoWithStorage[127.0.0.1:42067,DS-d3cc7f9c-41d5-41c1-93a8-ab9b29070010,DISK], DatanodeInfoWithStorage[127.0.0.1:43408,DS-70fc5d64-c993-4223-ad00-2ecc43f29009,DISK], DatanodeInfoWithStorage[127.0.0.1:43833,DS-09ad97f2-f84b-445e-b053-ef0726584947,DISK], DatanodeInfoWithStorage[127.0.0.1:38733,DS-40cbd885-f2bf-42f4-9e55-70f7fcf5e0dd,DISK], DatanodeInfoWithStorage[127.0.0.1:38714,DS-46ca255a-50c9-46e4-a47a-68f67483e0fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1511086986-172.17.0.8-1598421616716:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44117,DS-bc9c7d83-17f9-4e1d-995f-09288c244cc8,DISK], DatanodeInfoWithStorage[127.0.0.1:37439,DS-9d8e7b62-2217-4bcb-bfda-7c3ec1521310,DISK], DatanodeInfoWithStorage[127.0.0.1:37253,DS-c7d98737-54a2-4bbe-aa3e-41613f1ece75,DISK], DatanodeInfoWithStorage[127.0.0.1:42067,DS-d3cc7f9c-41d5-41c1-93a8-ab9b29070010,DISK], DatanodeInfoWithStorage[127.0.0.1:43408,DS-70fc5d64-c993-4223-ad00-2ecc43f29009,DISK], DatanodeInfoWithStorage[127.0.0.1:43833,DS-09ad97f2-f84b-445e-b053-ef0726584947,DISK], DatanodeInfoWithStorage[127.0.0.1:38733,DS-40cbd885-f2bf-42f4-9e55-70f7fcf5e0dd,DISK], DatanodeInfoWithStorage[127.0.0.1:38714,DS-46ca255a-50c9-46e4-a47a-68f67483e0fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1435239162-172.17.0.8-1598421689367:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39949,DS-3dbea41a-0414-412c-a257-c833a577c279,DISK], DatanodeInfoWithStorage[127.0.0.1:41872,DS-7e9ee24b-f01b-434a-8524-b311bd49924c,DISK], DatanodeInfoWithStorage[127.0.0.1:38704,DS-bab9b2a9-c6a9-4eac-bf50-41116fa28c37,DISK], DatanodeInfoWithStorage[127.0.0.1:36535,DS-841f42f4-49b0-4bfd-9374-b9ba2b470f70,DISK], DatanodeInfoWithStorage[127.0.0.1:42521,DS-b6c356cc-5245-4d6e-af84-59a48654f2dc,DISK], DatanodeInfoWithStorage[127.0.0.1:40608,DS-5afd50d6-5884-4746-b3d9-4b39c2793efa,DISK], DatanodeInfoWithStorage[127.0.0.1:33302,DS-48910170-29b5-408a-a73d-c1494aba21e5,DISK], DatanodeInfoWithStorage[127.0.0.1:42065,DS-0fa2cf18-1439-46c8-8b9d-5a21fa809c7d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1435239162-172.17.0.8-1598421689367:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39949,DS-3dbea41a-0414-412c-a257-c833a577c279,DISK], DatanodeInfoWithStorage[127.0.0.1:41872,DS-7e9ee24b-f01b-434a-8524-b311bd49924c,DISK], DatanodeInfoWithStorage[127.0.0.1:38704,DS-bab9b2a9-c6a9-4eac-bf50-41116fa28c37,DISK], DatanodeInfoWithStorage[127.0.0.1:36535,DS-841f42f4-49b0-4bfd-9374-b9ba2b470f70,DISK], DatanodeInfoWithStorage[127.0.0.1:42521,DS-b6c356cc-5245-4d6e-af84-59a48654f2dc,DISK], DatanodeInfoWithStorage[127.0.0.1:40608,DS-5afd50d6-5884-4746-b3d9-4b39c2793efa,DISK], DatanodeInfoWithStorage[127.0.0.1:33302,DS-48910170-29b5-408a-a73d-c1494aba21e5,DISK], DatanodeInfoWithStorage[127.0.0.1:42065,DS-0fa2cf18-1439-46c8-8b9d-5a21fa809c7d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1788305049-172.17.0.8-1598421816209:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33271,DS-d711e7f0-0938-4ed6-a251-2c726313c408,DISK], DatanodeInfoWithStorage[127.0.0.1:42752,DS-e8dd592e-56bd-4432-8580-82489b16500c,DISK], DatanodeInfoWithStorage[127.0.0.1:40473,DS-a31ce5b0-94d0-461c-a1b9-af4750db20cd,DISK], DatanodeInfoWithStorage[127.0.0.1:45858,DS-3aabb1ae-6d3b-47e1-8e23-679cb479d879,DISK], DatanodeInfoWithStorage[127.0.0.1:42912,DS-ebb7425c-df5e-4b68-9676-cbeeb0088f2d,DISK], DatanodeInfoWithStorage[127.0.0.1:42751,DS-a0780f96-9317-44da-a451-1081689bdcd8,DISK], DatanodeInfoWithStorage[127.0.0.1:34510,DS-13d69ed5-633f-4ea4-91c6-39dbb3c0c4f9,DISK], DatanodeInfoWithStorage[127.0.0.1:35551,DS-5a189562-96c8-4edc-8d75-6cd4a9b5c171,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1788305049-172.17.0.8-1598421816209:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33271,DS-d711e7f0-0938-4ed6-a251-2c726313c408,DISK], DatanodeInfoWithStorage[127.0.0.1:42752,DS-e8dd592e-56bd-4432-8580-82489b16500c,DISK], DatanodeInfoWithStorage[127.0.0.1:40473,DS-a31ce5b0-94d0-461c-a1b9-af4750db20cd,DISK], DatanodeInfoWithStorage[127.0.0.1:45858,DS-3aabb1ae-6d3b-47e1-8e23-679cb479d879,DISK], DatanodeInfoWithStorage[127.0.0.1:42912,DS-ebb7425c-df5e-4b68-9676-cbeeb0088f2d,DISK], DatanodeInfoWithStorage[127.0.0.1:42751,DS-a0780f96-9317-44da-a451-1081689bdcd8,DISK], DatanodeInfoWithStorage[127.0.0.1:34510,DS-13d69ed5-633f-4ea4-91c6-39dbb3c0c4f9,DISK], DatanodeInfoWithStorage[127.0.0.1:35551,DS-5a189562-96c8-4edc-8d75-6cd4a9b5c171,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1111474430-172.17.0.8-1598422242945:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36273,DS-d62d8434-4a83-44e5-b8f4-995e7d8009f0,DISK], DatanodeInfoWithStorage[127.0.0.1:44539,DS-24a274e5-2121-4384-847f-5b8515ebb6fb,DISK], DatanodeInfoWithStorage[127.0.0.1:41018,DS-7b7f150c-2c81-4839-a33d-9417387a7ffc,DISK], DatanodeInfoWithStorage[127.0.0.1:43930,DS-24749900-79c1-4914-8bdb-4971fe1293a7,DISK], DatanodeInfoWithStorage[127.0.0.1:39302,DS-9af5703a-4a51-49b2-ac31-b21b99a66063,DISK], DatanodeInfoWithStorage[127.0.0.1:43081,DS-82a8752a-23c1-4bc2-b25e-db2e2a53fa00,DISK], DatanodeInfoWithStorage[127.0.0.1:33729,DS-0dbc192f-a96c-43cc-838c-2dd1e77b7ba8,DISK], DatanodeInfoWithStorage[127.0.0.1:42652,DS-087e2e2d-c366-4d99-b371-2c67b84d6bd3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1111474430-172.17.0.8-1598422242945:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36273,DS-d62d8434-4a83-44e5-b8f4-995e7d8009f0,DISK], DatanodeInfoWithStorage[127.0.0.1:44539,DS-24a274e5-2121-4384-847f-5b8515ebb6fb,DISK], DatanodeInfoWithStorage[127.0.0.1:41018,DS-7b7f150c-2c81-4839-a33d-9417387a7ffc,DISK], DatanodeInfoWithStorage[127.0.0.1:43930,DS-24749900-79c1-4914-8bdb-4971fe1293a7,DISK], DatanodeInfoWithStorage[127.0.0.1:39302,DS-9af5703a-4a51-49b2-ac31-b21b99a66063,DISK], DatanodeInfoWithStorage[127.0.0.1:43081,DS-82a8752a-23c1-4bc2-b25e-db2e2a53fa00,DISK], DatanodeInfoWithStorage[127.0.0.1:33729,DS-0dbc192f-a96c-43cc-838c-2dd1e77b7ba8,DISK], DatanodeInfoWithStorage[127.0.0.1:42652,DS-087e2e2d-c366-4d99-b371-2c67b84d6bd3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-97908263-172.17.0.8-1598422464028:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33705,DS-c88f79ab-75a7-48e5-b190-4370fd14fe72,DISK], DatanodeInfoWithStorage[127.0.0.1:33004,DS-840ad057-46c5-4973-a9ed-44c2a7522e76,DISK], DatanodeInfoWithStorage[127.0.0.1:42339,DS-88dc1365-5bea-4e65-88de-1ee577cacf1d,DISK], DatanodeInfoWithStorage[127.0.0.1:36620,DS-1e43207d-a100-41f6-a46c-3d01d4f73cea,DISK], DatanodeInfoWithStorage[127.0.0.1:44120,DS-fd1bcf4d-e84a-4083-98a8-09733a7d3443,DISK], DatanodeInfoWithStorage[127.0.0.1:43807,DS-ad8fd27f-2324-478b-8aea-6547d1b5ce7c,DISK], DatanodeInfoWithStorage[127.0.0.1:43131,DS-b0e9a06d-4fe1-4cc8-a0a2-3362ecab13f2,DISK], DatanodeInfoWithStorage[127.0.0.1:36821,DS-f85e2290-0313-42d6-aab3-9f66a0d7ce8f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-97908263-172.17.0.8-1598422464028:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33705,DS-c88f79ab-75a7-48e5-b190-4370fd14fe72,DISK], DatanodeInfoWithStorage[127.0.0.1:33004,DS-840ad057-46c5-4973-a9ed-44c2a7522e76,DISK], DatanodeInfoWithStorage[127.0.0.1:42339,DS-88dc1365-5bea-4e65-88de-1ee577cacf1d,DISK], DatanodeInfoWithStorage[127.0.0.1:36620,DS-1e43207d-a100-41f6-a46c-3d01d4f73cea,DISK], DatanodeInfoWithStorage[127.0.0.1:44120,DS-fd1bcf4d-e84a-4083-98a8-09733a7d3443,DISK], DatanodeInfoWithStorage[127.0.0.1:43807,DS-ad8fd27f-2324-478b-8aea-6547d1b5ce7c,DISK], DatanodeInfoWithStorage[127.0.0.1:43131,DS-b0e9a06d-4fe1-4cc8-a0a2-3362ecab13f2,DISK], DatanodeInfoWithStorage[127.0.0.1:36821,DS-f85e2290-0313-42d6-aab3-9f66a0d7ce8f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-770474003-172.17.0.8-1598422779511:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39159,DS-743edf33-3ad9-4a40-8c1b-a02459fc8be5,DISK], DatanodeInfoWithStorage[127.0.0.1:37264,DS-045b9dd0-fe97-48e1-bcf7-397ed7cee452,DISK], DatanodeInfoWithStorage[127.0.0.1:35732,DS-258ab6ef-f6f8-4598-ac20-e8201ff3a868,DISK], DatanodeInfoWithStorage[127.0.0.1:33807,DS-8bf55a2c-c5ca-40eb-bbf8-a1093e607370,DISK], DatanodeInfoWithStorage[127.0.0.1:32794,DS-c933e103-2338-4d24-a89e-d93d2f6f96e8,DISK], DatanodeInfoWithStorage[127.0.0.1:37730,DS-3d40a398-ee4d-44af-80bf-d3206bb56547,DISK], DatanodeInfoWithStorage[127.0.0.1:36827,DS-0ea515e2-8c30-4ae7-ba2a-d0d54c818000,DISK], DatanodeInfoWithStorage[127.0.0.1:40101,DS-b87a1714-9b8c-486a-8368-7e222ff8b384,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-770474003-172.17.0.8-1598422779511:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39159,DS-743edf33-3ad9-4a40-8c1b-a02459fc8be5,DISK], DatanodeInfoWithStorage[127.0.0.1:37264,DS-045b9dd0-fe97-48e1-bcf7-397ed7cee452,DISK], DatanodeInfoWithStorage[127.0.0.1:35732,DS-258ab6ef-f6f8-4598-ac20-e8201ff3a868,DISK], DatanodeInfoWithStorage[127.0.0.1:33807,DS-8bf55a2c-c5ca-40eb-bbf8-a1093e607370,DISK], DatanodeInfoWithStorage[127.0.0.1:32794,DS-c933e103-2338-4d24-a89e-d93d2f6f96e8,DISK], DatanodeInfoWithStorage[127.0.0.1:37730,DS-3d40a398-ee4d-44af-80bf-d3206bb56547,DISK], DatanodeInfoWithStorage[127.0.0.1:36827,DS-0ea515e2-8c30-4ae7-ba2a-d0d54c818000,DISK], DatanodeInfoWithStorage[127.0.0.1:40101,DS-b87a1714-9b8c-486a-8368-7e222ff8b384,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-371182466-172.17.0.8-1598422988705:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41257,DS-e7ae9dc3-882f-4696-ad3f-e0b3ac9f2350,DISK], DatanodeInfoWithStorage[127.0.0.1:33649,DS-4775a455-2c73-46b0-bd2c-b9c4d8069f4e,DISK], DatanodeInfoWithStorage[127.0.0.1:37641,DS-6693c48b-8986-41e7-9c96-387d3d56ec99,DISK], DatanodeInfoWithStorage[127.0.0.1:39879,DS-bdce3198-23c2-4c6b-91d4-c8c23081af0a,DISK], DatanodeInfoWithStorage[127.0.0.1:46642,DS-fa5c4d7d-8659-4852-9902-10276f6f4705,DISK], DatanodeInfoWithStorage[127.0.0.1:33670,DS-acc818bd-2a23-439c-b656-933f4377b9f0,DISK], DatanodeInfoWithStorage[127.0.0.1:38293,DS-ed391efe-8dc1-442a-ae0a-a9cd06c38c26,DISK], DatanodeInfoWithStorage[127.0.0.1:38794,DS-dda644c2-5c8e-4d24-a2ff-26bb89ff72d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-371182466-172.17.0.8-1598422988705:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41257,DS-e7ae9dc3-882f-4696-ad3f-e0b3ac9f2350,DISK], DatanodeInfoWithStorage[127.0.0.1:33649,DS-4775a455-2c73-46b0-bd2c-b9c4d8069f4e,DISK], DatanodeInfoWithStorage[127.0.0.1:37641,DS-6693c48b-8986-41e7-9c96-387d3d56ec99,DISK], DatanodeInfoWithStorage[127.0.0.1:39879,DS-bdce3198-23c2-4c6b-91d4-c8c23081af0a,DISK], DatanodeInfoWithStorage[127.0.0.1:46642,DS-fa5c4d7d-8659-4852-9902-10276f6f4705,DISK], DatanodeInfoWithStorage[127.0.0.1:33670,DS-acc818bd-2a23-439c-b656-933f4377b9f0,DISK], DatanodeInfoWithStorage[127.0.0.1:38293,DS-ed391efe-8dc1-442a-ae0a-a9cd06c38c26,DISK], DatanodeInfoWithStorage[127.0.0.1:38794,DS-dda644c2-5c8e-4d24-a2ff-26bb89ff72d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1647970907-172.17.0.8-1598423123079:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36428,DS-d70345df-6541-4809-a21d-49d447149767,DISK], DatanodeInfoWithStorage[127.0.0.1:36634,DS-d003ad73-385c-45a3-94e7-a51816a6f29b,DISK], DatanodeInfoWithStorage[127.0.0.1:43429,DS-0ce85646-29a4-4cf6-8d05-91a779eb3e61,DISK], DatanodeInfoWithStorage[127.0.0.1:40946,DS-bc58d54b-babc-4eba-9208-b0b012f916a3,DISK], DatanodeInfoWithStorage[127.0.0.1:32840,DS-ed435871-220a-4dc5-b4d5-8e88c4600019,DISK], DatanodeInfoWithStorage[127.0.0.1:37081,DS-0a7b8f56-4c26-4d7e-b663-5b218b0e2116,DISK], DatanodeInfoWithStorage[127.0.0.1:36516,DS-71d3d72a-1dce-4345-bc62-b53e4fb51cce,DISK], DatanodeInfoWithStorage[127.0.0.1:38317,DS-13de4435-0598-4532-a3f5-996424153c3d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1647970907-172.17.0.8-1598423123079:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36428,DS-d70345df-6541-4809-a21d-49d447149767,DISK], DatanodeInfoWithStorage[127.0.0.1:36634,DS-d003ad73-385c-45a3-94e7-a51816a6f29b,DISK], DatanodeInfoWithStorage[127.0.0.1:43429,DS-0ce85646-29a4-4cf6-8d05-91a779eb3e61,DISK], DatanodeInfoWithStorage[127.0.0.1:40946,DS-bc58d54b-babc-4eba-9208-b0b012f916a3,DISK], DatanodeInfoWithStorage[127.0.0.1:32840,DS-ed435871-220a-4dc5-b4d5-8e88c4600019,DISK], DatanodeInfoWithStorage[127.0.0.1:37081,DS-0a7b8f56-4c26-4d7e-b663-5b218b0e2116,DISK], DatanodeInfoWithStorage[127.0.0.1:36516,DS-71d3d72a-1dce-4345-bc62-b53e4fb51cce,DISK], DatanodeInfoWithStorage[127.0.0.1:38317,DS-13de4435-0598-4532-a3f5-996424153c3d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2081475177-172.17.0.8-1598423185905:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41861,DS-7e4ac967-ea3c-4cc4-b924-310b105f66ad,DISK], DatanodeInfoWithStorage[127.0.0.1:37521,DS-e63c26fa-76a5-40a9-848e-2c55e8142b71,DISK], DatanodeInfoWithStorage[127.0.0.1:42083,DS-b0c277e2-7f56-4e07-b6cf-d84b0540ac6f,DISK], DatanodeInfoWithStorage[127.0.0.1:38814,DS-2a4c5606-167e-4641-ab8d-c5f837eb39f6,DISK], DatanodeInfoWithStorage[127.0.0.1:37494,DS-e7403f56-178b-4a77-b80c-b1294da90917,DISK], DatanodeInfoWithStorage[127.0.0.1:42584,DS-bb8dbaef-be03-4a97-a449-10196fc4d472,DISK], DatanodeInfoWithStorage[127.0.0.1:45353,DS-5eee491f-113c-4279-bb06-fc4802f8a15f,DISK], DatanodeInfoWithStorage[127.0.0.1:42053,DS-e2956d6b-8ce4-4dc8-a7a9-e8f66966fe7a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2081475177-172.17.0.8-1598423185905:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41861,DS-7e4ac967-ea3c-4cc4-b924-310b105f66ad,DISK], DatanodeInfoWithStorage[127.0.0.1:37521,DS-e63c26fa-76a5-40a9-848e-2c55e8142b71,DISK], DatanodeInfoWithStorage[127.0.0.1:42083,DS-b0c277e2-7f56-4e07-b6cf-d84b0540ac6f,DISK], DatanodeInfoWithStorage[127.0.0.1:38814,DS-2a4c5606-167e-4641-ab8d-c5f837eb39f6,DISK], DatanodeInfoWithStorage[127.0.0.1:37494,DS-e7403f56-178b-4a77-b80c-b1294da90917,DISK], DatanodeInfoWithStorage[127.0.0.1:42584,DS-bb8dbaef-be03-4a97-a449-10196fc4d472,DISK], DatanodeInfoWithStorage[127.0.0.1:45353,DS-5eee491f-113c-4279-bb06-fc4802f8a15f,DISK], DatanodeInfoWithStorage[127.0.0.1:42053,DS-e2956d6b-8ce4-4dc8-a7a9-e8f66966fe7a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1622922647-172.17.0.8-1598423562369:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44997,DS-fc427289-359a-49df-b22e-772c4bb633bb,DISK], DatanodeInfoWithStorage[127.0.0.1:37550,DS-5b24469a-f5bc-403e-b11f-265788fee396,DISK], DatanodeInfoWithStorage[127.0.0.1:39116,DS-1ba00853-d164-477d-8c89-5014c618d548,DISK], DatanodeInfoWithStorage[127.0.0.1:35073,DS-5e67b744-fa80-46a5-9cd7-74f0cf442bb6,DISK], DatanodeInfoWithStorage[127.0.0.1:34971,DS-977df4b6-1898-46b5-85a8-079a88893a37,DISK], DatanodeInfoWithStorage[127.0.0.1:43201,DS-2182f424-234c-40d3-8a2e-402f36bf65b4,DISK], DatanodeInfoWithStorage[127.0.0.1:33816,DS-4a00e485-c9d2-49b8-b58c-8521670c0b1a,DISK], DatanodeInfoWithStorage[127.0.0.1:38321,DS-2450c8f3-0f9b-4f9b-9976-96a2cce26d0b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1622922647-172.17.0.8-1598423562369:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44997,DS-fc427289-359a-49df-b22e-772c4bb633bb,DISK], DatanodeInfoWithStorage[127.0.0.1:37550,DS-5b24469a-f5bc-403e-b11f-265788fee396,DISK], DatanodeInfoWithStorage[127.0.0.1:39116,DS-1ba00853-d164-477d-8c89-5014c618d548,DISK], DatanodeInfoWithStorage[127.0.0.1:35073,DS-5e67b744-fa80-46a5-9cd7-74f0cf442bb6,DISK], DatanodeInfoWithStorage[127.0.0.1:34971,DS-977df4b6-1898-46b5-85a8-079a88893a37,DISK], DatanodeInfoWithStorage[127.0.0.1:43201,DS-2182f424-234c-40d3-8a2e-402f36bf65b4,DISK], DatanodeInfoWithStorage[127.0.0.1:33816,DS-4a00e485-c9d2-49b8-b58c-8521670c0b1a,DISK], DatanodeInfoWithStorage[127.0.0.1:38321,DS-2450c8f3-0f9b-4f9b-9976-96a2cce26d0b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-221777717-172.17.0.8-1598423661087:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43194,DS-79663595-922c-48a4-b007-3ece8becd75c,DISK], DatanodeInfoWithStorage[127.0.0.1:42757,DS-c2af4410-5b68-4cfd-8a86-3092bd3fcd72,DISK], DatanodeInfoWithStorage[127.0.0.1:40302,DS-6f8c70cb-6181-453b-a7e3-a14a7a4a3607,DISK], DatanodeInfoWithStorage[127.0.0.1:34264,DS-48ff1639-5e51-4541-8eef-93d738c40ba3,DISK], DatanodeInfoWithStorage[127.0.0.1:39502,DS-4b28d4c3-cf17-4594-ba7c-70faec6003d6,DISK], DatanodeInfoWithStorage[127.0.0.1:39897,DS-5d196cf7-4c31-4aaa-b9e2-f2456412873b,DISK], DatanodeInfoWithStorage[127.0.0.1:41302,DS-65494353-631f-4081-89b7-2ebb359604c5,DISK], DatanodeInfoWithStorage[127.0.0.1:38934,DS-7f299c80-48a3-4e61-a361-96742fd73fdd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-221777717-172.17.0.8-1598423661087:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43194,DS-79663595-922c-48a4-b007-3ece8becd75c,DISK], DatanodeInfoWithStorage[127.0.0.1:42757,DS-c2af4410-5b68-4cfd-8a86-3092bd3fcd72,DISK], DatanodeInfoWithStorage[127.0.0.1:40302,DS-6f8c70cb-6181-453b-a7e3-a14a7a4a3607,DISK], DatanodeInfoWithStorage[127.0.0.1:34264,DS-48ff1639-5e51-4541-8eef-93d738c40ba3,DISK], DatanodeInfoWithStorage[127.0.0.1:39502,DS-4b28d4c3-cf17-4594-ba7c-70faec6003d6,DISK], DatanodeInfoWithStorage[127.0.0.1:39897,DS-5d196cf7-4c31-4aaa-b9e2-f2456412873b,DISK], DatanodeInfoWithStorage[127.0.0.1:41302,DS-65494353-631f-4081-89b7-2ebb359604c5,DISK], DatanodeInfoWithStorage[127.0.0.1:38934,DS-7f299c80-48a3-4e61-a361-96742fd73fdd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-966640677-172.17.0.8-1598423692259:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41405,DS-d246ee6b-1506-4d36-88e3-10116aee737d,DISK], DatanodeInfoWithStorage[127.0.0.1:37806,DS-7413b84f-d6ed-4c5e-bdfd-355d260e288a,DISK], DatanodeInfoWithStorage[127.0.0.1:46755,DS-d720dd45-77a2-4f88-a9f6-6bd3ab8485a1,DISK], DatanodeInfoWithStorage[127.0.0.1:33836,DS-c49dd285-cc59-4d70-9071-658e4c5ccf21,DISK], DatanodeInfoWithStorage[127.0.0.1:46129,DS-9a90dce0-8912-479b-a42d-062cdbeb8da4,DISK], DatanodeInfoWithStorage[127.0.0.1:42235,DS-bcacd7fb-3cca-4e4a-ad6d-8f9013a549d8,DISK], DatanodeInfoWithStorage[127.0.0.1:38596,DS-f0aaf84c-462e-43ff-b7de-a73925855773,DISK], DatanodeInfoWithStorage[127.0.0.1:45938,DS-fc1dc121-3d0b-4805-be99-0f0351df3a82,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-966640677-172.17.0.8-1598423692259:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41405,DS-d246ee6b-1506-4d36-88e3-10116aee737d,DISK], DatanodeInfoWithStorage[127.0.0.1:37806,DS-7413b84f-d6ed-4c5e-bdfd-355d260e288a,DISK], DatanodeInfoWithStorage[127.0.0.1:46755,DS-d720dd45-77a2-4f88-a9f6-6bd3ab8485a1,DISK], DatanodeInfoWithStorage[127.0.0.1:33836,DS-c49dd285-cc59-4d70-9071-658e4c5ccf21,DISK], DatanodeInfoWithStorage[127.0.0.1:46129,DS-9a90dce0-8912-479b-a42d-062cdbeb8da4,DISK], DatanodeInfoWithStorage[127.0.0.1:42235,DS-bcacd7fb-3cca-4e4a-ad6d-8f9013a549d8,DISK], DatanodeInfoWithStorage[127.0.0.1:38596,DS-f0aaf84c-462e-43ff-b7de-a73925855773,DISK], DatanodeInfoWithStorage[127.0.0.1:45938,DS-fc1dc121-3d0b-4805-be99-0f0351df3a82,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-452722749-172.17.0.8-1598423879615:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41647,DS-2505f479-8a7f-4c23-8158-22f591132b65,DISK], DatanodeInfoWithStorage[127.0.0.1:35056,DS-e1f10275-b7b7-43b8-8f6a-dc306a3bc0fb,DISK], DatanodeInfoWithStorage[127.0.0.1:36322,DS-99c63bb4-8055-4025-a36e-50594f20d8ed,DISK], DatanodeInfoWithStorage[127.0.0.1:43260,DS-7e23133c-cc83-47b7-b3fb-5504dfd69cb6,DISK], DatanodeInfoWithStorage[127.0.0.1:42687,DS-8e92c70b-09c0-4955-869b-30b021cf8565,DISK], DatanodeInfoWithStorage[127.0.0.1:41079,DS-e9c786fe-9c79-4228-983e-fa304192a703,DISK], DatanodeInfoWithStorage[127.0.0.1:45021,DS-023827c3-82ce-40e3-80f1-c4d5cfdae68a,DISK], DatanodeInfoWithStorage[127.0.0.1:39650,DS-5dbe6bac-b994-4a4c-927c-e90819c19e8c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-452722749-172.17.0.8-1598423879615:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41647,DS-2505f479-8a7f-4c23-8158-22f591132b65,DISK], DatanodeInfoWithStorage[127.0.0.1:35056,DS-e1f10275-b7b7-43b8-8f6a-dc306a3bc0fb,DISK], DatanodeInfoWithStorage[127.0.0.1:36322,DS-99c63bb4-8055-4025-a36e-50594f20d8ed,DISK], DatanodeInfoWithStorage[127.0.0.1:43260,DS-7e23133c-cc83-47b7-b3fb-5504dfd69cb6,DISK], DatanodeInfoWithStorage[127.0.0.1:42687,DS-8e92c70b-09c0-4955-869b-30b021cf8565,DISK], DatanodeInfoWithStorage[127.0.0.1:41079,DS-e9c786fe-9c79-4228-983e-fa304192a703,DISK], DatanodeInfoWithStorage[127.0.0.1:45021,DS-023827c3-82ce-40e3-80f1-c4d5cfdae68a,DISK], DatanodeInfoWithStorage[127.0.0.1:39650,DS-5dbe6bac-b994-4a4c-927c-e90819c19e8c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1211676444-172.17.0.8-1598424384157:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44552,DS-0f1f3b34-38d7-4ef4-ad1e-eac5d253ef96,DISK], DatanodeInfoWithStorage[127.0.0.1:40425,DS-0960e800-3ad4-461f-9907-4ce1e6904009,DISK], DatanodeInfoWithStorage[127.0.0.1:46881,DS-b50aca48-6cd6-429d-b8b4-c75883d90732,DISK], DatanodeInfoWithStorage[127.0.0.1:34784,DS-8cfdeefb-1900-45ad-bb10-81f05d00c115,DISK], DatanodeInfoWithStorage[127.0.0.1:35511,DS-7670b47e-7de7-4dfc-984e-c16052012d1b,DISK], DatanodeInfoWithStorage[127.0.0.1:41371,DS-ffd61d10-28bf-44ce-ad7b-d11987c9ada9,DISK], DatanodeInfoWithStorage[127.0.0.1:35060,DS-96efb839-c666-4c39-95e9-e72d5bf5e810,DISK], DatanodeInfoWithStorage[127.0.0.1:34140,DS-e3cb4f98-1600-4e0d-868a-bb3bbecd0518,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1211676444-172.17.0.8-1598424384157:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44552,DS-0f1f3b34-38d7-4ef4-ad1e-eac5d253ef96,DISK], DatanodeInfoWithStorage[127.0.0.1:40425,DS-0960e800-3ad4-461f-9907-4ce1e6904009,DISK], DatanodeInfoWithStorage[127.0.0.1:46881,DS-b50aca48-6cd6-429d-b8b4-c75883d90732,DISK], DatanodeInfoWithStorage[127.0.0.1:34784,DS-8cfdeefb-1900-45ad-bb10-81f05d00c115,DISK], DatanodeInfoWithStorage[127.0.0.1:35511,DS-7670b47e-7de7-4dfc-984e-c16052012d1b,DISK], DatanodeInfoWithStorage[127.0.0.1:41371,DS-ffd61d10-28bf-44ce-ad7b-d11987c9ada9,DISK], DatanodeInfoWithStorage[127.0.0.1:35060,DS-96efb839-c666-4c39-95e9-e72d5bf5e810,DISK], DatanodeInfoWithStorage[127.0.0.1:34140,DS-e3cb4f98-1600-4e0d-868a-bb3bbecd0518,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1651958420-172.17.0.8-1598424459557:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36077,DS-86cd3088-c9c3-41ac-97e1-167f259ed08c,DISK], DatanodeInfoWithStorage[127.0.0.1:34725,DS-46e3e910-d63c-4578-9d59-1fabe20cc558,DISK], DatanodeInfoWithStorage[127.0.0.1:33063,DS-ac42ad0f-85cd-4570-b314-140fd799ccff,DISK], DatanodeInfoWithStorage[127.0.0.1:41951,DS-cb59b96e-74ab-480c-8804-7527c7329ccd,DISK], DatanodeInfoWithStorage[127.0.0.1:41430,DS-a5dae897-a8fb-4ea2-8029-0a2b6a11f65a,DISK], DatanodeInfoWithStorage[127.0.0.1:44814,DS-8ac9cb8a-1419-487f-a9e3-3f9c302b61b4,DISK], DatanodeInfoWithStorage[127.0.0.1:45428,DS-16227464-c3c9-49a6-9b65-66624b4a3e67,DISK], DatanodeInfoWithStorage[127.0.0.1:46105,DS-c0daf331-b42b-446a-bd26-0902b8119d97,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1651958420-172.17.0.8-1598424459557:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36077,DS-86cd3088-c9c3-41ac-97e1-167f259ed08c,DISK], DatanodeInfoWithStorage[127.0.0.1:34725,DS-46e3e910-d63c-4578-9d59-1fabe20cc558,DISK], DatanodeInfoWithStorage[127.0.0.1:33063,DS-ac42ad0f-85cd-4570-b314-140fd799ccff,DISK], DatanodeInfoWithStorage[127.0.0.1:41951,DS-cb59b96e-74ab-480c-8804-7527c7329ccd,DISK], DatanodeInfoWithStorage[127.0.0.1:41430,DS-a5dae897-a8fb-4ea2-8029-0a2b6a11f65a,DISK], DatanodeInfoWithStorage[127.0.0.1:44814,DS-8ac9cb8a-1419-487f-a9e3-3f9c302b61b4,DISK], DatanodeInfoWithStorage[127.0.0.1:45428,DS-16227464-c3c9-49a6-9b65-66624b4a3e67,DISK], DatanodeInfoWithStorage[127.0.0.1:46105,DS-c0daf331-b42b-446a-bd26-0902b8119d97,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-109632923-172.17.0.8-1598424701988:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44445,DS-f62a7cbb-e4bc-4718-9ee6-6bbf8a4f2bc0,DISK], DatanodeInfoWithStorage[127.0.0.1:35608,DS-b5d4b6a2-02a5-4a7f-81f2-1c1e1c069853,DISK], DatanodeInfoWithStorage[127.0.0.1:39768,DS-cefbfc02-c319-4b42-8e89-31aaf6d86877,DISK], DatanodeInfoWithStorage[127.0.0.1:40083,DS-acf04a12-9aec-46da-97b8-8c62cc05edc7,DISK], DatanodeInfoWithStorage[127.0.0.1:36261,DS-e550344d-1088-489d-939b-e83ba6f465cf,DISK], DatanodeInfoWithStorage[127.0.0.1:41383,DS-691591dc-5ccb-4b5c-87d2-6ce0df71f8ad,DISK], DatanodeInfoWithStorage[127.0.0.1:43811,DS-cd871427-09cc-4eef-90ac-d0c2ae75e11b,DISK], DatanodeInfoWithStorage[127.0.0.1:33746,DS-c8902d96-4906-4e8f-bf6d-b18aa299d09f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-109632923-172.17.0.8-1598424701988:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44445,DS-f62a7cbb-e4bc-4718-9ee6-6bbf8a4f2bc0,DISK], DatanodeInfoWithStorage[127.0.0.1:35608,DS-b5d4b6a2-02a5-4a7f-81f2-1c1e1c069853,DISK], DatanodeInfoWithStorage[127.0.0.1:39768,DS-cefbfc02-c319-4b42-8e89-31aaf6d86877,DISK], DatanodeInfoWithStorage[127.0.0.1:40083,DS-acf04a12-9aec-46da-97b8-8c62cc05edc7,DISK], DatanodeInfoWithStorage[127.0.0.1:36261,DS-e550344d-1088-489d-939b-e83ba6f465cf,DISK], DatanodeInfoWithStorage[127.0.0.1:41383,DS-691591dc-5ccb-4b5c-87d2-6ce0df71f8ad,DISK], DatanodeInfoWithStorage[127.0.0.1:43811,DS-cd871427-09cc-4eef-90ac-d0c2ae75e11b,DISK], DatanodeInfoWithStorage[127.0.0.1:33746,DS-c8902d96-4906-4e8f-bf6d-b18aa299d09f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1183860213-172.17.0.8-1598424773180:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41512,DS-63d588b5-b61c-4321-9713-2ea923fd234e,DISK], DatanodeInfoWithStorage[127.0.0.1:40249,DS-14ae7826-6a26-4c6d-8605-cdaca715aca9,DISK], DatanodeInfoWithStorage[127.0.0.1:45677,DS-723ac0de-bae5-479e-a9d7-6728eeed2e70,DISK], DatanodeInfoWithStorage[127.0.0.1:33593,DS-49c41b6b-940a-4d18-9568-124538df2aa4,DISK], DatanodeInfoWithStorage[127.0.0.1:38732,DS-29287e0a-6fca-4cac-923d-1949d33bf692,DISK], DatanodeInfoWithStorage[127.0.0.1:33342,DS-b802acb8-8a94-4f83-86a9-56e3f0593f69,DISK], DatanodeInfoWithStorage[127.0.0.1:44390,DS-aaa1f103-f434-4969-b637-7d1cfcfba5bf,DISK], DatanodeInfoWithStorage[127.0.0.1:32821,DS-37b8bba9-69e7-46b7-a651-d486e7e6a3aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1183860213-172.17.0.8-1598424773180:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41512,DS-63d588b5-b61c-4321-9713-2ea923fd234e,DISK], DatanodeInfoWithStorage[127.0.0.1:40249,DS-14ae7826-6a26-4c6d-8605-cdaca715aca9,DISK], DatanodeInfoWithStorage[127.0.0.1:45677,DS-723ac0de-bae5-479e-a9d7-6728eeed2e70,DISK], DatanodeInfoWithStorage[127.0.0.1:33593,DS-49c41b6b-940a-4d18-9568-124538df2aa4,DISK], DatanodeInfoWithStorage[127.0.0.1:38732,DS-29287e0a-6fca-4cac-923d-1949d33bf692,DISK], DatanodeInfoWithStorage[127.0.0.1:33342,DS-b802acb8-8a94-4f83-86a9-56e3f0593f69,DISK], DatanodeInfoWithStorage[127.0.0.1:44390,DS-aaa1f103-f434-4969-b637-7d1cfcfba5bf,DISK], DatanodeInfoWithStorage[127.0.0.1:32821,DS-37b8bba9-69e7-46b7-a651-d486e7e6a3aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-836338127-172.17.0.8-1598425026844:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42168,DS-efdbf367-430e-4c4e-b030-68f0d75a6dd9,DISK], DatanodeInfoWithStorage[127.0.0.1:40190,DS-d0d65aea-4a24-4b3c-8c00-58eb38d82fe3,DISK], DatanodeInfoWithStorage[127.0.0.1:38198,DS-91226ebb-95ed-477b-94b0-8613e1a90ca0,DISK], DatanodeInfoWithStorage[127.0.0.1:38014,DS-8cc54942-7ca2-455d-a6a9-29d764e76fb9,DISK], DatanodeInfoWithStorage[127.0.0.1:40392,DS-a60d1e52-f11a-44b2-8b1e-2f34a4a544b0,DISK], DatanodeInfoWithStorage[127.0.0.1:45265,DS-00b14975-5bc8-4f25-a0ed-13ea7f5fcca7,DISK], DatanodeInfoWithStorage[127.0.0.1:44454,DS-64e9c72b-615e-4f0d-b367-d885d8e8e681,DISK], DatanodeInfoWithStorage[127.0.0.1:33904,DS-49cefce5-53c8-446a-96f2-a99b2ece9969,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-836338127-172.17.0.8-1598425026844:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42168,DS-efdbf367-430e-4c4e-b030-68f0d75a6dd9,DISK], DatanodeInfoWithStorage[127.0.0.1:40190,DS-d0d65aea-4a24-4b3c-8c00-58eb38d82fe3,DISK], DatanodeInfoWithStorage[127.0.0.1:38198,DS-91226ebb-95ed-477b-94b0-8613e1a90ca0,DISK], DatanodeInfoWithStorage[127.0.0.1:38014,DS-8cc54942-7ca2-455d-a6a9-29d764e76fb9,DISK], DatanodeInfoWithStorage[127.0.0.1:40392,DS-a60d1e52-f11a-44b2-8b1e-2f34a4a544b0,DISK], DatanodeInfoWithStorage[127.0.0.1:45265,DS-00b14975-5bc8-4f25-a0ed-13ea7f5fcca7,DISK], DatanodeInfoWithStorage[127.0.0.1:44454,DS-64e9c72b-615e-4f0d-b367-d885d8e8e681,DISK], DatanodeInfoWithStorage[127.0.0.1:33904,DS-49cefce5-53c8-446a-96f2-a99b2ece9969,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 16 out of 50
result: false positive !!!
Total execution time in seconds : 5212
