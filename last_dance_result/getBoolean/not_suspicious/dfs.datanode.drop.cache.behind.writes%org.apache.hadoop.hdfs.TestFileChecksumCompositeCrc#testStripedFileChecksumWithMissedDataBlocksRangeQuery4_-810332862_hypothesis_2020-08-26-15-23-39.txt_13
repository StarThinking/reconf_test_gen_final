reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-382797307-172.17.0.19-1598456334891:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36766,DS-317d069d-5268-405c-b87f-3dda7aff0d86,DISK], DatanodeInfoWithStorage[127.0.0.1:39761,DS-957f95cd-988d-4954-9712-57383b0e0316,DISK], DatanodeInfoWithStorage[127.0.0.1:33500,DS-8ec292d5-08a3-4d93-9633-b26e6866f8d5,DISK], DatanodeInfoWithStorage[127.0.0.1:34655,DS-933783fc-73a7-4b9f-8da7-c6b85b155b18,DISK], DatanodeInfoWithStorage[127.0.0.1:46443,DS-d83f3fa4-cafa-4123-820f-68f4196ca76a,DISK], DatanodeInfoWithStorage[127.0.0.1:44577,DS-562796ce-3fc0-46aa-9289-6529788095e6,DISK], DatanodeInfoWithStorage[127.0.0.1:40723,DS-2212873e-f8ae-41f0-b5da-c921bbfe0a6f,DISK], DatanodeInfoWithStorage[127.0.0.1:38390,DS-95eaef53-5962-42b5-83e9-d0ee7d941154,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-382797307-172.17.0.19-1598456334891:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36766,DS-317d069d-5268-405c-b87f-3dda7aff0d86,DISK], DatanodeInfoWithStorage[127.0.0.1:39761,DS-957f95cd-988d-4954-9712-57383b0e0316,DISK], DatanodeInfoWithStorage[127.0.0.1:33500,DS-8ec292d5-08a3-4d93-9633-b26e6866f8d5,DISK], DatanodeInfoWithStorage[127.0.0.1:34655,DS-933783fc-73a7-4b9f-8da7-c6b85b155b18,DISK], DatanodeInfoWithStorage[127.0.0.1:46443,DS-d83f3fa4-cafa-4123-820f-68f4196ca76a,DISK], DatanodeInfoWithStorage[127.0.0.1:44577,DS-562796ce-3fc0-46aa-9289-6529788095e6,DISK], DatanodeInfoWithStorage[127.0.0.1:40723,DS-2212873e-f8ae-41f0-b5da-c921bbfe0a6f,DISK], DatanodeInfoWithStorage[127.0.0.1:38390,DS-95eaef53-5962-42b5-83e9-d0ee7d941154,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-84054485-172.17.0.19-1598456469547:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39398,DS-b87ede1f-88ae-43db-8d1d-9670c9c23a2a,DISK], DatanodeInfoWithStorage[127.0.0.1:37460,DS-510ee4a5-363c-4182-864d-a66a516eb94a,DISK], DatanodeInfoWithStorage[127.0.0.1:44267,DS-e1caeff3-53d7-4977-905f-1adb3a658d6f,DISK], DatanodeInfoWithStorage[127.0.0.1:46833,DS-4c0b172f-dcc2-441a-89ac-6bec815ed562,DISK], DatanodeInfoWithStorage[127.0.0.1:44080,DS-e5a6a3c7-487a-4376-bec9-e098e43476ce,DISK], DatanodeInfoWithStorage[127.0.0.1:39941,DS-10b83c52-1917-43ac-beeb-e84cce832245,DISK], DatanodeInfoWithStorage[127.0.0.1:34700,DS-ca382e98-8e55-40a2-aa78-9a8408d1a2aa,DISK], DatanodeInfoWithStorage[127.0.0.1:43527,DS-eab7a4c8-54f7-48c9-aa1c-55fbb92f1904,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-84054485-172.17.0.19-1598456469547:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39398,DS-b87ede1f-88ae-43db-8d1d-9670c9c23a2a,DISK], DatanodeInfoWithStorage[127.0.0.1:37460,DS-510ee4a5-363c-4182-864d-a66a516eb94a,DISK], DatanodeInfoWithStorage[127.0.0.1:44267,DS-e1caeff3-53d7-4977-905f-1adb3a658d6f,DISK], DatanodeInfoWithStorage[127.0.0.1:46833,DS-4c0b172f-dcc2-441a-89ac-6bec815ed562,DISK], DatanodeInfoWithStorage[127.0.0.1:44080,DS-e5a6a3c7-487a-4376-bec9-e098e43476ce,DISK], DatanodeInfoWithStorage[127.0.0.1:39941,DS-10b83c52-1917-43ac-beeb-e84cce832245,DISK], DatanodeInfoWithStorage[127.0.0.1:34700,DS-ca382e98-8e55-40a2-aa78-9a8408d1a2aa,DISK], DatanodeInfoWithStorage[127.0.0.1:43527,DS-eab7a4c8-54f7-48c9-aa1c-55fbb92f1904,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-906764572-172.17.0.19-1598456504116:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44494,DS-384512b0-3394-479a-b466-be3c42d8bd12,DISK], DatanodeInfoWithStorage[127.0.0.1:33586,DS-24d789c3-948f-483f-85a6-8d470668340e,DISK], DatanodeInfoWithStorage[127.0.0.1:33765,DS-3a223e46-f44d-4543-9c19-ca09130d4b44,DISK], DatanodeInfoWithStorage[127.0.0.1:37170,DS-3c4a7504-1028-4e62-aa96-ac7e4e7f88c6,DISK], DatanodeInfoWithStorage[127.0.0.1:38837,DS-671e2791-a130-4ad6-9613-01451ff29baf,DISK], DatanodeInfoWithStorage[127.0.0.1:46327,DS-b1d947bc-3215-4e68-93ff-f9e46c3acbcc,DISK], DatanodeInfoWithStorage[127.0.0.1:37647,DS-33166a6b-6450-43e3-8c9d-c10e48d7814f,DISK], DatanodeInfoWithStorage[127.0.0.1:46583,DS-7a70b428-df46-4bbb-81f2-04a9c61cc7aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-906764572-172.17.0.19-1598456504116:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44494,DS-384512b0-3394-479a-b466-be3c42d8bd12,DISK], DatanodeInfoWithStorage[127.0.0.1:33586,DS-24d789c3-948f-483f-85a6-8d470668340e,DISK], DatanodeInfoWithStorage[127.0.0.1:33765,DS-3a223e46-f44d-4543-9c19-ca09130d4b44,DISK], DatanodeInfoWithStorage[127.0.0.1:37170,DS-3c4a7504-1028-4e62-aa96-ac7e4e7f88c6,DISK], DatanodeInfoWithStorage[127.0.0.1:38837,DS-671e2791-a130-4ad6-9613-01451ff29baf,DISK], DatanodeInfoWithStorage[127.0.0.1:46327,DS-b1d947bc-3215-4e68-93ff-f9e46c3acbcc,DISK], DatanodeInfoWithStorage[127.0.0.1:37647,DS-33166a6b-6450-43e3-8c9d-c10e48d7814f,DISK], DatanodeInfoWithStorage[127.0.0.1:46583,DS-7a70b428-df46-4bbb-81f2-04a9c61cc7aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-236115318-172.17.0.19-1598456951611:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45386,DS-d45c631d-5962-4a48-ab76-d235bce2501f,DISK], DatanodeInfoWithStorage[127.0.0.1:35618,DS-47c19848-ee02-4cbd-b663-9d4210c46984,DISK], DatanodeInfoWithStorage[127.0.0.1:45692,DS-6b8470d1-9779-45be-8e15-fb41436e877e,DISK], DatanodeInfoWithStorage[127.0.0.1:38896,DS-ac58e629-072e-4144-b473-9c2b018c4ce0,DISK], DatanodeInfoWithStorage[127.0.0.1:38320,DS-fea8075d-ce38-4b1b-bb8c-a55e3c14c016,DISK], DatanodeInfoWithStorage[127.0.0.1:33134,DS-cb862c80-c33c-4168-907e-59804026c716,DISK], DatanodeInfoWithStorage[127.0.0.1:34743,DS-7842e705-da70-419c-a6a7-e407dee1dcd8,DISK], DatanodeInfoWithStorage[127.0.0.1:37340,DS-fbb6cd2d-280e-4780-9eb8-d417a01fd970,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-236115318-172.17.0.19-1598456951611:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45386,DS-d45c631d-5962-4a48-ab76-d235bce2501f,DISK], DatanodeInfoWithStorage[127.0.0.1:35618,DS-47c19848-ee02-4cbd-b663-9d4210c46984,DISK], DatanodeInfoWithStorage[127.0.0.1:45692,DS-6b8470d1-9779-45be-8e15-fb41436e877e,DISK], DatanodeInfoWithStorage[127.0.0.1:38896,DS-ac58e629-072e-4144-b473-9c2b018c4ce0,DISK], DatanodeInfoWithStorage[127.0.0.1:38320,DS-fea8075d-ce38-4b1b-bb8c-a55e3c14c016,DISK], DatanodeInfoWithStorage[127.0.0.1:33134,DS-cb862c80-c33c-4168-907e-59804026c716,DISK], DatanodeInfoWithStorage[127.0.0.1:34743,DS-7842e705-da70-419c-a6a7-e407dee1dcd8,DISK], DatanodeInfoWithStorage[127.0.0.1:37340,DS-fbb6cd2d-280e-4780-9eb8-d417a01fd970,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-13550093-172.17.0.19-1598457066886:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42866,DS-e1152fea-fd7d-4ed0-a9a9-15312780daf7,DISK], DatanodeInfoWithStorage[127.0.0.1:46373,DS-82c4ac4a-78b9-4a1b-acbf-2606b79549ad,DISK], DatanodeInfoWithStorage[127.0.0.1:37986,DS-84b3214a-7087-4954-8029-8afaccbd7c5a,DISK], DatanodeInfoWithStorage[127.0.0.1:39954,DS-3b915f9f-426b-4c01-a696-dcc4f6cad0ab,DISK], DatanodeInfoWithStorage[127.0.0.1:34047,DS-4c5c857e-895c-464d-85cf-14eec0c8815b,DISK], DatanodeInfoWithStorage[127.0.0.1:36667,DS-d0026692-d72f-4664-b2d2-68b096841379,DISK], DatanodeInfoWithStorage[127.0.0.1:46253,DS-7b5b834a-6226-483a-b47c-4b43072b7eb7,DISK], DatanodeInfoWithStorage[127.0.0.1:39318,DS-3e833c8f-fef5-4c3f-89a7-82185fcd39fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-13550093-172.17.0.19-1598457066886:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42866,DS-e1152fea-fd7d-4ed0-a9a9-15312780daf7,DISK], DatanodeInfoWithStorage[127.0.0.1:46373,DS-82c4ac4a-78b9-4a1b-acbf-2606b79549ad,DISK], DatanodeInfoWithStorage[127.0.0.1:37986,DS-84b3214a-7087-4954-8029-8afaccbd7c5a,DISK], DatanodeInfoWithStorage[127.0.0.1:39954,DS-3b915f9f-426b-4c01-a696-dcc4f6cad0ab,DISK], DatanodeInfoWithStorage[127.0.0.1:34047,DS-4c5c857e-895c-464d-85cf-14eec0c8815b,DISK], DatanodeInfoWithStorage[127.0.0.1:36667,DS-d0026692-d72f-4664-b2d2-68b096841379,DISK], DatanodeInfoWithStorage[127.0.0.1:46253,DS-7b5b834a-6226-483a-b47c-4b43072b7eb7,DISK], DatanodeInfoWithStorage[127.0.0.1:39318,DS-3e833c8f-fef5-4c3f-89a7-82185fcd39fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1784279976-172.17.0.19-1598457108107:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33812,DS-a9b1edef-2ed7-411c-bcb9-51c21257c12f,DISK], DatanodeInfoWithStorage[127.0.0.1:34306,DS-0ecd0b0e-dfe3-46a0-91b9-38015d88966f,DISK], DatanodeInfoWithStorage[127.0.0.1:39891,DS-38f38eee-9f1b-46d4-97a4-5849fe79e840,DISK], DatanodeInfoWithStorage[127.0.0.1:35651,DS-2271728a-5991-4d3a-ae7e-57c4be4213b7,DISK], DatanodeInfoWithStorage[127.0.0.1:46713,DS-a63fd9c7-cbf0-4de7-94c3-221c3e13d6c1,DISK], DatanodeInfoWithStorage[127.0.0.1:40743,DS-0657b205-9d73-4153-a656-0cd5e728e12b,DISK], DatanodeInfoWithStorage[127.0.0.1:37715,DS-5085db9b-1172-48fb-b9ef-c2567bb84ce3,DISK], DatanodeInfoWithStorage[127.0.0.1:40103,DS-87e530b9-49fa-4d42-aa46-9178377f8a60,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1784279976-172.17.0.19-1598457108107:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33812,DS-a9b1edef-2ed7-411c-bcb9-51c21257c12f,DISK], DatanodeInfoWithStorage[127.0.0.1:34306,DS-0ecd0b0e-dfe3-46a0-91b9-38015d88966f,DISK], DatanodeInfoWithStorage[127.0.0.1:39891,DS-38f38eee-9f1b-46d4-97a4-5849fe79e840,DISK], DatanodeInfoWithStorage[127.0.0.1:35651,DS-2271728a-5991-4d3a-ae7e-57c4be4213b7,DISK], DatanodeInfoWithStorage[127.0.0.1:46713,DS-a63fd9c7-cbf0-4de7-94c3-221c3e13d6c1,DISK], DatanodeInfoWithStorage[127.0.0.1:40743,DS-0657b205-9d73-4153-a656-0cd5e728e12b,DISK], DatanodeInfoWithStorage[127.0.0.1:37715,DS-5085db9b-1172-48fb-b9ef-c2567bb84ce3,DISK], DatanodeInfoWithStorage[127.0.0.1:40103,DS-87e530b9-49fa-4d42-aa46-9178377f8a60,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-366147000-172.17.0.19-1598457228068:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36814,DS-af9cbe5e-682b-42a2-b9ea-9e62573b8e1d,DISK], DatanodeInfoWithStorage[127.0.0.1:38543,DS-3e5943c1-43a4-4e85-bc2e-4a8454362464,DISK], DatanodeInfoWithStorage[127.0.0.1:32986,DS-c0082d4e-af58-40de-a0be-80828f08aece,DISK], DatanodeInfoWithStorage[127.0.0.1:42664,DS-8bde9fd4-19a8-4581-931d-dc6a1cae5510,DISK], DatanodeInfoWithStorage[127.0.0.1:36277,DS-385f29b4-d35f-4bd5-8ec2-1990fe92eea2,DISK], DatanodeInfoWithStorage[127.0.0.1:42811,DS-3d6d5559-b8f8-46ad-8436-539c268bdbdf,DISK], DatanodeInfoWithStorage[127.0.0.1:35100,DS-26f0fd46-2d84-4f94-af59-18c215983243,DISK], DatanodeInfoWithStorage[127.0.0.1:37747,DS-d1a9e8a7-84ee-4a96-9515-8df4e6247db2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-366147000-172.17.0.19-1598457228068:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36814,DS-af9cbe5e-682b-42a2-b9ea-9e62573b8e1d,DISK], DatanodeInfoWithStorage[127.0.0.1:38543,DS-3e5943c1-43a4-4e85-bc2e-4a8454362464,DISK], DatanodeInfoWithStorage[127.0.0.1:32986,DS-c0082d4e-af58-40de-a0be-80828f08aece,DISK], DatanodeInfoWithStorage[127.0.0.1:42664,DS-8bde9fd4-19a8-4581-931d-dc6a1cae5510,DISK], DatanodeInfoWithStorage[127.0.0.1:36277,DS-385f29b4-d35f-4bd5-8ec2-1990fe92eea2,DISK], DatanodeInfoWithStorage[127.0.0.1:42811,DS-3d6d5559-b8f8-46ad-8436-539c268bdbdf,DISK], DatanodeInfoWithStorage[127.0.0.1:35100,DS-26f0fd46-2d84-4f94-af59-18c215983243,DISK], DatanodeInfoWithStorage[127.0.0.1:37747,DS-d1a9e8a7-84ee-4a96-9515-8df4e6247db2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-684625258-172.17.0.19-1598457711449:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46154,DS-c98770f2-00a5-44da-9ca1-3ed39d64e504,DISK], DatanodeInfoWithStorage[127.0.0.1:42957,DS-875bc46b-f4f8-4151-a6b3-b5c1149edbc0,DISK], DatanodeInfoWithStorage[127.0.0.1:39679,DS-b5b39814-3a88-4fc3-9993-aed438944a3a,DISK], DatanodeInfoWithStorage[127.0.0.1:36349,DS-c7867a02-a4b2-46ce-937e-a32728726ddc,DISK], DatanodeInfoWithStorage[127.0.0.1:33766,DS-be5ba608-e9a4-45fa-9a1b-a091326a0480,DISK], DatanodeInfoWithStorage[127.0.0.1:36701,DS-83c70ec8-b9a1-40e8-8e81-0c734a0bba8f,DISK], DatanodeInfoWithStorage[127.0.0.1:44456,DS-22e23aaa-fc0c-4f55-9577-d52ef1eed881,DISK], DatanodeInfoWithStorage[127.0.0.1:44236,DS-1a9ab787-2026-49f3-b7dc-5fcf44a20fb7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-684625258-172.17.0.19-1598457711449:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46154,DS-c98770f2-00a5-44da-9ca1-3ed39d64e504,DISK], DatanodeInfoWithStorage[127.0.0.1:42957,DS-875bc46b-f4f8-4151-a6b3-b5c1149edbc0,DISK], DatanodeInfoWithStorage[127.0.0.1:39679,DS-b5b39814-3a88-4fc3-9993-aed438944a3a,DISK], DatanodeInfoWithStorage[127.0.0.1:36349,DS-c7867a02-a4b2-46ce-937e-a32728726ddc,DISK], DatanodeInfoWithStorage[127.0.0.1:33766,DS-be5ba608-e9a4-45fa-9a1b-a091326a0480,DISK], DatanodeInfoWithStorage[127.0.0.1:36701,DS-83c70ec8-b9a1-40e8-8e81-0c734a0bba8f,DISK], DatanodeInfoWithStorage[127.0.0.1:44456,DS-22e23aaa-fc0c-4f55-9577-d52ef1eed881,DISK], DatanodeInfoWithStorage[127.0.0.1:44236,DS-1a9ab787-2026-49f3-b7dc-5fcf44a20fb7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-251034821-172.17.0.19-1598457794611:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39816,DS-f897e27a-df44-49c6-85f7-7276a168127f,DISK], DatanodeInfoWithStorage[127.0.0.1:38029,DS-f1acaef7-4641-4af7-8386-99512b413cd2,DISK], DatanodeInfoWithStorage[127.0.0.1:34876,DS-1da67cbd-2fc4-44ca-bddc-811856a170f3,DISK], DatanodeInfoWithStorage[127.0.0.1:46142,DS-2af966b3-cee7-46a9-88f2-2eb71c1fa2fc,DISK], DatanodeInfoWithStorage[127.0.0.1:40695,DS-afc65f95-ba7e-48b2-a8e6-5226cecc6e75,DISK], DatanodeInfoWithStorage[127.0.0.1:39102,DS-46b977e6-5ed2-46a4-9d1f-5ab3be068bb2,DISK], DatanodeInfoWithStorage[127.0.0.1:38256,DS-49864c10-93df-46cc-bd59-cd68137f2756,DISK], DatanodeInfoWithStorage[127.0.0.1:39740,DS-e93f0bec-81ea-4ab5-baa2-2a19c626b4e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-251034821-172.17.0.19-1598457794611:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39816,DS-f897e27a-df44-49c6-85f7-7276a168127f,DISK], DatanodeInfoWithStorage[127.0.0.1:38029,DS-f1acaef7-4641-4af7-8386-99512b413cd2,DISK], DatanodeInfoWithStorage[127.0.0.1:34876,DS-1da67cbd-2fc4-44ca-bddc-811856a170f3,DISK], DatanodeInfoWithStorage[127.0.0.1:46142,DS-2af966b3-cee7-46a9-88f2-2eb71c1fa2fc,DISK], DatanodeInfoWithStorage[127.0.0.1:40695,DS-afc65f95-ba7e-48b2-a8e6-5226cecc6e75,DISK], DatanodeInfoWithStorage[127.0.0.1:39102,DS-46b977e6-5ed2-46a4-9d1f-5ab3be068bb2,DISK], DatanodeInfoWithStorage[127.0.0.1:38256,DS-49864c10-93df-46cc-bd59-cd68137f2756,DISK], DatanodeInfoWithStorage[127.0.0.1:39740,DS-e93f0bec-81ea-4ab5-baa2-2a19c626b4e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1178036341-172.17.0.19-1598458006377:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45606,DS-c3cdfe67-1cf1-4ce0-a318-c83c716a8182,DISK], DatanodeInfoWithStorage[127.0.0.1:41714,DS-db0854db-73f8-4a9d-ae95-c71384315789,DISK], DatanodeInfoWithStorage[127.0.0.1:34937,DS-872670fa-b060-4db5-aa8f-1a5dff32ecfc,DISK], DatanodeInfoWithStorage[127.0.0.1:44340,DS-4d4d9dcc-c69f-4d0c-894d-fe1973d31c64,DISK], DatanodeInfoWithStorage[127.0.0.1:46543,DS-49206f12-2837-4ea7-b329-5c7b118bf032,DISK], DatanodeInfoWithStorage[127.0.0.1:43071,DS-aec16693-f876-43f5-a104-508370ef40df,DISK], DatanodeInfoWithStorage[127.0.0.1:39718,DS-808d69d9-ba99-4ee2-b30f-4a8b2857da08,DISK], DatanodeInfoWithStorage[127.0.0.1:33128,DS-bfe19340-cbc0-40d5-8d82-ee9d6278630d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1178036341-172.17.0.19-1598458006377:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45606,DS-c3cdfe67-1cf1-4ce0-a318-c83c716a8182,DISK], DatanodeInfoWithStorage[127.0.0.1:41714,DS-db0854db-73f8-4a9d-ae95-c71384315789,DISK], DatanodeInfoWithStorage[127.0.0.1:34937,DS-872670fa-b060-4db5-aa8f-1a5dff32ecfc,DISK], DatanodeInfoWithStorage[127.0.0.1:44340,DS-4d4d9dcc-c69f-4d0c-894d-fe1973d31c64,DISK], DatanodeInfoWithStorage[127.0.0.1:46543,DS-49206f12-2837-4ea7-b329-5c7b118bf032,DISK], DatanodeInfoWithStorage[127.0.0.1:43071,DS-aec16693-f876-43f5-a104-508370ef40df,DISK], DatanodeInfoWithStorage[127.0.0.1:39718,DS-808d69d9-ba99-4ee2-b30f-4a8b2857da08,DISK], DatanodeInfoWithStorage[127.0.0.1:33128,DS-bfe19340-cbc0-40d5-8d82-ee9d6278630d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1753804979-172.17.0.19-1598458045769:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40927,DS-c7f39cd4-a540-4a8a-a94e-a25fda279112,DISK], DatanodeInfoWithStorage[127.0.0.1:43900,DS-b5b6fe77-a018-46c9-ac70-9d711b8ddcfd,DISK], DatanodeInfoWithStorage[127.0.0.1:39124,DS-afa1dd0f-9deb-42db-b14d-b5290f808843,DISK], DatanodeInfoWithStorage[127.0.0.1:44912,DS-3a5999e4-7702-4c00-9992-b51342ba28da,DISK], DatanodeInfoWithStorage[127.0.0.1:40096,DS-e716cd82-0a6a-4e58-906d-3615e2d78ff4,DISK], DatanodeInfoWithStorage[127.0.0.1:43679,DS-1c4057d1-a308-4124-95d4-1fff7de235b0,DISK], DatanodeInfoWithStorage[127.0.0.1:43048,DS-13da85fc-0e3b-45c7-8635-038ecb885dd8,DISK], DatanodeInfoWithStorage[127.0.0.1:43450,DS-f3110ba5-c748-465d-bb7e-547dad67dea2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1753804979-172.17.0.19-1598458045769:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40927,DS-c7f39cd4-a540-4a8a-a94e-a25fda279112,DISK], DatanodeInfoWithStorage[127.0.0.1:43900,DS-b5b6fe77-a018-46c9-ac70-9d711b8ddcfd,DISK], DatanodeInfoWithStorage[127.0.0.1:39124,DS-afa1dd0f-9deb-42db-b14d-b5290f808843,DISK], DatanodeInfoWithStorage[127.0.0.1:44912,DS-3a5999e4-7702-4c00-9992-b51342ba28da,DISK], DatanodeInfoWithStorage[127.0.0.1:40096,DS-e716cd82-0a6a-4e58-906d-3615e2d78ff4,DISK], DatanodeInfoWithStorage[127.0.0.1:43679,DS-1c4057d1-a308-4124-95d4-1fff7de235b0,DISK], DatanodeInfoWithStorage[127.0.0.1:43048,DS-13da85fc-0e3b-45c7-8635-038ecb885dd8,DISK], DatanodeInfoWithStorage[127.0.0.1:43450,DS-f3110ba5-c748-465d-bb7e-547dad67dea2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1710290041-172.17.0.19-1598458634097:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36756,DS-5bffa11f-4bce-47b7-ab79-1b296a5811c4,DISK], DatanodeInfoWithStorage[127.0.0.1:42501,DS-14b80e3b-e166-4923-ad90-6642c415b641,DISK], DatanodeInfoWithStorage[127.0.0.1:42882,DS-595642e5-abed-4a5b-8674-8316ceb794fd,DISK], DatanodeInfoWithStorage[127.0.0.1:44521,DS-066bb3c6-9480-410f-b2a9-490ffbfba456,DISK], DatanodeInfoWithStorage[127.0.0.1:45284,DS-9442568f-2723-410c-b44c-e80069789f73,DISK], DatanodeInfoWithStorage[127.0.0.1:43939,DS-79723c36-24a7-4916-af96-013394f87d2f,DISK], DatanodeInfoWithStorage[127.0.0.1:43428,DS-9a5461ea-5695-41f4-a472-cba79be28fb6,DISK], DatanodeInfoWithStorage[127.0.0.1:36283,DS-a51370a4-4274-4374-ab12-97f2237cb069,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1710290041-172.17.0.19-1598458634097:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36756,DS-5bffa11f-4bce-47b7-ab79-1b296a5811c4,DISK], DatanodeInfoWithStorage[127.0.0.1:42501,DS-14b80e3b-e166-4923-ad90-6642c415b641,DISK], DatanodeInfoWithStorage[127.0.0.1:42882,DS-595642e5-abed-4a5b-8674-8316ceb794fd,DISK], DatanodeInfoWithStorage[127.0.0.1:44521,DS-066bb3c6-9480-410f-b2a9-490ffbfba456,DISK], DatanodeInfoWithStorage[127.0.0.1:45284,DS-9442568f-2723-410c-b44c-e80069789f73,DISK], DatanodeInfoWithStorage[127.0.0.1:43939,DS-79723c36-24a7-4916-af96-013394f87d2f,DISK], DatanodeInfoWithStorage[127.0.0.1:43428,DS-9a5461ea-5695-41f4-a472-cba79be28fb6,DISK], DatanodeInfoWithStorage[127.0.0.1:36283,DS-a51370a4-4274-4374-ab12-97f2237cb069,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-623131349-172.17.0.19-1598458671303:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45114,DS-819a0b57-59c1-4853-bbec-888a069f54ca,DISK], DatanodeInfoWithStorage[127.0.0.1:34019,DS-f2dc0593-1d23-4adf-8c66-e006a6b34ffc,DISK], DatanodeInfoWithStorage[127.0.0.1:35329,DS-cc74eda7-8ec3-4b38-9df5-d22b10e50d7a,DISK], DatanodeInfoWithStorage[127.0.0.1:43705,DS-eb0fe007-73b0-4dd2-8cf1-d48f68fdbe24,DISK], DatanodeInfoWithStorage[127.0.0.1:40462,DS-e330f02c-62b3-4262-a37f-4c5170015d3c,DISK], DatanodeInfoWithStorage[127.0.0.1:43696,DS-037977aa-383e-4db6-87ea-c33e9ec16ed7,DISK], DatanodeInfoWithStorage[127.0.0.1:34110,DS-569640b0-43e4-4683-9609-408c6c026f2a,DISK], DatanodeInfoWithStorage[127.0.0.1:43717,DS-9bcebed5-a220-4921-b4bd-77ab01da8f1c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-623131349-172.17.0.19-1598458671303:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45114,DS-819a0b57-59c1-4853-bbec-888a069f54ca,DISK], DatanodeInfoWithStorage[127.0.0.1:34019,DS-f2dc0593-1d23-4adf-8c66-e006a6b34ffc,DISK], DatanodeInfoWithStorage[127.0.0.1:35329,DS-cc74eda7-8ec3-4b38-9df5-d22b10e50d7a,DISK], DatanodeInfoWithStorage[127.0.0.1:43705,DS-eb0fe007-73b0-4dd2-8cf1-d48f68fdbe24,DISK], DatanodeInfoWithStorage[127.0.0.1:40462,DS-e330f02c-62b3-4262-a37f-4c5170015d3c,DISK], DatanodeInfoWithStorage[127.0.0.1:43696,DS-037977aa-383e-4db6-87ea-c33e9ec16ed7,DISK], DatanodeInfoWithStorage[127.0.0.1:34110,DS-569640b0-43e4-4683-9609-408c6c026f2a,DISK], DatanodeInfoWithStorage[127.0.0.1:43717,DS-9bcebed5-a220-4921-b4bd-77ab01da8f1c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-486657968-172.17.0.19-1598458743516:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38366,DS-ffffe5b7-0c58-419e-8d69-38cd84eb6a45,DISK], DatanodeInfoWithStorage[127.0.0.1:38876,DS-652217db-c1ab-4909-8af8-5a1348c61a58,DISK], DatanodeInfoWithStorage[127.0.0.1:36977,DS-b2b14cb7-2e1e-4032-ad3a-dd223b27d5c6,DISK], DatanodeInfoWithStorage[127.0.0.1:41430,DS-21836fc6-d00f-4a60-b9e4-667de650288b,DISK], DatanodeInfoWithStorage[127.0.0.1:34585,DS-efd3e192-a38c-4f25-8b97-4a405ef2d67e,DISK], DatanodeInfoWithStorage[127.0.0.1:46384,DS-8862b9f6-71f6-46aa-b9b4-30d62dbeac24,DISK], DatanodeInfoWithStorage[127.0.0.1:43892,DS-c8dd1332-15a6-4315-9b1d-9c4708856027,DISK], DatanodeInfoWithStorage[127.0.0.1:37142,DS-e06b6d8c-b214-4a2d-8c60-8214a9e7ee49,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-486657968-172.17.0.19-1598458743516:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38366,DS-ffffe5b7-0c58-419e-8d69-38cd84eb6a45,DISK], DatanodeInfoWithStorage[127.0.0.1:38876,DS-652217db-c1ab-4909-8af8-5a1348c61a58,DISK], DatanodeInfoWithStorage[127.0.0.1:36977,DS-b2b14cb7-2e1e-4032-ad3a-dd223b27d5c6,DISK], DatanodeInfoWithStorage[127.0.0.1:41430,DS-21836fc6-d00f-4a60-b9e4-667de650288b,DISK], DatanodeInfoWithStorage[127.0.0.1:34585,DS-efd3e192-a38c-4f25-8b97-4a405ef2d67e,DISK], DatanodeInfoWithStorage[127.0.0.1:46384,DS-8862b9f6-71f6-46aa-b9b4-30d62dbeac24,DISK], DatanodeInfoWithStorage[127.0.0.1:43892,DS-c8dd1332-15a6-4315-9b1d-9c4708856027,DISK], DatanodeInfoWithStorage[127.0.0.1:37142,DS-e06b6d8c-b214-4a2d-8c60-8214a9e7ee49,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-377488158-172.17.0.19-1598458887159:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35807,DS-6bc9cde2-9d7e-4e03-95f0-91155cba130e,DISK], DatanodeInfoWithStorage[127.0.0.1:41164,DS-8496465c-83d8-4bbb-baa8-a993a53d888a,DISK], DatanodeInfoWithStorage[127.0.0.1:38158,DS-8546a052-1d1d-407a-b3d1-c7b27fc9d812,DISK], DatanodeInfoWithStorage[127.0.0.1:38363,DS-f64245d9-0403-404c-9428-f54f8b031c6f,DISK], DatanodeInfoWithStorage[127.0.0.1:41722,DS-6a9c16e1-4b2c-405f-ae08-f3b1b5d3c740,DISK], DatanodeInfoWithStorage[127.0.0.1:33236,DS-a3545f82-0813-4743-b1d4-5502627eea4b,DISK], DatanodeInfoWithStorage[127.0.0.1:36043,DS-1d72257e-f686-48a6-9627-18dcc51dbb70,DISK], DatanodeInfoWithStorage[127.0.0.1:41483,DS-1d774e59-f200-42fa-83d0-d563d6d9adfb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-377488158-172.17.0.19-1598458887159:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35807,DS-6bc9cde2-9d7e-4e03-95f0-91155cba130e,DISK], DatanodeInfoWithStorage[127.0.0.1:41164,DS-8496465c-83d8-4bbb-baa8-a993a53d888a,DISK], DatanodeInfoWithStorage[127.0.0.1:38158,DS-8546a052-1d1d-407a-b3d1-c7b27fc9d812,DISK], DatanodeInfoWithStorage[127.0.0.1:38363,DS-f64245d9-0403-404c-9428-f54f8b031c6f,DISK], DatanodeInfoWithStorage[127.0.0.1:41722,DS-6a9c16e1-4b2c-405f-ae08-f3b1b5d3c740,DISK], DatanodeInfoWithStorage[127.0.0.1:33236,DS-a3545f82-0813-4743-b1d4-5502627eea4b,DISK], DatanodeInfoWithStorage[127.0.0.1:36043,DS-1d72257e-f686-48a6-9627-18dcc51dbb70,DISK], DatanodeInfoWithStorage[127.0.0.1:41483,DS-1d774e59-f200-42fa-83d0-d563d6d9adfb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-265382589-172.17.0.19-1598459693708:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38700,DS-1efd0d7d-05cc-456c-81fc-e8e4e4bf402b,DISK], DatanodeInfoWithStorage[127.0.0.1:34410,DS-c3babe50-90ee-4f84-92f6-26ab7ade1dae,DISK], DatanodeInfoWithStorage[127.0.0.1:46166,DS-fbcb514d-41d0-4ca2-bda7-c08c68d8e876,DISK], DatanodeInfoWithStorage[127.0.0.1:42641,DS-f38489e3-f830-481c-9d61-2c9805888a24,DISK], DatanodeInfoWithStorage[127.0.0.1:42749,DS-504eb279-c06c-4c1f-9e1b-2847d6fa7292,DISK], DatanodeInfoWithStorage[127.0.0.1:46549,DS-d91ec21e-8233-44fc-8aee-eec1996f3b87,DISK], DatanodeInfoWithStorage[127.0.0.1:35187,DS-ab3d96fb-1290-479a-bd5a-50e34adb8b9d,DISK], DatanodeInfoWithStorage[127.0.0.1:35217,DS-41a911d8-1fe7-43a3-80ce-d9b6906e84ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-265382589-172.17.0.19-1598459693708:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38700,DS-1efd0d7d-05cc-456c-81fc-e8e4e4bf402b,DISK], DatanodeInfoWithStorage[127.0.0.1:34410,DS-c3babe50-90ee-4f84-92f6-26ab7ade1dae,DISK], DatanodeInfoWithStorage[127.0.0.1:46166,DS-fbcb514d-41d0-4ca2-bda7-c08c68d8e876,DISK], DatanodeInfoWithStorage[127.0.0.1:42641,DS-f38489e3-f830-481c-9d61-2c9805888a24,DISK], DatanodeInfoWithStorage[127.0.0.1:42749,DS-504eb279-c06c-4c1f-9e1b-2847d6fa7292,DISK], DatanodeInfoWithStorage[127.0.0.1:46549,DS-d91ec21e-8233-44fc-8aee-eec1996f3b87,DISK], DatanodeInfoWithStorage[127.0.0.1:35187,DS-ab3d96fb-1290-479a-bd5a-50e34adb8b9d,DISK], DatanodeInfoWithStorage[127.0.0.1:35217,DS-41a911d8-1fe7-43a3-80ce-d9b6906e84ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-25840559-172.17.0.19-1598459901062:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34845,DS-a40346f9-1327-46ea-8461-c59d2dd28e8a,DISK], DatanodeInfoWithStorage[127.0.0.1:41724,DS-22074288-8b1a-484e-84c1-0b36f4068eae,DISK], DatanodeInfoWithStorage[127.0.0.1:45909,DS-2855e5aa-c7b4-4200-9c31-632a028d3421,DISK], DatanodeInfoWithStorage[127.0.0.1:36053,DS-d79ba67f-bef2-4c2e-ba12-72db0abc5a06,DISK], DatanodeInfoWithStorage[127.0.0.1:39297,DS-2c047a7a-961d-42e8-bf56-da2032f78da5,DISK], DatanodeInfoWithStorage[127.0.0.1:39967,DS-ebb765a9-e0c5-42fe-899d-211894257f23,DISK], DatanodeInfoWithStorage[127.0.0.1:43152,DS-5dca2369-4d58-4657-9769-0ffc0f45bf7c,DISK], DatanodeInfoWithStorage[127.0.0.1:33602,DS-d495f0b3-0327-4120-a524-195a87e6b829,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-25840559-172.17.0.19-1598459901062:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34845,DS-a40346f9-1327-46ea-8461-c59d2dd28e8a,DISK], DatanodeInfoWithStorage[127.0.0.1:41724,DS-22074288-8b1a-484e-84c1-0b36f4068eae,DISK], DatanodeInfoWithStorage[127.0.0.1:45909,DS-2855e5aa-c7b4-4200-9c31-632a028d3421,DISK], DatanodeInfoWithStorage[127.0.0.1:36053,DS-d79ba67f-bef2-4c2e-ba12-72db0abc5a06,DISK], DatanodeInfoWithStorage[127.0.0.1:39297,DS-2c047a7a-961d-42e8-bf56-da2032f78da5,DISK], DatanodeInfoWithStorage[127.0.0.1:39967,DS-ebb765a9-e0c5-42fe-899d-211894257f23,DISK], DatanodeInfoWithStorage[127.0.0.1:43152,DS-5dca2369-4d58-4657-9769-0ffc0f45bf7c,DISK], DatanodeInfoWithStorage[127.0.0.1:33602,DS-d495f0b3-0327-4120-a524-195a87e6b829,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-130951844-172.17.0.19-1598460617237:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38693,DS-30c6f744-eeec-4e58-917c-a60c154aec10,DISK], DatanodeInfoWithStorage[127.0.0.1:44613,DS-ed10cd51-1955-410b-8011-8e5f4803a619,DISK], DatanodeInfoWithStorage[127.0.0.1:41375,DS-cf377851-3093-46ed-a247-825fbe8b08a7,DISK], DatanodeInfoWithStorage[127.0.0.1:33507,DS-9d0de0a8-a44a-4fc4-ba21-4e8113469880,DISK], DatanodeInfoWithStorage[127.0.0.1:42554,DS-9c2475fd-70e3-4f80-a24d-8c0c9ba39347,DISK], DatanodeInfoWithStorage[127.0.0.1:36642,DS-30e23ed0-a9e6-4c1c-b262-18c632ec3dd9,DISK], DatanodeInfoWithStorage[127.0.0.1:42333,DS-4cc26d11-f594-4eaf-ae16-e36d8f8c8d34,DISK], DatanodeInfoWithStorage[127.0.0.1:45612,DS-82220878-9657-4cdc-830e-fbf3755527b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-130951844-172.17.0.19-1598460617237:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38693,DS-30c6f744-eeec-4e58-917c-a60c154aec10,DISK], DatanodeInfoWithStorage[127.0.0.1:44613,DS-ed10cd51-1955-410b-8011-8e5f4803a619,DISK], DatanodeInfoWithStorage[127.0.0.1:41375,DS-cf377851-3093-46ed-a247-825fbe8b08a7,DISK], DatanodeInfoWithStorage[127.0.0.1:33507,DS-9d0de0a8-a44a-4fc4-ba21-4e8113469880,DISK], DatanodeInfoWithStorage[127.0.0.1:42554,DS-9c2475fd-70e3-4f80-a24d-8c0c9ba39347,DISK], DatanodeInfoWithStorage[127.0.0.1:36642,DS-30e23ed0-a9e6-4c1c-b262-18c632ec3dd9,DISK], DatanodeInfoWithStorage[127.0.0.1:42333,DS-4cc26d11-f594-4eaf-ae16-e36d8f8c8d34,DISK], DatanodeInfoWithStorage[127.0.0.1:45612,DS-82220878-9657-4cdc-830e-fbf3755527b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5515
