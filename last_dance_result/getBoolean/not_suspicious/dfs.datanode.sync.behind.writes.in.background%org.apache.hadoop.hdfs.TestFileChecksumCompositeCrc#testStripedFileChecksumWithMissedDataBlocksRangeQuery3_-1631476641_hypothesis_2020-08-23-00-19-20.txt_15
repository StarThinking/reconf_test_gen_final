reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1387129095-172.17.0.16-1598141974805:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41060,DS-3aaea931-e9e2-4b28-a3c1-005019e8d993,DISK], DatanodeInfoWithStorage[127.0.0.1:37877,DS-d65aacb9-3037-41d6-927d-3d529b36c4f4,DISK], DatanodeInfoWithStorage[127.0.0.1:38331,DS-381ab875-11b1-4645-a9de-447512760413,DISK], DatanodeInfoWithStorage[127.0.0.1:37626,DS-61a38ddf-5d07-4376-9357-83a525309a40,DISK], DatanodeInfoWithStorage[127.0.0.1:39524,DS-ac5f9fb1-9592-4d82-9ebc-0fb738320922,DISK], DatanodeInfoWithStorage[127.0.0.1:38889,DS-ca9eaf41-2761-466b-b5a0-b3b34dd1b052,DISK], DatanodeInfoWithStorage[127.0.0.1:36028,DS-38e93470-93e4-4738-a5c3-025e8d380156,DISK], DatanodeInfoWithStorage[127.0.0.1:35428,DS-2d84e87b-7549-42fe-a0f9-cc136224df3c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1387129095-172.17.0.16-1598141974805:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41060,DS-3aaea931-e9e2-4b28-a3c1-005019e8d993,DISK], DatanodeInfoWithStorage[127.0.0.1:37877,DS-d65aacb9-3037-41d6-927d-3d529b36c4f4,DISK], DatanodeInfoWithStorage[127.0.0.1:38331,DS-381ab875-11b1-4645-a9de-447512760413,DISK], DatanodeInfoWithStorage[127.0.0.1:37626,DS-61a38ddf-5d07-4376-9357-83a525309a40,DISK], DatanodeInfoWithStorage[127.0.0.1:39524,DS-ac5f9fb1-9592-4d82-9ebc-0fb738320922,DISK], DatanodeInfoWithStorage[127.0.0.1:38889,DS-ca9eaf41-2761-466b-b5a0-b3b34dd1b052,DISK], DatanodeInfoWithStorage[127.0.0.1:36028,DS-38e93470-93e4-4738-a5c3-025e8d380156,DISK], DatanodeInfoWithStorage[127.0.0.1:35428,DS-2d84e87b-7549-42fe-a0f9-cc136224df3c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-518626584-172.17.0.16-1598142336653:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36818,DS-a29837d6-9423-41f1-89f9-d6c03b3bb3fe,DISK], DatanodeInfoWithStorage[127.0.0.1:43841,DS-5f266849-4907-40d5-8476-a7befbe1770a,DISK], DatanodeInfoWithStorage[127.0.0.1:42942,DS-f8963c0f-ce1e-472e-860b-c02edcb38172,DISK], DatanodeInfoWithStorage[127.0.0.1:33858,DS-8b5fb535-de12-419d-9514-cc9b28702cb3,DISK], DatanodeInfoWithStorage[127.0.0.1:33407,DS-aabd1a45-7627-4917-97b0-ae7180915240,DISK], DatanodeInfoWithStorage[127.0.0.1:37389,DS-60e6a1fa-8f39-4da3-98bc-ff9ac9bb5667,DISK], DatanodeInfoWithStorage[127.0.0.1:44388,DS-a27266b1-805b-4604-a0f1-87efc96dfbf0,DISK], DatanodeInfoWithStorage[127.0.0.1:34963,DS-6db8a1e2-0593-42fc-b65d-edf36d3d9185,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-518626584-172.17.0.16-1598142336653:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36818,DS-a29837d6-9423-41f1-89f9-d6c03b3bb3fe,DISK], DatanodeInfoWithStorage[127.0.0.1:43841,DS-5f266849-4907-40d5-8476-a7befbe1770a,DISK], DatanodeInfoWithStorage[127.0.0.1:42942,DS-f8963c0f-ce1e-472e-860b-c02edcb38172,DISK], DatanodeInfoWithStorage[127.0.0.1:33858,DS-8b5fb535-de12-419d-9514-cc9b28702cb3,DISK], DatanodeInfoWithStorage[127.0.0.1:33407,DS-aabd1a45-7627-4917-97b0-ae7180915240,DISK], DatanodeInfoWithStorage[127.0.0.1:37389,DS-60e6a1fa-8f39-4da3-98bc-ff9ac9bb5667,DISK], DatanodeInfoWithStorage[127.0.0.1:44388,DS-a27266b1-805b-4604-a0f1-87efc96dfbf0,DISK], DatanodeInfoWithStorage[127.0.0.1:34963,DS-6db8a1e2-0593-42fc-b65d-edf36d3d9185,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2024548614-172.17.0.16-1598142724456:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40632,DS-c29324c9-e5b1-421a-af5f-afd6d07b827d,DISK], DatanodeInfoWithStorage[127.0.0.1:45586,DS-e01450bc-6a6e-4e63-87cf-f80f25ba235b,DISK], DatanodeInfoWithStorage[127.0.0.1:44631,DS-0771b57a-ef2b-49d3-8730-22e8ecf91601,DISK], DatanodeInfoWithStorage[127.0.0.1:41200,DS-eeee28e1-250c-489f-914c-a349ceda333e,DISK], DatanodeInfoWithStorage[127.0.0.1:37674,DS-b9f02b84-399f-47cd-b4d3-bd15374cfa0e,DISK], DatanodeInfoWithStorage[127.0.0.1:41153,DS-dbd999e2-0561-4355-bae1-943e1b677cdd,DISK], DatanodeInfoWithStorage[127.0.0.1:39980,DS-416ca457-a35d-4a61-b87d-43a37e2d5911,DISK], DatanodeInfoWithStorage[127.0.0.1:41135,DS-47febb95-88fb-475e-b245-c0ba6a5604d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2024548614-172.17.0.16-1598142724456:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40632,DS-c29324c9-e5b1-421a-af5f-afd6d07b827d,DISK], DatanodeInfoWithStorage[127.0.0.1:45586,DS-e01450bc-6a6e-4e63-87cf-f80f25ba235b,DISK], DatanodeInfoWithStorage[127.0.0.1:44631,DS-0771b57a-ef2b-49d3-8730-22e8ecf91601,DISK], DatanodeInfoWithStorage[127.0.0.1:41200,DS-eeee28e1-250c-489f-914c-a349ceda333e,DISK], DatanodeInfoWithStorage[127.0.0.1:37674,DS-b9f02b84-399f-47cd-b4d3-bd15374cfa0e,DISK], DatanodeInfoWithStorage[127.0.0.1:41153,DS-dbd999e2-0561-4355-bae1-943e1b677cdd,DISK], DatanodeInfoWithStorage[127.0.0.1:39980,DS-416ca457-a35d-4a61-b87d-43a37e2d5911,DISK], DatanodeInfoWithStorage[127.0.0.1:41135,DS-47febb95-88fb-475e-b245-c0ba6a5604d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-141192405-172.17.0.16-1598142758954:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34000,DS-21bd8c83-c06b-4506-948b-caf631ee45dd,DISK], DatanodeInfoWithStorage[127.0.0.1:41415,DS-b86e5e57-640f-4a67-bb1a-6842b5c49711,DISK], DatanodeInfoWithStorage[127.0.0.1:35230,DS-3f58653b-9e79-406d-b6e7-2553557dd555,DISK], DatanodeInfoWithStorage[127.0.0.1:45685,DS-e4d57c7d-c548-4ce6-9ed8-aba38650267d,DISK], DatanodeInfoWithStorage[127.0.0.1:39190,DS-dd99158a-170e-43b4-afc4-4756c714bc2c,DISK], DatanodeInfoWithStorage[127.0.0.1:42008,DS-f290d6ec-e5ab-4326-bf46-7dfc4c42c5b5,DISK], DatanodeInfoWithStorage[127.0.0.1:35692,DS-a12d4911-cbfc-426e-b857-dae90af0c83b,DISK], DatanodeInfoWithStorage[127.0.0.1:40526,DS-6a6103fd-7aef-4e5a-93bc-db5238518374,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-141192405-172.17.0.16-1598142758954:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34000,DS-21bd8c83-c06b-4506-948b-caf631ee45dd,DISK], DatanodeInfoWithStorage[127.0.0.1:41415,DS-b86e5e57-640f-4a67-bb1a-6842b5c49711,DISK], DatanodeInfoWithStorage[127.0.0.1:35230,DS-3f58653b-9e79-406d-b6e7-2553557dd555,DISK], DatanodeInfoWithStorage[127.0.0.1:45685,DS-e4d57c7d-c548-4ce6-9ed8-aba38650267d,DISK], DatanodeInfoWithStorage[127.0.0.1:39190,DS-dd99158a-170e-43b4-afc4-4756c714bc2c,DISK], DatanodeInfoWithStorage[127.0.0.1:42008,DS-f290d6ec-e5ab-4326-bf46-7dfc4c42c5b5,DISK], DatanodeInfoWithStorage[127.0.0.1:35692,DS-a12d4911-cbfc-426e-b857-dae90af0c83b,DISK], DatanodeInfoWithStorage[127.0.0.1:40526,DS-6a6103fd-7aef-4e5a-93bc-db5238518374,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1052190249-172.17.0.16-1598142828619:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45681,DS-e5d84894-82e0-4939-84df-de3efffbee72,DISK], DatanodeInfoWithStorage[127.0.0.1:36250,DS-0d3622c2-54bc-4954-9442-2f40e3962237,DISK], DatanodeInfoWithStorage[127.0.0.1:38470,DS-2f8c4a71-f5e3-4e16-9762-c5fd70454cb5,DISK], DatanodeInfoWithStorage[127.0.0.1:41405,DS-e51a00ca-c04f-43e2-928d-0760e214504c,DISK], DatanodeInfoWithStorage[127.0.0.1:43923,DS-e6bb8453-8b4b-4b43-a256-05009730f1c6,DISK], DatanodeInfoWithStorage[127.0.0.1:38207,DS-a741abd7-60c7-4727-b710-7da68883ae21,DISK], DatanodeInfoWithStorage[127.0.0.1:40332,DS-302e7d82-939d-4878-a045-4b6108faf081,DISK], DatanodeInfoWithStorage[127.0.0.1:39079,DS-868f1a6f-66dd-4120-8a70-04adb7421c44,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1052190249-172.17.0.16-1598142828619:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45681,DS-e5d84894-82e0-4939-84df-de3efffbee72,DISK], DatanodeInfoWithStorage[127.0.0.1:36250,DS-0d3622c2-54bc-4954-9442-2f40e3962237,DISK], DatanodeInfoWithStorage[127.0.0.1:38470,DS-2f8c4a71-f5e3-4e16-9762-c5fd70454cb5,DISK], DatanodeInfoWithStorage[127.0.0.1:41405,DS-e51a00ca-c04f-43e2-928d-0760e214504c,DISK], DatanodeInfoWithStorage[127.0.0.1:43923,DS-e6bb8453-8b4b-4b43-a256-05009730f1c6,DISK], DatanodeInfoWithStorage[127.0.0.1:38207,DS-a741abd7-60c7-4727-b710-7da68883ae21,DISK], DatanodeInfoWithStorage[127.0.0.1:40332,DS-302e7d82-939d-4878-a045-4b6108faf081,DISK], DatanodeInfoWithStorage[127.0.0.1:39079,DS-868f1a6f-66dd-4120-8a70-04adb7421c44,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1430109578-172.17.0.16-1598143061787:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44332,DS-752b5ce2-c0af-4d13-a1ad-b97632fb8f2f,DISK], DatanodeInfoWithStorage[127.0.0.1:46029,DS-58ffcce5-947b-46b7-9230-f6be7d11bbaa,DISK], DatanodeInfoWithStorage[127.0.0.1:37083,DS-39827be7-a914-4813-a5eb-01fcf65d7f0c,DISK], DatanodeInfoWithStorage[127.0.0.1:40284,DS-b2abd5d5-564b-4e02-be77-582ad42e334a,DISK], DatanodeInfoWithStorage[127.0.0.1:44734,DS-52b1b6af-6c56-4187-a2b4-37b86e90e73b,DISK], DatanodeInfoWithStorage[127.0.0.1:32888,DS-bf011d0f-fe82-4c10-bdd5-2b16ec2df029,DISK], DatanodeInfoWithStorage[127.0.0.1:43059,DS-0a48b85d-e030-4b4b-9e8a-771f9807c9df,DISK], DatanodeInfoWithStorage[127.0.0.1:45369,DS-b9951b3c-ddfb-4cc1-bba5-f8eed0484a8b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1430109578-172.17.0.16-1598143061787:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44332,DS-752b5ce2-c0af-4d13-a1ad-b97632fb8f2f,DISK], DatanodeInfoWithStorage[127.0.0.1:46029,DS-58ffcce5-947b-46b7-9230-f6be7d11bbaa,DISK], DatanodeInfoWithStorage[127.0.0.1:37083,DS-39827be7-a914-4813-a5eb-01fcf65d7f0c,DISK], DatanodeInfoWithStorage[127.0.0.1:40284,DS-b2abd5d5-564b-4e02-be77-582ad42e334a,DISK], DatanodeInfoWithStorage[127.0.0.1:44734,DS-52b1b6af-6c56-4187-a2b4-37b86e90e73b,DISK], DatanodeInfoWithStorage[127.0.0.1:32888,DS-bf011d0f-fe82-4c10-bdd5-2b16ec2df029,DISK], DatanodeInfoWithStorage[127.0.0.1:43059,DS-0a48b85d-e030-4b4b-9e8a-771f9807c9df,DISK], DatanodeInfoWithStorage[127.0.0.1:45369,DS-b9951b3c-ddfb-4cc1-bba5-f8eed0484a8b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1667917007-172.17.0.16-1598143256684:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43241,DS-d465db6a-9082-44f8-8d22-29e11d3b0e76,DISK], DatanodeInfoWithStorage[127.0.0.1:39089,DS-7f562aaf-5a97-42e8-80e0-3ff664c27047,DISK], DatanodeInfoWithStorage[127.0.0.1:42885,DS-a58582de-7248-4f06-a936-a818a5f18ec3,DISK], DatanodeInfoWithStorage[127.0.0.1:45295,DS-f775d244-0c49-48e4-b14e-f6cf2429c8a7,DISK], DatanodeInfoWithStorage[127.0.0.1:36529,DS-f3ab923a-3a65-44d2-b43a-fd43ab0107b1,DISK], DatanodeInfoWithStorage[127.0.0.1:35899,DS-241b288d-75ec-451e-8d8f-ff72942ab954,DISK], DatanodeInfoWithStorage[127.0.0.1:38443,DS-0660a02d-73f9-4706-bae5-87ad607b9650,DISK], DatanodeInfoWithStorage[127.0.0.1:44005,DS-80eaa3fd-a6b3-46d5-bff5-83d824e1f0ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1667917007-172.17.0.16-1598143256684:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43241,DS-d465db6a-9082-44f8-8d22-29e11d3b0e76,DISK], DatanodeInfoWithStorage[127.0.0.1:39089,DS-7f562aaf-5a97-42e8-80e0-3ff664c27047,DISK], DatanodeInfoWithStorage[127.0.0.1:42885,DS-a58582de-7248-4f06-a936-a818a5f18ec3,DISK], DatanodeInfoWithStorage[127.0.0.1:45295,DS-f775d244-0c49-48e4-b14e-f6cf2429c8a7,DISK], DatanodeInfoWithStorage[127.0.0.1:36529,DS-f3ab923a-3a65-44d2-b43a-fd43ab0107b1,DISK], DatanodeInfoWithStorage[127.0.0.1:35899,DS-241b288d-75ec-451e-8d8f-ff72942ab954,DISK], DatanodeInfoWithStorage[127.0.0.1:38443,DS-0660a02d-73f9-4706-bae5-87ad607b9650,DISK], DatanodeInfoWithStorage[127.0.0.1:44005,DS-80eaa3fd-a6b3-46d5-bff5-83d824e1f0ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-320790945-172.17.0.16-1598143488136:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37023,DS-094210d2-ce84-477f-a45b-3b329297d412,DISK], DatanodeInfoWithStorage[127.0.0.1:34662,DS-8ee30159-9369-47af-b38e-d6e4df8e685d,DISK], DatanodeInfoWithStorage[127.0.0.1:44061,DS-ea3a41cb-7682-4677-89a5-07b274cecafd,DISK], DatanodeInfoWithStorage[127.0.0.1:39162,DS-02485460-bd55-4301-8011-7123881d0175,DISK], DatanodeInfoWithStorage[127.0.0.1:37366,DS-92666a89-e0df-4835-a572-d11580c3d76f,DISK], DatanodeInfoWithStorage[127.0.0.1:33399,DS-67cedd9e-ce91-4b66-860e-a37602b9450a,DISK], DatanodeInfoWithStorage[127.0.0.1:40949,DS-bd2ce994-6829-417b-9638-7577f8d33ecc,DISK], DatanodeInfoWithStorage[127.0.0.1:35250,DS-d639b0fb-920c-46e8-8d27-ec3a2ffee3a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-320790945-172.17.0.16-1598143488136:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37023,DS-094210d2-ce84-477f-a45b-3b329297d412,DISK], DatanodeInfoWithStorage[127.0.0.1:34662,DS-8ee30159-9369-47af-b38e-d6e4df8e685d,DISK], DatanodeInfoWithStorage[127.0.0.1:44061,DS-ea3a41cb-7682-4677-89a5-07b274cecafd,DISK], DatanodeInfoWithStorage[127.0.0.1:39162,DS-02485460-bd55-4301-8011-7123881d0175,DISK], DatanodeInfoWithStorage[127.0.0.1:37366,DS-92666a89-e0df-4835-a572-d11580c3d76f,DISK], DatanodeInfoWithStorage[127.0.0.1:33399,DS-67cedd9e-ce91-4b66-860e-a37602b9450a,DISK], DatanodeInfoWithStorage[127.0.0.1:40949,DS-bd2ce994-6829-417b-9638-7577f8d33ecc,DISK], DatanodeInfoWithStorage[127.0.0.1:35250,DS-d639b0fb-920c-46e8-8d27-ec3a2ffee3a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1345105149-172.17.0.16-1598143878347:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34965,DS-2a6f5726-65ed-4e00-bdaa-4d4369e12e52,DISK], DatanodeInfoWithStorage[127.0.0.1:35772,DS-ee571e45-ed70-4ad3-9a4e-8b1bdcf30e1d,DISK], DatanodeInfoWithStorage[127.0.0.1:43763,DS-693e11aa-8ed9-4971-bf8a-fb1af1bee6ee,DISK], DatanodeInfoWithStorage[127.0.0.1:46597,DS-e081d247-0173-4f62-9f30-2fe2dec7bc1c,DISK], DatanodeInfoWithStorage[127.0.0.1:32976,DS-7a56fa4a-5759-4f6e-8723-3ca2b990067a,DISK], DatanodeInfoWithStorage[127.0.0.1:41258,DS-35afe5db-d0dd-450f-94c4-eda586c9490e,DISK], DatanodeInfoWithStorage[127.0.0.1:45553,DS-79724fa6-5502-4fa8-bbc2-daa5d72d3a47,DISK], DatanodeInfoWithStorage[127.0.0.1:45113,DS-9451972f-99fd-447f-8ef3-b7f8388c85e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1345105149-172.17.0.16-1598143878347:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34965,DS-2a6f5726-65ed-4e00-bdaa-4d4369e12e52,DISK], DatanodeInfoWithStorage[127.0.0.1:35772,DS-ee571e45-ed70-4ad3-9a4e-8b1bdcf30e1d,DISK], DatanodeInfoWithStorage[127.0.0.1:43763,DS-693e11aa-8ed9-4971-bf8a-fb1af1bee6ee,DISK], DatanodeInfoWithStorage[127.0.0.1:46597,DS-e081d247-0173-4f62-9f30-2fe2dec7bc1c,DISK], DatanodeInfoWithStorage[127.0.0.1:32976,DS-7a56fa4a-5759-4f6e-8723-3ca2b990067a,DISK], DatanodeInfoWithStorage[127.0.0.1:41258,DS-35afe5db-d0dd-450f-94c4-eda586c9490e,DISK], DatanodeInfoWithStorage[127.0.0.1:45553,DS-79724fa6-5502-4fa8-bbc2-daa5d72d3a47,DISK], DatanodeInfoWithStorage[127.0.0.1:45113,DS-9451972f-99fd-447f-8ef3-b7f8388c85e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-460171955-172.17.0.16-1598144129280:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43677,DS-12b4e0b3-f774-4b45-9d8b-c36cb0aebd3f,DISK], DatanodeInfoWithStorage[127.0.0.1:33093,DS-8087b9d6-7030-458f-a5d2-03da030e8c6d,DISK], DatanodeInfoWithStorage[127.0.0.1:36243,DS-bb4c5dd1-534c-454c-b8d0-30798e1cd291,DISK], DatanodeInfoWithStorage[127.0.0.1:46248,DS-e09cbe50-77f8-47d6-8b21-b95132521b1f,DISK], DatanodeInfoWithStorage[127.0.0.1:34569,DS-4a933806-310e-42b2-b00c-0f7bf15ad359,DISK], DatanodeInfoWithStorage[127.0.0.1:34394,DS-fa3a5de6-f607-4959-adcf-147599e75419,DISK], DatanodeInfoWithStorage[127.0.0.1:44586,DS-9d1a75dc-417e-4231-beac-c7a28ae17de0,DISK], DatanodeInfoWithStorage[127.0.0.1:38681,DS-2e5994b1-5816-4e18-92dc-9e7ab9b2456e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-460171955-172.17.0.16-1598144129280:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43677,DS-12b4e0b3-f774-4b45-9d8b-c36cb0aebd3f,DISK], DatanodeInfoWithStorage[127.0.0.1:33093,DS-8087b9d6-7030-458f-a5d2-03da030e8c6d,DISK], DatanodeInfoWithStorage[127.0.0.1:36243,DS-bb4c5dd1-534c-454c-b8d0-30798e1cd291,DISK], DatanodeInfoWithStorage[127.0.0.1:46248,DS-e09cbe50-77f8-47d6-8b21-b95132521b1f,DISK], DatanodeInfoWithStorage[127.0.0.1:34569,DS-4a933806-310e-42b2-b00c-0f7bf15ad359,DISK], DatanodeInfoWithStorage[127.0.0.1:34394,DS-fa3a5de6-f607-4959-adcf-147599e75419,DISK], DatanodeInfoWithStorage[127.0.0.1:44586,DS-9d1a75dc-417e-4231-beac-c7a28ae17de0,DISK], DatanodeInfoWithStorage[127.0.0.1:38681,DS-2e5994b1-5816-4e18-92dc-9e7ab9b2456e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1560245988-172.17.0.16-1598144263416:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41682,DS-0ff6e691-e7aa-4334-ba9f-4f10220286b7,DISK], DatanodeInfoWithStorage[127.0.0.1:33125,DS-174dedd7-2471-4beb-b737-a2a8413c6e5e,DISK], DatanodeInfoWithStorage[127.0.0.1:35784,DS-25a51c1f-a32a-45a9-9fd7-454d0147f2d3,DISK], DatanodeInfoWithStorage[127.0.0.1:39837,DS-02d483d7-7919-4f33-8322-fbfd9a294cd2,DISK], DatanodeInfoWithStorage[127.0.0.1:33528,DS-8b822a37-595b-4030-b746-52634b5230ea,DISK], DatanodeInfoWithStorage[127.0.0.1:42981,DS-ad2f6a94-95d7-44fa-b336-5e3785e96df0,DISK], DatanodeInfoWithStorage[127.0.0.1:44059,DS-47b3cc03-3291-4d17-83b0-0ef28d40b4c8,DISK], DatanodeInfoWithStorage[127.0.0.1:40048,DS-ef4cad38-0b92-4e13-867d-04ed65f9c3c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1560245988-172.17.0.16-1598144263416:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41682,DS-0ff6e691-e7aa-4334-ba9f-4f10220286b7,DISK], DatanodeInfoWithStorage[127.0.0.1:33125,DS-174dedd7-2471-4beb-b737-a2a8413c6e5e,DISK], DatanodeInfoWithStorage[127.0.0.1:35784,DS-25a51c1f-a32a-45a9-9fd7-454d0147f2d3,DISK], DatanodeInfoWithStorage[127.0.0.1:39837,DS-02d483d7-7919-4f33-8322-fbfd9a294cd2,DISK], DatanodeInfoWithStorage[127.0.0.1:33528,DS-8b822a37-595b-4030-b746-52634b5230ea,DISK], DatanodeInfoWithStorage[127.0.0.1:42981,DS-ad2f6a94-95d7-44fa-b336-5e3785e96df0,DISK], DatanodeInfoWithStorage[127.0.0.1:44059,DS-47b3cc03-3291-4d17-83b0-0ef28d40b4c8,DISK], DatanodeInfoWithStorage[127.0.0.1:40048,DS-ef4cad38-0b92-4e13-867d-04ed65f9c3c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-315438133-172.17.0.16-1598144379429:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44878,DS-89e77db4-f006-4477-97c8-1de33732e3a5,DISK], DatanodeInfoWithStorage[127.0.0.1:33787,DS-f6c52ffe-c4b3-498d-a503-364286bf661a,DISK], DatanodeInfoWithStorage[127.0.0.1:43770,DS-24b8a0b6-3991-4ef2-8c7b-17e17f3860b5,DISK], DatanodeInfoWithStorage[127.0.0.1:40214,DS-1990504f-caf0-42e4-8bb2-f3c4f93ba920,DISK], DatanodeInfoWithStorage[127.0.0.1:39671,DS-2f1afb2c-e125-42ec-8418-2303a3d8e2f7,DISK], DatanodeInfoWithStorage[127.0.0.1:38066,DS-7f811d85-26ea-4b59-a592-b042a42baf07,DISK], DatanodeInfoWithStorage[127.0.0.1:36658,DS-978fdf6f-a56c-4f36-9181-d32fc7008c1c,DISK], DatanodeInfoWithStorage[127.0.0.1:46438,DS-26e2d0d4-e814-402e-8105-42a7f64a2a41,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-315438133-172.17.0.16-1598144379429:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44878,DS-89e77db4-f006-4477-97c8-1de33732e3a5,DISK], DatanodeInfoWithStorage[127.0.0.1:33787,DS-f6c52ffe-c4b3-498d-a503-364286bf661a,DISK], DatanodeInfoWithStorage[127.0.0.1:43770,DS-24b8a0b6-3991-4ef2-8c7b-17e17f3860b5,DISK], DatanodeInfoWithStorage[127.0.0.1:40214,DS-1990504f-caf0-42e4-8bb2-f3c4f93ba920,DISK], DatanodeInfoWithStorage[127.0.0.1:39671,DS-2f1afb2c-e125-42ec-8418-2303a3d8e2f7,DISK], DatanodeInfoWithStorage[127.0.0.1:38066,DS-7f811d85-26ea-4b59-a592-b042a42baf07,DISK], DatanodeInfoWithStorage[127.0.0.1:36658,DS-978fdf6f-a56c-4f36-9181-d32fc7008c1c,DISK], DatanodeInfoWithStorage[127.0.0.1:46438,DS-26e2d0d4-e814-402e-8105-42a7f64a2a41,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-37347361-172.17.0.16-1598144563984:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40478,DS-f2ec5f7b-1dbc-4101-9dd5-fab2e78b13f5,DISK], DatanodeInfoWithStorage[127.0.0.1:46790,DS-e61e6d14-d1e9-4655-8fa3-477344e38e81,DISK], DatanodeInfoWithStorage[127.0.0.1:37640,DS-c3ea4847-79fd-42b5-a009-6d33073d75c6,DISK], DatanodeInfoWithStorage[127.0.0.1:40920,DS-da955a68-99ee-4991-9833-7e256921c656,DISK], DatanodeInfoWithStorage[127.0.0.1:35173,DS-41fdfcc4-e8b7-4f3e-a5f9-d419591b471e,DISK], DatanodeInfoWithStorage[127.0.0.1:34450,DS-cd41a485-0640-470a-9de9-67be8a264b97,DISK], DatanodeInfoWithStorage[127.0.0.1:42585,DS-59404573-1992-47b3-a05a-5816e214067c,DISK], DatanodeInfoWithStorage[127.0.0.1:41846,DS-9e660897-ab6f-44ef-b418-84d0a8f3d8e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-37347361-172.17.0.16-1598144563984:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40478,DS-f2ec5f7b-1dbc-4101-9dd5-fab2e78b13f5,DISK], DatanodeInfoWithStorage[127.0.0.1:46790,DS-e61e6d14-d1e9-4655-8fa3-477344e38e81,DISK], DatanodeInfoWithStorage[127.0.0.1:37640,DS-c3ea4847-79fd-42b5-a009-6d33073d75c6,DISK], DatanodeInfoWithStorage[127.0.0.1:40920,DS-da955a68-99ee-4991-9833-7e256921c656,DISK], DatanodeInfoWithStorage[127.0.0.1:35173,DS-41fdfcc4-e8b7-4f3e-a5f9-d419591b471e,DISK], DatanodeInfoWithStorage[127.0.0.1:34450,DS-cd41a485-0640-470a-9de9-67be8a264b97,DISK], DatanodeInfoWithStorage[127.0.0.1:42585,DS-59404573-1992-47b3-a05a-5816e214067c,DISK], DatanodeInfoWithStorage[127.0.0.1:41846,DS-9e660897-ab6f-44ef-b418-84d0a8f3d8e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-856692176-172.17.0.16-1598144786524:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44101,DS-f9ffc4d2-959c-4c4c-b019-c92d68e55614,DISK], DatanodeInfoWithStorage[127.0.0.1:34375,DS-4c76f263-29b0-499d-ad43-5b5258f7bd53,DISK], DatanodeInfoWithStorage[127.0.0.1:32927,DS-bb0ae15f-e73f-4c63-bae2-c0d18274a7db,DISK], DatanodeInfoWithStorage[127.0.0.1:36834,DS-d807429e-0622-436e-9349-138b4f8d2cf5,DISK], DatanodeInfoWithStorage[127.0.0.1:32979,DS-60d5bfb8-4a98-42c7-b939-b8dd9252865a,DISK], DatanodeInfoWithStorage[127.0.0.1:43314,DS-6b720ee1-2c50-4e3b-a21a-ed46f1d95006,DISK], DatanodeInfoWithStorage[127.0.0.1:35055,DS-97a5bff2-33ee-460b-9007-a567c7e93c28,DISK], DatanodeInfoWithStorage[127.0.0.1:33517,DS-5c69ba64-e0e3-4e59-b868-0d75b92ff367,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-856692176-172.17.0.16-1598144786524:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44101,DS-f9ffc4d2-959c-4c4c-b019-c92d68e55614,DISK], DatanodeInfoWithStorage[127.0.0.1:34375,DS-4c76f263-29b0-499d-ad43-5b5258f7bd53,DISK], DatanodeInfoWithStorage[127.0.0.1:32927,DS-bb0ae15f-e73f-4c63-bae2-c0d18274a7db,DISK], DatanodeInfoWithStorage[127.0.0.1:36834,DS-d807429e-0622-436e-9349-138b4f8d2cf5,DISK], DatanodeInfoWithStorage[127.0.0.1:32979,DS-60d5bfb8-4a98-42c7-b939-b8dd9252865a,DISK], DatanodeInfoWithStorage[127.0.0.1:43314,DS-6b720ee1-2c50-4e3b-a21a-ed46f1d95006,DISK], DatanodeInfoWithStorage[127.0.0.1:35055,DS-97a5bff2-33ee-460b-9007-a567c7e93c28,DISK], DatanodeInfoWithStorage[127.0.0.1:33517,DS-5c69ba64-e0e3-4e59-b868-0d75b92ff367,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1746698254-172.17.0.16-1598144916812:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35560,DS-da9fbc5c-d011-409c-af01-f7827b1c4986,DISK], DatanodeInfoWithStorage[127.0.0.1:33329,DS-7f2cc7e1-1747-4bce-a9b3-138cc2829667,DISK], DatanodeInfoWithStorage[127.0.0.1:34277,DS-1ffa13f9-c3aa-4493-b31b-fb33604c9ef9,DISK], DatanodeInfoWithStorage[127.0.0.1:41937,DS-1590acb8-3bc1-4650-a6cf-81439336d164,DISK], DatanodeInfoWithStorage[127.0.0.1:39188,DS-342b1819-11db-4757-9c61-26310e109726,DISK], DatanodeInfoWithStorage[127.0.0.1:44372,DS-33ed862c-782e-43ba-b38a-019219608817,DISK], DatanodeInfoWithStorage[127.0.0.1:46364,DS-30e86924-58d9-42b7-98bd-6c52a7695aa6,DISK], DatanodeInfoWithStorage[127.0.0.1:34303,DS-7ffea715-fcad-4d1c-bfef-32c8c00b38ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1746698254-172.17.0.16-1598144916812:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35560,DS-da9fbc5c-d011-409c-af01-f7827b1c4986,DISK], DatanodeInfoWithStorage[127.0.0.1:33329,DS-7f2cc7e1-1747-4bce-a9b3-138cc2829667,DISK], DatanodeInfoWithStorage[127.0.0.1:34277,DS-1ffa13f9-c3aa-4493-b31b-fb33604c9ef9,DISK], DatanodeInfoWithStorage[127.0.0.1:41937,DS-1590acb8-3bc1-4650-a6cf-81439336d164,DISK], DatanodeInfoWithStorage[127.0.0.1:39188,DS-342b1819-11db-4757-9c61-26310e109726,DISK], DatanodeInfoWithStorage[127.0.0.1:44372,DS-33ed862c-782e-43ba-b38a-019219608817,DISK], DatanodeInfoWithStorage[127.0.0.1:46364,DS-30e86924-58d9-42b7-98bd-6c52a7695aa6,DISK], DatanodeInfoWithStorage[127.0.0.1:34303,DS-7ffea715-fcad-4d1c-bfef-32c8c00b38ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2056597876-172.17.0.16-1598145093741:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38585,DS-e6219f47-9d60-42ae-a3a2-2472673b356e,DISK], DatanodeInfoWithStorage[127.0.0.1:45118,DS-5bba9668-800b-4d97-a119-c2ce374844e0,DISK], DatanodeInfoWithStorage[127.0.0.1:39091,DS-8e04d7d1-6478-4d54-ad7d-8e9c89d14b20,DISK], DatanodeInfoWithStorage[127.0.0.1:44592,DS-9e52a567-5582-4033-ba3e-41e033adff83,DISK], DatanodeInfoWithStorage[127.0.0.1:38079,DS-6c576bf1-e120-4644-a2c4-cf6aa4ba1a57,DISK], DatanodeInfoWithStorage[127.0.0.1:44594,DS-b27113c8-9964-4f88-abbb-94aaae62b35d,DISK], DatanodeInfoWithStorage[127.0.0.1:38842,DS-84db7d78-9aa0-49e8-991f-451a01369533,DISK], DatanodeInfoWithStorage[127.0.0.1:46655,DS-8bf7a770-e816-46af-bc0d-9184c620e9cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2056597876-172.17.0.16-1598145093741:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38585,DS-e6219f47-9d60-42ae-a3a2-2472673b356e,DISK], DatanodeInfoWithStorage[127.0.0.1:45118,DS-5bba9668-800b-4d97-a119-c2ce374844e0,DISK], DatanodeInfoWithStorage[127.0.0.1:39091,DS-8e04d7d1-6478-4d54-ad7d-8e9c89d14b20,DISK], DatanodeInfoWithStorage[127.0.0.1:44592,DS-9e52a567-5582-4033-ba3e-41e033adff83,DISK], DatanodeInfoWithStorage[127.0.0.1:38079,DS-6c576bf1-e120-4644-a2c4-cf6aa4ba1a57,DISK], DatanodeInfoWithStorage[127.0.0.1:44594,DS-b27113c8-9964-4f88-abbb-94aaae62b35d,DISK], DatanodeInfoWithStorage[127.0.0.1:38842,DS-84db7d78-9aa0-49e8-991f-451a01369533,DISK], DatanodeInfoWithStorage[127.0.0.1:46655,DS-8bf7a770-e816-46af-bc0d-9184c620e9cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-35611880-172.17.0.16-1598145160537:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36462,DS-6fb97e84-4515-4b7c-a5f1-4ff870048111,DISK], DatanodeInfoWithStorage[127.0.0.1:45600,DS-17cba904-589f-4628-b410-aeb4914ed91c,DISK], DatanodeInfoWithStorage[127.0.0.1:46086,DS-975b49af-55ac-46d6-a5a0-bc930b19b5ab,DISK], DatanodeInfoWithStorage[127.0.0.1:37557,DS-f8736a04-5cdb-4b2a-93c3-6fd16e2da58d,DISK], DatanodeInfoWithStorage[127.0.0.1:39490,DS-3dd045c2-4328-4d26-8eb0-8aad54897ea5,DISK], DatanodeInfoWithStorage[127.0.0.1:37617,DS-85801575-b441-42f5-b96f-fedb0de8908f,DISK], DatanodeInfoWithStorage[127.0.0.1:44597,DS-bc94ca3b-2b42-4b5f-b4c5-f2bed82e005b,DISK], DatanodeInfoWithStorage[127.0.0.1:42812,DS-ef28bef4-ce42-44f3-bbdd-114f4733f360,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-35611880-172.17.0.16-1598145160537:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36462,DS-6fb97e84-4515-4b7c-a5f1-4ff870048111,DISK], DatanodeInfoWithStorage[127.0.0.1:45600,DS-17cba904-589f-4628-b410-aeb4914ed91c,DISK], DatanodeInfoWithStorage[127.0.0.1:46086,DS-975b49af-55ac-46d6-a5a0-bc930b19b5ab,DISK], DatanodeInfoWithStorage[127.0.0.1:37557,DS-f8736a04-5cdb-4b2a-93c3-6fd16e2da58d,DISK], DatanodeInfoWithStorage[127.0.0.1:39490,DS-3dd045c2-4328-4d26-8eb0-8aad54897ea5,DISK], DatanodeInfoWithStorage[127.0.0.1:37617,DS-85801575-b441-42f5-b96f-fedb0de8908f,DISK], DatanodeInfoWithStorage[127.0.0.1:44597,DS-bc94ca3b-2b42-4b5f-b4c5-f2bed82e005b,DISK], DatanodeInfoWithStorage[127.0.0.1:42812,DS-ef28bef4-ce42-44f3-bbdd-114f4733f360,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-951394039-172.17.0.16-1598145289651:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34218,DS-6ae69fd4-3c85-48b2-b26e-96b734adba7e,DISK], DatanodeInfoWithStorage[127.0.0.1:37090,DS-d3c67fc2-ddaf-4ebc-8dbb-028d9b54f220,DISK], DatanodeInfoWithStorage[127.0.0.1:35221,DS-35a88f60-f1e4-4607-9ac9-e6d44428e501,DISK], DatanodeInfoWithStorage[127.0.0.1:45155,DS-21fad49d-aa04-4c25-9db5-52aa8bc33f56,DISK], DatanodeInfoWithStorage[127.0.0.1:33807,DS-27a88992-b097-4cfb-91a3-89138bd85d6d,DISK], DatanodeInfoWithStorage[127.0.0.1:33884,DS-cce2d5f5-c8c6-456c-9e5c-d80b37866c5d,DISK], DatanodeInfoWithStorage[127.0.0.1:33647,DS-8eed1ddd-e50a-4995-b2ec-b41c029eb03b,DISK], DatanodeInfoWithStorage[127.0.0.1:39755,DS-43494a44-2fef-4704-9685-8fde39ec89c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-951394039-172.17.0.16-1598145289651:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34218,DS-6ae69fd4-3c85-48b2-b26e-96b734adba7e,DISK], DatanodeInfoWithStorage[127.0.0.1:37090,DS-d3c67fc2-ddaf-4ebc-8dbb-028d9b54f220,DISK], DatanodeInfoWithStorage[127.0.0.1:35221,DS-35a88f60-f1e4-4607-9ac9-e6d44428e501,DISK], DatanodeInfoWithStorage[127.0.0.1:45155,DS-21fad49d-aa04-4c25-9db5-52aa8bc33f56,DISK], DatanodeInfoWithStorage[127.0.0.1:33807,DS-27a88992-b097-4cfb-91a3-89138bd85d6d,DISK], DatanodeInfoWithStorage[127.0.0.1:33884,DS-cce2d5f5-c8c6-456c-9e5c-d80b37866c5d,DISK], DatanodeInfoWithStorage[127.0.0.1:33647,DS-8eed1ddd-e50a-4995-b2ec-b41c029eb03b,DISK], DatanodeInfoWithStorage[127.0.0.1:39755,DS-43494a44-2fef-4704-9685-8fde39ec89c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1227292581-172.17.0.16-1598145442361:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37291,DS-68bc2e47-63ca-45b5-8d07-a2df5e18debd,DISK], DatanodeInfoWithStorage[127.0.0.1:40302,DS-3ce2fc06-ee71-424e-bc62-22b1d76f44b8,DISK], DatanodeInfoWithStorage[127.0.0.1:42873,DS-95271b7b-0be1-4728-9706-aeb599ff3a91,DISK], DatanodeInfoWithStorage[127.0.0.1:45590,DS-aadf881d-9f82-4a2a-a04a-376bfd1b88c0,DISK], DatanodeInfoWithStorage[127.0.0.1:32956,DS-771be1db-9d06-43f6-9c59-1878d6e439e7,DISK], DatanodeInfoWithStorage[127.0.0.1:40913,DS-444b1136-54c5-4fea-a0eb-b28d0943315b,DISK], DatanodeInfoWithStorage[127.0.0.1:43877,DS-c69235fd-a23e-4cc5-8c2c-86488cf462c2,DISK], DatanodeInfoWithStorage[127.0.0.1:39052,DS-7e557323-60d9-4199-aef4-70e8e16b8a8a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1227292581-172.17.0.16-1598145442361:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37291,DS-68bc2e47-63ca-45b5-8d07-a2df5e18debd,DISK], DatanodeInfoWithStorage[127.0.0.1:40302,DS-3ce2fc06-ee71-424e-bc62-22b1d76f44b8,DISK], DatanodeInfoWithStorage[127.0.0.1:42873,DS-95271b7b-0be1-4728-9706-aeb599ff3a91,DISK], DatanodeInfoWithStorage[127.0.0.1:45590,DS-aadf881d-9f82-4a2a-a04a-376bfd1b88c0,DISK], DatanodeInfoWithStorage[127.0.0.1:32956,DS-771be1db-9d06-43f6-9c59-1878d6e439e7,DISK], DatanodeInfoWithStorage[127.0.0.1:40913,DS-444b1136-54c5-4fea-a0eb-b28d0943315b,DISK], DatanodeInfoWithStorage[127.0.0.1:43877,DS-c69235fd-a23e-4cc5-8c2c-86488cf462c2,DISK], DatanodeInfoWithStorage[127.0.0.1:39052,DS-7e557323-60d9-4199-aef4-70e8e16b8a8a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1214095435-172.17.0.16-1598145631327:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38707,DS-c68886c0-8b20-48c7-bbba-687d7eca5a9a,DISK], DatanodeInfoWithStorage[127.0.0.1:46406,DS-6b814507-b8ab-43c7-b20c-5b99d255ac7a,DISK], DatanodeInfoWithStorage[127.0.0.1:42446,DS-dab2e19a-41db-4f20-9f94-656ba5bf9cc0,DISK], DatanodeInfoWithStorage[127.0.0.1:34846,DS-c029672b-44de-458f-9797-25d18c9e4e95,DISK], DatanodeInfoWithStorage[127.0.0.1:39179,DS-8886f560-b24f-4b11-b919-15dc33432d45,DISK], DatanodeInfoWithStorage[127.0.0.1:44355,DS-073c4868-f670-45b5-b2c8-0200c612dc12,DISK], DatanodeInfoWithStorage[127.0.0.1:36504,DS-f24b7316-750e-4396-9c37-6e03a669f184,DISK], DatanodeInfoWithStorage[127.0.0.1:33177,DS-d3bdf5ba-dbc0-4d37-9dea-67ff3b481dbc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1214095435-172.17.0.16-1598145631327:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38707,DS-c68886c0-8b20-48c7-bbba-687d7eca5a9a,DISK], DatanodeInfoWithStorage[127.0.0.1:46406,DS-6b814507-b8ab-43c7-b20c-5b99d255ac7a,DISK], DatanodeInfoWithStorage[127.0.0.1:42446,DS-dab2e19a-41db-4f20-9f94-656ba5bf9cc0,DISK], DatanodeInfoWithStorage[127.0.0.1:34846,DS-c029672b-44de-458f-9797-25d18c9e4e95,DISK], DatanodeInfoWithStorage[127.0.0.1:39179,DS-8886f560-b24f-4b11-b919-15dc33432d45,DISK], DatanodeInfoWithStorage[127.0.0.1:44355,DS-073c4868-f670-45b5-b2c8-0200c612dc12,DISK], DatanodeInfoWithStorage[127.0.0.1:36504,DS-f24b7316-750e-4396-9c37-6e03a669f184,DISK], DatanodeInfoWithStorage[127.0.0.1:33177,DS-d3bdf5ba-dbc0-4d37-9dea-67ff3b481dbc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1232812894-172.17.0.16-1598146350994:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33895,DS-d4bc7699-ece7-4170-a6ae-fd11279150a5,DISK], DatanodeInfoWithStorage[127.0.0.1:42099,DS-af16a128-5a23-44ae-b4fc-f8cb9db929ff,DISK], DatanodeInfoWithStorage[127.0.0.1:39588,DS-7c4ab6e2-c156-4046-93e5-b43cb370c712,DISK], DatanodeInfoWithStorage[127.0.0.1:44974,DS-a93b4157-ab0f-4c67-81dd-e56578757851,DISK], DatanodeInfoWithStorage[127.0.0.1:44592,DS-95ed2bf6-fae5-4999-bff9-025628cd3b17,DISK], DatanodeInfoWithStorage[127.0.0.1:40247,DS-c6838e4a-a659-455c-a011-31219c6bd6bb,DISK], DatanodeInfoWithStorage[127.0.0.1:35751,DS-8a6cbb41-ee9d-4ed8-b544-1a8854d17857,DISK], DatanodeInfoWithStorage[127.0.0.1:36835,DS-d792911a-d9dd-411e-b67c-c56b97d0d6d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1232812894-172.17.0.16-1598146350994:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33895,DS-d4bc7699-ece7-4170-a6ae-fd11279150a5,DISK], DatanodeInfoWithStorage[127.0.0.1:42099,DS-af16a128-5a23-44ae-b4fc-f8cb9db929ff,DISK], DatanodeInfoWithStorage[127.0.0.1:39588,DS-7c4ab6e2-c156-4046-93e5-b43cb370c712,DISK], DatanodeInfoWithStorage[127.0.0.1:44974,DS-a93b4157-ab0f-4c67-81dd-e56578757851,DISK], DatanodeInfoWithStorage[127.0.0.1:44592,DS-95ed2bf6-fae5-4999-bff9-025628cd3b17,DISK], DatanodeInfoWithStorage[127.0.0.1:40247,DS-c6838e4a-a659-455c-a011-31219c6bd6bb,DISK], DatanodeInfoWithStorage[127.0.0.1:35751,DS-8a6cbb41-ee9d-4ed8-b544-1a8854d17857,DISK], DatanodeInfoWithStorage[127.0.0.1:36835,DS-d792911a-d9dd-411e-b67c-c56b97d0d6d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-528376426-172.17.0.16-1598146508429:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37371,DS-dd7da7d8-865a-4874-9386-c11b0b91b603,DISK], DatanodeInfoWithStorage[127.0.0.1:38270,DS-b5af760d-358f-424e-bc78-3eb51aff07df,DISK], DatanodeInfoWithStorage[127.0.0.1:46568,DS-b8f9124e-e95d-4923-9394-cdf7751e4516,DISK], DatanodeInfoWithStorage[127.0.0.1:36527,DS-d1622356-48cd-4c8a-b76f-f71d2176696d,DISK], DatanodeInfoWithStorage[127.0.0.1:40813,DS-137836d4-e20d-44e9-862d-af9fb521f877,DISK], DatanodeInfoWithStorage[127.0.0.1:38842,DS-709fbbfb-637c-480c-83c3-5f1e18fc7d23,DISK], DatanodeInfoWithStorage[127.0.0.1:41877,DS-5dbc2606-bc49-4dee-af12-d0278cab0483,DISK], DatanodeInfoWithStorage[127.0.0.1:36991,DS-624d82c2-b844-4ec2-b31f-75a9d9abef36,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-528376426-172.17.0.16-1598146508429:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37371,DS-dd7da7d8-865a-4874-9386-c11b0b91b603,DISK], DatanodeInfoWithStorage[127.0.0.1:38270,DS-b5af760d-358f-424e-bc78-3eb51aff07df,DISK], DatanodeInfoWithStorage[127.0.0.1:46568,DS-b8f9124e-e95d-4923-9394-cdf7751e4516,DISK], DatanodeInfoWithStorage[127.0.0.1:36527,DS-d1622356-48cd-4c8a-b76f-f71d2176696d,DISK], DatanodeInfoWithStorage[127.0.0.1:40813,DS-137836d4-e20d-44e9-862d-af9fb521f877,DISK], DatanodeInfoWithStorage[127.0.0.1:38842,DS-709fbbfb-637c-480c-83c3-5f1e18fc7d23,DISK], DatanodeInfoWithStorage[127.0.0.1:41877,DS-5dbc2606-bc49-4dee-af12-d0278cab0483,DISK], DatanodeInfoWithStorage[127.0.0.1:36991,DS-624d82c2-b844-4ec2-b31f-75a9d9abef36,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 16 out of 50
result: false positive !!!
Total execution time in seconds : 5498
