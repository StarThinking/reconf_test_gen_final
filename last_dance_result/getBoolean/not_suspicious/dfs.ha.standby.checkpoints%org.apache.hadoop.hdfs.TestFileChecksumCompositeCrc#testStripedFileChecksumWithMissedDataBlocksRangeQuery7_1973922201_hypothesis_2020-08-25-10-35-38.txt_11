reconf_parameter: dfs.ha.standby.checkpoints
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.ha.standby.checkpoints
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-484153329-172.17.0.7-1598351903361:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41107,DS-17d59436-12bc-421a-bf21-24907e03bf87,DISK], DatanodeInfoWithStorage[127.0.0.1:37673,DS-a5482bc1-5a1a-4b46-af9c-44d0d1911b94,DISK], DatanodeInfoWithStorage[127.0.0.1:46123,DS-8b8a91c0-339e-472b-959b-905ae6ab3c4a,DISK], DatanodeInfoWithStorage[127.0.0.1:33306,DS-5092faf2-9766-419c-8935-f2ef1840d587,DISK], DatanodeInfoWithStorage[127.0.0.1:41675,DS-c4d5973f-af96-4ce1-9033-7e1acc80ee60,DISK], DatanodeInfoWithStorage[127.0.0.1:40926,DS-df89bd82-5d4e-45d3-8b07-a05dc935168f,DISK], DatanodeInfoWithStorage[127.0.0.1:33067,DS-1cc307c3-ea32-4ae5-9284-bc55710c2efa,DISK], DatanodeInfoWithStorage[127.0.0.1:33760,DS-7db4388d-393d-4758-a664-0fe74d6aeb49,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-484153329-172.17.0.7-1598351903361:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41107,DS-17d59436-12bc-421a-bf21-24907e03bf87,DISK], DatanodeInfoWithStorage[127.0.0.1:37673,DS-a5482bc1-5a1a-4b46-af9c-44d0d1911b94,DISK], DatanodeInfoWithStorage[127.0.0.1:46123,DS-8b8a91c0-339e-472b-959b-905ae6ab3c4a,DISK], DatanodeInfoWithStorage[127.0.0.1:33306,DS-5092faf2-9766-419c-8935-f2ef1840d587,DISK], DatanodeInfoWithStorage[127.0.0.1:41675,DS-c4d5973f-af96-4ce1-9033-7e1acc80ee60,DISK], DatanodeInfoWithStorage[127.0.0.1:40926,DS-df89bd82-5d4e-45d3-8b07-a05dc935168f,DISK], DatanodeInfoWithStorage[127.0.0.1:33067,DS-1cc307c3-ea32-4ae5-9284-bc55710c2efa,DISK], DatanodeInfoWithStorage[127.0.0.1:33760,DS-7db4388d-393d-4758-a664-0fe74d6aeb49,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.ha.standby.checkpoints
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1995417483-172.17.0.7-1598351941775:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33522,DS-c0cc8008-e9e3-46db-812a-efb550171ada,DISK], DatanodeInfoWithStorage[127.0.0.1:35816,DS-eeb59c96-6db5-4190-91cb-20ac39a4b583,DISK], DatanodeInfoWithStorage[127.0.0.1:39933,DS-c265165d-4fd8-449f-8741-83df84ec2686,DISK], DatanodeInfoWithStorage[127.0.0.1:40019,DS-90eb9bab-a484-47fd-84eb-d33fa60ca436,DISK], DatanodeInfoWithStorage[127.0.0.1:46612,DS-71833b44-9d0d-4629-8702-82908944d39b,DISK], DatanodeInfoWithStorage[127.0.0.1:34622,DS-ac7631e8-6fa5-491b-a042-373a6200ed26,DISK], DatanodeInfoWithStorage[127.0.0.1:41885,DS-d89becf3-2d51-4ce6-ab2d-bfefdeecd9d7,DISK], DatanodeInfoWithStorage[127.0.0.1:35205,DS-03344f92-a929-4b4d-951e-5e6e0ae8ff0e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1995417483-172.17.0.7-1598351941775:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33522,DS-c0cc8008-e9e3-46db-812a-efb550171ada,DISK], DatanodeInfoWithStorage[127.0.0.1:35816,DS-eeb59c96-6db5-4190-91cb-20ac39a4b583,DISK], DatanodeInfoWithStorage[127.0.0.1:39933,DS-c265165d-4fd8-449f-8741-83df84ec2686,DISK], DatanodeInfoWithStorage[127.0.0.1:40019,DS-90eb9bab-a484-47fd-84eb-d33fa60ca436,DISK], DatanodeInfoWithStorage[127.0.0.1:46612,DS-71833b44-9d0d-4629-8702-82908944d39b,DISK], DatanodeInfoWithStorage[127.0.0.1:34622,DS-ac7631e8-6fa5-491b-a042-373a6200ed26,DISK], DatanodeInfoWithStorage[127.0.0.1:41885,DS-d89becf3-2d51-4ce6-ab2d-bfefdeecd9d7,DISK], DatanodeInfoWithStorage[127.0.0.1:35205,DS-03344f92-a929-4b4d-951e-5e6e0ae8ff0e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.ha.standby.checkpoints
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-63361031-172.17.0.7-1598351980709:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36666,DS-c46a509f-b5de-49de-8bdb-e01770371ea3,DISK], DatanodeInfoWithStorage[127.0.0.1:33330,DS-65136509-eb5b-49f2-b244-f2599df2cead,DISK], DatanodeInfoWithStorage[127.0.0.1:36085,DS-c1a18d41-e698-4a10-8732-4cb7f6322f4b,DISK], DatanodeInfoWithStorage[127.0.0.1:33951,DS-8591ee15-6746-4ae9-9b79-bbb1a0bd5eb4,DISK], DatanodeInfoWithStorage[127.0.0.1:34482,DS-d3c7a8f4-b568-4443-b753-1686518f97c7,DISK], DatanodeInfoWithStorage[127.0.0.1:36924,DS-ffde8c34-5f48-4d2a-9c82-10d04861ce73,DISK], DatanodeInfoWithStorage[127.0.0.1:36238,DS-2350426e-ffe5-4ab2-a893-ccb6c54d684b,DISK], DatanodeInfoWithStorage[127.0.0.1:45820,DS-fa175f45-6fbd-4494-a8fb-6b960e5b4a7b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-63361031-172.17.0.7-1598351980709:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36666,DS-c46a509f-b5de-49de-8bdb-e01770371ea3,DISK], DatanodeInfoWithStorage[127.0.0.1:33330,DS-65136509-eb5b-49f2-b244-f2599df2cead,DISK], DatanodeInfoWithStorage[127.0.0.1:36085,DS-c1a18d41-e698-4a10-8732-4cb7f6322f4b,DISK], DatanodeInfoWithStorage[127.0.0.1:33951,DS-8591ee15-6746-4ae9-9b79-bbb1a0bd5eb4,DISK], DatanodeInfoWithStorage[127.0.0.1:34482,DS-d3c7a8f4-b568-4443-b753-1686518f97c7,DISK], DatanodeInfoWithStorage[127.0.0.1:36924,DS-ffde8c34-5f48-4d2a-9c82-10d04861ce73,DISK], DatanodeInfoWithStorage[127.0.0.1:36238,DS-2350426e-ffe5-4ab2-a893-ccb6c54d684b,DISK], DatanodeInfoWithStorage[127.0.0.1:45820,DS-fa175f45-6fbd-4494-a8fb-6b960e5b4a7b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.ha.standby.checkpoints
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-144549212-172.17.0.7-1598352279993:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40543,DS-84350d4a-a95a-4b23-b370-e916245f833e,DISK], DatanodeInfoWithStorage[127.0.0.1:35940,DS-df420274-2419-43e6-a520-962b1200540f,DISK], DatanodeInfoWithStorage[127.0.0.1:42057,DS-ef299f15-8cf4-4671-ac25-1ab1906dc911,DISK], DatanodeInfoWithStorage[127.0.0.1:35706,DS-3d7d57c3-5e1f-460c-bcb4-7ecd9a04cfa6,DISK], DatanodeInfoWithStorage[127.0.0.1:44687,DS-489f5589-1848-408c-bf4d-4fc1785b53cf,DISK], DatanodeInfoWithStorage[127.0.0.1:46737,DS-78a36019-63e5-4dd0-a2b3-7d7120849c1b,DISK], DatanodeInfoWithStorage[127.0.0.1:41094,DS-5807ad32-a63d-437e-b3c5-836252403089,DISK], DatanodeInfoWithStorage[127.0.0.1:45375,DS-d4327317-1d48-450e-8927-9046a3219d19,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-144549212-172.17.0.7-1598352279993:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40543,DS-84350d4a-a95a-4b23-b370-e916245f833e,DISK], DatanodeInfoWithStorage[127.0.0.1:35940,DS-df420274-2419-43e6-a520-962b1200540f,DISK], DatanodeInfoWithStorage[127.0.0.1:42057,DS-ef299f15-8cf4-4671-ac25-1ab1906dc911,DISK], DatanodeInfoWithStorage[127.0.0.1:35706,DS-3d7d57c3-5e1f-460c-bcb4-7ecd9a04cfa6,DISK], DatanodeInfoWithStorage[127.0.0.1:44687,DS-489f5589-1848-408c-bf4d-4fc1785b53cf,DISK], DatanodeInfoWithStorage[127.0.0.1:46737,DS-78a36019-63e5-4dd0-a2b3-7d7120849c1b,DISK], DatanodeInfoWithStorage[127.0.0.1:41094,DS-5807ad32-a63d-437e-b3c5-836252403089,DISK], DatanodeInfoWithStorage[127.0.0.1:45375,DS-d4327317-1d48-450e-8927-9046a3219d19,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.ha.standby.checkpoints
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2016715333-172.17.0.7-1598352396377:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34115,DS-98e8c597-d225-4f10-ba28-48f618b07a03,DISK], DatanodeInfoWithStorage[127.0.0.1:42604,DS-a1045dc2-882d-42e7-84e3-338d5dc5c31a,DISK], DatanodeInfoWithStorage[127.0.0.1:46693,DS-13e532a2-d0e0-45ab-b186-f2c0da0d8628,DISK], DatanodeInfoWithStorage[127.0.0.1:42036,DS-f8f7b109-9a07-4cc4-b7f7-528b4c819ffd,DISK], DatanodeInfoWithStorage[127.0.0.1:40074,DS-b4e3d4d0-c90f-4b88-b67c-55a353ccf785,DISK], DatanodeInfoWithStorage[127.0.0.1:39983,DS-cd7582cc-c340-484e-badb-2673006db68f,DISK], DatanodeInfoWithStorage[127.0.0.1:38607,DS-add93b69-7c81-40f3-8db2-6f796e056554,DISK], DatanodeInfoWithStorage[127.0.0.1:36835,DS-b01d774e-517a-40af-b85a-70b44fcfc5b6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2016715333-172.17.0.7-1598352396377:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34115,DS-98e8c597-d225-4f10-ba28-48f618b07a03,DISK], DatanodeInfoWithStorage[127.0.0.1:42604,DS-a1045dc2-882d-42e7-84e3-338d5dc5c31a,DISK], DatanodeInfoWithStorage[127.0.0.1:46693,DS-13e532a2-d0e0-45ab-b186-f2c0da0d8628,DISK], DatanodeInfoWithStorage[127.0.0.1:42036,DS-f8f7b109-9a07-4cc4-b7f7-528b4c819ffd,DISK], DatanodeInfoWithStorage[127.0.0.1:40074,DS-b4e3d4d0-c90f-4b88-b67c-55a353ccf785,DISK], DatanodeInfoWithStorage[127.0.0.1:39983,DS-cd7582cc-c340-484e-badb-2673006db68f,DISK], DatanodeInfoWithStorage[127.0.0.1:38607,DS-add93b69-7c81-40f3-8db2-6f796e056554,DISK], DatanodeInfoWithStorage[127.0.0.1:36835,DS-b01d774e-517a-40af-b85a-70b44fcfc5b6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.ha.standby.checkpoints
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1201096123-172.17.0.7-1598352552334:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33046,DS-9c850b3e-1494-4cc3-90f3-20a431aca813,DISK], DatanodeInfoWithStorage[127.0.0.1:36647,DS-5128afee-73d3-4db1-8f4e-c8c4a13d5b72,DISK], DatanodeInfoWithStorage[127.0.0.1:37418,DS-54d905b0-8bde-40f5-abbc-e4af5e77b05f,DISK], DatanodeInfoWithStorage[127.0.0.1:42729,DS-03eca734-1a97-44c4-96dd-a206e4c32aa7,DISK], DatanodeInfoWithStorage[127.0.0.1:39916,DS-e86ccbf2-37ed-43a4-b8b6-4ee87993b974,DISK], DatanodeInfoWithStorage[127.0.0.1:38487,DS-db290e73-1171-4d9f-845e-08dcc23f1537,DISK], DatanodeInfoWithStorage[127.0.0.1:40384,DS-721cff62-2f4d-42fe-ba13-acd5331fc0c6,DISK], DatanodeInfoWithStorage[127.0.0.1:42315,DS-e394d656-1728-4931-9d5c-e20f66db3b68,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1201096123-172.17.0.7-1598352552334:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33046,DS-9c850b3e-1494-4cc3-90f3-20a431aca813,DISK], DatanodeInfoWithStorage[127.0.0.1:36647,DS-5128afee-73d3-4db1-8f4e-c8c4a13d5b72,DISK], DatanodeInfoWithStorage[127.0.0.1:37418,DS-54d905b0-8bde-40f5-abbc-e4af5e77b05f,DISK], DatanodeInfoWithStorage[127.0.0.1:42729,DS-03eca734-1a97-44c4-96dd-a206e4c32aa7,DISK], DatanodeInfoWithStorage[127.0.0.1:39916,DS-e86ccbf2-37ed-43a4-b8b6-4ee87993b974,DISK], DatanodeInfoWithStorage[127.0.0.1:38487,DS-db290e73-1171-4d9f-845e-08dcc23f1537,DISK], DatanodeInfoWithStorage[127.0.0.1:40384,DS-721cff62-2f4d-42fe-ba13-acd5331fc0c6,DISK], DatanodeInfoWithStorage[127.0.0.1:42315,DS-e394d656-1728-4931-9d5c-e20f66db3b68,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.ha.standby.checkpoints
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1824178564-172.17.0.7-1598352618177:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45281,DS-aee1eed4-35b0-4197-8db3-7b160fb77b8f,DISK], DatanodeInfoWithStorage[127.0.0.1:41135,DS-0b891aa6-fd91-4023-8ea2-6a26f5c5b452,DISK], DatanodeInfoWithStorage[127.0.0.1:43032,DS-a370fb1e-0039-4abf-95d0-24303a56308d,DISK], DatanodeInfoWithStorage[127.0.0.1:41767,DS-55d43f14-42f6-4c6e-8922-de2a6baa891d,DISK], DatanodeInfoWithStorage[127.0.0.1:40084,DS-4b7235e9-1443-4f55-8baa-67e99f89a64e,DISK], DatanodeInfoWithStorage[127.0.0.1:44697,DS-6bb3d0a6-dd6c-4be7-9e9e-9eb21f00e6ce,DISK], DatanodeInfoWithStorage[127.0.0.1:44480,DS-ad7dbf9e-29a6-463f-b381-ee33c9674cfe,DISK], DatanodeInfoWithStorage[127.0.0.1:36233,DS-a8013f6e-8b23-4b63-bfae-0bc276b45ac1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1824178564-172.17.0.7-1598352618177:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45281,DS-aee1eed4-35b0-4197-8db3-7b160fb77b8f,DISK], DatanodeInfoWithStorage[127.0.0.1:41135,DS-0b891aa6-fd91-4023-8ea2-6a26f5c5b452,DISK], DatanodeInfoWithStorage[127.0.0.1:43032,DS-a370fb1e-0039-4abf-95d0-24303a56308d,DISK], DatanodeInfoWithStorage[127.0.0.1:41767,DS-55d43f14-42f6-4c6e-8922-de2a6baa891d,DISK], DatanodeInfoWithStorage[127.0.0.1:40084,DS-4b7235e9-1443-4f55-8baa-67e99f89a64e,DISK], DatanodeInfoWithStorage[127.0.0.1:44697,DS-6bb3d0a6-dd6c-4be7-9e9e-9eb21f00e6ce,DISK], DatanodeInfoWithStorage[127.0.0.1:44480,DS-ad7dbf9e-29a6-463f-b381-ee33c9674cfe,DISK], DatanodeInfoWithStorage[127.0.0.1:36233,DS-a8013f6e-8b23-4b63-bfae-0bc276b45ac1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.ha.standby.checkpoints
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1173942696-172.17.0.7-1598352772688:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36915,DS-e0daec87-861a-497f-a0c9-cea5dd81adf2,DISK], DatanodeInfoWithStorage[127.0.0.1:38069,DS-b22aa63d-3d20-4ad2-9b5a-c21da85867d5,DISK], DatanodeInfoWithStorage[127.0.0.1:34996,DS-2e016b1a-eab4-49d8-97c6-216536c84c30,DISK], DatanodeInfoWithStorage[127.0.0.1:45088,DS-a3fd4220-5fb9-464f-9251-29c21374c53c,DISK], DatanodeInfoWithStorage[127.0.0.1:39233,DS-a54e1636-5200-4347-9120-79694e56d324,DISK], DatanodeInfoWithStorage[127.0.0.1:36543,DS-5c7f0833-368a-4e10-b598-82833d535793,DISK], DatanodeInfoWithStorage[127.0.0.1:33784,DS-4e055852-b930-4552-a2f4-25bf1e6885ac,DISK], DatanodeInfoWithStorage[127.0.0.1:43444,DS-5d9af668-95b0-4ca8-97fd-b38ae8549a06,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1173942696-172.17.0.7-1598352772688:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36915,DS-e0daec87-861a-497f-a0c9-cea5dd81adf2,DISK], DatanodeInfoWithStorage[127.0.0.1:38069,DS-b22aa63d-3d20-4ad2-9b5a-c21da85867d5,DISK], DatanodeInfoWithStorage[127.0.0.1:34996,DS-2e016b1a-eab4-49d8-97c6-216536c84c30,DISK], DatanodeInfoWithStorage[127.0.0.1:45088,DS-a3fd4220-5fb9-464f-9251-29c21374c53c,DISK], DatanodeInfoWithStorage[127.0.0.1:39233,DS-a54e1636-5200-4347-9120-79694e56d324,DISK], DatanodeInfoWithStorage[127.0.0.1:36543,DS-5c7f0833-368a-4e10-b598-82833d535793,DISK], DatanodeInfoWithStorage[127.0.0.1:33784,DS-4e055852-b930-4552-a2f4-25bf1e6885ac,DISK], DatanodeInfoWithStorage[127.0.0.1:43444,DS-5d9af668-95b0-4ca8-97fd-b38ae8549a06,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.ha.standby.checkpoints
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1756958045-172.17.0.7-1598353045228:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36509,DS-e7bb5a28-f42d-4f3b-920b-fbc1e3da2247,DISK], DatanodeInfoWithStorage[127.0.0.1:36170,DS-1b1e0ddf-35f0-4514-9727-e0e84a2349bb,DISK], DatanodeInfoWithStorage[127.0.0.1:35282,DS-661daa1c-8c48-439a-92f1-8790f8c7fa65,DISK], DatanodeInfoWithStorage[127.0.0.1:34671,DS-a0f6a31c-22f2-474c-ab3c-cfe7c0bd6d17,DISK], DatanodeInfoWithStorage[127.0.0.1:46424,DS-f1e037a9-8aba-4916-850e-dbaf2c41bef2,DISK], DatanodeInfoWithStorage[127.0.0.1:34654,DS-c130e99f-90f9-4433-80b2-89b4f00b641d,DISK], DatanodeInfoWithStorage[127.0.0.1:38846,DS-b98ced71-9986-4b33-9b58-7103ee09120a,DISK], DatanodeInfoWithStorage[127.0.0.1:36368,DS-daf26f60-9101-4f6c-9bad-b31ed1df9d73,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1756958045-172.17.0.7-1598353045228:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36509,DS-e7bb5a28-f42d-4f3b-920b-fbc1e3da2247,DISK], DatanodeInfoWithStorage[127.0.0.1:36170,DS-1b1e0ddf-35f0-4514-9727-e0e84a2349bb,DISK], DatanodeInfoWithStorage[127.0.0.1:35282,DS-661daa1c-8c48-439a-92f1-8790f8c7fa65,DISK], DatanodeInfoWithStorage[127.0.0.1:34671,DS-a0f6a31c-22f2-474c-ab3c-cfe7c0bd6d17,DISK], DatanodeInfoWithStorage[127.0.0.1:46424,DS-f1e037a9-8aba-4916-850e-dbaf2c41bef2,DISK], DatanodeInfoWithStorage[127.0.0.1:34654,DS-c130e99f-90f9-4433-80b2-89b4f00b641d,DISK], DatanodeInfoWithStorage[127.0.0.1:38846,DS-b98ced71-9986-4b33-9b58-7103ee09120a,DISK], DatanodeInfoWithStorage[127.0.0.1:36368,DS-daf26f60-9101-4f6c-9bad-b31ed1df9d73,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.ha.standby.checkpoints
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1061017798-172.17.0.7-1598353110885:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34604,DS-40865b57-0788-4db3-b315-4b044a8c1c86,DISK], DatanodeInfoWithStorage[127.0.0.1:38738,DS-4393d1ea-6ad1-480e-9a23-ff8ba8580320,DISK], DatanodeInfoWithStorage[127.0.0.1:43858,DS-0515075c-1c56-44de-b460-78b2ccf7db6e,DISK], DatanodeInfoWithStorage[127.0.0.1:44087,DS-6d5b9750-86b0-4fc6-aa30-b8eb43af572d,DISK], DatanodeInfoWithStorage[127.0.0.1:45340,DS-0ca6d90d-c25e-4a22-9920-734c1119e569,DISK], DatanodeInfoWithStorage[127.0.0.1:34117,DS-5e0e6d67-daec-479e-99fd-318f9ba93a65,DISK], DatanodeInfoWithStorage[127.0.0.1:41286,DS-dff1f55d-7291-4001-8cf4-d2231905b2b8,DISK], DatanodeInfoWithStorage[127.0.0.1:42058,DS-fd3aaa6b-b01d-47d1-a56f-fd002280c370,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1061017798-172.17.0.7-1598353110885:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34604,DS-40865b57-0788-4db3-b315-4b044a8c1c86,DISK], DatanodeInfoWithStorage[127.0.0.1:38738,DS-4393d1ea-6ad1-480e-9a23-ff8ba8580320,DISK], DatanodeInfoWithStorage[127.0.0.1:43858,DS-0515075c-1c56-44de-b460-78b2ccf7db6e,DISK], DatanodeInfoWithStorage[127.0.0.1:44087,DS-6d5b9750-86b0-4fc6-aa30-b8eb43af572d,DISK], DatanodeInfoWithStorage[127.0.0.1:45340,DS-0ca6d90d-c25e-4a22-9920-734c1119e569,DISK], DatanodeInfoWithStorage[127.0.0.1:34117,DS-5e0e6d67-daec-479e-99fd-318f9ba93a65,DISK], DatanodeInfoWithStorage[127.0.0.1:41286,DS-dff1f55d-7291-4001-8cf4-d2231905b2b8,DISK], DatanodeInfoWithStorage[127.0.0.1:42058,DS-fd3aaa6b-b01d-47d1-a56f-fd002280c370,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.ha.standby.checkpoints
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1367113957-172.17.0.7-1598353510183:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42955,DS-cbbc2b43-e8de-48ba-8791-264ecca40e2a,DISK], DatanodeInfoWithStorage[127.0.0.1:33876,DS-59771025-241b-4e7b-82d4-43c50009a934,DISK], DatanodeInfoWithStorage[127.0.0.1:42547,DS-863c3144-10e3-4002-8206-bacafdea0a6a,DISK], DatanodeInfoWithStorage[127.0.0.1:39172,DS-6df79268-04ab-4b90-b122-d75669625331,DISK], DatanodeInfoWithStorage[127.0.0.1:45418,DS-2f844751-7298-4d49-923b-5b9759cd6bcd,DISK], DatanodeInfoWithStorage[127.0.0.1:34431,DS-90b5013b-bf6f-4b6a-98d6-ee57b59f7cad,DISK], DatanodeInfoWithStorage[127.0.0.1:35858,DS-2702daf8-8428-4d5f-b0e2-407b48e49d7d,DISK], DatanodeInfoWithStorage[127.0.0.1:44715,DS-4daba0d7-0a2f-4b9c-aeaf-10370aae9d2a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1367113957-172.17.0.7-1598353510183:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42955,DS-cbbc2b43-e8de-48ba-8791-264ecca40e2a,DISK], DatanodeInfoWithStorage[127.0.0.1:33876,DS-59771025-241b-4e7b-82d4-43c50009a934,DISK], DatanodeInfoWithStorage[127.0.0.1:42547,DS-863c3144-10e3-4002-8206-bacafdea0a6a,DISK], DatanodeInfoWithStorage[127.0.0.1:39172,DS-6df79268-04ab-4b90-b122-d75669625331,DISK], DatanodeInfoWithStorage[127.0.0.1:45418,DS-2f844751-7298-4d49-923b-5b9759cd6bcd,DISK], DatanodeInfoWithStorage[127.0.0.1:34431,DS-90b5013b-bf6f-4b6a-98d6-ee57b59f7cad,DISK], DatanodeInfoWithStorage[127.0.0.1:35858,DS-2702daf8-8428-4d5f-b0e2-407b48e49d7d,DISK], DatanodeInfoWithStorage[127.0.0.1:44715,DS-4daba0d7-0a2f-4b9c-aeaf-10370aae9d2a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.ha.standby.checkpoints
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-974090229-172.17.0.7-1598353739355:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43631,DS-2f615cf5-24bc-4637-a3a5-09f0be784d06,DISK], DatanodeInfoWithStorage[127.0.0.1:41571,DS-c529e5e4-8870-4a8c-9181-eeef9d279669,DISK], DatanodeInfoWithStorage[127.0.0.1:34778,DS-1c29d8c9-1f88-477b-b034-9400646a0c5f,DISK], DatanodeInfoWithStorage[127.0.0.1:42182,DS-1a040158-8bd2-496c-92aa-74de573946f8,DISK], DatanodeInfoWithStorage[127.0.0.1:44933,DS-728f1cea-7129-496c-9e65-477218d2f6d1,DISK], DatanodeInfoWithStorage[127.0.0.1:35398,DS-c031716e-91d2-4a5f-82d4-3b0b0f509cea,DISK], DatanodeInfoWithStorage[127.0.0.1:44231,DS-7b37872b-2392-41c4-a9bb-2b2cc0a6c228,DISK], DatanodeInfoWithStorage[127.0.0.1:39276,DS-b5344bf8-90e9-468b-a08a-a93b41f402f5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-974090229-172.17.0.7-1598353739355:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43631,DS-2f615cf5-24bc-4637-a3a5-09f0be784d06,DISK], DatanodeInfoWithStorage[127.0.0.1:41571,DS-c529e5e4-8870-4a8c-9181-eeef9d279669,DISK], DatanodeInfoWithStorage[127.0.0.1:34778,DS-1c29d8c9-1f88-477b-b034-9400646a0c5f,DISK], DatanodeInfoWithStorage[127.0.0.1:42182,DS-1a040158-8bd2-496c-92aa-74de573946f8,DISK], DatanodeInfoWithStorage[127.0.0.1:44933,DS-728f1cea-7129-496c-9e65-477218d2f6d1,DISK], DatanodeInfoWithStorage[127.0.0.1:35398,DS-c031716e-91d2-4a5f-82d4-3b0b0f509cea,DISK], DatanodeInfoWithStorage[127.0.0.1:44231,DS-7b37872b-2392-41c4-a9bb-2b2cc0a6c228,DISK], DatanodeInfoWithStorage[127.0.0.1:39276,DS-b5344bf8-90e9-468b-a08a-a93b41f402f5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.ha.standby.checkpoints
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-621752052-172.17.0.7-1598353878537:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34576,DS-775a2695-384c-40f6-a64d-c3df4a974caf,DISK], DatanodeInfoWithStorage[127.0.0.1:37460,DS-3e0fe427-6df3-48ab-8f06-bc2b0d35a69d,DISK], DatanodeInfoWithStorage[127.0.0.1:33645,DS-57b75c41-d250-422a-af7f-09ea7954972c,DISK], DatanodeInfoWithStorage[127.0.0.1:36862,DS-e6b144dc-c120-4330-b5ce-87f09ffaa5b8,DISK], DatanodeInfoWithStorage[127.0.0.1:43610,DS-1f5865ba-7a90-42af-b12d-19d18e3ed505,DISK], DatanodeInfoWithStorage[127.0.0.1:35490,DS-23ec9748-0236-412e-961e-a369dbf80f64,DISK], DatanodeInfoWithStorage[127.0.0.1:45034,DS-33021a63-4745-4446-8940-f9c3dcbfd48c,DISK], DatanodeInfoWithStorage[127.0.0.1:35472,DS-0e4198d2-e946-4047-a9ee-d3d88648eb73,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-621752052-172.17.0.7-1598353878537:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34576,DS-775a2695-384c-40f6-a64d-c3df4a974caf,DISK], DatanodeInfoWithStorage[127.0.0.1:37460,DS-3e0fe427-6df3-48ab-8f06-bc2b0d35a69d,DISK], DatanodeInfoWithStorage[127.0.0.1:33645,DS-57b75c41-d250-422a-af7f-09ea7954972c,DISK], DatanodeInfoWithStorage[127.0.0.1:36862,DS-e6b144dc-c120-4330-b5ce-87f09ffaa5b8,DISK], DatanodeInfoWithStorage[127.0.0.1:43610,DS-1f5865ba-7a90-42af-b12d-19d18e3ed505,DISK], DatanodeInfoWithStorage[127.0.0.1:35490,DS-23ec9748-0236-412e-961e-a369dbf80f64,DISK], DatanodeInfoWithStorage[127.0.0.1:45034,DS-33021a63-4745-4446-8940-f9c3dcbfd48c,DISK], DatanodeInfoWithStorage[127.0.0.1:35472,DS-0e4198d2-e946-4047-a9ee-d3d88648eb73,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.ha.standby.checkpoints
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1314061466-172.17.0.7-1598353916296:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45787,DS-edf85d1a-f876-431d-b2f9-3441a6892f7e,DISK], DatanodeInfoWithStorage[127.0.0.1:35776,DS-4fcab36f-4724-4235-975c-476d6407dc65,DISK], DatanodeInfoWithStorage[127.0.0.1:39146,DS-296616fb-fabf-4a23-b200-510851a5d3b5,DISK], DatanodeInfoWithStorage[127.0.0.1:46819,DS-7a825503-3ea7-4766-b3b7-d6208f4f961d,DISK], DatanodeInfoWithStorage[127.0.0.1:43631,DS-f2c92bd0-b8fb-40aa-a1ad-f35463a338c5,DISK], DatanodeInfoWithStorage[127.0.0.1:33615,DS-54014350-d891-4732-a3f3-56ba70d85766,DISK], DatanodeInfoWithStorage[127.0.0.1:34066,DS-0873ee75-9969-42d6-b1ad-c93c0803aa70,DISK], DatanodeInfoWithStorage[127.0.0.1:42946,DS-ec953110-b037-44e7-ab0a-089f4d011dfb,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1314061466-172.17.0.7-1598353916296:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45787,DS-edf85d1a-f876-431d-b2f9-3441a6892f7e,DISK], DatanodeInfoWithStorage[127.0.0.1:35776,DS-4fcab36f-4724-4235-975c-476d6407dc65,DISK], DatanodeInfoWithStorage[127.0.0.1:39146,DS-296616fb-fabf-4a23-b200-510851a5d3b5,DISK], DatanodeInfoWithStorage[127.0.0.1:46819,DS-7a825503-3ea7-4766-b3b7-d6208f4f961d,DISK], DatanodeInfoWithStorage[127.0.0.1:43631,DS-f2c92bd0-b8fb-40aa-a1ad-f35463a338c5,DISK], DatanodeInfoWithStorage[127.0.0.1:33615,DS-54014350-d891-4732-a3f3-56ba70d85766,DISK], DatanodeInfoWithStorage[127.0.0.1:34066,DS-0873ee75-9969-42d6-b1ad-c93c0803aa70,DISK], DatanodeInfoWithStorage[127.0.0.1:42946,DS-ec953110-b037-44e7-ab0a-089f4d011dfb,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.ha.standby.checkpoints
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-934542759-172.17.0.7-1598354032996:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35150,DS-6aa58bbe-8f41-4557-b433-f73134af57ba,DISK], DatanodeInfoWithStorage[127.0.0.1:44745,DS-ce06d3f9-321f-4317-973f-5b799e8f15aa,DISK], DatanodeInfoWithStorage[127.0.0.1:41170,DS-acd103a0-346c-4dee-baf9-1fbef14076c2,DISK], DatanodeInfoWithStorage[127.0.0.1:43759,DS-4ece39ba-ecd6-45f3-96cd-7308ab558c75,DISK], DatanodeInfoWithStorage[127.0.0.1:43417,DS-b067bfe3-071a-4e83-ad86-de5e41f664af,DISK], DatanodeInfoWithStorage[127.0.0.1:37952,DS-666cbe86-78fd-4328-810b-188366deb4aa,DISK], DatanodeInfoWithStorage[127.0.0.1:44153,DS-8dd21441-3cd4-40f2-9d73-dc109c815411,DISK], DatanodeInfoWithStorage[127.0.0.1:36980,DS-04e11489-8b2f-4c89-9f0e-03c685f91e97,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-934542759-172.17.0.7-1598354032996:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35150,DS-6aa58bbe-8f41-4557-b433-f73134af57ba,DISK], DatanodeInfoWithStorage[127.0.0.1:44745,DS-ce06d3f9-321f-4317-973f-5b799e8f15aa,DISK], DatanodeInfoWithStorage[127.0.0.1:41170,DS-acd103a0-346c-4dee-baf9-1fbef14076c2,DISK], DatanodeInfoWithStorage[127.0.0.1:43759,DS-4ece39ba-ecd6-45f3-96cd-7308ab558c75,DISK], DatanodeInfoWithStorage[127.0.0.1:43417,DS-b067bfe3-071a-4e83-ad86-de5e41f664af,DISK], DatanodeInfoWithStorage[127.0.0.1:37952,DS-666cbe86-78fd-4328-810b-188366deb4aa,DISK], DatanodeInfoWithStorage[127.0.0.1:44153,DS-8dd21441-3cd4-40f2-9d73-dc109c815411,DISK], DatanodeInfoWithStorage[127.0.0.1:36980,DS-04e11489-8b2f-4c89-9f0e-03c685f91e97,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.ha.standby.checkpoints
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1988979855-172.17.0.7-1598354070946:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37857,DS-4b948425-96ff-4903-adee-7b1d3dda1ffe,DISK], DatanodeInfoWithStorage[127.0.0.1:44388,DS-74204c8e-8c0c-41aa-b76a-685bace2dc10,DISK], DatanodeInfoWithStorage[127.0.0.1:39566,DS-05683fd7-91a7-42e9-ade8-00ae4a92dcb9,DISK], DatanodeInfoWithStorage[127.0.0.1:39123,DS-5f90d150-21b5-4d98-93ab-bed23ccee0a0,DISK], DatanodeInfoWithStorage[127.0.0.1:41495,DS-4e1c5976-024b-4a87-a031-b36d3220f5ea,DISK], DatanodeInfoWithStorage[127.0.0.1:44803,DS-68c7bbb7-7bad-46ec-bea3-b1e82cefc959,DISK], DatanodeInfoWithStorage[127.0.0.1:42658,DS-a4e8bc64-c267-4ee5-ae9b-719741de9754,DISK], DatanodeInfoWithStorage[127.0.0.1:34000,DS-bc7c9f5c-66f4-4d1c-bbfd-e59137f77e5c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1988979855-172.17.0.7-1598354070946:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37857,DS-4b948425-96ff-4903-adee-7b1d3dda1ffe,DISK], DatanodeInfoWithStorage[127.0.0.1:44388,DS-74204c8e-8c0c-41aa-b76a-685bace2dc10,DISK], DatanodeInfoWithStorage[127.0.0.1:39566,DS-05683fd7-91a7-42e9-ade8-00ae4a92dcb9,DISK], DatanodeInfoWithStorage[127.0.0.1:39123,DS-5f90d150-21b5-4d98-93ab-bed23ccee0a0,DISK], DatanodeInfoWithStorage[127.0.0.1:41495,DS-4e1c5976-024b-4a87-a031-b36d3220f5ea,DISK], DatanodeInfoWithStorage[127.0.0.1:44803,DS-68c7bbb7-7bad-46ec-bea3-b1e82cefc959,DISK], DatanodeInfoWithStorage[127.0.0.1:42658,DS-a4e8bc64-c267-4ee5-ae9b-719741de9754,DISK], DatanodeInfoWithStorage[127.0.0.1:34000,DS-bc7c9f5c-66f4-4d1c-bbfd-e59137f77e5c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.ha.standby.checkpoints
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1943196287-172.17.0.7-1598354114475:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40279,DS-1bc3fe84-2b0b-4c29-8d6c-78441fd31aa9,DISK], DatanodeInfoWithStorage[127.0.0.1:43890,DS-2726e734-e483-4700-b745-3a353eabe26e,DISK], DatanodeInfoWithStorage[127.0.0.1:35061,DS-beee88b6-a1dd-4c15-bc8f-b4809745f143,DISK], DatanodeInfoWithStorage[127.0.0.1:41241,DS-314c2daf-79ad-4fc7-93a1-401a97703f5a,DISK], DatanodeInfoWithStorage[127.0.0.1:46014,DS-d151bdca-ced4-4c6d-abbe-77f7a2a3f526,DISK], DatanodeInfoWithStorage[127.0.0.1:41833,DS-b28e0aca-36eb-41a6-b780-fa60dc990003,DISK], DatanodeInfoWithStorage[127.0.0.1:36341,DS-237c4731-1c55-44c3-9013-fadc27f82c17,DISK], DatanodeInfoWithStorage[127.0.0.1:45332,DS-f78c6fb3-9128-4608-bb16-038f6c12ba73,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1943196287-172.17.0.7-1598354114475:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40279,DS-1bc3fe84-2b0b-4c29-8d6c-78441fd31aa9,DISK], DatanodeInfoWithStorage[127.0.0.1:43890,DS-2726e734-e483-4700-b745-3a353eabe26e,DISK], DatanodeInfoWithStorage[127.0.0.1:35061,DS-beee88b6-a1dd-4c15-bc8f-b4809745f143,DISK], DatanodeInfoWithStorage[127.0.0.1:41241,DS-314c2daf-79ad-4fc7-93a1-401a97703f5a,DISK], DatanodeInfoWithStorage[127.0.0.1:46014,DS-d151bdca-ced4-4c6d-abbe-77f7a2a3f526,DISK], DatanodeInfoWithStorage[127.0.0.1:41833,DS-b28e0aca-36eb-41a6-b780-fa60dc990003,DISK], DatanodeInfoWithStorage[127.0.0.1:36341,DS-237c4731-1c55-44c3-9013-fadc27f82c17,DISK], DatanodeInfoWithStorage[127.0.0.1:45332,DS-f78c6fb3-9128-4608-bb16-038f6c12ba73,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.ha.standby.checkpoints
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1349394865-172.17.0.7-1598354144512:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33737,DS-435a20f3-c37d-4267-b1fc-dbcf58f4896a,DISK], DatanodeInfoWithStorage[127.0.0.1:36852,DS-95eac2c1-fc41-4d17-8501-781c0802f3e6,DISK], DatanodeInfoWithStorage[127.0.0.1:37737,DS-526a387b-4474-401e-aad9-6e5538e79ac6,DISK], DatanodeInfoWithStorage[127.0.0.1:46652,DS-9bd654a6-06da-4b84-8bd5-66e01cac5c3a,DISK], DatanodeInfoWithStorage[127.0.0.1:41588,DS-244ae90c-ea01-4c3b-b338-ac4b0ddbd2ae,DISK], DatanodeInfoWithStorage[127.0.0.1:35195,DS-a7d09753-0c24-44fe-a127-4d9965a9103e,DISK], DatanodeInfoWithStorage[127.0.0.1:34284,DS-1b263d8c-c2d0-4362-9312-49feeaae6f88,DISK], DatanodeInfoWithStorage[127.0.0.1:46463,DS-998cc945-fd4d-4df9-9d94-3de42aa4a88d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1349394865-172.17.0.7-1598354144512:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33737,DS-435a20f3-c37d-4267-b1fc-dbcf58f4896a,DISK], DatanodeInfoWithStorage[127.0.0.1:36852,DS-95eac2c1-fc41-4d17-8501-781c0802f3e6,DISK], DatanodeInfoWithStorage[127.0.0.1:37737,DS-526a387b-4474-401e-aad9-6e5538e79ac6,DISK], DatanodeInfoWithStorage[127.0.0.1:46652,DS-9bd654a6-06da-4b84-8bd5-66e01cac5c3a,DISK], DatanodeInfoWithStorage[127.0.0.1:41588,DS-244ae90c-ea01-4c3b-b338-ac4b0ddbd2ae,DISK], DatanodeInfoWithStorage[127.0.0.1:35195,DS-a7d09753-0c24-44fe-a127-4d9965a9103e,DISK], DatanodeInfoWithStorage[127.0.0.1:34284,DS-1b263d8c-c2d0-4362-9312-49feeaae6f88,DISK], DatanodeInfoWithStorage[127.0.0.1:46463,DS-998cc945-fd4d-4df9-9d94-3de42aa4a88d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.ha.standby.checkpoints
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1012372236-172.17.0.7-1598354180777:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45085,DS-b8f8834f-70fb-48d2-a7a0-f02788cb89e8,DISK], DatanodeInfoWithStorage[127.0.0.1:44244,DS-aed48c59-d0d4-4b05-89a4-b9bbd131e27c,DISK], DatanodeInfoWithStorage[127.0.0.1:46048,DS-c653660d-53df-4209-8aae-bb7710b147c4,DISK], DatanodeInfoWithStorage[127.0.0.1:35155,DS-4f28affa-a0a7-4248-bc85-484bf2c50bbf,DISK], DatanodeInfoWithStorage[127.0.0.1:38906,DS-edd5103b-44a6-427c-9b35-5e70a972db9b,DISK], DatanodeInfoWithStorage[127.0.0.1:34367,DS-6cfaf8e8-9231-4dcc-9873-f95356a15b2b,DISK], DatanodeInfoWithStorage[127.0.0.1:39020,DS-3bd4c143-3f8d-4cf9-a94e-fedb22aba99e,DISK], DatanodeInfoWithStorage[127.0.0.1:35198,DS-f76a9ec2-65be-48c0-8f06-0f74a0afccf2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1012372236-172.17.0.7-1598354180777:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45085,DS-b8f8834f-70fb-48d2-a7a0-f02788cb89e8,DISK], DatanodeInfoWithStorage[127.0.0.1:44244,DS-aed48c59-d0d4-4b05-89a4-b9bbd131e27c,DISK], DatanodeInfoWithStorage[127.0.0.1:46048,DS-c653660d-53df-4209-8aae-bb7710b147c4,DISK], DatanodeInfoWithStorage[127.0.0.1:35155,DS-4f28affa-a0a7-4248-bc85-484bf2c50bbf,DISK], DatanodeInfoWithStorage[127.0.0.1:38906,DS-edd5103b-44a6-427c-9b35-5e70a972db9b,DISK], DatanodeInfoWithStorage[127.0.0.1:34367,DS-6cfaf8e8-9231-4dcc-9873-f95356a15b2b,DISK], DatanodeInfoWithStorage[127.0.0.1:39020,DS-3bd4c143-3f8d-4cf9-a94e-fedb22aba99e,DISK], DatanodeInfoWithStorage[127.0.0.1:35198,DS-f76a9ec2-65be-48c0-8f06-0f74a0afccf2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.ha.standby.checkpoints
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1888528057-172.17.0.7-1598354349988:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44811,DS-d5cb0a5c-c79d-481e-aac6-5addd58cc44c,DISK], DatanodeInfoWithStorage[127.0.0.1:40222,DS-5bacff2c-b6f9-45cf-94ba-8e79350a6ebf,DISK], DatanodeInfoWithStorage[127.0.0.1:33391,DS-5403ec30-3043-4a3e-9d85-9f621b270613,DISK], DatanodeInfoWithStorage[127.0.0.1:37021,DS-65a2519d-ff81-43e9-ba30-57a48574c84c,DISK], DatanodeInfoWithStorage[127.0.0.1:44526,DS-e9be7162-c1e4-423a-a272-4f58cd0d6c14,DISK], DatanodeInfoWithStorage[127.0.0.1:46307,DS-34a7721d-d485-4fb7-aa4a-49af9b0bd9e5,DISK], DatanodeInfoWithStorage[127.0.0.1:32881,DS-616f4d9a-4be0-4d24-9083-a7a392776ea7,DISK], DatanodeInfoWithStorage[127.0.0.1:41366,DS-f476503e-fb93-41fa-bbcc-23b3e963c987,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1888528057-172.17.0.7-1598354349988:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44811,DS-d5cb0a5c-c79d-481e-aac6-5addd58cc44c,DISK], DatanodeInfoWithStorage[127.0.0.1:40222,DS-5bacff2c-b6f9-45cf-94ba-8e79350a6ebf,DISK], DatanodeInfoWithStorage[127.0.0.1:33391,DS-5403ec30-3043-4a3e-9d85-9f621b270613,DISK], DatanodeInfoWithStorage[127.0.0.1:37021,DS-65a2519d-ff81-43e9-ba30-57a48574c84c,DISK], DatanodeInfoWithStorage[127.0.0.1:44526,DS-e9be7162-c1e4-423a-a272-4f58cd0d6c14,DISK], DatanodeInfoWithStorage[127.0.0.1:46307,DS-34a7721d-d485-4fb7-aa4a-49af9b0bd9e5,DISK], DatanodeInfoWithStorage[127.0.0.1:32881,DS-616f4d9a-4be0-4d24-9083-a7a392776ea7,DISK], DatanodeInfoWithStorage[127.0.0.1:41366,DS-f476503e-fb93-41fa-bbcc-23b3e963c987,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.ha.standby.checkpoints
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1004008963-172.17.0.7-1598354387023:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46824,DS-b1a48b84-af1a-4ab5-8398-55b712f5acbd,DISK], DatanodeInfoWithStorage[127.0.0.1:35540,DS-cf1d74ef-8176-4593-8ede-b19a00a31947,DISK], DatanodeInfoWithStorage[127.0.0.1:33640,DS-591c70be-f828-4320-96b3-ff3e9725b6da,DISK], DatanodeInfoWithStorage[127.0.0.1:46277,DS-4dda5e16-52b6-44ae-b7e6-1d57dea312f7,DISK], DatanodeInfoWithStorage[127.0.0.1:44145,DS-237d5f3e-6411-48c2-ba55-7a0fd6a7569c,DISK], DatanodeInfoWithStorage[127.0.0.1:36002,DS-fa826449-045c-409d-9f43-d7dbec52d9b7,DISK], DatanodeInfoWithStorage[127.0.0.1:40223,DS-c9de039c-4111-4346-a1e7-6b8179658041,DISK], DatanodeInfoWithStorage[127.0.0.1:40025,DS-221f7caa-795d-4c6b-a0bc-d2078b1531db,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1004008963-172.17.0.7-1598354387023:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46824,DS-b1a48b84-af1a-4ab5-8398-55b712f5acbd,DISK], DatanodeInfoWithStorage[127.0.0.1:35540,DS-cf1d74ef-8176-4593-8ede-b19a00a31947,DISK], DatanodeInfoWithStorage[127.0.0.1:33640,DS-591c70be-f828-4320-96b3-ff3e9725b6da,DISK], DatanodeInfoWithStorage[127.0.0.1:46277,DS-4dda5e16-52b6-44ae-b7e6-1d57dea312f7,DISK], DatanodeInfoWithStorage[127.0.0.1:44145,DS-237d5f3e-6411-48c2-ba55-7a0fd6a7569c,DISK], DatanodeInfoWithStorage[127.0.0.1:36002,DS-fa826449-045c-409d-9f43-d7dbec52d9b7,DISK], DatanodeInfoWithStorage[127.0.0.1:40223,DS-c9de039c-4111-4346-a1e7-6b8179658041,DISK], DatanodeInfoWithStorage[127.0.0.1:40025,DS-221f7caa-795d-4c6b-a0bc-d2078b1531db,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.ha.standby.checkpoints
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-232741186-172.17.0.7-1598354427422:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43744,DS-b836934e-bfdb-4ae1-83db-2e36b7109568,DISK], DatanodeInfoWithStorage[127.0.0.1:46670,DS-11aa0f0d-a1e0-4da0-adab-e9f6945aa96f,DISK], DatanodeInfoWithStorage[127.0.0.1:42276,DS-dc8a6442-3bb8-41df-ae0a-e704e2801960,DISK], DatanodeInfoWithStorage[127.0.0.1:46286,DS-6d6943ed-9c67-454e-a8ba-89cad16685e5,DISK], DatanodeInfoWithStorage[127.0.0.1:42314,DS-97137c5f-0af5-4e6c-8cee-d658940b1feb,DISK], DatanodeInfoWithStorage[127.0.0.1:40436,DS-71179853-12ae-49eb-9135-b82717f6e9e3,DISK], DatanodeInfoWithStorage[127.0.0.1:46130,DS-d145bf46-798a-48c0-871c-a5b278797131,DISK], DatanodeInfoWithStorage[127.0.0.1:43047,DS-ffac11bb-67a5-4af7-80ff-6336fc7989dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-232741186-172.17.0.7-1598354427422:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43744,DS-b836934e-bfdb-4ae1-83db-2e36b7109568,DISK], DatanodeInfoWithStorage[127.0.0.1:46670,DS-11aa0f0d-a1e0-4da0-adab-e9f6945aa96f,DISK], DatanodeInfoWithStorage[127.0.0.1:42276,DS-dc8a6442-3bb8-41df-ae0a-e704e2801960,DISK], DatanodeInfoWithStorage[127.0.0.1:46286,DS-6d6943ed-9c67-454e-a8ba-89cad16685e5,DISK], DatanodeInfoWithStorage[127.0.0.1:42314,DS-97137c5f-0af5-4e6c-8cee-d658940b1feb,DISK], DatanodeInfoWithStorage[127.0.0.1:40436,DS-71179853-12ae-49eb-9135-b82717f6e9e3,DISK], DatanodeInfoWithStorage[127.0.0.1:46130,DS-d145bf46-798a-48c0-871c-a5b278797131,DISK], DatanodeInfoWithStorage[127.0.0.1:43047,DS-ffac11bb-67a5-4af7-80ff-6336fc7989dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.ha.standby.checkpoints
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-90378168-172.17.0.7-1598354572598:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34250,DS-e4eefba0-b900-4f2e-80e0-08036d2551bd,DISK], DatanodeInfoWithStorage[127.0.0.1:43588,DS-ee03601c-fc78-40cc-b1b0-80ad4e92567b,DISK], DatanodeInfoWithStorage[127.0.0.1:35469,DS-428c3dfd-01af-4cca-acc2-d24470a187cf,DISK], DatanodeInfoWithStorage[127.0.0.1:46278,DS-9e9dd292-e504-4886-996b-c01c2bb6a721,DISK], DatanodeInfoWithStorage[127.0.0.1:45103,DS-0e853752-8cca-42e1-9acc-49747658c5ce,DISK], DatanodeInfoWithStorage[127.0.0.1:34258,DS-277e5587-31f9-40ca-a621-de3e66a1dff0,DISK], DatanodeInfoWithStorage[127.0.0.1:38153,DS-8366342e-2099-4c63-9b4e-1683b5be405d,DISK], DatanodeInfoWithStorage[127.0.0.1:44837,DS-ca4a5949-407e-4db0-99c0-7cd13ba9ef84,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-90378168-172.17.0.7-1598354572598:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34250,DS-e4eefba0-b900-4f2e-80e0-08036d2551bd,DISK], DatanodeInfoWithStorage[127.0.0.1:43588,DS-ee03601c-fc78-40cc-b1b0-80ad4e92567b,DISK], DatanodeInfoWithStorage[127.0.0.1:35469,DS-428c3dfd-01af-4cca-acc2-d24470a187cf,DISK], DatanodeInfoWithStorage[127.0.0.1:46278,DS-9e9dd292-e504-4886-996b-c01c2bb6a721,DISK], DatanodeInfoWithStorage[127.0.0.1:45103,DS-0e853752-8cca-42e1-9acc-49747658c5ce,DISK], DatanodeInfoWithStorage[127.0.0.1:34258,DS-277e5587-31f9-40ca-a621-de3e66a1dff0,DISK], DatanodeInfoWithStorage[127.0.0.1:38153,DS-8366342e-2099-4c63-9b4e-1683b5be405d,DISK], DatanodeInfoWithStorage[127.0.0.1:44837,DS-ca4a5949-407e-4db0-99c0-7cd13ba9ef84,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.ha.standby.checkpoints
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1962441566-172.17.0.7-1598354646522:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39308,DS-883e310e-28d8-4957-8b22-6a1dd8c31894,DISK], DatanodeInfoWithStorage[127.0.0.1:41814,DS-e1229c56-ee79-40db-a61f-0f157f7ea782,DISK], DatanodeInfoWithStorage[127.0.0.1:39548,DS-e7d45f1d-a8c6-4453-b6e7-8d583ff10114,DISK], DatanodeInfoWithStorage[127.0.0.1:36267,DS-74a273af-a8c1-4973-85a3-c04cc529ffda,DISK], DatanodeInfoWithStorage[127.0.0.1:37981,DS-8cde53fd-956d-4083-b905-80dcc1f642e0,DISK], DatanodeInfoWithStorage[127.0.0.1:46172,DS-29b119b9-080d-4602-a356-540e3bafaff9,DISK], DatanodeInfoWithStorage[127.0.0.1:45573,DS-524a202d-7c56-4a6c-a08c-0e918203ff85,DISK], DatanodeInfoWithStorage[127.0.0.1:33338,DS-1fb4030c-4878-414d-9934-4b40282388ee,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1962441566-172.17.0.7-1598354646522:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39308,DS-883e310e-28d8-4957-8b22-6a1dd8c31894,DISK], DatanodeInfoWithStorage[127.0.0.1:41814,DS-e1229c56-ee79-40db-a61f-0f157f7ea782,DISK], DatanodeInfoWithStorage[127.0.0.1:39548,DS-e7d45f1d-a8c6-4453-b6e7-8d583ff10114,DISK], DatanodeInfoWithStorage[127.0.0.1:36267,DS-74a273af-a8c1-4973-85a3-c04cc529ffda,DISK], DatanodeInfoWithStorage[127.0.0.1:37981,DS-8cde53fd-956d-4083-b905-80dcc1f642e0,DISK], DatanodeInfoWithStorage[127.0.0.1:46172,DS-29b119b9-080d-4602-a356-540e3bafaff9,DISK], DatanodeInfoWithStorage[127.0.0.1:45573,DS-524a202d-7c56-4a6c-a08c-0e918203ff85,DISK], DatanodeInfoWithStorage[127.0.0.1:33338,DS-1fb4030c-4878-414d-9934-4b40282388ee,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.ha.standby.checkpoints
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1932149951-172.17.0.7-1598354754637:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43948,DS-6c508e51-9b2f-4842-91de-a5dcf8525416,DISK], DatanodeInfoWithStorage[127.0.0.1:40935,DS-1fd9d33d-85a3-4b18-88ef-56ee1aa556e3,DISK], DatanodeInfoWithStorage[127.0.0.1:40109,DS-7c1cd2f7-4bd5-435a-864a-4af64781a12a,DISK], DatanodeInfoWithStorage[127.0.0.1:37727,DS-2dd7f60e-5066-40fe-b45b-920e6e23aa09,DISK], DatanodeInfoWithStorage[127.0.0.1:32903,DS-604c231e-ddca-45a5-b8dd-91b93ffdf7b3,DISK], DatanodeInfoWithStorage[127.0.0.1:39820,DS-9962008a-8b4f-431b-bc59-5b578ae63883,DISK], DatanodeInfoWithStorage[127.0.0.1:38908,DS-0773ac81-5f21-405e-8c18-3e5296c9c0dc,DISK], DatanodeInfoWithStorage[127.0.0.1:46024,DS-02131d0a-8b0f-4d44-9d09-79e3e5467709,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1932149951-172.17.0.7-1598354754637:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43948,DS-6c508e51-9b2f-4842-91de-a5dcf8525416,DISK], DatanodeInfoWithStorage[127.0.0.1:40935,DS-1fd9d33d-85a3-4b18-88ef-56ee1aa556e3,DISK], DatanodeInfoWithStorage[127.0.0.1:40109,DS-7c1cd2f7-4bd5-435a-864a-4af64781a12a,DISK], DatanodeInfoWithStorage[127.0.0.1:37727,DS-2dd7f60e-5066-40fe-b45b-920e6e23aa09,DISK], DatanodeInfoWithStorage[127.0.0.1:32903,DS-604c231e-ddca-45a5-b8dd-91b93ffdf7b3,DISK], DatanodeInfoWithStorage[127.0.0.1:39820,DS-9962008a-8b4f-431b-bc59-5b578ae63883,DISK], DatanodeInfoWithStorage[127.0.0.1:38908,DS-0773ac81-5f21-405e-8c18-3e5296c9c0dc,DISK], DatanodeInfoWithStorage[127.0.0.1:46024,DS-02131d0a-8b0f-4d44-9d09-79e3e5467709,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.ha.standby.checkpoints
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-907608987-172.17.0.7-1598354857679:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34044,DS-4d4e1c8a-d696-4530-8679-b366a8459ce1,DISK], DatanodeInfoWithStorage[127.0.0.1:35221,DS-46036399-e34e-42bc-a32c-44528fa2b6b7,DISK], DatanodeInfoWithStorage[127.0.0.1:46845,DS-b58ae484-0cf7-4550-935c-90481ca9042f,DISK], DatanodeInfoWithStorage[127.0.0.1:41697,DS-fefd8f3a-cf04-4d64-a37f-255f779532c6,DISK], DatanodeInfoWithStorage[127.0.0.1:35446,DS-2795e229-3b91-4df6-8f7c-23316ed2d90a,DISK], DatanodeInfoWithStorage[127.0.0.1:43385,DS-d6fcd3f4-6516-453f-9e00-2642fab94707,DISK], DatanodeInfoWithStorage[127.0.0.1:43023,DS-65f9c3af-0d64-445f-8107-a3543ba3ddf3,DISK], DatanodeInfoWithStorage[127.0.0.1:46692,DS-665efdd0-ed68-4b08-beea-36fb727f4149,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-907608987-172.17.0.7-1598354857679:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34044,DS-4d4e1c8a-d696-4530-8679-b366a8459ce1,DISK], DatanodeInfoWithStorage[127.0.0.1:35221,DS-46036399-e34e-42bc-a32c-44528fa2b6b7,DISK], DatanodeInfoWithStorage[127.0.0.1:46845,DS-b58ae484-0cf7-4550-935c-90481ca9042f,DISK], DatanodeInfoWithStorage[127.0.0.1:41697,DS-fefd8f3a-cf04-4d64-a37f-255f779532c6,DISK], DatanodeInfoWithStorage[127.0.0.1:35446,DS-2795e229-3b91-4df6-8f7c-23316ed2d90a,DISK], DatanodeInfoWithStorage[127.0.0.1:43385,DS-d6fcd3f4-6516-453f-9e00-2642fab94707,DISK], DatanodeInfoWithStorage[127.0.0.1:43023,DS-65f9c3af-0d64-445f-8107-a3543ba3ddf3,DISK], DatanodeInfoWithStorage[127.0.0.1:46692,DS-665efdd0-ed68-4b08-beea-36fb727f4149,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.ha.standby.checkpoints
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-255557602-172.17.0.7-1598354889684:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46144,DS-3e3b0ca4-6a36-4111-be52-aebd8f0dc917,DISK], DatanodeInfoWithStorage[127.0.0.1:35012,DS-2bbda63a-d348-4a92-a0f0-f82f38078098,DISK], DatanodeInfoWithStorage[127.0.0.1:42325,DS-688f46f5-2a17-4715-84de-4bd77af08280,DISK], DatanodeInfoWithStorage[127.0.0.1:43899,DS-7bc02c5a-23dd-42f6-9d30-0f370761d46a,DISK], DatanodeInfoWithStorage[127.0.0.1:38732,DS-c5de9f16-00e3-49e7-b381-92873f7822a2,DISK], DatanodeInfoWithStorage[127.0.0.1:44657,DS-9f5c2d56-2847-4590-8b7d-1e76d885a562,DISK], DatanodeInfoWithStorage[127.0.0.1:46287,DS-71f3493a-2fbe-48ad-902d-412306b2cbb5,DISK], DatanodeInfoWithStorage[127.0.0.1:36782,DS-a53865d3-d3e2-45dc-ba30-0cda084f0447,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-255557602-172.17.0.7-1598354889684:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46144,DS-3e3b0ca4-6a36-4111-be52-aebd8f0dc917,DISK], DatanodeInfoWithStorage[127.0.0.1:35012,DS-2bbda63a-d348-4a92-a0f0-f82f38078098,DISK], DatanodeInfoWithStorage[127.0.0.1:42325,DS-688f46f5-2a17-4715-84de-4bd77af08280,DISK], DatanodeInfoWithStorage[127.0.0.1:43899,DS-7bc02c5a-23dd-42f6-9d30-0f370761d46a,DISK], DatanodeInfoWithStorage[127.0.0.1:38732,DS-c5de9f16-00e3-49e7-b381-92873f7822a2,DISK], DatanodeInfoWithStorage[127.0.0.1:44657,DS-9f5c2d56-2847-4590-8b7d-1e76d885a562,DISK], DatanodeInfoWithStorage[127.0.0.1:46287,DS-71f3493a-2fbe-48ad-902d-412306b2cbb5,DISK], DatanodeInfoWithStorage[127.0.0.1:36782,DS-a53865d3-d3e2-45dc-ba30-0cda084f0447,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.ha.standby.checkpoints
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-688707904-172.17.0.7-1598355295140:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46077,DS-fd221440-2832-4a35-b039-eb7f64d0a60c,DISK], DatanodeInfoWithStorage[127.0.0.1:33039,DS-ca100fa8-7b7b-44e8-8b89-4a32563d872e,DISK], DatanodeInfoWithStorage[127.0.0.1:45248,DS-564f5275-279f-490e-a067-f74694d42110,DISK], DatanodeInfoWithStorage[127.0.0.1:34109,DS-9c7fafef-9d13-4e56-ab15-dd459c08dd50,DISK], DatanodeInfoWithStorage[127.0.0.1:37888,DS-0f462e33-de6a-4024-83a2-2e05d5d6b3fd,DISK], DatanodeInfoWithStorage[127.0.0.1:44778,DS-2869f14c-3c57-4c62-8d7b-a54bd9693038,DISK], DatanodeInfoWithStorage[127.0.0.1:33994,DS-d8315b35-9f64-4bfa-9d4b-c04d5ee4ce11,DISK], DatanodeInfoWithStorage[127.0.0.1:38248,DS-0a5905db-515c-4c1d-9252-426cdc9b3dba,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-688707904-172.17.0.7-1598355295140:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46077,DS-fd221440-2832-4a35-b039-eb7f64d0a60c,DISK], DatanodeInfoWithStorage[127.0.0.1:33039,DS-ca100fa8-7b7b-44e8-8b89-4a32563d872e,DISK], DatanodeInfoWithStorage[127.0.0.1:45248,DS-564f5275-279f-490e-a067-f74694d42110,DISK], DatanodeInfoWithStorage[127.0.0.1:34109,DS-9c7fafef-9d13-4e56-ab15-dd459c08dd50,DISK], DatanodeInfoWithStorage[127.0.0.1:37888,DS-0f462e33-de6a-4024-83a2-2e05d5d6b3fd,DISK], DatanodeInfoWithStorage[127.0.0.1:44778,DS-2869f14c-3c57-4c62-8d7b-a54bd9693038,DISK], DatanodeInfoWithStorage[127.0.0.1:33994,DS-d8315b35-9f64-4bfa-9d4b-c04d5ee4ce11,DISK], DatanodeInfoWithStorage[127.0.0.1:38248,DS-0a5905db-515c-4c1d-9252-426cdc9b3dba,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.ha.standby.checkpoints
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1315692286-172.17.0.7-1598355490458:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37262,DS-98c173ff-353c-46b9-a729-02e7f180b8ff,DISK], DatanodeInfoWithStorage[127.0.0.1:33512,DS-1b97aba4-eae0-4269-9db9-0b8e9a3a405d,DISK], DatanodeInfoWithStorage[127.0.0.1:44578,DS-518b6865-881f-4104-8d60-79b8ade784af,DISK], DatanodeInfoWithStorage[127.0.0.1:36899,DS-95ba70e9-efb8-4f94-a1a2-b259745fd5e7,DISK], DatanodeInfoWithStorage[127.0.0.1:44793,DS-df4a1aa2-1751-4684-b320-595b64754fcf,DISK], DatanodeInfoWithStorage[127.0.0.1:46220,DS-95c6bde9-88ba-4a71-97fc-3a8c79aeb7fb,DISK], DatanodeInfoWithStorage[127.0.0.1:38290,DS-ecbee5e9-11ac-438a-a874-31a0ff88d660,DISK], DatanodeInfoWithStorage[127.0.0.1:39302,DS-b2f28e81-25f5-4c10-90d1-e984ff83bfec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1315692286-172.17.0.7-1598355490458:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37262,DS-98c173ff-353c-46b9-a729-02e7f180b8ff,DISK], DatanodeInfoWithStorage[127.0.0.1:33512,DS-1b97aba4-eae0-4269-9db9-0b8e9a3a405d,DISK], DatanodeInfoWithStorage[127.0.0.1:44578,DS-518b6865-881f-4104-8d60-79b8ade784af,DISK], DatanodeInfoWithStorage[127.0.0.1:36899,DS-95ba70e9-efb8-4f94-a1a2-b259745fd5e7,DISK], DatanodeInfoWithStorage[127.0.0.1:44793,DS-df4a1aa2-1751-4684-b320-595b64754fcf,DISK], DatanodeInfoWithStorage[127.0.0.1:46220,DS-95c6bde9-88ba-4a71-97fc-3a8c79aeb7fb,DISK], DatanodeInfoWithStorage[127.0.0.1:38290,DS-ecbee5e9-11ac-438a-a874-31a0ff88d660,DISK], DatanodeInfoWithStorage[127.0.0.1:39302,DS-b2f28e81-25f5-4c10-90d1-e984ff83bfec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.ha.standby.checkpoints
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1874421740-172.17.0.7-1598355610145:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40610,DS-6b12965f-4c17-41fc-8c98-48ffa2531b2a,DISK], DatanodeInfoWithStorage[127.0.0.1:33756,DS-032d3b92-f904-41eb-a3e3-add9c2c278ad,DISK], DatanodeInfoWithStorage[127.0.0.1:42367,DS-aefaebaf-0ec3-48dc-a1eb-12b9aaf09e9a,DISK], DatanodeInfoWithStorage[127.0.0.1:40276,DS-437ee97e-2a0c-40ea-81c0-002bf1434dc5,DISK], DatanodeInfoWithStorage[127.0.0.1:45380,DS-e48ed03d-21fa-4807-bf32-03d7ea55eaae,DISK], DatanodeInfoWithStorage[127.0.0.1:45458,DS-05bb8291-a59e-4046-9d03-6f0b0388317e,DISK], DatanodeInfoWithStorage[127.0.0.1:34710,DS-91373c65-5a84-4c40-b9e3-5068efa5f17a,DISK], DatanodeInfoWithStorage[127.0.0.1:40265,DS-8f313a56-9ff7-43f9-952e-9777dfedcdfd,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1874421740-172.17.0.7-1598355610145:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40610,DS-6b12965f-4c17-41fc-8c98-48ffa2531b2a,DISK], DatanodeInfoWithStorage[127.0.0.1:33756,DS-032d3b92-f904-41eb-a3e3-add9c2c278ad,DISK], DatanodeInfoWithStorage[127.0.0.1:42367,DS-aefaebaf-0ec3-48dc-a1eb-12b9aaf09e9a,DISK], DatanodeInfoWithStorage[127.0.0.1:40276,DS-437ee97e-2a0c-40ea-81c0-002bf1434dc5,DISK], DatanodeInfoWithStorage[127.0.0.1:45380,DS-e48ed03d-21fa-4807-bf32-03d7ea55eaae,DISK], DatanodeInfoWithStorage[127.0.0.1:45458,DS-05bb8291-a59e-4046-9d03-6f0b0388317e,DISK], DatanodeInfoWithStorage[127.0.0.1:34710,DS-91373c65-5a84-4c40-b9e3-5068efa5f17a,DISK], DatanodeInfoWithStorage[127.0.0.1:40265,DS-8f313a56-9ff7-43f9-952e-9777dfedcdfd,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.ha.standby.checkpoints
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-100053787-172.17.0.7-1598355650183:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34073,DS-45b5c9fe-5b9e-49b8-9e6b-785f99678c0c,DISK], DatanodeInfoWithStorage[127.0.0.1:40608,DS-64dfe536-4edf-4d66-8918-7df3748c2483,DISK], DatanodeInfoWithStorage[127.0.0.1:36334,DS-c34521ae-2b75-498e-a215-ab428d30d82f,DISK], DatanodeInfoWithStorage[127.0.0.1:43986,DS-71b88ca8-a597-4293-bca7-85d833f40d76,DISK], DatanodeInfoWithStorage[127.0.0.1:32900,DS-aa20a43b-d2ea-4819-b46c-19b7c6c49c81,DISK], DatanodeInfoWithStorage[127.0.0.1:41202,DS-d5ff8950-1146-4cd1-88e9-aabd2c46a368,DISK], DatanodeInfoWithStorage[127.0.0.1:36183,DS-5c6ce394-f58f-421f-9392-4118c37a87d7,DISK], DatanodeInfoWithStorage[127.0.0.1:39115,DS-ed42d3fc-b8b3-4e81-9f46-2cf20aeb6448,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-100053787-172.17.0.7-1598355650183:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34073,DS-45b5c9fe-5b9e-49b8-9e6b-785f99678c0c,DISK], DatanodeInfoWithStorage[127.0.0.1:40608,DS-64dfe536-4edf-4d66-8918-7df3748c2483,DISK], DatanodeInfoWithStorage[127.0.0.1:36334,DS-c34521ae-2b75-498e-a215-ab428d30d82f,DISK], DatanodeInfoWithStorage[127.0.0.1:43986,DS-71b88ca8-a597-4293-bca7-85d833f40d76,DISK], DatanodeInfoWithStorage[127.0.0.1:32900,DS-aa20a43b-d2ea-4819-b46c-19b7c6c49c81,DISK], DatanodeInfoWithStorage[127.0.0.1:41202,DS-d5ff8950-1146-4cd1-88e9-aabd2c46a368,DISK], DatanodeInfoWithStorage[127.0.0.1:36183,DS-5c6ce394-f58f-421f-9392-4118c37a87d7,DISK], DatanodeInfoWithStorage[127.0.0.1:39115,DS-ed42d3fc-b8b3-4e81-9f46-2cf20aeb6448,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.ha.standby.checkpoints
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-307202982-172.17.0.7-1598355917090:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33180,DS-5b7f564f-c414-4d84-a3a1-557013bff7da,DISK], DatanodeInfoWithStorage[127.0.0.1:43022,DS-dd35f341-9496-40ef-b42f-87f2c54d69ec,DISK], DatanodeInfoWithStorage[127.0.0.1:35392,DS-1f3a99ed-fbdf-40ec-bf9e-265802915185,DISK], DatanodeInfoWithStorage[127.0.0.1:43556,DS-0580d095-f919-442b-bb43-f2dda085dbac,DISK], DatanodeInfoWithStorage[127.0.0.1:36344,DS-27657d34-9d9b-45b7-a9ca-07b93b802250,DISK], DatanodeInfoWithStorage[127.0.0.1:43994,DS-a723d575-1a01-41ff-92c2-62501d4b3a5f,DISK], DatanodeInfoWithStorage[127.0.0.1:45146,DS-36530402-c996-4d0c-939f-6f36eed9c727,DISK], DatanodeInfoWithStorage[127.0.0.1:41698,DS-20618e61-82bb-42f7-91bb-ccada83549ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-307202982-172.17.0.7-1598355917090:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33180,DS-5b7f564f-c414-4d84-a3a1-557013bff7da,DISK], DatanodeInfoWithStorage[127.0.0.1:43022,DS-dd35f341-9496-40ef-b42f-87f2c54d69ec,DISK], DatanodeInfoWithStorage[127.0.0.1:35392,DS-1f3a99ed-fbdf-40ec-bf9e-265802915185,DISK], DatanodeInfoWithStorage[127.0.0.1:43556,DS-0580d095-f919-442b-bb43-f2dda085dbac,DISK], DatanodeInfoWithStorage[127.0.0.1:36344,DS-27657d34-9d9b-45b7-a9ca-07b93b802250,DISK], DatanodeInfoWithStorage[127.0.0.1:43994,DS-a723d575-1a01-41ff-92c2-62501d4b3a5f,DISK], DatanodeInfoWithStorage[127.0.0.1:45146,DS-36530402-c996-4d0c-939f-6f36eed9c727,DISK], DatanodeInfoWithStorage[127.0.0.1:41698,DS-20618e61-82bb-42f7-91bb-ccada83549ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.ha.standby.checkpoints
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-949934285-172.17.0.7-1598355953944:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43446,DS-78172eae-5728-4727-8edb-a2f68aa86597,DISK], DatanodeInfoWithStorage[127.0.0.1:46400,DS-abf5a26c-afae-4d78-b241-aaae2a22e7c2,DISK], DatanodeInfoWithStorage[127.0.0.1:42417,DS-3899cca0-6938-4717-a437-908e0179a76a,DISK], DatanodeInfoWithStorage[127.0.0.1:43396,DS-51f3010f-2b35-4185-8276-e1c1186e36e0,DISK], DatanodeInfoWithStorage[127.0.0.1:42346,DS-e03f6794-9383-466d-8236-f80a29419bb9,DISK], DatanodeInfoWithStorage[127.0.0.1:37709,DS-71368543-6e45-46ef-9414-a4552b1d6d3d,DISK], DatanodeInfoWithStorage[127.0.0.1:44164,DS-fa763a89-357e-4531-858b-f06958e23e1c,DISK], DatanodeInfoWithStorage[127.0.0.1:46140,DS-130f89af-37a8-427f-a8dd-0007cace076b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-949934285-172.17.0.7-1598355953944:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43446,DS-78172eae-5728-4727-8edb-a2f68aa86597,DISK], DatanodeInfoWithStorage[127.0.0.1:46400,DS-abf5a26c-afae-4d78-b241-aaae2a22e7c2,DISK], DatanodeInfoWithStorage[127.0.0.1:42417,DS-3899cca0-6938-4717-a437-908e0179a76a,DISK], DatanodeInfoWithStorage[127.0.0.1:43396,DS-51f3010f-2b35-4185-8276-e1c1186e36e0,DISK], DatanodeInfoWithStorage[127.0.0.1:42346,DS-e03f6794-9383-466d-8236-f80a29419bb9,DISK], DatanodeInfoWithStorage[127.0.0.1:37709,DS-71368543-6e45-46ef-9414-a4552b1d6d3d,DISK], DatanodeInfoWithStorage[127.0.0.1:44164,DS-fa763a89-357e-4531-858b-f06958e23e1c,DISK], DatanodeInfoWithStorage[127.0.0.1:46140,DS-130f89af-37a8-427f-a8dd-0007cace076b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.ha.standby.checkpoints
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-426584446-172.17.0.7-1598356144612:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37175,DS-f97bf7c4-88fd-4718-9a59-7cea3c66c81c,DISK], DatanodeInfoWithStorage[127.0.0.1:44697,DS-81d1bed0-b389-436d-bf02-c4a9b4fb5e59,DISK], DatanodeInfoWithStorage[127.0.0.1:39272,DS-37849646-04b6-4480-9bd4-e6a287584f90,DISK], DatanodeInfoWithStorage[127.0.0.1:41388,DS-cff79e5a-d12d-459e-aa1b-7f75457c630b,DISK], DatanodeInfoWithStorage[127.0.0.1:44001,DS-98b5dbb3-ec80-4ab1-9917-6e9a0efc037f,DISK], DatanodeInfoWithStorage[127.0.0.1:38831,DS-1b45928c-b959-4f28-8dca-7711f80f808a,DISK], DatanodeInfoWithStorage[127.0.0.1:37711,DS-540fa3a2-df52-462a-b399-e6d4046a0336,DISK], DatanodeInfoWithStorage[127.0.0.1:45235,DS-5841a215-7265-42b1-9505-7d44a5839a75,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-426584446-172.17.0.7-1598356144612:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37175,DS-f97bf7c4-88fd-4718-9a59-7cea3c66c81c,DISK], DatanodeInfoWithStorage[127.0.0.1:44697,DS-81d1bed0-b389-436d-bf02-c4a9b4fb5e59,DISK], DatanodeInfoWithStorage[127.0.0.1:39272,DS-37849646-04b6-4480-9bd4-e6a287584f90,DISK], DatanodeInfoWithStorage[127.0.0.1:41388,DS-cff79e5a-d12d-459e-aa1b-7f75457c630b,DISK], DatanodeInfoWithStorage[127.0.0.1:44001,DS-98b5dbb3-ec80-4ab1-9917-6e9a0efc037f,DISK], DatanodeInfoWithStorage[127.0.0.1:38831,DS-1b45928c-b959-4f28-8dca-7711f80f808a,DISK], DatanodeInfoWithStorage[127.0.0.1:37711,DS-540fa3a2-df52-462a-b399-e6d4046a0336,DISK], DatanodeInfoWithStorage[127.0.0.1:45235,DS-5841a215-7265-42b1-9505-7d44a5839a75,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.ha.standby.checkpoints
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-653655190-172.17.0.7-1598356331950:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43158,DS-598cf044-13ad-42a7-b86b-c75772aa47a4,DISK], DatanodeInfoWithStorage[127.0.0.1:33821,DS-16adeaf8-61d8-4251-8df6-3b62319be60d,DISK], DatanodeInfoWithStorage[127.0.0.1:33660,DS-01b70669-4d49-4bb3-8be3-09524d29635e,DISK], DatanodeInfoWithStorage[127.0.0.1:35767,DS-cc5ca5d2-8646-4b47-b00d-d474ce6e44b6,DISK], DatanodeInfoWithStorage[127.0.0.1:46549,DS-fe885a43-3f60-4cb9-b159-9ee25de986a6,DISK], DatanodeInfoWithStorage[127.0.0.1:33181,DS-39c0a86e-9881-4524-8bdd-7202c50830b5,DISK], DatanodeInfoWithStorage[127.0.0.1:42303,DS-e810a7f4-6609-4528-9284-da06f2ba508d,DISK], DatanodeInfoWithStorage[127.0.0.1:44409,DS-085572d3-2046-456c-8daf-1af05e882de5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-653655190-172.17.0.7-1598356331950:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43158,DS-598cf044-13ad-42a7-b86b-c75772aa47a4,DISK], DatanodeInfoWithStorage[127.0.0.1:33821,DS-16adeaf8-61d8-4251-8df6-3b62319be60d,DISK], DatanodeInfoWithStorage[127.0.0.1:33660,DS-01b70669-4d49-4bb3-8be3-09524d29635e,DISK], DatanodeInfoWithStorage[127.0.0.1:35767,DS-cc5ca5d2-8646-4b47-b00d-d474ce6e44b6,DISK], DatanodeInfoWithStorage[127.0.0.1:46549,DS-fe885a43-3f60-4cb9-b159-9ee25de986a6,DISK], DatanodeInfoWithStorage[127.0.0.1:33181,DS-39c0a86e-9881-4524-8bdd-7202c50830b5,DISK], DatanodeInfoWithStorage[127.0.0.1:42303,DS-e810a7f4-6609-4528-9284-da06f2ba508d,DISK], DatanodeInfoWithStorage[127.0.0.1:44409,DS-085572d3-2046-456c-8daf-1af05e882de5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.ha.standby.checkpoints
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1376984999-172.17.0.7-1598356366927:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43504,DS-e447c3b6-9616-4f70-8942-78b23ed0498e,DISK], DatanodeInfoWithStorage[127.0.0.1:45983,DS-da6d58d4-a85f-489a-ae65-5899471b78ad,DISK], DatanodeInfoWithStorage[127.0.0.1:35074,DS-cfeb12f2-b8ba-4c57-8dd6-497eed8304b7,DISK], DatanodeInfoWithStorage[127.0.0.1:36666,DS-b6ae062e-99cf-491b-9aea-fc30d4e49a1f,DISK], DatanodeInfoWithStorage[127.0.0.1:35929,DS-87a08500-588f-486e-a2fb-aa0fc2287737,DISK], DatanodeInfoWithStorage[127.0.0.1:39790,DS-f3b8502a-9c4f-4431-a4c2-39fcc613937a,DISK], DatanodeInfoWithStorage[127.0.0.1:36291,DS-db272b47-eb4f-4afe-ac03-e8ca18096829,DISK], DatanodeInfoWithStorage[127.0.0.1:38182,DS-74a020e3-93f3-4759-8dc3-93ff57312890,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1376984999-172.17.0.7-1598356366927:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43504,DS-e447c3b6-9616-4f70-8942-78b23ed0498e,DISK], DatanodeInfoWithStorage[127.0.0.1:45983,DS-da6d58d4-a85f-489a-ae65-5899471b78ad,DISK], DatanodeInfoWithStorage[127.0.0.1:35074,DS-cfeb12f2-b8ba-4c57-8dd6-497eed8304b7,DISK], DatanodeInfoWithStorage[127.0.0.1:36666,DS-b6ae062e-99cf-491b-9aea-fc30d4e49a1f,DISK], DatanodeInfoWithStorage[127.0.0.1:35929,DS-87a08500-588f-486e-a2fb-aa0fc2287737,DISK], DatanodeInfoWithStorage[127.0.0.1:39790,DS-f3b8502a-9c4f-4431-a4c2-39fcc613937a,DISK], DatanodeInfoWithStorage[127.0.0.1:36291,DS-db272b47-eb4f-4afe-ac03-e8ca18096829,DISK], DatanodeInfoWithStorage[127.0.0.1:38182,DS-74a020e3-93f3-4759-8dc3-93ff57312890,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.ha.standby.checkpoints
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-729469824-172.17.0.7-1598356722979:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40956,DS-a0949274-24f0-4f02-834c-7f857f8f7c87,DISK], DatanodeInfoWithStorage[127.0.0.1:36724,DS-d76b2050-1078-43fc-8a36-05ca7bee393b,DISK], DatanodeInfoWithStorage[127.0.0.1:39046,DS-b6647c3d-6b82-47b7-9889-40eb9288f461,DISK], DatanodeInfoWithStorage[127.0.0.1:37786,DS-203e63da-cf78-4085-b93d-eba614094c53,DISK], DatanodeInfoWithStorage[127.0.0.1:33922,DS-a0674da1-8e6b-41ce-a247-35ab2d7df611,DISK], DatanodeInfoWithStorage[127.0.0.1:33504,DS-6addd333-66bb-49e6-b24c-8afe3a31aaae,DISK], DatanodeInfoWithStorage[127.0.0.1:44740,DS-377d8ba1-9440-441e-84c3-f35235fc76ca,DISK], DatanodeInfoWithStorage[127.0.0.1:41008,DS-d502affb-a00b-4f1a-a531-d8b370bc1ae2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-729469824-172.17.0.7-1598356722979:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40956,DS-a0949274-24f0-4f02-834c-7f857f8f7c87,DISK], DatanodeInfoWithStorage[127.0.0.1:36724,DS-d76b2050-1078-43fc-8a36-05ca7bee393b,DISK], DatanodeInfoWithStorage[127.0.0.1:39046,DS-b6647c3d-6b82-47b7-9889-40eb9288f461,DISK], DatanodeInfoWithStorage[127.0.0.1:37786,DS-203e63da-cf78-4085-b93d-eba614094c53,DISK], DatanodeInfoWithStorage[127.0.0.1:33922,DS-a0674da1-8e6b-41ce-a247-35ab2d7df611,DISK], DatanodeInfoWithStorage[127.0.0.1:33504,DS-6addd333-66bb-49e6-b24c-8afe3a31aaae,DISK], DatanodeInfoWithStorage[127.0.0.1:44740,DS-377d8ba1-9440-441e-84c3-f35235fc76ca,DISK], DatanodeInfoWithStorage[127.0.0.1:41008,DS-d502affb-a00b-4f1a-a531-d8b370bc1ae2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.ha.standby.checkpoints
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1187223403-172.17.0.7-1598356786106:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32938,DS-b267a651-715b-4add-bc95-542a486d71b2,DISK], DatanodeInfoWithStorage[127.0.0.1:36512,DS-326ef3ee-87c8-4c26-b30d-134a1ab049fa,DISK], DatanodeInfoWithStorage[127.0.0.1:38625,DS-c140d9b5-04b1-40a0-a9a6-e59719680c6b,DISK], DatanodeInfoWithStorage[127.0.0.1:36336,DS-e99588f4-61ba-4178-9f97-a97edbaccfd9,DISK], DatanodeInfoWithStorage[127.0.0.1:36195,DS-f0c095aa-d7c8-4667-a82b-638baed01b67,DISK], DatanodeInfoWithStorage[127.0.0.1:43989,DS-b536d5b0-c5ec-4f95-b659-656c875f9bca,DISK], DatanodeInfoWithStorage[127.0.0.1:35442,DS-81a6b81e-8361-4514-a808-afc1ef85c673,DISK], DatanodeInfoWithStorage[127.0.0.1:35269,DS-3c508b33-a009-4ea3-955b-7da7ca50b3ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1187223403-172.17.0.7-1598356786106:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32938,DS-b267a651-715b-4add-bc95-542a486d71b2,DISK], DatanodeInfoWithStorage[127.0.0.1:36512,DS-326ef3ee-87c8-4c26-b30d-134a1ab049fa,DISK], DatanodeInfoWithStorage[127.0.0.1:38625,DS-c140d9b5-04b1-40a0-a9a6-e59719680c6b,DISK], DatanodeInfoWithStorage[127.0.0.1:36336,DS-e99588f4-61ba-4178-9f97-a97edbaccfd9,DISK], DatanodeInfoWithStorage[127.0.0.1:36195,DS-f0c095aa-d7c8-4667-a82b-638baed01b67,DISK], DatanodeInfoWithStorage[127.0.0.1:43989,DS-b536d5b0-c5ec-4f95-b659-656c875f9bca,DISK], DatanodeInfoWithStorage[127.0.0.1:35442,DS-81a6b81e-8361-4514-a808-afc1ef85c673,DISK], DatanodeInfoWithStorage[127.0.0.1:35269,DS-3c508b33-a009-4ea3-955b-7da7ca50b3ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.ha.standby.checkpoints
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1429983366-172.17.0.7-1598356849082:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45575,DS-b0d86c3c-a50d-444d-a71d-f7d0bf40cda6,DISK], DatanodeInfoWithStorage[127.0.0.1:33326,DS-73450282-485a-4bab-955f-5c75a00fd53c,DISK], DatanodeInfoWithStorage[127.0.0.1:41890,DS-03e56335-705c-4a0d-9b61-c70ca8630b24,DISK], DatanodeInfoWithStorage[127.0.0.1:34290,DS-1e496a82-c104-43b3-a2b7-65173b0662c2,DISK], DatanodeInfoWithStorage[127.0.0.1:33001,DS-4c0c85ef-7763-4333-9e6b-aac03a94ebc5,DISK], DatanodeInfoWithStorage[127.0.0.1:37535,DS-1619f00a-6ab0-45e5-a294-523ae3d68185,DISK], DatanodeInfoWithStorage[127.0.0.1:33685,DS-1574ef36-3db2-4f8c-a977-679a2e58489b,DISK], DatanodeInfoWithStorage[127.0.0.1:33229,DS-c47a5bab-9a93-4a47-be12-15b02327e970,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1429983366-172.17.0.7-1598356849082:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45575,DS-b0d86c3c-a50d-444d-a71d-f7d0bf40cda6,DISK], DatanodeInfoWithStorage[127.0.0.1:33326,DS-73450282-485a-4bab-955f-5c75a00fd53c,DISK], DatanodeInfoWithStorage[127.0.0.1:41890,DS-03e56335-705c-4a0d-9b61-c70ca8630b24,DISK], DatanodeInfoWithStorage[127.0.0.1:34290,DS-1e496a82-c104-43b3-a2b7-65173b0662c2,DISK], DatanodeInfoWithStorage[127.0.0.1:33001,DS-4c0c85ef-7763-4333-9e6b-aac03a94ebc5,DISK], DatanodeInfoWithStorage[127.0.0.1:37535,DS-1619f00a-6ab0-45e5-a294-523ae3d68185,DISK], DatanodeInfoWithStorage[127.0.0.1:33685,DS-1574ef36-3db2-4f8c-a977-679a2e58489b,DISK], DatanodeInfoWithStorage[127.0.0.1:33229,DS-c47a5bab-9a93-4a47-be12-15b02327e970,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.ha.standby.checkpoints
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-786430884-172.17.0.7-1598356983947:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33433,DS-e0c5f16f-b5a7-4e3f-b7db-ad5536f556ad,DISK], DatanodeInfoWithStorage[127.0.0.1:33262,DS-62f898b6-1e10-400d-bfba-964614149da2,DISK], DatanodeInfoWithStorage[127.0.0.1:46378,DS-528ecae7-6b88-4cf8-acd7-0a795770f069,DISK], DatanodeInfoWithStorage[127.0.0.1:46708,DS-dddb0939-3ab7-4ab2-9e18-1e9d6ebf0117,DISK], DatanodeInfoWithStorage[127.0.0.1:38204,DS-b3082e9d-fc0c-4083-89bd-81ec9e4f94c6,DISK], DatanodeInfoWithStorage[127.0.0.1:33903,DS-f2fc065f-b540-4770-8571-ed5394a093c8,DISK], DatanodeInfoWithStorage[127.0.0.1:41544,DS-3a19f311-ace4-4905-9fa6-da7b75e44c10,DISK], DatanodeInfoWithStorage[127.0.0.1:41489,DS-aaec5c90-f938-424d-9f9d-caa442a9c0dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-786430884-172.17.0.7-1598356983947:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33433,DS-e0c5f16f-b5a7-4e3f-b7db-ad5536f556ad,DISK], DatanodeInfoWithStorage[127.0.0.1:33262,DS-62f898b6-1e10-400d-bfba-964614149da2,DISK], DatanodeInfoWithStorage[127.0.0.1:46378,DS-528ecae7-6b88-4cf8-acd7-0a795770f069,DISK], DatanodeInfoWithStorage[127.0.0.1:46708,DS-dddb0939-3ab7-4ab2-9e18-1e9d6ebf0117,DISK], DatanodeInfoWithStorage[127.0.0.1:38204,DS-b3082e9d-fc0c-4083-89bd-81ec9e4f94c6,DISK], DatanodeInfoWithStorage[127.0.0.1:33903,DS-f2fc065f-b540-4770-8571-ed5394a093c8,DISK], DatanodeInfoWithStorage[127.0.0.1:41544,DS-3a19f311-ace4-4905-9fa6-da7b75e44c10,DISK], DatanodeInfoWithStorage[127.0.0.1:41489,DS-aaec5c90-f938-424d-9f9d-caa442a9c0dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 15 out of 50
v1v1v2v2 failed with probability 22 out of 50
result: false positive !!!
Total execution time in seconds : 5276
