reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-276628614-172.17.0.3-1598366913675:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46187,DS-30da6732-f55f-4738-a202-048e08dddc6d,DISK], DatanodeInfoWithStorage[127.0.0.1:42633,DS-898b8b8d-f6ac-4604-98ae-8859a5aa83c1,DISK], DatanodeInfoWithStorage[127.0.0.1:43924,DS-4af1e1a5-c2dd-407e-b00c-11b9b05f84a7,DISK], DatanodeInfoWithStorage[127.0.0.1:37001,DS-098c3b5e-31cd-4b4e-bc03-15b28e570ac9,DISK], DatanodeInfoWithStorage[127.0.0.1:40885,DS-1c695b2e-99a4-471b-a87d-7ba4d2a69557,DISK], DatanodeInfoWithStorage[127.0.0.1:37411,DS-6ed57166-f8a7-4935-bcab-5971a882fdaa,DISK], DatanodeInfoWithStorage[127.0.0.1:37686,DS-9f22c1db-5c10-44e1-8741-d569489b741e,DISK], DatanodeInfoWithStorage[127.0.0.1:35205,DS-a92e5182-fa77-4f9e-8fb6-3f8159344fc0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-276628614-172.17.0.3-1598366913675:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46187,DS-30da6732-f55f-4738-a202-048e08dddc6d,DISK], DatanodeInfoWithStorage[127.0.0.1:42633,DS-898b8b8d-f6ac-4604-98ae-8859a5aa83c1,DISK], DatanodeInfoWithStorage[127.0.0.1:43924,DS-4af1e1a5-c2dd-407e-b00c-11b9b05f84a7,DISK], DatanodeInfoWithStorage[127.0.0.1:37001,DS-098c3b5e-31cd-4b4e-bc03-15b28e570ac9,DISK], DatanodeInfoWithStorage[127.0.0.1:40885,DS-1c695b2e-99a4-471b-a87d-7ba4d2a69557,DISK], DatanodeInfoWithStorage[127.0.0.1:37411,DS-6ed57166-f8a7-4935-bcab-5971a882fdaa,DISK], DatanodeInfoWithStorage[127.0.0.1:37686,DS-9f22c1db-5c10-44e1-8741-d569489b741e,DISK], DatanodeInfoWithStorage[127.0.0.1:35205,DS-a92e5182-fa77-4f9e-8fb6-3f8159344fc0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1789164330-172.17.0.3-1598367258619:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33206,DS-9f6fa5d2-334f-4915-b252-b4b363b090b2,DISK], DatanodeInfoWithStorage[127.0.0.1:44766,DS-1dead17d-0e86-4e0e-bd6b-a823f73abcf3,DISK], DatanodeInfoWithStorage[127.0.0.1:40907,DS-1dc13873-56da-4d33-badb-c8519077b2c7,DISK], DatanodeInfoWithStorage[127.0.0.1:37148,DS-7ccd6cd7-76c4-43d8-bbc1-372fa36a39e0,DISK], DatanodeInfoWithStorage[127.0.0.1:46372,DS-8daeaefa-d447-4b8a-acbc-296e59818a79,DISK], DatanodeInfoWithStorage[127.0.0.1:42515,DS-0da01c11-3de7-4271-8a9e-728be54428a8,DISK], DatanodeInfoWithStorage[127.0.0.1:33585,DS-302f81b6-33f7-4e54-b915-b3d7148cbc16,DISK], DatanodeInfoWithStorage[127.0.0.1:34715,DS-9b1c3c9d-488d-4b67-8e8e-72c2acf77c2f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1789164330-172.17.0.3-1598367258619:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33206,DS-9f6fa5d2-334f-4915-b252-b4b363b090b2,DISK], DatanodeInfoWithStorage[127.0.0.1:44766,DS-1dead17d-0e86-4e0e-bd6b-a823f73abcf3,DISK], DatanodeInfoWithStorage[127.0.0.1:40907,DS-1dc13873-56da-4d33-badb-c8519077b2c7,DISK], DatanodeInfoWithStorage[127.0.0.1:37148,DS-7ccd6cd7-76c4-43d8-bbc1-372fa36a39e0,DISK], DatanodeInfoWithStorage[127.0.0.1:46372,DS-8daeaefa-d447-4b8a-acbc-296e59818a79,DISK], DatanodeInfoWithStorage[127.0.0.1:42515,DS-0da01c11-3de7-4271-8a9e-728be54428a8,DISK], DatanodeInfoWithStorage[127.0.0.1:33585,DS-302f81b6-33f7-4e54-b915-b3d7148cbc16,DISK], DatanodeInfoWithStorage[127.0.0.1:34715,DS-9b1c3c9d-488d-4b67-8e8e-72c2acf77c2f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-395161415-172.17.0.3-1598367786769:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34620,DS-6b182a96-9fcf-4a67-a36a-a203eabd34d9,DISK], DatanodeInfoWithStorage[127.0.0.1:35127,DS-08187d61-208a-4e1a-8e3b-79136df77093,DISK], DatanodeInfoWithStorage[127.0.0.1:39950,DS-f1d8ea45-afaa-4455-b23c-89b14ae89343,DISK], DatanodeInfoWithStorage[127.0.0.1:36331,DS-d03599fc-9c9e-46a8-ab47-762364e12a83,DISK], DatanodeInfoWithStorage[127.0.0.1:34462,DS-5e39302e-a15c-4e0a-89f6-44bf8f5a8226,DISK], DatanodeInfoWithStorage[127.0.0.1:35806,DS-031b45a6-13d4-4529-a174-24388ca091ac,DISK], DatanodeInfoWithStorage[127.0.0.1:41414,DS-8984fc0a-19d8-4c65-a956-136a120f1c39,DISK], DatanodeInfoWithStorage[127.0.0.1:45629,DS-6f4ac7d5-9a22-4864-91d1-660f34ee81ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-395161415-172.17.0.3-1598367786769:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34620,DS-6b182a96-9fcf-4a67-a36a-a203eabd34d9,DISK], DatanodeInfoWithStorage[127.0.0.1:35127,DS-08187d61-208a-4e1a-8e3b-79136df77093,DISK], DatanodeInfoWithStorage[127.0.0.1:39950,DS-f1d8ea45-afaa-4455-b23c-89b14ae89343,DISK], DatanodeInfoWithStorage[127.0.0.1:36331,DS-d03599fc-9c9e-46a8-ab47-762364e12a83,DISK], DatanodeInfoWithStorage[127.0.0.1:34462,DS-5e39302e-a15c-4e0a-89f6-44bf8f5a8226,DISK], DatanodeInfoWithStorage[127.0.0.1:35806,DS-031b45a6-13d4-4529-a174-24388ca091ac,DISK], DatanodeInfoWithStorage[127.0.0.1:41414,DS-8984fc0a-19d8-4c65-a956-136a120f1c39,DISK], DatanodeInfoWithStorage[127.0.0.1:45629,DS-6f4ac7d5-9a22-4864-91d1-660f34ee81ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1241871838-172.17.0.3-1598367843685:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43801,DS-a6b8a707-cbed-44cf-80b2-af4ca81bd727,DISK], DatanodeInfoWithStorage[127.0.0.1:46032,DS-f76c4dcd-0efa-4158-8b09-4c3208bdd6d5,DISK], DatanodeInfoWithStorage[127.0.0.1:46736,DS-99f72b25-a5e3-4e8b-8a88-8ab5bd1480de,DISK], DatanodeInfoWithStorage[127.0.0.1:41218,DS-2a407044-6db1-4af9-8a98-bc623c299f6e,DISK], DatanodeInfoWithStorage[127.0.0.1:35273,DS-583dadbf-bdf5-487e-abc7-5bdd763d79d8,DISK], DatanodeInfoWithStorage[127.0.0.1:41720,DS-d6d9bbb4-9b0a-4987-bffa-aa6be7c50fad,DISK], DatanodeInfoWithStorage[127.0.0.1:38064,DS-deb570b0-f698-4a28-8ce9-b9c0504e99b2,DISK], DatanodeInfoWithStorage[127.0.0.1:37853,DS-c4a56835-0c11-468d-a2ed-b16f5a62e766,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1241871838-172.17.0.3-1598367843685:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43801,DS-a6b8a707-cbed-44cf-80b2-af4ca81bd727,DISK], DatanodeInfoWithStorage[127.0.0.1:46032,DS-f76c4dcd-0efa-4158-8b09-4c3208bdd6d5,DISK], DatanodeInfoWithStorage[127.0.0.1:46736,DS-99f72b25-a5e3-4e8b-8a88-8ab5bd1480de,DISK], DatanodeInfoWithStorage[127.0.0.1:41218,DS-2a407044-6db1-4af9-8a98-bc623c299f6e,DISK], DatanodeInfoWithStorage[127.0.0.1:35273,DS-583dadbf-bdf5-487e-abc7-5bdd763d79d8,DISK], DatanodeInfoWithStorage[127.0.0.1:41720,DS-d6d9bbb4-9b0a-4987-bffa-aa6be7c50fad,DISK], DatanodeInfoWithStorage[127.0.0.1:38064,DS-deb570b0-f698-4a28-8ce9-b9c0504e99b2,DISK], DatanodeInfoWithStorage[127.0.0.1:37853,DS-c4a56835-0c11-468d-a2ed-b16f5a62e766,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-189087278-172.17.0.3-1598368336304:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35131,DS-2cdb5fee-5b12-46e0-a9bb-c562e7d5e8c2,DISK], DatanodeInfoWithStorage[127.0.0.1:43560,DS-43d00d5f-52ca-4a52-b7a3-dc329d28dcc7,DISK], DatanodeInfoWithStorage[127.0.0.1:39068,DS-ae0ce8fd-76ad-43cc-90dd-dd9ea0c690d3,DISK], DatanodeInfoWithStorage[127.0.0.1:46608,DS-f12e2633-c9e8-48c7-819c-e5de94f950a8,DISK], DatanodeInfoWithStorage[127.0.0.1:34039,DS-e0bfc231-6742-4a7d-aa04-d0fa72ba67da,DISK], DatanodeInfoWithStorage[127.0.0.1:44618,DS-9f61dd04-545e-4873-a893-a53962c5fee0,DISK], DatanodeInfoWithStorage[127.0.0.1:32998,DS-a8bc27cf-43f1-4f56-8c4e-aa593014ab32,DISK], DatanodeInfoWithStorage[127.0.0.1:37899,DS-d49f463c-6a5b-4106-bc53-c2b1847d072b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-189087278-172.17.0.3-1598368336304:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35131,DS-2cdb5fee-5b12-46e0-a9bb-c562e7d5e8c2,DISK], DatanodeInfoWithStorage[127.0.0.1:43560,DS-43d00d5f-52ca-4a52-b7a3-dc329d28dcc7,DISK], DatanodeInfoWithStorage[127.0.0.1:39068,DS-ae0ce8fd-76ad-43cc-90dd-dd9ea0c690d3,DISK], DatanodeInfoWithStorage[127.0.0.1:46608,DS-f12e2633-c9e8-48c7-819c-e5de94f950a8,DISK], DatanodeInfoWithStorage[127.0.0.1:34039,DS-e0bfc231-6742-4a7d-aa04-d0fa72ba67da,DISK], DatanodeInfoWithStorage[127.0.0.1:44618,DS-9f61dd04-545e-4873-a893-a53962c5fee0,DISK], DatanodeInfoWithStorage[127.0.0.1:32998,DS-a8bc27cf-43f1-4f56-8c4e-aa593014ab32,DISK], DatanodeInfoWithStorage[127.0.0.1:37899,DS-d49f463c-6a5b-4106-bc53-c2b1847d072b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-788304603-172.17.0.3-1598368940964:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43978,DS-3ccb2dcb-aa6a-4d51-99f2-0b4e95248b47,DISK], DatanodeInfoWithStorage[127.0.0.1:45903,DS-05b7ab2a-4e0f-4254-b7c6-eee58a6c2ed1,DISK], DatanodeInfoWithStorage[127.0.0.1:42334,DS-9b0d14a3-b0af-4366-9469-d4c0a12d487c,DISK], DatanodeInfoWithStorage[127.0.0.1:35820,DS-8aa15d44-69ef-4468-9f33-adb9866067d5,DISK], DatanodeInfoWithStorage[127.0.0.1:36531,DS-f9ac2666-1293-4d4c-ae42-44f3f61ed733,DISK], DatanodeInfoWithStorage[127.0.0.1:42121,DS-a68769df-01b7-4422-93ff-8365c0c7fae7,DISK], DatanodeInfoWithStorage[127.0.0.1:41778,DS-9011742a-944f-4dfd-ab0a-ecef5217bb61,DISK], DatanodeInfoWithStorage[127.0.0.1:41784,DS-6710ee0b-ba66-4f41-bbff-99763de6623d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-788304603-172.17.0.3-1598368940964:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43978,DS-3ccb2dcb-aa6a-4d51-99f2-0b4e95248b47,DISK], DatanodeInfoWithStorage[127.0.0.1:45903,DS-05b7ab2a-4e0f-4254-b7c6-eee58a6c2ed1,DISK], DatanodeInfoWithStorage[127.0.0.1:42334,DS-9b0d14a3-b0af-4366-9469-d4c0a12d487c,DISK], DatanodeInfoWithStorage[127.0.0.1:35820,DS-8aa15d44-69ef-4468-9f33-adb9866067d5,DISK], DatanodeInfoWithStorage[127.0.0.1:36531,DS-f9ac2666-1293-4d4c-ae42-44f3f61ed733,DISK], DatanodeInfoWithStorage[127.0.0.1:42121,DS-a68769df-01b7-4422-93ff-8365c0c7fae7,DISK], DatanodeInfoWithStorage[127.0.0.1:41778,DS-9011742a-944f-4dfd-ab0a-ecef5217bb61,DISK], DatanodeInfoWithStorage[127.0.0.1:41784,DS-6710ee0b-ba66-4f41-bbff-99763de6623d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1647023718-172.17.0.3-1598369098967:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36544,DS-cb5bc824-fa42-4c56-a81d-476eba4e342c,DISK], DatanodeInfoWithStorage[127.0.0.1:42410,DS-077bd8d7-1440-4c3d-b9eb-16c4275fb266,DISK], DatanodeInfoWithStorage[127.0.0.1:36622,DS-0f5de43a-12ac-4798-8b64-9e8d03c29309,DISK], DatanodeInfoWithStorage[127.0.0.1:38514,DS-9c40088a-f5a1-4f74-b0db-87d1a2e20a2d,DISK], DatanodeInfoWithStorage[127.0.0.1:46195,DS-eb12bc43-1623-423a-85ef-84746de10075,DISK], DatanodeInfoWithStorage[127.0.0.1:37974,DS-55065f8c-9d0e-490f-8aee-e7443bff8b2c,DISK], DatanodeInfoWithStorage[127.0.0.1:42676,DS-8c3dcc37-242a-4390-bee7-ee7e234923f5,DISK], DatanodeInfoWithStorage[127.0.0.1:38701,DS-bf0c3094-ab15-418c-bcfd-4bda6b0b7af0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1647023718-172.17.0.3-1598369098967:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36544,DS-cb5bc824-fa42-4c56-a81d-476eba4e342c,DISK], DatanodeInfoWithStorage[127.0.0.1:42410,DS-077bd8d7-1440-4c3d-b9eb-16c4275fb266,DISK], DatanodeInfoWithStorage[127.0.0.1:36622,DS-0f5de43a-12ac-4798-8b64-9e8d03c29309,DISK], DatanodeInfoWithStorage[127.0.0.1:38514,DS-9c40088a-f5a1-4f74-b0db-87d1a2e20a2d,DISK], DatanodeInfoWithStorage[127.0.0.1:46195,DS-eb12bc43-1623-423a-85ef-84746de10075,DISK], DatanodeInfoWithStorage[127.0.0.1:37974,DS-55065f8c-9d0e-490f-8aee-e7443bff8b2c,DISK], DatanodeInfoWithStorage[127.0.0.1:42676,DS-8c3dcc37-242a-4390-bee7-ee7e234923f5,DISK], DatanodeInfoWithStorage[127.0.0.1:38701,DS-bf0c3094-ab15-418c-bcfd-4bda6b0b7af0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2062261157-172.17.0.3-1598369266793:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43682,DS-bd340ec0-2df7-42bc-b08b-6882ff3af23c,DISK], DatanodeInfoWithStorage[127.0.0.1:38321,DS-c791b05d-d6b6-46c4-a133-b5deec70e89a,DISK], DatanodeInfoWithStorage[127.0.0.1:39951,DS-76cdd7a2-fa08-4867-bdd6-0729ea285363,DISK], DatanodeInfoWithStorage[127.0.0.1:42468,DS-040f2a84-6eec-41b6-a614-7dc9168045fa,DISK], DatanodeInfoWithStorage[127.0.0.1:33853,DS-789c56ae-202f-4173-8674-8d386f7d6a47,DISK], DatanodeInfoWithStorage[127.0.0.1:43581,DS-30a53586-b388-4900-8fc5-11d1023da5c4,DISK], DatanodeInfoWithStorage[127.0.0.1:33167,DS-0ee70ddc-3eeb-4749-bf72-502bc704d888,DISK], DatanodeInfoWithStorage[127.0.0.1:40978,DS-9e433494-be9c-4f62-9f7c-39f2c3bca950,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2062261157-172.17.0.3-1598369266793:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43682,DS-bd340ec0-2df7-42bc-b08b-6882ff3af23c,DISK], DatanodeInfoWithStorage[127.0.0.1:38321,DS-c791b05d-d6b6-46c4-a133-b5deec70e89a,DISK], DatanodeInfoWithStorage[127.0.0.1:39951,DS-76cdd7a2-fa08-4867-bdd6-0729ea285363,DISK], DatanodeInfoWithStorage[127.0.0.1:42468,DS-040f2a84-6eec-41b6-a614-7dc9168045fa,DISK], DatanodeInfoWithStorage[127.0.0.1:33853,DS-789c56ae-202f-4173-8674-8d386f7d6a47,DISK], DatanodeInfoWithStorage[127.0.0.1:43581,DS-30a53586-b388-4900-8fc5-11d1023da5c4,DISK], DatanodeInfoWithStorage[127.0.0.1:33167,DS-0ee70ddc-3eeb-4749-bf72-502bc704d888,DISK], DatanodeInfoWithStorage[127.0.0.1:40978,DS-9e433494-be9c-4f62-9f7c-39f2c3bca950,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1387564916-172.17.0.3-1598369713321:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45828,DS-23e05784-56ce-4177-883b-c42bd6580253,DISK], DatanodeInfoWithStorage[127.0.0.1:33343,DS-b9f5b1b7-88ae-495b-80af-b787aa5caa37,DISK], DatanodeInfoWithStorage[127.0.0.1:36085,DS-715b61e5-adac-4eb8-a67a-ab45d1a82930,DISK], DatanodeInfoWithStorage[127.0.0.1:45324,DS-73d0c34b-506f-4cde-973a-a11aa2867edc,DISK], DatanodeInfoWithStorage[127.0.0.1:46442,DS-c52094dd-917e-48a1-9beb-df9aad0c88f7,DISK], DatanodeInfoWithStorage[127.0.0.1:45165,DS-8894489a-0b0b-4c39-813d-b96aa737fd9e,DISK], DatanodeInfoWithStorage[127.0.0.1:39987,DS-c0ab9892-5d60-4c9b-83cc-7245c8894abb,DISK], DatanodeInfoWithStorage[127.0.0.1:39263,DS-8aee639d-dc9e-4950-b295-490d1759d590,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1387564916-172.17.0.3-1598369713321:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45828,DS-23e05784-56ce-4177-883b-c42bd6580253,DISK], DatanodeInfoWithStorage[127.0.0.1:33343,DS-b9f5b1b7-88ae-495b-80af-b787aa5caa37,DISK], DatanodeInfoWithStorage[127.0.0.1:36085,DS-715b61e5-adac-4eb8-a67a-ab45d1a82930,DISK], DatanodeInfoWithStorage[127.0.0.1:45324,DS-73d0c34b-506f-4cde-973a-a11aa2867edc,DISK], DatanodeInfoWithStorage[127.0.0.1:46442,DS-c52094dd-917e-48a1-9beb-df9aad0c88f7,DISK], DatanodeInfoWithStorage[127.0.0.1:45165,DS-8894489a-0b0b-4c39-813d-b96aa737fd9e,DISK], DatanodeInfoWithStorage[127.0.0.1:39987,DS-c0ab9892-5d60-4c9b-83cc-7245c8894abb,DISK], DatanodeInfoWithStorage[127.0.0.1:39263,DS-8aee639d-dc9e-4950-b295-490d1759d590,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1051674206-172.17.0.3-1598370042258:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40172,DS-1a8656ee-7e89-41ce-b405-416921cd596c,DISK], DatanodeInfoWithStorage[127.0.0.1:33894,DS-a49feee1-0db8-41f4-909c-bb97b8645fdc,DISK], DatanodeInfoWithStorage[127.0.0.1:36479,DS-8178376a-b6ad-466e-a501-ee0f2c18bf95,DISK], DatanodeInfoWithStorage[127.0.0.1:35570,DS-799505d9-9d6a-4720-aecf-11d5e38ebfc8,DISK], DatanodeInfoWithStorage[127.0.0.1:44492,DS-180b0d71-1c11-4289-b1d9-ccbf83223ddc,DISK], DatanodeInfoWithStorage[127.0.0.1:44711,DS-7d135cf9-d0fd-4726-a07e-389b65460776,DISK], DatanodeInfoWithStorage[127.0.0.1:36512,DS-59caa50a-060f-4be3-a125-c861940c3a06,DISK], DatanodeInfoWithStorage[127.0.0.1:43027,DS-860e50e5-73e0-4e25-ac6a-7c862e6ec26c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1051674206-172.17.0.3-1598370042258:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40172,DS-1a8656ee-7e89-41ce-b405-416921cd596c,DISK], DatanodeInfoWithStorage[127.0.0.1:33894,DS-a49feee1-0db8-41f4-909c-bb97b8645fdc,DISK], DatanodeInfoWithStorage[127.0.0.1:36479,DS-8178376a-b6ad-466e-a501-ee0f2c18bf95,DISK], DatanodeInfoWithStorage[127.0.0.1:35570,DS-799505d9-9d6a-4720-aecf-11d5e38ebfc8,DISK], DatanodeInfoWithStorage[127.0.0.1:44492,DS-180b0d71-1c11-4289-b1d9-ccbf83223ddc,DISK], DatanodeInfoWithStorage[127.0.0.1:44711,DS-7d135cf9-d0fd-4726-a07e-389b65460776,DISK], DatanodeInfoWithStorage[127.0.0.1:36512,DS-59caa50a-060f-4be3-a125-c861940c3a06,DISK], DatanodeInfoWithStorage[127.0.0.1:43027,DS-860e50e5-73e0-4e25-ac6a-7c862e6ec26c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-802961539-172.17.0.3-1598370106531:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33880,DS-61c598a6-0d27-4279-a5a7-2a2bc1c9a581,DISK], DatanodeInfoWithStorage[127.0.0.1:44066,DS-485e2564-1e8f-4bf5-9308-a6d75c66b9d3,DISK], DatanodeInfoWithStorage[127.0.0.1:35494,DS-89d2a23f-5e14-49d2-88a8-7cf47453b3e3,DISK], DatanodeInfoWithStorage[127.0.0.1:40685,DS-7ac77072-0036-4016-8bcf-e5a1f9f62e5d,DISK], DatanodeInfoWithStorage[127.0.0.1:33338,DS-9049a5fc-7bb7-43f5-a83d-9e68906dd83d,DISK], DatanodeInfoWithStorage[127.0.0.1:43009,DS-0af63bf9-3c70-4f5a-936a-00ed9c80725d,DISK], DatanodeInfoWithStorage[127.0.0.1:36623,DS-96176f84-c6fd-47ee-95f3-ac3312c75dad,DISK], DatanodeInfoWithStorage[127.0.0.1:45501,DS-2c369b22-b6c7-48b2-b211-4214b532f875,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-802961539-172.17.0.3-1598370106531:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33880,DS-61c598a6-0d27-4279-a5a7-2a2bc1c9a581,DISK], DatanodeInfoWithStorage[127.0.0.1:44066,DS-485e2564-1e8f-4bf5-9308-a6d75c66b9d3,DISK], DatanodeInfoWithStorage[127.0.0.1:35494,DS-89d2a23f-5e14-49d2-88a8-7cf47453b3e3,DISK], DatanodeInfoWithStorage[127.0.0.1:40685,DS-7ac77072-0036-4016-8bcf-e5a1f9f62e5d,DISK], DatanodeInfoWithStorage[127.0.0.1:33338,DS-9049a5fc-7bb7-43f5-a83d-9e68906dd83d,DISK], DatanodeInfoWithStorage[127.0.0.1:43009,DS-0af63bf9-3c70-4f5a-936a-00ed9c80725d,DISK], DatanodeInfoWithStorage[127.0.0.1:36623,DS-96176f84-c6fd-47ee-95f3-ac3312c75dad,DISK], DatanodeInfoWithStorage[127.0.0.1:45501,DS-2c369b22-b6c7-48b2-b211-4214b532f875,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1132543122-172.17.0.3-1598370205413:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38154,DS-ddd2ca0b-eda0-4747-9918-49d85951592b,DISK], DatanodeInfoWithStorage[127.0.0.1:44423,DS-dd7b848f-d437-406c-8826-c2785c532417,DISK], DatanodeInfoWithStorage[127.0.0.1:41855,DS-2033c3fa-6f25-478e-a57e-6fcacbf8c350,DISK], DatanodeInfoWithStorage[127.0.0.1:35577,DS-aec374a9-6a9f-4e36-93e2-09b119ee2d85,DISK], DatanodeInfoWithStorage[127.0.0.1:40056,DS-ba1437df-e13a-4be2-b41a-6bfee71fc732,DISK], DatanodeInfoWithStorage[127.0.0.1:39367,DS-9345730e-6308-4d24-86e4-b1c59fd7aba2,DISK], DatanodeInfoWithStorage[127.0.0.1:43450,DS-9596edcd-f413-45ff-860f-07febcc935dd,DISK], DatanodeInfoWithStorage[127.0.0.1:37150,DS-62e95124-064a-4fc7-a61a-4be1c389474b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1132543122-172.17.0.3-1598370205413:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38154,DS-ddd2ca0b-eda0-4747-9918-49d85951592b,DISK], DatanodeInfoWithStorage[127.0.0.1:44423,DS-dd7b848f-d437-406c-8826-c2785c532417,DISK], DatanodeInfoWithStorage[127.0.0.1:41855,DS-2033c3fa-6f25-478e-a57e-6fcacbf8c350,DISK], DatanodeInfoWithStorage[127.0.0.1:35577,DS-aec374a9-6a9f-4e36-93e2-09b119ee2d85,DISK], DatanodeInfoWithStorage[127.0.0.1:40056,DS-ba1437df-e13a-4be2-b41a-6bfee71fc732,DISK], DatanodeInfoWithStorage[127.0.0.1:39367,DS-9345730e-6308-4d24-86e4-b1c59fd7aba2,DISK], DatanodeInfoWithStorage[127.0.0.1:43450,DS-9596edcd-f413-45ff-860f-07febcc935dd,DISK], DatanodeInfoWithStorage[127.0.0.1:37150,DS-62e95124-064a-4fc7-a61a-4be1c389474b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1566435697-172.17.0.3-1598370298375:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46336,DS-324147fc-8d7d-4244-a4bf-3b066d1274eb,DISK], DatanodeInfoWithStorage[127.0.0.1:43267,DS-559f7281-a6aa-4be3-ba8e-20f1aaa07756,DISK], DatanodeInfoWithStorage[127.0.0.1:38320,DS-10265173-5b0b-4900-9834-f2a22e3d50b9,DISK], DatanodeInfoWithStorage[127.0.0.1:33598,DS-28aa05d0-e809-4479-9abc-f1aaa88c9d71,DISK], DatanodeInfoWithStorage[127.0.0.1:33584,DS-4894ade7-3182-4dc2-8d3c-55e6aaf6e621,DISK], DatanodeInfoWithStorage[127.0.0.1:38796,DS-955deb5c-9dc0-4af8-872c-4a1eb07a2578,DISK], DatanodeInfoWithStorage[127.0.0.1:43975,DS-89ae3d4b-7483-4a85-bee2-3833b06ded77,DISK], DatanodeInfoWithStorage[127.0.0.1:32935,DS-b7a40db9-3466-4cec-991b-c87fd40c98a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1566435697-172.17.0.3-1598370298375:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46336,DS-324147fc-8d7d-4244-a4bf-3b066d1274eb,DISK], DatanodeInfoWithStorage[127.0.0.1:43267,DS-559f7281-a6aa-4be3-ba8e-20f1aaa07756,DISK], DatanodeInfoWithStorage[127.0.0.1:38320,DS-10265173-5b0b-4900-9834-f2a22e3d50b9,DISK], DatanodeInfoWithStorage[127.0.0.1:33598,DS-28aa05d0-e809-4479-9abc-f1aaa88c9d71,DISK], DatanodeInfoWithStorage[127.0.0.1:33584,DS-4894ade7-3182-4dc2-8d3c-55e6aaf6e621,DISK], DatanodeInfoWithStorage[127.0.0.1:38796,DS-955deb5c-9dc0-4af8-872c-4a1eb07a2578,DISK], DatanodeInfoWithStorage[127.0.0.1:43975,DS-89ae3d4b-7483-4a85-bee2-3833b06ded77,DISK], DatanodeInfoWithStorage[127.0.0.1:32935,DS-b7a40db9-3466-4cec-991b-c87fd40c98a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1941913058-172.17.0.3-1598370337065:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40600,DS-a3eeb3f7-f1d6-4050-85ce-980a70b4ccce,DISK], DatanodeInfoWithStorage[127.0.0.1:46611,DS-e521341c-3d09-48db-a20c-23e4f88c7a1b,DISK], DatanodeInfoWithStorage[127.0.0.1:38625,DS-51d70e80-cf12-47e7-bbeb-cc207fa19365,DISK], DatanodeInfoWithStorage[127.0.0.1:41880,DS-4a9e4f5c-6a81-4cbb-8d91-f683f0409f14,DISK], DatanodeInfoWithStorage[127.0.0.1:34818,DS-e405db3e-7924-4b37-9dfe-e61fd1a582a9,DISK], DatanodeInfoWithStorage[127.0.0.1:37945,DS-67ec004c-ebd6-428f-a0da-603c958296a0,DISK], DatanodeInfoWithStorage[127.0.0.1:46394,DS-db8f9166-ef7b-4834-8613-b7a6f891112c,DISK], DatanodeInfoWithStorage[127.0.0.1:41816,DS-36e5a5a3-175d-4b4a-85fe-c5aec29e4db1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1941913058-172.17.0.3-1598370337065:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40600,DS-a3eeb3f7-f1d6-4050-85ce-980a70b4ccce,DISK], DatanodeInfoWithStorage[127.0.0.1:46611,DS-e521341c-3d09-48db-a20c-23e4f88c7a1b,DISK], DatanodeInfoWithStorage[127.0.0.1:38625,DS-51d70e80-cf12-47e7-bbeb-cc207fa19365,DISK], DatanodeInfoWithStorage[127.0.0.1:41880,DS-4a9e4f5c-6a81-4cbb-8d91-f683f0409f14,DISK], DatanodeInfoWithStorage[127.0.0.1:34818,DS-e405db3e-7924-4b37-9dfe-e61fd1a582a9,DISK], DatanodeInfoWithStorage[127.0.0.1:37945,DS-67ec004c-ebd6-428f-a0da-603c958296a0,DISK], DatanodeInfoWithStorage[127.0.0.1:46394,DS-db8f9166-ef7b-4834-8613-b7a6f891112c,DISK], DatanodeInfoWithStorage[127.0.0.1:41816,DS-36e5a5a3-175d-4b4a-85fe-c5aec29e4db1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1437119514-172.17.0.3-1598370739969:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43069,DS-8b94a960-8296-48ff-9270-dfc0e7653f03,DISK], DatanodeInfoWithStorage[127.0.0.1:35346,DS-9b2d7fcc-c824-409a-8dc9-4a128aa7f22f,DISK], DatanodeInfoWithStorage[127.0.0.1:32871,DS-b81bf293-5da4-4aa7-b91c-7071cd170d9f,DISK], DatanodeInfoWithStorage[127.0.0.1:40464,DS-ad39139c-a6b7-47bf-8f64-ea11572ffe0a,DISK], DatanodeInfoWithStorage[127.0.0.1:40074,DS-2827ad46-43f5-498a-8b66-141f6bb010aa,DISK], DatanodeInfoWithStorage[127.0.0.1:37511,DS-a7473635-f674-4381-a1fb-f6658eb86e9a,DISK], DatanodeInfoWithStorage[127.0.0.1:40885,DS-c9b60bcc-3909-4c22-bbfa-0b13b83c4a15,DISK], DatanodeInfoWithStorage[127.0.0.1:33125,DS-af6a7361-742e-4b8a-8fbf-b123afe6cca4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1437119514-172.17.0.3-1598370739969:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43069,DS-8b94a960-8296-48ff-9270-dfc0e7653f03,DISK], DatanodeInfoWithStorage[127.0.0.1:35346,DS-9b2d7fcc-c824-409a-8dc9-4a128aa7f22f,DISK], DatanodeInfoWithStorage[127.0.0.1:32871,DS-b81bf293-5da4-4aa7-b91c-7071cd170d9f,DISK], DatanodeInfoWithStorage[127.0.0.1:40464,DS-ad39139c-a6b7-47bf-8f64-ea11572ffe0a,DISK], DatanodeInfoWithStorage[127.0.0.1:40074,DS-2827ad46-43f5-498a-8b66-141f6bb010aa,DISK], DatanodeInfoWithStorage[127.0.0.1:37511,DS-a7473635-f674-4381-a1fb-f6658eb86e9a,DISK], DatanodeInfoWithStorage[127.0.0.1:40885,DS-c9b60bcc-3909-4c22-bbfa-0b13b83c4a15,DISK], DatanodeInfoWithStorage[127.0.0.1:33125,DS-af6a7361-742e-4b8a-8fbf-b123afe6cca4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1884034951-172.17.0.3-1598371286241:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45166,DS-2a1cf9a7-9d1a-4f6a-bb90-22a9e5268f0f,DISK], DatanodeInfoWithStorage[127.0.0.1:45511,DS-1e54fcf5-bd8f-4371-a3d1-c25eaceec49d,DISK], DatanodeInfoWithStorage[127.0.0.1:40442,DS-e1f517c7-959f-44f1-bfee-14464fc41a98,DISK], DatanodeInfoWithStorage[127.0.0.1:45596,DS-df0cc202-5bc7-48cb-8650-499fe58838a9,DISK], DatanodeInfoWithStorage[127.0.0.1:41945,DS-737638f2-9356-4d2b-b845-90ce869fb068,DISK], DatanodeInfoWithStorage[127.0.0.1:42676,DS-50e2be42-5eea-4ecd-8c4c-6ba6d080986e,DISK], DatanodeInfoWithStorage[127.0.0.1:41309,DS-040b7040-5755-48f8-a949-229b287bf7ae,DISK], DatanodeInfoWithStorage[127.0.0.1:46028,DS-ea3b9798-f68a-4e4f-b9f9-2ca2505d964e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1884034951-172.17.0.3-1598371286241:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45166,DS-2a1cf9a7-9d1a-4f6a-bb90-22a9e5268f0f,DISK], DatanodeInfoWithStorage[127.0.0.1:45511,DS-1e54fcf5-bd8f-4371-a3d1-c25eaceec49d,DISK], DatanodeInfoWithStorage[127.0.0.1:40442,DS-e1f517c7-959f-44f1-bfee-14464fc41a98,DISK], DatanodeInfoWithStorage[127.0.0.1:45596,DS-df0cc202-5bc7-48cb-8650-499fe58838a9,DISK], DatanodeInfoWithStorage[127.0.0.1:41945,DS-737638f2-9356-4d2b-b845-90ce869fb068,DISK], DatanodeInfoWithStorage[127.0.0.1:42676,DS-50e2be42-5eea-4ecd-8c4c-6ba6d080986e,DISK], DatanodeInfoWithStorage[127.0.0.1:41309,DS-040b7040-5755-48f8-a949-229b287bf7ae,DISK], DatanodeInfoWithStorage[127.0.0.1:46028,DS-ea3b9798-f68a-4e4f-b9f9-2ca2505d964e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2085664455-172.17.0.3-1598371418738:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37716,DS-9118eb11-7da5-4474-b6a4-063b4fb31ad5,DISK], DatanodeInfoWithStorage[127.0.0.1:38750,DS-ab27da04-3467-4f6c-8b1f-61f9ebf988c3,DISK], DatanodeInfoWithStorage[127.0.0.1:34045,DS-14f8966e-afa0-4b86-ad99-5eea8a4bbd6f,DISK], DatanodeInfoWithStorage[127.0.0.1:33535,DS-71bd2156-a496-419b-9e5f-5949c84ad308,DISK], DatanodeInfoWithStorage[127.0.0.1:38382,DS-443003a1-9da9-4ebe-8a6c-0fa2d5f66a92,DISK], DatanodeInfoWithStorage[127.0.0.1:40064,DS-33efd5e9-e873-4c46-8a03-da517f95b765,DISK], DatanodeInfoWithStorage[127.0.0.1:34537,DS-b618ce3b-21e4-43a4-9465-5a24beb85418,DISK], DatanodeInfoWithStorage[127.0.0.1:37337,DS-8e7a727a-42fb-44cf-b671-67499ba8d8c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2085664455-172.17.0.3-1598371418738:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37716,DS-9118eb11-7da5-4474-b6a4-063b4fb31ad5,DISK], DatanodeInfoWithStorage[127.0.0.1:38750,DS-ab27da04-3467-4f6c-8b1f-61f9ebf988c3,DISK], DatanodeInfoWithStorage[127.0.0.1:34045,DS-14f8966e-afa0-4b86-ad99-5eea8a4bbd6f,DISK], DatanodeInfoWithStorage[127.0.0.1:33535,DS-71bd2156-a496-419b-9e5f-5949c84ad308,DISK], DatanodeInfoWithStorage[127.0.0.1:38382,DS-443003a1-9da9-4ebe-8a6c-0fa2d5f66a92,DISK], DatanodeInfoWithStorage[127.0.0.1:40064,DS-33efd5e9-e873-4c46-8a03-da517f95b765,DISK], DatanodeInfoWithStorage[127.0.0.1:34537,DS-b618ce3b-21e4-43a4-9465-5a24beb85418,DISK], DatanodeInfoWithStorage[127.0.0.1:37337,DS-8e7a727a-42fb-44cf-b671-67499ba8d8c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 4994
