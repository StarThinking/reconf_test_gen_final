reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-259811437-172.17.0.6-1598129381201:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43875,DS-52f21b39-0b3b-4879-a6c5-5497870f3503,DISK], DatanodeInfoWithStorage[127.0.0.1:33977,DS-0dbd7142-b526-4fe3-afd1-e0cb45cb3b18,DISK], DatanodeInfoWithStorage[127.0.0.1:42179,DS-655e9a03-e468-4113-b980-9553f28ded6e,DISK], DatanodeInfoWithStorage[127.0.0.1:36373,DS-f7250906-5943-4af8-99e8-6dd188509bbf,DISK], DatanodeInfoWithStorage[127.0.0.1:44898,DS-9f413476-8ebb-4405-b473-80015f7d8d24,DISK], DatanodeInfoWithStorage[127.0.0.1:35130,DS-e47bfd98-423c-4413-8903-bd231b389c04,DISK], DatanodeInfoWithStorage[127.0.0.1:45641,DS-3ca28970-638e-4327-bd1a-47b637619ffe,DISK], DatanodeInfoWithStorage[127.0.0.1:41949,DS-3da794e6-d5f5-4dcf-879d-7e256d5a75a9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-259811437-172.17.0.6-1598129381201:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43875,DS-52f21b39-0b3b-4879-a6c5-5497870f3503,DISK], DatanodeInfoWithStorage[127.0.0.1:33977,DS-0dbd7142-b526-4fe3-afd1-e0cb45cb3b18,DISK], DatanodeInfoWithStorage[127.0.0.1:42179,DS-655e9a03-e468-4113-b980-9553f28ded6e,DISK], DatanodeInfoWithStorage[127.0.0.1:36373,DS-f7250906-5943-4af8-99e8-6dd188509bbf,DISK], DatanodeInfoWithStorage[127.0.0.1:44898,DS-9f413476-8ebb-4405-b473-80015f7d8d24,DISK], DatanodeInfoWithStorage[127.0.0.1:35130,DS-e47bfd98-423c-4413-8903-bd231b389c04,DISK], DatanodeInfoWithStorage[127.0.0.1:45641,DS-3ca28970-638e-4327-bd1a-47b637619ffe,DISK], DatanodeInfoWithStorage[127.0.0.1:41949,DS-3da794e6-d5f5-4dcf-879d-7e256d5a75a9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1341533302-172.17.0.6-1598129460404:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44115,DS-835c10de-8628-4d43-856f-fbe951b07822,DISK], DatanodeInfoWithStorage[127.0.0.1:38119,DS-5a7b54e1-0c75-4737-8d2d-d7c6cc7fe4fa,DISK], DatanodeInfoWithStorage[127.0.0.1:34770,DS-4f8714d7-ec2f-4f42-9df4-6489349d8ca7,DISK], DatanodeInfoWithStorage[127.0.0.1:46688,DS-28308cc4-3e6f-486a-be5f-666cd972b24f,DISK], DatanodeInfoWithStorage[127.0.0.1:40420,DS-4ff46324-60c8-443f-b2b9-e9a5a00b94e9,DISK], DatanodeInfoWithStorage[127.0.0.1:46650,DS-a3641a6e-d394-40bb-bc96-67c15d937a75,DISK], DatanodeInfoWithStorage[127.0.0.1:33794,DS-4981c74a-ad0f-49cf-90c4-857d1e25140b,DISK], DatanodeInfoWithStorage[127.0.0.1:39216,DS-98156210-594c-4bed-953e-d86474e69c0c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1341533302-172.17.0.6-1598129460404:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44115,DS-835c10de-8628-4d43-856f-fbe951b07822,DISK], DatanodeInfoWithStorage[127.0.0.1:38119,DS-5a7b54e1-0c75-4737-8d2d-d7c6cc7fe4fa,DISK], DatanodeInfoWithStorage[127.0.0.1:34770,DS-4f8714d7-ec2f-4f42-9df4-6489349d8ca7,DISK], DatanodeInfoWithStorage[127.0.0.1:46688,DS-28308cc4-3e6f-486a-be5f-666cd972b24f,DISK], DatanodeInfoWithStorage[127.0.0.1:40420,DS-4ff46324-60c8-443f-b2b9-e9a5a00b94e9,DISK], DatanodeInfoWithStorage[127.0.0.1:46650,DS-a3641a6e-d394-40bb-bc96-67c15d937a75,DISK], DatanodeInfoWithStorage[127.0.0.1:33794,DS-4981c74a-ad0f-49cf-90c4-857d1e25140b,DISK], DatanodeInfoWithStorage[127.0.0.1:39216,DS-98156210-594c-4bed-953e-d86474e69c0c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1291804234-172.17.0.6-1598130500882:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40891,DS-e8714565-c75e-4894-87e9-896c6e1d8372,DISK], DatanodeInfoWithStorage[127.0.0.1:38753,DS-3ff5a608-b0a9-493b-9e1a-fd264519d8c8,DISK], DatanodeInfoWithStorage[127.0.0.1:44768,DS-4a8f6234-f7bd-4966-99dc-9b2465bff301,DISK], DatanodeInfoWithStorage[127.0.0.1:41272,DS-899b1a69-11ec-4a2f-ab53-69f307f905e9,DISK], DatanodeInfoWithStorage[127.0.0.1:37515,DS-5d721280-e3f4-4587-9b70-6486bb4f9ee1,DISK], DatanodeInfoWithStorage[127.0.0.1:42717,DS-6cfd37f0-89c9-4e73-8d63-b5c286b398ee,DISK], DatanodeInfoWithStorage[127.0.0.1:42211,DS-569feab0-24cb-4efa-831b-3cbb478b149d,DISK], DatanodeInfoWithStorage[127.0.0.1:36716,DS-add68cc7-bfd7-4e55-846b-5bebf95fc64d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1291804234-172.17.0.6-1598130500882:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40891,DS-e8714565-c75e-4894-87e9-896c6e1d8372,DISK], DatanodeInfoWithStorage[127.0.0.1:38753,DS-3ff5a608-b0a9-493b-9e1a-fd264519d8c8,DISK], DatanodeInfoWithStorage[127.0.0.1:44768,DS-4a8f6234-f7bd-4966-99dc-9b2465bff301,DISK], DatanodeInfoWithStorage[127.0.0.1:41272,DS-899b1a69-11ec-4a2f-ab53-69f307f905e9,DISK], DatanodeInfoWithStorage[127.0.0.1:37515,DS-5d721280-e3f4-4587-9b70-6486bb4f9ee1,DISK], DatanodeInfoWithStorage[127.0.0.1:42717,DS-6cfd37f0-89c9-4e73-8d63-b5c286b398ee,DISK], DatanodeInfoWithStorage[127.0.0.1:42211,DS-569feab0-24cb-4efa-831b-3cbb478b149d,DISK], DatanodeInfoWithStorage[127.0.0.1:36716,DS-add68cc7-bfd7-4e55-846b-5bebf95fc64d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1062347869-172.17.0.6-1598130770121:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44685,DS-ca8990bd-3bca-4ba4-9912-5de501ec66a5,DISK], DatanodeInfoWithStorage[127.0.0.1:41972,DS-269a9576-95ad-43d4-865c-64b9765bce6a,DISK], DatanodeInfoWithStorage[127.0.0.1:44484,DS-862af83a-38d2-43b0-8e3a-38123e0c20c6,DISK], DatanodeInfoWithStorage[127.0.0.1:36135,DS-c93f0fd3-f58b-48c0-9013-d5ec464a5a6f,DISK], DatanodeInfoWithStorage[127.0.0.1:33664,DS-34f701a3-ccc7-41c8-932f-355375801018,DISK], DatanodeInfoWithStorage[127.0.0.1:36589,DS-f9130c5f-aa18-45f9-91dc-f4abc9b4f518,DISK], DatanodeInfoWithStorage[127.0.0.1:37264,DS-d946db81-232e-4196-9786-2380eca35f18,DISK], DatanodeInfoWithStorage[127.0.0.1:44924,DS-6ad322d7-6d5c-48f4-92e7-f47c6f208778,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1062347869-172.17.0.6-1598130770121:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44685,DS-ca8990bd-3bca-4ba4-9912-5de501ec66a5,DISK], DatanodeInfoWithStorage[127.0.0.1:41972,DS-269a9576-95ad-43d4-865c-64b9765bce6a,DISK], DatanodeInfoWithStorage[127.0.0.1:44484,DS-862af83a-38d2-43b0-8e3a-38123e0c20c6,DISK], DatanodeInfoWithStorage[127.0.0.1:36135,DS-c93f0fd3-f58b-48c0-9013-d5ec464a5a6f,DISK], DatanodeInfoWithStorage[127.0.0.1:33664,DS-34f701a3-ccc7-41c8-932f-355375801018,DISK], DatanodeInfoWithStorage[127.0.0.1:36589,DS-f9130c5f-aa18-45f9-91dc-f4abc9b4f518,DISK], DatanodeInfoWithStorage[127.0.0.1:37264,DS-d946db81-232e-4196-9786-2380eca35f18,DISK], DatanodeInfoWithStorage[127.0.0.1:44924,DS-6ad322d7-6d5c-48f4-92e7-f47c6f208778,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-644392317-172.17.0.6-1598130831701:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33646,DS-7f2924de-ee23-455e-8f33-463cacd6435d,DISK], DatanodeInfoWithStorage[127.0.0.1:42661,DS-debe9104-5b3e-4ae5-a805-7f372bcfbe70,DISK], DatanodeInfoWithStorage[127.0.0.1:36991,DS-6440c88a-d5e5-4af9-b38b-92a7003a944c,DISK], DatanodeInfoWithStorage[127.0.0.1:36823,DS-1b945d4f-6359-45a0-a14c-a1badf9e448d,DISK], DatanodeInfoWithStorage[127.0.0.1:38173,DS-08eff80c-0e70-4b9c-bedf-32bf7228878c,DISK], DatanodeInfoWithStorage[127.0.0.1:46823,DS-01b96d0d-c544-4d8b-a098-f881710eded9,DISK], DatanodeInfoWithStorage[127.0.0.1:46871,DS-046913d5-c133-4a86-9816-f976c971dbe9,DISK], DatanodeInfoWithStorage[127.0.0.1:44012,DS-50245f16-b755-4a76-90f6-dbc9baf18a89,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-644392317-172.17.0.6-1598130831701:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33646,DS-7f2924de-ee23-455e-8f33-463cacd6435d,DISK], DatanodeInfoWithStorage[127.0.0.1:42661,DS-debe9104-5b3e-4ae5-a805-7f372bcfbe70,DISK], DatanodeInfoWithStorage[127.0.0.1:36991,DS-6440c88a-d5e5-4af9-b38b-92a7003a944c,DISK], DatanodeInfoWithStorage[127.0.0.1:36823,DS-1b945d4f-6359-45a0-a14c-a1badf9e448d,DISK], DatanodeInfoWithStorage[127.0.0.1:38173,DS-08eff80c-0e70-4b9c-bedf-32bf7228878c,DISK], DatanodeInfoWithStorage[127.0.0.1:46823,DS-01b96d0d-c544-4d8b-a098-f881710eded9,DISK], DatanodeInfoWithStorage[127.0.0.1:46871,DS-046913d5-c133-4a86-9816-f976c971dbe9,DISK], DatanodeInfoWithStorage[127.0.0.1:44012,DS-50245f16-b755-4a76-90f6-dbc9baf18a89,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2141283374-172.17.0.6-1598131234591:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37908,DS-026f62bb-981b-42de-b79e-359cd036670f,DISK], DatanodeInfoWithStorage[127.0.0.1:39654,DS-98647195-309c-48ba-99af-826f912bfa54,DISK], DatanodeInfoWithStorage[127.0.0.1:42483,DS-23955023-604a-4d2c-a123-d259a7ac8cca,DISK], DatanodeInfoWithStorage[127.0.0.1:43525,DS-b56b720f-78e4-462a-80cb-38613340375a,DISK], DatanodeInfoWithStorage[127.0.0.1:44338,DS-b9682239-f5ad-4587-aeb5-d85df21f41fc,DISK], DatanodeInfoWithStorage[127.0.0.1:43033,DS-6b78535b-622a-4df2-8306-73e606e1bdb7,DISK], DatanodeInfoWithStorage[127.0.0.1:38474,DS-ec83fe17-f4ee-4fb9-b8ed-f3e6e9d27c0b,DISK], DatanodeInfoWithStorage[127.0.0.1:40873,DS-ed04af15-2ebf-4a18-b4f8-6f87346c1836,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2141283374-172.17.0.6-1598131234591:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37908,DS-026f62bb-981b-42de-b79e-359cd036670f,DISK], DatanodeInfoWithStorage[127.0.0.1:39654,DS-98647195-309c-48ba-99af-826f912bfa54,DISK], DatanodeInfoWithStorage[127.0.0.1:42483,DS-23955023-604a-4d2c-a123-d259a7ac8cca,DISK], DatanodeInfoWithStorage[127.0.0.1:43525,DS-b56b720f-78e4-462a-80cb-38613340375a,DISK], DatanodeInfoWithStorage[127.0.0.1:44338,DS-b9682239-f5ad-4587-aeb5-d85df21f41fc,DISK], DatanodeInfoWithStorage[127.0.0.1:43033,DS-6b78535b-622a-4df2-8306-73e606e1bdb7,DISK], DatanodeInfoWithStorage[127.0.0.1:38474,DS-ec83fe17-f4ee-4fb9-b8ed-f3e6e9d27c0b,DISK], DatanodeInfoWithStorage[127.0.0.1:40873,DS-ed04af15-2ebf-4a18-b4f8-6f87346c1836,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1229626649-172.17.0.6-1598131704267:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40035,DS-342c611a-e112-41c8-ab25-7378ffaa86d2,DISK], DatanodeInfoWithStorage[127.0.0.1:45460,DS-adf3de6e-4805-4301-b27f-f47a7dce8e33,DISK], DatanodeInfoWithStorage[127.0.0.1:41952,DS-506e0a45-296e-4e35-b1e0-6145b4624718,DISK], DatanodeInfoWithStorage[127.0.0.1:42484,DS-89e5cfe6-3682-4ea1-b596-f35e1f86370a,DISK], DatanodeInfoWithStorage[127.0.0.1:33099,DS-7815309f-7e2f-4384-a1f3-5e388a800381,DISK], DatanodeInfoWithStorage[127.0.0.1:33876,DS-42a15991-0aae-4caa-9376-e42b78ce85d0,DISK], DatanodeInfoWithStorage[127.0.0.1:43284,DS-f36377a7-913b-4d00-86a8-153102fa9a68,DISK], DatanodeInfoWithStorage[127.0.0.1:36321,DS-6eb4c4aa-b9a2-46d5-be6a-f76b4562cbd8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1229626649-172.17.0.6-1598131704267:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40035,DS-342c611a-e112-41c8-ab25-7378ffaa86d2,DISK], DatanodeInfoWithStorage[127.0.0.1:45460,DS-adf3de6e-4805-4301-b27f-f47a7dce8e33,DISK], DatanodeInfoWithStorage[127.0.0.1:41952,DS-506e0a45-296e-4e35-b1e0-6145b4624718,DISK], DatanodeInfoWithStorage[127.0.0.1:42484,DS-89e5cfe6-3682-4ea1-b596-f35e1f86370a,DISK], DatanodeInfoWithStorage[127.0.0.1:33099,DS-7815309f-7e2f-4384-a1f3-5e388a800381,DISK], DatanodeInfoWithStorage[127.0.0.1:33876,DS-42a15991-0aae-4caa-9376-e42b78ce85d0,DISK], DatanodeInfoWithStorage[127.0.0.1:43284,DS-f36377a7-913b-4d00-86a8-153102fa9a68,DISK], DatanodeInfoWithStorage[127.0.0.1:36321,DS-6eb4c4aa-b9a2-46d5-be6a-f76b4562cbd8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1449317573-172.17.0.6-1598132356117:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36361,DS-cd87d444-8369-49f5-80e2-c10ac5b48403,DISK], DatanodeInfoWithStorage[127.0.0.1:44815,DS-5f884eb4-d54c-41ef-b2d8-0dfabd87f18f,DISK], DatanodeInfoWithStorage[127.0.0.1:43748,DS-f31a3d59-9184-466a-9cb0-28219810c7b8,DISK], DatanodeInfoWithStorage[127.0.0.1:35183,DS-3d5ecb10-0483-4d90-b9fb-2c09c8fead8d,DISK], DatanodeInfoWithStorage[127.0.0.1:39628,DS-0ddcdf8c-832f-4a81-a065-01875a9c33f1,DISK], DatanodeInfoWithStorage[127.0.0.1:33880,DS-b4b364a1-da37-461b-8750-cc614ef82949,DISK], DatanodeInfoWithStorage[127.0.0.1:39908,DS-5f953ea0-a4cf-49fa-b38e-c5096d275208,DISK], DatanodeInfoWithStorage[127.0.0.1:43107,DS-96d86907-5a70-4faa-ba60-91d94c3c12d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1449317573-172.17.0.6-1598132356117:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36361,DS-cd87d444-8369-49f5-80e2-c10ac5b48403,DISK], DatanodeInfoWithStorage[127.0.0.1:44815,DS-5f884eb4-d54c-41ef-b2d8-0dfabd87f18f,DISK], DatanodeInfoWithStorage[127.0.0.1:43748,DS-f31a3d59-9184-466a-9cb0-28219810c7b8,DISK], DatanodeInfoWithStorage[127.0.0.1:35183,DS-3d5ecb10-0483-4d90-b9fb-2c09c8fead8d,DISK], DatanodeInfoWithStorage[127.0.0.1:39628,DS-0ddcdf8c-832f-4a81-a065-01875a9c33f1,DISK], DatanodeInfoWithStorage[127.0.0.1:33880,DS-b4b364a1-da37-461b-8750-cc614ef82949,DISK], DatanodeInfoWithStorage[127.0.0.1:39908,DS-5f953ea0-a4cf-49fa-b38e-c5096d275208,DISK], DatanodeInfoWithStorage[127.0.0.1:43107,DS-96d86907-5a70-4faa-ba60-91d94c3c12d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1521281448-172.17.0.6-1598132824790:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36886,DS-20172906-2952-40c4-b0fd-3e46a7021bb8,DISK], DatanodeInfoWithStorage[127.0.0.1:44632,DS-3df18088-9830-4b7a-93d3-2d3095c2abcf,DISK], DatanodeInfoWithStorage[127.0.0.1:40528,DS-31b33dd7-d388-44ec-92f5-950a558376bc,DISK], DatanodeInfoWithStorage[127.0.0.1:39999,DS-69e89f3c-6ea1-4b24-a833-7a024ceed903,DISK], DatanodeInfoWithStorage[127.0.0.1:44634,DS-deb1537d-312e-4da5-8413-4b602080686f,DISK], DatanodeInfoWithStorage[127.0.0.1:39582,DS-9ad1e033-82d2-44af-8985-0e1f0b76d72d,DISK], DatanodeInfoWithStorage[127.0.0.1:45179,DS-db714c1b-ccd2-4e65-b80e-b895a93b1486,DISK], DatanodeInfoWithStorage[127.0.0.1:40754,DS-128e6bcf-795e-4298-9b6c-4591ec64b336,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1521281448-172.17.0.6-1598132824790:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36886,DS-20172906-2952-40c4-b0fd-3e46a7021bb8,DISK], DatanodeInfoWithStorage[127.0.0.1:44632,DS-3df18088-9830-4b7a-93d3-2d3095c2abcf,DISK], DatanodeInfoWithStorage[127.0.0.1:40528,DS-31b33dd7-d388-44ec-92f5-950a558376bc,DISK], DatanodeInfoWithStorage[127.0.0.1:39999,DS-69e89f3c-6ea1-4b24-a833-7a024ceed903,DISK], DatanodeInfoWithStorage[127.0.0.1:44634,DS-deb1537d-312e-4da5-8413-4b602080686f,DISK], DatanodeInfoWithStorage[127.0.0.1:39582,DS-9ad1e033-82d2-44af-8985-0e1f0b76d72d,DISK], DatanodeInfoWithStorage[127.0.0.1:45179,DS-db714c1b-ccd2-4e65-b80e-b895a93b1486,DISK], DatanodeInfoWithStorage[127.0.0.1:40754,DS-128e6bcf-795e-4298-9b6c-4591ec64b336,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-287798186-172.17.0.6-1598132908954:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33715,DS-09b436ff-bd10-44e2-87ae-018e77af468b,DISK], DatanodeInfoWithStorage[127.0.0.1:43703,DS-117dc1b3-b1d9-4e62-923d-873bf4ecf1c3,DISK], DatanodeInfoWithStorage[127.0.0.1:36131,DS-53255e49-e951-442e-9cf0-b703dfddb968,DISK], DatanodeInfoWithStorage[127.0.0.1:42675,DS-b3df083c-73be-4161-bd43-78644db493ae,DISK], DatanodeInfoWithStorage[127.0.0.1:32917,DS-2b0e66f8-bccd-43ea-83ae-8c384da88e6d,DISK], DatanodeInfoWithStorage[127.0.0.1:42654,DS-9a6f5fcf-3d0f-4356-811e-024831289308,DISK], DatanodeInfoWithStorage[127.0.0.1:34757,DS-fab1324b-a390-48b0-b9b0-a139d61bc04f,DISK], DatanodeInfoWithStorage[127.0.0.1:40088,DS-87213095-3464-444c-9e45-9c78ed929b23,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-287798186-172.17.0.6-1598132908954:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33715,DS-09b436ff-bd10-44e2-87ae-018e77af468b,DISK], DatanodeInfoWithStorage[127.0.0.1:43703,DS-117dc1b3-b1d9-4e62-923d-873bf4ecf1c3,DISK], DatanodeInfoWithStorage[127.0.0.1:36131,DS-53255e49-e951-442e-9cf0-b703dfddb968,DISK], DatanodeInfoWithStorage[127.0.0.1:42675,DS-b3df083c-73be-4161-bd43-78644db493ae,DISK], DatanodeInfoWithStorage[127.0.0.1:32917,DS-2b0e66f8-bccd-43ea-83ae-8c384da88e6d,DISK], DatanodeInfoWithStorage[127.0.0.1:42654,DS-9a6f5fcf-3d0f-4356-811e-024831289308,DISK], DatanodeInfoWithStorage[127.0.0.1:34757,DS-fab1324b-a390-48b0-b9b0-a139d61bc04f,DISK], DatanodeInfoWithStorage[127.0.0.1:40088,DS-87213095-3464-444c-9e45-9c78ed929b23,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-369562138-172.17.0.6-1598133171261:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44811,DS-1d14d954-54ff-49e0-a597-7c04269a32b6,DISK], DatanodeInfoWithStorage[127.0.0.1:44321,DS-e02594dc-3239-48fe-ac18-1696b9b6cf08,DISK], DatanodeInfoWithStorage[127.0.0.1:35586,DS-9375ae51-55c5-43d0-b52e-a776f7a8a5e1,DISK], DatanodeInfoWithStorage[127.0.0.1:44203,DS-26a9510b-95f4-4926-befa-31336e95736a,DISK], DatanodeInfoWithStorage[127.0.0.1:38699,DS-4c18eb8b-3968-4c40-8631-0802fa314369,DISK], DatanodeInfoWithStorage[127.0.0.1:34167,DS-023dc2d9-8913-4c4d-bb7e-de60279ce2bc,DISK], DatanodeInfoWithStorage[127.0.0.1:43630,DS-c864e03c-99d1-47f3-822e-396aa5d5e04e,DISK], DatanodeInfoWithStorage[127.0.0.1:42315,DS-52663853-761c-42f9-818b-fe9a06f01c56,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-369562138-172.17.0.6-1598133171261:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44811,DS-1d14d954-54ff-49e0-a597-7c04269a32b6,DISK], DatanodeInfoWithStorage[127.0.0.1:44321,DS-e02594dc-3239-48fe-ac18-1696b9b6cf08,DISK], DatanodeInfoWithStorage[127.0.0.1:35586,DS-9375ae51-55c5-43d0-b52e-a776f7a8a5e1,DISK], DatanodeInfoWithStorage[127.0.0.1:44203,DS-26a9510b-95f4-4926-befa-31336e95736a,DISK], DatanodeInfoWithStorage[127.0.0.1:38699,DS-4c18eb8b-3968-4c40-8631-0802fa314369,DISK], DatanodeInfoWithStorage[127.0.0.1:34167,DS-023dc2d9-8913-4c4d-bb7e-de60279ce2bc,DISK], DatanodeInfoWithStorage[127.0.0.1:43630,DS-c864e03c-99d1-47f3-822e-396aa5d5e04e,DISK], DatanodeInfoWithStorage[127.0.0.1:42315,DS-52663853-761c-42f9-818b-fe9a06f01c56,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1016127691-172.17.0.6-1598133269435:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40851,DS-8a44f2e7-79c0-495c-9a95-23af04395235,DISK], DatanodeInfoWithStorage[127.0.0.1:41947,DS-e717d03a-0fc7-4d6e-ab22-ad72d86c7dc4,DISK], DatanodeInfoWithStorage[127.0.0.1:44731,DS-93012c28-35ef-40ef-848d-42bb96a5a56f,DISK], DatanodeInfoWithStorage[127.0.0.1:33865,DS-56fde581-500a-4bc3-bd99-57f8f2734d3e,DISK], DatanodeInfoWithStorage[127.0.0.1:46170,DS-6a879df3-66fa-4137-8773-033f2bd97ed0,DISK], DatanodeInfoWithStorage[127.0.0.1:42815,DS-acb3e98b-e5b8-468f-8f39-1ec7c74e70fa,DISK], DatanodeInfoWithStorage[127.0.0.1:34937,DS-8200f9f6-9797-4d9f-9be5-b5a3d164643f,DISK], DatanodeInfoWithStorage[127.0.0.1:33010,DS-a5d62152-6559-4e9a-8220-73a1885aefb8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1016127691-172.17.0.6-1598133269435:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40851,DS-8a44f2e7-79c0-495c-9a95-23af04395235,DISK], DatanodeInfoWithStorage[127.0.0.1:41947,DS-e717d03a-0fc7-4d6e-ab22-ad72d86c7dc4,DISK], DatanodeInfoWithStorage[127.0.0.1:44731,DS-93012c28-35ef-40ef-848d-42bb96a5a56f,DISK], DatanodeInfoWithStorage[127.0.0.1:33865,DS-56fde581-500a-4bc3-bd99-57f8f2734d3e,DISK], DatanodeInfoWithStorage[127.0.0.1:46170,DS-6a879df3-66fa-4137-8773-033f2bd97ed0,DISK], DatanodeInfoWithStorage[127.0.0.1:42815,DS-acb3e98b-e5b8-468f-8f39-1ec7c74e70fa,DISK], DatanodeInfoWithStorage[127.0.0.1:34937,DS-8200f9f6-9797-4d9f-9be5-b5a3d164643f,DISK], DatanodeInfoWithStorage[127.0.0.1:33010,DS-a5d62152-6559-4e9a-8220-73a1885aefb8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-614073561-172.17.0.6-1598133338584:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33569,DS-95971fe8-fa32-442a-8035-f5c1b8739181,DISK], DatanodeInfoWithStorage[127.0.0.1:44809,DS-0dd34088-eed2-41bf-836c-f1f4e8d2d5fb,DISK], DatanodeInfoWithStorage[127.0.0.1:45027,DS-c3d444d0-bca3-40be-9c7c-f23c0e205df3,DISK], DatanodeInfoWithStorage[127.0.0.1:34100,DS-b87201d9-5213-4753-aace-be2c26673d80,DISK], DatanodeInfoWithStorage[127.0.0.1:41099,DS-ec8ef2e5-a091-488a-8a13-4810c9ac61bf,DISK], DatanodeInfoWithStorage[127.0.0.1:45199,DS-caad5247-e303-4453-ab7f-c982c4ab91c6,DISK], DatanodeInfoWithStorage[127.0.0.1:38062,DS-d5b415b0-b6ba-4ba9-b843-af962dd12a6a,DISK], DatanodeInfoWithStorage[127.0.0.1:44428,DS-478b36eb-9d6e-4543-810d-1b61a6ad25f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-614073561-172.17.0.6-1598133338584:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33569,DS-95971fe8-fa32-442a-8035-f5c1b8739181,DISK], DatanodeInfoWithStorage[127.0.0.1:44809,DS-0dd34088-eed2-41bf-836c-f1f4e8d2d5fb,DISK], DatanodeInfoWithStorage[127.0.0.1:45027,DS-c3d444d0-bca3-40be-9c7c-f23c0e205df3,DISK], DatanodeInfoWithStorage[127.0.0.1:34100,DS-b87201d9-5213-4753-aace-be2c26673d80,DISK], DatanodeInfoWithStorage[127.0.0.1:41099,DS-ec8ef2e5-a091-488a-8a13-4810c9ac61bf,DISK], DatanodeInfoWithStorage[127.0.0.1:45199,DS-caad5247-e303-4453-ab7f-c982c4ab91c6,DISK], DatanodeInfoWithStorage[127.0.0.1:38062,DS-d5b415b0-b6ba-4ba9-b843-af962dd12a6a,DISK], DatanodeInfoWithStorage[127.0.0.1:44428,DS-478b36eb-9d6e-4543-810d-1b61a6ad25f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-869894155-172.17.0.6-1598133828133:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46609,DS-e9a9b7fc-a651-481f-843a-83ff77d241c6,DISK], DatanodeInfoWithStorage[127.0.0.1:43781,DS-a0da0d04-652c-4571-8ca3-c975ae6223f3,DISK], DatanodeInfoWithStorage[127.0.0.1:38334,DS-fcbf105d-00d4-4741-9b02-a225f3a4523b,DISK], DatanodeInfoWithStorage[127.0.0.1:34882,DS-c7d20fca-6ea7-43da-baa2-b9b0359709fa,DISK], DatanodeInfoWithStorage[127.0.0.1:32850,DS-fc1fb1bb-cda6-41b2-8d5b-b4b005e56b93,DISK], DatanodeInfoWithStorage[127.0.0.1:43356,DS-f15b9b13-db7a-4478-8431-107fee9759bb,DISK], DatanodeInfoWithStorage[127.0.0.1:40330,DS-50272608-04c0-457e-85c7-b653f0490057,DISK], DatanodeInfoWithStorage[127.0.0.1:36928,DS-c21482cc-b42a-4b73-b11c-99b91ea860fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-869894155-172.17.0.6-1598133828133:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46609,DS-e9a9b7fc-a651-481f-843a-83ff77d241c6,DISK], DatanodeInfoWithStorage[127.0.0.1:43781,DS-a0da0d04-652c-4571-8ca3-c975ae6223f3,DISK], DatanodeInfoWithStorage[127.0.0.1:38334,DS-fcbf105d-00d4-4741-9b02-a225f3a4523b,DISK], DatanodeInfoWithStorage[127.0.0.1:34882,DS-c7d20fca-6ea7-43da-baa2-b9b0359709fa,DISK], DatanodeInfoWithStorage[127.0.0.1:32850,DS-fc1fb1bb-cda6-41b2-8d5b-b4b005e56b93,DISK], DatanodeInfoWithStorage[127.0.0.1:43356,DS-f15b9b13-db7a-4478-8431-107fee9759bb,DISK], DatanodeInfoWithStorage[127.0.0.1:40330,DS-50272608-04c0-457e-85c7-b653f0490057,DISK], DatanodeInfoWithStorage[127.0.0.1:36928,DS-c21482cc-b42a-4b73-b11c-99b91ea860fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-396090171-172.17.0.6-1598133856633:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45989,DS-4bdb0b34-55ea-484b-94b2-1a4b87be80b1,DISK], DatanodeInfoWithStorage[127.0.0.1:36841,DS-337deffd-6140-44a7-a185-9a9b7662abfd,DISK], DatanodeInfoWithStorage[127.0.0.1:42186,DS-24bfcbad-5e8e-4503-bb4b-31a420375c1a,DISK], DatanodeInfoWithStorage[127.0.0.1:42062,DS-490610b2-6d3b-4358-9130-4da1553b156b,DISK], DatanodeInfoWithStorage[127.0.0.1:36676,DS-36fa074a-ae18-4969-89a4-4ae5804f550c,DISK], DatanodeInfoWithStorage[127.0.0.1:38704,DS-b8e79771-65f1-4a42-9f54-332f1b7cb432,DISK], DatanodeInfoWithStorage[127.0.0.1:40305,DS-e0d6883b-c9f2-4d5a-b0af-570efa22dc99,DISK], DatanodeInfoWithStorage[127.0.0.1:42017,DS-2b3aedce-b384-49fc-a1da-35b845edd863,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-396090171-172.17.0.6-1598133856633:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45989,DS-4bdb0b34-55ea-484b-94b2-1a4b87be80b1,DISK], DatanodeInfoWithStorage[127.0.0.1:36841,DS-337deffd-6140-44a7-a185-9a9b7662abfd,DISK], DatanodeInfoWithStorage[127.0.0.1:42186,DS-24bfcbad-5e8e-4503-bb4b-31a420375c1a,DISK], DatanodeInfoWithStorage[127.0.0.1:42062,DS-490610b2-6d3b-4358-9130-4da1553b156b,DISK], DatanodeInfoWithStorage[127.0.0.1:36676,DS-36fa074a-ae18-4969-89a4-4ae5804f550c,DISK], DatanodeInfoWithStorage[127.0.0.1:38704,DS-b8e79771-65f1-4a42-9f54-332f1b7cb432,DISK], DatanodeInfoWithStorage[127.0.0.1:40305,DS-e0d6883b-c9f2-4d5a-b0af-570efa22dc99,DISK], DatanodeInfoWithStorage[127.0.0.1:42017,DS-2b3aedce-b384-49fc-a1da-35b845edd863,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5191
