reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1911728125-172.17.0.18-1598425581121:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37776,DS-fb2ef2c6-b256-49ff-8dbb-41c8b914b737,DISK], DatanodeInfoWithStorage[127.0.0.1:35932,DS-9cae90ad-f841-43bf-9440-54e58704f42c,DISK], DatanodeInfoWithStorage[127.0.0.1:40728,DS-bc6442ff-0838-4025-b520-e6bddddb1773,DISK], DatanodeInfoWithStorage[127.0.0.1:43991,DS-e6d3d3df-5598-418f-84b2-823e0d18bb71,DISK], DatanodeInfoWithStorage[127.0.0.1:46103,DS-da413f7a-1d95-418a-a6fd-9e2bf2bc9dd6,DISK], DatanodeInfoWithStorage[127.0.0.1:34141,DS-5df41b63-bdb9-46d9-9afd-6f5e72c4a56d,DISK], DatanodeInfoWithStorage[127.0.0.1:41667,DS-ab5bc9c2-ac33-4af8-9f01-bafca1778483,DISK], DatanodeInfoWithStorage[127.0.0.1:37142,DS-696322a7-e263-4520-a80d-89a63a4d9d21,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1911728125-172.17.0.18-1598425581121:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37776,DS-fb2ef2c6-b256-49ff-8dbb-41c8b914b737,DISK], DatanodeInfoWithStorage[127.0.0.1:35932,DS-9cae90ad-f841-43bf-9440-54e58704f42c,DISK], DatanodeInfoWithStorage[127.0.0.1:40728,DS-bc6442ff-0838-4025-b520-e6bddddb1773,DISK], DatanodeInfoWithStorage[127.0.0.1:43991,DS-e6d3d3df-5598-418f-84b2-823e0d18bb71,DISK], DatanodeInfoWithStorage[127.0.0.1:46103,DS-da413f7a-1d95-418a-a6fd-9e2bf2bc9dd6,DISK], DatanodeInfoWithStorage[127.0.0.1:34141,DS-5df41b63-bdb9-46d9-9afd-6f5e72c4a56d,DISK], DatanodeInfoWithStorage[127.0.0.1:41667,DS-ab5bc9c2-ac33-4af8-9f01-bafca1778483,DISK], DatanodeInfoWithStorage[127.0.0.1:37142,DS-696322a7-e263-4520-a80d-89a63a4d9d21,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-685310923-172.17.0.18-1598425833026:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38164,DS-93c882a0-85f6-4c7d-a1ed-9e2ba6b36fa6,DISK], DatanodeInfoWithStorage[127.0.0.1:45937,DS-5fcfa9a0-fc9e-4122-8c79-ce10c9c04b67,DISK], DatanodeInfoWithStorage[127.0.0.1:45942,DS-24525eb7-fa59-4d74-be61-ef134972a42c,DISK], DatanodeInfoWithStorage[127.0.0.1:37153,DS-700a4f98-fd93-428f-945a-ccd1fba69c38,DISK], DatanodeInfoWithStorage[127.0.0.1:39426,DS-00dbb171-4a01-4b5c-8bc6-ee74d2490ff9,DISK], DatanodeInfoWithStorage[127.0.0.1:33582,DS-b29c3cdd-0c25-4c1f-8d25-53d0e859b6bd,DISK], DatanodeInfoWithStorage[127.0.0.1:36543,DS-27cb152c-d20e-42b6-a352-e5a1ebceb20b,DISK], DatanodeInfoWithStorage[127.0.0.1:33494,DS-792163c2-f883-4394-b420-b33dc2fdde66,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-685310923-172.17.0.18-1598425833026:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38164,DS-93c882a0-85f6-4c7d-a1ed-9e2ba6b36fa6,DISK], DatanodeInfoWithStorage[127.0.0.1:45937,DS-5fcfa9a0-fc9e-4122-8c79-ce10c9c04b67,DISK], DatanodeInfoWithStorage[127.0.0.1:45942,DS-24525eb7-fa59-4d74-be61-ef134972a42c,DISK], DatanodeInfoWithStorage[127.0.0.1:37153,DS-700a4f98-fd93-428f-945a-ccd1fba69c38,DISK], DatanodeInfoWithStorage[127.0.0.1:39426,DS-00dbb171-4a01-4b5c-8bc6-ee74d2490ff9,DISK], DatanodeInfoWithStorage[127.0.0.1:33582,DS-b29c3cdd-0c25-4c1f-8d25-53d0e859b6bd,DISK], DatanodeInfoWithStorage[127.0.0.1:36543,DS-27cb152c-d20e-42b6-a352-e5a1ebceb20b,DISK], DatanodeInfoWithStorage[127.0.0.1:33494,DS-792163c2-f883-4394-b420-b33dc2fdde66,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-217886407-172.17.0.18-1598426055263:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42067,DS-8c4d81b0-3515-45ae-8f5f-3fd09a94d821,DISK], DatanodeInfoWithStorage[127.0.0.1:41990,DS-633103e5-a9af-4267-90f2-c1a189fed8cf,DISK], DatanodeInfoWithStorage[127.0.0.1:43423,DS-97a32a16-b287-4b88-a100-b138ee7cd23b,DISK], DatanodeInfoWithStorage[127.0.0.1:45854,DS-c2ba3944-d075-438d-a0e0-c9f4bdbeae7a,DISK], DatanodeInfoWithStorage[127.0.0.1:33194,DS-72f0e3b3-251e-4a9f-bbd3-1400612212a7,DISK], DatanodeInfoWithStorage[127.0.0.1:40341,DS-441de6b2-2200-4cb7-8d31-d99afbf85418,DISK], DatanodeInfoWithStorage[127.0.0.1:36497,DS-7399fea1-4a53-40e4-8655-6a7f7f25330a,DISK], DatanodeInfoWithStorage[127.0.0.1:33742,DS-8e769613-b65f-4620-99f7-dab7840d7b32,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-217886407-172.17.0.18-1598426055263:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42067,DS-8c4d81b0-3515-45ae-8f5f-3fd09a94d821,DISK], DatanodeInfoWithStorage[127.0.0.1:41990,DS-633103e5-a9af-4267-90f2-c1a189fed8cf,DISK], DatanodeInfoWithStorage[127.0.0.1:43423,DS-97a32a16-b287-4b88-a100-b138ee7cd23b,DISK], DatanodeInfoWithStorage[127.0.0.1:45854,DS-c2ba3944-d075-438d-a0e0-c9f4bdbeae7a,DISK], DatanodeInfoWithStorage[127.0.0.1:33194,DS-72f0e3b3-251e-4a9f-bbd3-1400612212a7,DISK], DatanodeInfoWithStorage[127.0.0.1:40341,DS-441de6b2-2200-4cb7-8d31-d99afbf85418,DISK], DatanodeInfoWithStorage[127.0.0.1:36497,DS-7399fea1-4a53-40e4-8655-6a7f7f25330a,DISK], DatanodeInfoWithStorage[127.0.0.1:33742,DS-8e769613-b65f-4620-99f7-dab7840d7b32,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1023130602-172.17.0.18-1598426117653:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44195,DS-f9bc2e31-ebce-45ec-8188-548fac978994,DISK], DatanodeInfoWithStorage[127.0.0.1:34279,DS-1595d55d-33a5-4555-b7b4-40e28dd85f1d,DISK], DatanodeInfoWithStorage[127.0.0.1:43185,DS-4a1b17ad-2b87-4775-b98b-6d325237c87e,DISK], DatanodeInfoWithStorage[127.0.0.1:33375,DS-c54e9493-8a15-4b62-bf4a-08b77167723b,DISK], DatanodeInfoWithStorage[127.0.0.1:34557,DS-18a2fda7-6bdb-429c-9a0f-614c12571bed,DISK], DatanodeInfoWithStorage[127.0.0.1:33206,DS-36713dd3-a1ca-48da-9559-b438c9aaaee3,DISK], DatanodeInfoWithStorage[127.0.0.1:43335,DS-c5eb9594-14ca-4e53-a354-492023bf3a06,DISK], DatanodeInfoWithStorage[127.0.0.1:36833,DS-ef46c778-351b-49db-a243-555c5c6af8c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1023130602-172.17.0.18-1598426117653:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44195,DS-f9bc2e31-ebce-45ec-8188-548fac978994,DISK], DatanodeInfoWithStorage[127.0.0.1:34279,DS-1595d55d-33a5-4555-b7b4-40e28dd85f1d,DISK], DatanodeInfoWithStorage[127.0.0.1:43185,DS-4a1b17ad-2b87-4775-b98b-6d325237c87e,DISK], DatanodeInfoWithStorage[127.0.0.1:33375,DS-c54e9493-8a15-4b62-bf4a-08b77167723b,DISK], DatanodeInfoWithStorage[127.0.0.1:34557,DS-18a2fda7-6bdb-429c-9a0f-614c12571bed,DISK], DatanodeInfoWithStorage[127.0.0.1:33206,DS-36713dd3-a1ca-48da-9559-b438c9aaaee3,DISK], DatanodeInfoWithStorage[127.0.0.1:43335,DS-c5eb9594-14ca-4e53-a354-492023bf3a06,DISK], DatanodeInfoWithStorage[127.0.0.1:36833,DS-ef46c778-351b-49db-a243-555c5c6af8c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1296854437-172.17.0.18-1598426254724:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46589,DS-8bf4a748-01bc-4a6c-a8ea-479772aa115a,DISK], DatanodeInfoWithStorage[127.0.0.1:35595,DS-fe84e116-fcdc-443f-ba63-c9b02f91c36d,DISK], DatanodeInfoWithStorage[127.0.0.1:35365,DS-83c6efd9-4e63-41a3-ad2c-35f930e864ac,DISK], DatanodeInfoWithStorage[127.0.0.1:36176,DS-0f1dca92-5126-4b20-99cd-e2386c28e157,DISK], DatanodeInfoWithStorage[127.0.0.1:37859,DS-2b31416a-9b6d-46a0-9a76-034519a96f90,DISK], DatanodeInfoWithStorage[127.0.0.1:45679,DS-5b859917-a52e-4424-aa69-4f3caf12c8cb,DISK], DatanodeInfoWithStorage[127.0.0.1:39906,DS-c816fc60-fff4-4cee-a679-f7bdb9071137,DISK], DatanodeInfoWithStorage[127.0.0.1:35212,DS-49e6aea5-c39f-4dd3-927f-79d8d7da2218,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1296854437-172.17.0.18-1598426254724:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46589,DS-8bf4a748-01bc-4a6c-a8ea-479772aa115a,DISK], DatanodeInfoWithStorage[127.0.0.1:35595,DS-fe84e116-fcdc-443f-ba63-c9b02f91c36d,DISK], DatanodeInfoWithStorage[127.0.0.1:35365,DS-83c6efd9-4e63-41a3-ad2c-35f930e864ac,DISK], DatanodeInfoWithStorage[127.0.0.1:36176,DS-0f1dca92-5126-4b20-99cd-e2386c28e157,DISK], DatanodeInfoWithStorage[127.0.0.1:37859,DS-2b31416a-9b6d-46a0-9a76-034519a96f90,DISK], DatanodeInfoWithStorage[127.0.0.1:45679,DS-5b859917-a52e-4424-aa69-4f3caf12c8cb,DISK], DatanodeInfoWithStorage[127.0.0.1:39906,DS-c816fc60-fff4-4cee-a679-f7bdb9071137,DISK], DatanodeInfoWithStorage[127.0.0.1:35212,DS-49e6aea5-c39f-4dd3-927f-79d8d7da2218,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-760235250-172.17.0.18-1598426282440:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44563,DS-306164cb-da2d-4614-bf77-4bbe2f446ad1,DISK], DatanodeInfoWithStorage[127.0.0.1:33290,DS-21bc928c-8cea-4bbe-bd2b-080ce8f7ed97,DISK], DatanodeInfoWithStorage[127.0.0.1:33179,DS-dafd72ff-b334-404e-ab3b-fd56dddf601b,DISK], DatanodeInfoWithStorage[127.0.0.1:42570,DS-e626ce84-af02-49c1-859f-47ecc1d07f60,DISK], DatanodeInfoWithStorage[127.0.0.1:35786,DS-43a8fe24-52b9-46fb-bce1-6483e9bafe8e,DISK], DatanodeInfoWithStorage[127.0.0.1:34132,DS-931e0abd-418c-4fad-85a0-2fa6684819e2,DISK], DatanodeInfoWithStorage[127.0.0.1:39110,DS-91f93a6d-d088-4c67-8b01-5e307b742373,DISK], DatanodeInfoWithStorage[127.0.0.1:44725,DS-ad693574-7582-4608-b768-8e7519a63b04,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-760235250-172.17.0.18-1598426282440:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44563,DS-306164cb-da2d-4614-bf77-4bbe2f446ad1,DISK], DatanodeInfoWithStorage[127.0.0.1:33290,DS-21bc928c-8cea-4bbe-bd2b-080ce8f7ed97,DISK], DatanodeInfoWithStorage[127.0.0.1:33179,DS-dafd72ff-b334-404e-ab3b-fd56dddf601b,DISK], DatanodeInfoWithStorage[127.0.0.1:42570,DS-e626ce84-af02-49c1-859f-47ecc1d07f60,DISK], DatanodeInfoWithStorage[127.0.0.1:35786,DS-43a8fe24-52b9-46fb-bce1-6483e9bafe8e,DISK], DatanodeInfoWithStorage[127.0.0.1:34132,DS-931e0abd-418c-4fad-85a0-2fa6684819e2,DISK], DatanodeInfoWithStorage[127.0.0.1:39110,DS-91f93a6d-d088-4c67-8b01-5e307b742373,DISK], DatanodeInfoWithStorage[127.0.0.1:44725,DS-ad693574-7582-4608-b768-8e7519a63b04,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-325102729-172.17.0.18-1598426898681:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45063,DS-b1597741-1092-4b81-87ac-6c2eedb95bef,DISK], DatanodeInfoWithStorage[127.0.0.1:38366,DS-ecffb2fc-fa5a-4558-8a3e-0042a2b90509,DISK], DatanodeInfoWithStorage[127.0.0.1:36596,DS-3a75f89e-444c-4d55-8f35-956a1c00b9dc,DISK], DatanodeInfoWithStorage[127.0.0.1:43077,DS-c07a895e-91af-4988-806e-345a7b5f111c,DISK], DatanodeInfoWithStorage[127.0.0.1:45876,DS-4d946e7c-076c-42fd-a772-30c934a293d4,DISK], DatanodeInfoWithStorage[127.0.0.1:34984,DS-5735546b-932a-4abe-a2d1-002726cd1738,DISK], DatanodeInfoWithStorage[127.0.0.1:44082,DS-c63c6b7d-2d9b-40a2-ab8f-e1c1470cb540,DISK], DatanodeInfoWithStorage[127.0.0.1:42229,DS-817ed587-a8a8-4482-a0a1-41b33595a23c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-325102729-172.17.0.18-1598426898681:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45063,DS-b1597741-1092-4b81-87ac-6c2eedb95bef,DISK], DatanodeInfoWithStorage[127.0.0.1:38366,DS-ecffb2fc-fa5a-4558-8a3e-0042a2b90509,DISK], DatanodeInfoWithStorage[127.0.0.1:36596,DS-3a75f89e-444c-4d55-8f35-956a1c00b9dc,DISK], DatanodeInfoWithStorage[127.0.0.1:43077,DS-c07a895e-91af-4988-806e-345a7b5f111c,DISK], DatanodeInfoWithStorage[127.0.0.1:45876,DS-4d946e7c-076c-42fd-a772-30c934a293d4,DISK], DatanodeInfoWithStorage[127.0.0.1:34984,DS-5735546b-932a-4abe-a2d1-002726cd1738,DISK], DatanodeInfoWithStorage[127.0.0.1:44082,DS-c63c6b7d-2d9b-40a2-ab8f-e1c1470cb540,DISK], DatanodeInfoWithStorage[127.0.0.1:42229,DS-817ed587-a8a8-4482-a0a1-41b33595a23c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-258208073-172.17.0.18-1598427334638:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39037,DS-bfa7ca8a-fa64-4672-9197-99f604d5441d,DISK], DatanodeInfoWithStorage[127.0.0.1:38729,DS-0acde9f8-b9eb-44c4-9b74-a9608f6d8f99,DISK], DatanodeInfoWithStorage[127.0.0.1:36766,DS-4fbd7d4f-af09-4c30-b816-5ff374ccdde6,DISK], DatanodeInfoWithStorage[127.0.0.1:37750,DS-f39cb7a9-9a74-4803-97a4-8650bf32924b,DISK], DatanodeInfoWithStorage[127.0.0.1:41177,DS-b8451414-d680-46d8-a6e1-753ee6e45b19,DISK], DatanodeInfoWithStorage[127.0.0.1:44401,DS-b8e98c83-12b1-49ab-b9aa-8fc8ddcbe636,DISK], DatanodeInfoWithStorage[127.0.0.1:37469,DS-cc0691cc-af7b-477f-a543-ef0330b41420,DISK], DatanodeInfoWithStorage[127.0.0.1:46855,DS-27a38fed-a31f-496c-ae87-95453a68fe69,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-258208073-172.17.0.18-1598427334638:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39037,DS-bfa7ca8a-fa64-4672-9197-99f604d5441d,DISK], DatanodeInfoWithStorage[127.0.0.1:38729,DS-0acde9f8-b9eb-44c4-9b74-a9608f6d8f99,DISK], DatanodeInfoWithStorage[127.0.0.1:36766,DS-4fbd7d4f-af09-4c30-b816-5ff374ccdde6,DISK], DatanodeInfoWithStorage[127.0.0.1:37750,DS-f39cb7a9-9a74-4803-97a4-8650bf32924b,DISK], DatanodeInfoWithStorage[127.0.0.1:41177,DS-b8451414-d680-46d8-a6e1-753ee6e45b19,DISK], DatanodeInfoWithStorage[127.0.0.1:44401,DS-b8e98c83-12b1-49ab-b9aa-8fc8ddcbe636,DISK], DatanodeInfoWithStorage[127.0.0.1:37469,DS-cc0691cc-af7b-477f-a543-ef0330b41420,DISK], DatanodeInfoWithStorage[127.0.0.1:46855,DS-27a38fed-a31f-496c-ae87-95453a68fe69,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-449597134-172.17.0.18-1598428564033:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42012,DS-5efbeb37-d01f-4be6-ae0a-441d8341db76,DISK], DatanodeInfoWithStorage[127.0.0.1:43532,DS-579b7555-7f3b-4f21-bdb6-67a793b1b16c,DISK], DatanodeInfoWithStorage[127.0.0.1:44233,DS-55a8a877-dd67-49f7-a9be-b355fefe8f19,DISK], DatanodeInfoWithStorage[127.0.0.1:39129,DS-68234ff7-f238-4b95-bc60-e7eec3bf7bae,DISK], DatanodeInfoWithStorage[127.0.0.1:42287,DS-7c39d7d6-b032-4189-a6be-9e90c1f14833,DISK], DatanodeInfoWithStorage[127.0.0.1:40372,DS-619a14fb-6d44-4739-b46e-11c32fe286c2,DISK], DatanodeInfoWithStorage[127.0.0.1:40957,DS-e62b0e68-74f0-4bfa-94cf-f1de84182f61,DISK], DatanodeInfoWithStorage[127.0.0.1:45884,DS-756c1183-9359-497b-b5ef-46f4afa3ac33,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-449597134-172.17.0.18-1598428564033:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42012,DS-5efbeb37-d01f-4be6-ae0a-441d8341db76,DISK], DatanodeInfoWithStorage[127.0.0.1:43532,DS-579b7555-7f3b-4f21-bdb6-67a793b1b16c,DISK], DatanodeInfoWithStorage[127.0.0.1:44233,DS-55a8a877-dd67-49f7-a9be-b355fefe8f19,DISK], DatanodeInfoWithStorage[127.0.0.1:39129,DS-68234ff7-f238-4b95-bc60-e7eec3bf7bae,DISK], DatanodeInfoWithStorage[127.0.0.1:42287,DS-7c39d7d6-b032-4189-a6be-9e90c1f14833,DISK], DatanodeInfoWithStorage[127.0.0.1:40372,DS-619a14fb-6d44-4739-b46e-11c32fe286c2,DISK], DatanodeInfoWithStorage[127.0.0.1:40957,DS-e62b0e68-74f0-4bfa-94cf-f1de84182f61,DISK], DatanodeInfoWithStorage[127.0.0.1:45884,DS-756c1183-9359-497b-b5ef-46f4afa3ac33,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-377440266-172.17.0.18-1598429321471:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33600,DS-edcf1edd-cf57-487a-8386-d50c35e2cbac,DISK], DatanodeInfoWithStorage[127.0.0.1:33416,DS-f8636b2f-3d07-495b-ab8d-14fb22c60bb2,DISK], DatanodeInfoWithStorage[127.0.0.1:41493,DS-534c9346-6f87-4156-a554-9ea3f6ca888c,DISK], DatanodeInfoWithStorage[127.0.0.1:34297,DS-e1790a10-3035-488c-9ad3-e37bddd86008,DISK], DatanodeInfoWithStorage[127.0.0.1:44548,DS-980af8c4-0c31-4b0e-91a2-8a285cabc976,DISK], DatanodeInfoWithStorage[127.0.0.1:42664,DS-d757dec8-80db-4b9d-9ef6-f5c5f4142b77,DISK], DatanodeInfoWithStorage[127.0.0.1:33957,DS-c1f24d8e-e6d8-4826-96fc-482f2eae5477,DISK], DatanodeInfoWithStorage[127.0.0.1:38286,DS-41f36abf-0ab1-46e6-903b-97876cb13690,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-377440266-172.17.0.18-1598429321471:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33600,DS-edcf1edd-cf57-487a-8386-d50c35e2cbac,DISK], DatanodeInfoWithStorage[127.0.0.1:33416,DS-f8636b2f-3d07-495b-ab8d-14fb22c60bb2,DISK], DatanodeInfoWithStorage[127.0.0.1:41493,DS-534c9346-6f87-4156-a554-9ea3f6ca888c,DISK], DatanodeInfoWithStorage[127.0.0.1:34297,DS-e1790a10-3035-488c-9ad3-e37bddd86008,DISK], DatanodeInfoWithStorage[127.0.0.1:44548,DS-980af8c4-0c31-4b0e-91a2-8a285cabc976,DISK], DatanodeInfoWithStorage[127.0.0.1:42664,DS-d757dec8-80db-4b9d-9ef6-f5c5f4142b77,DISK], DatanodeInfoWithStorage[127.0.0.1:33957,DS-c1f24d8e-e6d8-4826-96fc-482f2eae5477,DISK], DatanodeInfoWithStorage[127.0.0.1:38286,DS-41f36abf-0ab1-46e6-903b-97876cb13690,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 5 out of 50
result: false positive !!!
Total execution time in seconds : 5263
