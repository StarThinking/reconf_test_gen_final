reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.best-effort
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.best-effort
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1375184824-172.17.0.20-1598437534982:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46809,DS-c25ee07e-cc33-4bc1-b94c-dd000a6a344d,DISK], DatanodeInfoWithStorage[127.0.0.1:35542,DS-28b2a0b2-b0c3-49b8-8c44-717e2328e25e,DISK], DatanodeInfoWithStorage[127.0.0.1:41916,DS-d3f5cbff-0137-45c2-84b7-e4b5e7e1742a,DISK], DatanodeInfoWithStorage[127.0.0.1:42806,DS-03d904df-fd18-4513-9c09-31397d1363ec,DISK], DatanodeInfoWithStorage[127.0.0.1:44960,DS-6d9f9eba-0ff7-4e8b-a69b-1f794451bebc,DISK], DatanodeInfoWithStorage[127.0.0.1:36832,DS-3c70d9ee-40df-4e7b-910d-eebab2b4d694,DISK], DatanodeInfoWithStorage[127.0.0.1:45977,DS-150a7bfd-487b-45d0-90ab-bd60206dae6f,DISK], DatanodeInfoWithStorage[127.0.0.1:36720,DS-aa08ef1f-c9c0-407e-95bf-f3c15e895e67,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1375184824-172.17.0.20-1598437534982:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46809,DS-c25ee07e-cc33-4bc1-b94c-dd000a6a344d,DISK], DatanodeInfoWithStorage[127.0.0.1:35542,DS-28b2a0b2-b0c3-49b8-8c44-717e2328e25e,DISK], DatanodeInfoWithStorage[127.0.0.1:41916,DS-d3f5cbff-0137-45c2-84b7-e4b5e7e1742a,DISK], DatanodeInfoWithStorage[127.0.0.1:42806,DS-03d904df-fd18-4513-9c09-31397d1363ec,DISK], DatanodeInfoWithStorage[127.0.0.1:44960,DS-6d9f9eba-0ff7-4e8b-a69b-1f794451bebc,DISK], DatanodeInfoWithStorage[127.0.0.1:36832,DS-3c70d9ee-40df-4e7b-910d-eebab2b4d694,DISK], DatanodeInfoWithStorage[127.0.0.1:45977,DS-150a7bfd-487b-45d0-90ab-bd60206dae6f,DISK], DatanodeInfoWithStorage[127.0.0.1:36720,DS-aa08ef1f-c9c0-407e-95bf-f3c15e895e67,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.best-effort
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2011951269-172.17.0.20-1598437568055:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40038,DS-5e2d67fb-2771-417d-9251-4badd4cd1e6c,DISK], DatanodeInfoWithStorage[127.0.0.1:42249,DS-6c1d4e13-fe4a-404f-a836-34e2d43f6ea0,DISK], DatanodeInfoWithStorage[127.0.0.1:42175,DS-46f2b562-d122-4e6e-89b2-4dc5bc199559,DISK], DatanodeInfoWithStorage[127.0.0.1:43750,DS-f6f855f4-53a1-4f26-89fc-129919e85d4f,DISK], DatanodeInfoWithStorage[127.0.0.1:35965,DS-3c4615b2-61e7-4df8-8d3d-ed5f14320d0f,DISK], DatanodeInfoWithStorage[127.0.0.1:33308,DS-32128c94-8eda-4c87-9cc3-d77c3744d37c,DISK], DatanodeInfoWithStorage[127.0.0.1:45953,DS-52b398cf-15cc-40dd-84f9-e8b81c236255,DISK], DatanodeInfoWithStorage[127.0.0.1:36250,DS-fe925c51-31f3-4926-9ee5-43ccfd3a5f0e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2011951269-172.17.0.20-1598437568055:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40038,DS-5e2d67fb-2771-417d-9251-4badd4cd1e6c,DISK], DatanodeInfoWithStorage[127.0.0.1:42249,DS-6c1d4e13-fe4a-404f-a836-34e2d43f6ea0,DISK], DatanodeInfoWithStorage[127.0.0.1:42175,DS-46f2b562-d122-4e6e-89b2-4dc5bc199559,DISK], DatanodeInfoWithStorage[127.0.0.1:43750,DS-f6f855f4-53a1-4f26-89fc-129919e85d4f,DISK], DatanodeInfoWithStorage[127.0.0.1:35965,DS-3c4615b2-61e7-4df8-8d3d-ed5f14320d0f,DISK], DatanodeInfoWithStorage[127.0.0.1:33308,DS-32128c94-8eda-4c87-9cc3-d77c3744d37c,DISK], DatanodeInfoWithStorage[127.0.0.1:45953,DS-52b398cf-15cc-40dd-84f9-e8b81c236255,DISK], DatanodeInfoWithStorage[127.0.0.1:36250,DS-fe925c51-31f3-4926-9ee5-43ccfd3a5f0e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.best-effort
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1863996561-172.17.0.20-1598437906634:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37421,DS-fc109b8f-d09e-4ef2-a10b-99749cd872eb,DISK], DatanodeInfoWithStorage[127.0.0.1:46606,DS-bcd2dd34-e20b-4151-9326-b3653b684f64,DISK], DatanodeInfoWithStorage[127.0.0.1:34026,DS-e86a0722-476a-4ce4-ab5e-99e2b9ff4342,DISK], DatanodeInfoWithStorage[127.0.0.1:39932,DS-7acbd62b-7286-4179-a11f-62feb9ff7033,DISK], DatanodeInfoWithStorage[127.0.0.1:39142,DS-d7f22d0c-a798-4cca-b9c1-8a798c28308e,DISK], DatanodeInfoWithStorage[127.0.0.1:32837,DS-128bcdf2-d2f8-4aed-9473-d1f946c71b19,DISK], DatanodeInfoWithStorage[127.0.0.1:40347,DS-c410c362-ebf0-4091-85e0-4df2a35cd2d1,DISK], DatanodeInfoWithStorage[127.0.0.1:37046,DS-0c0fc626-75f3-4bb5-90c9-2c8b40c1a553,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1863996561-172.17.0.20-1598437906634:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37421,DS-fc109b8f-d09e-4ef2-a10b-99749cd872eb,DISK], DatanodeInfoWithStorage[127.0.0.1:46606,DS-bcd2dd34-e20b-4151-9326-b3653b684f64,DISK], DatanodeInfoWithStorage[127.0.0.1:34026,DS-e86a0722-476a-4ce4-ab5e-99e2b9ff4342,DISK], DatanodeInfoWithStorage[127.0.0.1:39932,DS-7acbd62b-7286-4179-a11f-62feb9ff7033,DISK], DatanodeInfoWithStorage[127.0.0.1:39142,DS-d7f22d0c-a798-4cca-b9c1-8a798c28308e,DISK], DatanodeInfoWithStorage[127.0.0.1:32837,DS-128bcdf2-d2f8-4aed-9473-d1f946c71b19,DISK], DatanodeInfoWithStorage[127.0.0.1:40347,DS-c410c362-ebf0-4091-85e0-4df2a35cd2d1,DISK], DatanodeInfoWithStorage[127.0.0.1:37046,DS-0c0fc626-75f3-4bb5-90c9-2c8b40c1a553,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.best-effort
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1135236438-172.17.0.20-1598437974351:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39130,DS-d0f60386-fba9-40c2-9179-a86f1d332304,DISK], DatanodeInfoWithStorage[127.0.0.1:36223,DS-dc0f8ef5-ffcd-4a14-9855-3b0bf7d5db16,DISK], DatanodeInfoWithStorage[127.0.0.1:33001,DS-a94f07ea-44e9-44e0-b139-3d5b0a2f5e34,DISK], DatanodeInfoWithStorage[127.0.0.1:35986,DS-27eb593f-4acb-4277-85c5-c6689bb3d921,DISK], DatanodeInfoWithStorage[127.0.0.1:41692,DS-e51119fa-532b-4a8d-be05-9d4e83af096f,DISK], DatanodeInfoWithStorage[127.0.0.1:44138,DS-90935b7b-8967-4010-a6be-b63dd4bf6836,DISK], DatanodeInfoWithStorage[127.0.0.1:42299,DS-9a90953a-f624-4476-8210-b411c1ec6915,DISK], DatanodeInfoWithStorage[127.0.0.1:39786,DS-5cd3c48d-6ce7-45fe-a205-b030dcb2b57b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1135236438-172.17.0.20-1598437974351:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39130,DS-d0f60386-fba9-40c2-9179-a86f1d332304,DISK], DatanodeInfoWithStorage[127.0.0.1:36223,DS-dc0f8ef5-ffcd-4a14-9855-3b0bf7d5db16,DISK], DatanodeInfoWithStorage[127.0.0.1:33001,DS-a94f07ea-44e9-44e0-b139-3d5b0a2f5e34,DISK], DatanodeInfoWithStorage[127.0.0.1:35986,DS-27eb593f-4acb-4277-85c5-c6689bb3d921,DISK], DatanodeInfoWithStorage[127.0.0.1:41692,DS-e51119fa-532b-4a8d-be05-9d4e83af096f,DISK], DatanodeInfoWithStorage[127.0.0.1:44138,DS-90935b7b-8967-4010-a6be-b63dd4bf6836,DISK], DatanodeInfoWithStorage[127.0.0.1:42299,DS-9a90953a-f624-4476-8210-b411c1ec6915,DISK], DatanodeInfoWithStorage[127.0.0.1:39786,DS-5cd3c48d-6ce7-45fe-a205-b030dcb2b57b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.best-effort
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-965718504-172.17.0.20-1598438113045:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34167,DS-f728c55b-1d16-4d85-97eb-fb898dbc2c96,DISK], DatanodeInfoWithStorage[127.0.0.1:40232,DS-2a6cb56e-0284-4264-bca9-345133b9cad7,DISK], DatanodeInfoWithStorage[127.0.0.1:44562,DS-34b94fc5-e73e-46ca-81f0-c1f7afedb21d,DISK], DatanodeInfoWithStorage[127.0.0.1:43008,DS-9bed0a22-d551-4899-a3f1-790a658eacfd,DISK], DatanodeInfoWithStorage[127.0.0.1:46660,DS-748f0085-25a7-4c1c-8503-db68eab05975,DISK], DatanodeInfoWithStorage[127.0.0.1:41852,DS-0ced37be-dd99-40c2-a885-11f957f05c77,DISK], DatanodeInfoWithStorage[127.0.0.1:33555,DS-ad375a2c-3ce1-4d46-8b8a-478810760470,DISK], DatanodeInfoWithStorage[127.0.0.1:36420,DS-fbad88aa-0c16-4207-ad44-fb6f1e3a102d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-965718504-172.17.0.20-1598438113045:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34167,DS-f728c55b-1d16-4d85-97eb-fb898dbc2c96,DISK], DatanodeInfoWithStorage[127.0.0.1:40232,DS-2a6cb56e-0284-4264-bca9-345133b9cad7,DISK], DatanodeInfoWithStorage[127.0.0.1:44562,DS-34b94fc5-e73e-46ca-81f0-c1f7afedb21d,DISK], DatanodeInfoWithStorage[127.0.0.1:43008,DS-9bed0a22-d551-4899-a3f1-790a658eacfd,DISK], DatanodeInfoWithStorage[127.0.0.1:46660,DS-748f0085-25a7-4c1c-8503-db68eab05975,DISK], DatanodeInfoWithStorage[127.0.0.1:41852,DS-0ced37be-dd99-40c2-a885-11f957f05c77,DISK], DatanodeInfoWithStorage[127.0.0.1:33555,DS-ad375a2c-3ce1-4d46-8b8a-478810760470,DISK], DatanodeInfoWithStorage[127.0.0.1:36420,DS-fbad88aa-0c16-4207-ad44-fb6f1e3a102d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.best-effort
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-851546138-172.17.0.20-1598438221845:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44243,DS-04eb3aec-60ff-4e19-bd2f-12842cc2e664,DISK], DatanodeInfoWithStorage[127.0.0.1:41142,DS-46bc44b8-5bae-418b-a34a-66106e53affa,DISK], DatanodeInfoWithStorage[127.0.0.1:37437,DS-8276b870-4140-4c48-bb70-75be183a993c,DISK], DatanodeInfoWithStorage[127.0.0.1:38807,DS-5fe3d2e5-ebbc-45a5-8970-b686d0b9b12d,DISK], DatanodeInfoWithStorage[127.0.0.1:33745,DS-6c5e42e7-19c8-4e3e-bae8-1b8bdba4d83a,DISK], DatanodeInfoWithStorage[127.0.0.1:35920,DS-b5318478-c62c-49b6-b426-19a12bfbdb4f,DISK], DatanodeInfoWithStorage[127.0.0.1:43003,DS-5c91a8bd-3271-4c09-a588-beb7397b3c6e,DISK], DatanodeInfoWithStorage[127.0.0.1:45794,DS-35b62aca-149c-489a-a6c3-88058508dbb2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-851546138-172.17.0.20-1598438221845:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44243,DS-04eb3aec-60ff-4e19-bd2f-12842cc2e664,DISK], DatanodeInfoWithStorage[127.0.0.1:41142,DS-46bc44b8-5bae-418b-a34a-66106e53affa,DISK], DatanodeInfoWithStorage[127.0.0.1:37437,DS-8276b870-4140-4c48-bb70-75be183a993c,DISK], DatanodeInfoWithStorage[127.0.0.1:38807,DS-5fe3d2e5-ebbc-45a5-8970-b686d0b9b12d,DISK], DatanodeInfoWithStorage[127.0.0.1:33745,DS-6c5e42e7-19c8-4e3e-bae8-1b8bdba4d83a,DISK], DatanodeInfoWithStorage[127.0.0.1:35920,DS-b5318478-c62c-49b6-b426-19a12bfbdb4f,DISK], DatanodeInfoWithStorage[127.0.0.1:43003,DS-5c91a8bd-3271-4c09-a588-beb7397b3c6e,DISK], DatanodeInfoWithStorage[127.0.0.1:45794,DS-35b62aca-149c-489a-a6c3-88058508dbb2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.best-effort
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-396717969-172.17.0.20-1598438293990:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40805,DS-7bc24f6a-6028-4276-a436-c26570cbd799,DISK], DatanodeInfoWithStorage[127.0.0.1:35496,DS-110a8f27-7598-401b-a5bd-5d82d552ced9,DISK], DatanodeInfoWithStorage[127.0.0.1:43736,DS-5950a1c6-87d3-4158-b0e7-e35a9cab4dcb,DISK], DatanodeInfoWithStorage[127.0.0.1:35698,DS-a709d72a-f0c6-4293-87ab-d94fc52036bc,DISK], DatanodeInfoWithStorage[127.0.0.1:45444,DS-b804543c-ee6f-42ab-b89b-45e2f4e501d8,DISK], DatanodeInfoWithStorage[127.0.0.1:37202,DS-80ca6fb3-88f1-4048-8f62-444708a2c2e9,DISK], DatanodeInfoWithStorage[127.0.0.1:37553,DS-8cef86ed-6bcf-46c6-8ee1-4023bf6c9b79,DISK], DatanodeInfoWithStorage[127.0.0.1:45904,DS-c118a5bf-5566-424d-97df-da897fc687b2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-396717969-172.17.0.20-1598438293990:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40805,DS-7bc24f6a-6028-4276-a436-c26570cbd799,DISK], DatanodeInfoWithStorage[127.0.0.1:35496,DS-110a8f27-7598-401b-a5bd-5d82d552ced9,DISK], DatanodeInfoWithStorage[127.0.0.1:43736,DS-5950a1c6-87d3-4158-b0e7-e35a9cab4dcb,DISK], DatanodeInfoWithStorage[127.0.0.1:35698,DS-a709d72a-f0c6-4293-87ab-d94fc52036bc,DISK], DatanodeInfoWithStorage[127.0.0.1:45444,DS-b804543c-ee6f-42ab-b89b-45e2f4e501d8,DISK], DatanodeInfoWithStorage[127.0.0.1:37202,DS-80ca6fb3-88f1-4048-8f62-444708a2c2e9,DISK], DatanodeInfoWithStorage[127.0.0.1:37553,DS-8cef86ed-6bcf-46c6-8ee1-4023bf6c9b79,DISK], DatanodeInfoWithStorage[127.0.0.1:45904,DS-c118a5bf-5566-424d-97df-da897fc687b2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.best-effort
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1805716806-172.17.0.20-1598438433858:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37924,DS-604b377c-a3da-47bd-862f-b82c75503dc2,DISK], DatanodeInfoWithStorage[127.0.0.1:40162,DS-bbdde4f1-9fbb-4814-b16e-c8e0db537b4b,DISK], DatanodeInfoWithStorage[127.0.0.1:37867,DS-bf6eb7b6-b18f-41af-8977-b1771344aa7c,DISK], DatanodeInfoWithStorage[127.0.0.1:45303,DS-a511ec0e-3b32-42d3-a80d-bc2e082a58b4,DISK], DatanodeInfoWithStorage[127.0.0.1:37011,DS-6d0fb5ab-b6be-4d4a-b8ee-3df9a3fc04df,DISK], DatanodeInfoWithStorage[127.0.0.1:46776,DS-069ffa06-5c61-4e10-be94-b09f41e85a70,DISK], DatanodeInfoWithStorage[127.0.0.1:32869,DS-2ca062cf-62f6-48d1-b7ac-e60ec8f18b36,DISK], DatanodeInfoWithStorage[127.0.0.1:41633,DS-ddb96bdd-4024-4438-a73b-936b659ec4ac,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1805716806-172.17.0.20-1598438433858:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37924,DS-604b377c-a3da-47bd-862f-b82c75503dc2,DISK], DatanodeInfoWithStorage[127.0.0.1:40162,DS-bbdde4f1-9fbb-4814-b16e-c8e0db537b4b,DISK], DatanodeInfoWithStorage[127.0.0.1:37867,DS-bf6eb7b6-b18f-41af-8977-b1771344aa7c,DISK], DatanodeInfoWithStorage[127.0.0.1:45303,DS-a511ec0e-3b32-42d3-a80d-bc2e082a58b4,DISK], DatanodeInfoWithStorage[127.0.0.1:37011,DS-6d0fb5ab-b6be-4d4a-b8ee-3df9a3fc04df,DISK], DatanodeInfoWithStorage[127.0.0.1:46776,DS-069ffa06-5c61-4e10-be94-b09f41e85a70,DISK], DatanodeInfoWithStorage[127.0.0.1:32869,DS-2ca062cf-62f6-48d1-b7ac-e60ec8f18b36,DISK], DatanodeInfoWithStorage[127.0.0.1:41633,DS-ddb96bdd-4024-4438-a73b-936b659ec4ac,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.best-effort
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-95853472-172.17.0.20-1598438612960:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41448,DS-a74c114a-00a6-4806-a29d-9a462cc710a4,DISK], DatanodeInfoWithStorage[127.0.0.1:41057,DS-95ae4019-b11d-4d72-949d-4dd2b4fc5f6b,DISK], DatanodeInfoWithStorage[127.0.0.1:44621,DS-21044bf3-822c-48fb-b93b-dde38818d10a,DISK], DatanodeInfoWithStorage[127.0.0.1:46726,DS-ec8833c1-ec28-4a2c-9830-0c11923ab508,DISK], DatanodeInfoWithStorage[127.0.0.1:42254,DS-d7829995-03d3-48ef-9715-97798fabaa8d,DISK], DatanodeInfoWithStorage[127.0.0.1:39170,DS-3b328749-5818-4148-933f-c2d88ac4622f,DISK], DatanodeInfoWithStorage[127.0.0.1:37374,DS-a87cc97d-8580-4c6c-a220-d24e27cbfcec,DISK], DatanodeInfoWithStorage[127.0.0.1:37351,DS-bd2f14f7-0da5-48c6-9336-62dc752d54f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-95853472-172.17.0.20-1598438612960:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41448,DS-a74c114a-00a6-4806-a29d-9a462cc710a4,DISK], DatanodeInfoWithStorage[127.0.0.1:41057,DS-95ae4019-b11d-4d72-949d-4dd2b4fc5f6b,DISK], DatanodeInfoWithStorage[127.0.0.1:44621,DS-21044bf3-822c-48fb-b93b-dde38818d10a,DISK], DatanodeInfoWithStorage[127.0.0.1:46726,DS-ec8833c1-ec28-4a2c-9830-0c11923ab508,DISK], DatanodeInfoWithStorage[127.0.0.1:42254,DS-d7829995-03d3-48ef-9715-97798fabaa8d,DISK], DatanodeInfoWithStorage[127.0.0.1:39170,DS-3b328749-5818-4148-933f-c2d88ac4622f,DISK], DatanodeInfoWithStorage[127.0.0.1:37374,DS-a87cc97d-8580-4c6c-a220-d24e27cbfcec,DISK], DatanodeInfoWithStorage[127.0.0.1:37351,DS-bd2f14f7-0da5-48c6-9336-62dc752d54f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.best-effort
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-919840032-172.17.0.20-1598439038737:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37968,DS-2710369a-4739-424c-8ee0-cd6e4a71e1b6,DISK], DatanodeInfoWithStorage[127.0.0.1:33980,DS-18e127f0-7aa8-4b2d-a3bf-7bbe897d8121,DISK], DatanodeInfoWithStorage[127.0.0.1:35012,DS-6bbd1a87-38f1-4320-8123-7b2130bb8c8c,DISK], DatanodeInfoWithStorage[127.0.0.1:35445,DS-dd37093a-bf44-40a8-8927-c3bf6b3a6cac,DISK], DatanodeInfoWithStorage[127.0.0.1:45932,DS-69a8e938-7267-40a9-98ef-6a4722c2c218,DISK], DatanodeInfoWithStorage[127.0.0.1:44304,DS-1bb74985-a800-474b-aa8a-c850496662e9,DISK], DatanodeInfoWithStorage[127.0.0.1:44198,DS-05e46871-7aa5-4a03-be3a-fc577edbcb40,DISK], DatanodeInfoWithStorage[127.0.0.1:36636,DS-1d41bf17-0f5f-40c3-8456-970f6620e4b3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-919840032-172.17.0.20-1598439038737:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37968,DS-2710369a-4739-424c-8ee0-cd6e4a71e1b6,DISK], DatanodeInfoWithStorage[127.0.0.1:33980,DS-18e127f0-7aa8-4b2d-a3bf-7bbe897d8121,DISK], DatanodeInfoWithStorage[127.0.0.1:35012,DS-6bbd1a87-38f1-4320-8123-7b2130bb8c8c,DISK], DatanodeInfoWithStorage[127.0.0.1:35445,DS-dd37093a-bf44-40a8-8927-c3bf6b3a6cac,DISK], DatanodeInfoWithStorage[127.0.0.1:45932,DS-69a8e938-7267-40a9-98ef-6a4722c2c218,DISK], DatanodeInfoWithStorage[127.0.0.1:44304,DS-1bb74985-a800-474b-aa8a-c850496662e9,DISK], DatanodeInfoWithStorage[127.0.0.1:44198,DS-05e46871-7aa5-4a03-be3a-fc577edbcb40,DISK], DatanodeInfoWithStorage[127.0.0.1:36636,DS-1d41bf17-0f5f-40c3-8456-970f6620e4b3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.best-effort
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1528835024-172.17.0.20-1598439178307:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44878,DS-ccb813de-4b44-461e-af8a-6dec06a056aa,DISK], DatanodeInfoWithStorage[127.0.0.1:36525,DS-87fa6fb5-76b7-48b3-803e-f719da7be000,DISK], DatanodeInfoWithStorage[127.0.0.1:34496,DS-e899fb90-a890-4480-abff-f85a5c795d2a,DISK], DatanodeInfoWithStorage[127.0.0.1:41159,DS-ed40be35-1907-42b7-b4a1-45d96207102d,DISK], DatanodeInfoWithStorage[127.0.0.1:46828,DS-db24a382-a3ef-4d41-9709-8dc9b932e3d4,DISK], DatanodeInfoWithStorage[127.0.0.1:41828,DS-47231317-da06-49bc-910e-33a3529141ac,DISK], DatanodeInfoWithStorage[127.0.0.1:42604,DS-f16d6ef8-06f0-4684-a1e2-c76103fbb3ef,DISK], DatanodeInfoWithStorage[127.0.0.1:43079,DS-572e1c10-30d0-4d4d-affa-83db749ade7d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1528835024-172.17.0.20-1598439178307:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44878,DS-ccb813de-4b44-461e-af8a-6dec06a056aa,DISK], DatanodeInfoWithStorage[127.0.0.1:36525,DS-87fa6fb5-76b7-48b3-803e-f719da7be000,DISK], DatanodeInfoWithStorage[127.0.0.1:34496,DS-e899fb90-a890-4480-abff-f85a5c795d2a,DISK], DatanodeInfoWithStorage[127.0.0.1:41159,DS-ed40be35-1907-42b7-b4a1-45d96207102d,DISK], DatanodeInfoWithStorage[127.0.0.1:46828,DS-db24a382-a3ef-4d41-9709-8dc9b932e3d4,DISK], DatanodeInfoWithStorage[127.0.0.1:41828,DS-47231317-da06-49bc-910e-33a3529141ac,DISK], DatanodeInfoWithStorage[127.0.0.1:42604,DS-f16d6ef8-06f0-4684-a1e2-c76103fbb3ef,DISK], DatanodeInfoWithStorage[127.0.0.1:43079,DS-572e1c10-30d0-4d4d-affa-83db749ade7d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.best-effort
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-733968037-172.17.0.20-1598439213864:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44631,DS-592d02f2-f84a-4840-a600-111d71d93536,DISK], DatanodeInfoWithStorage[127.0.0.1:37643,DS-beb59166-cf49-49a1-b65e-7896bc63b4be,DISK], DatanodeInfoWithStorage[127.0.0.1:45184,DS-62b8225f-9302-446c-8085-562d32b7dd11,DISK], DatanodeInfoWithStorage[127.0.0.1:38018,DS-2c4008a0-736d-4929-930e-1cc40efe0df1,DISK], DatanodeInfoWithStorage[127.0.0.1:38477,DS-24c8a779-d125-4984-83be-07b6c9a737cd,DISK], DatanodeInfoWithStorage[127.0.0.1:44461,DS-2459e918-d887-4bdb-985b-30e73e293bf1,DISK], DatanodeInfoWithStorage[127.0.0.1:39819,DS-0bace823-b967-4241-8078-98d73ed49f8b,DISK], DatanodeInfoWithStorage[127.0.0.1:36260,DS-675f37ea-02fe-4d8f-b9c0-fbdcf7753141,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-733968037-172.17.0.20-1598439213864:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44631,DS-592d02f2-f84a-4840-a600-111d71d93536,DISK], DatanodeInfoWithStorage[127.0.0.1:37643,DS-beb59166-cf49-49a1-b65e-7896bc63b4be,DISK], DatanodeInfoWithStorage[127.0.0.1:45184,DS-62b8225f-9302-446c-8085-562d32b7dd11,DISK], DatanodeInfoWithStorage[127.0.0.1:38018,DS-2c4008a0-736d-4929-930e-1cc40efe0df1,DISK], DatanodeInfoWithStorage[127.0.0.1:38477,DS-24c8a779-d125-4984-83be-07b6c9a737cd,DISK], DatanodeInfoWithStorage[127.0.0.1:44461,DS-2459e918-d887-4bdb-985b-30e73e293bf1,DISK], DatanodeInfoWithStorage[127.0.0.1:39819,DS-0bace823-b967-4241-8078-98d73ed49f8b,DISK], DatanodeInfoWithStorage[127.0.0.1:36260,DS-675f37ea-02fe-4d8f-b9c0-fbdcf7753141,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.best-effort
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-663444012-172.17.0.20-1598439253274:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36058,DS-1d51ff5f-1859-4126-a7e1-987c9bbd5ed6,DISK], DatanodeInfoWithStorage[127.0.0.1:34155,DS-5175b55b-379e-4ed9-9e03-742629533a89,DISK], DatanodeInfoWithStorage[127.0.0.1:44360,DS-df12404d-9b19-4a94-ba6a-f9296b518f86,DISK], DatanodeInfoWithStorage[127.0.0.1:43528,DS-edcb9e3f-d80c-4309-a385-16bd6baf7c71,DISK], DatanodeInfoWithStorage[127.0.0.1:39031,DS-5ba22d33-b3a9-418c-8dea-18cb8f048683,DISK], DatanodeInfoWithStorage[127.0.0.1:42652,DS-ae230c2b-11d8-4ca6-9908-e8e3fb399951,DISK], DatanodeInfoWithStorage[127.0.0.1:34309,DS-167ad4ce-d1c2-4de1-ac5f-9f85d4d04d57,DISK], DatanodeInfoWithStorage[127.0.0.1:40324,DS-e100e020-c3e8-44cb-bb18-e48ee061a919,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-663444012-172.17.0.20-1598439253274:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36058,DS-1d51ff5f-1859-4126-a7e1-987c9bbd5ed6,DISK], DatanodeInfoWithStorage[127.0.0.1:34155,DS-5175b55b-379e-4ed9-9e03-742629533a89,DISK], DatanodeInfoWithStorage[127.0.0.1:44360,DS-df12404d-9b19-4a94-ba6a-f9296b518f86,DISK], DatanodeInfoWithStorage[127.0.0.1:43528,DS-edcb9e3f-d80c-4309-a385-16bd6baf7c71,DISK], DatanodeInfoWithStorage[127.0.0.1:39031,DS-5ba22d33-b3a9-418c-8dea-18cb8f048683,DISK], DatanodeInfoWithStorage[127.0.0.1:42652,DS-ae230c2b-11d8-4ca6-9908-e8e3fb399951,DISK], DatanodeInfoWithStorage[127.0.0.1:34309,DS-167ad4ce-d1c2-4de1-ac5f-9f85d4d04d57,DISK], DatanodeInfoWithStorage[127.0.0.1:40324,DS-e100e020-c3e8-44cb-bb18-e48ee061a919,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.best-effort
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-677894570-172.17.0.20-1598439292347:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40852,DS-edf8b906-ed0b-44f3-8ec7-8dc21d2c22dc,DISK], DatanodeInfoWithStorage[127.0.0.1:35475,DS-71b52d24-fd05-4233-a31d-6925f7fdf9b6,DISK], DatanodeInfoWithStorage[127.0.0.1:34636,DS-e4f3a41a-05b9-4398-addd-88acf2404157,DISK], DatanodeInfoWithStorage[127.0.0.1:33188,DS-5620a78c-a982-4ffd-8b0f-e83af9627b83,DISK], DatanodeInfoWithStorage[127.0.0.1:41451,DS-c76899d3-5c4e-4b21-841e-a2a7c9e6606b,DISK], DatanodeInfoWithStorage[127.0.0.1:44430,DS-2ad97c18-3708-457f-a35f-222d4167cf27,DISK], DatanodeInfoWithStorage[127.0.0.1:42456,DS-f5fd2914-ae61-4994-9e9f-47b606c75fe5,DISK], DatanodeInfoWithStorage[127.0.0.1:38348,DS-badedeb3-2f22-451c-9ca9-c94b2cd7bb9b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-677894570-172.17.0.20-1598439292347:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40852,DS-edf8b906-ed0b-44f3-8ec7-8dc21d2c22dc,DISK], DatanodeInfoWithStorage[127.0.0.1:35475,DS-71b52d24-fd05-4233-a31d-6925f7fdf9b6,DISK], DatanodeInfoWithStorage[127.0.0.1:34636,DS-e4f3a41a-05b9-4398-addd-88acf2404157,DISK], DatanodeInfoWithStorage[127.0.0.1:33188,DS-5620a78c-a982-4ffd-8b0f-e83af9627b83,DISK], DatanodeInfoWithStorage[127.0.0.1:41451,DS-c76899d3-5c4e-4b21-841e-a2a7c9e6606b,DISK], DatanodeInfoWithStorage[127.0.0.1:44430,DS-2ad97c18-3708-457f-a35f-222d4167cf27,DISK], DatanodeInfoWithStorage[127.0.0.1:42456,DS-f5fd2914-ae61-4994-9e9f-47b606c75fe5,DISK], DatanodeInfoWithStorage[127.0.0.1:38348,DS-badedeb3-2f22-451c-9ca9-c94b2cd7bb9b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.best-effort
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1412895381-172.17.0.20-1598439422863:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36325,DS-56620b26-0dc8-4ff9-a684-d7196ea7e5a2,DISK], DatanodeInfoWithStorage[127.0.0.1:34626,DS-3f9fee44-312e-4ba1-bf57-cf2815906092,DISK], DatanodeInfoWithStorage[127.0.0.1:33460,DS-8fbcca30-3dfd-460b-bcec-22d881b1cdff,DISK], DatanodeInfoWithStorage[127.0.0.1:36384,DS-36f6d7e3-8ea3-43ed-b5d1-0a74045432e5,DISK], DatanodeInfoWithStorage[127.0.0.1:35786,DS-571a3b31-1ea8-4191-8d41-421e2f59088d,DISK], DatanodeInfoWithStorage[127.0.0.1:36769,DS-f59d83c9-4ce6-4237-a30a-507280489d69,DISK], DatanodeInfoWithStorage[127.0.0.1:34740,DS-0cdfa0d3-9ad7-4ee8-a1a3-917621243145,DISK], DatanodeInfoWithStorage[127.0.0.1:43039,DS-6548104a-d12b-40d1-9822-392e1a66c20e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1412895381-172.17.0.20-1598439422863:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36325,DS-56620b26-0dc8-4ff9-a684-d7196ea7e5a2,DISK], DatanodeInfoWithStorage[127.0.0.1:34626,DS-3f9fee44-312e-4ba1-bf57-cf2815906092,DISK], DatanodeInfoWithStorage[127.0.0.1:33460,DS-8fbcca30-3dfd-460b-bcec-22d881b1cdff,DISK], DatanodeInfoWithStorage[127.0.0.1:36384,DS-36f6d7e3-8ea3-43ed-b5d1-0a74045432e5,DISK], DatanodeInfoWithStorage[127.0.0.1:35786,DS-571a3b31-1ea8-4191-8d41-421e2f59088d,DISK], DatanodeInfoWithStorage[127.0.0.1:36769,DS-f59d83c9-4ce6-4237-a30a-507280489d69,DISK], DatanodeInfoWithStorage[127.0.0.1:34740,DS-0cdfa0d3-9ad7-4ee8-a1a3-917621243145,DISK], DatanodeInfoWithStorage[127.0.0.1:43039,DS-6548104a-d12b-40d1-9822-392e1a66c20e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.best-effort
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1188883216-172.17.0.20-1598439562427:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33788,DS-dcdeb649-d3c2-4aaa-b803-b4b6ad2f37d8,DISK], DatanodeInfoWithStorage[127.0.0.1:45283,DS-e3beea93-708e-4733-9be3-f00fc93f2674,DISK], DatanodeInfoWithStorage[127.0.0.1:42273,DS-b39c5f86-60f2-4213-ae79-883790a48939,DISK], DatanodeInfoWithStorage[127.0.0.1:41324,DS-1bffac20-7cec-4445-a9ed-61b20f7a040e,DISK], DatanodeInfoWithStorage[127.0.0.1:38479,DS-a325d407-912f-4b57-ba85-dbbdd56940b0,DISK], DatanodeInfoWithStorage[127.0.0.1:37045,DS-0e52306b-df5b-4238-b4c7-b1f4e5289f57,DISK], DatanodeInfoWithStorage[127.0.0.1:41578,DS-6f012863-190d-418d-9611-77d7f835ef51,DISK], DatanodeInfoWithStorage[127.0.0.1:41310,DS-b064f641-1c66-4a1c-83b4-ec1916828e2f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1188883216-172.17.0.20-1598439562427:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33788,DS-dcdeb649-d3c2-4aaa-b803-b4b6ad2f37d8,DISK], DatanodeInfoWithStorage[127.0.0.1:45283,DS-e3beea93-708e-4733-9be3-f00fc93f2674,DISK], DatanodeInfoWithStorage[127.0.0.1:42273,DS-b39c5f86-60f2-4213-ae79-883790a48939,DISK], DatanodeInfoWithStorage[127.0.0.1:41324,DS-1bffac20-7cec-4445-a9ed-61b20f7a040e,DISK], DatanodeInfoWithStorage[127.0.0.1:38479,DS-a325d407-912f-4b57-ba85-dbbdd56940b0,DISK], DatanodeInfoWithStorage[127.0.0.1:37045,DS-0e52306b-df5b-4238-b4c7-b1f4e5289f57,DISK], DatanodeInfoWithStorage[127.0.0.1:41578,DS-6f012863-190d-418d-9611-77d7f835ef51,DISK], DatanodeInfoWithStorage[127.0.0.1:41310,DS-b064f641-1c66-4a1c-83b4-ec1916828e2f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.best-effort
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-196981769-172.17.0.20-1598439596499:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37266,DS-31fa92a1-dd1a-499b-b61b-49cabe627517,DISK], DatanodeInfoWithStorage[127.0.0.1:44190,DS-b6a97980-98b8-4cbc-b865-03da4e22b895,DISK], DatanodeInfoWithStorage[127.0.0.1:42728,DS-2191862b-c538-4905-ba36-aa15c7e64f53,DISK], DatanodeInfoWithStorage[127.0.0.1:40756,DS-9f0ee5ea-0823-4895-8512-5388378f9fb6,DISK], DatanodeInfoWithStorage[127.0.0.1:38158,DS-69e1ca59-a763-4848-b1b6-c3875b98f0a4,DISK], DatanodeInfoWithStorage[127.0.0.1:39264,DS-dc0af493-8c16-4e92-8413-8cabbbede260,DISK], DatanodeInfoWithStorage[127.0.0.1:34073,DS-d8173885-feaa-4a2e-8907-ad0c9c856346,DISK], DatanodeInfoWithStorage[127.0.0.1:37182,DS-afca4d9b-11a5-4256-a630-5af0ccfaeee3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-196981769-172.17.0.20-1598439596499:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37266,DS-31fa92a1-dd1a-499b-b61b-49cabe627517,DISK], DatanodeInfoWithStorage[127.0.0.1:44190,DS-b6a97980-98b8-4cbc-b865-03da4e22b895,DISK], DatanodeInfoWithStorage[127.0.0.1:42728,DS-2191862b-c538-4905-ba36-aa15c7e64f53,DISK], DatanodeInfoWithStorage[127.0.0.1:40756,DS-9f0ee5ea-0823-4895-8512-5388378f9fb6,DISK], DatanodeInfoWithStorage[127.0.0.1:38158,DS-69e1ca59-a763-4848-b1b6-c3875b98f0a4,DISK], DatanodeInfoWithStorage[127.0.0.1:39264,DS-dc0af493-8c16-4e92-8413-8cabbbede260,DISK], DatanodeInfoWithStorage[127.0.0.1:34073,DS-d8173885-feaa-4a2e-8907-ad0c9c856346,DISK], DatanodeInfoWithStorage[127.0.0.1:37182,DS-afca4d9b-11a5-4256-a630-5af0ccfaeee3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.best-effort
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-549368746-172.17.0.20-1598439706480:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38660,DS-7ae86b64-18ac-41a1-95d3-829d58937048,DISK], DatanodeInfoWithStorage[127.0.0.1:42804,DS-a4e82e28-d371-4932-99d2-4b554b75095c,DISK], DatanodeInfoWithStorage[127.0.0.1:46035,DS-d470cfa4-d4d2-4950-891f-416c3c651aaf,DISK], DatanodeInfoWithStorage[127.0.0.1:34277,DS-56f2f04b-72b9-46fb-b1be-52291e501d6d,DISK], DatanodeInfoWithStorage[127.0.0.1:44317,DS-4a29d1d5-6e6f-48ca-b885-dccd8fac8aae,DISK], DatanodeInfoWithStorage[127.0.0.1:43808,DS-8fe4c5b1-387e-4a47-9868-85fdd971c24f,DISK], DatanodeInfoWithStorage[127.0.0.1:46085,DS-5ab4ca63-d7cb-454f-9104-67d276582199,DISK], DatanodeInfoWithStorage[127.0.0.1:43220,DS-04adc1ad-0284-4a80-bfb0-a32be100c716,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-549368746-172.17.0.20-1598439706480:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38660,DS-7ae86b64-18ac-41a1-95d3-829d58937048,DISK], DatanodeInfoWithStorage[127.0.0.1:42804,DS-a4e82e28-d371-4932-99d2-4b554b75095c,DISK], DatanodeInfoWithStorage[127.0.0.1:46035,DS-d470cfa4-d4d2-4950-891f-416c3c651aaf,DISK], DatanodeInfoWithStorage[127.0.0.1:34277,DS-56f2f04b-72b9-46fb-b1be-52291e501d6d,DISK], DatanodeInfoWithStorage[127.0.0.1:44317,DS-4a29d1d5-6e6f-48ca-b885-dccd8fac8aae,DISK], DatanodeInfoWithStorage[127.0.0.1:43808,DS-8fe4c5b1-387e-4a47-9868-85fdd971c24f,DISK], DatanodeInfoWithStorage[127.0.0.1:46085,DS-5ab4ca63-d7cb-454f-9104-67d276582199,DISK], DatanodeInfoWithStorage[127.0.0.1:43220,DS-04adc1ad-0284-4a80-bfb0-a32be100c716,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.best-effort
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-454896715-172.17.0.20-1598439950916:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43348,DS-130dd34b-a80e-4470-8d87-03acd6ad52e6,DISK], DatanodeInfoWithStorage[127.0.0.1:41946,DS-671428bb-9e28-4f9f-a5e2-32f5de4a306c,DISK], DatanodeInfoWithStorage[127.0.0.1:42709,DS-d49b8d7b-a8b0-4eeb-9c14-c44b4491ab5d,DISK], DatanodeInfoWithStorage[127.0.0.1:35931,DS-5d738f83-b8f1-4264-997e-0b4d2629e3fe,DISK], DatanodeInfoWithStorage[127.0.0.1:40482,DS-c7b45f6f-a0b1-41a5-895f-ab4d140b5e3d,DISK], DatanodeInfoWithStorage[127.0.0.1:34894,DS-d7b119be-d226-4fec-b5ba-8bb93a0295b3,DISK], DatanodeInfoWithStorage[127.0.0.1:42827,DS-f0323529-3927-4979-977a-87fb076b092e,DISK], DatanodeInfoWithStorage[127.0.0.1:42061,DS-36a54eed-f4f8-41f1-8632-264c40cae62c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-454896715-172.17.0.20-1598439950916:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43348,DS-130dd34b-a80e-4470-8d87-03acd6ad52e6,DISK], DatanodeInfoWithStorage[127.0.0.1:41946,DS-671428bb-9e28-4f9f-a5e2-32f5de4a306c,DISK], DatanodeInfoWithStorage[127.0.0.1:42709,DS-d49b8d7b-a8b0-4eeb-9c14-c44b4491ab5d,DISK], DatanodeInfoWithStorage[127.0.0.1:35931,DS-5d738f83-b8f1-4264-997e-0b4d2629e3fe,DISK], DatanodeInfoWithStorage[127.0.0.1:40482,DS-c7b45f6f-a0b1-41a5-895f-ab4d140b5e3d,DISK], DatanodeInfoWithStorage[127.0.0.1:34894,DS-d7b119be-d226-4fec-b5ba-8bb93a0295b3,DISK], DatanodeInfoWithStorage[127.0.0.1:42827,DS-f0323529-3927-4979-977a-87fb076b092e,DISK], DatanodeInfoWithStorage[127.0.0.1:42061,DS-36a54eed-f4f8-41f1-8632-264c40cae62c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.best-effort
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-895971570-172.17.0.20-1598440243814:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35245,DS-c13c52f1-ea5d-4b4a-b1bb-806b106860e8,DISK], DatanodeInfoWithStorage[127.0.0.1:41354,DS-6265fcc4-5727-4107-8041-9d76b39900a2,DISK], DatanodeInfoWithStorage[127.0.0.1:38187,DS-3aecb437-e0f1-46ed-851e-ac68f3fdb883,DISK], DatanodeInfoWithStorage[127.0.0.1:43340,DS-7ddc980b-3dd3-46db-96be-6da73138db64,DISK], DatanodeInfoWithStorage[127.0.0.1:34731,DS-479ffdda-6c6f-49e3-b9fb-6d6674c862c7,DISK], DatanodeInfoWithStorage[127.0.0.1:35145,DS-bd46bd54-b7a7-4d37-8207-e7c0b053e312,DISK], DatanodeInfoWithStorage[127.0.0.1:44519,DS-a0e21528-ed98-4517-b0ef-9d8aff8179be,DISK], DatanodeInfoWithStorage[127.0.0.1:44999,DS-a1171f20-f881-4a12-b194-c0d1b2a2167d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-895971570-172.17.0.20-1598440243814:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35245,DS-c13c52f1-ea5d-4b4a-b1bb-806b106860e8,DISK], DatanodeInfoWithStorage[127.0.0.1:41354,DS-6265fcc4-5727-4107-8041-9d76b39900a2,DISK], DatanodeInfoWithStorage[127.0.0.1:38187,DS-3aecb437-e0f1-46ed-851e-ac68f3fdb883,DISK], DatanodeInfoWithStorage[127.0.0.1:43340,DS-7ddc980b-3dd3-46db-96be-6da73138db64,DISK], DatanodeInfoWithStorage[127.0.0.1:34731,DS-479ffdda-6c6f-49e3-b9fb-6d6674c862c7,DISK], DatanodeInfoWithStorage[127.0.0.1:35145,DS-bd46bd54-b7a7-4d37-8207-e7c0b053e312,DISK], DatanodeInfoWithStorage[127.0.0.1:44519,DS-a0e21528-ed98-4517-b0ef-9d8aff8179be,DISK], DatanodeInfoWithStorage[127.0.0.1:44999,DS-a1171f20-f881-4a12-b194-c0d1b2a2167d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.best-effort
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-168112586-172.17.0.20-1598440357855:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35789,DS-962ea6c0-5583-48c4-9a83-c7ac759678ba,DISK], DatanodeInfoWithStorage[127.0.0.1:40046,DS-45c48dfa-0e16-4c6d-9cd7-363aacde4683,DISK], DatanodeInfoWithStorage[127.0.0.1:35010,DS-01c746e5-2314-4e1e-922c-bd6b90359428,DISK], DatanodeInfoWithStorage[127.0.0.1:36073,DS-83d1856a-5a83-4952-adbe-e05634eca74f,DISK], DatanodeInfoWithStorage[127.0.0.1:34346,DS-877b1f97-d937-4e74-87d1-1b44884471f0,DISK], DatanodeInfoWithStorage[127.0.0.1:33028,DS-5e13ab90-f04f-43bb-9df3-3916fe88cd5d,DISK], DatanodeInfoWithStorage[127.0.0.1:41066,DS-ca78dec6-2a28-4820-b272-25fe52d8ce01,DISK], DatanodeInfoWithStorage[127.0.0.1:33914,DS-ccd161fc-e1a5-407a-9470-a0b4d390d975,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-168112586-172.17.0.20-1598440357855:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35789,DS-962ea6c0-5583-48c4-9a83-c7ac759678ba,DISK], DatanodeInfoWithStorage[127.0.0.1:40046,DS-45c48dfa-0e16-4c6d-9cd7-363aacde4683,DISK], DatanodeInfoWithStorage[127.0.0.1:35010,DS-01c746e5-2314-4e1e-922c-bd6b90359428,DISK], DatanodeInfoWithStorage[127.0.0.1:36073,DS-83d1856a-5a83-4952-adbe-e05634eca74f,DISK], DatanodeInfoWithStorage[127.0.0.1:34346,DS-877b1f97-d937-4e74-87d1-1b44884471f0,DISK], DatanodeInfoWithStorage[127.0.0.1:33028,DS-5e13ab90-f04f-43bb-9df3-3916fe88cd5d,DISK], DatanodeInfoWithStorage[127.0.0.1:41066,DS-ca78dec6-2a28-4820-b272-25fe52d8ce01,DISK], DatanodeInfoWithStorage[127.0.0.1:33914,DS-ccd161fc-e1a5-407a-9470-a0b4d390d975,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.best-effort
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-15225502-172.17.0.20-1598440442485:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43372,DS-ac33de92-46a8-41d9-897a-60efbff74fe4,DISK], DatanodeInfoWithStorage[127.0.0.1:43637,DS-d9b4e48c-7620-44da-886d-49b00299dbf2,DISK], DatanodeInfoWithStorage[127.0.0.1:32956,DS-2a423f14-f5d7-46a4-aa53-f87b628927e9,DISK], DatanodeInfoWithStorage[127.0.0.1:45802,DS-653dcb9e-473e-43d7-91e6-fb5279c3e44e,DISK], DatanodeInfoWithStorage[127.0.0.1:44943,DS-52aa2512-4945-44f4-909f-3cc373839f0a,DISK], DatanodeInfoWithStorage[127.0.0.1:35072,DS-7855e1a3-1e6e-484b-a4cb-eef87d1685fc,DISK], DatanodeInfoWithStorage[127.0.0.1:39188,DS-504b61a4-0135-4b11-9df5-78ae56377ef1,DISK], DatanodeInfoWithStorage[127.0.0.1:45803,DS-fde05d07-58e5-4304-8041-32c88019b770,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-15225502-172.17.0.20-1598440442485:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43372,DS-ac33de92-46a8-41d9-897a-60efbff74fe4,DISK], DatanodeInfoWithStorage[127.0.0.1:43637,DS-d9b4e48c-7620-44da-886d-49b00299dbf2,DISK], DatanodeInfoWithStorage[127.0.0.1:32956,DS-2a423f14-f5d7-46a4-aa53-f87b628927e9,DISK], DatanodeInfoWithStorage[127.0.0.1:45802,DS-653dcb9e-473e-43d7-91e6-fb5279c3e44e,DISK], DatanodeInfoWithStorage[127.0.0.1:44943,DS-52aa2512-4945-44f4-909f-3cc373839f0a,DISK], DatanodeInfoWithStorage[127.0.0.1:35072,DS-7855e1a3-1e6e-484b-a4cb-eef87d1685fc,DISK], DatanodeInfoWithStorage[127.0.0.1:39188,DS-504b61a4-0135-4b11-9df5-78ae56377ef1,DISK], DatanodeInfoWithStorage[127.0.0.1:45803,DS-fde05d07-58e5-4304-8041-32c88019b770,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.best-effort
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1874408839-172.17.0.20-1598440518449:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39421,DS-195095b6-888c-415f-9e9d-ca95ee2e9ed8,DISK], DatanodeInfoWithStorage[127.0.0.1:42585,DS-24f749f5-0ad8-458e-92fd-f8f76f23f403,DISK], DatanodeInfoWithStorage[127.0.0.1:34189,DS-2cfc8b5f-b403-4088-901e-4ec4893f9d9c,DISK], DatanodeInfoWithStorage[127.0.0.1:46177,DS-1e5daecf-4a63-4f58-be29-354e3745db5b,DISK], DatanodeInfoWithStorage[127.0.0.1:36565,DS-d087241a-23d9-43d8-81e0-15b9110b9974,DISK], DatanodeInfoWithStorage[127.0.0.1:46647,DS-7f4918ca-0ac0-48ed-8391-e907b233ee3c,DISK], DatanodeInfoWithStorage[127.0.0.1:37844,DS-56b90cf5-8405-4502-9b92-4c5df54ea4e5,DISK], DatanodeInfoWithStorage[127.0.0.1:33510,DS-20c49c08-bf87-421f-9c21-c20f6ad7937c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1874408839-172.17.0.20-1598440518449:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39421,DS-195095b6-888c-415f-9e9d-ca95ee2e9ed8,DISK], DatanodeInfoWithStorage[127.0.0.1:42585,DS-24f749f5-0ad8-458e-92fd-f8f76f23f403,DISK], DatanodeInfoWithStorage[127.0.0.1:34189,DS-2cfc8b5f-b403-4088-901e-4ec4893f9d9c,DISK], DatanodeInfoWithStorage[127.0.0.1:46177,DS-1e5daecf-4a63-4f58-be29-354e3745db5b,DISK], DatanodeInfoWithStorage[127.0.0.1:36565,DS-d087241a-23d9-43d8-81e0-15b9110b9974,DISK], DatanodeInfoWithStorage[127.0.0.1:46647,DS-7f4918ca-0ac0-48ed-8391-e907b233ee3c,DISK], DatanodeInfoWithStorage[127.0.0.1:37844,DS-56b90cf5-8405-4502-9b92-4c5df54ea4e5,DISK], DatanodeInfoWithStorage[127.0.0.1:33510,DS-20c49c08-bf87-421f-9c21-c20f6ad7937c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.best-effort
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1797662559-172.17.0.20-1598440814683:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43039,DS-0d3f870b-f676-413e-acea-b1126f863ca9,DISK], DatanodeInfoWithStorage[127.0.0.1:34472,DS-f9622581-6df3-4130-ace4-370af39c177f,DISK], DatanodeInfoWithStorage[127.0.0.1:33515,DS-eb2bfbb0-ef3a-4321-8a06-73e2ce5bd744,DISK], DatanodeInfoWithStorage[127.0.0.1:33498,DS-f8b21dee-aabe-467f-bd72-1ca5849a4811,DISK], DatanodeInfoWithStorage[127.0.0.1:45625,DS-b9ddb09d-0522-4772-b4d2-98184644c695,DISK], DatanodeInfoWithStorage[127.0.0.1:41696,DS-38af5ff3-8d47-4f6b-ae56-a1759a355f2b,DISK], DatanodeInfoWithStorage[127.0.0.1:46114,DS-83a59090-2daa-43e5-956f-11feb3bc5f2d,DISK], DatanodeInfoWithStorage[127.0.0.1:36218,DS-2cf473c2-d52f-4a1f-9738-3b393fd43fa2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1797662559-172.17.0.20-1598440814683:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43039,DS-0d3f870b-f676-413e-acea-b1126f863ca9,DISK], DatanodeInfoWithStorage[127.0.0.1:34472,DS-f9622581-6df3-4130-ace4-370af39c177f,DISK], DatanodeInfoWithStorage[127.0.0.1:33515,DS-eb2bfbb0-ef3a-4321-8a06-73e2ce5bd744,DISK], DatanodeInfoWithStorage[127.0.0.1:33498,DS-f8b21dee-aabe-467f-bd72-1ca5849a4811,DISK], DatanodeInfoWithStorage[127.0.0.1:45625,DS-b9ddb09d-0522-4772-b4d2-98184644c695,DISK], DatanodeInfoWithStorage[127.0.0.1:41696,DS-38af5ff3-8d47-4f6b-ae56-a1759a355f2b,DISK], DatanodeInfoWithStorage[127.0.0.1:46114,DS-83a59090-2daa-43e5-956f-11feb3bc5f2d,DISK], DatanodeInfoWithStorage[127.0.0.1:36218,DS-2cf473c2-d52f-4a1f-9738-3b393fd43fa2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.best-effort
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-457377606-172.17.0.20-1598440851777:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42809,DS-63dd5f88-fd7e-4573-af7c-14e046aff701,DISK], DatanodeInfoWithStorage[127.0.0.1:39551,DS-efe20d47-a3c7-446c-bb8b-3b7a55df0f66,DISK], DatanodeInfoWithStorage[127.0.0.1:38483,DS-2c15ec03-1f7e-49e9-b018-0efe964aa7e0,DISK], DatanodeInfoWithStorage[127.0.0.1:33623,DS-e7d1d660-d305-48e2-9724-78390acfc27d,DISK], DatanodeInfoWithStorage[127.0.0.1:33441,DS-39477f42-1f63-4be2-a1e8-88f9d266aeb6,DISK], DatanodeInfoWithStorage[127.0.0.1:40252,DS-d1db18e7-bd45-4784-a7e7-b4140ee985e4,DISK], DatanodeInfoWithStorage[127.0.0.1:37559,DS-4397aea8-ac81-46aa-b4e6-a177f4738c6e,DISK], DatanodeInfoWithStorage[127.0.0.1:35549,DS-15b31401-1fa8-4cbf-b213-4dd71ff33052,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-457377606-172.17.0.20-1598440851777:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42809,DS-63dd5f88-fd7e-4573-af7c-14e046aff701,DISK], DatanodeInfoWithStorage[127.0.0.1:39551,DS-efe20d47-a3c7-446c-bb8b-3b7a55df0f66,DISK], DatanodeInfoWithStorage[127.0.0.1:38483,DS-2c15ec03-1f7e-49e9-b018-0efe964aa7e0,DISK], DatanodeInfoWithStorage[127.0.0.1:33623,DS-e7d1d660-d305-48e2-9724-78390acfc27d,DISK], DatanodeInfoWithStorage[127.0.0.1:33441,DS-39477f42-1f63-4be2-a1e8-88f9d266aeb6,DISK], DatanodeInfoWithStorage[127.0.0.1:40252,DS-d1db18e7-bd45-4784-a7e7-b4140ee985e4,DISK], DatanodeInfoWithStorage[127.0.0.1:37559,DS-4397aea8-ac81-46aa-b4e6-a177f4738c6e,DISK], DatanodeInfoWithStorage[127.0.0.1:35549,DS-15b31401-1fa8-4cbf-b213-4dd71ff33052,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.best-effort
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-662745431-172.17.0.20-1598441214541:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43106,DS-6f9afc44-0560-48af-b8bb-7bac780eda48,DISK], DatanodeInfoWithStorage[127.0.0.1:45306,DS-76bdbe27-2369-43e4-92e7-95a61c450351,DISK], DatanodeInfoWithStorage[127.0.0.1:43938,DS-e11ca03a-2d46-412c-b71a-f80f5e41fda7,DISK], DatanodeInfoWithStorage[127.0.0.1:33756,DS-32d7e808-2c9f-4f7e-afa2-938cfec296db,DISK], DatanodeInfoWithStorage[127.0.0.1:40985,DS-9485a735-3857-4a6c-82af-455cbed11b39,DISK], DatanodeInfoWithStorage[127.0.0.1:35417,DS-b75fb0e8-bfc3-47e2-b579-f879bd234bd0,DISK], DatanodeInfoWithStorage[127.0.0.1:46823,DS-d4b082eb-b175-437b-b936-82a38e6f305f,DISK], DatanodeInfoWithStorage[127.0.0.1:43774,DS-d1a00fba-8e79-475c-adb8-89d63339afa9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-662745431-172.17.0.20-1598441214541:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43106,DS-6f9afc44-0560-48af-b8bb-7bac780eda48,DISK], DatanodeInfoWithStorage[127.0.0.1:45306,DS-76bdbe27-2369-43e4-92e7-95a61c450351,DISK], DatanodeInfoWithStorage[127.0.0.1:43938,DS-e11ca03a-2d46-412c-b71a-f80f5e41fda7,DISK], DatanodeInfoWithStorage[127.0.0.1:33756,DS-32d7e808-2c9f-4f7e-afa2-938cfec296db,DISK], DatanodeInfoWithStorage[127.0.0.1:40985,DS-9485a735-3857-4a6c-82af-455cbed11b39,DISK], DatanodeInfoWithStorage[127.0.0.1:35417,DS-b75fb0e8-bfc3-47e2-b579-f879bd234bd0,DISK], DatanodeInfoWithStorage[127.0.0.1:46823,DS-d4b082eb-b175-437b-b936-82a38e6f305f,DISK], DatanodeInfoWithStorage[127.0.0.1:43774,DS-d1a00fba-8e79-475c-adb8-89d63339afa9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.best-effort
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1620457461-172.17.0.20-1598441257637:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46330,DS-64051a50-ccbe-4fe5-8903-254efe95614a,DISK], DatanodeInfoWithStorage[127.0.0.1:36926,DS-99bcad70-3171-4768-b451-16a97c73f5a0,DISK], DatanodeInfoWithStorage[127.0.0.1:40178,DS-6abe1a41-025e-47c4-b533-31fe41b4f48a,DISK], DatanodeInfoWithStorage[127.0.0.1:46134,DS-5f58c36f-9f9b-41dd-a5a5-fe864b7c3312,DISK], DatanodeInfoWithStorage[127.0.0.1:36275,DS-e9abb811-3ca2-4eac-9b44-18f990c9d39b,DISK], DatanodeInfoWithStorage[127.0.0.1:37705,DS-6cadb707-be27-4fa4-b75a-9950209c5d54,DISK], DatanodeInfoWithStorage[127.0.0.1:43294,DS-9af85b72-9baf-4e0a-865c-a070632d8551,DISK], DatanodeInfoWithStorage[127.0.0.1:45269,DS-4d679d0b-de3e-447c-9068-7362ff6cf85b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1620457461-172.17.0.20-1598441257637:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46330,DS-64051a50-ccbe-4fe5-8903-254efe95614a,DISK], DatanodeInfoWithStorage[127.0.0.1:36926,DS-99bcad70-3171-4768-b451-16a97c73f5a0,DISK], DatanodeInfoWithStorage[127.0.0.1:40178,DS-6abe1a41-025e-47c4-b533-31fe41b4f48a,DISK], DatanodeInfoWithStorage[127.0.0.1:46134,DS-5f58c36f-9f9b-41dd-a5a5-fe864b7c3312,DISK], DatanodeInfoWithStorage[127.0.0.1:36275,DS-e9abb811-3ca2-4eac-9b44-18f990c9d39b,DISK], DatanodeInfoWithStorage[127.0.0.1:37705,DS-6cadb707-be27-4fa4-b75a-9950209c5d54,DISK], DatanodeInfoWithStorage[127.0.0.1:43294,DS-9af85b72-9baf-4e0a-865c-a070632d8551,DISK], DatanodeInfoWithStorage[127.0.0.1:45269,DS-4d679d0b-de3e-447c-9068-7362ff6cf85b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.best-effort
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-774342900-172.17.0.20-1598441405019:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46355,DS-765c6ccb-2a88-4f9b-b60f-81395cc5a0d0,DISK], DatanodeInfoWithStorage[127.0.0.1:40542,DS-e457aaaf-6c13-4c95-933d-b320ae08b05b,DISK], DatanodeInfoWithStorage[127.0.0.1:43140,DS-84f630c3-7d37-4483-b707-f9cecf2853da,DISK], DatanodeInfoWithStorage[127.0.0.1:45212,DS-448bee90-4171-456b-b7a8-270b86206eab,DISK], DatanodeInfoWithStorage[127.0.0.1:35000,DS-81f5f9e4-038a-4b7e-af15-9ea115de0337,DISK], DatanodeInfoWithStorage[127.0.0.1:39989,DS-f271b8d1-4ca4-4bd6-bff8-3a1f4b0b9be8,DISK], DatanodeInfoWithStorage[127.0.0.1:42913,DS-82372bb2-1db2-43cc-b46e-81482cfda89a,DISK], DatanodeInfoWithStorage[127.0.0.1:41560,DS-647bfbac-b28b-4e1a-b96a-d2a7c415ac5e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-774342900-172.17.0.20-1598441405019:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46355,DS-765c6ccb-2a88-4f9b-b60f-81395cc5a0d0,DISK], DatanodeInfoWithStorage[127.0.0.1:40542,DS-e457aaaf-6c13-4c95-933d-b320ae08b05b,DISK], DatanodeInfoWithStorage[127.0.0.1:43140,DS-84f630c3-7d37-4483-b707-f9cecf2853da,DISK], DatanodeInfoWithStorage[127.0.0.1:45212,DS-448bee90-4171-456b-b7a8-270b86206eab,DISK], DatanodeInfoWithStorage[127.0.0.1:35000,DS-81f5f9e4-038a-4b7e-af15-9ea115de0337,DISK], DatanodeInfoWithStorage[127.0.0.1:39989,DS-f271b8d1-4ca4-4bd6-bff8-3a1f4b0b9be8,DISK], DatanodeInfoWithStorage[127.0.0.1:42913,DS-82372bb2-1db2-43cc-b46e-81482cfda89a,DISK], DatanodeInfoWithStorage[127.0.0.1:41560,DS-647bfbac-b28b-4e1a-b96a-d2a7c415ac5e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.best-effort
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-3596749-172.17.0.20-1598441519426:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44524,DS-53ca8606-8444-403e-92dd-51affce4e04b,DISK], DatanodeInfoWithStorage[127.0.0.1:42471,DS-febd5ad3-4b09-4f53-9c53-19289861fd0a,DISK], DatanodeInfoWithStorage[127.0.0.1:39151,DS-bb74478a-4df5-4426-82f9-7e0b82103512,DISK], DatanodeInfoWithStorage[127.0.0.1:34965,DS-40d50e29-ed07-4080-9cc8-3160675b4138,DISK], DatanodeInfoWithStorage[127.0.0.1:39735,DS-a7722ce7-0c59-4c13-9e59-5aed0717ffb0,DISK], DatanodeInfoWithStorage[127.0.0.1:46086,DS-ffe1e6fd-8483-4fbd-9c4c-3631edc9d8aa,DISK], DatanodeInfoWithStorage[127.0.0.1:37678,DS-2a8fcc44-3ea2-4cd2-9591-29aeeb7ece4d,DISK], DatanodeInfoWithStorage[127.0.0.1:43668,DS-a2c7a8ec-84e7-4b53-80b4-fc702999906e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-3596749-172.17.0.20-1598441519426:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44524,DS-53ca8606-8444-403e-92dd-51affce4e04b,DISK], DatanodeInfoWithStorage[127.0.0.1:42471,DS-febd5ad3-4b09-4f53-9c53-19289861fd0a,DISK], DatanodeInfoWithStorage[127.0.0.1:39151,DS-bb74478a-4df5-4426-82f9-7e0b82103512,DISK], DatanodeInfoWithStorage[127.0.0.1:34965,DS-40d50e29-ed07-4080-9cc8-3160675b4138,DISK], DatanodeInfoWithStorage[127.0.0.1:39735,DS-a7722ce7-0c59-4c13-9e59-5aed0717ffb0,DISK], DatanodeInfoWithStorage[127.0.0.1:46086,DS-ffe1e6fd-8483-4fbd-9c4c-3631edc9d8aa,DISK], DatanodeInfoWithStorage[127.0.0.1:37678,DS-2a8fcc44-3ea2-4cd2-9591-29aeeb7ece4d,DISK], DatanodeInfoWithStorage[127.0.0.1:43668,DS-a2c7a8ec-84e7-4b53-80b4-fc702999906e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.best-effort
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2131001762-172.17.0.20-1598441630442:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32779,DS-3a8b1b64-3765-4332-8c23-8012400741aa,DISK], DatanodeInfoWithStorage[127.0.0.1:35426,DS-49e75f05-7dd5-4d09-8375-6e2fd276dbd9,DISK], DatanodeInfoWithStorage[127.0.0.1:38336,DS-050a6c64-7382-4011-a3d9-5b0b329e5a24,DISK], DatanodeInfoWithStorage[127.0.0.1:37845,DS-c365d57f-c3ef-49e7-9bfe-91a20228792a,DISK], DatanodeInfoWithStorage[127.0.0.1:41990,DS-b44fa82f-0a52-431f-b847-380f9d46e193,DISK], DatanodeInfoWithStorage[127.0.0.1:34518,DS-82dc1f85-26db-4590-b516-699d8900864d,DISK], DatanodeInfoWithStorage[127.0.0.1:36127,DS-ebe0f3d4-ff12-4f06-b2dd-5c6387aa913f,DISK], DatanodeInfoWithStorage[127.0.0.1:44826,DS-76bbcf8c-9bbf-43dc-87dd-e107aecae4ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2131001762-172.17.0.20-1598441630442:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32779,DS-3a8b1b64-3765-4332-8c23-8012400741aa,DISK], DatanodeInfoWithStorage[127.0.0.1:35426,DS-49e75f05-7dd5-4d09-8375-6e2fd276dbd9,DISK], DatanodeInfoWithStorage[127.0.0.1:38336,DS-050a6c64-7382-4011-a3d9-5b0b329e5a24,DISK], DatanodeInfoWithStorage[127.0.0.1:37845,DS-c365d57f-c3ef-49e7-9bfe-91a20228792a,DISK], DatanodeInfoWithStorage[127.0.0.1:41990,DS-b44fa82f-0a52-431f-b847-380f9d46e193,DISK], DatanodeInfoWithStorage[127.0.0.1:34518,DS-82dc1f85-26db-4590-b516-699d8900864d,DISK], DatanodeInfoWithStorage[127.0.0.1:36127,DS-ebe0f3d4-ff12-4f06-b2dd-5c6387aa913f,DISK], DatanodeInfoWithStorage[127.0.0.1:44826,DS-76bbcf8c-9bbf-43dc-87dd-e107aecae4ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.best-effort
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1821488797-172.17.0.20-1598441701816:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38278,DS-33082f2c-dc86-4572-b566-c937e85b6c81,DISK], DatanodeInfoWithStorage[127.0.0.1:44773,DS-da077142-d4e9-469b-816c-1571c2659fa4,DISK], DatanodeInfoWithStorage[127.0.0.1:41435,DS-d6ddc400-5431-4f1e-8209-8bdf4bd1d869,DISK], DatanodeInfoWithStorage[127.0.0.1:33716,DS-6ed6f85f-5074-47aa-970e-6a9bd3bba31c,DISK], DatanodeInfoWithStorage[127.0.0.1:44234,DS-9217610a-0d7d-4409-b585-bf7bc9f8f4d0,DISK], DatanodeInfoWithStorage[127.0.0.1:35216,DS-f9a5967b-b7ce-4d63-be9b-251feb78438d,DISK], DatanodeInfoWithStorage[127.0.0.1:36664,DS-061d4944-4f70-4b9e-a7af-77bf62b53928,DISK], DatanodeInfoWithStorage[127.0.0.1:35482,DS-c8bb1bac-4a20-4d63-851a-5aa92ad3f17e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1821488797-172.17.0.20-1598441701816:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38278,DS-33082f2c-dc86-4572-b566-c937e85b6c81,DISK], DatanodeInfoWithStorage[127.0.0.1:44773,DS-da077142-d4e9-469b-816c-1571c2659fa4,DISK], DatanodeInfoWithStorage[127.0.0.1:41435,DS-d6ddc400-5431-4f1e-8209-8bdf4bd1d869,DISK], DatanodeInfoWithStorage[127.0.0.1:33716,DS-6ed6f85f-5074-47aa-970e-6a9bd3bba31c,DISK], DatanodeInfoWithStorage[127.0.0.1:44234,DS-9217610a-0d7d-4409-b585-bf7bc9f8f4d0,DISK], DatanodeInfoWithStorage[127.0.0.1:35216,DS-f9a5967b-b7ce-4d63-be9b-251feb78438d,DISK], DatanodeInfoWithStorage[127.0.0.1:36664,DS-061d4944-4f70-4b9e-a7af-77bf62b53928,DISK], DatanodeInfoWithStorage[127.0.0.1:35482,DS-c8bb1bac-4a20-4d63-851a-5aa92ad3f17e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.best-effort
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1124085522-172.17.0.20-1598441866149:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41348,DS-cbb4a07f-f055-46d2-8c3d-01abb82a12b5,DISK], DatanodeInfoWithStorage[127.0.0.1:44114,DS-b7683bcb-0042-46fe-930d-d607d37040dd,DISK], DatanodeInfoWithStorage[127.0.0.1:34680,DS-7a9b8dda-70cc-4a22-9224-92c48694d2f3,DISK], DatanodeInfoWithStorage[127.0.0.1:45122,DS-921c67dc-cb9a-49f2-9559-dbee06e16f24,DISK], DatanodeInfoWithStorage[127.0.0.1:44966,DS-cd8c239c-73b2-4d78-9a6b-70730525b686,DISK], DatanodeInfoWithStorage[127.0.0.1:42654,DS-daa37828-54d5-402a-8155-0984139e7dcb,DISK], DatanodeInfoWithStorage[127.0.0.1:43577,DS-acd600fa-12bc-49a5-9d84-6dab1c3753bc,DISK], DatanodeInfoWithStorage[127.0.0.1:40591,DS-94b4c027-c98a-4b90-b1ef-014f37c30632,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1124085522-172.17.0.20-1598441866149:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41348,DS-cbb4a07f-f055-46d2-8c3d-01abb82a12b5,DISK], DatanodeInfoWithStorage[127.0.0.1:44114,DS-b7683bcb-0042-46fe-930d-d607d37040dd,DISK], DatanodeInfoWithStorage[127.0.0.1:34680,DS-7a9b8dda-70cc-4a22-9224-92c48694d2f3,DISK], DatanodeInfoWithStorage[127.0.0.1:45122,DS-921c67dc-cb9a-49f2-9559-dbee06e16f24,DISK], DatanodeInfoWithStorage[127.0.0.1:44966,DS-cd8c239c-73b2-4d78-9a6b-70730525b686,DISK], DatanodeInfoWithStorage[127.0.0.1:42654,DS-daa37828-54d5-402a-8155-0984139e7dcb,DISK], DatanodeInfoWithStorage[127.0.0.1:43577,DS-acd600fa-12bc-49a5-9d84-6dab1c3753bc,DISK], DatanodeInfoWithStorage[127.0.0.1:40591,DS-94b4c027-c98a-4b90-b1ef-014f37c30632,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.best-effort
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1315254978-172.17.0.20-1598441892583:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41477,DS-7ace4ad2-96fd-4ecc-a943-72bed3acfc57,DISK], DatanodeInfoWithStorage[127.0.0.1:40546,DS-2a4f7dd8-adfb-498f-97c4-2e252cb014dc,DISK], DatanodeInfoWithStorage[127.0.0.1:42872,DS-b7c87732-77a0-4efd-8cd9-7889227ee215,DISK], DatanodeInfoWithStorage[127.0.0.1:38185,DS-9e2ff1de-cc75-4966-b0df-7d7290df2177,DISK], DatanodeInfoWithStorage[127.0.0.1:44569,DS-3a26c1c6-9402-4522-a70a-fafd96e76d6b,DISK], DatanodeInfoWithStorage[127.0.0.1:40200,DS-38696ddd-a9e9-493a-9592-15e6df9b6d78,DISK], DatanodeInfoWithStorage[127.0.0.1:33074,DS-78132518-9f45-40db-81b6-1e913194113f,DISK], DatanodeInfoWithStorage[127.0.0.1:45675,DS-33cd6518-2cce-4655-af5a-15d382447d27,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1315254978-172.17.0.20-1598441892583:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41477,DS-7ace4ad2-96fd-4ecc-a943-72bed3acfc57,DISK], DatanodeInfoWithStorage[127.0.0.1:40546,DS-2a4f7dd8-adfb-498f-97c4-2e252cb014dc,DISK], DatanodeInfoWithStorage[127.0.0.1:42872,DS-b7c87732-77a0-4efd-8cd9-7889227ee215,DISK], DatanodeInfoWithStorage[127.0.0.1:38185,DS-9e2ff1de-cc75-4966-b0df-7d7290df2177,DISK], DatanodeInfoWithStorage[127.0.0.1:44569,DS-3a26c1c6-9402-4522-a70a-fafd96e76d6b,DISK], DatanodeInfoWithStorage[127.0.0.1:40200,DS-38696ddd-a9e9-493a-9592-15e6df9b6d78,DISK], DatanodeInfoWithStorage[127.0.0.1:33074,DS-78132518-9f45-40db-81b6-1e913194113f,DISK], DatanodeInfoWithStorage[127.0.0.1:45675,DS-33cd6518-2cce-4655-af5a-15d382447d27,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.best-effort
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1307637649-172.17.0.20-1598441968733:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44071,DS-d433bf8d-5b9b-4c5d-a532-df685e616f51,DISK], DatanodeInfoWithStorage[127.0.0.1:34086,DS-aabdee59-f8a4-4853-bd59-2b51807d0914,DISK], DatanodeInfoWithStorage[127.0.0.1:45758,DS-18484338-abc0-4fc5-846e-e89852b78fff,DISK], DatanodeInfoWithStorage[127.0.0.1:42201,DS-b1e8f35e-da0e-42da-be90-e56dbd7f64a1,DISK], DatanodeInfoWithStorage[127.0.0.1:38952,DS-73f54811-ddfb-4824-8b12-560a05fa0560,DISK], DatanodeInfoWithStorage[127.0.0.1:44041,DS-2e42afe6-a655-4303-a20b-4ccb9902016d,DISK], DatanodeInfoWithStorage[127.0.0.1:36066,DS-3aa77dc6-fd14-43ce-8d04-43ddda1f40ee,DISK], DatanodeInfoWithStorage[127.0.0.1:34533,DS-03bfeece-06a6-48e3-80e3-8cb9fac9ea5e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1307637649-172.17.0.20-1598441968733:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44071,DS-d433bf8d-5b9b-4c5d-a532-df685e616f51,DISK], DatanodeInfoWithStorage[127.0.0.1:34086,DS-aabdee59-f8a4-4853-bd59-2b51807d0914,DISK], DatanodeInfoWithStorage[127.0.0.1:45758,DS-18484338-abc0-4fc5-846e-e89852b78fff,DISK], DatanodeInfoWithStorage[127.0.0.1:42201,DS-b1e8f35e-da0e-42da-be90-e56dbd7f64a1,DISK], DatanodeInfoWithStorage[127.0.0.1:38952,DS-73f54811-ddfb-4824-8b12-560a05fa0560,DISK], DatanodeInfoWithStorage[127.0.0.1:44041,DS-2e42afe6-a655-4303-a20b-4ccb9902016d,DISK], DatanodeInfoWithStorage[127.0.0.1:36066,DS-3aa77dc6-fd14-43ce-8d04-43ddda1f40ee,DISK], DatanodeInfoWithStorage[127.0.0.1:34533,DS-03bfeece-06a6-48e3-80e3-8cb9fac9ea5e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.best-effort
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1117539728-172.17.0.20-1598442180525:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38709,DS-bd430787-4f2a-431d-9afd-65c6b3a8a68d,DISK], DatanodeInfoWithStorage[127.0.0.1:36582,DS-3365c26d-8141-45fd-ba8f-e80a240cf1d4,DISK], DatanodeInfoWithStorage[127.0.0.1:41047,DS-43c216b9-d47d-47c9-a809-ac133375fc5b,DISK], DatanodeInfoWithStorage[127.0.0.1:37794,DS-f85cab3e-1681-43ca-8872-d17f9c27fdb9,DISK], DatanodeInfoWithStorage[127.0.0.1:43138,DS-6a399da5-e03c-4511-a25b-4e99e563e80c,DISK], DatanodeInfoWithStorage[127.0.0.1:41668,DS-ec5db1fe-fdad-4f73-8887-e449ad79f31d,DISK], DatanodeInfoWithStorage[127.0.0.1:44945,DS-d5e69313-cf5f-41de-b219-ef58cc8c485c,DISK], DatanodeInfoWithStorage[127.0.0.1:44833,DS-295c029c-6477-44fa-a246-2ae66e108ed2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1117539728-172.17.0.20-1598442180525:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38709,DS-bd430787-4f2a-431d-9afd-65c6b3a8a68d,DISK], DatanodeInfoWithStorage[127.0.0.1:36582,DS-3365c26d-8141-45fd-ba8f-e80a240cf1d4,DISK], DatanodeInfoWithStorage[127.0.0.1:41047,DS-43c216b9-d47d-47c9-a809-ac133375fc5b,DISK], DatanodeInfoWithStorage[127.0.0.1:37794,DS-f85cab3e-1681-43ca-8872-d17f9c27fdb9,DISK], DatanodeInfoWithStorage[127.0.0.1:43138,DS-6a399da5-e03c-4511-a25b-4e99e563e80c,DISK], DatanodeInfoWithStorage[127.0.0.1:41668,DS-ec5db1fe-fdad-4f73-8887-e449ad79f31d,DISK], DatanodeInfoWithStorage[127.0.0.1:44945,DS-d5e69313-cf5f-41de-b219-ef58cc8c485c,DISK], DatanodeInfoWithStorage[127.0.0.1:44833,DS-295c029c-6477-44fa-a246-2ae66e108ed2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.best-effort
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-642493016-172.17.0.20-1598442332217:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40251,DS-6a81a5f6-3785-404b-9770-91614e6bde73,DISK], DatanodeInfoWithStorage[127.0.0.1:41215,DS-c0057436-40d8-4b3f-ac5c-4cd074b09911,DISK], DatanodeInfoWithStorage[127.0.0.1:38883,DS-820bcc33-58b9-448c-a7c2-dc2795fb802b,DISK], DatanodeInfoWithStorage[127.0.0.1:43826,DS-787805ff-fd3a-43c6-bc58-d8e9e5f582de,DISK], DatanodeInfoWithStorage[127.0.0.1:40107,DS-a5b91ddc-294d-4bf1-83bb-3f6f37a3744c,DISK], DatanodeInfoWithStorage[127.0.0.1:33262,DS-1fed43f4-1ce1-4f14-a5e7-80e685f6dd37,DISK], DatanodeInfoWithStorage[127.0.0.1:42664,DS-1a7ecedb-d8ac-4a48-ad82-ad083c4480ff,DISK], DatanodeInfoWithStorage[127.0.0.1:36960,DS-2f4fe141-3ad9-4dbb-8965-48af3feded9d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-642493016-172.17.0.20-1598442332217:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40251,DS-6a81a5f6-3785-404b-9770-91614e6bde73,DISK], DatanodeInfoWithStorage[127.0.0.1:41215,DS-c0057436-40d8-4b3f-ac5c-4cd074b09911,DISK], DatanodeInfoWithStorage[127.0.0.1:38883,DS-820bcc33-58b9-448c-a7c2-dc2795fb802b,DISK], DatanodeInfoWithStorage[127.0.0.1:43826,DS-787805ff-fd3a-43c6-bc58-d8e9e5f582de,DISK], DatanodeInfoWithStorage[127.0.0.1:40107,DS-a5b91ddc-294d-4bf1-83bb-3f6f37a3744c,DISK], DatanodeInfoWithStorage[127.0.0.1:33262,DS-1fed43f4-1ce1-4f14-a5e7-80e685f6dd37,DISK], DatanodeInfoWithStorage[127.0.0.1:42664,DS-1a7ecedb-d8ac-4a48-ad82-ad083c4480ff,DISK], DatanodeInfoWithStorage[127.0.0.1:36960,DS-2f4fe141-3ad9-4dbb-8965-48af3feded9d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.best-effort
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1114314277-172.17.0.20-1598442365520:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35241,DS-45cc861c-7b14-41b2-aa83-38e61f28cc7c,DISK], DatanodeInfoWithStorage[127.0.0.1:34529,DS-a2bc199e-8143-4130-820b-03b6701b2954,DISK], DatanodeInfoWithStorage[127.0.0.1:35897,DS-2e6307d1-7da0-4c8a-982e-ac66b985ac7f,DISK], DatanodeInfoWithStorage[127.0.0.1:44474,DS-e6aa881d-e703-493c-afa7-134b8eb81c98,DISK], DatanodeInfoWithStorage[127.0.0.1:44218,DS-860082be-d0da-4e93-9e3a-caf2b7880932,DISK], DatanodeInfoWithStorage[127.0.0.1:45816,DS-2d9c954c-ddc2-42ba-921b-2fcaf86cdaa6,DISK], DatanodeInfoWithStorage[127.0.0.1:44754,DS-74415c40-6ad6-44b1-b575-d37d9c109db1,DISK], DatanodeInfoWithStorage[127.0.0.1:44814,DS-fd3ee0ba-c6e9-420d-a472-e7b77fa3c790,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1114314277-172.17.0.20-1598442365520:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35241,DS-45cc861c-7b14-41b2-aa83-38e61f28cc7c,DISK], DatanodeInfoWithStorage[127.0.0.1:34529,DS-a2bc199e-8143-4130-820b-03b6701b2954,DISK], DatanodeInfoWithStorage[127.0.0.1:35897,DS-2e6307d1-7da0-4c8a-982e-ac66b985ac7f,DISK], DatanodeInfoWithStorage[127.0.0.1:44474,DS-e6aa881d-e703-493c-afa7-134b8eb81c98,DISK], DatanodeInfoWithStorage[127.0.0.1:44218,DS-860082be-d0da-4e93-9e3a-caf2b7880932,DISK], DatanodeInfoWithStorage[127.0.0.1:45816,DS-2d9c954c-ddc2-42ba-921b-2fcaf86cdaa6,DISK], DatanodeInfoWithStorage[127.0.0.1:44754,DS-74415c40-6ad6-44b1-b575-d37d9c109db1,DISK], DatanodeInfoWithStorage[127.0.0.1:44814,DS-fd3ee0ba-c6e9-420d-a472-e7b77fa3c790,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.best-effort
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1084712649-172.17.0.20-1598442409360:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43723,DS-555171c7-69e8-4bdc-b0f8-3151f445d706,DISK], DatanodeInfoWithStorage[127.0.0.1:39262,DS-025a2d64-68aa-41ed-bafe-5e2d5aefb53a,DISK], DatanodeInfoWithStorage[127.0.0.1:41263,DS-f3c84d32-ae66-42b0-851b-ac6cfd9fd6da,DISK], DatanodeInfoWithStorage[127.0.0.1:43058,DS-60c1b629-9c34-4db9-866e-174513363738,DISK], DatanodeInfoWithStorage[127.0.0.1:39754,DS-caf59ff9-c971-4584-a642-dd517a23b361,DISK], DatanodeInfoWithStorage[127.0.0.1:37792,DS-5a53c3eb-cb77-4281-bc10-2d011a7495bf,DISK], DatanodeInfoWithStorage[127.0.0.1:42814,DS-89839889-89e5-4ea5-afa0-f4e85ee376fb,DISK], DatanodeInfoWithStorage[127.0.0.1:44784,DS-82828966-6bf2-4500-89e6-7c3354d1236e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1084712649-172.17.0.20-1598442409360:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43723,DS-555171c7-69e8-4bdc-b0f8-3151f445d706,DISK], DatanodeInfoWithStorage[127.0.0.1:39262,DS-025a2d64-68aa-41ed-bafe-5e2d5aefb53a,DISK], DatanodeInfoWithStorage[127.0.0.1:41263,DS-f3c84d32-ae66-42b0-851b-ac6cfd9fd6da,DISK], DatanodeInfoWithStorage[127.0.0.1:43058,DS-60c1b629-9c34-4db9-866e-174513363738,DISK], DatanodeInfoWithStorage[127.0.0.1:39754,DS-caf59ff9-c971-4584-a642-dd517a23b361,DISK], DatanodeInfoWithStorage[127.0.0.1:37792,DS-5a53c3eb-cb77-4281-bc10-2d011a7495bf,DISK], DatanodeInfoWithStorage[127.0.0.1:42814,DS-89839889-89e5-4ea5-afa0-f4e85ee376fb,DISK], DatanodeInfoWithStorage[127.0.0.1:44784,DS-82828966-6bf2-4500-89e6-7c3354d1236e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.best-effort
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1618014321-172.17.0.20-1598442597153:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46282,DS-ec208244-a33b-41e8-a3e9-0421f1f10e95,DISK], DatanodeInfoWithStorage[127.0.0.1:41881,DS-3415be9b-04ed-4d89-b4a0-d1597162caeb,DISK], DatanodeInfoWithStorage[127.0.0.1:33002,DS-7c03a2a4-f139-483e-9ead-6dbdb0956c7c,DISK], DatanodeInfoWithStorage[127.0.0.1:45672,DS-13f9a723-8472-4c0f-95e0-396d397b9b5e,DISK], DatanodeInfoWithStorage[127.0.0.1:38229,DS-78d9170b-06c8-4109-b77e-1b35edd9f68a,DISK], DatanodeInfoWithStorage[127.0.0.1:41580,DS-dcba5c5c-f4dc-4523-ae7f-d9d918999dfe,DISK], DatanodeInfoWithStorage[127.0.0.1:40250,DS-48773a1e-9ee5-4393-914c-446de603843e,DISK], DatanodeInfoWithStorage[127.0.0.1:44173,DS-9bb405e6-f44d-43d9-92be-7b1813dce752,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1618014321-172.17.0.20-1598442597153:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46282,DS-ec208244-a33b-41e8-a3e9-0421f1f10e95,DISK], DatanodeInfoWithStorage[127.0.0.1:41881,DS-3415be9b-04ed-4d89-b4a0-d1597162caeb,DISK], DatanodeInfoWithStorage[127.0.0.1:33002,DS-7c03a2a4-f139-483e-9ead-6dbdb0956c7c,DISK], DatanodeInfoWithStorage[127.0.0.1:45672,DS-13f9a723-8472-4c0f-95e0-396d397b9b5e,DISK], DatanodeInfoWithStorage[127.0.0.1:38229,DS-78d9170b-06c8-4109-b77e-1b35edd9f68a,DISK], DatanodeInfoWithStorage[127.0.0.1:41580,DS-dcba5c5c-f4dc-4523-ae7f-d9d918999dfe,DISK], DatanodeInfoWithStorage[127.0.0.1:40250,DS-48773a1e-9ee5-4393-914c-446de603843e,DISK], DatanodeInfoWithStorage[127.0.0.1:44173,DS-9bb405e6-f44d-43d9-92be-7b1813dce752,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.best-effort
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-627558693-172.17.0.20-1598442828805:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43843,DS-1eee8753-3438-4af2-a480-7bf371edb1bb,DISK], DatanodeInfoWithStorage[127.0.0.1:41550,DS-a73c7ce1-f02f-4c3b-8807-03d1bd8fe9dd,DISK], DatanodeInfoWithStorage[127.0.0.1:34084,DS-15c71385-ef49-4393-b73d-f9a0d128ded8,DISK], DatanodeInfoWithStorage[127.0.0.1:35726,DS-42e78d50-3cfd-4cc8-9929-a8f33098f24f,DISK], DatanodeInfoWithStorage[127.0.0.1:42284,DS-a58f7e13-6ee1-428a-a235-e984005187f8,DISK], DatanodeInfoWithStorage[127.0.0.1:37509,DS-8b390212-7a14-4b58-a6b5-018b9c04fa9e,DISK], DatanodeInfoWithStorage[127.0.0.1:43875,DS-65a26b59-8c19-4803-8ddd-89c50991192d,DISK], DatanodeInfoWithStorage[127.0.0.1:39115,DS-76a9b122-ca9c-4e3b-b05e-90ab27e9c43e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-627558693-172.17.0.20-1598442828805:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43843,DS-1eee8753-3438-4af2-a480-7bf371edb1bb,DISK], DatanodeInfoWithStorage[127.0.0.1:41550,DS-a73c7ce1-f02f-4c3b-8807-03d1bd8fe9dd,DISK], DatanodeInfoWithStorage[127.0.0.1:34084,DS-15c71385-ef49-4393-b73d-f9a0d128ded8,DISK], DatanodeInfoWithStorage[127.0.0.1:35726,DS-42e78d50-3cfd-4cc8-9929-a8f33098f24f,DISK], DatanodeInfoWithStorage[127.0.0.1:42284,DS-a58f7e13-6ee1-428a-a235-e984005187f8,DISK], DatanodeInfoWithStorage[127.0.0.1:37509,DS-8b390212-7a14-4b58-a6b5-018b9c04fa9e,DISK], DatanodeInfoWithStorage[127.0.0.1:43875,DS-65a26b59-8c19-4803-8ddd-89c50991192d,DISK], DatanodeInfoWithStorage[127.0.0.1:39115,DS-76a9b122-ca9c-4e3b-b05e-90ab27e9c43e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.best-effort
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-854016902-172.17.0.20-1598442904832:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42761,DS-7dbc2015-e9ab-407a-805a-12f69cead946,DISK], DatanodeInfoWithStorage[127.0.0.1:44706,DS-f0327c56-ef59-4e30-8561-27c83b376e9a,DISK], DatanodeInfoWithStorage[127.0.0.1:32840,DS-4c1f70af-da85-4619-8a36-5145c1516f5c,DISK], DatanodeInfoWithStorage[127.0.0.1:46867,DS-5f7c655b-81cb-4500-aa96-ec02ad3d6887,DISK], DatanodeInfoWithStorage[127.0.0.1:44872,DS-7a6caa03-bd48-43f2-be61-94163b5021ec,DISK], DatanodeInfoWithStorage[127.0.0.1:39448,DS-51d1f074-8cd1-4d80-90a8-f03f0f554862,DISK], DatanodeInfoWithStorage[127.0.0.1:36773,DS-703ae2e9-b10a-4442-86e9-7fddef22ea80,DISK], DatanodeInfoWithStorage[127.0.0.1:38517,DS-01f5bd24-074b-4d7e-8283-6cee914d1216,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-854016902-172.17.0.20-1598442904832:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42761,DS-7dbc2015-e9ab-407a-805a-12f69cead946,DISK], DatanodeInfoWithStorage[127.0.0.1:44706,DS-f0327c56-ef59-4e30-8561-27c83b376e9a,DISK], DatanodeInfoWithStorage[127.0.0.1:32840,DS-4c1f70af-da85-4619-8a36-5145c1516f5c,DISK], DatanodeInfoWithStorage[127.0.0.1:46867,DS-5f7c655b-81cb-4500-aa96-ec02ad3d6887,DISK], DatanodeInfoWithStorage[127.0.0.1:44872,DS-7a6caa03-bd48-43f2-be61-94163b5021ec,DISK], DatanodeInfoWithStorage[127.0.0.1:39448,DS-51d1f074-8cd1-4d80-90a8-f03f0f554862,DISK], DatanodeInfoWithStorage[127.0.0.1:36773,DS-703ae2e9-b10a-4442-86e9-7fddef22ea80,DISK], DatanodeInfoWithStorage[127.0.0.1:38517,DS-01f5bd24-074b-4d7e-8283-6cee914d1216,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 9 out of 50
v1v1v2v2 failed with probability 29 out of 50
result: false positive !!!
Total execution time in seconds : 5479
