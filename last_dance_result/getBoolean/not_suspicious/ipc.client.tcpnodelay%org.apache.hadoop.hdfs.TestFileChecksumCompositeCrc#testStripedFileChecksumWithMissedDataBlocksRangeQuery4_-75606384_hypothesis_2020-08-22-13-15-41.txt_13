reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-124615642-172.17.0.20-1598102501011:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43157,DS-5df63487-81f3-43b7-b6bf-7a32355d935c,DISK], DatanodeInfoWithStorage[127.0.0.1:39676,DS-7ede0de6-8d80-4ede-b825-e34958e39680,DISK], DatanodeInfoWithStorage[127.0.0.1:35406,DS-cd950279-760f-4307-b46a-46f612377b41,DISK], DatanodeInfoWithStorage[127.0.0.1:38397,DS-1e2dcf89-aeb4-4a5c-a675-4a0bef06e002,DISK], DatanodeInfoWithStorage[127.0.0.1:41602,DS-8cf05ada-9326-4cd7-a786-230289fc89c9,DISK], DatanodeInfoWithStorage[127.0.0.1:34930,DS-1498d0c5-5ab5-4bd0-a497-4c92ebd7c261,DISK], DatanodeInfoWithStorage[127.0.0.1:37801,DS-43d27fe2-2b56-4586-b652-7a1fa5e4bd95,DISK], DatanodeInfoWithStorage[127.0.0.1:37047,DS-e6d7cb70-0153-419a-92d2-2236c0a24c3e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-124615642-172.17.0.20-1598102501011:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43157,DS-5df63487-81f3-43b7-b6bf-7a32355d935c,DISK], DatanodeInfoWithStorage[127.0.0.1:39676,DS-7ede0de6-8d80-4ede-b825-e34958e39680,DISK], DatanodeInfoWithStorage[127.0.0.1:35406,DS-cd950279-760f-4307-b46a-46f612377b41,DISK], DatanodeInfoWithStorage[127.0.0.1:38397,DS-1e2dcf89-aeb4-4a5c-a675-4a0bef06e002,DISK], DatanodeInfoWithStorage[127.0.0.1:41602,DS-8cf05ada-9326-4cd7-a786-230289fc89c9,DISK], DatanodeInfoWithStorage[127.0.0.1:34930,DS-1498d0c5-5ab5-4bd0-a497-4c92ebd7c261,DISK], DatanodeInfoWithStorage[127.0.0.1:37801,DS-43d27fe2-2b56-4586-b652-7a1fa5e4bd95,DISK], DatanodeInfoWithStorage[127.0.0.1:37047,DS-e6d7cb70-0153-419a-92d2-2236c0a24c3e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2687458-172.17.0.20-1598102572341:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36618,DS-31fb4ca2-c1f0-4296-b106-d75dd2ba7f25,DISK], DatanodeInfoWithStorage[127.0.0.1:36175,DS-bd9e1d51-81c3-42cd-8c33-5bf4fe7844c2,DISK], DatanodeInfoWithStorage[127.0.0.1:42037,DS-81e55458-653c-4011-b3ac-323b2ac62493,DISK], DatanodeInfoWithStorage[127.0.0.1:40763,DS-f0ef61da-0afd-4d60-8842-ef4ab50d61c9,DISK], DatanodeInfoWithStorage[127.0.0.1:35960,DS-7e3d4180-d3a5-4457-bca4-f9c0d59d27cf,DISK], DatanodeInfoWithStorage[127.0.0.1:42973,DS-e2706500-3013-446a-85f7-b1cb79428793,DISK], DatanodeInfoWithStorage[127.0.0.1:36342,DS-58262773-902b-4e1d-a760-d1966bb167d4,DISK], DatanodeInfoWithStorage[127.0.0.1:39725,DS-8719b18a-6b03-4fdd-832d-9012466222ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2687458-172.17.0.20-1598102572341:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36618,DS-31fb4ca2-c1f0-4296-b106-d75dd2ba7f25,DISK], DatanodeInfoWithStorage[127.0.0.1:36175,DS-bd9e1d51-81c3-42cd-8c33-5bf4fe7844c2,DISK], DatanodeInfoWithStorage[127.0.0.1:42037,DS-81e55458-653c-4011-b3ac-323b2ac62493,DISK], DatanodeInfoWithStorage[127.0.0.1:40763,DS-f0ef61da-0afd-4d60-8842-ef4ab50d61c9,DISK], DatanodeInfoWithStorage[127.0.0.1:35960,DS-7e3d4180-d3a5-4457-bca4-f9c0d59d27cf,DISK], DatanodeInfoWithStorage[127.0.0.1:42973,DS-e2706500-3013-446a-85f7-b1cb79428793,DISK], DatanodeInfoWithStorage[127.0.0.1:36342,DS-58262773-902b-4e1d-a760-d1966bb167d4,DISK], DatanodeInfoWithStorage[127.0.0.1:39725,DS-8719b18a-6b03-4fdd-832d-9012466222ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1531804237-172.17.0.20-1598102669629:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35188,DS-d40d4a40-8722-43cc-94c0-3ea98d49a85c,DISK], DatanodeInfoWithStorage[127.0.0.1:44694,DS-0d787f19-c5c1-4eb0-b7f9-7e5b99c6197f,DISK], DatanodeInfoWithStorage[127.0.0.1:46445,DS-552a0a0f-857b-43ee-827f-6c522135a2bd,DISK], DatanodeInfoWithStorage[127.0.0.1:35728,DS-087f03a8-77da-4086-9f5e-c59f5e0fcf91,DISK], DatanodeInfoWithStorage[127.0.0.1:46824,DS-d8df67e8-2800-483f-963d-359f04a2314a,DISK], DatanodeInfoWithStorage[127.0.0.1:40133,DS-7e3591d3-7579-4ecf-a2a9-b4f7b1215b65,DISK], DatanodeInfoWithStorage[127.0.0.1:41605,DS-d7522999-edc3-4d6f-a7a3-4f826d6503e2,DISK], DatanodeInfoWithStorage[127.0.0.1:42715,DS-47286f91-18ad-4a99-91bc-3b8caefae3a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1531804237-172.17.0.20-1598102669629:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35188,DS-d40d4a40-8722-43cc-94c0-3ea98d49a85c,DISK], DatanodeInfoWithStorage[127.0.0.1:44694,DS-0d787f19-c5c1-4eb0-b7f9-7e5b99c6197f,DISK], DatanodeInfoWithStorage[127.0.0.1:46445,DS-552a0a0f-857b-43ee-827f-6c522135a2bd,DISK], DatanodeInfoWithStorage[127.0.0.1:35728,DS-087f03a8-77da-4086-9f5e-c59f5e0fcf91,DISK], DatanodeInfoWithStorage[127.0.0.1:46824,DS-d8df67e8-2800-483f-963d-359f04a2314a,DISK], DatanodeInfoWithStorage[127.0.0.1:40133,DS-7e3591d3-7579-4ecf-a2a9-b4f7b1215b65,DISK], DatanodeInfoWithStorage[127.0.0.1:41605,DS-d7522999-edc3-4d6f-a7a3-4f826d6503e2,DISK], DatanodeInfoWithStorage[127.0.0.1:42715,DS-47286f91-18ad-4a99-91bc-3b8caefae3a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-599561160-172.17.0.20-1598102739014:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39699,DS-329ed6e6-d7c6-49d7-af22-5b1176da4863,DISK], DatanodeInfoWithStorage[127.0.0.1:37779,DS-9450d25c-7cb3-46aa-9d55-79582a4f3c94,DISK], DatanodeInfoWithStorage[127.0.0.1:32857,DS-ef879ca6-bb81-452e-961c-f070c40a1024,DISK], DatanodeInfoWithStorage[127.0.0.1:35545,DS-c4b49ccb-352f-4c11-8947-28dae251266b,DISK], DatanodeInfoWithStorage[127.0.0.1:37919,DS-5fc8d3be-92e0-463c-a9b6-2002fb603f16,DISK], DatanodeInfoWithStorage[127.0.0.1:41167,DS-ded4de46-7bcd-4201-a4d2-4244d5159ddd,DISK], DatanodeInfoWithStorage[127.0.0.1:44430,DS-ed7b8eb3-c657-481d-b075-ca2fb306927a,DISK], DatanodeInfoWithStorage[127.0.0.1:33368,DS-b5f79523-feb8-460f-a0b7-052257c9307c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-599561160-172.17.0.20-1598102739014:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39699,DS-329ed6e6-d7c6-49d7-af22-5b1176da4863,DISK], DatanodeInfoWithStorage[127.0.0.1:37779,DS-9450d25c-7cb3-46aa-9d55-79582a4f3c94,DISK], DatanodeInfoWithStorage[127.0.0.1:32857,DS-ef879ca6-bb81-452e-961c-f070c40a1024,DISK], DatanodeInfoWithStorage[127.0.0.1:35545,DS-c4b49ccb-352f-4c11-8947-28dae251266b,DISK], DatanodeInfoWithStorage[127.0.0.1:37919,DS-5fc8d3be-92e0-463c-a9b6-2002fb603f16,DISK], DatanodeInfoWithStorage[127.0.0.1:41167,DS-ded4de46-7bcd-4201-a4d2-4244d5159ddd,DISK], DatanodeInfoWithStorage[127.0.0.1:44430,DS-ed7b8eb3-c657-481d-b075-ca2fb306927a,DISK], DatanodeInfoWithStorage[127.0.0.1:33368,DS-b5f79523-feb8-460f-a0b7-052257c9307c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1730301378-172.17.0.20-1598102965221:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41702,DS-9c6e7011-2cde-4f48-acb7-f72adca14b6b,DISK], DatanodeInfoWithStorage[127.0.0.1:34606,DS-267602d3-12d5-4b28-ab70-a75238593fa3,DISK], DatanodeInfoWithStorage[127.0.0.1:46533,DS-e96928fe-affb-40bc-b206-7860b1aafd53,DISK], DatanodeInfoWithStorage[127.0.0.1:45919,DS-76b89124-8245-4100-a35a-bf23d4d33f2d,DISK], DatanodeInfoWithStorage[127.0.0.1:43194,DS-cf97f1c7-4cda-41aa-9bb6-28337081ba14,DISK], DatanodeInfoWithStorage[127.0.0.1:34836,DS-84fbf983-f73c-4eff-a342-4545ba638e1a,DISK], DatanodeInfoWithStorage[127.0.0.1:46800,DS-9674b1d6-7985-49ae-b722-12bfd8f42e6a,DISK], DatanodeInfoWithStorage[127.0.0.1:36885,DS-4d5aa518-c74b-4f6a-b3e6-2d4276e12186,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1730301378-172.17.0.20-1598102965221:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41702,DS-9c6e7011-2cde-4f48-acb7-f72adca14b6b,DISK], DatanodeInfoWithStorage[127.0.0.1:34606,DS-267602d3-12d5-4b28-ab70-a75238593fa3,DISK], DatanodeInfoWithStorage[127.0.0.1:46533,DS-e96928fe-affb-40bc-b206-7860b1aafd53,DISK], DatanodeInfoWithStorage[127.0.0.1:45919,DS-76b89124-8245-4100-a35a-bf23d4d33f2d,DISK], DatanodeInfoWithStorage[127.0.0.1:43194,DS-cf97f1c7-4cda-41aa-9bb6-28337081ba14,DISK], DatanodeInfoWithStorage[127.0.0.1:34836,DS-84fbf983-f73c-4eff-a342-4545ba638e1a,DISK], DatanodeInfoWithStorage[127.0.0.1:46800,DS-9674b1d6-7985-49ae-b722-12bfd8f42e6a,DISK], DatanodeInfoWithStorage[127.0.0.1:36885,DS-4d5aa518-c74b-4f6a-b3e6-2d4276e12186,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-479484627-172.17.0.20-1598102999343:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35341,DS-484cea78-9b12-4e8a-9a5d-3c1492b2ad3a,DISK], DatanodeInfoWithStorage[127.0.0.1:44085,DS-a758255f-741a-48d7-92d5-fa642c31c1a6,DISK], DatanodeInfoWithStorage[127.0.0.1:36683,DS-3b64ef21-14e8-4b8b-8f40-7380dde4a904,DISK], DatanodeInfoWithStorage[127.0.0.1:45980,DS-2f6bfe6d-0afe-4724-b538-25b37c8fa464,DISK], DatanodeInfoWithStorage[127.0.0.1:43957,DS-3bddf35e-2405-4958-977e-2a0e0a43c05c,DISK], DatanodeInfoWithStorage[127.0.0.1:40863,DS-257bc6e5-5dae-4210-8fbe-880a886974b2,DISK], DatanodeInfoWithStorage[127.0.0.1:39671,DS-099d0b7c-b9bd-492e-8661-36d999340515,DISK], DatanodeInfoWithStorage[127.0.0.1:41182,DS-5114ec38-d7b1-40b6-a53a-1867f8c502ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-479484627-172.17.0.20-1598102999343:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35341,DS-484cea78-9b12-4e8a-9a5d-3c1492b2ad3a,DISK], DatanodeInfoWithStorage[127.0.0.1:44085,DS-a758255f-741a-48d7-92d5-fa642c31c1a6,DISK], DatanodeInfoWithStorage[127.0.0.1:36683,DS-3b64ef21-14e8-4b8b-8f40-7380dde4a904,DISK], DatanodeInfoWithStorage[127.0.0.1:45980,DS-2f6bfe6d-0afe-4724-b538-25b37c8fa464,DISK], DatanodeInfoWithStorage[127.0.0.1:43957,DS-3bddf35e-2405-4958-977e-2a0e0a43c05c,DISK], DatanodeInfoWithStorage[127.0.0.1:40863,DS-257bc6e5-5dae-4210-8fbe-880a886974b2,DISK], DatanodeInfoWithStorage[127.0.0.1:39671,DS-099d0b7c-b9bd-492e-8661-36d999340515,DISK], DatanodeInfoWithStorage[127.0.0.1:41182,DS-5114ec38-d7b1-40b6-a53a-1867f8c502ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-961824311-172.17.0.20-1598103333811:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42780,DS-635efb68-0434-4f2a-be25-c4be4944b7d4,DISK], DatanodeInfoWithStorage[127.0.0.1:42735,DS-41aa118c-642b-40b2-91d0-7b9e20a4c673,DISK], DatanodeInfoWithStorage[127.0.0.1:36663,DS-633190ba-02c1-4530-bdb4-347e607f9ea0,DISK], DatanodeInfoWithStorage[127.0.0.1:32928,DS-0b498b4d-0900-400d-804b-36de667dd2c7,DISK], DatanodeInfoWithStorage[127.0.0.1:39191,DS-45fd787d-1979-42b4-8556-adf4a4acfbff,DISK], DatanodeInfoWithStorage[127.0.0.1:34141,DS-9f51ea13-2eff-49aa-bdd0-90cebf3ebd80,DISK], DatanodeInfoWithStorage[127.0.0.1:32818,DS-38446de3-73cb-4777-acbd-ec550b516d24,DISK], DatanodeInfoWithStorage[127.0.0.1:42942,DS-f839539b-40d2-4988-9e6f-2f69406a4522,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-961824311-172.17.0.20-1598103333811:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42780,DS-635efb68-0434-4f2a-be25-c4be4944b7d4,DISK], DatanodeInfoWithStorage[127.0.0.1:42735,DS-41aa118c-642b-40b2-91d0-7b9e20a4c673,DISK], DatanodeInfoWithStorage[127.0.0.1:36663,DS-633190ba-02c1-4530-bdb4-347e607f9ea0,DISK], DatanodeInfoWithStorage[127.0.0.1:32928,DS-0b498b4d-0900-400d-804b-36de667dd2c7,DISK], DatanodeInfoWithStorage[127.0.0.1:39191,DS-45fd787d-1979-42b4-8556-adf4a4acfbff,DISK], DatanodeInfoWithStorage[127.0.0.1:34141,DS-9f51ea13-2eff-49aa-bdd0-90cebf3ebd80,DISK], DatanodeInfoWithStorage[127.0.0.1:32818,DS-38446de3-73cb-4777-acbd-ec550b516d24,DISK], DatanodeInfoWithStorage[127.0.0.1:42942,DS-f839539b-40d2-4988-9e6f-2f69406a4522,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1407591172-172.17.0.20-1598104424171:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40536,DS-e25bd4c8-2cb8-4dac-a8c2-5802b22c5f81,DISK], DatanodeInfoWithStorage[127.0.0.1:42084,DS-697408b2-42ae-425b-9ea8-b36a82898250,DISK], DatanodeInfoWithStorage[127.0.0.1:44310,DS-74ada1e3-8399-49c5-bbda-29a5760dcc0d,DISK], DatanodeInfoWithStorage[127.0.0.1:35629,DS-f788f841-563c-4f58-ae16-24e7466eb330,DISK], DatanodeInfoWithStorage[127.0.0.1:39071,DS-d6352d08-e303-4d82-bd43-22046b398dbd,DISK], DatanodeInfoWithStorage[127.0.0.1:38917,DS-5fc22df9-0dd2-4cf6-98f3-aa4bdfd9dd3c,DISK], DatanodeInfoWithStorage[127.0.0.1:40639,DS-f6221e90-74a3-4c59-86c3-762c610012eb,DISK], DatanodeInfoWithStorage[127.0.0.1:36993,DS-381b2519-f209-47d8-a1a1-1a8e2135bf0a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1407591172-172.17.0.20-1598104424171:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40536,DS-e25bd4c8-2cb8-4dac-a8c2-5802b22c5f81,DISK], DatanodeInfoWithStorage[127.0.0.1:42084,DS-697408b2-42ae-425b-9ea8-b36a82898250,DISK], DatanodeInfoWithStorage[127.0.0.1:44310,DS-74ada1e3-8399-49c5-bbda-29a5760dcc0d,DISK], DatanodeInfoWithStorage[127.0.0.1:35629,DS-f788f841-563c-4f58-ae16-24e7466eb330,DISK], DatanodeInfoWithStorage[127.0.0.1:39071,DS-d6352d08-e303-4d82-bd43-22046b398dbd,DISK], DatanodeInfoWithStorage[127.0.0.1:38917,DS-5fc22df9-0dd2-4cf6-98f3-aa4bdfd9dd3c,DISK], DatanodeInfoWithStorage[127.0.0.1:40639,DS-f6221e90-74a3-4c59-86c3-762c610012eb,DISK], DatanodeInfoWithStorage[127.0.0.1:36993,DS-381b2519-f209-47d8-a1a1-1a8e2135bf0a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-291449288-172.17.0.20-1598104535616:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37560,DS-05783e4e-e0c9-4d75-bf25-0accc4bc790c,DISK], DatanodeInfoWithStorage[127.0.0.1:43916,DS-78f2605b-df15-4848-bf94-438829b5c90f,DISK], DatanodeInfoWithStorage[127.0.0.1:44814,DS-b424605d-27d1-4bd2-9812-f4e32975b64a,DISK], DatanodeInfoWithStorage[127.0.0.1:38795,DS-8a59c6ee-3e93-461c-a60b-4ab774873035,DISK], DatanodeInfoWithStorage[127.0.0.1:38417,DS-7fcfd243-6511-4404-90ef-a38a764fa2f2,DISK], DatanodeInfoWithStorage[127.0.0.1:45979,DS-233832b3-2ed1-4b6e-a2de-36b4f01d6752,DISK], DatanodeInfoWithStorage[127.0.0.1:41010,DS-0daaeb16-dbeb-4538-a7a8-7af99750a40c,DISK], DatanodeInfoWithStorage[127.0.0.1:45051,DS-ddeeb657-3b0c-4fe3-9f32-13a41299defb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-291449288-172.17.0.20-1598104535616:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37560,DS-05783e4e-e0c9-4d75-bf25-0accc4bc790c,DISK], DatanodeInfoWithStorage[127.0.0.1:43916,DS-78f2605b-df15-4848-bf94-438829b5c90f,DISK], DatanodeInfoWithStorage[127.0.0.1:44814,DS-b424605d-27d1-4bd2-9812-f4e32975b64a,DISK], DatanodeInfoWithStorage[127.0.0.1:38795,DS-8a59c6ee-3e93-461c-a60b-4ab774873035,DISK], DatanodeInfoWithStorage[127.0.0.1:38417,DS-7fcfd243-6511-4404-90ef-a38a764fa2f2,DISK], DatanodeInfoWithStorage[127.0.0.1:45979,DS-233832b3-2ed1-4b6e-a2de-36b4f01d6752,DISK], DatanodeInfoWithStorage[127.0.0.1:41010,DS-0daaeb16-dbeb-4538-a7a8-7af99750a40c,DISK], DatanodeInfoWithStorage[127.0.0.1:45051,DS-ddeeb657-3b0c-4fe3-9f32-13a41299defb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-7060853-172.17.0.20-1598105900753:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37921,DS-f4de7b5b-8345-45bb-87e0-23f9e30a1587,DISK], DatanodeInfoWithStorage[127.0.0.1:35976,DS-46517eef-d6c6-4b87-bb47-3c3db46bc58d,DISK], DatanodeInfoWithStorage[127.0.0.1:36304,DS-f43bba70-bed7-4364-b55c-a1fc2cb9cd40,DISK], DatanodeInfoWithStorage[127.0.0.1:41198,DS-4d863640-592e-4841-bf6d-0220908b1938,DISK], DatanodeInfoWithStorage[127.0.0.1:39362,DS-aa166e4e-1995-4f00-b107-299d8dc4e4ae,DISK], DatanodeInfoWithStorage[127.0.0.1:45311,DS-a1ffb35b-57c1-4c71-abf3-9fa4b1995348,DISK], DatanodeInfoWithStorage[127.0.0.1:39503,DS-d65e49a4-5836-4f36-8d64-3f67e0d06cbc,DISK], DatanodeInfoWithStorage[127.0.0.1:37446,DS-78fd7712-143a-4b4d-a496-763abc2e5a44,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-7060853-172.17.0.20-1598105900753:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37921,DS-f4de7b5b-8345-45bb-87e0-23f9e30a1587,DISK], DatanodeInfoWithStorage[127.0.0.1:35976,DS-46517eef-d6c6-4b87-bb47-3c3db46bc58d,DISK], DatanodeInfoWithStorage[127.0.0.1:36304,DS-f43bba70-bed7-4364-b55c-a1fc2cb9cd40,DISK], DatanodeInfoWithStorage[127.0.0.1:41198,DS-4d863640-592e-4841-bf6d-0220908b1938,DISK], DatanodeInfoWithStorage[127.0.0.1:39362,DS-aa166e4e-1995-4f00-b107-299d8dc4e4ae,DISK], DatanodeInfoWithStorage[127.0.0.1:45311,DS-a1ffb35b-57c1-4c71-abf3-9fa4b1995348,DISK], DatanodeInfoWithStorage[127.0.0.1:39503,DS-d65e49a4-5836-4f36-8d64-3f67e0d06cbc,DISK], DatanodeInfoWithStorage[127.0.0.1:37446,DS-78fd7712-143a-4b4d-a496-763abc2e5a44,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-357810268-172.17.0.20-1598105939113:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42839,DS-3a8646d4-050d-4c88-8a2b-59f3bfe1fef5,DISK], DatanodeInfoWithStorage[127.0.0.1:35406,DS-26933330-ab6b-49a7-bc36-ac82b3c0aa82,DISK], DatanodeInfoWithStorage[127.0.0.1:36425,DS-33373cad-13d1-49ed-9f73-12013b3cd487,DISK], DatanodeInfoWithStorage[127.0.0.1:36427,DS-249dfc75-6e77-484d-bd3a-6a66447084ce,DISK], DatanodeInfoWithStorage[127.0.0.1:36794,DS-56eb1db6-789f-438d-8fb4-1553199a08f6,DISK], DatanodeInfoWithStorage[127.0.0.1:38713,DS-7adf1c1a-decb-41d5-aaed-08eea407bf77,DISK], DatanodeInfoWithStorage[127.0.0.1:36915,DS-3d338a52-3180-43a6-88ab-e917bb1b4b53,DISK], DatanodeInfoWithStorage[127.0.0.1:40975,DS-68e551bd-a0d9-47e7-b2ed-0a4022d8bfe5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-357810268-172.17.0.20-1598105939113:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42839,DS-3a8646d4-050d-4c88-8a2b-59f3bfe1fef5,DISK], DatanodeInfoWithStorage[127.0.0.1:35406,DS-26933330-ab6b-49a7-bc36-ac82b3c0aa82,DISK], DatanodeInfoWithStorage[127.0.0.1:36425,DS-33373cad-13d1-49ed-9f73-12013b3cd487,DISK], DatanodeInfoWithStorage[127.0.0.1:36427,DS-249dfc75-6e77-484d-bd3a-6a66447084ce,DISK], DatanodeInfoWithStorage[127.0.0.1:36794,DS-56eb1db6-789f-438d-8fb4-1553199a08f6,DISK], DatanodeInfoWithStorage[127.0.0.1:38713,DS-7adf1c1a-decb-41d5-aaed-08eea407bf77,DISK], DatanodeInfoWithStorage[127.0.0.1:36915,DS-3d338a52-3180-43a6-88ab-e917bb1b4b53,DISK], DatanodeInfoWithStorage[127.0.0.1:40975,DS-68e551bd-a0d9-47e7-b2ed-0a4022d8bfe5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1454483163-172.17.0.20-1598106079351:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37111,DS-a123ecbd-b3a4-44ca-9184-e52913d6610f,DISK], DatanodeInfoWithStorage[127.0.0.1:44059,DS-8b8c4535-868d-42e9-b8ad-7d2d522ed61a,DISK], DatanodeInfoWithStorage[127.0.0.1:42701,DS-c39f0857-0666-43f9-a167-061780c44a5c,DISK], DatanodeInfoWithStorage[127.0.0.1:46130,DS-a0ce94eb-a48b-4b41-8a79-bc5ecce5855e,DISK], DatanodeInfoWithStorage[127.0.0.1:33520,DS-33e65ce8-317b-4b90-a647-2782b7e05a09,DISK], DatanodeInfoWithStorage[127.0.0.1:34572,DS-83424aed-3918-410a-a8f7-5d7890e89e8c,DISK], DatanodeInfoWithStorage[127.0.0.1:34306,DS-e0785186-0265-406c-890e-fdf3b597a6ba,DISK], DatanodeInfoWithStorage[127.0.0.1:46696,DS-34475097-c46e-4c3a-81e9-918f45b6be15,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1454483163-172.17.0.20-1598106079351:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37111,DS-a123ecbd-b3a4-44ca-9184-e52913d6610f,DISK], DatanodeInfoWithStorage[127.0.0.1:44059,DS-8b8c4535-868d-42e9-b8ad-7d2d522ed61a,DISK], DatanodeInfoWithStorage[127.0.0.1:42701,DS-c39f0857-0666-43f9-a167-061780c44a5c,DISK], DatanodeInfoWithStorage[127.0.0.1:46130,DS-a0ce94eb-a48b-4b41-8a79-bc5ecce5855e,DISK], DatanodeInfoWithStorage[127.0.0.1:33520,DS-33e65ce8-317b-4b90-a647-2782b7e05a09,DISK], DatanodeInfoWithStorage[127.0.0.1:34572,DS-83424aed-3918-410a-a8f7-5d7890e89e8c,DISK], DatanodeInfoWithStorage[127.0.0.1:34306,DS-e0785186-0265-406c-890e-fdf3b597a6ba,DISK], DatanodeInfoWithStorage[127.0.0.1:46696,DS-34475097-c46e-4c3a-81e9-918f45b6be15,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-855683908-172.17.0.20-1598106110784:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46735,DS-6608a009-30bc-4413-b487-921d7e5c53d0,DISK], DatanodeInfoWithStorage[127.0.0.1:42150,DS-e5d3c04f-1dc1-41c9-9362-6b8514ea3772,DISK], DatanodeInfoWithStorage[127.0.0.1:34991,DS-2449b0a6-0d2f-450d-9ed4-9fac34f1f62b,DISK], DatanodeInfoWithStorage[127.0.0.1:37179,DS-6e4908ba-5044-48b4-9a56-04c2dbb6487b,DISK], DatanodeInfoWithStorage[127.0.0.1:45155,DS-a3e58f68-2c91-4be0-bf90-20df0ebf4256,DISK], DatanodeInfoWithStorage[127.0.0.1:40309,DS-cc50da56-80b9-499d-925a-b8b15ea565e4,DISK], DatanodeInfoWithStorage[127.0.0.1:41105,DS-c6a0735f-506e-495a-959f-69a4eddd1897,DISK], DatanodeInfoWithStorage[127.0.0.1:39050,DS-0ace5937-ee38-46dc-ba9d-f192c26177db,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-855683908-172.17.0.20-1598106110784:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46735,DS-6608a009-30bc-4413-b487-921d7e5c53d0,DISK], DatanodeInfoWithStorage[127.0.0.1:42150,DS-e5d3c04f-1dc1-41c9-9362-6b8514ea3772,DISK], DatanodeInfoWithStorage[127.0.0.1:34991,DS-2449b0a6-0d2f-450d-9ed4-9fac34f1f62b,DISK], DatanodeInfoWithStorage[127.0.0.1:37179,DS-6e4908ba-5044-48b4-9a56-04c2dbb6487b,DISK], DatanodeInfoWithStorage[127.0.0.1:45155,DS-a3e58f68-2c91-4be0-bf90-20df0ebf4256,DISK], DatanodeInfoWithStorage[127.0.0.1:40309,DS-cc50da56-80b9-499d-925a-b8b15ea565e4,DISK], DatanodeInfoWithStorage[127.0.0.1:41105,DS-c6a0735f-506e-495a-959f-69a4eddd1897,DISK], DatanodeInfoWithStorage[127.0.0.1:39050,DS-0ace5937-ee38-46dc-ba9d-f192c26177db,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-207758344-172.17.0.20-1598106359061:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34733,DS-7029b64b-3853-4efd-9032-35b05d69103d,DISK], DatanodeInfoWithStorage[127.0.0.1:41938,DS-9b5dae9d-53fe-4a12-a0b9-e6ea4dac1548,DISK], DatanodeInfoWithStorage[127.0.0.1:37992,DS-2201a1d2-6488-4216-8880-44a469735374,DISK], DatanodeInfoWithStorage[127.0.0.1:38542,DS-3ac42634-da54-4eb7-93b3-ce35ffeb5966,DISK], DatanodeInfoWithStorage[127.0.0.1:46480,DS-2ba456e7-13c7-495b-ba00-d5dc62b2d04f,DISK], DatanodeInfoWithStorage[127.0.0.1:37691,DS-4b784a0f-5786-42cb-843e-7bf8aa838982,DISK], DatanodeInfoWithStorage[127.0.0.1:42359,DS-797a53f4-aa04-4373-834a-4d86bf4f665f,DISK], DatanodeInfoWithStorage[127.0.0.1:42420,DS-d17f15c0-ef70-492e-b027-c1fdfa8ff25d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-207758344-172.17.0.20-1598106359061:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34733,DS-7029b64b-3853-4efd-9032-35b05d69103d,DISK], DatanodeInfoWithStorage[127.0.0.1:41938,DS-9b5dae9d-53fe-4a12-a0b9-e6ea4dac1548,DISK], DatanodeInfoWithStorage[127.0.0.1:37992,DS-2201a1d2-6488-4216-8880-44a469735374,DISK], DatanodeInfoWithStorage[127.0.0.1:38542,DS-3ac42634-da54-4eb7-93b3-ce35ffeb5966,DISK], DatanodeInfoWithStorage[127.0.0.1:46480,DS-2ba456e7-13c7-495b-ba00-d5dc62b2d04f,DISK], DatanodeInfoWithStorage[127.0.0.1:37691,DS-4b784a0f-5786-42cb-843e-7bf8aa838982,DISK], DatanodeInfoWithStorage[127.0.0.1:42359,DS-797a53f4-aa04-4373-834a-4d86bf4f665f,DISK], DatanodeInfoWithStorage[127.0.0.1:42420,DS-d17f15c0-ef70-492e-b027-c1fdfa8ff25d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-496780208-172.17.0.20-1598106394040:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41171,DS-e9a50894-265f-43c7-9f3f-0d266c1b4201,DISK], DatanodeInfoWithStorage[127.0.0.1:36910,DS-87953db5-feaa-4b79-9290-2ab3d3bc16aa,DISK], DatanodeInfoWithStorage[127.0.0.1:42023,DS-106d2ca1-c3b4-4138-8cda-2d606b655173,DISK], DatanodeInfoWithStorage[127.0.0.1:42190,DS-2e6d5a72-3e9e-4c8c-aa6d-e7fbc69d3a26,DISK], DatanodeInfoWithStorage[127.0.0.1:42205,DS-e7e6db30-f337-4ef7-974f-e390e9e10977,DISK], DatanodeInfoWithStorage[127.0.0.1:39976,DS-46fca202-6608-4d7c-8f11-7686054aa0f5,DISK], DatanodeInfoWithStorage[127.0.0.1:37825,DS-0c738a2b-7a1a-4628-b467-40bf1aacbbd4,DISK], DatanodeInfoWithStorage[127.0.0.1:46598,DS-71277aa4-4948-4acf-8a72-4494c0ccdd95,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-496780208-172.17.0.20-1598106394040:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41171,DS-e9a50894-265f-43c7-9f3f-0d266c1b4201,DISK], DatanodeInfoWithStorage[127.0.0.1:36910,DS-87953db5-feaa-4b79-9290-2ab3d3bc16aa,DISK], DatanodeInfoWithStorage[127.0.0.1:42023,DS-106d2ca1-c3b4-4138-8cda-2d606b655173,DISK], DatanodeInfoWithStorage[127.0.0.1:42190,DS-2e6d5a72-3e9e-4c8c-aa6d-e7fbc69d3a26,DISK], DatanodeInfoWithStorage[127.0.0.1:42205,DS-e7e6db30-f337-4ef7-974f-e390e9e10977,DISK], DatanodeInfoWithStorage[127.0.0.1:39976,DS-46fca202-6608-4d7c-8f11-7686054aa0f5,DISK], DatanodeInfoWithStorage[127.0.0.1:37825,DS-0c738a2b-7a1a-4628-b467-40bf1aacbbd4,DISK], DatanodeInfoWithStorage[127.0.0.1:46598,DS-71277aa4-4948-4acf-8a72-4494c0ccdd95,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1532055792-172.17.0.20-1598107089144:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35566,DS-2484ccc8-cde8-47ec-ba48-4b133d3f2145,DISK], DatanodeInfoWithStorage[127.0.0.1:41994,DS-f14f4f5d-4347-4aba-93f6-7249f9b5542d,DISK], DatanodeInfoWithStorage[127.0.0.1:42699,DS-53688a5c-2b94-408d-a35d-09f1ea33a73d,DISK], DatanodeInfoWithStorage[127.0.0.1:41601,DS-b9970863-cbfa-474c-9ad5-53aefc205d35,DISK], DatanodeInfoWithStorage[127.0.0.1:39199,DS-5c69dc1e-aa23-4eda-9f6b-68027dd276b5,DISK], DatanodeInfoWithStorage[127.0.0.1:45135,DS-885f65c1-2365-41f4-8fab-c3e908669240,DISK], DatanodeInfoWithStorage[127.0.0.1:38452,DS-5809a487-fe11-4d6b-9406-6f7d14423c7e,DISK], DatanodeInfoWithStorage[127.0.0.1:46819,DS-cf5be418-c62d-4c64-8029-4c71876dbe4d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1532055792-172.17.0.20-1598107089144:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35566,DS-2484ccc8-cde8-47ec-ba48-4b133d3f2145,DISK], DatanodeInfoWithStorage[127.0.0.1:41994,DS-f14f4f5d-4347-4aba-93f6-7249f9b5542d,DISK], DatanodeInfoWithStorage[127.0.0.1:42699,DS-53688a5c-2b94-408d-a35d-09f1ea33a73d,DISK], DatanodeInfoWithStorage[127.0.0.1:41601,DS-b9970863-cbfa-474c-9ad5-53aefc205d35,DISK], DatanodeInfoWithStorage[127.0.0.1:39199,DS-5c69dc1e-aa23-4eda-9f6b-68027dd276b5,DISK], DatanodeInfoWithStorage[127.0.0.1:45135,DS-885f65c1-2365-41f4-8fab-c3e908669240,DISK], DatanodeInfoWithStorage[127.0.0.1:38452,DS-5809a487-fe11-4d6b-9406-6f7d14423c7e,DISK], DatanodeInfoWithStorage[127.0.0.1:46819,DS-cf5be418-c62d-4c64-8029-4c71876dbe4d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-258097497-172.17.0.20-1598107458657:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45285,DS-83f03e33-70b0-473c-bf0b-5b21fe2274cf,DISK], DatanodeInfoWithStorage[127.0.0.1:38809,DS-ce3851a9-a0ca-45d9-9f97-20f64f8c217a,DISK], DatanodeInfoWithStorage[127.0.0.1:35224,DS-f481a81e-26bf-4cbf-a36c-277015ff9437,DISK], DatanodeInfoWithStorage[127.0.0.1:44464,DS-48f6c162-00c7-4a71-810b-39bbc8b87170,DISK], DatanodeInfoWithStorage[127.0.0.1:41622,DS-51db44ca-3bfa-4b1f-b313-1daee3f3a35c,DISK], DatanodeInfoWithStorage[127.0.0.1:42706,DS-e94abfaf-e671-4312-be24-5d376aa9ba20,DISK], DatanodeInfoWithStorage[127.0.0.1:40935,DS-bbdabee0-c647-4293-8321-b9936bd9ce59,DISK], DatanodeInfoWithStorage[127.0.0.1:46077,DS-a9d336aa-8b26-4fbe-ad18-c8c27034d964,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-258097497-172.17.0.20-1598107458657:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45285,DS-83f03e33-70b0-473c-bf0b-5b21fe2274cf,DISK], DatanodeInfoWithStorage[127.0.0.1:38809,DS-ce3851a9-a0ca-45d9-9f97-20f64f8c217a,DISK], DatanodeInfoWithStorage[127.0.0.1:35224,DS-f481a81e-26bf-4cbf-a36c-277015ff9437,DISK], DatanodeInfoWithStorage[127.0.0.1:44464,DS-48f6c162-00c7-4a71-810b-39bbc8b87170,DISK], DatanodeInfoWithStorage[127.0.0.1:41622,DS-51db44ca-3bfa-4b1f-b313-1daee3f3a35c,DISK], DatanodeInfoWithStorage[127.0.0.1:42706,DS-e94abfaf-e671-4312-be24-5d376aa9ba20,DISK], DatanodeInfoWithStorage[127.0.0.1:40935,DS-bbdabee0-c647-4293-8321-b9936bd9ce59,DISK], DatanodeInfoWithStorage[127.0.0.1:46077,DS-a9d336aa-8b26-4fbe-ad18-c8c27034d964,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1075760184-172.17.0.20-1598107491555:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41187,DS-dd90955f-6cd2-4d80-b1f6-a6a045cb7b47,DISK], DatanodeInfoWithStorage[127.0.0.1:45284,DS-f348dff5-b5ce-4fa5-b549-f3b27d6800df,DISK], DatanodeInfoWithStorage[127.0.0.1:43320,DS-93442120-4311-41ed-9ea7-7b840a646fe2,DISK], DatanodeInfoWithStorage[127.0.0.1:42160,DS-08a7f7f1-5a50-46ad-b409-7d933ae50789,DISK], DatanodeInfoWithStorage[127.0.0.1:35473,DS-9e4e337d-58f8-4912-a3e5-d46167f3af4d,DISK], DatanodeInfoWithStorage[127.0.0.1:36967,DS-6d47f6ea-6fe3-4fd4-aa58-5d30a337df9f,DISK], DatanodeInfoWithStorage[127.0.0.1:39374,DS-f1a20d17-7c15-4ef2-8b2e-7dd40ba5ea9a,DISK], DatanodeInfoWithStorage[127.0.0.1:39157,DS-c1c31c4a-aa6e-4fd3-84f5-4f38de271733,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1075760184-172.17.0.20-1598107491555:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41187,DS-dd90955f-6cd2-4d80-b1f6-a6a045cb7b47,DISK], DatanodeInfoWithStorage[127.0.0.1:45284,DS-f348dff5-b5ce-4fa5-b549-f3b27d6800df,DISK], DatanodeInfoWithStorage[127.0.0.1:43320,DS-93442120-4311-41ed-9ea7-7b840a646fe2,DISK], DatanodeInfoWithStorage[127.0.0.1:42160,DS-08a7f7f1-5a50-46ad-b409-7d933ae50789,DISK], DatanodeInfoWithStorage[127.0.0.1:35473,DS-9e4e337d-58f8-4912-a3e5-d46167f3af4d,DISK], DatanodeInfoWithStorage[127.0.0.1:36967,DS-6d47f6ea-6fe3-4fd4-aa58-5d30a337df9f,DISK], DatanodeInfoWithStorage[127.0.0.1:39374,DS-f1a20d17-7c15-4ef2-8b2e-7dd40ba5ea9a,DISK], DatanodeInfoWithStorage[127.0.0.1:39157,DS-c1c31c4a-aa6e-4fd3-84f5-4f38de271733,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5467
