reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-195409474-172.17.0.5-1598350618487:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37973,DS-88cc3c6e-e471-4ba8-b604-976c943c10f0,DISK], DatanodeInfoWithStorage[127.0.0.1:42525,DS-0d5b34e5-b87d-462b-bf17-655b13de4513,DISK], DatanodeInfoWithStorage[127.0.0.1:33151,DS-fdaf719a-b087-4a0f-b988-b1be9861a539,DISK], DatanodeInfoWithStorage[127.0.0.1:38471,DS-924f49ff-bfdb-4310-902d-24cac2328a77,DISK], DatanodeInfoWithStorage[127.0.0.1:35110,DS-39d3bfa2-5bc7-4762-84ac-9c1687911e32,DISK], DatanodeInfoWithStorage[127.0.0.1:34506,DS-5f284add-0621-43f0-9802-8aea6f488c91,DISK], DatanodeInfoWithStorage[127.0.0.1:33375,DS-644d9a9f-e511-4d0f-856e-66673a1b0818,DISK], DatanodeInfoWithStorage[127.0.0.1:44030,DS-88d28ff6-f49d-42a5-9756-7b69b5d780db,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-195409474-172.17.0.5-1598350618487:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37973,DS-88cc3c6e-e471-4ba8-b604-976c943c10f0,DISK], DatanodeInfoWithStorage[127.0.0.1:42525,DS-0d5b34e5-b87d-462b-bf17-655b13de4513,DISK], DatanodeInfoWithStorage[127.0.0.1:33151,DS-fdaf719a-b087-4a0f-b988-b1be9861a539,DISK], DatanodeInfoWithStorage[127.0.0.1:38471,DS-924f49ff-bfdb-4310-902d-24cac2328a77,DISK], DatanodeInfoWithStorage[127.0.0.1:35110,DS-39d3bfa2-5bc7-4762-84ac-9c1687911e32,DISK], DatanodeInfoWithStorage[127.0.0.1:34506,DS-5f284add-0621-43f0-9802-8aea6f488c91,DISK], DatanodeInfoWithStorage[127.0.0.1:33375,DS-644d9a9f-e511-4d0f-856e-66673a1b0818,DISK], DatanodeInfoWithStorage[127.0.0.1:44030,DS-88d28ff6-f49d-42a5-9756-7b69b5d780db,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-7694410-172.17.0.5-1598350915869:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39736,DS-b92691ab-1c92-4cf0-b9ae-9f3e81083e37,DISK], DatanodeInfoWithStorage[127.0.0.1:37248,DS-0567ad24-7063-4140-bc1d-fca20395fe25,DISK], DatanodeInfoWithStorage[127.0.0.1:35902,DS-4db957b1-9c60-44cd-b3ec-5cc9b42f9df1,DISK], DatanodeInfoWithStorage[127.0.0.1:34606,DS-1da56d32-48e7-4add-82c0-717a1d065fa2,DISK], DatanodeInfoWithStorage[127.0.0.1:41659,DS-aeef7afb-1d69-4b05-98de-737df6a441c8,DISK], DatanodeInfoWithStorage[127.0.0.1:41842,DS-65158c92-559c-4edb-aa2e-e53fa953b444,DISK], DatanodeInfoWithStorage[127.0.0.1:38908,DS-2dcbf11a-50f7-4da1-97b2-c35c5d2ecdc6,DISK], DatanodeInfoWithStorage[127.0.0.1:41979,DS-8837e17e-a78c-483b-bc21-a17908993b1b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-7694410-172.17.0.5-1598350915869:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39736,DS-b92691ab-1c92-4cf0-b9ae-9f3e81083e37,DISK], DatanodeInfoWithStorage[127.0.0.1:37248,DS-0567ad24-7063-4140-bc1d-fca20395fe25,DISK], DatanodeInfoWithStorage[127.0.0.1:35902,DS-4db957b1-9c60-44cd-b3ec-5cc9b42f9df1,DISK], DatanodeInfoWithStorage[127.0.0.1:34606,DS-1da56d32-48e7-4add-82c0-717a1d065fa2,DISK], DatanodeInfoWithStorage[127.0.0.1:41659,DS-aeef7afb-1d69-4b05-98de-737df6a441c8,DISK], DatanodeInfoWithStorage[127.0.0.1:41842,DS-65158c92-559c-4edb-aa2e-e53fa953b444,DISK], DatanodeInfoWithStorage[127.0.0.1:38908,DS-2dcbf11a-50f7-4da1-97b2-c35c5d2ecdc6,DISK], DatanodeInfoWithStorage[127.0.0.1:41979,DS-8837e17e-a78c-483b-bc21-a17908993b1b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-150862476-172.17.0.5-1598351121120:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37538,DS-7f02eb9c-62c1-4a2d-a05a-c4176e78024a,DISK], DatanodeInfoWithStorage[127.0.0.1:43847,DS-30765d9e-424a-47e0-83c3-27e199a0119b,DISK], DatanodeInfoWithStorage[127.0.0.1:37908,DS-9ea144bd-3d60-4eda-8960-5f3645c5dd8f,DISK], DatanodeInfoWithStorage[127.0.0.1:45338,DS-44ea3adc-93b5-4adc-969f-c7a12cd63131,DISK], DatanodeInfoWithStorage[127.0.0.1:42072,DS-21be5b5e-d498-4a4f-96e6-16d48d39b0ed,DISK], DatanodeInfoWithStorage[127.0.0.1:38241,DS-899d69d0-2f83-4352-a873-2c18819a255c,DISK], DatanodeInfoWithStorage[127.0.0.1:44133,DS-6403d1a8-c5cf-43e7-bd33-1b84338fd64a,DISK], DatanodeInfoWithStorage[127.0.0.1:45392,DS-86673d18-148b-487e-8e3e-e88dd719cad0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-150862476-172.17.0.5-1598351121120:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37538,DS-7f02eb9c-62c1-4a2d-a05a-c4176e78024a,DISK], DatanodeInfoWithStorage[127.0.0.1:43847,DS-30765d9e-424a-47e0-83c3-27e199a0119b,DISK], DatanodeInfoWithStorage[127.0.0.1:37908,DS-9ea144bd-3d60-4eda-8960-5f3645c5dd8f,DISK], DatanodeInfoWithStorage[127.0.0.1:45338,DS-44ea3adc-93b5-4adc-969f-c7a12cd63131,DISK], DatanodeInfoWithStorage[127.0.0.1:42072,DS-21be5b5e-d498-4a4f-96e6-16d48d39b0ed,DISK], DatanodeInfoWithStorage[127.0.0.1:38241,DS-899d69d0-2f83-4352-a873-2c18819a255c,DISK], DatanodeInfoWithStorage[127.0.0.1:44133,DS-6403d1a8-c5cf-43e7-bd33-1b84338fd64a,DISK], DatanodeInfoWithStorage[127.0.0.1:45392,DS-86673d18-148b-487e-8e3e-e88dd719cad0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1053241698-172.17.0.5-1598351473152:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45555,DS-0e2593dd-44d5-4b0b-85ce-2bbe2505733d,DISK], DatanodeInfoWithStorage[127.0.0.1:33138,DS-005188a5-dcd7-49f9-ad3a-adc0d8854bb5,DISK], DatanodeInfoWithStorage[127.0.0.1:42241,DS-98439abd-e7b1-47ff-88da-47a86aea3650,DISK], DatanodeInfoWithStorage[127.0.0.1:38752,DS-0f022a9d-c4a9-4c1f-9fb0-aa2c8a78ef95,DISK], DatanodeInfoWithStorage[127.0.0.1:33982,DS-f634e68b-2995-4520-8234-9e332fdd35d2,DISK], DatanodeInfoWithStorage[127.0.0.1:44802,DS-682bd806-f984-4b77-a9c3-69d1081a961c,DISK], DatanodeInfoWithStorage[127.0.0.1:34988,DS-52940703-db7c-47a4-9217-0519286862da,DISK], DatanodeInfoWithStorage[127.0.0.1:44510,DS-7040844f-3859-4543-9d51-174e20c17347,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1053241698-172.17.0.5-1598351473152:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45555,DS-0e2593dd-44d5-4b0b-85ce-2bbe2505733d,DISK], DatanodeInfoWithStorage[127.0.0.1:33138,DS-005188a5-dcd7-49f9-ad3a-adc0d8854bb5,DISK], DatanodeInfoWithStorage[127.0.0.1:42241,DS-98439abd-e7b1-47ff-88da-47a86aea3650,DISK], DatanodeInfoWithStorage[127.0.0.1:38752,DS-0f022a9d-c4a9-4c1f-9fb0-aa2c8a78ef95,DISK], DatanodeInfoWithStorage[127.0.0.1:33982,DS-f634e68b-2995-4520-8234-9e332fdd35d2,DISK], DatanodeInfoWithStorage[127.0.0.1:44802,DS-682bd806-f984-4b77-a9c3-69d1081a961c,DISK], DatanodeInfoWithStorage[127.0.0.1:34988,DS-52940703-db7c-47a4-9217-0519286862da,DISK], DatanodeInfoWithStorage[127.0.0.1:44510,DS-7040844f-3859-4543-9d51-174e20c17347,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-516110360-172.17.0.5-1598351504271:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35277,DS-10cc0e42-1474-4291-994e-dab4fbd8ebb1,DISK], DatanodeInfoWithStorage[127.0.0.1:38825,DS-9ed50426-8338-4489-8e8a-3da42be882d5,DISK], DatanodeInfoWithStorage[127.0.0.1:45431,DS-53c8aa3c-27ab-48b6-83e4-751f59160a54,DISK], DatanodeInfoWithStorage[127.0.0.1:36334,DS-89f0d0b0-0a63-4df2-8dd3-c40ae5d2d148,DISK], DatanodeInfoWithStorage[127.0.0.1:45496,DS-3aac7c4c-19da-42d7-a73d-0e41667525a0,DISK], DatanodeInfoWithStorage[127.0.0.1:32964,DS-ae726d28-a090-4d19-b1c2-73cd3d73d64a,DISK], DatanodeInfoWithStorage[127.0.0.1:38899,DS-148746ed-1d55-47f1-8f7e-9a63e5779ad6,DISK], DatanodeInfoWithStorage[127.0.0.1:45309,DS-6d1aa59d-a047-438a-b4bf-cd42f69ebc76,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-516110360-172.17.0.5-1598351504271:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35277,DS-10cc0e42-1474-4291-994e-dab4fbd8ebb1,DISK], DatanodeInfoWithStorage[127.0.0.1:38825,DS-9ed50426-8338-4489-8e8a-3da42be882d5,DISK], DatanodeInfoWithStorage[127.0.0.1:45431,DS-53c8aa3c-27ab-48b6-83e4-751f59160a54,DISK], DatanodeInfoWithStorage[127.0.0.1:36334,DS-89f0d0b0-0a63-4df2-8dd3-c40ae5d2d148,DISK], DatanodeInfoWithStorage[127.0.0.1:45496,DS-3aac7c4c-19da-42d7-a73d-0e41667525a0,DISK], DatanodeInfoWithStorage[127.0.0.1:32964,DS-ae726d28-a090-4d19-b1c2-73cd3d73d64a,DISK], DatanodeInfoWithStorage[127.0.0.1:38899,DS-148746ed-1d55-47f1-8f7e-9a63e5779ad6,DISK], DatanodeInfoWithStorage[127.0.0.1:45309,DS-6d1aa59d-a047-438a-b4bf-cd42f69ebc76,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-460401599-172.17.0.5-1598351597210:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44868,DS-c4c874d7-f1c3-405a-be50-cf70a29f49c0,DISK], DatanodeInfoWithStorage[127.0.0.1:39849,DS-792cc236-5255-4691-a9c2-52d752dfb0a4,DISK], DatanodeInfoWithStorage[127.0.0.1:45353,DS-215ae64e-6ab7-4c55-8382-2d2b7bb88da3,DISK], DatanodeInfoWithStorage[127.0.0.1:39355,DS-d34791e2-f21b-4a59-bdfe-eff778b22f4b,DISK], DatanodeInfoWithStorage[127.0.0.1:39673,DS-954854b7-f7dc-4e01-8986-80ed8d03b479,DISK], DatanodeInfoWithStorage[127.0.0.1:45183,DS-d2cfc529-ed6d-491c-9861-d6d95436c4b1,DISK], DatanodeInfoWithStorage[127.0.0.1:37141,DS-d9f920e1-209a-4ef7-984c-d86949979afd,DISK], DatanodeInfoWithStorage[127.0.0.1:35777,DS-582258a6-a918-480e-9842-066f336e5351,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-460401599-172.17.0.5-1598351597210:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44868,DS-c4c874d7-f1c3-405a-be50-cf70a29f49c0,DISK], DatanodeInfoWithStorage[127.0.0.1:39849,DS-792cc236-5255-4691-a9c2-52d752dfb0a4,DISK], DatanodeInfoWithStorage[127.0.0.1:45353,DS-215ae64e-6ab7-4c55-8382-2d2b7bb88da3,DISK], DatanodeInfoWithStorage[127.0.0.1:39355,DS-d34791e2-f21b-4a59-bdfe-eff778b22f4b,DISK], DatanodeInfoWithStorage[127.0.0.1:39673,DS-954854b7-f7dc-4e01-8986-80ed8d03b479,DISK], DatanodeInfoWithStorage[127.0.0.1:45183,DS-d2cfc529-ed6d-491c-9861-d6d95436c4b1,DISK], DatanodeInfoWithStorage[127.0.0.1:37141,DS-d9f920e1-209a-4ef7-984c-d86949979afd,DISK], DatanodeInfoWithStorage[127.0.0.1:35777,DS-582258a6-a918-480e-9842-066f336e5351,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1740371274-172.17.0.5-1598351682112:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42319,DS-03b7c056-4ed0-4ffd-a016-7306911cbbf2,DISK], DatanodeInfoWithStorage[127.0.0.1:46002,DS-de327ec4-da11-4de1-b821-ad3e25887db1,DISK], DatanodeInfoWithStorage[127.0.0.1:40490,DS-f7971b21-1f11-4b84-8239-5cd4cfddc526,DISK], DatanodeInfoWithStorage[127.0.0.1:40516,DS-ffb870f3-48af-4e06-ad4e-c0b511017171,DISK], DatanodeInfoWithStorage[127.0.0.1:36590,DS-4e8eee7c-99fc-4b3f-b9f7-48ec8d2c5a01,DISK], DatanodeInfoWithStorage[127.0.0.1:44543,DS-d9b60565-644b-43b8-b624-5e5f52306fe0,DISK], DatanodeInfoWithStorage[127.0.0.1:33009,DS-f2cb794d-70e6-4fbb-9559-51540f8df699,DISK], DatanodeInfoWithStorage[127.0.0.1:37469,DS-cd2e24de-a10a-47df-bd90-7464fcbd256d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1740371274-172.17.0.5-1598351682112:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42319,DS-03b7c056-4ed0-4ffd-a016-7306911cbbf2,DISK], DatanodeInfoWithStorage[127.0.0.1:46002,DS-de327ec4-da11-4de1-b821-ad3e25887db1,DISK], DatanodeInfoWithStorage[127.0.0.1:40490,DS-f7971b21-1f11-4b84-8239-5cd4cfddc526,DISK], DatanodeInfoWithStorage[127.0.0.1:40516,DS-ffb870f3-48af-4e06-ad4e-c0b511017171,DISK], DatanodeInfoWithStorage[127.0.0.1:36590,DS-4e8eee7c-99fc-4b3f-b9f7-48ec8d2c5a01,DISK], DatanodeInfoWithStorage[127.0.0.1:44543,DS-d9b60565-644b-43b8-b624-5e5f52306fe0,DISK], DatanodeInfoWithStorage[127.0.0.1:33009,DS-f2cb794d-70e6-4fbb-9559-51540f8df699,DISK], DatanodeInfoWithStorage[127.0.0.1:37469,DS-cd2e24de-a10a-47df-bd90-7464fcbd256d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-165460351-172.17.0.5-1598351744692:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34110,DS-122230e4-41d5-4eb4-8fd4-a5f733c8f21f,DISK], DatanodeInfoWithStorage[127.0.0.1:36253,DS-803c00f1-e231-45cd-9033-cce4f4a603c3,DISK], DatanodeInfoWithStorage[127.0.0.1:46671,DS-2fa517ea-3fca-46d0-a16f-f8392f14fe88,DISK], DatanodeInfoWithStorage[127.0.0.1:44559,DS-7f976a4e-0b8a-4bb5-b13c-d8e4317e058e,DISK], DatanodeInfoWithStorage[127.0.0.1:41276,DS-99630bad-c421-4189-b0a6-cf0d9d3e28cf,DISK], DatanodeInfoWithStorage[127.0.0.1:34558,DS-d09f7ca8-5551-4016-a4b5-fb148e9894b7,DISK], DatanodeInfoWithStorage[127.0.0.1:34717,DS-a47fb2dd-307d-4a6f-ade4-5fa9a7e83f4d,DISK], DatanodeInfoWithStorage[127.0.0.1:37966,DS-5d8ba7c2-b34a-46dd-a0d5-68e58f1da444,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-165460351-172.17.0.5-1598351744692:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34110,DS-122230e4-41d5-4eb4-8fd4-a5f733c8f21f,DISK], DatanodeInfoWithStorage[127.0.0.1:36253,DS-803c00f1-e231-45cd-9033-cce4f4a603c3,DISK], DatanodeInfoWithStorage[127.0.0.1:46671,DS-2fa517ea-3fca-46d0-a16f-f8392f14fe88,DISK], DatanodeInfoWithStorage[127.0.0.1:44559,DS-7f976a4e-0b8a-4bb5-b13c-d8e4317e058e,DISK], DatanodeInfoWithStorage[127.0.0.1:41276,DS-99630bad-c421-4189-b0a6-cf0d9d3e28cf,DISK], DatanodeInfoWithStorage[127.0.0.1:34558,DS-d09f7ca8-5551-4016-a4b5-fb148e9894b7,DISK], DatanodeInfoWithStorage[127.0.0.1:34717,DS-a47fb2dd-307d-4a6f-ade4-5fa9a7e83f4d,DISK], DatanodeInfoWithStorage[127.0.0.1:37966,DS-5d8ba7c2-b34a-46dd-a0d5-68e58f1da444,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1381306455-172.17.0.5-1598351803334:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34502,DS-3a132c25-c26b-4ca8-bbd0-118114585748,DISK], DatanodeInfoWithStorage[127.0.0.1:39426,DS-f030bceb-6da8-40b3-9db0-9b5986f39a21,DISK], DatanodeInfoWithStorage[127.0.0.1:43114,DS-494c777c-5bfa-43b3-bf72-8cb20e60882c,DISK], DatanodeInfoWithStorage[127.0.0.1:38016,DS-9a645165-c2d0-4f4a-8570-4f2fbd74c766,DISK], DatanodeInfoWithStorage[127.0.0.1:38129,DS-a842caef-9f40-48cf-b423-abddd8f1e847,DISK], DatanodeInfoWithStorage[127.0.0.1:41491,DS-8134600e-a84e-4d82-8c86-ceb3115f1a2c,DISK], DatanodeInfoWithStorage[127.0.0.1:39974,DS-00002c16-f9e1-40db-966e-3025d4fda25d,DISK], DatanodeInfoWithStorage[127.0.0.1:45330,DS-41d9bd5b-dafd-4b87-bf9d-d9a0e59ef936,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1381306455-172.17.0.5-1598351803334:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34502,DS-3a132c25-c26b-4ca8-bbd0-118114585748,DISK], DatanodeInfoWithStorage[127.0.0.1:39426,DS-f030bceb-6da8-40b3-9db0-9b5986f39a21,DISK], DatanodeInfoWithStorage[127.0.0.1:43114,DS-494c777c-5bfa-43b3-bf72-8cb20e60882c,DISK], DatanodeInfoWithStorage[127.0.0.1:38016,DS-9a645165-c2d0-4f4a-8570-4f2fbd74c766,DISK], DatanodeInfoWithStorage[127.0.0.1:38129,DS-a842caef-9f40-48cf-b423-abddd8f1e847,DISK], DatanodeInfoWithStorage[127.0.0.1:41491,DS-8134600e-a84e-4d82-8c86-ceb3115f1a2c,DISK], DatanodeInfoWithStorage[127.0.0.1:39974,DS-00002c16-f9e1-40db-966e-3025d4fda25d,DISK], DatanodeInfoWithStorage[127.0.0.1:45330,DS-41d9bd5b-dafd-4b87-bf9d-d9a0e59ef936,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1694383664-172.17.0.5-1598352432130:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36169,DS-60a36350-1d13-4870-a9f1-b03a3395513f,DISK], DatanodeInfoWithStorage[127.0.0.1:34474,DS-b639e88f-7875-49d8-beea-eb23f19bd2b2,DISK], DatanodeInfoWithStorage[127.0.0.1:35692,DS-54880398-8008-41cb-9a32-987e0b00a080,DISK], DatanodeInfoWithStorage[127.0.0.1:42433,DS-2339d51b-88a3-4024-b7a2-4cca527160d7,DISK], DatanodeInfoWithStorage[127.0.0.1:36145,DS-8f287f0c-11f3-420f-a16a-b6ba2d3c75fc,DISK], DatanodeInfoWithStorage[127.0.0.1:43514,DS-65c9f8ed-7018-4ba2-bb13-b81a46674deb,DISK], DatanodeInfoWithStorage[127.0.0.1:37107,DS-4cda7b5d-03d5-4d08-a02e-2aab80cbabd7,DISK], DatanodeInfoWithStorage[127.0.0.1:37257,DS-82c80145-6a1d-45a1-9220-7ba50e25e642,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1694383664-172.17.0.5-1598352432130:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36169,DS-60a36350-1d13-4870-a9f1-b03a3395513f,DISK], DatanodeInfoWithStorage[127.0.0.1:34474,DS-b639e88f-7875-49d8-beea-eb23f19bd2b2,DISK], DatanodeInfoWithStorage[127.0.0.1:35692,DS-54880398-8008-41cb-9a32-987e0b00a080,DISK], DatanodeInfoWithStorage[127.0.0.1:42433,DS-2339d51b-88a3-4024-b7a2-4cca527160d7,DISK], DatanodeInfoWithStorage[127.0.0.1:36145,DS-8f287f0c-11f3-420f-a16a-b6ba2d3c75fc,DISK], DatanodeInfoWithStorage[127.0.0.1:43514,DS-65c9f8ed-7018-4ba2-bb13-b81a46674deb,DISK], DatanodeInfoWithStorage[127.0.0.1:37107,DS-4cda7b5d-03d5-4d08-a02e-2aab80cbabd7,DISK], DatanodeInfoWithStorage[127.0.0.1:37257,DS-82c80145-6a1d-45a1-9220-7ba50e25e642,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1776197547-172.17.0.5-1598352642570:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33226,DS-a483c9b5-d9ca-4ee9-b4d9-8888c148c557,DISK], DatanodeInfoWithStorage[127.0.0.1:38060,DS-6475accd-953f-49dc-9383-8507f8f435e3,DISK], DatanodeInfoWithStorage[127.0.0.1:41822,DS-1ca8a0b5-d979-4445-babe-8edd6e06ff35,DISK], DatanodeInfoWithStorage[127.0.0.1:44891,DS-023f8a4e-ac33-479b-a62c-80988f2665df,DISK], DatanodeInfoWithStorage[127.0.0.1:35319,DS-403e4f25-1e8f-44bc-adf4-8c0fc21471c5,DISK], DatanodeInfoWithStorage[127.0.0.1:36899,DS-5ac62d95-a502-41b3-b946-f4e6b2b3e0aa,DISK], DatanodeInfoWithStorage[127.0.0.1:36600,DS-3c2256d3-fb61-47d1-9762-cd5406c672ad,DISK], DatanodeInfoWithStorage[127.0.0.1:40512,DS-a9aac327-69e0-48f7-a6ff-b2e08e1445ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1776197547-172.17.0.5-1598352642570:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33226,DS-a483c9b5-d9ca-4ee9-b4d9-8888c148c557,DISK], DatanodeInfoWithStorage[127.0.0.1:38060,DS-6475accd-953f-49dc-9383-8507f8f435e3,DISK], DatanodeInfoWithStorage[127.0.0.1:41822,DS-1ca8a0b5-d979-4445-babe-8edd6e06ff35,DISK], DatanodeInfoWithStorage[127.0.0.1:44891,DS-023f8a4e-ac33-479b-a62c-80988f2665df,DISK], DatanodeInfoWithStorage[127.0.0.1:35319,DS-403e4f25-1e8f-44bc-adf4-8c0fc21471c5,DISK], DatanodeInfoWithStorage[127.0.0.1:36899,DS-5ac62d95-a502-41b3-b946-f4e6b2b3e0aa,DISK], DatanodeInfoWithStorage[127.0.0.1:36600,DS-3c2256d3-fb61-47d1-9762-cd5406c672ad,DISK], DatanodeInfoWithStorage[127.0.0.1:40512,DS-a9aac327-69e0-48f7-a6ff-b2e08e1445ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-796662439-172.17.0.5-1598352863511:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39174,DS-79219368-575f-42ec-850b-d339493a7587,DISK], DatanodeInfoWithStorage[127.0.0.1:38388,DS-daf9eaf3-15f9-4a0d-a049-1dbd6e9c066e,DISK], DatanodeInfoWithStorage[127.0.0.1:38514,DS-24d5e207-75d4-4a70-8662-df2a101e37c1,DISK], DatanodeInfoWithStorage[127.0.0.1:41937,DS-8b5cea72-12e3-4776-aec1-543cb96536df,DISK], DatanodeInfoWithStorage[127.0.0.1:39243,DS-7bcd567d-0f82-451c-8d08-24f683d8dc28,DISK], DatanodeInfoWithStorage[127.0.0.1:44531,DS-effd6822-b96b-4497-b76a-c75aeaa286b9,DISK], DatanodeInfoWithStorage[127.0.0.1:33880,DS-843db306-aadb-43c3-ab52-e1b70666c232,DISK], DatanodeInfoWithStorage[127.0.0.1:41730,DS-75f8f77b-d013-4447-a4f3-b50945ee2af3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-796662439-172.17.0.5-1598352863511:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39174,DS-79219368-575f-42ec-850b-d339493a7587,DISK], DatanodeInfoWithStorage[127.0.0.1:38388,DS-daf9eaf3-15f9-4a0d-a049-1dbd6e9c066e,DISK], DatanodeInfoWithStorage[127.0.0.1:38514,DS-24d5e207-75d4-4a70-8662-df2a101e37c1,DISK], DatanodeInfoWithStorage[127.0.0.1:41937,DS-8b5cea72-12e3-4776-aec1-543cb96536df,DISK], DatanodeInfoWithStorage[127.0.0.1:39243,DS-7bcd567d-0f82-451c-8d08-24f683d8dc28,DISK], DatanodeInfoWithStorage[127.0.0.1:44531,DS-effd6822-b96b-4497-b76a-c75aeaa286b9,DISK], DatanodeInfoWithStorage[127.0.0.1:33880,DS-843db306-aadb-43c3-ab52-e1b70666c232,DISK], DatanodeInfoWithStorage[127.0.0.1:41730,DS-75f8f77b-d013-4447-a4f3-b50945ee2af3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-109921170-172.17.0.5-1598353142090:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41678,DS-40c4ed9a-9df0-40d5-b4bf-4b7a7c75e4ae,DISK], DatanodeInfoWithStorage[127.0.0.1:37971,DS-a5d75e96-4f98-417f-b1fd-2d3667fe3958,DISK], DatanodeInfoWithStorage[127.0.0.1:34340,DS-99f7a95a-87c7-4350-aae9-e5d7836f157f,DISK], DatanodeInfoWithStorage[127.0.0.1:36216,DS-1aa7fd89-86c1-4aa4-bc40-b52afff05a01,DISK], DatanodeInfoWithStorage[127.0.0.1:36402,DS-0737870f-6f62-48cd-9e82-d7d0141cf5fb,DISK], DatanodeInfoWithStorage[127.0.0.1:39298,DS-d1bd6466-9563-413f-b787-d4ec19df431e,DISK], DatanodeInfoWithStorage[127.0.0.1:46520,DS-683851ea-c029-4344-9e73-bdc6a1bf08aa,DISK], DatanodeInfoWithStorage[127.0.0.1:33311,DS-34f6eaf2-0be9-43e1-9d59-c348cfea59c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-109921170-172.17.0.5-1598353142090:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41678,DS-40c4ed9a-9df0-40d5-b4bf-4b7a7c75e4ae,DISK], DatanodeInfoWithStorage[127.0.0.1:37971,DS-a5d75e96-4f98-417f-b1fd-2d3667fe3958,DISK], DatanodeInfoWithStorage[127.0.0.1:34340,DS-99f7a95a-87c7-4350-aae9-e5d7836f157f,DISK], DatanodeInfoWithStorage[127.0.0.1:36216,DS-1aa7fd89-86c1-4aa4-bc40-b52afff05a01,DISK], DatanodeInfoWithStorage[127.0.0.1:36402,DS-0737870f-6f62-48cd-9e82-d7d0141cf5fb,DISK], DatanodeInfoWithStorage[127.0.0.1:39298,DS-d1bd6466-9563-413f-b787-d4ec19df431e,DISK], DatanodeInfoWithStorage[127.0.0.1:46520,DS-683851ea-c029-4344-9e73-bdc6a1bf08aa,DISK], DatanodeInfoWithStorage[127.0.0.1:33311,DS-34f6eaf2-0be9-43e1-9d59-c348cfea59c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1010169505-172.17.0.5-1598353652240:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40240,DS-319d6dbc-8357-4c89-86be-f362dac36cff,DISK], DatanodeInfoWithStorage[127.0.0.1:42588,DS-7a51fdb9-2461-41de-b18f-340f1976440d,DISK], DatanodeInfoWithStorage[127.0.0.1:38213,DS-765f80c6-6711-43f2-888a-2f9ccbd55c5d,DISK], DatanodeInfoWithStorage[127.0.0.1:37424,DS-85264df2-a2ac-4b9d-a0ea-a58f0dc50d12,DISK], DatanodeInfoWithStorage[127.0.0.1:41562,DS-1d0f72e8-8bc7-4abc-8466-c13802967ad6,DISK], DatanodeInfoWithStorage[127.0.0.1:37102,DS-82ce1141-ed4c-4b62-afe3-42166927e134,DISK], DatanodeInfoWithStorage[127.0.0.1:33291,DS-35a2967f-ebaa-4a5d-b5ec-8a679370d520,DISK], DatanodeInfoWithStorage[127.0.0.1:37278,DS-97296e4e-53ef-402d-ad31-1ad2e58c2278,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1010169505-172.17.0.5-1598353652240:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40240,DS-319d6dbc-8357-4c89-86be-f362dac36cff,DISK], DatanodeInfoWithStorage[127.0.0.1:42588,DS-7a51fdb9-2461-41de-b18f-340f1976440d,DISK], DatanodeInfoWithStorage[127.0.0.1:38213,DS-765f80c6-6711-43f2-888a-2f9ccbd55c5d,DISK], DatanodeInfoWithStorage[127.0.0.1:37424,DS-85264df2-a2ac-4b9d-a0ea-a58f0dc50d12,DISK], DatanodeInfoWithStorage[127.0.0.1:41562,DS-1d0f72e8-8bc7-4abc-8466-c13802967ad6,DISK], DatanodeInfoWithStorage[127.0.0.1:37102,DS-82ce1141-ed4c-4b62-afe3-42166927e134,DISK], DatanodeInfoWithStorage[127.0.0.1:33291,DS-35a2967f-ebaa-4a5d-b5ec-8a679370d520,DISK], DatanodeInfoWithStorage[127.0.0.1:37278,DS-97296e4e-53ef-402d-ad31-1ad2e58c2278,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1472073339-172.17.0.5-1598353938164:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44940,DS-29b3d26f-fa39-4ede-9fa1-01dfea8a8efa,DISK], DatanodeInfoWithStorage[127.0.0.1:37045,DS-fa341578-9ca8-47f6-9787-77f3c5c66ee4,DISK], DatanodeInfoWithStorage[127.0.0.1:45552,DS-93801f3f-ac07-4ef8-8a6c-4e0707abd64a,DISK], DatanodeInfoWithStorage[127.0.0.1:45814,DS-0f4a5efe-2767-4b08-a759-9fabb64825a8,DISK], DatanodeInfoWithStorage[127.0.0.1:40259,DS-53b2196c-5993-4159-9ce1-17552e9a17b7,DISK], DatanodeInfoWithStorage[127.0.0.1:40737,DS-f60e27cc-99b8-43d2-94d6-3926c77ae401,DISK], DatanodeInfoWithStorage[127.0.0.1:34300,DS-845c7b2c-7110-4292-b55d-bbf24d7a3324,DISK], DatanodeInfoWithStorage[127.0.0.1:45261,DS-1ca8fd9d-b69a-4e35-b06f-af265e301819,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1472073339-172.17.0.5-1598353938164:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44940,DS-29b3d26f-fa39-4ede-9fa1-01dfea8a8efa,DISK], DatanodeInfoWithStorage[127.0.0.1:37045,DS-fa341578-9ca8-47f6-9787-77f3c5c66ee4,DISK], DatanodeInfoWithStorage[127.0.0.1:45552,DS-93801f3f-ac07-4ef8-8a6c-4e0707abd64a,DISK], DatanodeInfoWithStorage[127.0.0.1:45814,DS-0f4a5efe-2767-4b08-a759-9fabb64825a8,DISK], DatanodeInfoWithStorage[127.0.0.1:40259,DS-53b2196c-5993-4159-9ce1-17552e9a17b7,DISK], DatanodeInfoWithStorage[127.0.0.1:40737,DS-f60e27cc-99b8-43d2-94d6-3926c77ae401,DISK], DatanodeInfoWithStorage[127.0.0.1:34300,DS-845c7b2c-7110-4292-b55d-bbf24d7a3324,DISK], DatanodeInfoWithStorage[127.0.0.1:45261,DS-1ca8fd9d-b69a-4e35-b06f-af265e301819,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1451359970-172.17.0.5-1598354677456:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46386,DS-ce229131-e6ad-47da-b0ca-b91abbe70761,DISK], DatanodeInfoWithStorage[127.0.0.1:37629,DS-cdcbb72d-50d7-4574-8e4d-da5390620068,DISK], DatanodeInfoWithStorage[127.0.0.1:39498,DS-05bc5ea6-f2ba-4571-abe6-398c0daa816e,DISK], DatanodeInfoWithStorage[127.0.0.1:39370,DS-81da4428-fdfe-4fc8-aee0-9c07afd87f2f,DISK], DatanodeInfoWithStorage[127.0.0.1:40403,DS-d962b8dc-be93-47b7-96e6-695b44e80f91,DISK], DatanodeInfoWithStorage[127.0.0.1:39359,DS-8135724c-4742-4eb9-b8d6-b3072d74c569,DISK], DatanodeInfoWithStorage[127.0.0.1:42473,DS-3606d191-d08a-4ceb-b713-63180bf6d7b4,DISK], DatanodeInfoWithStorage[127.0.0.1:36599,DS-0fe2a660-15fb-4c51-9cf0-7a623219bfdd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1451359970-172.17.0.5-1598354677456:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46386,DS-ce229131-e6ad-47da-b0ca-b91abbe70761,DISK], DatanodeInfoWithStorage[127.0.0.1:37629,DS-cdcbb72d-50d7-4574-8e4d-da5390620068,DISK], DatanodeInfoWithStorage[127.0.0.1:39498,DS-05bc5ea6-f2ba-4571-abe6-398c0daa816e,DISK], DatanodeInfoWithStorage[127.0.0.1:39370,DS-81da4428-fdfe-4fc8-aee0-9c07afd87f2f,DISK], DatanodeInfoWithStorage[127.0.0.1:40403,DS-d962b8dc-be93-47b7-96e6-695b44e80f91,DISK], DatanodeInfoWithStorage[127.0.0.1:39359,DS-8135724c-4742-4eb9-b8d6-b3072d74c569,DISK], DatanodeInfoWithStorage[127.0.0.1:42473,DS-3606d191-d08a-4ceb-b713-63180bf6d7b4,DISK], DatanodeInfoWithStorage[127.0.0.1:36599,DS-0fe2a660-15fb-4c51-9cf0-7a623219bfdd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-978272027-172.17.0.5-1598354709257:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33452,DS-caba59b6-01cc-4292-b813-1436bdcc14af,DISK], DatanodeInfoWithStorage[127.0.0.1:42969,DS-9ff2247d-d035-438f-a21c-e49ea9fd2eea,DISK], DatanodeInfoWithStorage[127.0.0.1:33805,DS-9f5e6e42-bbc5-4cf3-8f2e-8d410314e0f0,DISK], DatanodeInfoWithStorage[127.0.0.1:39140,DS-7e629e8c-773b-452f-b6ff-61591cd7a450,DISK], DatanodeInfoWithStorage[127.0.0.1:37499,DS-9028f522-302f-4f44-a749-d5f2ec047b6b,DISK], DatanodeInfoWithStorage[127.0.0.1:37329,DS-f2307080-b85f-460a-aab5-d40c5319d735,DISK], DatanodeInfoWithStorage[127.0.0.1:39868,DS-36699843-7dd1-403c-8dca-2cc473233f00,DISK], DatanodeInfoWithStorage[127.0.0.1:39054,DS-2a962859-3b73-4c0c-963f-2e476141536d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-978272027-172.17.0.5-1598354709257:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33452,DS-caba59b6-01cc-4292-b813-1436bdcc14af,DISK], DatanodeInfoWithStorage[127.0.0.1:42969,DS-9ff2247d-d035-438f-a21c-e49ea9fd2eea,DISK], DatanodeInfoWithStorage[127.0.0.1:33805,DS-9f5e6e42-bbc5-4cf3-8f2e-8d410314e0f0,DISK], DatanodeInfoWithStorage[127.0.0.1:39140,DS-7e629e8c-773b-452f-b6ff-61591cd7a450,DISK], DatanodeInfoWithStorage[127.0.0.1:37499,DS-9028f522-302f-4f44-a749-d5f2ec047b6b,DISK], DatanodeInfoWithStorage[127.0.0.1:37329,DS-f2307080-b85f-460a-aab5-d40c5319d735,DISK], DatanodeInfoWithStorage[127.0.0.1:39868,DS-36699843-7dd1-403c-8dca-2cc473233f00,DISK], DatanodeInfoWithStorage[127.0.0.1:39054,DS-2a962859-3b73-4c0c-963f-2e476141536d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-613224600-172.17.0.5-1598355471827:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36195,DS-3a633869-dd20-43ee-81ce-be81cbcb9b83,DISK], DatanodeInfoWithStorage[127.0.0.1:39289,DS-7380b107-6175-4662-b131-54af2f2b4d3a,DISK], DatanodeInfoWithStorage[127.0.0.1:34044,DS-bfca2870-d429-4a4f-8240-1113f6bcaaa4,DISK], DatanodeInfoWithStorage[127.0.0.1:35309,DS-ccacaffe-4bd6-40e6-8ee6-310843e32ec3,DISK], DatanodeInfoWithStorage[127.0.0.1:40024,DS-8d03fc26-ab55-442f-9138-ace67cefe39e,DISK], DatanodeInfoWithStorage[127.0.0.1:39465,DS-44a0eb0f-f266-41b9-84a5-21798fdd411a,DISK], DatanodeInfoWithStorage[127.0.0.1:42080,DS-a8bd05f1-ad12-421e-ad3b-6e8aca4b86fd,DISK], DatanodeInfoWithStorage[127.0.0.1:40396,DS-831186fb-dcfe-4b52-909d-cfe2e2a500aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-613224600-172.17.0.5-1598355471827:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36195,DS-3a633869-dd20-43ee-81ce-be81cbcb9b83,DISK], DatanodeInfoWithStorage[127.0.0.1:39289,DS-7380b107-6175-4662-b131-54af2f2b4d3a,DISK], DatanodeInfoWithStorage[127.0.0.1:34044,DS-bfca2870-d429-4a4f-8240-1113f6bcaaa4,DISK], DatanodeInfoWithStorage[127.0.0.1:35309,DS-ccacaffe-4bd6-40e6-8ee6-310843e32ec3,DISK], DatanodeInfoWithStorage[127.0.0.1:40024,DS-8d03fc26-ab55-442f-9138-ace67cefe39e,DISK], DatanodeInfoWithStorage[127.0.0.1:39465,DS-44a0eb0f-f266-41b9-84a5-21798fdd411a,DISK], DatanodeInfoWithStorage[127.0.0.1:42080,DS-a8bd05f1-ad12-421e-ad3b-6e8aca4b86fd,DISK], DatanodeInfoWithStorage[127.0.0.1:40396,DS-831186fb-dcfe-4b52-909d-cfe2e2a500aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 14 out of 50
result: false positive !!!
Total execution time in seconds : 5132
