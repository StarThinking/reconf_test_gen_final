reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1577936521-172.17.0.12-1598322963597:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37076,DS-375afa06-dea5-4647-85ae-6e914ba5cd18,DISK], DatanodeInfoWithStorage[127.0.0.1:45914,DS-79f55957-b1ce-4447-a60c-cf0ae4dec4ea,DISK], DatanodeInfoWithStorage[127.0.0.1:43441,DS-e3a2af10-fb33-48bc-9fff-7182d279acf0,DISK], DatanodeInfoWithStorage[127.0.0.1:35261,DS-cd3eaa87-272a-4052-a61f-1d5d068d1832,DISK], DatanodeInfoWithStorage[127.0.0.1:37298,DS-e06fdc77-6e3b-493c-a2e7-e7b0a28eff72,DISK], DatanodeInfoWithStorage[127.0.0.1:35740,DS-eb0828ea-141e-45b7-b1a7-d6b935fca642,DISK], DatanodeInfoWithStorage[127.0.0.1:43447,DS-cae4af0c-abef-4d29-abe1-f92ae4c2e312,DISK], DatanodeInfoWithStorage[127.0.0.1:37163,DS-844a62af-6e15-4029-9df7-1b64d6c9dd66,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1577936521-172.17.0.12-1598322963597:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37076,DS-375afa06-dea5-4647-85ae-6e914ba5cd18,DISK], DatanodeInfoWithStorage[127.0.0.1:45914,DS-79f55957-b1ce-4447-a60c-cf0ae4dec4ea,DISK], DatanodeInfoWithStorage[127.0.0.1:43441,DS-e3a2af10-fb33-48bc-9fff-7182d279acf0,DISK], DatanodeInfoWithStorage[127.0.0.1:35261,DS-cd3eaa87-272a-4052-a61f-1d5d068d1832,DISK], DatanodeInfoWithStorage[127.0.0.1:37298,DS-e06fdc77-6e3b-493c-a2e7-e7b0a28eff72,DISK], DatanodeInfoWithStorage[127.0.0.1:35740,DS-eb0828ea-141e-45b7-b1a7-d6b935fca642,DISK], DatanodeInfoWithStorage[127.0.0.1:43447,DS-cae4af0c-abef-4d29-abe1-f92ae4c2e312,DISK], DatanodeInfoWithStorage[127.0.0.1:37163,DS-844a62af-6e15-4029-9df7-1b64d6c9dd66,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-381689127-172.17.0.12-1598323041463:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35532,DS-3bd678ee-51c9-4ee0-a076-7899d80f8579,DISK], DatanodeInfoWithStorage[127.0.0.1:38228,DS-6dabb549-1268-440f-a489-1147a5c0d024,DISK], DatanodeInfoWithStorage[127.0.0.1:40115,DS-a1f327bf-edf3-46cf-9a57-4def30caec7f,DISK], DatanodeInfoWithStorage[127.0.0.1:38955,DS-666d991a-93dc-4998-a6d4-75e856be758d,DISK], DatanodeInfoWithStorage[127.0.0.1:45016,DS-d05e0fe9-f7a3-4d27-932b-c84515460a5d,DISK], DatanodeInfoWithStorage[127.0.0.1:35588,DS-23005d06-3157-41e5-b6c2-58842e510786,DISK], DatanodeInfoWithStorage[127.0.0.1:44954,DS-3457acfb-f852-4961-90a3-b7e625e3c5c7,DISK], DatanodeInfoWithStorage[127.0.0.1:32969,DS-1fb88057-9184-4e09-86d6-6f1df770c438,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-381689127-172.17.0.12-1598323041463:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35532,DS-3bd678ee-51c9-4ee0-a076-7899d80f8579,DISK], DatanodeInfoWithStorage[127.0.0.1:38228,DS-6dabb549-1268-440f-a489-1147a5c0d024,DISK], DatanodeInfoWithStorage[127.0.0.1:40115,DS-a1f327bf-edf3-46cf-9a57-4def30caec7f,DISK], DatanodeInfoWithStorage[127.0.0.1:38955,DS-666d991a-93dc-4998-a6d4-75e856be758d,DISK], DatanodeInfoWithStorage[127.0.0.1:45016,DS-d05e0fe9-f7a3-4d27-932b-c84515460a5d,DISK], DatanodeInfoWithStorage[127.0.0.1:35588,DS-23005d06-3157-41e5-b6c2-58842e510786,DISK], DatanodeInfoWithStorage[127.0.0.1:44954,DS-3457acfb-f852-4961-90a3-b7e625e3c5c7,DISK], DatanodeInfoWithStorage[127.0.0.1:32969,DS-1fb88057-9184-4e09-86d6-6f1df770c438,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1849120319-172.17.0.12-1598323494557:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37353,DS-045c8253-60a9-4a46-b735-d2ce28a017c0,DISK], DatanodeInfoWithStorage[127.0.0.1:42958,DS-69ca2db6-7bb3-422b-a95f-2d4a5a3ada77,DISK], DatanodeInfoWithStorage[127.0.0.1:36185,DS-472dcadf-805e-4b0d-956a-dd8590b7d1dc,DISK], DatanodeInfoWithStorage[127.0.0.1:37471,DS-e4a47211-5192-45b4-bdd3-50d612315bf7,DISK], DatanodeInfoWithStorage[127.0.0.1:38849,DS-14c15337-f092-45f4-b5e0-9aac7eaef360,DISK], DatanodeInfoWithStorage[127.0.0.1:44871,DS-d643061e-887f-455e-b28c-b5d7f048b965,DISK], DatanodeInfoWithStorage[127.0.0.1:44816,DS-d112e26a-7058-4301-af53-9e06e589d42d,DISK], DatanodeInfoWithStorage[127.0.0.1:43407,DS-365d9433-5c4f-4446-af86-1ec0747dc2d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1849120319-172.17.0.12-1598323494557:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37353,DS-045c8253-60a9-4a46-b735-d2ce28a017c0,DISK], DatanodeInfoWithStorage[127.0.0.1:42958,DS-69ca2db6-7bb3-422b-a95f-2d4a5a3ada77,DISK], DatanodeInfoWithStorage[127.0.0.1:36185,DS-472dcadf-805e-4b0d-956a-dd8590b7d1dc,DISK], DatanodeInfoWithStorage[127.0.0.1:37471,DS-e4a47211-5192-45b4-bdd3-50d612315bf7,DISK], DatanodeInfoWithStorage[127.0.0.1:38849,DS-14c15337-f092-45f4-b5e0-9aac7eaef360,DISK], DatanodeInfoWithStorage[127.0.0.1:44871,DS-d643061e-887f-455e-b28c-b5d7f048b965,DISK], DatanodeInfoWithStorage[127.0.0.1:44816,DS-d112e26a-7058-4301-af53-9e06e589d42d,DISK], DatanodeInfoWithStorage[127.0.0.1:43407,DS-365d9433-5c4f-4446-af86-1ec0747dc2d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1552414492-172.17.0.12-1598323976014:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46795,DS-bdffae2f-4525-460f-a5bc-4a9ecfa8441f,DISK], DatanodeInfoWithStorage[127.0.0.1:34170,DS-3a064522-dfc3-4462-bf7a-fce5d8404ccd,DISK], DatanodeInfoWithStorage[127.0.0.1:36945,DS-1944b022-b291-44b1-a1b5-a2999c5cf4cd,DISK], DatanodeInfoWithStorage[127.0.0.1:43500,DS-be298416-21b0-407d-8aeb-ea028a2cf8dd,DISK], DatanodeInfoWithStorage[127.0.0.1:33845,DS-624196fe-3b2e-470e-a02d-1f430e157f07,DISK], DatanodeInfoWithStorage[127.0.0.1:39987,DS-6e841aa3-268b-4144-a653-fb90f388a3e6,DISK], DatanodeInfoWithStorage[127.0.0.1:41290,DS-b1ce9eec-9567-4a35-b776-dad2b69bc63c,DISK], DatanodeInfoWithStorage[127.0.0.1:38896,DS-0ac806ca-cad0-4742-8d64-73483adf3a12,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1552414492-172.17.0.12-1598323976014:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46795,DS-bdffae2f-4525-460f-a5bc-4a9ecfa8441f,DISK], DatanodeInfoWithStorage[127.0.0.1:34170,DS-3a064522-dfc3-4462-bf7a-fce5d8404ccd,DISK], DatanodeInfoWithStorage[127.0.0.1:36945,DS-1944b022-b291-44b1-a1b5-a2999c5cf4cd,DISK], DatanodeInfoWithStorage[127.0.0.1:43500,DS-be298416-21b0-407d-8aeb-ea028a2cf8dd,DISK], DatanodeInfoWithStorage[127.0.0.1:33845,DS-624196fe-3b2e-470e-a02d-1f430e157f07,DISK], DatanodeInfoWithStorage[127.0.0.1:39987,DS-6e841aa3-268b-4144-a653-fb90f388a3e6,DISK], DatanodeInfoWithStorage[127.0.0.1:41290,DS-b1ce9eec-9567-4a35-b776-dad2b69bc63c,DISK], DatanodeInfoWithStorage[127.0.0.1:38896,DS-0ac806ca-cad0-4742-8d64-73483adf3a12,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-75134925-172.17.0.12-1598324381000:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46116,DS-9d3ef86c-26b0-4c14-8a53-1fa39f1594b1,DISK], DatanodeInfoWithStorage[127.0.0.1:37302,DS-6d3d9bf0-3990-4871-aae2-0721fb79765f,DISK], DatanodeInfoWithStorage[127.0.0.1:32870,DS-65c81e62-76f9-4393-a420-83a51de128ec,DISK], DatanodeInfoWithStorage[127.0.0.1:36632,DS-5dfeeb7a-a3f3-4609-8f1f-4f96d2ba6d16,DISK], DatanodeInfoWithStorage[127.0.0.1:42978,DS-e1231bfc-0dd8-4353-8fcd-790075b2de36,DISK], DatanodeInfoWithStorage[127.0.0.1:40911,DS-0286ec3d-c185-4913-9240-3fd1adb65419,DISK], DatanodeInfoWithStorage[127.0.0.1:33498,DS-2cd004d3-a157-40af-a72b-7172caf7cb01,DISK], DatanodeInfoWithStorage[127.0.0.1:44976,DS-f2b30093-d106-4f34-8b5f-4aea480ba644,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-75134925-172.17.0.12-1598324381000:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46116,DS-9d3ef86c-26b0-4c14-8a53-1fa39f1594b1,DISK], DatanodeInfoWithStorage[127.0.0.1:37302,DS-6d3d9bf0-3990-4871-aae2-0721fb79765f,DISK], DatanodeInfoWithStorage[127.0.0.1:32870,DS-65c81e62-76f9-4393-a420-83a51de128ec,DISK], DatanodeInfoWithStorage[127.0.0.1:36632,DS-5dfeeb7a-a3f3-4609-8f1f-4f96d2ba6d16,DISK], DatanodeInfoWithStorage[127.0.0.1:42978,DS-e1231bfc-0dd8-4353-8fcd-790075b2de36,DISK], DatanodeInfoWithStorage[127.0.0.1:40911,DS-0286ec3d-c185-4913-9240-3fd1adb65419,DISK], DatanodeInfoWithStorage[127.0.0.1:33498,DS-2cd004d3-a157-40af-a72b-7172caf7cb01,DISK], DatanodeInfoWithStorage[127.0.0.1:44976,DS-f2b30093-d106-4f34-8b5f-4aea480ba644,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1603707569-172.17.0.12-1598324486543:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46649,DS-07b256d0-9114-43b3-b021-8551b0d75361,DISK], DatanodeInfoWithStorage[127.0.0.1:41203,DS-d69c7896-24d5-40da-b4b9-3f357b924544,DISK], DatanodeInfoWithStorage[127.0.0.1:39907,DS-a67e582d-e0d5-4eb8-b1c6-ee71ea170702,DISK], DatanodeInfoWithStorage[127.0.0.1:41465,DS-91be5056-1da0-4e23-ad7a-883545164987,DISK], DatanodeInfoWithStorage[127.0.0.1:44865,DS-2a1e0834-beb3-42e2-a847-8b2c1215ef06,DISK], DatanodeInfoWithStorage[127.0.0.1:45088,DS-b308e5a6-82c6-4c93-b359-277f1bb95d89,DISK], DatanodeInfoWithStorage[127.0.0.1:43777,DS-52627d67-4404-484d-ae39-5be76959b53a,DISK], DatanodeInfoWithStorage[127.0.0.1:39034,DS-7ea3f060-57b8-467b-af0d-3299abffad24,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1603707569-172.17.0.12-1598324486543:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46649,DS-07b256d0-9114-43b3-b021-8551b0d75361,DISK], DatanodeInfoWithStorage[127.0.0.1:41203,DS-d69c7896-24d5-40da-b4b9-3f357b924544,DISK], DatanodeInfoWithStorage[127.0.0.1:39907,DS-a67e582d-e0d5-4eb8-b1c6-ee71ea170702,DISK], DatanodeInfoWithStorage[127.0.0.1:41465,DS-91be5056-1da0-4e23-ad7a-883545164987,DISK], DatanodeInfoWithStorage[127.0.0.1:44865,DS-2a1e0834-beb3-42e2-a847-8b2c1215ef06,DISK], DatanodeInfoWithStorage[127.0.0.1:45088,DS-b308e5a6-82c6-4c93-b359-277f1bb95d89,DISK], DatanodeInfoWithStorage[127.0.0.1:43777,DS-52627d67-4404-484d-ae39-5be76959b53a,DISK], DatanodeInfoWithStorage[127.0.0.1:39034,DS-7ea3f060-57b8-467b-af0d-3299abffad24,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-749419186-172.17.0.12-1598325030790:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34462,DS-55834ffb-6d44-4fa8-9956-322366a4eaa2,DISK], DatanodeInfoWithStorage[127.0.0.1:44947,DS-9204fa19-ce96-466e-9665-86ec257f31cb,DISK], DatanodeInfoWithStorage[127.0.0.1:42496,DS-47b886fb-1bcd-4c76-ab4f-510a73ae1947,DISK], DatanodeInfoWithStorage[127.0.0.1:46315,DS-ffdc7b12-f9b8-44a3-a0ab-b05101b9ad3a,DISK], DatanodeInfoWithStorage[127.0.0.1:41721,DS-fbd939d7-abda-4d84-8c74-4223c436ee13,DISK], DatanodeInfoWithStorage[127.0.0.1:39796,DS-678cdec4-09b6-4c93-b911-ec9bf6807309,DISK], DatanodeInfoWithStorage[127.0.0.1:45085,DS-4394df59-dc23-4e58-9a9d-a54f5bc2251c,DISK], DatanodeInfoWithStorage[127.0.0.1:40209,DS-a9c3851c-1e98-4d1e-baea-729097a2a862,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-749419186-172.17.0.12-1598325030790:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34462,DS-55834ffb-6d44-4fa8-9956-322366a4eaa2,DISK], DatanodeInfoWithStorage[127.0.0.1:44947,DS-9204fa19-ce96-466e-9665-86ec257f31cb,DISK], DatanodeInfoWithStorage[127.0.0.1:42496,DS-47b886fb-1bcd-4c76-ab4f-510a73ae1947,DISK], DatanodeInfoWithStorage[127.0.0.1:46315,DS-ffdc7b12-f9b8-44a3-a0ab-b05101b9ad3a,DISK], DatanodeInfoWithStorage[127.0.0.1:41721,DS-fbd939d7-abda-4d84-8c74-4223c436ee13,DISK], DatanodeInfoWithStorage[127.0.0.1:39796,DS-678cdec4-09b6-4c93-b911-ec9bf6807309,DISK], DatanodeInfoWithStorage[127.0.0.1:45085,DS-4394df59-dc23-4e58-9a9d-a54f5bc2251c,DISK], DatanodeInfoWithStorage[127.0.0.1:40209,DS-a9c3851c-1e98-4d1e-baea-729097a2a862,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2129274821-172.17.0.12-1598325185863:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37192,DS-6286a463-36bc-4829-ab71-d2f6a1329ddd,DISK], DatanodeInfoWithStorage[127.0.0.1:32853,DS-a4bab301-2f15-4b5b-8646-d51502d50ee4,DISK], DatanodeInfoWithStorage[127.0.0.1:42541,DS-3b7b91cc-c7c3-4de4-a2b4-df7531eb4e53,DISK], DatanodeInfoWithStorage[127.0.0.1:33535,DS-d7272185-8540-459f-bd98-d104e5c3f079,DISK], DatanodeInfoWithStorage[127.0.0.1:34224,DS-c526c378-cbf5-4b71-8e61-e24970c9de0f,DISK], DatanodeInfoWithStorage[127.0.0.1:38533,DS-f6299b02-dc25-47e8-a57e-205e412dc855,DISK], DatanodeInfoWithStorage[127.0.0.1:34223,DS-b12457d3-be8d-4285-b4fa-0f5e45e3cbc3,DISK], DatanodeInfoWithStorage[127.0.0.1:46835,DS-0c492e9c-7a6b-414c-bd5f-96dda8a22f68,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2129274821-172.17.0.12-1598325185863:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37192,DS-6286a463-36bc-4829-ab71-d2f6a1329ddd,DISK], DatanodeInfoWithStorage[127.0.0.1:32853,DS-a4bab301-2f15-4b5b-8646-d51502d50ee4,DISK], DatanodeInfoWithStorage[127.0.0.1:42541,DS-3b7b91cc-c7c3-4de4-a2b4-df7531eb4e53,DISK], DatanodeInfoWithStorage[127.0.0.1:33535,DS-d7272185-8540-459f-bd98-d104e5c3f079,DISK], DatanodeInfoWithStorage[127.0.0.1:34224,DS-c526c378-cbf5-4b71-8e61-e24970c9de0f,DISK], DatanodeInfoWithStorage[127.0.0.1:38533,DS-f6299b02-dc25-47e8-a57e-205e412dc855,DISK], DatanodeInfoWithStorage[127.0.0.1:34223,DS-b12457d3-be8d-4285-b4fa-0f5e45e3cbc3,DISK], DatanodeInfoWithStorage[127.0.0.1:46835,DS-0c492e9c-7a6b-414c-bd5f-96dda8a22f68,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-885950033-172.17.0.12-1598325278751:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37465,DS-e06c74d7-6a38-41e0-ac7f-efa69af9ff6d,DISK], DatanodeInfoWithStorage[127.0.0.1:40666,DS-a67e792b-df75-4c93-b4ff-8b79891cbedd,DISK], DatanodeInfoWithStorage[127.0.0.1:36685,DS-e54ca277-5c07-49c8-b70f-7dc8a8941bb7,DISK], DatanodeInfoWithStorage[127.0.0.1:44550,DS-68e18969-06ee-4a51-9eb0-a0b970cd5e78,DISK], DatanodeInfoWithStorage[127.0.0.1:42581,DS-cf09d298-879f-40dd-82ec-43810352cdcc,DISK], DatanodeInfoWithStorage[127.0.0.1:36676,DS-65c5e7e2-f7be-41c4-8cbd-b54fba71ef8d,DISK], DatanodeInfoWithStorage[127.0.0.1:45046,DS-a3bd450a-c61d-464f-a38e-9a76802a0b5e,DISK], DatanodeInfoWithStorage[127.0.0.1:35110,DS-f3ecaa54-c0e3-4b4e-acd4-b79afce22bdb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-885950033-172.17.0.12-1598325278751:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37465,DS-e06c74d7-6a38-41e0-ac7f-efa69af9ff6d,DISK], DatanodeInfoWithStorage[127.0.0.1:40666,DS-a67e792b-df75-4c93-b4ff-8b79891cbedd,DISK], DatanodeInfoWithStorage[127.0.0.1:36685,DS-e54ca277-5c07-49c8-b70f-7dc8a8941bb7,DISK], DatanodeInfoWithStorage[127.0.0.1:44550,DS-68e18969-06ee-4a51-9eb0-a0b970cd5e78,DISK], DatanodeInfoWithStorage[127.0.0.1:42581,DS-cf09d298-879f-40dd-82ec-43810352cdcc,DISK], DatanodeInfoWithStorage[127.0.0.1:36676,DS-65c5e7e2-f7be-41c4-8cbd-b54fba71ef8d,DISK], DatanodeInfoWithStorage[127.0.0.1:45046,DS-a3bd450a-c61d-464f-a38e-9a76802a0b5e,DISK], DatanodeInfoWithStorage[127.0.0.1:35110,DS-f3ecaa54-c0e3-4b4e-acd4-b79afce22bdb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1583903517-172.17.0.12-1598325628852:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36408,DS-89d2a0a1-3efb-450b-bf8c-ecad6a96246f,DISK], DatanodeInfoWithStorage[127.0.0.1:36078,DS-482f08e3-6a8a-4132-ad8a-65a8549ce1ba,DISK], DatanodeInfoWithStorage[127.0.0.1:38354,DS-d6cd36a8-7b6e-43ed-b146-da53a7c26103,DISK], DatanodeInfoWithStorage[127.0.0.1:38638,DS-a2bdf10d-63a0-4866-b1d5-875a46a0555d,DISK], DatanodeInfoWithStorage[127.0.0.1:42495,DS-eeea1793-a666-49fc-a41c-13cd4bc2a6c2,DISK], DatanodeInfoWithStorage[127.0.0.1:39079,DS-63ae57d4-9a9d-4756-a2b7-da0cc13d4357,DISK], DatanodeInfoWithStorage[127.0.0.1:39918,DS-a7f2baec-bc96-439d-8f2b-290db2ea82ae,DISK], DatanodeInfoWithStorage[127.0.0.1:35258,DS-d4b68d4d-718c-42e6-9737-9fb8a69dc939,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1583903517-172.17.0.12-1598325628852:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36408,DS-89d2a0a1-3efb-450b-bf8c-ecad6a96246f,DISK], DatanodeInfoWithStorage[127.0.0.1:36078,DS-482f08e3-6a8a-4132-ad8a-65a8549ce1ba,DISK], DatanodeInfoWithStorage[127.0.0.1:38354,DS-d6cd36a8-7b6e-43ed-b146-da53a7c26103,DISK], DatanodeInfoWithStorage[127.0.0.1:38638,DS-a2bdf10d-63a0-4866-b1d5-875a46a0555d,DISK], DatanodeInfoWithStorage[127.0.0.1:42495,DS-eeea1793-a666-49fc-a41c-13cd4bc2a6c2,DISK], DatanodeInfoWithStorage[127.0.0.1:39079,DS-63ae57d4-9a9d-4756-a2b7-da0cc13d4357,DISK], DatanodeInfoWithStorage[127.0.0.1:39918,DS-a7f2baec-bc96-439d-8f2b-290db2ea82ae,DISK], DatanodeInfoWithStorage[127.0.0.1:35258,DS-d4b68d4d-718c-42e6-9737-9fb8a69dc939,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1626158313-172.17.0.12-1598325695514:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33295,DS-90e2348c-dfa6-4b7b-add3-8e6684be6ab0,DISK], DatanodeInfoWithStorage[127.0.0.1:32934,DS-5f4b4e02-c4f2-48e8-9b78-b0b23bea2cbc,DISK], DatanodeInfoWithStorage[127.0.0.1:38020,DS-b63ae2eb-6ecd-4ae8-ae86-d33903e8722f,DISK], DatanodeInfoWithStorage[127.0.0.1:38207,DS-8cf8b0d2-fd2b-4a2c-a4dc-793f5b72c1de,DISK], DatanodeInfoWithStorage[127.0.0.1:45871,DS-74f3f4d3-e96e-4c82-85b4-947896793fd5,DISK], DatanodeInfoWithStorage[127.0.0.1:41929,DS-516561da-4a03-4c7b-aa19-0dbd2cf26c16,DISK], DatanodeInfoWithStorage[127.0.0.1:37804,DS-58b882df-7c75-4f7d-b115-b795b17ebd1d,DISK], DatanodeInfoWithStorage[127.0.0.1:36678,DS-13e0d932-fec6-49e1-bf7f-c81993eab046,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1626158313-172.17.0.12-1598325695514:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33295,DS-90e2348c-dfa6-4b7b-add3-8e6684be6ab0,DISK], DatanodeInfoWithStorage[127.0.0.1:32934,DS-5f4b4e02-c4f2-48e8-9b78-b0b23bea2cbc,DISK], DatanodeInfoWithStorage[127.0.0.1:38020,DS-b63ae2eb-6ecd-4ae8-ae86-d33903e8722f,DISK], DatanodeInfoWithStorage[127.0.0.1:38207,DS-8cf8b0d2-fd2b-4a2c-a4dc-793f5b72c1de,DISK], DatanodeInfoWithStorage[127.0.0.1:45871,DS-74f3f4d3-e96e-4c82-85b4-947896793fd5,DISK], DatanodeInfoWithStorage[127.0.0.1:41929,DS-516561da-4a03-4c7b-aa19-0dbd2cf26c16,DISK], DatanodeInfoWithStorage[127.0.0.1:37804,DS-58b882df-7c75-4f7d-b115-b795b17ebd1d,DISK], DatanodeInfoWithStorage[127.0.0.1:36678,DS-13e0d932-fec6-49e1-bf7f-c81993eab046,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1264016573-172.17.0.12-1598325883260:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46882,DS-feb562d8-7312-431d-91e8-10b303f85bb6,DISK], DatanodeInfoWithStorage[127.0.0.1:41826,DS-0bc5d5e2-eb4a-4a54-adf6-f00e85cb2bc1,DISK], DatanodeInfoWithStorage[127.0.0.1:38247,DS-168dcc4c-82ec-4658-b3eb-b124fb77a799,DISK], DatanodeInfoWithStorage[127.0.0.1:44162,DS-47f2d2ba-30aa-459c-a673-5a6679784403,DISK], DatanodeInfoWithStorage[127.0.0.1:39873,DS-c5002266-e54e-4d43-8a9c-052cb58f10b7,DISK], DatanodeInfoWithStorage[127.0.0.1:43111,DS-9675bcb2-4d7d-4329-ab6d-5afde119cb11,DISK], DatanodeInfoWithStorage[127.0.0.1:40546,DS-5bd27514-d4ae-4488-968b-845013940c9b,DISK], DatanodeInfoWithStorage[127.0.0.1:43768,DS-24c86796-29a8-4c1a-bc9f-a2f0003f517a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1264016573-172.17.0.12-1598325883260:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46882,DS-feb562d8-7312-431d-91e8-10b303f85bb6,DISK], DatanodeInfoWithStorage[127.0.0.1:41826,DS-0bc5d5e2-eb4a-4a54-adf6-f00e85cb2bc1,DISK], DatanodeInfoWithStorage[127.0.0.1:38247,DS-168dcc4c-82ec-4658-b3eb-b124fb77a799,DISK], DatanodeInfoWithStorage[127.0.0.1:44162,DS-47f2d2ba-30aa-459c-a673-5a6679784403,DISK], DatanodeInfoWithStorage[127.0.0.1:39873,DS-c5002266-e54e-4d43-8a9c-052cb58f10b7,DISK], DatanodeInfoWithStorage[127.0.0.1:43111,DS-9675bcb2-4d7d-4329-ab6d-5afde119cb11,DISK], DatanodeInfoWithStorage[127.0.0.1:40546,DS-5bd27514-d4ae-4488-968b-845013940c9b,DISK], DatanodeInfoWithStorage[127.0.0.1:43768,DS-24c86796-29a8-4c1a-bc9f-a2f0003f517a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2084250816-172.17.0.12-1598326286239:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41948,DS-9cc0580c-37f1-4371-a4c5-215e57cffb81,DISK], DatanodeInfoWithStorage[127.0.0.1:40318,DS-5512ec55-8903-40fc-a0ad-2ed7282469c7,DISK], DatanodeInfoWithStorage[127.0.0.1:34211,DS-47ea2238-0533-48ac-b511-f6fc376d0b94,DISK], DatanodeInfoWithStorage[127.0.0.1:42021,DS-3b09fc68-bb41-4d58-85b8-11240743bac4,DISK], DatanodeInfoWithStorage[127.0.0.1:41058,DS-a0067b2e-a4a9-45a4-8202-771bc1add0aa,DISK], DatanodeInfoWithStorage[127.0.0.1:43084,DS-04225ef2-edd7-4af7-bd4b-92f2b7e40662,DISK], DatanodeInfoWithStorage[127.0.0.1:37488,DS-8c2b511e-f775-4932-9dd9-b357c790c0bb,DISK], DatanodeInfoWithStorage[127.0.0.1:34938,DS-552f0576-c5f4-4570-94d4-9df165ed09eb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2084250816-172.17.0.12-1598326286239:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41948,DS-9cc0580c-37f1-4371-a4c5-215e57cffb81,DISK], DatanodeInfoWithStorage[127.0.0.1:40318,DS-5512ec55-8903-40fc-a0ad-2ed7282469c7,DISK], DatanodeInfoWithStorage[127.0.0.1:34211,DS-47ea2238-0533-48ac-b511-f6fc376d0b94,DISK], DatanodeInfoWithStorage[127.0.0.1:42021,DS-3b09fc68-bb41-4d58-85b8-11240743bac4,DISK], DatanodeInfoWithStorage[127.0.0.1:41058,DS-a0067b2e-a4a9-45a4-8202-771bc1add0aa,DISK], DatanodeInfoWithStorage[127.0.0.1:43084,DS-04225ef2-edd7-4af7-bd4b-92f2b7e40662,DISK], DatanodeInfoWithStorage[127.0.0.1:37488,DS-8c2b511e-f775-4932-9dd9-b357c790c0bb,DISK], DatanodeInfoWithStorage[127.0.0.1:34938,DS-552f0576-c5f4-4570-94d4-9df165ed09eb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1025281357-172.17.0.12-1598326423597:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38300,DS-d3267f0d-6dae-414c-981d-c1d32cd7006d,DISK], DatanodeInfoWithStorage[127.0.0.1:40558,DS-0c812a7b-7dd2-45de-bd2e-99f0f2a4ed91,DISK], DatanodeInfoWithStorage[127.0.0.1:33325,DS-465e736d-b9e7-4687-8ab3-c64101bbd574,DISK], DatanodeInfoWithStorage[127.0.0.1:43675,DS-603e206a-030e-49e9-a9ab-c38999bd917b,DISK], DatanodeInfoWithStorage[127.0.0.1:38036,DS-036dd9a2-1b1e-4558-b553-916d796110c5,DISK], DatanodeInfoWithStorage[127.0.0.1:34438,DS-c3a65ba2-71f6-49a1-89d6-4abc16583367,DISK], DatanodeInfoWithStorage[127.0.0.1:42750,DS-2f4bfe39-4a86-479d-9783-7a89f7885ca4,DISK], DatanodeInfoWithStorage[127.0.0.1:42236,DS-07c86fa9-e414-4965-ad86-d57ec43644b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1025281357-172.17.0.12-1598326423597:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38300,DS-d3267f0d-6dae-414c-981d-c1d32cd7006d,DISK], DatanodeInfoWithStorage[127.0.0.1:40558,DS-0c812a7b-7dd2-45de-bd2e-99f0f2a4ed91,DISK], DatanodeInfoWithStorage[127.0.0.1:33325,DS-465e736d-b9e7-4687-8ab3-c64101bbd574,DISK], DatanodeInfoWithStorage[127.0.0.1:43675,DS-603e206a-030e-49e9-a9ab-c38999bd917b,DISK], DatanodeInfoWithStorage[127.0.0.1:38036,DS-036dd9a2-1b1e-4558-b553-916d796110c5,DISK], DatanodeInfoWithStorage[127.0.0.1:34438,DS-c3a65ba2-71f6-49a1-89d6-4abc16583367,DISK], DatanodeInfoWithStorage[127.0.0.1:42750,DS-2f4bfe39-4a86-479d-9783-7a89f7885ca4,DISK], DatanodeInfoWithStorage[127.0.0.1:42236,DS-07c86fa9-e414-4965-ad86-d57ec43644b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1486904130-172.17.0.12-1598326534955:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34572,DS-e1be8949-c4be-4b33-bd5b-e3b0d0a7dfce,DISK], DatanodeInfoWithStorage[127.0.0.1:43084,DS-9e5daad6-c134-4d6f-8a16-bd3b8568ead9,DISK], DatanodeInfoWithStorage[127.0.0.1:40663,DS-f8ba3455-8909-4e8c-a0a5-f03e300fe75a,DISK], DatanodeInfoWithStorage[127.0.0.1:33934,DS-b22c34d7-be35-4b6f-bc70-d848d6b28da7,DISK], DatanodeInfoWithStorage[127.0.0.1:42814,DS-d4644e77-7859-45fa-9e1d-09fd0212421f,DISK], DatanodeInfoWithStorage[127.0.0.1:44120,DS-07e6cafd-e420-4776-913f-0d7ea1d92291,DISK], DatanodeInfoWithStorage[127.0.0.1:44300,DS-95e7323e-cf9c-45cc-afc9-f22905f3aa56,DISK], DatanodeInfoWithStorage[127.0.0.1:45680,DS-2713f27f-ea09-422e-9614-b2db7733f812,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1486904130-172.17.0.12-1598326534955:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34572,DS-e1be8949-c4be-4b33-bd5b-e3b0d0a7dfce,DISK], DatanodeInfoWithStorage[127.0.0.1:43084,DS-9e5daad6-c134-4d6f-8a16-bd3b8568ead9,DISK], DatanodeInfoWithStorage[127.0.0.1:40663,DS-f8ba3455-8909-4e8c-a0a5-f03e300fe75a,DISK], DatanodeInfoWithStorage[127.0.0.1:33934,DS-b22c34d7-be35-4b6f-bc70-d848d6b28da7,DISK], DatanodeInfoWithStorage[127.0.0.1:42814,DS-d4644e77-7859-45fa-9e1d-09fd0212421f,DISK], DatanodeInfoWithStorage[127.0.0.1:44120,DS-07e6cafd-e420-4776-913f-0d7ea1d92291,DISK], DatanodeInfoWithStorage[127.0.0.1:44300,DS-95e7323e-cf9c-45cc-afc9-f22905f3aa56,DISK], DatanodeInfoWithStorage[127.0.0.1:45680,DS-2713f27f-ea09-422e-9614-b2db7733f812,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1748946046-172.17.0.12-1598326647805:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41375,DS-a5adb66b-2667-4575-907c-1c830659e21a,DISK], DatanodeInfoWithStorage[127.0.0.1:45856,DS-50d60463-24fb-4f33-8409-62ac6dc9bf19,DISK], DatanodeInfoWithStorage[127.0.0.1:36065,DS-e3394179-6c28-43e4-9804-fab52ac1fd3b,DISK], DatanodeInfoWithStorage[127.0.0.1:38869,DS-f7eccb74-3e4e-4948-94e1-3c4be6989202,DISK], DatanodeInfoWithStorage[127.0.0.1:42268,DS-2f3e7c87-9d52-43e7-ac02-92fdd0e01ccb,DISK], DatanodeInfoWithStorage[127.0.0.1:40412,DS-a462203a-227e-451b-96a2-58a8903c5755,DISK], DatanodeInfoWithStorage[127.0.0.1:39401,DS-64a63a0b-841f-42f1-9711-c0f5a438c1e8,DISK], DatanodeInfoWithStorage[127.0.0.1:41459,DS-ad9cf633-240d-450a-88f8-29d8b420093f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1748946046-172.17.0.12-1598326647805:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41375,DS-a5adb66b-2667-4575-907c-1c830659e21a,DISK], DatanodeInfoWithStorage[127.0.0.1:45856,DS-50d60463-24fb-4f33-8409-62ac6dc9bf19,DISK], DatanodeInfoWithStorage[127.0.0.1:36065,DS-e3394179-6c28-43e4-9804-fab52ac1fd3b,DISK], DatanodeInfoWithStorage[127.0.0.1:38869,DS-f7eccb74-3e4e-4948-94e1-3c4be6989202,DISK], DatanodeInfoWithStorage[127.0.0.1:42268,DS-2f3e7c87-9d52-43e7-ac02-92fdd0e01ccb,DISK], DatanodeInfoWithStorage[127.0.0.1:40412,DS-a462203a-227e-451b-96a2-58a8903c5755,DISK], DatanodeInfoWithStorage[127.0.0.1:39401,DS-64a63a0b-841f-42f1-9711-c0f5a438c1e8,DISK], DatanodeInfoWithStorage[127.0.0.1:41459,DS-ad9cf633-240d-450a-88f8-29d8b420093f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-535334579-172.17.0.12-1598326753116:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44415,DS-72e5ff15-89fe-4dcf-b615-10b6ad6e22f9,DISK], DatanodeInfoWithStorage[127.0.0.1:39992,DS-f45a4734-e222-4434-963b-64f9788cb3b1,DISK], DatanodeInfoWithStorage[127.0.0.1:42486,DS-272ba928-2385-42e8-a2d5-2662b4099746,DISK], DatanodeInfoWithStorage[127.0.0.1:35578,DS-92818469-bb98-428e-aaaf-1b174da53e94,DISK], DatanodeInfoWithStorage[127.0.0.1:40601,DS-78ed94f3-19da-4ca7-9943-525109bbc0ae,DISK], DatanodeInfoWithStorage[127.0.0.1:44536,DS-86aa130c-3c43-4698-bfdf-b58c52641c93,DISK], DatanodeInfoWithStorage[127.0.0.1:43351,DS-e55c0ca2-679b-4570-aa86-9babf3c0abb7,DISK], DatanodeInfoWithStorage[127.0.0.1:42166,DS-bede2cf2-161c-454b-b41d-f6db0309705d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-535334579-172.17.0.12-1598326753116:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44415,DS-72e5ff15-89fe-4dcf-b615-10b6ad6e22f9,DISK], DatanodeInfoWithStorage[127.0.0.1:39992,DS-f45a4734-e222-4434-963b-64f9788cb3b1,DISK], DatanodeInfoWithStorage[127.0.0.1:42486,DS-272ba928-2385-42e8-a2d5-2662b4099746,DISK], DatanodeInfoWithStorage[127.0.0.1:35578,DS-92818469-bb98-428e-aaaf-1b174da53e94,DISK], DatanodeInfoWithStorage[127.0.0.1:40601,DS-78ed94f3-19da-4ca7-9943-525109bbc0ae,DISK], DatanodeInfoWithStorage[127.0.0.1:44536,DS-86aa130c-3c43-4698-bfdf-b58c52641c93,DISK], DatanodeInfoWithStorage[127.0.0.1:43351,DS-e55c0ca2-679b-4570-aa86-9babf3c0abb7,DISK], DatanodeInfoWithStorage[127.0.0.1:42166,DS-bede2cf2-161c-454b-b41d-f6db0309705d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2061402030-172.17.0.12-1598327172610:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36234,DS-0bbd65cc-0a91-4268-af37-fdd7fa571d7f,DISK], DatanodeInfoWithStorage[127.0.0.1:43993,DS-cfd2861c-9f5e-4c97-a70c-49e8245e57b3,DISK], DatanodeInfoWithStorage[127.0.0.1:42969,DS-58ca0faa-fad6-4ad4-9b97-546e75d08636,DISK], DatanodeInfoWithStorage[127.0.0.1:37605,DS-ab712669-aa10-4546-8c03-7df92ce0523d,DISK], DatanodeInfoWithStorage[127.0.0.1:45147,DS-b3c58890-60ae-4060-bf6b-4e386e528dd2,DISK], DatanodeInfoWithStorage[127.0.0.1:35218,DS-0a4ce922-fa19-4509-8709-5d26e3abebdf,DISK], DatanodeInfoWithStorage[127.0.0.1:46246,DS-91010209-df03-4dd5-b434-c8649fb3366f,DISK], DatanodeInfoWithStorage[127.0.0.1:43246,DS-3bb7dc6b-b03d-4049-a92c-2354da9c24b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2061402030-172.17.0.12-1598327172610:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36234,DS-0bbd65cc-0a91-4268-af37-fdd7fa571d7f,DISK], DatanodeInfoWithStorage[127.0.0.1:43993,DS-cfd2861c-9f5e-4c97-a70c-49e8245e57b3,DISK], DatanodeInfoWithStorage[127.0.0.1:42969,DS-58ca0faa-fad6-4ad4-9b97-546e75d08636,DISK], DatanodeInfoWithStorage[127.0.0.1:37605,DS-ab712669-aa10-4546-8c03-7df92ce0523d,DISK], DatanodeInfoWithStorage[127.0.0.1:45147,DS-b3c58890-60ae-4060-bf6b-4e386e528dd2,DISK], DatanodeInfoWithStorage[127.0.0.1:35218,DS-0a4ce922-fa19-4509-8709-5d26e3abebdf,DISK], DatanodeInfoWithStorage[127.0.0.1:46246,DS-91010209-df03-4dd5-b434-c8649fb3366f,DISK], DatanodeInfoWithStorage[127.0.0.1:43246,DS-3bb7dc6b-b03d-4049-a92c-2354da9c24b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1919474385-172.17.0.12-1598327790389:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33872,DS-64e3dfb6-615c-4076-878d-bf24b3b65e2e,DISK], DatanodeInfoWithStorage[127.0.0.1:44085,DS-c68b770b-c5d0-4d43-8d83-f3f0a0cc8566,DISK], DatanodeInfoWithStorage[127.0.0.1:39346,DS-877b01fa-e982-457e-a2f0-933d069d2a50,DISK], DatanodeInfoWithStorage[127.0.0.1:44771,DS-2b576436-dc7f-4756-84a5-90eb6d184149,DISK], DatanodeInfoWithStorage[127.0.0.1:37712,DS-99da0624-033b-48d7-b7e1-dcf51ad3ed0f,DISK], DatanodeInfoWithStorage[127.0.0.1:43644,DS-2c0a7638-dec3-4f5c-9729-d9d7098bc50a,DISK], DatanodeInfoWithStorage[127.0.0.1:34099,DS-6dd9f8bb-86d1-4602-9f2d-b9ef2ea2415a,DISK], DatanodeInfoWithStorage[127.0.0.1:35012,DS-9153981f-3718-44f6-b3ea-6d5761cf6145,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1919474385-172.17.0.12-1598327790389:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33872,DS-64e3dfb6-615c-4076-878d-bf24b3b65e2e,DISK], DatanodeInfoWithStorage[127.0.0.1:44085,DS-c68b770b-c5d0-4d43-8d83-f3f0a0cc8566,DISK], DatanodeInfoWithStorage[127.0.0.1:39346,DS-877b01fa-e982-457e-a2f0-933d069d2a50,DISK], DatanodeInfoWithStorage[127.0.0.1:44771,DS-2b576436-dc7f-4756-84a5-90eb6d184149,DISK], DatanodeInfoWithStorage[127.0.0.1:37712,DS-99da0624-033b-48d7-b7e1-dcf51ad3ed0f,DISK], DatanodeInfoWithStorage[127.0.0.1:43644,DS-2c0a7638-dec3-4f5c-9729-d9d7098bc50a,DISK], DatanodeInfoWithStorage[127.0.0.1:34099,DS-6dd9f8bb-86d1-4602-9f2d-b9ef2ea2415a,DISK], DatanodeInfoWithStorage[127.0.0.1:35012,DS-9153981f-3718-44f6-b3ea-6d5761cf6145,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-825485097-172.17.0.12-1598327836479:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33383,DS-f4af8454-3b97-49d9-b285-3db1a5ae5bc4,DISK], DatanodeInfoWithStorage[127.0.0.1:42991,DS-3091c898-2dbc-4104-bf1f-ebfb160a6256,DISK], DatanodeInfoWithStorage[127.0.0.1:37216,DS-9edb6827-65ae-4748-ae59-c0ab6d6502d5,DISK], DatanodeInfoWithStorage[127.0.0.1:35658,DS-d4471ae2-3944-4d59-9f71-08910b78b54c,DISK], DatanodeInfoWithStorage[127.0.0.1:45627,DS-8daea591-7985-4c8b-b15e-3998c89ac13c,DISK], DatanodeInfoWithStorage[127.0.0.1:42142,DS-9f377a68-e8a0-4363-99e5-31c71606ef45,DISK], DatanodeInfoWithStorage[127.0.0.1:38722,DS-13e0ae8d-9f36-4f0d-9100-9c4c22e430fc,DISK], DatanodeInfoWithStorage[127.0.0.1:36778,DS-769e563d-1a64-4752-be6c-3566146ba74c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-825485097-172.17.0.12-1598327836479:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33383,DS-f4af8454-3b97-49d9-b285-3db1a5ae5bc4,DISK], DatanodeInfoWithStorage[127.0.0.1:42991,DS-3091c898-2dbc-4104-bf1f-ebfb160a6256,DISK], DatanodeInfoWithStorage[127.0.0.1:37216,DS-9edb6827-65ae-4748-ae59-c0ab6d6502d5,DISK], DatanodeInfoWithStorage[127.0.0.1:35658,DS-d4471ae2-3944-4d59-9f71-08910b78b54c,DISK], DatanodeInfoWithStorage[127.0.0.1:45627,DS-8daea591-7985-4c8b-b15e-3998c89ac13c,DISK], DatanodeInfoWithStorage[127.0.0.1:42142,DS-9f377a68-e8a0-4363-99e5-31c71606ef45,DISK], DatanodeInfoWithStorage[127.0.0.1:38722,DS-13e0ae8d-9f36-4f0d-9100-9c4c22e430fc,DISK], DatanodeInfoWithStorage[127.0.0.1:36778,DS-769e563d-1a64-4752-be6c-3566146ba74c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 2 out of 50
v1v1v2v2 failed with probability 17 out of 50
result: false positive !!!
Total execution time in seconds : 5344
