reconf_parameter: dfs.permissions.ContentSummary.subAccess
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.ContentSummary.subAccess
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1969341705-172.17.0.12-1598354171450:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45487,DS-417158e9-584e-479c-9e08-a7c28d564501,DISK], DatanodeInfoWithStorage[127.0.0.1:46499,DS-fd73964b-9873-4385-a268-3fcf4d227eea,DISK], DatanodeInfoWithStorage[127.0.0.1:43342,DS-ab748cbd-c1ae-4bb8-b63b-ac725f4c378a,DISK], DatanodeInfoWithStorage[127.0.0.1:42208,DS-ead7e6b0-8f31-4dbb-b05b-0d2a4912be10,DISK], DatanodeInfoWithStorage[127.0.0.1:37602,DS-b5588f51-d827-4d96-a713-8f01a9d22f63,DISK], DatanodeInfoWithStorage[127.0.0.1:38686,DS-ce74384e-fd9f-4cfc-8b6d-ba247c580ab0,DISK], DatanodeInfoWithStorage[127.0.0.1:45230,DS-3d481e04-d07b-4fd5-8a2e-3446d51a76be,DISK], DatanodeInfoWithStorage[127.0.0.1:40789,DS-65ac207b-6f8e-48ef-9e79-ca054bbe89b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1969341705-172.17.0.12-1598354171450:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45487,DS-417158e9-584e-479c-9e08-a7c28d564501,DISK], DatanodeInfoWithStorage[127.0.0.1:46499,DS-fd73964b-9873-4385-a268-3fcf4d227eea,DISK], DatanodeInfoWithStorage[127.0.0.1:43342,DS-ab748cbd-c1ae-4bb8-b63b-ac725f4c378a,DISK], DatanodeInfoWithStorage[127.0.0.1:42208,DS-ead7e6b0-8f31-4dbb-b05b-0d2a4912be10,DISK], DatanodeInfoWithStorage[127.0.0.1:37602,DS-b5588f51-d827-4d96-a713-8f01a9d22f63,DISK], DatanodeInfoWithStorage[127.0.0.1:38686,DS-ce74384e-fd9f-4cfc-8b6d-ba247c580ab0,DISK], DatanodeInfoWithStorage[127.0.0.1:45230,DS-3d481e04-d07b-4fd5-8a2e-3446d51a76be,DISK], DatanodeInfoWithStorage[127.0.0.1:40789,DS-65ac207b-6f8e-48ef-9e79-ca054bbe89b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.ContentSummary.subAccess
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2040460468-172.17.0.12-1598354358262:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37675,DS-8619fb0d-7cb4-4f74-9fa9-f39562abac95,DISK], DatanodeInfoWithStorage[127.0.0.1:42537,DS-6278e525-401d-4f51-abf9-11458e3accf6,DISK], DatanodeInfoWithStorage[127.0.0.1:39143,DS-49b05c8c-cc75-4e13-a718-b9c6c9c5b339,DISK], DatanodeInfoWithStorage[127.0.0.1:44508,DS-16d77732-aa04-4f76-9144-c475c358b65f,DISK], DatanodeInfoWithStorage[127.0.0.1:41571,DS-e2339e83-823d-40f4-88da-adeab6b7761e,DISK], DatanodeInfoWithStorage[127.0.0.1:38178,DS-a1c0ba28-9936-4780-9fa9-5011d99748dd,DISK], DatanodeInfoWithStorage[127.0.0.1:35163,DS-704ef4ec-9ce1-4b14-b205-3ef520a9cfbf,DISK], DatanodeInfoWithStorage[127.0.0.1:33481,DS-b2e2eb80-3932-4a99-873a-87a6ed934ece,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2040460468-172.17.0.12-1598354358262:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37675,DS-8619fb0d-7cb4-4f74-9fa9-f39562abac95,DISK], DatanodeInfoWithStorage[127.0.0.1:42537,DS-6278e525-401d-4f51-abf9-11458e3accf6,DISK], DatanodeInfoWithStorage[127.0.0.1:39143,DS-49b05c8c-cc75-4e13-a718-b9c6c9c5b339,DISK], DatanodeInfoWithStorage[127.0.0.1:44508,DS-16d77732-aa04-4f76-9144-c475c358b65f,DISK], DatanodeInfoWithStorage[127.0.0.1:41571,DS-e2339e83-823d-40f4-88da-adeab6b7761e,DISK], DatanodeInfoWithStorage[127.0.0.1:38178,DS-a1c0ba28-9936-4780-9fa9-5011d99748dd,DISK], DatanodeInfoWithStorage[127.0.0.1:35163,DS-704ef4ec-9ce1-4b14-b205-3ef520a9cfbf,DISK], DatanodeInfoWithStorage[127.0.0.1:33481,DS-b2e2eb80-3932-4a99-873a-87a6ed934ece,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.ContentSummary.subAccess
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1578598366-172.17.0.12-1598354537806:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41491,DS-1dcfc8a6-f6b5-4e35-af6c-d6be2e817d19,DISK], DatanodeInfoWithStorage[127.0.0.1:45336,DS-a483a099-7fd0-43c9-bed3-f13d5a37acbb,DISK], DatanodeInfoWithStorage[127.0.0.1:35187,DS-accc054c-7e46-4de1-aeab-137692f71969,DISK], DatanodeInfoWithStorage[127.0.0.1:43378,DS-827c81ec-817c-4055-8b02-70a79482a70a,DISK], DatanodeInfoWithStorage[127.0.0.1:37553,DS-574b56bf-b794-4090-b06f-c34beb2e671f,DISK], DatanodeInfoWithStorage[127.0.0.1:35688,DS-fc5aa459-8cc2-406b-b6eb-ac12f3bae940,DISK], DatanodeInfoWithStorage[127.0.0.1:36546,DS-b818cf7d-03af-48f0-b065-2e6e552c53d4,DISK], DatanodeInfoWithStorage[127.0.0.1:35500,DS-3d317742-af83-43ac-8103-61fec1f830b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1578598366-172.17.0.12-1598354537806:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41491,DS-1dcfc8a6-f6b5-4e35-af6c-d6be2e817d19,DISK], DatanodeInfoWithStorage[127.0.0.1:45336,DS-a483a099-7fd0-43c9-bed3-f13d5a37acbb,DISK], DatanodeInfoWithStorage[127.0.0.1:35187,DS-accc054c-7e46-4de1-aeab-137692f71969,DISK], DatanodeInfoWithStorage[127.0.0.1:43378,DS-827c81ec-817c-4055-8b02-70a79482a70a,DISK], DatanodeInfoWithStorage[127.0.0.1:37553,DS-574b56bf-b794-4090-b06f-c34beb2e671f,DISK], DatanodeInfoWithStorage[127.0.0.1:35688,DS-fc5aa459-8cc2-406b-b6eb-ac12f3bae940,DISK], DatanodeInfoWithStorage[127.0.0.1:36546,DS-b818cf7d-03af-48f0-b065-2e6e552c53d4,DISK], DatanodeInfoWithStorage[127.0.0.1:35500,DS-3d317742-af83-43ac-8103-61fec1f830b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.ContentSummary.subAccess
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-448145815-172.17.0.12-1598354811029:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46189,DS-232b9733-f6e2-49d0-bbbf-56a16efc9932,DISK], DatanodeInfoWithStorage[127.0.0.1:35482,DS-a6e9bf90-245d-45a3-8392-0c52ec5b0b30,DISK], DatanodeInfoWithStorage[127.0.0.1:40243,DS-dc4e307e-a009-4e6a-a240-b9d9cf183d8c,DISK], DatanodeInfoWithStorage[127.0.0.1:39314,DS-9a12033e-dd09-4d05-a877-df7e149acf55,DISK], DatanodeInfoWithStorage[127.0.0.1:34209,DS-97330435-35b0-427b-87d5-b413fcdaf440,DISK], DatanodeInfoWithStorage[127.0.0.1:45054,DS-4e67825e-30e7-4815-a99b-307b6dac0a8e,DISK], DatanodeInfoWithStorage[127.0.0.1:35688,DS-fc193906-89cb-4e7a-9627-867227692c47,DISK], DatanodeInfoWithStorage[127.0.0.1:37707,DS-47c4d402-87de-49de-9146-fed4d082ebef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-448145815-172.17.0.12-1598354811029:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46189,DS-232b9733-f6e2-49d0-bbbf-56a16efc9932,DISK], DatanodeInfoWithStorage[127.0.0.1:35482,DS-a6e9bf90-245d-45a3-8392-0c52ec5b0b30,DISK], DatanodeInfoWithStorage[127.0.0.1:40243,DS-dc4e307e-a009-4e6a-a240-b9d9cf183d8c,DISK], DatanodeInfoWithStorage[127.0.0.1:39314,DS-9a12033e-dd09-4d05-a877-df7e149acf55,DISK], DatanodeInfoWithStorage[127.0.0.1:34209,DS-97330435-35b0-427b-87d5-b413fcdaf440,DISK], DatanodeInfoWithStorage[127.0.0.1:45054,DS-4e67825e-30e7-4815-a99b-307b6dac0a8e,DISK], DatanodeInfoWithStorage[127.0.0.1:35688,DS-fc193906-89cb-4e7a-9627-867227692c47,DISK], DatanodeInfoWithStorage[127.0.0.1:37707,DS-47c4d402-87de-49de-9146-fed4d082ebef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.ContentSummary.subAccess
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-351703964-172.17.0.12-1598354844364:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43728,DS-67ff3db0-7122-427a-bbe6-0c3fcda186fe,DISK], DatanodeInfoWithStorage[127.0.0.1:42875,DS-43f5b707-95c8-4ebc-af4f-22880837bbc3,DISK], DatanodeInfoWithStorage[127.0.0.1:46463,DS-fce8ec48-d135-4639-a133-c10f548b7dd4,DISK], DatanodeInfoWithStorage[127.0.0.1:37606,DS-09c417f8-d57f-4482-9746-db204eb0bb27,DISK], DatanodeInfoWithStorage[127.0.0.1:33401,DS-7955aae6-2bc4-49ed-b1e8-aefea0ed3fb0,DISK], DatanodeInfoWithStorage[127.0.0.1:45139,DS-01f24c98-d43d-4552-882d-c6f33cde5aa5,DISK], DatanodeInfoWithStorage[127.0.0.1:45971,DS-531f7e7c-ccf0-4564-8205-b289563573fb,DISK], DatanodeInfoWithStorage[127.0.0.1:46242,DS-be2b4f3c-e33d-4f88-8c38-f1e10d147279,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-351703964-172.17.0.12-1598354844364:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43728,DS-67ff3db0-7122-427a-bbe6-0c3fcda186fe,DISK], DatanodeInfoWithStorage[127.0.0.1:42875,DS-43f5b707-95c8-4ebc-af4f-22880837bbc3,DISK], DatanodeInfoWithStorage[127.0.0.1:46463,DS-fce8ec48-d135-4639-a133-c10f548b7dd4,DISK], DatanodeInfoWithStorage[127.0.0.1:37606,DS-09c417f8-d57f-4482-9746-db204eb0bb27,DISK], DatanodeInfoWithStorage[127.0.0.1:33401,DS-7955aae6-2bc4-49ed-b1e8-aefea0ed3fb0,DISK], DatanodeInfoWithStorage[127.0.0.1:45139,DS-01f24c98-d43d-4552-882d-c6f33cde5aa5,DISK], DatanodeInfoWithStorage[127.0.0.1:45971,DS-531f7e7c-ccf0-4564-8205-b289563573fb,DISK], DatanodeInfoWithStorage[127.0.0.1:46242,DS-be2b4f3c-e33d-4f88-8c38-f1e10d147279,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.ContentSummary.subAccess
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1677998902-172.17.0.12-1598354938427:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45221,DS-8e13b3c5-4678-4e0b-b340-3df0a67e791b,DISK], DatanodeInfoWithStorage[127.0.0.1:43446,DS-95ffbee2-ccd5-4e4b-99c5-8c3ff23b5baa,DISK], DatanodeInfoWithStorage[127.0.0.1:45569,DS-9e50dca3-e0e5-4be6-a4e3-bcae522d5262,DISK], DatanodeInfoWithStorage[127.0.0.1:37876,DS-1a3b8c63-b09a-4c2f-8cec-4a80af25bd9a,DISK], DatanodeInfoWithStorage[127.0.0.1:46850,DS-5a6721b5-a86f-41d3-b250-c0eb8a8945c8,DISK], DatanodeInfoWithStorage[127.0.0.1:40671,DS-b4539330-783e-4c42-b962-77a56c586e09,DISK], DatanodeInfoWithStorage[127.0.0.1:38992,DS-ab2b2002-9587-4af2-b46e-0e123b67c04a,DISK], DatanodeInfoWithStorage[127.0.0.1:34405,DS-919c12fb-5925-41b9-82d0-85249842a77c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1677998902-172.17.0.12-1598354938427:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45221,DS-8e13b3c5-4678-4e0b-b340-3df0a67e791b,DISK], DatanodeInfoWithStorage[127.0.0.1:43446,DS-95ffbee2-ccd5-4e4b-99c5-8c3ff23b5baa,DISK], DatanodeInfoWithStorage[127.0.0.1:45569,DS-9e50dca3-e0e5-4be6-a4e3-bcae522d5262,DISK], DatanodeInfoWithStorage[127.0.0.1:37876,DS-1a3b8c63-b09a-4c2f-8cec-4a80af25bd9a,DISK], DatanodeInfoWithStorage[127.0.0.1:46850,DS-5a6721b5-a86f-41d3-b250-c0eb8a8945c8,DISK], DatanodeInfoWithStorage[127.0.0.1:40671,DS-b4539330-783e-4c42-b962-77a56c586e09,DISK], DatanodeInfoWithStorage[127.0.0.1:38992,DS-ab2b2002-9587-4af2-b46e-0e123b67c04a,DISK], DatanodeInfoWithStorage[127.0.0.1:34405,DS-919c12fb-5925-41b9-82d0-85249842a77c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.ContentSummary.subAccess
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1436780489-172.17.0.12-1598355966265:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42818,DS-10aa0d72-9381-40b6-8bd6-313223fa0173,DISK], DatanodeInfoWithStorage[127.0.0.1:37017,DS-7f0de3cd-8086-4c0b-8d01-6c2f6ac053f3,DISK], DatanodeInfoWithStorage[127.0.0.1:33484,DS-4fcac01b-6fd2-4f52-bd50-3e9cace1d40c,DISK], DatanodeInfoWithStorage[127.0.0.1:38066,DS-79bd6b88-38ff-4c9a-be77-b6a69e020cbc,DISK], DatanodeInfoWithStorage[127.0.0.1:41562,DS-54304bfc-0921-4cd9-baa4-3b5b59e5b6bc,DISK], DatanodeInfoWithStorage[127.0.0.1:42177,DS-da33480a-2f20-4806-afac-a2391ebc29a9,DISK], DatanodeInfoWithStorage[127.0.0.1:38831,DS-6e0bf146-6163-4996-b266-0bc2072fbb4c,DISK], DatanodeInfoWithStorage[127.0.0.1:45098,DS-0b81e9d0-1b47-4e2a-aeaf-0f68d6b0a8b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1436780489-172.17.0.12-1598355966265:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42818,DS-10aa0d72-9381-40b6-8bd6-313223fa0173,DISK], DatanodeInfoWithStorage[127.0.0.1:37017,DS-7f0de3cd-8086-4c0b-8d01-6c2f6ac053f3,DISK], DatanodeInfoWithStorage[127.0.0.1:33484,DS-4fcac01b-6fd2-4f52-bd50-3e9cace1d40c,DISK], DatanodeInfoWithStorage[127.0.0.1:38066,DS-79bd6b88-38ff-4c9a-be77-b6a69e020cbc,DISK], DatanodeInfoWithStorage[127.0.0.1:41562,DS-54304bfc-0921-4cd9-baa4-3b5b59e5b6bc,DISK], DatanodeInfoWithStorage[127.0.0.1:42177,DS-da33480a-2f20-4806-afac-a2391ebc29a9,DISK], DatanodeInfoWithStorage[127.0.0.1:38831,DS-6e0bf146-6163-4996-b266-0bc2072fbb4c,DISK], DatanodeInfoWithStorage[127.0.0.1:45098,DS-0b81e9d0-1b47-4e2a-aeaf-0f68d6b0a8b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.ContentSummary.subAccess
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-596151882-172.17.0.12-1598356326136:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36426,DS-46a125fc-1626-4008-974f-eebee11352d3,DISK], DatanodeInfoWithStorage[127.0.0.1:34495,DS-eb8da6d1-f184-4c7d-91e8-fe30de1577f9,DISK], DatanodeInfoWithStorage[127.0.0.1:38556,DS-0b97681c-46a9-4905-8d08-3000c738dba1,DISK], DatanodeInfoWithStorage[127.0.0.1:39840,DS-c7acb931-b822-46bf-b290-2e6d2fc56948,DISK], DatanodeInfoWithStorage[127.0.0.1:46041,DS-2b46c249-e9a8-40b3-a2ff-b842142227b9,DISK], DatanodeInfoWithStorage[127.0.0.1:46251,DS-3c9e853d-7c9e-40a8-9209-6dac93ec54ab,DISK], DatanodeInfoWithStorage[127.0.0.1:35382,DS-42bc7c3a-6edf-4b9a-9c77-4c028eda7bb1,DISK], DatanodeInfoWithStorage[127.0.0.1:33096,DS-c10e1e7f-ec46-45c6-9bdc-0e9615eb8ae9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-596151882-172.17.0.12-1598356326136:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36426,DS-46a125fc-1626-4008-974f-eebee11352d3,DISK], DatanodeInfoWithStorage[127.0.0.1:34495,DS-eb8da6d1-f184-4c7d-91e8-fe30de1577f9,DISK], DatanodeInfoWithStorage[127.0.0.1:38556,DS-0b97681c-46a9-4905-8d08-3000c738dba1,DISK], DatanodeInfoWithStorage[127.0.0.1:39840,DS-c7acb931-b822-46bf-b290-2e6d2fc56948,DISK], DatanodeInfoWithStorage[127.0.0.1:46041,DS-2b46c249-e9a8-40b3-a2ff-b842142227b9,DISK], DatanodeInfoWithStorage[127.0.0.1:46251,DS-3c9e853d-7c9e-40a8-9209-6dac93ec54ab,DISK], DatanodeInfoWithStorage[127.0.0.1:35382,DS-42bc7c3a-6edf-4b9a-9c77-4c028eda7bb1,DISK], DatanodeInfoWithStorage[127.0.0.1:33096,DS-c10e1e7f-ec46-45c6-9bdc-0e9615eb8ae9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.ContentSummary.subAccess
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1707266875-172.17.0.12-1598356978922:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42919,DS-9ec3afac-3e87-4d74-8723-489da147893c,DISK], DatanodeInfoWithStorage[127.0.0.1:44784,DS-d544056d-1285-4a8f-b253-8ab1b12dfbcd,DISK], DatanodeInfoWithStorage[127.0.0.1:43836,DS-8e5e8122-802c-4ca8-bc71-8a332c9433a7,DISK], DatanodeInfoWithStorage[127.0.0.1:37181,DS-7308aac2-c63e-46d3-8058-0e281c9d0622,DISK], DatanodeInfoWithStorage[127.0.0.1:43916,DS-490fbee8-609b-4e96-abe3-16610ae32a65,DISK], DatanodeInfoWithStorage[127.0.0.1:38577,DS-51530625-591c-485a-9f23-1ad998106ebd,DISK], DatanodeInfoWithStorage[127.0.0.1:38494,DS-886128d8-1308-4854-8b0f-349a1f6be377,DISK], DatanodeInfoWithStorage[127.0.0.1:44316,DS-c5bb0990-deb2-416f-8bcb-5ba84cec90f4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1707266875-172.17.0.12-1598356978922:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42919,DS-9ec3afac-3e87-4d74-8723-489da147893c,DISK], DatanodeInfoWithStorage[127.0.0.1:44784,DS-d544056d-1285-4a8f-b253-8ab1b12dfbcd,DISK], DatanodeInfoWithStorage[127.0.0.1:43836,DS-8e5e8122-802c-4ca8-bc71-8a332c9433a7,DISK], DatanodeInfoWithStorage[127.0.0.1:37181,DS-7308aac2-c63e-46d3-8058-0e281c9d0622,DISK], DatanodeInfoWithStorage[127.0.0.1:43916,DS-490fbee8-609b-4e96-abe3-16610ae32a65,DISK], DatanodeInfoWithStorage[127.0.0.1:38577,DS-51530625-591c-485a-9f23-1ad998106ebd,DISK], DatanodeInfoWithStorage[127.0.0.1:38494,DS-886128d8-1308-4854-8b0f-349a1f6be377,DISK], DatanodeInfoWithStorage[127.0.0.1:44316,DS-c5bb0990-deb2-416f-8bcb-5ba84cec90f4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.ContentSummary.subAccess
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-109837378-172.17.0.12-1598357863923:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46300,DS-067129dd-1788-42b8-8cfc-1a8a384f1d60,DISK], DatanodeInfoWithStorage[127.0.0.1:40389,DS-29a60383-ea77-47b5-9b1b-abb6bb1197f7,DISK], DatanodeInfoWithStorage[127.0.0.1:38032,DS-0936a15f-ed07-44a0-bae6-2c62a783ddbb,DISK], DatanodeInfoWithStorage[127.0.0.1:39266,DS-e26fa22b-9b08-4019-9435-26e11190ae66,DISK], DatanodeInfoWithStorage[127.0.0.1:39125,DS-d2cf443a-2832-46f5-b42d-152d87c705b2,DISK], DatanodeInfoWithStorage[127.0.0.1:41369,DS-ed724c66-738a-424d-948c-f1cf1eadbfea,DISK], DatanodeInfoWithStorage[127.0.0.1:39797,DS-479eed35-a1ba-4eec-b281-b39f9e31aba5,DISK], DatanodeInfoWithStorage[127.0.0.1:37994,DS-eb11d648-50c5-40e6-922c-d4e4f3748788,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-109837378-172.17.0.12-1598357863923:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46300,DS-067129dd-1788-42b8-8cfc-1a8a384f1d60,DISK], DatanodeInfoWithStorage[127.0.0.1:40389,DS-29a60383-ea77-47b5-9b1b-abb6bb1197f7,DISK], DatanodeInfoWithStorage[127.0.0.1:38032,DS-0936a15f-ed07-44a0-bae6-2c62a783ddbb,DISK], DatanodeInfoWithStorage[127.0.0.1:39266,DS-e26fa22b-9b08-4019-9435-26e11190ae66,DISK], DatanodeInfoWithStorage[127.0.0.1:39125,DS-d2cf443a-2832-46f5-b42d-152d87c705b2,DISK], DatanodeInfoWithStorage[127.0.0.1:41369,DS-ed724c66-738a-424d-948c-f1cf1eadbfea,DISK], DatanodeInfoWithStorage[127.0.0.1:39797,DS-479eed35-a1ba-4eec-b281-b39f9e31aba5,DISK], DatanodeInfoWithStorage[127.0.0.1:37994,DS-eb11d648-50c5-40e6-922c-d4e4f3748788,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.ContentSummary.subAccess
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-717868326-172.17.0.12-1598358948557:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33593,DS-5713671a-4987-4b08-b793-7efa373cba34,DISK], DatanodeInfoWithStorage[127.0.0.1:38537,DS-f7217cc1-f1d4-4de2-999d-31b0da2bb8bd,DISK], DatanodeInfoWithStorage[127.0.0.1:37554,DS-0ac00ff0-e48c-425f-83d2-dcb439aa94d3,DISK], DatanodeInfoWithStorage[127.0.0.1:37873,DS-2a2fa1a9-9ed7-4cd7-991c-205af6620912,DISK], DatanodeInfoWithStorage[127.0.0.1:35107,DS-29e1284d-1bd4-43f7-98aa-5c3140164526,DISK], DatanodeInfoWithStorage[127.0.0.1:35139,DS-48cfc218-ad57-4862-8ba7-615b5abe0c9b,DISK], DatanodeInfoWithStorage[127.0.0.1:45629,DS-5f3c897e-acbe-44da-8cce-e42e9a8c6fd1,DISK], DatanodeInfoWithStorage[127.0.0.1:33112,DS-bd996a4c-da48-45be-9b55-a6fe96a03102,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-717868326-172.17.0.12-1598358948557:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33593,DS-5713671a-4987-4b08-b793-7efa373cba34,DISK], DatanodeInfoWithStorage[127.0.0.1:38537,DS-f7217cc1-f1d4-4de2-999d-31b0da2bb8bd,DISK], DatanodeInfoWithStorage[127.0.0.1:37554,DS-0ac00ff0-e48c-425f-83d2-dcb439aa94d3,DISK], DatanodeInfoWithStorage[127.0.0.1:37873,DS-2a2fa1a9-9ed7-4cd7-991c-205af6620912,DISK], DatanodeInfoWithStorage[127.0.0.1:35107,DS-29e1284d-1bd4-43f7-98aa-5c3140164526,DISK], DatanodeInfoWithStorage[127.0.0.1:35139,DS-48cfc218-ad57-4862-8ba7-615b5abe0c9b,DISK], DatanodeInfoWithStorage[127.0.0.1:45629,DS-5f3c897e-acbe-44da-8cce-e42e9a8c6fd1,DISK], DatanodeInfoWithStorage[127.0.0.1:33112,DS-bd996a4c-da48-45be-9b55-a6fe96a03102,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 6 out of 50
result: false positive !!!
Total execution time in seconds : 5430
