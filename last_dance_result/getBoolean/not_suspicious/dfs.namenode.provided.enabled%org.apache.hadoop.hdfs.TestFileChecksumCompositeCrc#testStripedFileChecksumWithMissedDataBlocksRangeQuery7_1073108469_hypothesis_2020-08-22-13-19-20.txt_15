reconf_parameter: dfs.namenode.provided.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.provided.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1257136814-172.17.0.16-1598102514894:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37275,DS-2dc45c46-6588-4c10-9969-9a98f2f816be,DISK], DatanodeInfoWithStorage[127.0.0.1:37035,DS-a75d8f96-caa9-45c4-bd1a-dfcb9d8dfe64,DISK], DatanodeInfoWithStorage[127.0.0.1:32961,DS-ac0ed8eb-dca0-478c-a684-4b3fe1988a0d,DISK], DatanodeInfoWithStorage[127.0.0.1:39443,DS-14068c57-6050-465a-be52-fa56c225b2f0,DISK], DatanodeInfoWithStorage[127.0.0.1:44393,DS-5232f88e-0a21-48f1-bafc-a2bcb919e4e0,DISK], DatanodeInfoWithStorage[127.0.0.1:42899,DS-ceafefae-adaf-4780-8d01-8dcf6e187233,DISK], DatanodeInfoWithStorage[127.0.0.1:43547,DS-fa5997d8-ddab-4dce-8fb4-7b4efecc0284,DISK], DatanodeInfoWithStorage[127.0.0.1:40200,DS-b35259ce-0ad2-43de-9280-a8e64f68ca85,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1257136814-172.17.0.16-1598102514894:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37275,DS-2dc45c46-6588-4c10-9969-9a98f2f816be,DISK], DatanodeInfoWithStorage[127.0.0.1:37035,DS-a75d8f96-caa9-45c4-bd1a-dfcb9d8dfe64,DISK], DatanodeInfoWithStorage[127.0.0.1:32961,DS-ac0ed8eb-dca0-478c-a684-4b3fe1988a0d,DISK], DatanodeInfoWithStorage[127.0.0.1:39443,DS-14068c57-6050-465a-be52-fa56c225b2f0,DISK], DatanodeInfoWithStorage[127.0.0.1:44393,DS-5232f88e-0a21-48f1-bafc-a2bcb919e4e0,DISK], DatanodeInfoWithStorage[127.0.0.1:42899,DS-ceafefae-adaf-4780-8d01-8dcf6e187233,DISK], DatanodeInfoWithStorage[127.0.0.1:43547,DS-fa5997d8-ddab-4dce-8fb4-7b4efecc0284,DISK], DatanodeInfoWithStorage[127.0.0.1:40200,DS-b35259ce-0ad2-43de-9280-a8e64f68ca85,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.provided.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-935004823-172.17.0.16-1598102697737:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45963,DS-b5375ed1-4c8d-4acc-97e4-b9bbc82d14d1,DISK], DatanodeInfoWithStorage[127.0.0.1:38019,DS-d3b2b6e6-e020-4230-a6ff-76cdc3dc129a,DISK], DatanodeInfoWithStorage[127.0.0.1:33365,DS-28835112-48ed-48b1-af77-73d98d9e6673,DISK], DatanodeInfoWithStorage[127.0.0.1:35368,DS-2aa5308b-5369-4983-b1c6-9a3f744676e5,DISK], DatanodeInfoWithStorage[127.0.0.1:44585,DS-3ac10595-e1bd-4e60-bc91-b9a612b32dfb,DISK], DatanodeInfoWithStorage[127.0.0.1:38379,DS-2738ec68-44ea-4ffd-8c37-c5f51ec1230a,DISK], DatanodeInfoWithStorage[127.0.0.1:45124,DS-f0361ea6-666e-432e-afc2-2c1e74757f96,DISK], DatanodeInfoWithStorage[127.0.0.1:37832,DS-5dbfec80-9d29-4b81-a8a0-309bd0a101de,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-935004823-172.17.0.16-1598102697737:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45963,DS-b5375ed1-4c8d-4acc-97e4-b9bbc82d14d1,DISK], DatanodeInfoWithStorage[127.0.0.1:38019,DS-d3b2b6e6-e020-4230-a6ff-76cdc3dc129a,DISK], DatanodeInfoWithStorage[127.0.0.1:33365,DS-28835112-48ed-48b1-af77-73d98d9e6673,DISK], DatanodeInfoWithStorage[127.0.0.1:35368,DS-2aa5308b-5369-4983-b1c6-9a3f744676e5,DISK], DatanodeInfoWithStorage[127.0.0.1:44585,DS-3ac10595-e1bd-4e60-bc91-b9a612b32dfb,DISK], DatanodeInfoWithStorage[127.0.0.1:38379,DS-2738ec68-44ea-4ffd-8c37-c5f51ec1230a,DISK], DatanodeInfoWithStorage[127.0.0.1:45124,DS-f0361ea6-666e-432e-afc2-2c1e74757f96,DISK], DatanodeInfoWithStorage[127.0.0.1:37832,DS-5dbfec80-9d29-4b81-a8a0-309bd0a101de,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.provided.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1114829173-172.17.0.16-1598103565281:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37849,DS-829a4479-ae7a-4570-b95a-40612f89d081,DISK], DatanodeInfoWithStorage[127.0.0.1:43652,DS-92bcbeee-26f1-4caf-a0fa-a181e588aebf,DISK], DatanodeInfoWithStorage[127.0.0.1:44031,DS-510d099f-cc9b-45ee-bf6f-e0d91fb5cf86,DISK], DatanodeInfoWithStorage[127.0.0.1:39038,DS-56537139-c5d3-4f45-8145-dfe02caac641,DISK], DatanodeInfoWithStorage[127.0.0.1:37174,DS-34f56b69-d826-4fd7-a703-560afaa2f3ad,DISK], DatanodeInfoWithStorage[127.0.0.1:34619,DS-1599b4f3-be41-432e-b082-004cd491ac9f,DISK], DatanodeInfoWithStorage[127.0.0.1:33583,DS-ea8ad67c-ef01-4737-8be7-fcff9c1115f0,DISK], DatanodeInfoWithStorage[127.0.0.1:41846,DS-b234fe8c-0a6b-4fe8-9831-89bf1a1a1e1e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1114829173-172.17.0.16-1598103565281:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37849,DS-829a4479-ae7a-4570-b95a-40612f89d081,DISK], DatanodeInfoWithStorage[127.0.0.1:43652,DS-92bcbeee-26f1-4caf-a0fa-a181e588aebf,DISK], DatanodeInfoWithStorage[127.0.0.1:44031,DS-510d099f-cc9b-45ee-bf6f-e0d91fb5cf86,DISK], DatanodeInfoWithStorage[127.0.0.1:39038,DS-56537139-c5d3-4f45-8145-dfe02caac641,DISK], DatanodeInfoWithStorage[127.0.0.1:37174,DS-34f56b69-d826-4fd7-a703-560afaa2f3ad,DISK], DatanodeInfoWithStorage[127.0.0.1:34619,DS-1599b4f3-be41-432e-b082-004cd491ac9f,DISK], DatanodeInfoWithStorage[127.0.0.1:33583,DS-ea8ad67c-ef01-4737-8be7-fcff9c1115f0,DISK], DatanodeInfoWithStorage[127.0.0.1:41846,DS-b234fe8c-0a6b-4fe8-9831-89bf1a1a1e1e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.provided.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1695029863-172.17.0.16-1598103796758:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32904,DS-abb12d1e-5ac4-4a39-94b1-b415a6f507a8,DISK], DatanodeInfoWithStorage[127.0.0.1:39823,DS-2f9f3bce-e0da-420b-9737-c4bab657408d,DISK], DatanodeInfoWithStorage[127.0.0.1:40412,DS-1c4e51ce-ba41-41d5-a56f-e292f2ba8a0c,DISK], DatanodeInfoWithStorage[127.0.0.1:44460,DS-4237394a-c631-43b7-bbc0-40b0710e966d,DISK], DatanodeInfoWithStorage[127.0.0.1:46456,DS-803e4966-5818-4bb4-ba5f-7ac7c011ed17,DISK], DatanodeInfoWithStorage[127.0.0.1:41439,DS-b081c463-a0b7-485e-b642-9de727986a0b,DISK], DatanodeInfoWithStorage[127.0.0.1:41919,DS-ebb625c9-c417-493a-8c43-f2dde98bf5c7,DISK], DatanodeInfoWithStorage[127.0.0.1:37867,DS-cb80c7c6-1f2c-42ec-aab0-fe89ad62623d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1695029863-172.17.0.16-1598103796758:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32904,DS-abb12d1e-5ac4-4a39-94b1-b415a6f507a8,DISK], DatanodeInfoWithStorage[127.0.0.1:39823,DS-2f9f3bce-e0da-420b-9737-c4bab657408d,DISK], DatanodeInfoWithStorage[127.0.0.1:40412,DS-1c4e51ce-ba41-41d5-a56f-e292f2ba8a0c,DISK], DatanodeInfoWithStorage[127.0.0.1:44460,DS-4237394a-c631-43b7-bbc0-40b0710e966d,DISK], DatanodeInfoWithStorage[127.0.0.1:46456,DS-803e4966-5818-4bb4-ba5f-7ac7c011ed17,DISK], DatanodeInfoWithStorage[127.0.0.1:41439,DS-b081c463-a0b7-485e-b642-9de727986a0b,DISK], DatanodeInfoWithStorage[127.0.0.1:41919,DS-ebb625c9-c417-493a-8c43-f2dde98bf5c7,DISK], DatanodeInfoWithStorage[127.0.0.1:37867,DS-cb80c7c6-1f2c-42ec-aab0-fe89ad62623d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.provided.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-134337722-172.17.0.16-1598103839604:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39375,DS-89a141e9-d2d0-41aa-909d-f5a6de7000aa,DISK], DatanodeInfoWithStorage[127.0.0.1:46653,DS-69a20885-6b8a-4d30-9156-87835907f0ad,DISK], DatanodeInfoWithStorage[127.0.0.1:36106,DS-5db8efc7-746e-4e54-afd9-75e08b5c7c9c,DISK], DatanodeInfoWithStorage[127.0.0.1:37884,DS-9eedeee4-25a0-4b33-8f70-69617b779dbe,DISK], DatanodeInfoWithStorage[127.0.0.1:45381,DS-41dc4394-40f9-4086-ac3c-c41b916f50da,DISK], DatanodeInfoWithStorage[127.0.0.1:38089,DS-2f44e95a-111d-43d7-b743-c53419244112,DISK], DatanodeInfoWithStorage[127.0.0.1:34314,DS-8e426786-5b2c-4320-a3fe-10a8db4dce96,DISK], DatanodeInfoWithStorage[127.0.0.1:33443,DS-7b9e41b3-3440-4508-9718-adb89432f469,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-134337722-172.17.0.16-1598103839604:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39375,DS-89a141e9-d2d0-41aa-909d-f5a6de7000aa,DISK], DatanodeInfoWithStorage[127.0.0.1:46653,DS-69a20885-6b8a-4d30-9156-87835907f0ad,DISK], DatanodeInfoWithStorage[127.0.0.1:36106,DS-5db8efc7-746e-4e54-afd9-75e08b5c7c9c,DISK], DatanodeInfoWithStorage[127.0.0.1:37884,DS-9eedeee4-25a0-4b33-8f70-69617b779dbe,DISK], DatanodeInfoWithStorage[127.0.0.1:45381,DS-41dc4394-40f9-4086-ac3c-c41b916f50da,DISK], DatanodeInfoWithStorage[127.0.0.1:38089,DS-2f44e95a-111d-43d7-b743-c53419244112,DISK], DatanodeInfoWithStorage[127.0.0.1:34314,DS-8e426786-5b2c-4320-a3fe-10a8db4dce96,DISK], DatanodeInfoWithStorage[127.0.0.1:33443,DS-7b9e41b3-3440-4508-9718-adb89432f469,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.provided.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1561033867-172.17.0.16-1598104179931:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44532,DS-1aae2535-4533-412d-92fa-1022977599bc,DISK], DatanodeInfoWithStorage[127.0.0.1:46151,DS-03111967-b967-4126-9203-69c9de20ce34,DISK], DatanodeInfoWithStorage[127.0.0.1:44436,DS-42f7ae3f-93d3-4160-b968-8dd04bdb3421,DISK], DatanodeInfoWithStorage[127.0.0.1:38929,DS-737f3fb4-5f1e-4305-9292-3851969f9895,DISK], DatanodeInfoWithStorage[127.0.0.1:43193,DS-efa276f2-df1f-4de2-ac1a-c9084a567a38,DISK], DatanodeInfoWithStorage[127.0.0.1:45317,DS-cf7178c6-a06e-4844-bb80-5d138b2f5fd5,DISK], DatanodeInfoWithStorage[127.0.0.1:41645,DS-182d8fe4-7e68-41d0-b669-cb67e1aed576,DISK], DatanodeInfoWithStorage[127.0.0.1:34415,DS-cacb3759-aaa7-4b6a-a997-e79893b94a7b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1561033867-172.17.0.16-1598104179931:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44532,DS-1aae2535-4533-412d-92fa-1022977599bc,DISK], DatanodeInfoWithStorage[127.0.0.1:46151,DS-03111967-b967-4126-9203-69c9de20ce34,DISK], DatanodeInfoWithStorage[127.0.0.1:44436,DS-42f7ae3f-93d3-4160-b968-8dd04bdb3421,DISK], DatanodeInfoWithStorage[127.0.0.1:38929,DS-737f3fb4-5f1e-4305-9292-3851969f9895,DISK], DatanodeInfoWithStorage[127.0.0.1:43193,DS-efa276f2-df1f-4de2-ac1a-c9084a567a38,DISK], DatanodeInfoWithStorage[127.0.0.1:45317,DS-cf7178c6-a06e-4844-bb80-5d138b2f5fd5,DISK], DatanodeInfoWithStorage[127.0.0.1:41645,DS-182d8fe4-7e68-41d0-b669-cb67e1aed576,DISK], DatanodeInfoWithStorage[127.0.0.1:34415,DS-cacb3759-aaa7-4b6a-a997-e79893b94a7b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.provided.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-5069155-172.17.0.16-1598104217612:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38627,DS-9b8398b4-5f6c-46f9-89b0-f74ed7db3a87,DISK], DatanodeInfoWithStorage[127.0.0.1:36295,DS-1fbedebf-44f9-456d-818b-217bdbca3f89,DISK], DatanodeInfoWithStorage[127.0.0.1:45539,DS-a17451f4-32c9-4b5f-8c41-2c63667bc323,DISK], DatanodeInfoWithStorage[127.0.0.1:35703,DS-be6ac5df-9632-4255-acac-bc85ca7f12c7,DISK], DatanodeInfoWithStorage[127.0.0.1:33802,DS-6797926f-3bf0-44a4-bb56-949ae1b9e0b6,DISK], DatanodeInfoWithStorage[127.0.0.1:43677,DS-690f06b2-9c70-4870-953c-382bf35552ae,DISK], DatanodeInfoWithStorage[127.0.0.1:41743,DS-bb498618-9fd5-4ded-82f2-3f82d4dadf88,DISK], DatanodeInfoWithStorage[127.0.0.1:42468,DS-9d0715ce-d588-4897-bc94-c0b3ee61f60e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-5069155-172.17.0.16-1598104217612:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38627,DS-9b8398b4-5f6c-46f9-89b0-f74ed7db3a87,DISK], DatanodeInfoWithStorage[127.0.0.1:36295,DS-1fbedebf-44f9-456d-818b-217bdbca3f89,DISK], DatanodeInfoWithStorage[127.0.0.1:45539,DS-a17451f4-32c9-4b5f-8c41-2c63667bc323,DISK], DatanodeInfoWithStorage[127.0.0.1:35703,DS-be6ac5df-9632-4255-acac-bc85ca7f12c7,DISK], DatanodeInfoWithStorage[127.0.0.1:33802,DS-6797926f-3bf0-44a4-bb56-949ae1b9e0b6,DISK], DatanodeInfoWithStorage[127.0.0.1:43677,DS-690f06b2-9c70-4870-953c-382bf35552ae,DISK], DatanodeInfoWithStorage[127.0.0.1:41743,DS-bb498618-9fd5-4ded-82f2-3f82d4dadf88,DISK], DatanodeInfoWithStorage[127.0.0.1:42468,DS-9d0715ce-d588-4897-bc94-c0b3ee61f60e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.provided.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1818915754-172.17.0.16-1598104263987:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39590,DS-3950fead-baf1-4fde-9ed3-22ef92c595da,DISK], DatanodeInfoWithStorage[127.0.0.1:41692,DS-c2392b0d-95c8-4c0b-aaef-96a339e61f08,DISK], DatanodeInfoWithStorage[127.0.0.1:44595,DS-b0e28981-4fae-4757-9d75-8df970ee8579,DISK], DatanodeInfoWithStorage[127.0.0.1:33771,DS-14ca824e-7b0d-433d-a96e-7dc075615698,DISK], DatanodeInfoWithStorage[127.0.0.1:33220,DS-0e08c4fd-8579-40c9-8ae3-8ae8bc0f82b9,DISK], DatanodeInfoWithStorage[127.0.0.1:43129,DS-5be2527e-6314-446c-bc00-7989298965ab,DISK], DatanodeInfoWithStorage[127.0.0.1:39761,DS-fa56e878-15d4-4c21-9d15-25bc5bbceec4,DISK], DatanodeInfoWithStorage[127.0.0.1:39591,DS-3b6658fa-95f6-4a2e-a604-3f4fbc1768ca,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1818915754-172.17.0.16-1598104263987:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39590,DS-3950fead-baf1-4fde-9ed3-22ef92c595da,DISK], DatanodeInfoWithStorage[127.0.0.1:41692,DS-c2392b0d-95c8-4c0b-aaef-96a339e61f08,DISK], DatanodeInfoWithStorage[127.0.0.1:44595,DS-b0e28981-4fae-4757-9d75-8df970ee8579,DISK], DatanodeInfoWithStorage[127.0.0.1:33771,DS-14ca824e-7b0d-433d-a96e-7dc075615698,DISK], DatanodeInfoWithStorage[127.0.0.1:33220,DS-0e08c4fd-8579-40c9-8ae3-8ae8bc0f82b9,DISK], DatanodeInfoWithStorage[127.0.0.1:43129,DS-5be2527e-6314-446c-bc00-7989298965ab,DISK], DatanodeInfoWithStorage[127.0.0.1:39761,DS-fa56e878-15d4-4c21-9d15-25bc5bbceec4,DISK], DatanodeInfoWithStorage[127.0.0.1:39591,DS-3b6658fa-95f6-4a2e-a604-3f4fbc1768ca,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.provided.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-297460561-172.17.0.16-1598104421526:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34843,DS-3df3b72e-7d6c-4b5c-89be-a5766ad7ddd2,DISK], DatanodeInfoWithStorage[127.0.0.1:42614,DS-9d59073e-ae3f-4cf3-aee0-f444f91fd9bc,DISK], DatanodeInfoWithStorage[127.0.0.1:34381,DS-55ab129a-7b3b-40b3-8e99-0636869a5f05,DISK], DatanodeInfoWithStorage[127.0.0.1:40672,DS-8eee5890-9589-4859-b54f-c25e64f731ce,DISK], DatanodeInfoWithStorage[127.0.0.1:40130,DS-1ec8e376-1d26-4bde-b839-bf75c34f002a,DISK], DatanodeInfoWithStorage[127.0.0.1:40754,DS-8915ac50-89f8-407e-8a9d-286463a5eb1d,DISK], DatanodeInfoWithStorage[127.0.0.1:45229,DS-3ba1a200-3273-44c3-b474-7d707d3094a3,DISK], DatanodeInfoWithStorage[127.0.0.1:41542,DS-67c58d72-ac3f-4882-9b40-fc9b2942701e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-297460561-172.17.0.16-1598104421526:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34843,DS-3df3b72e-7d6c-4b5c-89be-a5766ad7ddd2,DISK], DatanodeInfoWithStorage[127.0.0.1:42614,DS-9d59073e-ae3f-4cf3-aee0-f444f91fd9bc,DISK], DatanodeInfoWithStorage[127.0.0.1:34381,DS-55ab129a-7b3b-40b3-8e99-0636869a5f05,DISK], DatanodeInfoWithStorage[127.0.0.1:40672,DS-8eee5890-9589-4859-b54f-c25e64f731ce,DISK], DatanodeInfoWithStorage[127.0.0.1:40130,DS-1ec8e376-1d26-4bde-b839-bf75c34f002a,DISK], DatanodeInfoWithStorage[127.0.0.1:40754,DS-8915ac50-89f8-407e-8a9d-286463a5eb1d,DISK], DatanodeInfoWithStorage[127.0.0.1:45229,DS-3ba1a200-3273-44c3-b474-7d707d3094a3,DISK], DatanodeInfoWithStorage[127.0.0.1:41542,DS-67c58d72-ac3f-4882-9b40-fc9b2942701e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.provided.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2018840305-172.17.0.16-1598104830468:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41198,DS-f26c997d-a8cc-486e-add2-7c944f438a84,DISK], DatanodeInfoWithStorage[127.0.0.1:46654,DS-900986c5-c139-4799-80c0-d54706acc32e,DISK], DatanodeInfoWithStorage[127.0.0.1:41009,DS-fae6b390-539b-46d4-97cb-5066452c04db,DISK], DatanodeInfoWithStorage[127.0.0.1:33337,DS-6200f4ff-a6ee-424e-b886-34b703ca7b31,DISK], DatanodeInfoWithStorage[127.0.0.1:45318,DS-e324d960-4e8e-49cb-880e-37fb247d8cae,DISK], DatanodeInfoWithStorage[127.0.0.1:36727,DS-d9d79e53-7009-4450-ad9a-f89773e84ff7,DISK], DatanodeInfoWithStorage[127.0.0.1:37808,DS-05491653-59fb-48d1-baa6-848eec846b18,DISK], DatanodeInfoWithStorage[127.0.0.1:42933,DS-eaf659c8-ab44-4348-a73f-c6c313d87b60,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2018840305-172.17.0.16-1598104830468:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41198,DS-f26c997d-a8cc-486e-add2-7c944f438a84,DISK], DatanodeInfoWithStorage[127.0.0.1:46654,DS-900986c5-c139-4799-80c0-d54706acc32e,DISK], DatanodeInfoWithStorage[127.0.0.1:41009,DS-fae6b390-539b-46d4-97cb-5066452c04db,DISK], DatanodeInfoWithStorage[127.0.0.1:33337,DS-6200f4ff-a6ee-424e-b886-34b703ca7b31,DISK], DatanodeInfoWithStorage[127.0.0.1:45318,DS-e324d960-4e8e-49cb-880e-37fb247d8cae,DISK], DatanodeInfoWithStorage[127.0.0.1:36727,DS-d9d79e53-7009-4450-ad9a-f89773e84ff7,DISK], DatanodeInfoWithStorage[127.0.0.1:37808,DS-05491653-59fb-48d1-baa6-848eec846b18,DISK], DatanodeInfoWithStorage[127.0.0.1:42933,DS-eaf659c8-ab44-4348-a73f-c6c313d87b60,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.provided.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-875383363-172.17.0.16-1598104957488:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41596,DS-3f5159af-6823-4c46-b9f9-4c9812801650,DISK], DatanodeInfoWithStorage[127.0.0.1:45260,DS-18732f86-9dad-4e95-9278-b26c94647502,DISK], DatanodeInfoWithStorage[127.0.0.1:34155,DS-aed16bfc-755f-4857-a798-8d81ece1d680,DISK], DatanodeInfoWithStorage[127.0.0.1:36158,DS-0fc4f4b9-6c75-4e63-80df-43b07ba94273,DISK], DatanodeInfoWithStorage[127.0.0.1:33609,DS-73bf453f-d0ed-41ea-aa4b-dec31d5f8399,DISK], DatanodeInfoWithStorage[127.0.0.1:36752,DS-e7cbe156-7102-4f0c-addf-886a26fe47f9,DISK], DatanodeInfoWithStorage[127.0.0.1:33324,DS-9b03e6a1-67aa-4d3a-9403-089316a916e7,DISK], DatanodeInfoWithStorage[127.0.0.1:36851,DS-ea986288-1ac0-4464-bfd2-3cb4273815a0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-875383363-172.17.0.16-1598104957488:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41596,DS-3f5159af-6823-4c46-b9f9-4c9812801650,DISK], DatanodeInfoWithStorage[127.0.0.1:45260,DS-18732f86-9dad-4e95-9278-b26c94647502,DISK], DatanodeInfoWithStorage[127.0.0.1:34155,DS-aed16bfc-755f-4857-a798-8d81ece1d680,DISK], DatanodeInfoWithStorage[127.0.0.1:36158,DS-0fc4f4b9-6c75-4e63-80df-43b07ba94273,DISK], DatanodeInfoWithStorage[127.0.0.1:33609,DS-73bf453f-d0ed-41ea-aa4b-dec31d5f8399,DISK], DatanodeInfoWithStorage[127.0.0.1:36752,DS-e7cbe156-7102-4f0c-addf-886a26fe47f9,DISK], DatanodeInfoWithStorage[127.0.0.1:33324,DS-9b03e6a1-67aa-4d3a-9403-089316a916e7,DISK], DatanodeInfoWithStorage[127.0.0.1:36851,DS-ea986288-1ac0-4464-bfd2-3cb4273815a0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.provided.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-598281374-172.17.0.16-1598105256504:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46076,DS-87e41b41-1109-4675-8d92-8452dae265d4,DISK], DatanodeInfoWithStorage[127.0.0.1:34508,DS-3061e145-2419-49f2-b9a7-292d01f2b9de,DISK], DatanodeInfoWithStorage[127.0.0.1:35020,DS-29c04df2-f123-4a9b-8a4a-df486a3a7089,DISK], DatanodeInfoWithStorage[127.0.0.1:41961,DS-5af68dad-ecae-47f9-92db-026098772879,DISK], DatanodeInfoWithStorage[127.0.0.1:41974,DS-29183eee-9f43-4c75-8e09-2be1137935e4,DISK], DatanodeInfoWithStorage[127.0.0.1:35874,DS-72684ce7-adc6-4c7c-8102-b826826e3f54,DISK], DatanodeInfoWithStorage[127.0.0.1:37915,DS-ea575b76-d7d0-416f-9956-4fc508bfc9c9,DISK], DatanodeInfoWithStorage[127.0.0.1:45250,DS-2aa1273f-7440-49f3-9f8a-18af50a73689,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-598281374-172.17.0.16-1598105256504:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46076,DS-87e41b41-1109-4675-8d92-8452dae265d4,DISK], DatanodeInfoWithStorage[127.0.0.1:34508,DS-3061e145-2419-49f2-b9a7-292d01f2b9de,DISK], DatanodeInfoWithStorage[127.0.0.1:35020,DS-29c04df2-f123-4a9b-8a4a-df486a3a7089,DISK], DatanodeInfoWithStorage[127.0.0.1:41961,DS-5af68dad-ecae-47f9-92db-026098772879,DISK], DatanodeInfoWithStorage[127.0.0.1:41974,DS-29183eee-9f43-4c75-8e09-2be1137935e4,DISK], DatanodeInfoWithStorage[127.0.0.1:35874,DS-72684ce7-adc6-4c7c-8102-b826826e3f54,DISK], DatanodeInfoWithStorage[127.0.0.1:37915,DS-ea575b76-d7d0-416f-9956-4fc508bfc9c9,DISK], DatanodeInfoWithStorage[127.0.0.1:45250,DS-2aa1273f-7440-49f3-9f8a-18af50a73689,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.provided.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1335520426-172.17.0.16-1598105908468:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44623,DS-9c164fff-e3a2-4645-98cb-74265c2c97e5,DISK], DatanodeInfoWithStorage[127.0.0.1:35603,DS-a2034595-de01-45cc-b2ca-bf66bdaa6ae8,DISK], DatanodeInfoWithStorage[127.0.0.1:42132,DS-96c9720c-4575-4a0a-b29b-2790c3325e03,DISK], DatanodeInfoWithStorage[127.0.0.1:46853,DS-d3e710ea-ce87-470d-b75f-225647b3fdde,DISK], DatanodeInfoWithStorage[127.0.0.1:36107,DS-6efc4fa9-08b0-4337-9085-3e672068ca8c,DISK], DatanodeInfoWithStorage[127.0.0.1:41365,DS-d6062fba-4f7f-45fe-ab48-088f5201121e,DISK], DatanodeInfoWithStorage[127.0.0.1:34770,DS-c5a1e746-540e-4033-a97c-c562217df5b8,DISK], DatanodeInfoWithStorage[127.0.0.1:46658,DS-ef707f97-aeb8-487c-9a5e-c242091f29b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1335520426-172.17.0.16-1598105908468:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44623,DS-9c164fff-e3a2-4645-98cb-74265c2c97e5,DISK], DatanodeInfoWithStorage[127.0.0.1:35603,DS-a2034595-de01-45cc-b2ca-bf66bdaa6ae8,DISK], DatanodeInfoWithStorage[127.0.0.1:42132,DS-96c9720c-4575-4a0a-b29b-2790c3325e03,DISK], DatanodeInfoWithStorage[127.0.0.1:46853,DS-d3e710ea-ce87-470d-b75f-225647b3fdde,DISK], DatanodeInfoWithStorage[127.0.0.1:36107,DS-6efc4fa9-08b0-4337-9085-3e672068ca8c,DISK], DatanodeInfoWithStorage[127.0.0.1:41365,DS-d6062fba-4f7f-45fe-ab48-088f5201121e,DISK], DatanodeInfoWithStorage[127.0.0.1:34770,DS-c5a1e746-540e-4033-a97c-c562217df5b8,DISK], DatanodeInfoWithStorage[127.0.0.1:46658,DS-ef707f97-aeb8-487c-9a5e-c242091f29b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.provided.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1617463856-172.17.0.16-1598105959752:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35664,DS-9f26da6e-8755-4559-aa2a-0ec2748cd9dc,DISK], DatanodeInfoWithStorage[127.0.0.1:40693,DS-b2a926ae-3e1c-49e9-aad6-60e779607fbb,DISK], DatanodeInfoWithStorage[127.0.0.1:42768,DS-04d8f956-1c4e-4fee-b177-e1da4d27183b,DISK], DatanodeInfoWithStorage[127.0.0.1:40197,DS-a4c477e0-481b-4f95-a605-57d9cd51d5a7,DISK], DatanodeInfoWithStorage[127.0.0.1:33977,DS-515dc79e-472e-455e-9246-548d6fcaf441,DISK], DatanodeInfoWithStorage[127.0.0.1:39895,DS-88e68ea4-0757-4838-bc28-7fc82bff6bea,DISK], DatanodeInfoWithStorage[127.0.0.1:40811,DS-f1a4c250-e725-4379-8e48-6dc6502db4a8,DISK], DatanodeInfoWithStorage[127.0.0.1:44503,DS-a6cadd25-7812-4fc8-800d-d0f5488d6db3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1617463856-172.17.0.16-1598105959752:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35664,DS-9f26da6e-8755-4559-aa2a-0ec2748cd9dc,DISK], DatanodeInfoWithStorage[127.0.0.1:40693,DS-b2a926ae-3e1c-49e9-aad6-60e779607fbb,DISK], DatanodeInfoWithStorage[127.0.0.1:42768,DS-04d8f956-1c4e-4fee-b177-e1da4d27183b,DISK], DatanodeInfoWithStorage[127.0.0.1:40197,DS-a4c477e0-481b-4f95-a605-57d9cd51d5a7,DISK], DatanodeInfoWithStorage[127.0.0.1:33977,DS-515dc79e-472e-455e-9246-548d6fcaf441,DISK], DatanodeInfoWithStorage[127.0.0.1:39895,DS-88e68ea4-0757-4838-bc28-7fc82bff6bea,DISK], DatanodeInfoWithStorage[127.0.0.1:40811,DS-f1a4c250-e725-4379-8e48-6dc6502db4a8,DISK], DatanodeInfoWithStorage[127.0.0.1:44503,DS-a6cadd25-7812-4fc8-800d-d0f5488d6db3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.provided.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-567539283-172.17.0.16-1598106134584:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38992,DS-f0858328-d3f7-4bc2-bebf-145d243bef59,DISK], DatanodeInfoWithStorage[127.0.0.1:43184,DS-1bf78f2c-3dbf-44ac-9d9a-e380e8c8a565,DISK], DatanodeInfoWithStorage[127.0.0.1:37785,DS-de539f50-9be4-4ab0-88df-72e463043385,DISK], DatanodeInfoWithStorage[127.0.0.1:43848,DS-c384921f-7005-4c82-86bd-3407393a6865,DISK], DatanodeInfoWithStorage[127.0.0.1:38945,DS-8764d28c-d838-4f68-b60a-24144fff97c3,DISK], DatanodeInfoWithStorage[127.0.0.1:39370,DS-e910d5ba-82a1-4533-b0c0-43202e8d058e,DISK], DatanodeInfoWithStorage[127.0.0.1:45966,DS-1e7b55a0-38c6-40e7-b315-ec89304fcb22,DISK], DatanodeInfoWithStorage[127.0.0.1:38821,DS-7419ba9e-52e8-46b1-830e-afb912e6726f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-567539283-172.17.0.16-1598106134584:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38992,DS-f0858328-d3f7-4bc2-bebf-145d243bef59,DISK], DatanodeInfoWithStorage[127.0.0.1:43184,DS-1bf78f2c-3dbf-44ac-9d9a-e380e8c8a565,DISK], DatanodeInfoWithStorage[127.0.0.1:37785,DS-de539f50-9be4-4ab0-88df-72e463043385,DISK], DatanodeInfoWithStorage[127.0.0.1:43848,DS-c384921f-7005-4c82-86bd-3407393a6865,DISK], DatanodeInfoWithStorage[127.0.0.1:38945,DS-8764d28c-d838-4f68-b60a-24144fff97c3,DISK], DatanodeInfoWithStorage[127.0.0.1:39370,DS-e910d5ba-82a1-4533-b0c0-43202e8d058e,DISK], DatanodeInfoWithStorage[127.0.0.1:45966,DS-1e7b55a0-38c6-40e7-b315-ec89304fcb22,DISK], DatanodeInfoWithStorage[127.0.0.1:38821,DS-7419ba9e-52e8-46b1-830e-afb912e6726f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.provided.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-957565547-172.17.0.16-1598106224849:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34481,DS-dace0a80-1b76-4ebb-9905-e8f6d0cb49b8,DISK], DatanodeInfoWithStorage[127.0.0.1:39212,DS-bae9db79-1089-4719-8675-fdddf19e67be,DISK], DatanodeInfoWithStorage[127.0.0.1:42026,DS-7f7127fd-4330-49e9-91bb-d5435b78a1f4,DISK], DatanodeInfoWithStorage[127.0.0.1:35485,DS-96916b04-2d53-408b-98b9-556a488b0938,DISK], DatanodeInfoWithStorage[127.0.0.1:43090,DS-cc6cfbd1-d341-4062-8f95-a45b69bc1f8d,DISK], DatanodeInfoWithStorage[127.0.0.1:40531,DS-f7657266-d2a2-4efe-8a80-c938d73ac46d,DISK], DatanodeInfoWithStorage[127.0.0.1:43435,DS-98023525-68c6-44d5-9d81-ce41d5bc0832,DISK], DatanodeInfoWithStorage[127.0.0.1:41083,DS-3c31a6d9-a4aa-4d7c-b93d-7746b1bdccef,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-957565547-172.17.0.16-1598106224849:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34481,DS-dace0a80-1b76-4ebb-9905-e8f6d0cb49b8,DISK], DatanodeInfoWithStorage[127.0.0.1:39212,DS-bae9db79-1089-4719-8675-fdddf19e67be,DISK], DatanodeInfoWithStorage[127.0.0.1:42026,DS-7f7127fd-4330-49e9-91bb-d5435b78a1f4,DISK], DatanodeInfoWithStorage[127.0.0.1:35485,DS-96916b04-2d53-408b-98b9-556a488b0938,DISK], DatanodeInfoWithStorage[127.0.0.1:43090,DS-cc6cfbd1-d341-4062-8f95-a45b69bc1f8d,DISK], DatanodeInfoWithStorage[127.0.0.1:40531,DS-f7657266-d2a2-4efe-8a80-c938d73ac46d,DISK], DatanodeInfoWithStorage[127.0.0.1:43435,DS-98023525-68c6-44d5-9d81-ce41d5bc0832,DISK], DatanodeInfoWithStorage[127.0.0.1:41083,DS-3c31a6d9-a4aa-4d7c-b93d-7746b1bdccef,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.provided.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1781408859-172.17.0.16-1598106307308:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44252,DS-d8533ae0-0020-4ec9-8ef5-f65d56f613df,DISK], DatanodeInfoWithStorage[127.0.0.1:40752,DS-3cb1afb2-f17d-452c-8dec-516d7465a748,DISK], DatanodeInfoWithStorage[127.0.0.1:39759,DS-3f9c35b5-e298-479a-99a2-35b4dff49adf,DISK], DatanodeInfoWithStorage[127.0.0.1:38129,DS-376957e7-b586-475f-a7d4-4a0c39907e9b,DISK], DatanodeInfoWithStorage[127.0.0.1:42612,DS-8fc6ac03-5a1f-4211-a930-869a7673f0f1,DISK], DatanodeInfoWithStorage[127.0.0.1:35103,DS-db497c1c-e51f-4598-b950-f3b4d194543d,DISK], DatanodeInfoWithStorage[127.0.0.1:42200,DS-2f159eec-b983-4792-a46d-4f246da52d03,DISK], DatanodeInfoWithStorage[127.0.0.1:37331,DS-1d678ce3-3571-4fb8-9107-96d98cabf7b8,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1781408859-172.17.0.16-1598106307308:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44252,DS-d8533ae0-0020-4ec9-8ef5-f65d56f613df,DISK], DatanodeInfoWithStorage[127.0.0.1:40752,DS-3cb1afb2-f17d-452c-8dec-516d7465a748,DISK], DatanodeInfoWithStorage[127.0.0.1:39759,DS-3f9c35b5-e298-479a-99a2-35b4dff49adf,DISK], DatanodeInfoWithStorage[127.0.0.1:38129,DS-376957e7-b586-475f-a7d4-4a0c39907e9b,DISK], DatanodeInfoWithStorage[127.0.0.1:42612,DS-8fc6ac03-5a1f-4211-a930-869a7673f0f1,DISK], DatanodeInfoWithStorage[127.0.0.1:35103,DS-db497c1c-e51f-4598-b950-f3b4d194543d,DISK], DatanodeInfoWithStorage[127.0.0.1:42200,DS-2f159eec-b983-4792-a46d-4f246da52d03,DISK], DatanodeInfoWithStorage[127.0.0.1:37331,DS-1d678ce3-3571-4fb8-9107-96d98cabf7b8,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.provided.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1148302443-172.17.0.16-1598106684881:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39298,DS-dc18ca64-0451-4326-9f31-c8be92e0f646,DISK], DatanodeInfoWithStorage[127.0.0.1:34021,DS-d1eee6ef-f756-4491-a83d-3de55057f07a,DISK], DatanodeInfoWithStorage[127.0.0.1:41167,DS-2105e572-8b07-4aa4-9a45-ae71ea12a4d3,DISK], DatanodeInfoWithStorage[127.0.0.1:40703,DS-2e009c45-9c85-4174-a828-fcd18ee9f6f0,DISK], DatanodeInfoWithStorage[127.0.0.1:40316,DS-03697531-26d1-4317-802b-5c90686e9d91,DISK], DatanodeInfoWithStorage[127.0.0.1:33484,DS-2fa2ca56-e969-4226-8468-49523bd43e46,DISK], DatanodeInfoWithStorage[127.0.0.1:43331,DS-0311219f-4f7d-4a1a-9a44-6691beb845e8,DISK], DatanodeInfoWithStorage[127.0.0.1:38704,DS-78d13cb7-7fff-4f62-9195-1cd07014ca01,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1148302443-172.17.0.16-1598106684881:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39298,DS-dc18ca64-0451-4326-9f31-c8be92e0f646,DISK], DatanodeInfoWithStorage[127.0.0.1:34021,DS-d1eee6ef-f756-4491-a83d-3de55057f07a,DISK], DatanodeInfoWithStorage[127.0.0.1:41167,DS-2105e572-8b07-4aa4-9a45-ae71ea12a4d3,DISK], DatanodeInfoWithStorage[127.0.0.1:40703,DS-2e009c45-9c85-4174-a828-fcd18ee9f6f0,DISK], DatanodeInfoWithStorage[127.0.0.1:40316,DS-03697531-26d1-4317-802b-5c90686e9d91,DISK], DatanodeInfoWithStorage[127.0.0.1:33484,DS-2fa2ca56-e969-4226-8468-49523bd43e46,DISK], DatanodeInfoWithStorage[127.0.0.1:43331,DS-0311219f-4f7d-4a1a-9a44-6691beb845e8,DISK], DatanodeInfoWithStorage[127.0.0.1:38704,DS-78d13cb7-7fff-4f62-9195-1cd07014ca01,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.provided.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1936289848-172.17.0.16-1598106784622:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41043,DS-164b9a23-7b94-4efa-86b3-0a04c0cacd00,DISK], DatanodeInfoWithStorage[127.0.0.1:36498,DS-3047d61d-2331-49c4-8c79-27df204d8b60,DISK], DatanodeInfoWithStorage[127.0.0.1:42788,DS-1bf362dd-7e9b-46f6-b1fb-6eca1804edbc,DISK], DatanodeInfoWithStorage[127.0.0.1:45890,DS-c96e4e1b-50cb-4338-8940-84ac1866a640,DISK], DatanodeInfoWithStorage[127.0.0.1:35087,DS-996783d1-7981-4e6a-9961-1c785969761e,DISK], DatanodeInfoWithStorage[127.0.0.1:45580,DS-cda71f9b-c8f9-4672-a997-c8f2367b62b2,DISK], DatanodeInfoWithStorage[127.0.0.1:45925,DS-e9ee15d3-491e-41af-af04-ce78333ece0e,DISK], DatanodeInfoWithStorage[127.0.0.1:42696,DS-8f853269-8a16-488d-957e-209da9a5e001,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1936289848-172.17.0.16-1598106784622:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41043,DS-164b9a23-7b94-4efa-86b3-0a04c0cacd00,DISK], DatanodeInfoWithStorage[127.0.0.1:36498,DS-3047d61d-2331-49c4-8c79-27df204d8b60,DISK], DatanodeInfoWithStorage[127.0.0.1:42788,DS-1bf362dd-7e9b-46f6-b1fb-6eca1804edbc,DISK], DatanodeInfoWithStorage[127.0.0.1:45890,DS-c96e4e1b-50cb-4338-8940-84ac1866a640,DISK], DatanodeInfoWithStorage[127.0.0.1:35087,DS-996783d1-7981-4e6a-9961-1c785969761e,DISK], DatanodeInfoWithStorage[127.0.0.1:45580,DS-cda71f9b-c8f9-4672-a997-c8f2367b62b2,DISK], DatanodeInfoWithStorage[127.0.0.1:45925,DS-e9ee15d3-491e-41af-af04-ce78333ece0e,DISK], DatanodeInfoWithStorage[127.0.0.1:42696,DS-8f853269-8a16-488d-957e-209da9a5e001,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.provided.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1598450278-172.17.0.16-1598106915869:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41144,DS-af9d36d0-64de-4d86-97be-b4b786db22c5,DISK], DatanodeInfoWithStorage[127.0.0.1:35559,DS-c96eeda0-3c06-46e3-aecb-4befcab13903,DISK], DatanodeInfoWithStorage[127.0.0.1:35234,DS-b631f554-2690-47bf-b605-345e5655e511,DISK], DatanodeInfoWithStorage[127.0.0.1:39147,DS-2cd365fa-8903-400c-a58d-8eeb6b180b9a,DISK], DatanodeInfoWithStorage[127.0.0.1:36682,DS-bc861b40-6360-4248-afe8-a51034df312c,DISK], DatanodeInfoWithStorage[127.0.0.1:35558,DS-5a65ab2f-5130-40b3-ad58-5507a3fde873,DISK], DatanodeInfoWithStorage[127.0.0.1:36736,DS-af69ffc6-da20-4dd4-b21e-a65aca391f4a,DISK], DatanodeInfoWithStorage[127.0.0.1:37109,DS-4908ec2d-5ced-4333-9638-9b1ea9405d12,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1598450278-172.17.0.16-1598106915869:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41144,DS-af9d36d0-64de-4d86-97be-b4b786db22c5,DISK], DatanodeInfoWithStorage[127.0.0.1:35559,DS-c96eeda0-3c06-46e3-aecb-4befcab13903,DISK], DatanodeInfoWithStorage[127.0.0.1:35234,DS-b631f554-2690-47bf-b605-345e5655e511,DISK], DatanodeInfoWithStorage[127.0.0.1:39147,DS-2cd365fa-8903-400c-a58d-8eeb6b180b9a,DISK], DatanodeInfoWithStorage[127.0.0.1:36682,DS-bc861b40-6360-4248-afe8-a51034df312c,DISK], DatanodeInfoWithStorage[127.0.0.1:35558,DS-5a65ab2f-5130-40b3-ad58-5507a3fde873,DISK], DatanodeInfoWithStorage[127.0.0.1:36736,DS-af69ffc6-da20-4dd4-b21e-a65aca391f4a,DISK], DatanodeInfoWithStorage[127.0.0.1:37109,DS-4908ec2d-5ced-4333-9638-9b1ea9405d12,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.provided.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1590391589-172.17.0.16-1598106958915:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44043,DS-1368fc65-58d1-4474-836b-74596e17b002,DISK], DatanodeInfoWithStorage[127.0.0.1:43293,DS-623c334c-2fa0-4f0e-a8f5-5d9e9c2b41fd,DISK], DatanodeInfoWithStorage[127.0.0.1:41381,DS-9a4e8f47-9a2d-406e-b46d-988322e5e54c,DISK], DatanodeInfoWithStorage[127.0.0.1:34153,DS-272dc5ef-f3b7-4788-8089-60381ce52a7f,DISK], DatanodeInfoWithStorage[127.0.0.1:37309,DS-058abc2b-208e-40e0-ad9f-dc4cc2643b52,DISK], DatanodeInfoWithStorage[127.0.0.1:46105,DS-a99e1f3e-c107-4a1c-8e1c-76e595f855b7,DISK], DatanodeInfoWithStorage[127.0.0.1:45238,DS-28d3145c-1c1d-49c7-b572-c9038c291691,DISK], DatanodeInfoWithStorage[127.0.0.1:43899,DS-bbb79412-e53d-44fa-838c-5390249b3fdd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1590391589-172.17.0.16-1598106958915:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44043,DS-1368fc65-58d1-4474-836b-74596e17b002,DISK], DatanodeInfoWithStorage[127.0.0.1:43293,DS-623c334c-2fa0-4f0e-a8f5-5d9e9c2b41fd,DISK], DatanodeInfoWithStorage[127.0.0.1:41381,DS-9a4e8f47-9a2d-406e-b46d-988322e5e54c,DISK], DatanodeInfoWithStorage[127.0.0.1:34153,DS-272dc5ef-f3b7-4788-8089-60381ce52a7f,DISK], DatanodeInfoWithStorage[127.0.0.1:37309,DS-058abc2b-208e-40e0-ad9f-dc4cc2643b52,DISK], DatanodeInfoWithStorage[127.0.0.1:46105,DS-a99e1f3e-c107-4a1c-8e1c-76e595f855b7,DISK], DatanodeInfoWithStorage[127.0.0.1:45238,DS-28d3145c-1c1d-49c7-b572-c9038c291691,DISK], DatanodeInfoWithStorage[127.0.0.1:43899,DS-bbb79412-e53d-44fa-838c-5390249b3fdd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.provided.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1748507114-172.17.0.16-1598107186217:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44966,DS-2d48584e-3b23-4bee-8351-046290785492,DISK], DatanodeInfoWithStorage[127.0.0.1:33397,DS-df6804d6-70e7-44c3-8634-bdd0aed31b03,DISK], DatanodeInfoWithStorage[127.0.0.1:41226,DS-3724b9ab-b8f0-47e4-8b6c-001c2584aafd,DISK], DatanodeInfoWithStorage[127.0.0.1:38804,DS-1784b75c-7fa0-47f7-a40d-cda0bb77ccc8,DISK], DatanodeInfoWithStorage[127.0.0.1:46747,DS-c7ffb203-6ab3-4231-b508-707398dc07df,DISK], DatanodeInfoWithStorage[127.0.0.1:35979,DS-8e989210-0485-48dc-8eb9-9d5a4507d48e,DISK], DatanodeInfoWithStorage[127.0.0.1:35027,DS-aed2df8f-05a2-470a-94e0-931e697a8c05,DISK], DatanodeInfoWithStorage[127.0.0.1:42804,DS-ba051dba-d3ae-41b1-8bc3-46cfd5cb8d47,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1748507114-172.17.0.16-1598107186217:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44966,DS-2d48584e-3b23-4bee-8351-046290785492,DISK], DatanodeInfoWithStorage[127.0.0.1:33397,DS-df6804d6-70e7-44c3-8634-bdd0aed31b03,DISK], DatanodeInfoWithStorage[127.0.0.1:41226,DS-3724b9ab-b8f0-47e4-8b6c-001c2584aafd,DISK], DatanodeInfoWithStorage[127.0.0.1:38804,DS-1784b75c-7fa0-47f7-a40d-cda0bb77ccc8,DISK], DatanodeInfoWithStorage[127.0.0.1:46747,DS-c7ffb203-6ab3-4231-b508-707398dc07df,DISK], DatanodeInfoWithStorage[127.0.0.1:35979,DS-8e989210-0485-48dc-8eb9-9d5a4507d48e,DISK], DatanodeInfoWithStorage[127.0.0.1:35027,DS-aed2df8f-05a2-470a-94e0-931e697a8c05,DISK], DatanodeInfoWithStorage[127.0.0.1:42804,DS-ba051dba-d3ae-41b1-8bc3-46cfd5cb8d47,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.provided.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-427455611-172.17.0.16-1598107235065:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37505,DS-97439493-e47c-4243-81d3-1d1465af84ad,DISK], DatanodeInfoWithStorage[127.0.0.1:43529,DS-272fef5a-c5ab-4433-93f6-3b832506d1d3,DISK], DatanodeInfoWithStorage[127.0.0.1:40220,DS-5102aff1-4bca-4685-8016-8586cfbe17e1,DISK], DatanodeInfoWithStorage[127.0.0.1:33058,DS-2cf9d67c-0eff-48c1-b686-8abf1eb81852,DISK], DatanodeInfoWithStorage[127.0.0.1:38103,DS-7865a497-efaf-4bbd-bda6-d3154231572d,DISK], DatanodeInfoWithStorage[127.0.0.1:45673,DS-5abdc753-6186-478f-9c42-de7bf6f548f1,DISK], DatanodeInfoWithStorage[127.0.0.1:35257,DS-86bf2ca4-9275-4aa8-a931-7dacba7b6731,DISK], DatanodeInfoWithStorage[127.0.0.1:34744,DS-6feea0ae-2973-419f-b188-a063f291fa5c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-427455611-172.17.0.16-1598107235065:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37505,DS-97439493-e47c-4243-81d3-1d1465af84ad,DISK], DatanodeInfoWithStorage[127.0.0.1:43529,DS-272fef5a-c5ab-4433-93f6-3b832506d1d3,DISK], DatanodeInfoWithStorage[127.0.0.1:40220,DS-5102aff1-4bca-4685-8016-8586cfbe17e1,DISK], DatanodeInfoWithStorage[127.0.0.1:33058,DS-2cf9d67c-0eff-48c1-b686-8abf1eb81852,DISK], DatanodeInfoWithStorage[127.0.0.1:38103,DS-7865a497-efaf-4bbd-bda6-d3154231572d,DISK], DatanodeInfoWithStorage[127.0.0.1:45673,DS-5abdc753-6186-478f-9c42-de7bf6f548f1,DISK], DatanodeInfoWithStorage[127.0.0.1:35257,DS-86bf2ca4-9275-4aa8-a931-7dacba7b6731,DISK], DatanodeInfoWithStorage[127.0.0.1:34744,DS-6feea0ae-2973-419f-b188-a063f291fa5c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.provided.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-383788455-172.17.0.16-1598107328122:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34058,DS-07075394-38da-4ecf-acdd-0f6b68230eaf,DISK], DatanodeInfoWithStorage[127.0.0.1:44562,DS-96fd7857-7395-470e-a405-34f756d7d6fe,DISK], DatanodeInfoWithStorage[127.0.0.1:34534,DS-0befd7af-c9f4-43be-8b97-3384a06b105e,DISK], DatanodeInfoWithStorage[127.0.0.1:45830,DS-f9c7f30c-9f30-4f54-ab2d-d0a489d2af30,DISK], DatanodeInfoWithStorage[127.0.0.1:34926,DS-61ec6e23-bc9c-4ce7-8fe2-74aa5cf25c76,DISK], DatanodeInfoWithStorage[127.0.0.1:34713,DS-e4b8b078-f90d-429a-8c06-a68cf7df8263,DISK], DatanodeInfoWithStorage[127.0.0.1:35277,DS-13717f31-02c3-4e38-8bd3-c119bdcc139d,DISK], DatanodeInfoWithStorage[127.0.0.1:38649,DS-15a0b7b4-9834-4101-80a5-14d477d18cf6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-383788455-172.17.0.16-1598107328122:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34058,DS-07075394-38da-4ecf-acdd-0f6b68230eaf,DISK], DatanodeInfoWithStorage[127.0.0.1:44562,DS-96fd7857-7395-470e-a405-34f756d7d6fe,DISK], DatanodeInfoWithStorage[127.0.0.1:34534,DS-0befd7af-c9f4-43be-8b97-3384a06b105e,DISK], DatanodeInfoWithStorage[127.0.0.1:45830,DS-f9c7f30c-9f30-4f54-ab2d-d0a489d2af30,DISK], DatanodeInfoWithStorage[127.0.0.1:34926,DS-61ec6e23-bc9c-4ce7-8fe2-74aa5cf25c76,DISK], DatanodeInfoWithStorage[127.0.0.1:34713,DS-e4b8b078-f90d-429a-8c06-a68cf7df8263,DISK], DatanodeInfoWithStorage[127.0.0.1:35277,DS-13717f31-02c3-4e38-8bd3-c119bdcc139d,DISK], DatanodeInfoWithStorage[127.0.0.1:38649,DS-15a0b7b4-9834-4101-80a5-14d477d18cf6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.provided.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-831155656-172.17.0.16-1598107588124:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40113,DS-1bc388e6-db3d-40c9-bfe1-2aa94fe26fa4,DISK], DatanodeInfoWithStorage[127.0.0.1:45781,DS-2b9b8a72-82de-40f9-af0e-c8e842cf2c47,DISK], DatanodeInfoWithStorage[127.0.0.1:46733,DS-ed32b8a8-95bc-4d7e-b773-ad97b628d652,DISK], DatanodeInfoWithStorage[127.0.0.1:40169,DS-38bb0a0e-dc73-4078-afa6-9aef4c849204,DISK], DatanodeInfoWithStorage[127.0.0.1:35719,DS-b482b90e-25ae-41a1-921f-572c90945d64,DISK], DatanodeInfoWithStorage[127.0.0.1:33761,DS-6fdf9ccc-e067-4060-b393-b09cd02051f5,DISK], DatanodeInfoWithStorage[127.0.0.1:38453,DS-3410eca4-3dc4-4a80-9c79-d02fcf846164,DISK], DatanodeInfoWithStorage[127.0.0.1:40979,DS-943c2eb4-dd9f-4a99-a59d-9befa105ebe3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-831155656-172.17.0.16-1598107588124:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40113,DS-1bc388e6-db3d-40c9-bfe1-2aa94fe26fa4,DISK], DatanodeInfoWithStorage[127.0.0.1:45781,DS-2b9b8a72-82de-40f9-af0e-c8e842cf2c47,DISK], DatanodeInfoWithStorage[127.0.0.1:46733,DS-ed32b8a8-95bc-4d7e-b773-ad97b628d652,DISK], DatanodeInfoWithStorage[127.0.0.1:40169,DS-38bb0a0e-dc73-4078-afa6-9aef4c849204,DISK], DatanodeInfoWithStorage[127.0.0.1:35719,DS-b482b90e-25ae-41a1-921f-572c90945d64,DISK], DatanodeInfoWithStorage[127.0.0.1:33761,DS-6fdf9ccc-e067-4060-b393-b09cd02051f5,DISK], DatanodeInfoWithStorage[127.0.0.1:38453,DS-3410eca4-3dc4-4a80-9c79-d02fcf846164,DISK], DatanodeInfoWithStorage[127.0.0.1:40979,DS-943c2eb4-dd9f-4a99-a59d-9befa105ebe3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.provided.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-305278037-172.17.0.16-1598107728030:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38104,DS-6e5d7370-eeb5-4f7c-ba9c-b5603b28376f,DISK], DatanodeInfoWithStorage[127.0.0.1:35478,DS-aa742c5f-fba2-495b-9c36-25e7628db688,DISK], DatanodeInfoWithStorage[127.0.0.1:33059,DS-ddcf1b85-d90c-47d4-8452-4300f0064c98,DISK], DatanodeInfoWithStorage[127.0.0.1:34005,DS-39eaf6de-c5af-4555-9a81-4ba39b114fe5,DISK], DatanodeInfoWithStorage[127.0.0.1:40556,DS-36e96471-2f96-409c-bd5c-c302f0f3bca2,DISK], DatanodeInfoWithStorage[127.0.0.1:39307,DS-2d8e29cf-5f96-47c0-ab0e-3fd32709ccf3,DISK], DatanodeInfoWithStorage[127.0.0.1:39936,DS-244c141e-f8da-43be-bdb5-de48b43cda44,DISK], DatanodeInfoWithStorage[127.0.0.1:38603,DS-40ab7fa4-0602-4734-9ed5-f72e975ac543,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-305278037-172.17.0.16-1598107728030:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38104,DS-6e5d7370-eeb5-4f7c-ba9c-b5603b28376f,DISK], DatanodeInfoWithStorage[127.0.0.1:35478,DS-aa742c5f-fba2-495b-9c36-25e7628db688,DISK], DatanodeInfoWithStorage[127.0.0.1:33059,DS-ddcf1b85-d90c-47d4-8452-4300f0064c98,DISK], DatanodeInfoWithStorage[127.0.0.1:34005,DS-39eaf6de-c5af-4555-9a81-4ba39b114fe5,DISK], DatanodeInfoWithStorage[127.0.0.1:40556,DS-36e96471-2f96-409c-bd5c-c302f0f3bca2,DISK], DatanodeInfoWithStorage[127.0.0.1:39307,DS-2d8e29cf-5f96-47c0-ab0e-3fd32709ccf3,DISK], DatanodeInfoWithStorage[127.0.0.1:39936,DS-244c141e-f8da-43be-bdb5-de48b43cda44,DISK], DatanodeInfoWithStorage[127.0.0.1:38603,DS-40ab7fa4-0602-4734-9ed5-f72e975ac543,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.provided.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1886006916-172.17.0.16-1598107868875:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44954,DS-9d78b6e6-c6af-479c-b696-099105c885ef,DISK], DatanodeInfoWithStorage[127.0.0.1:45102,DS-e56c5890-5d74-4b25-93da-d14c772f3b11,DISK], DatanodeInfoWithStorage[127.0.0.1:41680,DS-b0332b19-eece-4829-983f-9687d4e781cc,DISK], DatanodeInfoWithStorage[127.0.0.1:45486,DS-928ed98c-c551-41e9-a853-51d490f1f521,DISK], DatanodeInfoWithStorage[127.0.0.1:42919,DS-eebbd191-0b63-41f1-af06-a53734b3cb77,DISK], DatanodeInfoWithStorage[127.0.0.1:43510,DS-0b75ab9d-bf08-4b57-bf1f-aef26a51dd3c,DISK], DatanodeInfoWithStorage[127.0.0.1:33843,DS-6a73c28d-13bd-4744-92a1-621d963c500d,DISK], DatanodeInfoWithStorage[127.0.0.1:37739,DS-a31714ff-d3b4-4d53-8d28-ef2a003b2b3c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1886006916-172.17.0.16-1598107868875:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44954,DS-9d78b6e6-c6af-479c-b696-099105c885ef,DISK], DatanodeInfoWithStorage[127.0.0.1:45102,DS-e56c5890-5d74-4b25-93da-d14c772f3b11,DISK], DatanodeInfoWithStorage[127.0.0.1:41680,DS-b0332b19-eece-4829-983f-9687d4e781cc,DISK], DatanodeInfoWithStorage[127.0.0.1:45486,DS-928ed98c-c551-41e9-a853-51d490f1f521,DISK], DatanodeInfoWithStorage[127.0.0.1:42919,DS-eebbd191-0b63-41f1-af06-a53734b3cb77,DISK], DatanodeInfoWithStorage[127.0.0.1:43510,DS-0b75ab9d-bf08-4b57-bf1f-aef26a51dd3c,DISK], DatanodeInfoWithStorage[127.0.0.1:33843,DS-6a73c28d-13bd-4744-92a1-621d963c500d,DISK], DatanodeInfoWithStorage[127.0.0.1:37739,DS-a31714ff-d3b4-4d53-8d28-ef2a003b2b3c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.provided.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1728479436-172.17.0.16-1598108063330:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41114,DS-63adb6de-206c-499f-b003-0a0b8f03a33f,DISK], DatanodeInfoWithStorage[127.0.0.1:40525,DS-90c9aee5-0fbc-4201-a93f-978d7ef3d582,DISK], DatanodeInfoWithStorage[127.0.0.1:39947,DS-0a781ab0-f236-472b-a750-11ad0acd122c,DISK], DatanodeInfoWithStorage[127.0.0.1:41093,DS-464e23b8-9b3a-4506-a644-273753da1447,DISK], DatanodeInfoWithStorage[127.0.0.1:35330,DS-7cac4d6e-f3b9-4926-b16e-cf07a8a4cf26,DISK], DatanodeInfoWithStorage[127.0.0.1:33000,DS-483695cf-715e-40e5-a964-514df6ac1e48,DISK], DatanodeInfoWithStorage[127.0.0.1:38838,DS-618496b4-17f6-4d6e-92cf-54caf0df74f0,DISK], DatanodeInfoWithStorage[127.0.0.1:33458,DS-7848ccf0-7690-4df7-b6da-0bc1f57979ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1728479436-172.17.0.16-1598108063330:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41114,DS-63adb6de-206c-499f-b003-0a0b8f03a33f,DISK], DatanodeInfoWithStorage[127.0.0.1:40525,DS-90c9aee5-0fbc-4201-a93f-978d7ef3d582,DISK], DatanodeInfoWithStorage[127.0.0.1:39947,DS-0a781ab0-f236-472b-a750-11ad0acd122c,DISK], DatanodeInfoWithStorage[127.0.0.1:41093,DS-464e23b8-9b3a-4506-a644-273753da1447,DISK], DatanodeInfoWithStorage[127.0.0.1:35330,DS-7cac4d6e-f3b9-4926-b16e-cf07a8a4cf26,DISK], DatanodeInfoWithStorage[127.0.0.1:33000,DS-483695cf-715e-40e5-a964-514df6ac1e48,DISK], DatanodeInfoWithStorage[127.0.0.1:38838,DS-618496b4-17f6-4d6e-92cf-54caf0df74f0,DISK], DatanodeInfoWithStorage[127.0.0.1:33458,DS-7848ccf0-7690-4df7-b6da-0bc1f57979ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.provided.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-669949945-172.17.0.16-1598108859488:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46826,DS-94a83de2-43c2-4002-a5ab-4632f2c471ef,DISK], DatanodeInfoWithStorage[127.0.0.1:41247,DS-840d4839-b929-43d6-baf6-2379ac7b2851,DISK], DatanodeInfoWithStorage[127.0.0.1:40819,DS-9aa30585-e3aa-4b35-b12a-238a6fbbcbc9,DISK], DatanodeInfoWithStorage[127.0.0.1:33377,DS-3f34a89d-636c-422d-8b10-7acd98861895,DISK], DatanodeInfoWithStorage[127.0.0.1:35810,DS-8bd434f7-59d4-4e33-b17d-ed3ac2f233c4,DISK], DatanodeInfoWithStorage[127.0.0.1:35109,DS-d5d362d1-ec3e-454c-9702-726b2f887e40,DISK], DatanodeInfoWithStorage[127.0.0.1:36473,DS-60aa19d9-5299-4cdf-88e8-7d34e39e52cf,DISK], DatanodeInfoWithStorage[127.0.0.1:45664,DS-139c001a-ebae-4709-bb13-6f3222360178,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-669949945-172.17.0.16-1598108859488:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46826,DS-94a83de2-43c2-4002-a5ab-4632f2c471ef,DISK], DatanodeInfoWithStorage[127.0.0.1:41247,DS-840d4839-b929-43d6-baf6-2379ac7b2851,DISK], DatanodeInfoWithStorage[127.0.0.1:40819,DS-9aa30585-e3aa-4b35-b12a-238a6fbbcbc9,DISK], DatanodeInfoWithStorage[127.0.0.1:33377,DS-3f34a89d-636c-422d-8b10-7acd98861895,DISK], DatanodeInfoWithStorage[127.0.0.1:35810,DS-8bd434f7-59d4-4e33-b17d-ed3ac2f233c4,DISK], DatanodeInfoWithStorage[127.0.0.1:35109,DS-d5d362d1-ec3e-454c-9702-726b2f887e40,DISK], DatanodeInfoWithStorage[127.0.0.1:36473,DS-60aa19d9-5299-4cdf-88e8-7d34e39e52cf,DISK], DatanodeInfoWithStorage[127.0.0.1:45664,DS-139c001a-ebae-4709-bb13-6f3222360178,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.provided.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1145809433-172.17.0.16-1598108951547:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40743,DS-ff05a4b5-56c0-47e7-9661-55d1b064c8d7,DISK], DatanodeInfoWithStorage[127.0.0.1:40567,DS-2ed3a27a-d6fd-45f8-a20c-f9ccb0a55a3a,DISK], DatanodeInfoWithStorage[127.0.0.1:46664,DS-b5e1937f-e115-4811-a88f-4f251a509e45,DISK], DatanodeInfoWithStorage[127.0.0.1:46617,DS-3ae453ff-5d4a-4e6e-8bf1-12ac1fed72de,DISK], DatanodeInfoWithStorage[127.0.0.1:46469,DS-4b06f428-4403-4937-b389-bae0b9e1f1ca,DISK], DatanodeInfoWithStorage[127.0.0.1:35049,DS-364bef70-073e-4675-ba47-f03400a280b1,DISK], DatanodeInfoWithStorage[127.0.0.1:35597,DS-a34a60a6-d63d-4c1e-afd0-da7e7aca9ee1,DISK], DatanodeInfoWithStorage[127.0.0.1:44685,DS-82f0499f-9f73-47fb-942e-07f73c1edb37,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1145809433-172.17.0.16-1598108951547:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40743,DS-ff05a4b5-56c0-47e7-9661-55d1b064c8d7,DISK], DatanodeInfoWithStorage[127.0.0.1:40567,DS-2ed3a27a-d6fd-45f8-a20c-f9ccb0a55a3a,DISK], DatanodeInfoWithStorage[127.0.0.1:46664,DS-b5e1937f-e115-4811-a88f-4f251a509e45,DISK], DatanodeInfoWithStorage[127.0.0.1:46617,DS-3ae453ff-5d4a-4e6e-8bf1-12ac1fed72de,DISK], DatanodeInfoWithStorage[127.0.0.1:46469,DS-4b06f428-4403-4937-b389-bae0b9e1f1ca,DISK], DatanodeInfoWithStorage[127.0.0.1:35049,DS-364bef70-073e-4675-ba47-f03400a280b1,DISK], DatanodeInfoWithStorage[127.0.0.1:35597,DS-a34a60a6-d63d-4c1e-afd0-da7e7aca9ee1,DISK], DatanodeInfoWithStorage[127.0.0.1:44685,DS-82f0499f-9f73-47fb-942e-07f73c1edb37,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 10 out of 50
v1v1v2v2 failed with probability 17 out of 50
result: false positive !!!
Total execution time in seconds : 6887
