reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-429931407-172.17.0.10-1598186059638:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42576,DS-2e7bb26a-d19a-4154-8d28-fbceb423119a,DISK], DatanodeInfoWithStorage[127.0.0.1:41080,DS-bd38e32e-8c3d-4717-a742-df6c2dde8184,DISK], DatanodeInfoWithStorage[127.0.0.1:36326,DS-5d6b2c34-0009-4163-bdc3-274cdf5dd078,DISK], DatanodeInfoWithStorage[127.0.0.1:45920,DS-838ad31a-dcc2-42be-9b13-e642b5850e48,DISK], DatanodeInfoWithStorage[127.0.0.1:46504,DS-4260ce98-8ae7-4b7c-98a9-9cf5b653ab41,DISK], DatanodeInfoWithStorage[127.0.0.1:46793,DS-6f8b4aa1-2205-4dca-becc-2ab94882b9e4,DISK], DatanodeInfoWithStorage[127.0.0.1:38970,DS-9e909ab1-ea4e-4f4a-84bb-884211259a05,DISK], DatanodeInfoWithStorage[127.0.0.1:38306,DS-3c217108-cf6c-4529-a1b3-66472e7f9501,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-429931407-172.17.0.10-1598186059638:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42576,DS-2e7bb26a-d19a-4154-8d28-fbceb423119a,DISK], DatanodeInfoWithStorage[127.0.0.1:41080,DS-bd38e32e-8c3d-4717-a742-df6c2dde8184,DISK], DatanodeInfoWithStorage[127.0.0.1:36326,DS-5d6b2c34-0009-4163-bdc3-274cdf5dd078,DISK], DatanodeInfoWithStorage[127.0.0.1:45920,DS-838ad31a-dcc2-42be-9b13-e642b5850e48,DISK], DatanodeInfoWithStorage[127.0.0.1:46504,DS-4260ce98-8ae7-4b7c-98a9-9cf5b653ab41,DISK], DatanodeInfoWithStorage[127.0.0.1:46793,DS-6f8b4aa1-2205-4dca-becc-2ab94882b9e4,DISK], DatanodeInfoWithStorage[127.0.0.1:38970,DS-9e909ab1-ea4e-4f4a-84bb-884211259a05,DISK], DatanodeInfoWithStorage[127.0.0.1:38306,DS-3c217108-cf6c-4529-a1b3-66472e7f9501,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2082601085-172.17.0.10-1598186249020:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43496,DS-25ddb946-246c-48f2-bb51-8873d07725b5,DISK], DatanodeInfoWithStorage[127.0.0.1:37858,DS-74cef373-0c7a-4645-8fc5-528150563dcb,DISK], DatanodeInfoWithStorage[127.0.0.1:44744,DS-09685e25-e90b-4e50-8cde-0b7a5d9f3ba3,DISK], DatanodeInfoWithStorage[127.0.0.1:43917,DS-dee58626-ee9e-48cf-bc14-dd34aa01f5c9,DISK], DatanodeInfoWithStorage[127.0.0.1:44184,DS-647b8d9c-4131-4dfc-9b60-658c04c54b06,DISK], DatanodeInfoWithStorage[127.0.0.1:43544,DS-3bd2630e-c01c-4bc0-8808-972edd981dff,DISK], DatanodeInfoWithStorage[127.0.0.1:44774,DS-c368185a-60bc-4f60-b87b-6ebcbe45e895,DISK], DatanodeInfoWithStorage[127.0.0.1:44575,DS-3753c873-094e-4287-bc43-a8afb605de1c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2082601085-172.17.0.10-1598186249020:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43496,DS-25ddb946-246c-48f2-bb51-8873d07725b5,DISK], DatanodeInfoWithStorage[127.0.0.1:37858,DS-74cef373-0c7a-4645-8fc5-528150563dcb,DISK], DatanodeInfoWithStorage[127.0.0.1:44744,DS-09685e25-e90b-4e50-8cde-0b7a5d9f3ba3,DISK], DatanodeInfoWithStorage[127.0.0.1:43917,DS-dee58626-ee9e-48cf-bc14-dd34aa01f5c9,DISK], DatanodeInfoWithStorage[127.0.0.1:44184,DS-647b8d9c-4131-4dfc-9b60-658c04c54b06,DISK], DatanodeInfoWithStorage[127.0.0.1:43544,DS-3bd2630e-c01c-4bc0-8808-972edd981dff,DISK], DatanodeInfoWithStorage[127.0.0.1:44774,DS-c368185a-60bc-4f60-b87b-6ebcbe45e895,DISK], DatanodeInfoWithStorage[127.0.0.1:44575,DS-3753c873-094e-4287-bc43-a8afb605de1c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1379574785-172.17.0.10-1598186709757:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34741,DS-fb577b31-42ea-42e1-9b0b-d2a1b1bde766,DISK], DatanodeInfoWithStorage[127.0.0.1:40914,DS-a4aec004-de25-422c-84aa-96f365e32710,DISK], DatanodeInfoWithStorage[127.0.0.1:40923,DS-cfee52c0-648b-4370-89af-b7cd78b68923,DISK], DatanodeInfoWithStorage[127.0.0.1:45729,DS-20cd7279-bfbc-448b-ac2d-e085dfaf98d4,DISK], DatanodeInfoWithStorage[127.0.0.1:45595,DS-cd9b40ac-3d95-4340-974c-e74f19aee1d1,DISK], DatanodeInfoWithStorage[127.0.0.1:37931,DS-cb8e99d0-0b9a-42d8-a391-fcc03d4d2301,DISK], DatanodeInfoWithStorage[127.0.0.1:39834,DS-055112c6-4b07-4374-837f-bc2cc4f931ee,DISK], DatanodeInfoWithStorage[127.0.0.1:40135,DS-dc9d0ae9-7d33-40de-8f33-3cb3173d5adb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1379574785-172.17.0.10-1598186709757:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34741,DS-fb577b31-42ea-42e1-9b0b-d2a1b1bde766,DISK], DatanodeInfoWithStorage[127.0.0.1:40914,DS-a4aec004-de25-422c-84aa-96f365e32710,DISK], DatanodeInfoWithStorage[127.0.0.1:40923,DS-cfee52c0-648b-4370-89af-b7cd78b68923,DISK], DatanodeInfoWithStorage[127.0.0.1:45729,DS-20cd7279-bfbc-448b-ac2d-e085dfaf98d4,DISK], DatanodeInfoWithStorage[127.0.0.1:45595,DS-cd9b40ac-3d95-4340-974c-e74f19aee1d1,DISK], DatanodeInfoWithStorage[127.0.0.1:37931,DS-cb8e99d0-0b9a-42d8-a391-fcc03d4d2301,DISK], DatanodeInfoWithStorage[127.0.0.1:39834,DS-055112c6-4b07-4374-837f-bc2cc4f931ee,DISK], DatanodeInfoWithStorage[127.0.0.1:40135,DS-dc9d0ae9-7d33-40de-8f33-3cb3173d5adb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2139752118-172.17.0.10-1598186934823:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37643,DS-90c3008e-30a2-4c0e-8891-c9ef909d4633,DISK], DatanodeInfoWithStorage[127.0.0.1:44754,DS-3199cfd7-6484-4d6b-9dcf-450ae8e6dd87,DISK], DatanodeInfoWithStorage[127.0.0.1:37695,DS-51012cdd-a339-401f-9628-9dfad3e399ac,DISK], DatanodeInfoWithStorage[127.0.0.1:36462,DS-a17c048d-6fff-47dc-89f7-3d7423e3ddf1,DISK], DatanodeInfoWithStorage[127.0.0.1:45732,DS-705279da-b640-4a0a-ad91-605197c4beb7,DISK], DatanodeInfoWithStorage[127.0.0.1:40738,DS-bab29bbc-b686-4992-bd63-b98f0944a0c9,DISK], DatanodeInfoWithStorage[127.0.0.1:34982,DS-823890e5-bb1b-41fe-8408-cb20c09cfdad,DISK], DatanodeInfoWithStorage[127.0.0.1:42307,DS-3b8c538c-2caa-4c24-bc7b-e96fba3c6be7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2139752118-172.17.0.10-1598186934823:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37643,DS-90c3008e-30a2-4c0e-8891-c9ef909d4633,DISK], DatanodeInfoWithStorage[127.0.0.1:44754,DS-3199cfd7-6484-4d6b-9dcf-450ae8e6dd87,DISK], DatanodeInfoWithStorage[127.0.0.1:37695,DS-51012cdd-a339-401f-9628-9dfad3e399ac,DISK], DatanodeInfoWithStorage[127.0.0.1:36462,DS-a17c048d-6fff-47dc-89f7-3d7423e3ddf1,DISK], DatanodeInfoWithStorage[127.0.0.1:45732,DS-705279da-b640-4a0a-ad91-605197c4beb7,DISK], DatanodeInfoWithStorage[127.0.0.1:40738,DS-bab29bbc-b686-4992-bd63-b98f0944a0c9,DISK], DatanodeInfoWithStorage[127.0.0.1:34982,DS-823890e5-bb1b-41fe-8408-cb20c09cfdad,DISK], DatanodeInfoWithStorage[127.0.0.1:42307,DS-3b8c538c-2caa-4c24-bc7b-e96fba3c6be7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-407742209-172.17.0.10-1598187440922:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35156,DS-99314bbd-9de0-467e-9684-2139a7282835,DISK], DatanodeInfoWithStorage[127.0.0.1:41077,DS-d81b4deb-3a5f-4a15-9203-6721f28c95f2,DISK], DatanodeInfoWithStorage[127.0.0.1:42276,DS-81ba2c5f-9f39-4b4f-b31b-ad0a60ecd18a,DISK], DatanodeInfoWithStorage[127.0.0.1:36207,DS-07bd26dc-db73-48b2-9ac0-ba514a4aedf5,DISK], DatanodeInfoWithStorage[127.0.0.1:45985,DS-d586fb5c-c621-4235-9c68-d585e83d1c6d,DISK], DatanodeInfoWithStorage[127.0.0.1:35063,DS-45f458a1-de2d-401e-92dc-8a4b3df79630,DISK], DatanodeInfoWithStorage[127.0.0.1:36737,DS-6e585959-16b3-4a39-a1c7-2aacae3a24b7,DISK], DatanodeInfoWithStorage[127.0.0.1:33882,DS-d3a3e2d7-cd0c-4203-b838-043a3f243fe0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-407742209-172.17.0.10-1598187440922:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35156,DS-99314bbd-9de0-467e-9684-2139a7282835,DISK], DatanodeInfoWithStorage[127.0.0.1:41077,DS-d81b4deb-3a5f-4a15-9203-6721f28c95f2,DISK], DatanodeInfoWithStorage[127.0.0.1:42276,DS-81ba2c5f-9f39-4b4f-b31b-ad0a60ecd18a,DISK], DatanodeInfoWithStorage[127.0.0.1:36207,DS-07bd26dc-db73-48b2-9ac0-ba514a4aedf5,DISK], DatanodeInfoWithStorage[127.0.0.1:45985,DS-d586fb5c-c621-4235-9c68-d585e83d1c6d,DISK], DatanodeInfoWithStorage[127.0.0.1:35063,DS-45f458a1-de2d-401e-92dc-8a4b3df79630,DISK], DatanodeInfoWithStorage[127.0.0.1:36737,DS-6e585959-16b3-4a39-a1c7-2aacae3a24b7,DISK], DatanodeInfoWithStorage[127.0.0.1:33882,DS-d3a3e2d7-cd0c-4203-b838-043a3f243fe0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1194655436-172.17.0.10-1598187471282:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41218,DS-3e1fef46-2203-4c2a-b37d-0fb9b0081c47,DISK], DatanodeInfoWithStorage[127.0.0.1:42162,DS-32f7336c-279e-4102-a108-11a8af828697,DISK], DatanodeInfoWithStorage[127.0.0.1:37362,DS-f0c29bda-aa33-4cc4-99f7-fdc1761eab49,DISK], DatanodeInfoWithStorage[127.0.0.1:35201,DS-0cdd7db9-1c99-473c-87e0-a87b6b0bc561,DISK], DatanodeInfoWithStorage[127.0.0.1:38919,DS-1ecdcba6-e327-4fa2-aaaf-e9e52faca3f6,DISK], DatanodeInfoWithStorage[127.0.0.1:33356,DS-820c3935-924e-4e4b-a7e3-cbaa99c98ffc,DISK], DatanodeInfoWithStorage[127.0.0.1:37326,DS-d41b46a6-a83c-4c53-8dda-7fe785ca413b,DISK], DatanodeInfoWithStorage[127.0.0.1:42485,DS-8a2aa9df-f646-4a7e-83e8-68c1118b763d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1194655436-172.17.0.10-1598187471282:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41218,DS-3e1fef46-2203-4c2a-b37d-0fb9b0081c47,DISK], DatanodeInfoWithStorage[127.0.0.1:42162,DS-32f7336c-279e-4102-a108-11a8af828697,DISK], DatanodeInfoWithStorage[127.0.0.1:37362,DS-f0c29bda-aa33-4cc4-99f7-fdc1761eab49,DISK], DatanodeInfoWithStorage[127.0.0.1:35201,DS-0cdd7db9-1c99-473c-87e0-a87b6b0bc561,DISK], DatanodeInfoWithStorage[127.0.0.1:38919,DS-1ecdcba6-e327-4fa2-aaaf-e9e52faca3f6,DISK], DatanodeInfoWithStorage[127.0.0.1:33356,DS-820c3935-924e-4e4b-a7e3-cbaa99c98ffc,DISK], DatanodeInfoWithStorage[127.0.0.1:37326,DS-d41b46a6-a83c-4c53-8dda-7fe785ca413b,DISK], DatanodeInfoWithStorage[127.0.0.1:42485,DS-8a2aa9df-f646-4a7e-83e8-68c1118b763d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2113182151-172.17.0.10-1598187607113:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42368,DS-f6ffa760-c8c3-40b5-a235-53ef97d05ba0,DISK], DatanodeInfoWithStorage[127.0.0.1:37964,DS-21f9cea0-4e24-4c00-92ff-3ffb97eef6c4,DISK], DatanodeInfoWithStorage[127.0.0.1:38567,DS-1ad006d5-c929-4f55-838f-89d05d32117b,DISK], DatanodeInfoWithStorage[127.0.0.1:43782,DS-c64766a8-54f6-4751-82a2-876720b98e7b,DISK], DatanodeInfoWithStorage[127.0.0.1:38576,DS-f98229fc-2f99-4dd6-a90c-e5362cad66ad,DISK], DatanodeInfoWithStorage[127.0.0.1:35663,DS-7b47a054-529c-4e16-b5fb-cacd1bbd9610,DISK], DatanodeInfoWithStorage[127.0.0.1:36192,DS-3612ab91-aa1d-412b-b320-d4df852c3d1a,DISK], DatanodeInfoWithStorage[127.0.0.1:40767,DS-cacc15bf-11a2-4c32-870f-c0d4624e7f2f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2113182151-172.17.0.10-1598187607113:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42368,DS-f6ffa760-c8c3-40b5-a235-53ef97d05ba0,DISK], DatanodeInfoWithStorage[127.0.0.1:37964,DS-21f9cea0-4e24-4c00-92ff-3ffb97eef6c4,DISK], DatanodeInfoWithStorage[127.0.0.1:38567,DS-1ad006d5-c929-4f55-838f-89d05d32117b,DISK], DatanodeInfoWithStorage[127.0.0.1:43782,DS-c64766a8-54f6-4751-82a2-876720b98e7b,DISK], DatanodeInfoWithStorage[127.0.0.1:38576,DS-f98229fc-2f99-4dd6-a90c-e5362cad66ad,DISK], DatanodeInfoWithStorage[127.0.0.1:35663,DS-7b47a054-529c-4e16-b5fb-cacd1bbd9610,DISK], DatanodeInfoWithStorage[127.0.0.1:36192,DS-3612ab91-aa1d-412b-b320-d4df852c3d1a,DISK], DatanodeInfoWithStorage[127.0.0.1:40767,DS-cacc15bf-11a2-4c32-870f-c0d4624e7f2f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-926998143-172.17.0.10-1598188273734:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46263,DS-8f1d77b2-e000-43d4-8f42-6587e832bcb8,DISK], DatanodeInfoWithStorage[127.0.0.1:41501,DS-52c3afde-54dc-4d1c-a8a8-c05e2d89a0d5,DISK], DatanodeInfoWithStorage[127.0.0.1:36912,DS-d630f402-2ee6-453b-82f7-939cb35c9c75,DISK], DatanodeInfoWithStorage[127.0.0.1:45473,DS-65baf8ee-b6f0-4bee-a167-d215a03e3eab,DISK], DatanodeInfoWithStorage[127.0.0.1:42700,DS-7d5f9a42-3f86-46e2-9023-9a847972dc07,DISK], DatanodeInfoWithStorage[127.0.0.1:35034,DS-7ee16eda-ca02-42a1-8a96-00cf81534e5e,DISK], DatanodeInfoWithStorage[127.0.0.1:33257,DS-c0c49737-a8b9-4612-8f76-5a959b7c1e90,DISK], DatanodeInfoWithStorage[127.0.0.1:38247,DS-7ee2e5a1-6261-4772-abb3-90457ad0d046,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-926998143-172.17.0.10-1598188273734:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46263,DS-8f1d77b2-e000-43d4-8f42-6587e832bcb8,DISK], DatanodeInfoWithStorage[127.0.0.1:41501,DS-52c3afde-54dc-4d1c-a8a8-c05e2d89a0d5,DISK], DatanodeInfoWithStorage[127.0.0.1:36912,DS-d630f402-2ee6-453b-82f7-939cb35c9c75,DISK], DatanodeInfoWithStorage[127.0.0.1:45473,DS-65baf8ee-b6f0-4bee-a167-d215a03e3eab,DISK], DatanodeInfoWithStorage[127.0.0.1:42700,DS-7d5f9a42-3f86-46e2-9023-9a847972dc07,DISK], DatanodeInfoWithStorage[127.0.0.1:35034,DS-7ee16eda-ca02-42a1-8a96-00cf81534e5e,DISK], DatanodeInfoWithStorage[127.0.0.1:33257,DS-c0c49737-a8b9-4612-8f76-5a959b7c1e90,DISK], DatanodeInfoWithStorage[127.0.0.1:38247,DS-7ee2e5a1-6261-4772-abb3-90457ad0d046,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-24694496-172.17.0.10-1598188337558:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37531,DS-21d8dfb0-b28a-4b75-b2e8-56a557bcbc0a,DISK], DatanodeInfoWithStorage[127.0.0.1:44333,DS-c0dcbdbf-b0dc-42de-aa47-7a3ddce51de6,DISK], DatanodeInfoWithStorage[127.0.0.1:43086,DS-d41abb55-05d7-412c-8ce3-1953b8fedc10,DISK], DatanodeInfoWithStorage[127.0.0.1:44057,DS-ced774e1-6b73-4286-817a-ba52a4ba7418,DISK], DatanodeInfoWithStorage[127.0.0.1:34232,DS-92c6935b-ca8a-43ae-be73-765536a1167d,DISK], DatanodeInfoWithStorage[127.0.0.1:36397,DS-270c40cd-55d2-4ab8-a105-8604b313cf5c,DISK], DatanodeInfoWithStorage[127.0.0.1:39798,DS-74d5f64f-e0fe-4c11-9fce-992460f3601b,DISK], DatanodeInfoWithStorage[127.0.0.1:38699,DS-5fd60582-20c9-4ab6-be24-6e1ce9af4b34,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-24694496-172.17.0.10-1598188337558:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37531,DS-21d8dfb0-b28a-4b75-b2e8-56a557bcbc0a,DISK], DatanodeInfoWithStorage[127.0.0.1:44333,DS-c0dcbdbf-b0dc-42de-aa47-7a3ddce51de6,DISK], DatanodeInfoWithStorage[127.0.0.1:43086,DS-d41abb55-05d7-412c-8ce3-1953b8fedc10,DISK], DatanodeInfoWithStorage[127.0.0.1:44057,DS-ced774e1-6b73-4286-817a-ba52a4ba7418,DISK], DatanodeInfoWithStorage[127.0.0.1:34232,DS-92c6935b-ca8a-43ae-be73-765536a1167d,DISK], DatanodeInfoWithStorage[127.0.0.1:36397,DS-270c40cd-55d2-4ab8-a105-8604b313cf5c,DISK], DatanodeInfoWithStorage[127.0.0.1:39798,DS-74d5f64f-e0fe-4c11-9fce-992460f3601b,DISK], DatanodeInfoWithStorage[127.0.0.1:38699,DS-5fd60582-20c9-4ab6-be24-6e1ce9af4b34,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-774104457-172.17.0.10-1598188813699:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35135,DS-805b82b2-eec6-4713-aa20-03dc14811147,DISK], DatanodeInfoWithStorage[127.0.0.1:42306,DS-d86e5256-e39e-4cfa-ad5d-68ed3d255869,DISK], DatanodeInfoWithStorage[127.0.0.1:38248,DS-12e3d425-112c-4173-bc79-824869c861ad,DISK], DatanodeInfoWithStorage[127.0.0.1:44303,DS-c281d922-3c66-49d1-828a-e5d7a6eb0313,DISK], DatanodeInfoWithStorage[127.0.0.1:37115,DS-d0874084-160e-4142-b4bc-eb0380909e7a,DISK], DatanodeInfoWithStorage[127.0.0.1:46365,DS-874c2988-4ff8-4d69-afdb-c32ab473f51a,DISK], DatanodeInfoWithStorage[127.0.0.1:33995,DS-0feab983-a0e4-49fb-aff1-a7cd24746d93,DISK], DatanodeInfoWithStorage[127.0.0.1:40696,DS-94f63221-522b-491c-8e35-0455500bdb0f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-774104457-172.17.0.10-1598188813699:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35135,DS-805b82b2-eec6-4713-aa20-03dc14811147,DISK], DatanodeInfoWithStorage[127.0.0.1:42306,DS-d86e5256-e39e-4cfa-ad5d-68ed3d255869,DISK], DatanodeInfoWithStorage[127.0.0.1:38248,DS-12e3d425-112c-4173-bc79-824869c861ad,DISK], DatanodeInfoWithStorage[127.0.0.1:44303,DS-c281d922-3c66-49d1-828a-e5d7a6eb0313,DISK], DatanodeInfoWithStorage[127.0.0.1:37115,DS-d0874084-160e-4142-b4bc-eb0380909e7a,DISK], DatanodeInfoWithStorage[127.0.0.1:46365,DS-874c2988-4ff8-4d69-afdb-c32ab473f51a,DISK], DatanodeInfoWithStorage[127.0.0.1:33995,DS-0feab983-a0e4-49fb-aff1-a7cd24746d93,DISK], DatanodeInfoWithStorage[127.0.0.1:40696,DS-94f63221-522b-491c-8e35-0455500bdb0f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1217670284-172.17.0.10-1598189153328:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45315,DS-fe19c8e5-1767-4f11-b259-910cdd0b8241,DISK], DatanodeInfoWithStorage[127.0.0.1:35804,DS-e45aaacf-eef7-4ad7-8529-cd1907f502fc,DISK], DatanodeInfoWithStorage[127.0.0.1:37591,DS-3a35f8ef-e4e8-4e23-b92e-a1da9bf0d4f2,DISK], DatanodeInfoWithStorage[127.0.0.1:36347,DS-de01dd7f-8065-48c6-b46f-f11a0564cb32,DISK], DatanodeInfoWithStorage[127.0.0.1:39782,DS-7d786b43-c1ee-4875-82ed-c065f0472880,DISK], DatanodeInfoWithStorage[127.0.0.1:46491,DS-598adbd2-bd85-471b-b94e-e59bc9cf6a3b,DISK], DatanodeInfoWithStorage[127.0.0.1:38587,DS-c6c3e31e-1851-4f93-bec4-82f6cffba379,DISK], DatanodeInfoWithStorage[127.0.0.1:35209,DS-05cab893-c4c5-41a1-aab2-3b4b3808441e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1217670284-172.17.0.10-1598189153328:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45315,DS-fe19c8e5-1767-4f11-b259-910cdd0b8241,DISK], DatanodeInfoWithStorage[127.0.0.1:35804,DS-e45aaacf-eef7-4ad7-8529-cd1907f502fc,DISK], DatanodeInfoWithStorage[127.0.0.1:37591,DS-3a35f8ef-e4e8-4e23-b92e-a1da9bf0d4f2,DISK], DatanodeInfoWithStorage[127.0.0.1:36347,DS-de01dd7f-8065-48c6-b46f-f11a0564cb32,DISK], DatanodeInfoWithStorage[127.0.0.1:39782,DS-7d786b43-c1ee-4875-82ed-c065f0472880,DISK], DatanodeInfoWithStorage[127.0.0.1:46491,DS-598adbd2-bd85-471b-b94e-e59bc9cf6a3b,DISK], DatanodeInfoWithStorage[127.0.0.1:38587,DS-c6c3e31e-1851-4f93-bec4-82f6cffba379,DISK], DatanodeInfoWithStorage[127.0.0.1:35209,DS-05cab893-c4c5-41a1-aab2-3b4b3808441e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-442186252-172.17.0.10-1598189622263:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40225,DS-88324710-03bb-4ae8-9776-eea3e0bbcc63,DISK], DatanodeInfoWithStorage[127.0.0.1:34705,DS-f5a6f8fa-7ac7-40fb-9618-56fa7f95de84,DISK], DatanodeInfoWithStorage[127.0.0.1:41204,DS-46a4e2ea-39cc-476b-a67c-7b7889ecc891,DISK], DatanodeInfoWithStorage[127.0.0.1:41177,DS-147f39b4-080b-4660-9be1-706137f538b5,DISK], DatanodeInfoWithStorage[127.0.0.1:46601,DS-c175a8e1-98a6-458a-be92-9c85722028fd,DISK], DatanodeInfoWithStorage[127.0.0.1:40549,DS-159ec2ef-e65d-416d-af5d-4ab9ae870d90,DISK], DatanodeInfoWithStorage[127.0.0.1:45613,DS-24e71a99-69da-4991-b583-d5307a6cb5ca,DISK], DatanodeInfoWithStorage[127.0.0.1:44771,DS-ec995ac6-cede-4a7d-9262-718ca0448b7e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-442186252-172.17.0.10-1598189622263:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40225,DS-88324710-03bb-4ae8-9776-eea3e0bbcc63,DISK], DatanodeInfoWithStorage[127.0.0.1:34705,DS-f5a6f8fa-7ac7-40fb-9618-56fa7f95de84,DISK], DatanodeInfoWithStorage[127.0.0.1:41204,DS-46a4e2ea-39cc-476b-a67c-7b7889ecc891,DISK], DatanodeInfoWithStorage[127.0.0.1:41177,DS-147f39b4-080b-4660-9be1-706137f538b5,DISK], DatanodeInfoWithStorage[127.0.0.1:46601,DS-c175a8e1-98a6-458a-be92-9c85722028fd,DISK], DatanodeInfoWithStorage[127.0.0.1:40549,DS-159ec2ef-e65d-416d-af5d-4ab9ae870d90,DISK], DatanodeInfoWithStorage[127.0.0.1:45613,DS-24e71a99-69da-4991-b583-d5307a6cb5ca,DISK], DatanodeInfoWithStorage[127.0.0.1:44771,DS-ec995ac6-cede-4a7d-9262-718ca0448b7e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-831982130-172.17.0.10-1598189655213:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33377,DS-9fe313b8-67e9-4222-90ec-e3fe9ee225f2,DISK], DatanodeInfoWithStorage[127.0.0.1:36806,DS-da25daed-e263-420d-981e-9015bf05de68,DISK], DatanodeInfoWithStorage[127.0.0.1:38140,DS-f972c903-117c-4d7d-822f-cd2a7918d0fe,DISK], DatanodeInfoWithStorage[127.0.0.1:37644,DS-38068525-418a-45b9-baa3-d446852d51ea,DISK], DatanodeInfoWithStorage[127.0.0.1:38748,DS-ee72703f-1b0f-46be-92bc-50bb053e7ed2,DISK], DatanodeInfoWithStorage[127.0.0.1:38381,DS-c9c006c0-8af0-4772-b81c-4ac6c0bb273c,DISK], DatanodeInfoWithStorage[127.0.0.1:34471,DS-3b674397-b2b8-460c-8eaf-201a561cb8c6,DISK], DatanodeInfoWithStorage[127.0.0.1:33213,DS-80d93896-55db-4c61-9e24-9b2bf2a88539,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-831982130-172.17.0.10-1598189655213:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33377,DS-9fe313b8-67e9-4222-90ec-e3fe9ee225f2,DISK], DatanodeInfoWithStorage[127.0.0.1:36806,DS-da25daed-e263-420d-981e-9015bf05de68,DISK], DatanodeInfoWithStorage[127.0.0.1:38140,DS-f972c903-117c-4d7d-822f-cd2a7918d0fe,DISK], DatanodeInfoWithStorage[127.0.0.1:37644,DS-38068525-418a-45b9-baa3-d446852d51ea,DISK], DatanodeInfoWithStorage[127.0.0.1:38748,DS-ee72703f-1b0f-46be-92bc-50bb053e7ed2,DISK], DatanodeInfoWithStorage[127.0.0.1:38381,DS-c9c006c0-8af0-4772-b81c-4ac6c0bb273c,DISK], DatanodeInfoWithStorage[127.0.0.1:34471,DS-3b674397-b2b8-460c-8eaf-201a561cb8c6,DISK], DatanodeInfoWithStorage[127.0.0.1:33213,DS-80d93896-55db-4c61-9e24-9b2bf2a88539,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-87620322-172.17.0.10-1598190237174:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42318,DS-2a35a2f2-7123-40cc-904d-e68a3177db9b,DISK], DatanodeInfoWithStorage[127.0.0.1:40901,DS-f579d036-59bc-4c33-9222-3a7747081a5b,DISK], DatanodeInfoWithStorage[127.0.0.1:45670,DS-8f6fba09-03b1-46af-b86b-5b6184b42c2f,DISK], DatanodeInfoWithStorage[127.0.0.1:44198,DS-dc681c76-8e95-4f6c-a0fd-480e654cdb83,DISK], DatanodeInfoWithStorage[127.0.0.1:42014,DS-f1670e0f-590d-4a35-b038-6a2b21a0754b,DISK], DatanodeInfoWithStorage[127.0.0.1:36927,DS-6c9ffe07-1aec-47df-b54f-73e6c67cb2e4,DISK], DatanodeInfoWithStorage[127.0.0.1:45511,DS-b29b66f6-78b2-43ab-8a7c-eae79c894722,DISK], DatanodeInfoWithStorage[127.0.0.1:45242,DS-3def5a47-c9a6-4b2c-8e4c-ebdf123d97c5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-87620322-172.17.0.10-1598190237174:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42318,DS-2a35a2f2-7123-40cc-904d-e68a3177db9b,DISK], DatanodeInfoWithStorage[127.0.0.1:40901,DS-f579d036-59bc-4c33-9222-3a7747081a5b,DISK], DatanodeInfoWithStorage[127.0.0.1:45670,DS-8f6fba09-03b1-46af-b86b-5b6184b42c2f,DISK], DatanodeInfoWithStorage[127.0.0.1:44198,DS-dc681c76-8e95-4f6c-a0fd-480e654cdb83,DISK], DatanodeInfoWithStorage[127.0.0.1:42014,DS-f1670e0f-590d-4a35-b038-6a2b21a0754b,DISK], DatanodeInfoWithStorage[127.0.0.1:36927,DS-6c9ffe07-1aec-47df-b54f-73e6c67cb2e4,DISK], DatanodeInfoWithStorage[127.0.0.1:45511,DS-b29b66f6-78b2-43ab-8a7c-eae79c894722,DISK], DatanodeInfoWithStorage[127.0.0.1:45242,DS-3def5a47-c9a6-4b2c-8e4c-ebdf123d97c5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1873662256-172.17.0.10-1598190555152:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35788,DS-fa5486eb-baff-4a61-a73f-c0d6f557c9b9,DISK], DatanodeInfoWithStorage[127.0.0.1:46320,DS-7187963e-f2b4-4538-af5a-4789795e6d9c,DISK], DatanodeInfoWithStorage[127.0.0.1:40134,DS-a1658b21-094d-421c-bb7b-18bb6d3d08b1,DISK], DatanodeInfoWithStorage[127.0.0.1:43529,DS-87549a36-7c30-4525-be48-159e3029b6aa,DISK], DatanodeInfoWithStorage[127.0.0.1:37543,DS-6cdfeecd-bcca-4d8a-b870-e96b939e1211,DISK], DatanodeInfoWithStorage[127.0.0.1:33932,DS-5400edb0-a78c-465f-89c9-1666a82f8f84,DISK], DatanodeInfoWithStorage[127.0.0.1:40581,DS-fbf60ddd-97d8-4dcb-b5fe-8f8ba4bd2fd1,DISK], DatanodeInfoWithStorage[127.0.0.1:33251,DS-57921d17-a8dc-4dea-b4d8-fb358c21b0bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1873662256-172.17.0.10-1598190555152:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35788,DS-fa5486eb-baff-4a61-a73f-c0d6f557c9b9,DISK], DatanodeInfoWithStorage[127.0.0.1:46320,DS-7187963e-f2b4-4538-af5a-4789795e6d9c,DISK], DatanodeInfoWithStorage[127.0.0.1:40134,DS-a1658b21-094d-421c-bb7b-18bb6d3d08b1,DISK], DatanodeInfoWithStorage[127.0.0.1:43529,DS-87549a36-7c30-4525-be48-159e3029b6aa,DISK], DatanodeInfoWithStorage[127.0.0.1:37543,DS-6cdfeecd-bcca-4d8a-b870-e96b939e1211,DISK], DatanodeInfoWithStorage[127.0.0.1:33932,DS-5400edb0-a78c-465f-89c9-1666a82f8f84,DISK], DatanodeInfoWithStorage[127.0.0.1:40581,DS-fbf60ddd-97d8-4dcb-b5fe-8f8ba4bd2fd1,DISK], DatanodeInfoWithStorage[127.0.0.1:33251,DS-57921d17-a8dc-4dea-b4d8-fb358c21b0bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1866576401-172.17.0.10-1598190836382:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35929,DS-50102b63-3a87-4a2d-b1f0-7820e9144c2a,DISK], DatanodeInfoWithStorage[127.0.0.1:35526,DS-95ee2e17-3330-420c-a496-febd29daecd3,DISK], DatanodeInfoWithStorage[127.0.0.1:38640,DS-bd292677-8160-4831-bf0b-77076eac5648,DISK], DatanodeInfoWithStorage[127.0.0.1:40190,DS-483cfebb-4b4f-4076-ac1b-2fdb21b38e29,DISK], DatanodeInfoWithStorage[127.0.0.1:35351,DS-258e198f-1a5e-4fe4-8c1e-254631c37511,DISK], DatanodeInfoWithStorage[127.0.0.1:42512,DS-bfd47758-e9f9-48ad-804c-01ed69e3ddaa,DISK], DatanodeInfoWithStorage[127.0.0.1:45872,DS-1668f347-3246-4575-9534-01c7c903117a,DISK], DatanodeInfoWithStorage[127.0.0.1:42691,DS-d364ade9-50cb-441b-a808-ece0e55987ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1866576401-172.17.0.10-1598190836382:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35929,DS-50102b63-3a87-4a2d-b1f0-7820e9144c2a,DISK], DatanodeInfoWithStorage[127.0.0.1:35526,DS-95ee2e17-3330-420c-a496-febd29daecd3,DISK], DatanodeInfoWithStorage[127.0.0.1:38640,DS-bd292677-8160-4831-bf0b-77076eac5648,DISK], DatanodeInfoWithStorage[127.0.0.1:40190,DS-483cfebb-4b4f-4076-ac1b-2fdb21b38e29,DISK], DatanodeInfoWithStorage[127.0.0.1:35351,DS-258e198f-1a5e-4fe4-8c1e-254631c37511,DISK], DatanodeInfoWithStorage[127.0.0.1:42512,DS-bfd47758-e9f9-48ad-804c-01ed69e3ddaa,DISK], DatanodeInfoWithStorage[127.0.0.1:45872,DS-1668f347-3246-4575-9534-01c7c903117a,DISK], DatanodeInfoWithStorage[127.0.0.1:42691,DS-d364ade9-50cb-441b-a808-ece0e55987ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1382504784-172.17.0.10-1598190945547:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42119,DS-b13cd015-cefb-4018-8197-ea6ecff691b5,DISK], DatanodeInfoWithStorage[127.0.0.1:36335,DS-abdf2f96-ae3f-4cb8-9dd8-82e4708aa1bd,DISK], DatanodeInfoWithStorage[127.0.0.1:44990,DS-c9a9bc73-5ec2-42f6-98a9-7d7ca2515d85,DISK], DatanodeInfoWithStorage[127.0.0.1:41865,DS-56c885f5-c82e-4972-a599-9d4d0ae5c211,DISK], DatanodeInfoWithStorage[127.0.0.1:46307,DS-4e157fb4-3fc4-416e-a6e6-fad43774a338,DISK], DatanodeInfoWithStorage[127.0.0.1:38818,DS-07e47075-6cb0-4267-9c2a-a56c51db98ca,DISK], DatanodeInfoWithStorage[127.0.0.1:34783,DS-3e53fbd8-39ee-49c0-9bc0-b6cf1c6aedfa,DISK], DatanodeInfoWithStorage[127.0.0.1:46137,DS-e0a38327-0db7-4f06-b9ab-1d2f10e09cb7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1382504784-172.17.0.10-1598190945547:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42119,DS-b13cd015-cefb-4018-8197-ea6ecff691b5,DISK], DatanodeInfoWithStorage[127.0.0.1:36335,DS-abdf2f96-ae3f-4cb8-9dd8-82e4708aa1bd,DISK], DatanodeInfoWithStorage[127.0.0.1:44990,DS-c9a9bc73-5ec2-42f6-98a9-7d7ca2515d85,DISK], DatanodeInfoWithStorage[127.0.0.1:41865,DS-56c885f5-c82e-4972-a599-9d4d0ae5c211,DISK], DatanodeInfoWithStorage[127.0.0.1:46307,DS-4e157fb4-3fc4-416e-a6e6-fad43774a338,DISK], DatanodeInfoWithStorage[127.0.0.1:38818,DS-07e47075-6cb0-4267-9c2a-a56c51db98ca,DISK], DatanodeInfoWithStorage[127.0.0.1:34783,DS-3e53fbd8-39ee-49c0-9bc0-b6cf1c6aedfa,DISK], DatanodeInfoWithStorage[127.0.0.1:46137,DS-e0a38327-0db7-4f06-b9ab-1d2f10e09cb7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 14 out of 50
result: false positive !!!
Total execution time in seconds : 5137
