reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1548780992-172.17.0.16-1598175030055:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33535,DS-498bd081-8dd7-4310-92de-b98fbd7a075b,DISK], DatanodeInfoWithStorage[127.0.0.1:38088,DS-ee72f944-d140-40da-b9f2-5ec918d6b460,DISK], DatanodeInfoWithStorage[127.0.0.1:40800,DS-84a109ae-2111-4a5e-a3e6-583e3da2a409,DISK], DatanodeInfoWithStorage[127.0.0.1:37431,DS-7674e780-7594-41b0-a5d6-2036a417503e,DISK], DatanodeInfoWithStorage[127.0.0.1:44416,DS-2d106eb7-f0ae-4bfd-8ba8-51b07ffb7814,DISK], DatanodeInfoWithStorage[127.0.0.1:36029,DS-159e38a3-598d-41d4-8513-0cd6005c08c4,DISK], DatanodeInfoWithStorage[127.0.0.1:42074,DS-0067a7b6-7ba0-418b-8067-7cb73e776bf2,DISK], DatanodeInfoWithStorage[127.0.0.1:40565,DS-42a376a5-1c3b-40c6-9649-94fa6db82006,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1548780992-172.17.0.16-1598175030055:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33535,DS-498bd081-8dd7-4310-92de-b98fbd7a075b,DISK], DatanodeInfoWithStorage[127.0.0.1:38088,DS-ee72f944-d140-40da-b9f2-5ec918d6b460,DISK], DatanodeInfoWithStorage[127.0.0.1:40800,DS-84a109ae-2111-4a5e-a3e6-583e3da2a409,DISK], DatanodeInfoWithStorage[127.0.0.1:37431,DS-7674e780-7594-41b0-a5d6-2036a417503e,DISK], DatanodeInfoWithStorage[127.0.0.1:44416,DS-2d106eb7-f0ae-4bfd-8ba8-51b07ffb7814,DISK], DatanodeInfoWithStorage[127.0.0.1:36029,DS-159e38a3-598d-41d4-8513-0cd6005c08c4,DISK], DatanodeInfoWithStorage[127.0.0.1:42074,DS-0067a7b6-7ba0-418b-8067-7cb73e776bf2,DISK], DatanodeInfoWithStorage[127.0.0.1:40565,DS-42a376a5-1c3b-40c6-9649-94fa6db82006,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1070137746-172.17.0.16-1598175293359:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40167,DS-96dcc2e6-ced5-4e33-b9d3-446a8c00feef,DISK], DatanodeInfoWithStorage[127.0.0.1:44192,DS-18c1c854-a401-42a9-a443-77fd365a7b90,DISK], DatanodeInfoWithStorage[127.0.0.1:37296,DS-2c0d7556-f30d-4e0c-bdb6-558c77e4a194,DISK], DatanodeInfoWithStorage[127.0.0.1:37054,DS-4a7bd663-6d66-4adb-b983-582b0f5d1117,DISK], DatanodeInfoWithStorage[127.0.0.1:34091,DS-2366a256-3a0e-4592-b799-0b973dd638ca,DISK], DatanodeInfoWithStorage[127.0.0.1:36765,DS-b22ced12-ab26-4fcb-8bf8-777751cd4628,DISK], DatanodeInfoWithStorage[127.0.0.1:37893,DS-f1a860fd-b4b2-415d-b7c3-ac0a0de5db8c,DISK], DatanodeInfoWithStorage[127.0.0.1:44322,DS-7f5e89cc-a566-4ac8-b354-791f3d596383,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1070137746-172.17.0.16-1598175293359:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40167,DS-96dcc2e6-ced5-4e33-b9d3-446a8c00feef,DISK], DatanodeInfoWithStorage[127.0.0.1:44192,DS-18c1c854-a401-42a9-a443-77fd365a7b90,DISK], DatanodeInfoWithStorage[127.0.0.1:37296,DS-2c0d7556-f30d-4e0c-bdb6-558c77e4a194,DISK], DatanodeInfoWithStorage[127.0.0.1:37054,DS-4a7bd663-6d66-4adb-b983-582b0f5d1117,DISK], DatanodeInfoWithStorage[127.0.0.1:34091,DS-2366a256-3a0e-4592-b799-0b973dd638ca,DISK], DatanodeInfoWithStorage[127.0.0.1:36765,DS-b22ced12-ab26-4fcb-8bf8-777751cd4628,DISK], DatanodeInfoWithStorage[127.0.0.1:37893,DS-f1a860fd-b4b2-415d-b7c3-ac0a0de5db8c,DISK], DatanodeInfoWithStorage[127.0.0.1:44322,DS-7f5e89cc-a566-4ac8-b354-791f3d596383,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2004890891-172.17.0.16-1598176003338:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45254,DS-5f737a25-0e47-43c7-82fc-db8da54052b9,DISK], DatanodeInfoWithStorage[127.0.0.1:41423,DS-086e592f-de39-43bc-b4df-8c55fef711c1,DISK], DatanodeInfoWithStorage[127.0.0.1:32870,DS-77c777d5-4841-4404-8b1f-03f285b66ccb,DISK], DatanodeInfoWithStorage[127.0.0.1:37827,DS-0599bddb-6db6-4b45-950d-02c5d965c4a4,DISK], DatanodeInfoWithStorage[127.0.0.1:39928,DS-b79ef078-e61d-4452-89a9-d49e66b14800,DISK], DatanodeInfoWithStorage[127.0.0.1:45631,DS-0e84504a-e099-475a-a161-2b3220d7ba97,DISK], DatanodeInfoWithStorage[127.0.0.1:34603,DS-27168a55-883e-4cb8-a439-190de7fbc2ae,DISK], DatanodeInfoWithStorage[127.0.0.1:34153,DS-f5a3d737-4333-415d-bb0e-333ea84cc166,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2004890891-172.17.0.16-1598176003338:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45254,DS-5f737a25-0e47-43c7-82fc-db8da54052b9,DISK], DatanodeInfoWithStorage[127.0.0.1:41423,DS-086e592f-de39-43bc-b4df-8c55fef711c1,DISK], DatanodeInfoWithStorage[127.0.0.1:32870,DS-77c777d5-4841-4404-8b1f-03f285b66ccb,DISK], DatanodeInfoWithStorage[127.0.0.1:37827,DS-0599bddb-6db6-4b45-950d-02c5d965c4a4,DISK], DatanodeInfoWithStorage[127.0.0.1:39928,DS-b79ef078-e61d-4452-89a9-d49e66b14800,DISK], DatanodeInfoWithStorage[127.0.0.1:45631,DS-0e84504a-e099-475a-a161-2b3220d7ba97,DISK], DatanodeInfoWithStorage[127.0.0.1:34603,DS-27168a55-883e-4cb8-a439-190de7fbc2ae,DISK], DatanodeInfoWithStorage[127.0.0.1:34153,DS-f5a3d737-4333-415d-bb0e-333ea84cc166,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-797843525-172.17.0.16-1598176150638:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43295,DS-e8a9b106-d2c3-498c-b953-5bc81fc92b64,DISK], DatanodeInfoWithStorage[127.0.0.1:43189,DS-a083ec9e-3872-4382-b5f8-bb9aaab1a423,DISK], DatanodeInfoWithStorage[127.0.0.1:42780,DS-f4f44a7d-eef6-4f38-9c86-e2a39f925253,DISK], DatanodeInfoWithStorage[127.0.0.1:39254,DS-842733b5-5303-492b-a4d3-3f8f3db1f924,DISK], DatanodeInfoWithStorage[127.0.0.1:36148,DS-ce29acc7-52dc-4602-b822-9a69a75ce4cd,DISK], DatanodeInfoWithStorage[127.0.0.1:35125,DS-ecdc9553-24ca-4c64-a2af-6852f7cbea98,DISK], DatanodeInfoWithStorage[127.0.0.1:39739,DS-dab137b5-fba6-4f4d-82d0-e1a43c7aad5d,DISK], DatanodeInfoWithStorage[127.0.0.1:37791,DS-54c098b3-ec32-4b39-a9ff-18d03aadb233,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-797843525-172.17.0.16-1598176150638:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43295,DS-e8a9b106-d2c3-498c-b953-5bc81fc92b64,DISK], DatanodeInfoWithStorage[127.0.0.1:43189,DS-a083ec9e-3872-4382-b5f8-bb9aaab1a423,DISK], DatanodeInfoWithStorage[127.0.0.1:42780,DS-f4f44a7d-eef6-4f38-9c86-e2a39f925253,DISK], DatanodeInfoWithStorage[127.0.0.1:39254,DS-842733b5-5303-492b-a4d3-3f8f3db1f924,DISK], DatanodeInfoWithStorage[127.0.0.1:36148,DS-ce29acc7-52dc-4602-b822-9a69a75ce4cd,DISK], DatanodeInfoWithStorage[127.0.0.1:35125,DS-ecdc9553-24ca-4c64-a2af-6852f7cbea98,DISK], DatanodeInfoWithStorage[127.0.0.1:39739,DS-dab137b5-fba6-4f4d-82d0-e1a43c7aad5d,DISK], DatanodeInfoWithStorage[127.0.0.1:37791,DS-54c098b3-ec32-4b39-a9ff-18d03aadb233,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-249149926-172.17.0.16-1598176494957:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40019,DS-545b7a3a-5610-43f5-92df-c627c9f18bed,DISK], DatanodeInfoWithStorage[127.0.0.1:33379,DS-62050ea7-25c8-4ee5-bc43-a2f7489ebcf2,DISK], DatanodeInfoWithStorage[127.0.0.1:41307,DS-a7664579-65d1-48f6-9418-1c53cc63b8d4,DISK], DatanodeInfoWithStorage[127.0.0.1:43079,DS-afcc7f16-0704-4070-b2df-4d06212d0a6f,DISK], DatanodeInfoWithStorage[127.0.0.1:40720,DS-28ecd555-1b5a-4534-bbae-4312ea2fee72,DISK], DatanodeInfoWithStorage[127.0.0.1:32894,DS-a7e74f74-7879-4fd6-a9eb-f7e0a6d71ed8,DISK], DatanodeInfoWithStorage[127.0.0.1:39244,DS-f1b7b34d-7bf4-4efe-bbbf-78e609c61758,DISK], DatanodeInfoWithStorage[127.0.0.1:38061,DS-0700d39c-4482-40d7-86f4-d8f83d4cc6e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-249149926-172.17.0.16-1598176494957:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40019,DS-545b7a3a-5610-43f5-92df-c627c9f18bed,DISK], DatanodeInfoWithStorage[127.0.0.1:33379,DS-62050ea7-25c8-4ee5-bc43-a2f7489ebcf2,DISK], DatanodeInfoWithStorage[127.0.0.1:41307,DS-a7664579-65d1-48f6-9418-1c53cc63b8d4,DISK], DatanodeInfoWithStorage[127.0.0.1:43079,DS-afcc7f16-0704-4070-b2df-4d06212d0a6f,DISK], DatanodeInfoWithStorage[127.0.0.1:40720,DS-28ecd555-1b5a-4534-bbae-4312ea2fee72,DISK], DatanodeInfoWithStorage[127.0.0.1:32894,DS-a7e74f74-7879-4fd6-a9eb-f7e0a6d71ed8,DISK], DatanodeInfoWithStorage[127.0.0.1:39244,DS-f1b7b34d-7bf4-4efe-bbbf-78e609c61758,DISK], DatanodeInfoWithStorage[127.0.0.1:38061,DS-0700d39c-4482-40d7-86f4-d8f83d4cc6e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1106797251-172.17.0.16-1598176677385:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34910,DS-17a564ef-7f77-4f1a-b0e1-1a355181bdd9,DISK], DatanodeInfoWithStorage[127.0.0.1:45241,DS-80f0e165-d742-4330-a909-4b92d8e9f9f8,DISK], DatanodeInfoWithStorage[127.0.0.1:34425,DS-4dc94476-2a1e-4f73-a7b7-e2d9dc5c7a45,DISK], DatanodeInfoWithStorage[127.0.0.1:43455,DS-2c0bd678-1898-4a3d-b7f4-132e6bcc7b08,DISK], DatanodeInfoWithStorage[127.0.0.1:44750,DS-9ccd7022-a5e5-4cd6-bca5-c74140d59750,DISK], DatanodeInfoWithStorage[127.0.0.1:40633,DS-64a9dc13-084c-4201-b7f7-72f9f21b13b0,DISK], DatanodeInfoWithStorage[127.0.0.1:46198,DS-6d72593d-f08a-41b6-b6ef-e4d6c7ba4dce,DISK], DatanodeInfoWithStorage[127.0.0.1:35907,DS-d5c1597c-5e36-4f4a-a2d6-52173332ce33,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1106797251-172.17.0.16-1598176677385:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34910,DS-17a564ef-7f77-4f1a-b0e1-1a355181bdd9,DISK], DatanodeInfoWithStorage[127.0.0.1:45241,DS-80f0e165-d742-4330-a909-4b92d8e9f9f8,DISK], DatanodeInfoWithStorage[127.0.0.1:34425,DS-4dc94476-2a1e-4f73-a7b7-e2d9dc5c7a45,DISK], DatanodeInfoWithStorage[127.0.0.1:43455,DS-2c0bd678-1898-4a3d-b7f4-132e6bcc7b08,DISK], DatanodeInfoWithStorage[127.0.0.1:44750,DS-9ccd7022-a5e5-4cd6-bca5-c74140d59750,DISK], DatanodeInfoWithStorage[127.0.0.1:40633,DS-64a9dc13-084c-4201-b7f7-72f9f21b13b0,DISK], DatanodeInfoWithStorage[127.0.0.1:46198,DS-6d72593d-f08a-41b6-b6ef-e4d6c7ba4dce,DISK], DatanodeInfoWithStorage[127.0.0.1:35907,DS-d5c1597c-5e36-4f4a-a2d6-52173332ce33,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1647502793-172.17.0.16-1598176894092:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41071,DS-9d8444ef-3a91-4756-ae3f-8a2e0f543a97,DISK], DatanodeInfoWithStorage[127.0.0.1:39061,DS-92fa2e9b-b207-45aa-934a-0065151b54cc,DISK], DatanodeInfoWithStorage[127.0.0.1:41058,DS-7c761106-0007-4112-a6c9-9c2e64c27588,DISK], DatanodeInfoWithStorage[127.0.0.1:40773,DS-4beef7f5-09fc-4c83-89d8-c027a1ba366d,DISK], DatanodeInfoWithStorage[127.0.0.1:42815,DS-99b527c5-7a3d-41f1-9566-8d1987abd65b,DISK], DatanodeInfoWithStorage[127.0.0.1:42143,DS-1e4f43ab-bf53-479f-9baf-408ced044e0e,DISK], DatanodeInfoWithStorage[127.0.0.1:45819,DS-286cd1a8-0cd4-4dd4-976a-c6cb7dea1b0a,DISK], DatanodeInfoWithStorage[127.0.0.1:45592,DS-ca002472-7db3-4fd7-ba97-eb8c70185e2a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1647502793-172.17.0.16-1598176894092:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41071,DS-9d8444ef-3a91-4756-ae3f-8a2e0f543a97,DISK], DatanodeInfoWithStorage[127.0.0.1:39061,DS-92fa2e9b-b207-45aa-934a-0065151b54cc,DISK], DatanodeInfoWithStorage[127.0.0.1:41058,DS-7c761106-0007-4112-a6c9-9c2e64c27588,DISK], DatanodeInfoWithStorage[127.0.0.1:40773,DS-4beef7f5-09fc-4c83-89d8-c027a1ba366d,DISK], DatanodeInfoWithStorage[127.0.0.1:42815,DS-99b527c5-7a3d-41f1-9566-8d1987abd65b,DISK], DatanodeInfoWithStorage[127.0.0.1:42143,DS-1e4f43ab-bf53-479f-9baf-408ced044e0e,DISK], DatanodeInfoWithStorage[127.0.0.1:45819,DS-286cd1a8-0cd4-4dd4-976a-c6cb7dea1b0a,DISK], DatanodeInfoWithStorage[127.0.0.1:45592,DS-ca002472-7db3-4fd7-ba97-eb8c70185e2a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-607369300-172.17.0.16-1598176933304:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34968,DS-e12454bf-eb30-4dd6-b4bf-dfae086b5636,DISK], DatanodeInfoWithStorage[127.0.0.1:44980,DS-6f15633f-443a-434e-9969-4657a16c87a6,DISK], DatanodeInfoWithStorage[127.0.0.1:33504,DS-29493c87-06c3-46da-aba0-8c8da6cd0231,DISK], DatanodeInfoWithStorage[127.0.0.1:46875,DS-98ae6b17-99c4-4cab-bf24-270ca5da5641,DISK], DatanodeInfoWithStorage[127.0.0.1:43545,DS-03652bfd-8d12-4b95-ae44-9c5c9b1886d9,DISK], DatanodeInfoWithStorage[127.0.0.1:42516,DS-71feee05-022e-40b2-b769-57c7caa96a3f,DISK], DatanodeInfoWithStorage[127.0.0.1:38725,DS-cf51151e-141c-408d-b4db-e3824046ce3c,DISK], DatanodeInfoWithStorage[127.0.0.1:38100,DS-d27b6073-9f76-4fce-9398-7980ec6b9bee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-607369300-172.17.0.16-1598176933304:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34968,DS-e12454bf-eb30-4dd6-b4bf-dfae086b5636,DISK], DatanodeInfoWithStorage[127.0.0.1:44980,DS-6f15633f-443a-434e-9969-4657a16c87a6,DISK], DatanodeInfoWithStorage[127.0.0.1:33504,DS-29493c87-06c3-46da-aba0-8c8da6cd0231,DISK], DatanodeInfoWithStorage[127.0.0.1:46875,DS-98ae6b17-99c4-4cab-bf24-270ca5da5641,DISK], DatanodeInfoWithStorage[127.0.0.1:43545,DS-03652bfd-8d12-4b95-ae44-9c5c9b1886d9,DISK], DatanodeInfoWithStorage[127.0.0.1:42516,DS-71feee05-022e-40b2-b769-57c7caa96a3f,DISK], DatanodeInfoWithStorage[127.0.0.1:38725,DS-cf51151e-141c-408d-b4db-e3824046ce3c,DISK], DatanodeInfoWithStorage[127.0.0.1:38100,DS-d27b6073-9f76-4fce-9398-7980ec6b9bee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1573825081-172.17.0.16-1598177924843:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33959,DS-21f3bd49-e403-4c8c-aa62-82b1f602234f,DISK], DatanodeInfoWithStorage[127.0.0.1:38166,DS-d59fb49a-42ea-448e-8f54-41d1f68afba7,DISK], DatanodeInfoWithStorage[127.0.0.1:38128,DS-08121b0e-f119-454f-9ff0-beb4fed8d046,DISK], DatanodeInfoWithStorage[127.0.0.1:45070,DS-5889c5ca-1a73-43bb-b1f9-fcf34dc10549,DISK], DatanodeInfoWithStorage[127.0.0.1:42707,DS-15897178-0524-4fbf-9c6a-caede33e39d0,DISK], DatanodeInfoWithStorage[127.0.0.1:41782,DS-2244c757-61a8-4ab7-bf96-76978ca0d0a6,DISK], DatanodeInfoWithStorage[127.0.0.1:41877,DS-f3feee00-17eb-4fab-b340-6277b9c5edf3,DISK], DatanodeInfoWithStorage[127.0.0.1:43382,DS-3db0ce48-1e7a-469a-929b-ac6ead20433a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1573825081-172.17.0.16-1598177924843:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33959,DS-21f3bd49-e403-4c8c-aa62-82b1f602234f,DISK], DatanodeInfoWithStorage[127.0.0.1:38166,DS-d59fb49a-42ea-448e-8f54-41d1f68afba7,DISK], DatanodeInfoWithStorage[127.0.0.1:38128,DS-08121b0e-f119-454f-9ff0-beb4fed8d046,DISK], DatanodeInfoWithStorage[127.0.0.1:45070,DS-5889c5ca-1a73-43bb-b1f9-fcf34dc10549,DISK], DatanodeInfoWithStorage[127.0.0.1:42707,DS-15897178-0524-4fbf-9c6a-caede33e39d0,DISK], DatanodeInfoWithStorage[127.0.0.1:41782,DS-2244c757-61a8-4ab7-bf96-76978ca0d0a6,DISK], DatanodeInfoWithStorage[127.0.0.1:41877,DS-f3feee00-17eb-4fab-b340-6277b9c5edf3,DISK], DatanodeInfoWithStorage[127.0.0.1:43382,DS-3db0ce48-1e7a-469a-929b-ac6ead20433a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-133806883-172.17.0.16-1598177955826:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38382,DS-e5da0ded-0e64-488a-9b02-12cbeda9bcf1,DISK], DatanodeInfoWithStorage[127.0.0.1:35074,DS-c1e0b669-553a-4ab9-805d-9d8667c2467d,DISK], DatanodeInfoWithStorage[127.0.0.1:45318,DS-b4c9abf5-0998-45c1-ba87-c390128867e4,DISK], DatanodeInfoWithStorage[127.0.0.1:43700,DS-4bccd805-e7d0-446d-9304-55de1d399d9c,DISK], DatanodeInfoWithStorage[127.0.0.1:36338,DS-350d471b-7194-4e76-94f9-8753e19bbeb5,DISK], DatanodeInfoWithStorage[127.0.0.1:34653,DS-7fd5b1f3-a19a-4eb3-9065-75521fe02f13,DISK], DatanodeInfoWithStorage[127.0.0.1:41039,DS-8994b50e-861c-4470-a2bb-077eaf01ba68,DISK], DatanodeInfoWithStorage[127.0.0.1:44919,DS-8f3936ff-69f2-4a51-9fe6-74e4316a8e3a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-133806883-172.17.0.16-1598177955826:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38382,DS-e5da0ded-0e64-488a-9b02-12cbeda9bcf1,DISK], DatanodeInfoWithStorage[127.0.0.1:35074,DS-c1e0b669-553a-4ab9-805d-9d8667c2467d,DISK], DatanodeInfoWithStorage[127.0.0.1:45318,DS-b4c9abf5-0998-45c1-ba87-c390128867e4,DISK], DatanodeInfoWithStorage[127.0.0.1:43700,DS-4bccd805-e7d0-446d-9304-55de1d399d9c,DISK], DatanodeInfoWithStorage[127.0.0.1:36338,DS-350d471b-7194-4e76-94f9-8753e19bbeb5,DISK], DatanodeInfoWithStorage[127.0.0.1:34653,DS-7fd5b1f3-a19a-4eb3-9065-75521fe02f13,DISK], DatanodeInfoWithStorage[127.0.0.1:41039,DS-8994b50e-861c-4470-a2bb-077eaf01ba68,DISK], DatanodeInfoWithStorage[127.0.0.1:44919,DS-8f3936ff-69f2-4a51-9fe6-74e4316a8e3a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1785507247-172.17.0.16-1598178028690:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40778,DS-9da4167b-0107-48c4-8c2e-232334d4d6c6,DISK], DatanodeInfoWithStorage[127.0.0.1:34109,DS-b1e87830-a533-4192-bb8e-ff8a7578f0e2,DISK], DatanodeInfoWithStorage[127.0.0.1:44102,DS-fb82bf3f-36fc-46be-918f-d2e78cde5259,DISK], DatanodeInfoWithStorage[127.0.0.1:35445,DS-3968886b-a4ea-41c5-85a2-ed400667d1b9,DISK], DatanodeInfoWithStorage[127.0.0.1:46427,DS-621708a2-6be0-484e-bb5d-8eb52534a354,DISK], DatanodeInfoWithStorage[127.0.0.1:32799,DS-631bc521-bd74-4ca8-9380-7221770f7b90,DISK], DatanodeInfoWithStorage[127.0.0.1:35373,DS-b0f8b879-cd8a-4705-abe6-7129cc2eeda6,DISK], DatanodeInfoWithStorage[127.0.0.1:36525,DS-0209aab8-9fe4-4405-86e4-7ac3217c9b26,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1785507247-172.17.0.16-1598178028690:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40778,DS-9da4167b-0107-48c4-8c2e-232334d4d6c6,DISK], DatanodeInfoWithStorage[127.0.0.1:34109,DS-b1e87830-a533-4192-bb8e-ff8a7578f0e2,DISK], DatanodeInfoWithStorage[127.0.0.1:44102,DS-fb82bf3f-36fc-46be-918f-d2e78cde5259,DISK], DatanodeInfoWithStorage[127.0.0.1:35445,DS-3968886b-a4ea-41c5-85a2-ed400667d1b9,DISK], DatanodeInfoWithStorage[127.0.0.1:46427,DS-621708a2-6be0-484e-bb5d-8eb52534a354,DISK], DatanodeInfoWithStorage[127.0.0.1:32799,DS-631bc521-bd74-4ca8-9380-7221770f7b90,DISK], DatanodeInfoWithStorage[127.0.0.1:35373,DS-b0f8b879-cd8a-4705-abe6-7129cc2eeda6,DISK], DatanodeInfoWithStorage[127.0.0.1:36525,DS-0209aab8-9fe4-4405-86e4-7ac3217c9b26,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1019232878-172.17.0.16-1598179188104:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40156,DS-cf11472b-412d-4dba-8044-a605b134ab73,DISK], DatanodeInfoWithStorage[127.0.0.1:33204,DS-569015d4-327e-4098-8d6f-4e7a4b1a012c,DISK], DatanodeInfoWithStorage[127.0.0.1:36203,DS-2e4e4829-cb59-4adc-b81b-020b89bad664,DISK], DatanodeInfoWithStorage[127.0.0.1:36284,DS-59c5897d-3310-419c-9f0e-1f0ea8944175,DISK], DatanodeInfoWithStorage[127.0.0.1:37031,DS-870b081c-c3c2-485b-bfbd-df1532007576,DISK], DatanodeInfoWithStorage[127.0.0.1:37410,DS-afee6f13-cce2-49b1-834f-94b17e968a31,DISK], DatanodeInfoWithStorage[127.0.0.1:38244,DS-1442c000-038e-4a97-ac5a-eb370462913e,DISK], DatanodeInfoWithStorage[127.0.0.1:38584,DS-7c5e194e-4ad3-4e73-9bdd-80ac1892f124,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1019232878-172.17.0.16-1598179188104:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40156,DS-cf11472b-412d-4dba-8044-a605b134ab73,DISK], DatanodeInfoWithStorage[127.0.0.1:33204,DS-569015d4-327e-4098-8d6f-4e7a4b1a012c,DISK], DatanodeInfoWithStorage[127.0.0.1:36203,DS-2e4e4829-cb59-4adc-b81b-020b89bad664,DISK], DatanodeInfoWithStorage[127.0.0.1:36284,DS-59c5897d-3310-419c-9f0e-1f0ea8944175,DISK], DatanodeInfoWithStorage[127.0.0.1:37031,DS-870b081c-c3c2-485b-bfbd-df1532007576,DISK], DatanodeInfoWithStorage[127.0.0.1:37410,DS-afee6f13-cce2-49b1-834f-94b17e968a31,DISK], DatanodeInfoWithStorage[127.0.0.1:38244,DS-1442c000-038e-4a97-ac5a-eb370462913e,DISK], DatanodeInfoWithStorage[127.0.0.1:38584,DS-7c5e194e-4ad3-4e73-9bdd-80ac1892f124,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-972723875-172.17.0.16-1598179670158:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39346,DS-ae96f4c2-c03d-42f6-99dd-f3a07e1409eb,DISK], DatanodeInfoWithStorage[127.0.0.1:34313,DS-d8917c2b-c4d8-4947-9ee2-f1d46d8cd5d0,DISK], DatanodeInfoWithStorage[127.0.0.1:40555,DS-e955e89e-eb8d-41df-abb5-32f01d06f8d1,DISK], DatanodeInfoWithStorage[127.0.0.1:39107,DS-8e2fb48e-6010-40f1-982a-c55b94b9028a,DISK], DatanodeInfoWithStorage[127.0.0.1:40442,DS-b189c1f5-c1f6-4063-8de0-11f2d6a2dd97,DISK], DatanodeInfoWithStorage[127.0.0.1:40008,DS-42f2fc18-7af0-4558-8b2c-0db57fe1af5b,DISK], DatanodeInfoWithStorage[127.0.0.1:40558,DS-ac7ef1d0-37f1-4279-a966-38f257e4783c,DISK], DatanodeInfoWithStorage[127.0.0.1:34222,DS-9208e1ed-712b-4ef7-ac4a-e1c2464deef9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-972723875-172.17.0.16-1598179670158:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39346,DS-ae96f4c2-c03d-42f6-99dd-f3a07e1409eb,DISK], DatanodeInfoWithStorage[127.0.0.1:34313,DS-d8917c2b-c4d8-4947-9ee2-f1d46d8cd5d0,DISK], DatanodeInfoWithStorage[127.0.0.1:40555,DS-e955e89e-eb8d-41df-abb5-32f01d06f8d1,DISK], DatanodeInfoWithStorage[127.0.0.1:39107,DS-8e2fb48e-6010-40f1-982a-c55b94b9028a,DISK], DatanodeInfoWithStorage[127.0.0.1:40442,DS-b189c1f5-c1f6-4063-8de0-11f2d6a2dd97,DISK], DatanodeInfoWithStorage[127.0.0.1:40008,DS-42f2fc18-7af0-4558-8b2c-0db57fe1af5b,DISK], DatanodeInfoWithStorage[127.0.0.1:40558,DS-ac7ef1d0-37f1-4279-a966-38f257e4783c,DISK], DatanodeInfoWithStorage[127.0.0.1:34222,DS-9208e1ed-712b-4ef7-ac4a-e1c2464deef9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-66954995-172.17.0.16-1598179735654:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43218,DS-9174941f-37c8-4105-a32f-ecd0e94a8dd2,DISK], DatanodeInfoWithStorage[127.0.0.1:35439,DS-9b09286a-51e2-4a01-bd13-c9c4263dc715,DISK], DatanodeInfoWithStorage[127.0.0.1:44403,DS-16be9f85-d65f-488c-8503-4ac32c0b391c,DISK], DatanodeInfoWithStorage[127.0.0.1:36553,DS-cf938de5-7fb2-44ce-801f-46dcbf47edc2,DISK], DatanodeInfoWithStorage[127.0.0.1:33190,DS-1c73c6df-8460-4207-a50a-30087575db07,DISK], DatanodeInfoWithStorage[127.0.0.1:45833,DS-4800fbc4-b631-481a-a3b7-14d596b05083,DISK], DatanodeInfoWithStorage[127.0.0.1:45250,DS-e3dbb669-d965-4524-b1c0-f692cef92f3c,DISK], DatanodeInfoWithStorage[127.0.0.1:36580,DS-52fd1dbb-70a2-49c3-b827-e6988c901bb1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-66954995-172.17.0.16-1598179735654:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43218,DS-9174941f-37c8-4105-a32f-ecd0e94a8dd2,DISK], DatanodeInfoWithStorage[127.0.0.1:35439,DS-9b09286a-51e2-4a01-bd13-c9c4263dc715,DISK], DatanodeInfoWithStorage[127.0.0.1:44403,DS-16be9f85-d65f-488c-8503-4ac32c0b391c,DISK], DatanodeInfoWithStorage[127.0.0.1:36553,DS-cf938de5-7fb2-44ce-801f-46dcbf47edc2,DISK], DatanodeInfoWithStorage[127.0.0.1:33190,DS-1c73c6df-8460-4207-a50a-30087575db07,DISK], DatanodeInfoWithStorage[127.0.0.1:45833,DS-4800fbc4-b631-481a-a3b7-14d596b05083,DISK], DatanodeInfoWithStorage[127.0.0.1:45250,DS-e3dbb669-d965-4524-b1c0-f692cef92f3c,DISK], DatanodeInfoWithStorage[127.0.0.1:36580,DS-52fd1dbb-70a2-49c3-b827-e6988c901bb1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1571171280-172.17.0.16-1598179806900:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45250,DS-857a48f4-9b8b-4ed1-99f7-c0e60a4753c6,DISK], DatanodeInfoWithStorage[127.0.0.1:35730,DS-8efab478-3a59-4ed3-b080-180aa660c2fe,DISK], DatanodeInfoWithStorage[127.0.0.1:36790,DS-7209a1aa-dc4a-42bc-a5d4-1b3e43a839ee,DISK], DatanodeInfoWithStorage[127.0.0.1:34853,DS-39c572d6-3ef5-4c79-a749-0030b0da7fee,DISK], DatanodeInfoWithStorage[127.0.0.1:37330,DS-39429637-8e86-4786-9d7a-4ca5b799786d,DISK], DatanodeInfoWithStorage[127.0.0.1:46728,DS-533aa133-cdc0-45aa-b379-fca626e3e08f,DISK], DatanodeInfoWithStorage[127.0.0.1:36468,DS-177bb4cd-a3e0-43d2-b971-6fdbdea75a15,DISK], DatanodeInfoWithStorage[127.0.0.1:33088,DS-0035e629-926c-47cd-869d-45f8bfaa60bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1571171280-172.17.0.16-1598179806900:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45250,DS-857a48f4-9b8b-4ed1-99f7-c0e60a4753c6,DISK], DatanodeInfoWithStorage[127.0.0.1:35730,DS-8efab478-3a59-4ed3-b080-180aa660c2fe,DISK], DatanodeInfoWithStorage[127.0.0.1:36790,DS-7209a1aa-dc4a-42bc-a5d4-1b3e43a839ee,DISK], DatanodeInfoWithStorage[127.0.0.1:34853,DS-39c572d6-3ef5-4c79-a749-0030b0da7fee,DISK], DatanodeInfoWithStorage[127.0.0.1:37330,DS-39429637-8e86-4786-9d7a-4ca5b799786d,DISK], DatanodeInfoWithStorage[127.0.0.1:46728,DS-533aa133-cdc0-45aa-b379-fca626e3e08f,DISK], DatanodeInfoWithStorage[127.0.0.1:36468,DS-177bb4cd-a3e0-43d2-b971-6fdbdea75a15,DISK], DatanodeInfoWithStorage[127.0.0.1:33088,DS-0035e629-926c-47cd-869d-45f8bfaa60bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-43232096-172.17.0.16-1598180120445:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34319,DS-daf597fd-da15-4da6-870d-a0d740834cf9,DISK], DatanodeInfoWithStorage[127.0.0.1:36412,DS-40f79e75-bf90-4081-8da0-fe30899e7eea,DISK], DatanodeInfoWithStorage[127.0.0.1:40573,DS-8b086304-cfde-483b-8b2b-8092b4de7f8a,DISK], DatanodeInfoWithStorage[127.0.0.1:34565,DS-9bc01aaa-8472-40c8-be7b-4501bff65e91,DISK], DatanodeInfoWithStorage[127.0.0.1:44813,DS-dd0a24fb-510a-4393-bca1-e3ce9286318f,DISK], DatanodeInfoWithStorage[127.0.0.1:38314,DS-606dc140-34ac-4359-a8df-7c6c00c8febf,DISK], DatanodeInfoWithStorage[127.0.0.1:37003,DS-1958e44c-788e-42bf-b4e4-339523cde318,DISK], DatanodeInfoWithStorage[127.0.0.1:42576,DS-649a7388-87e7-49b6-86cf-fba6a29f422b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-43232096-172.17.0.16-1598180120445:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34319,DS-daf597fd-da15-4da6-870d-a0d740834cf9,DISK], DatanodeInfoWithStorage[127.0.0.1:36412,DS-40f79e75-bf90-4081-8da0-fe30899e7eea,DISK], DatanodeInfoWithStorage[127.0.0.1:40573,DS-8b086304-cfde-483b-8b2b-8092b4de7f8a,DISK], DatanodeInfoWithStorage[127.0.0.1:34565,DS-9bc01aaa-8472-40c8-be7b-4501bff65e91,DISK], DatanodeInfoWithStorage[127.0.0.1:44813,DS-dd0a24fb-510a-4393-bca1-e3ce9286318f,DISK], DatanodeInfoWithStorage[127.0.0.1:38314,DS-606dc140-34ac-4359-a8df-7c6c00c8febf,DISK], DatanodeInfoWithStorage[127.0.0.1:37003,DS-1958e44c-788e-42bf-b4e4-339523cde318,DISK], DatanodeInfoWithStorage[127.0.0.1:42576,DS-649a7388-87e7-49b6-86cf-fba6a29f422b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-722667187-172.17.0.16-1598180328740:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45636,DS-6cf0a7b4-55bd-4234-8507-5f6f0cd644a8,DISK], DatanodeInfoWithStorage[127.0.0.1:43995,DS-261a2fef-d4ce-4b72-b32c-3e10bde5167f,DISK], DatanodeInfoWithStorage[127.0.0.1:44176,DS-85ca506f-d0de-4162-8cf8-0b693570caef,DISK], DatanodeInfoWithStorage[127.0.0.1:34918,DS-00e28403-a903-4c71-abc2-0d5166c2a4c5,DISK], DatanodeInfoWithStorage[127.0.0.1:46797,DS-c02111fe-97dc-46ba-9e52-e41ea86e3b45,DISK], DatanodeInfoWithStorage[127.0.0.1:42652,DS-6040e46e-55b9-4b85-84d0-8077241f8a10,DISK], DatanodeInfoWithStorage[127.0.0.1:42969,DS-8f89b4d4-397b-4030-bac0-57ce13fd2bba,DISK], DatanodeInfoWithStorage[127.0.0.1:45572,DS-0cb87360-8139-4458-b3fa-6628a7df78de,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-722667187-172.17.0.16-1598180328740:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45636,DS-6cf0a7b4-55bd-4234-8507-5f6f0cd644a8,DISK], DatanodeInfoWithStorage[127.0.0.1:43995,DS-261a2fef-d4ce-4b72-b32c-3e10bde5167f,DISK], DatanodeInfoWithStorage[127.0.0.1:44176,DS-85ca506f-d0de-4162-8cf8-0b693570caef,DISK], DatanodeInfoWithStorage[127.0.0.1:34918,DS-00e28403-a903-4c71-abc2-0d5166c2a4c5,DISK], DatanodeInfoWithStorage[127.0.0.1:46797,DS-c02111fe-97dc-46ba-9e52-e41ea86e3b45,DISK], DatanodeInfoWithStorage[127.0.0.1:42652,DS-6040e46e-55b9-4b85-84d0-8077241f8a10,DISK], DatanodeInfoWithStorage[127.0.0.1:42969,DS-8f89b4d4-397b-4030-bac0-57ce13fd2bba,DISK], DatanodeInfoWithStorage[127.0.0.1:45572,DS-0cb87360-8139-4458-b3fa-6628a7df78de,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5405
