reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-947035456-172.17.0.9-1598380596187:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34153,DS-215918b0-8555-4f74-9ef6-76c2aee2a936,DISK], DatanodeInfoWithStorage[127.0.0.1:39832,DS-5f47dcab-454a-4d60-bc94-ea9aed2eda46,DISK], DatanodeInfoWithStorage[127.0.0.1:33721,DS-fc94d440-1805-499e-8309-d680fcf57b03,DISK], DatanodeInfoWithStorage[127.0.0.1:34635,DS-78e0004a-58f8-488b-8c22-229054a923c0,DISK], DatanodeInfoWithStorage[127.0.0.1:40878,DS-80b40364-3780-458f-9d03-8c990dce7779,DISK], DatanodeInfoWithStorage[127.0.0.1:45459,DS-d48bdadc-b1e8-47dd-9e51-beff294ff863,DISK], DatanodeInfoWithStorage[127.0.0.1:34579,DS-5ed61360-10a6-4436-a54c-3e2d310a560b,DISK], DatanodeInfoWithStorage[127.0.0.1:42673,DS-5bade2d4-f228-41f8-be97-6ff5ee81956f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-947035456-172.17.0.9-1598380596187:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34153,DS-215918b0-8555-4f74-9ef6-76c2aee2a936,DISK], DatanodeInfoWithStorage[127.0.0.1:39832,DS-5f47dcab-454a-4d60-bc94-ea9aed2eda46,DISK], DatanodeInfoWithStorage[127.0.0.1:33721,DS-fc94d440-1805-499e-8309-d680fcf57b03,DISK], DatanodeInfoWithStorage[127.0.0.1:34635,DS-78e0004a-58f8-488b-8c22-229054a923c0,DISK], DatanodeInfoWithStorage[127.0.0.1:40878,DS-80b40364-3780-458f-9d03-8c990dce7779,DISK], DatanodeInfoWithStorage[127.0.0.1:45459,DS-d48bdadc-b1e8-47dd-9e51-beff294ff863,DISK], DatanodeInfoWithStorage[127.0.0.1:34579,DS-5ed61360-10a6-4436-a54c-3e2d310a560b,DISK], DatanodeInfoWithStorage[127.0.0.1:42673,DS-5bade2d4-f228-41f8-be97-6ff5ee81956f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-88192636-172.17.0.9-1598381174815:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40537,DS-3822dc90-f92e-40d3-bbdf-562d41a4f192,DISK], DatanodeInfoWithStorage[127.0.0.1:32977,DS-15de9e15-2ee0-4c65-afa4-4d40357eec5a,DISK], DatanodeInfoWithStorage[127.0.0.1:40263,DS-cc5765d2-fd16-446c-bc23-c75a296567f0,DISK], DatanodeInfoWithStorage[127.0.0.1:37927,DS-d215ca84-1710-402e-bd8b-70b371f2ecf4,DISK], DatanodeInfoWithStorage[127.0.0.1:39655,DS-612766ce-99a9-4480-8a9c-7b50f3745a24,DISK], DatanodeInfoWithStorage[127.0.0.1:33687,DS-174b54fa-00d5-4c00-9c2f-3d4d04aa7468,DISK], DatanodeInfoWithStorage[127.0.0.1:37849,DS-1ebcf580-2407-477f-859d-1a3823c1805d,DISK], DatanodeInfoWithStorage[127.0.0.1:39564,DS-ae877dfa-37a0-4c80-8264-c840f3cbc9e2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-88192636-172.17.0.9-1598381174815:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40537,DS-3822dc90-f92e-40d3-bbdf-562d41a4f192,DISK], DatanodeInfoWithStorage[127.0.0.1:32977,DS-15de9e15-2ee0-4c65-afa4-4d40357eec5a,DISK], DatanodeInfoWithStorage[127.0.0.1:40263,DS-cc5765d2-fd16-446c-bc23-c75a296567f0,DISK], DatanodeInfoWithStorage[127.0.0.1:37927,DS-d215ca84-1710-402e-bd8b-70b371f2ecf4,DISK], DatanodeInfoWithStorage[127.0.0.1:39655,DS-612766ce-99a9-4480-8a9c-7b50f3745a24,DISK], DatanodeInfoWithStorage[127.0.0.1:33687,DS-174b54fa-00d5-4c00-9c2f-3d4d04aa7468,DISK], DatanodeInfoWithStorage[127.0.0.1:37849,DS-1ebcf580-2407-477f-859d-1a3823c1805d,DISK], DatanodeInfoWithStorage[127.0.0.1:39564,DS-ae877dfa-37a0-4c80-8264-c840f3cbc9e2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1900173579-172.17.0.9-1598381254706:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33228,DS-0d2a25e4-2f58-43bc-a4fb-041b1046fe72,DISK], DatanodeInfoWithStorage[127.0.0.1:41229,DS-ec1ca6e4-5edb-436f-b2e1-6d95e94bdd43,DISK], DatanodeInfoWithStorage[127.0.0.1:43200,DS-60cb569a-10de-4261-8806-6ce195f66557,DISK], DatanodeInfoWithStorage[127.0.0.1:45713,DS-ce1fbc68-462a-4104-a73f-58c2bd78624d,DISK], DatanodeInfoWithStorage[127.0.0.1:34618,DS-7ca3b79b-a875-4c8a-8a9b-d7e065afb17b,DISK], DatanodeInfoWithStorage[127.0.0.1:46420,DS-543a6506-a960-4f42-b1b6-6c1eb10c0887,DISK], DatanodeInfoWithStorage[127.0.0.1:43979,DS-86e9f158-4fe4-43bc-8213-2cefc321dc35,DISK], DatanodeInfoWithStorage[127.0.0.1:41484,DS-7236ac8c-1597-4504-b030-323170b54b5f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1900173579-172.17.0.9-1598381254706:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33228,DS-0d2a25e4-2f58-43bc-a4fb-041b1046fe72,DISK], DatanodeInfoWithStorage[127.0.0.1:41229,DS-ec1ca6e4-5edb-436f-b2e1-6d95e94bdd43,DISK], DatanodeInfoWithStorage[127.0.0.1:43200,DS-60cb569a-10de-4261-8806-6ce195f66557,DISK], DatanodeInfoWithStorage[127.0.0.1:45713,DS-ce1fbc68-462a-4104-a73f-58c2bd78624d,DISK], DatanodeInfoWithStorage[127.0.0.1:34618,DS-7ca3b79b-a875-4c8a-8a9b-d7e065afb17b,DISK], DatanodeInfoWithStorage[127.0.0.1:46420,DS-543a6506-a960-4f42-b1b6-6c1eb10c0887,DISK], DatanodeInfoWithStorage[127.0.0.1:43979,DS-86e9f158-4fe4-43bc-8213-2cefc321dc35,DISK], DatanodeInfoWithStorage[127.0.0.1:41484,DS-7236ac8c-1597-4504-b030-323170b54b5f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1739283576-172.17.0.9-1598381532402:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40450,DS-2d822b49-224e-42da-a2bb-f4e5f860bcf7,DISK], DatanodeInfoWithStorage[127.0.0.1:46180,DS-97c13d81-b252-423f-81fd-3bf8559f8fa8,DISK], DatanodeInfoWithStorage[127.0.0.1:44234,DS-042ff336-d103-4016-9f6a-bb45aab90d1f,DISK], DatanodeInfoWithStorage[127.0.0.1:35611,DS-f32b102d-78e9-4756-ae35-da8fcd327ffb,DISK], DatanodeInfoWithStorage[127.0.0.1:33261,DS-3b9eaabd-8092-4fb6-92bc-086a5603d007,DISK], DatanodeInfoWithStorage[127.0.0.1:38410,DS-a71ab3bf-2199-4c98-90c0-95902bd9c813,DISK], DatanodeInfoWithStorage[127.0.0.1:37687,DS-edff0a5a-6802-44e2-81a3-b23de2d1a716,DISK], DatanodeInfoWithStorage[127.0.0.1:36220,DS-01b2f48e-50ff-49eb-9a43-1133c646e57f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1739283576-172.17.0.9-1598381532402:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40450,DS-2d822b49-224e-42da-a2bb-f4e5f860bcf7,DISK], DatanodeInfoWithStorage[127.0.0.1:46180,DS-97c13d81-b252-423f-81fd-3bf8559f8fa8,DISK], DatanodeInfoWithStorage[127.0.0.1:44234,DS-042ff336-d103-4016-9f6a-bb45aab90d1f,DISK], DatanodeInfoWithStorage[127.0.0.1:35611,DS-f32b102d-78e9-4756-ae35-da8fcd327ffb,DISK], DatanodeInfoWithStorage[127.0.0.1:33261,DS-3b9eaabd-8092-4fb6-92bc-086a5603d007,DISK], DatanodeInfoWithStorage[127.0.0.1:38410,DS-a71ab3bf-2199-4c98-90c0-95902bd9c813,DISK], DatanodeInfoWithStorage[127.0.0.1:37687,DS-edff0a5a-6802-44e2-81a3-b23de2d1a716,DISK], DatanodeInfoWithStorage[127.0.0.1:36220,DS-01b2f48e-50ff-49eb-9a43-1133c646e57f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-68525981-172.17.0.9-1598381712807:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33252,DS-4c21d19b-7dd8-436f-b8f4-e1b5a2cf89cc,DISK], DatanodeInfoWithStorage[127.0.0.1:35956,DS-a9a63e9e-abb8-443a-a576-5b4e0d392025,DISK], DatanodeInfoWithStorage[127.0.0.1:33219,DS-09d8520a-4d2d-47d1-b27b-d13c663e9df1,DISK], DatanodeInfoWithStorage[127.0.0.1:39484,DS-83b0ac0c-b960-4a83-a9c0-b9940912ab4c,DISK], DatanodeInfoWithStorage[127.0.0.1:38153,DS-a66c72ef-2c84-4856-b66e-477435ac1666,DISK], DatanodeInfoWithStorage[127.0.0.1:45964,DS-1a5217a0-da99-4f39-bb54-9a3f283c36aa,DISK], DatanodeInfoWithStorage[127.0.0.1:32966,DS-b3d47a18-a0e6-4fe3-920f-6750b2b7bc4c,DISK], DatanodeInfoWithStorage[127.0.0.1:34631,DS-c4317b61-2b97-4af8-b9c7-8c8f2a63c322,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-68525981-172.17.0.9-1598381712807:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33252,DS-4c21d19b-7dd8-436f-b8f4-e1b5a2cf89cc,DISK], DatanodeInfoWithStorage[127.0.0.1:35956,DS-a9a63e9e-abb8-443a-a576-5b4e0d392025,DISK], DatanodeInfoWithStorage[127.0.0.1:33219,DS-09d8520a-4d2d-47d1-b27b-d13c663e9df1,DISK], DatanodeInfoWithStorage[127.0.0.1:39484,DS-83b0ac0c-b960-4a83-a9c0-b9940912ab4c,DISK], DatanodeInfoWithStorage[127.0.0.1:38153,DS-a66c72ef-2c84-4856-b66e-477435ac1666,DISK], DatanodeInfoWithStorage[127.0.0.1:45964,DS-1a5217a0-da99-4f39-bb54-9a3f283c36aa,DISK], DatanodeInfoWithStorage[127.0.0.1:32966,DS-b3d47a18-a0e6-4fe3-920f-6750b2b7bc4c,DISK], DatanodeInfoWithStorage[127.0.0.1:34631,DS-c4317b61-2b97-4af8-b9c7-8c8f2a63c322,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1264437862-172.17.0.9-1598381751424:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38394,DS-635f2c99-a034-4e52-a410-0b6457791c6c,DISK], DatanodeInfoWithStorage[127.0.0.1:34551,DS-10d37f66-6eb4-4751-a7ca-37fbd59ffd03,DISK], DatanodeInfoWithStorage[127.0.0.1:42912,DS-70c63c58-7050-48eb-ad04-6dd4c9df6672,DISK], DatanodeInfoWithStorage[127.0.0.1:35985,DS-01eadbbd-c669-4958-8e35-fdc980ca486b,DISK], DatanodeInfoWithStorage[127.0.0.1:40378,DS-a497afe3-88bd-43b0-8701-76269a3bd29a,DISK], DatanodeInfoWithStorage[127.0.0.1:41965,DS-f4a27964-be62-4fc6-b1c7-c277a68fc088,DISK], DatanodeInfoWithStorage[127.0.0.1:38368,DS-2dc71ecf-299e-4d68-a7d5-adb68a2242eb,DISK], DatanodeInfoWithStorage[127.0.0.1:34754,DS-8ff9b870-2d25-414f-becf-544d55014dfa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1264437862-172.17.0.9-1598381751424:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38394,DS-635f2c99-a034-4e52-a410-0b6457791c6c,DISK], DatanodeInfoWithStorage[127.0.0.1:34551,DS-10d37f66-6eb4-4751-a7ca-37fbd59ffd03,DISK], DatanodeInfoWithStorage[127.0.0.1:42912,DS-70c63c58-7050-48eb-ad04-6dd4c9df6672,DISK], DatanodeInfoWithStorage[127.0.0.1:35985,DS-01eadbbd-c669-4958-8e35-fdc980ca486b,DISK], DatanodeInfoWithStorage[127.0.0.1:40378,DS-a497afe3-88bd-43b0-8701-76269a3bd29a,DISK], DatanodeInfoWithStorage[127.0.0.1:41965,DS-f4a27964-be62-4fc6-b1c7-c277a68fc088,DISK], DatanodeInfoWithStorage[127.0.0.1:38368,DS-2dc71ecf-299e-4d68-a7d5-adb68a2242eb,DISK], DatanodeInfoWithStorage[127.0.0.1:34754,DS-8ff9b870-2d25-414f-becf-544d55014dfa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-818602484-172.17.0.9-1598381828925:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37155,DS-89a06231-97a3-4e8d-a5e2-37a7cdccb191,DISK], DatanodeInfoWithStorage[127.0.0.1:46242,DS-2c87d183-8093-49f1-b00d-394efaa695c6,DISK], DatanodeInfoWithStorage[127.0.0.1:35682,DS-6667174e-f6ef-4168-8dc5-64bbddfdb5e9,DISK], DatanodeInfoWithStorage[127.0.0.1:36832,DS-07b7a191-71a7-44ae-b157-fe2773dee383,DISK], DatanodeInfoWithStorage[127.0.0.1:46510,DS-337851d6-bc1e-4507-aac1-a02c2dd5a5ab,DISK], DatanodeInfoWithStorage[127.0.0.1:36225,DS-aa6813b9-c9dd-4215-ac93-f3d77dfdafa7,DISK], DatanodeInfoWithStorage[127.0.0.1:44510,DS-329ee085-3224-42d4-99b4-6d3e21c6fc2d,DISK], DatanodeInfoWithStorage[127.0.0.1:39954,DS-e5c90f2c-96e2-4e5e-b27c-4434d4488d56,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-818602484-172.17.0.9-1598381828925:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37155,DS-89a06231-97a3-4e8d-a5e2-37a7cdccb191,DISK], DatanodeInfoWithStorage[127.0.0.1:46242,DS-2c87d183-8093-49f1-b00d-394efaa695c6,DISK], DatanodeInfoWithStorage[127.0.0.1:35682,DS-6667174e-f6ef-4168-8dc5-64bbddfdb5e9,DISK], DatanodeInfoWithStorage[127.0.0.1:36832,DS-07b7a191-71a7-44ae-b157-fe2773dee383,DISK], DatanodeInfoWithStorage[127.0.0.1:46510,DS-337851d6-bc1e-4507-aac1-a02c2dd5a5ab,DISK], DatanodeInfoWithStorage[127.0.0.1:36225,DS-aa6813b9-c9dd-4215-ac93-f3d77dfdafa7,DISK], DatanodeInfoWithStorage[127.0.0.1:44510,DS-329ee085-3224-42d4-99b4-6d3e21c6fc2d,DISK], DatanodeInfoWithStorage[127.0.0.1:39954,DS-e5c90f2c-96e2-4e5e-b27c-4434d4488d56,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-370892247-172.17.0.9-1598382095940:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42757,DS-78aea167-29af-4716-8fc1-1c70b00e24e7,DISK], DatanodeInfoWithStorage[127.0.0.1:44747,DS-56762003-2dd3-4e25-9dbf-1559a652ccb6,DISK], DatanodeInfoWithStorage[127.0.0.1:44541,DS-1ae06fb2-61e7-496f-b530-89072eb58f0c,DISK], DatanodeInfoWithStorage[127.0.0.1:38062,DS-ddc3ece6-0151-429f-a235-6f7c103caca4,DISK], DatanodeInfoWithStorage[127.0.0.1:46875,DS-cdfa47fd-e5d8-4db5-9dd3-b176e853780e,DISK], DatanodeInfoWithStorage[127.0.0.1:45908,DS-df4a50c2-2773-41e8-8454-8f157579b4a0,DISK], DatanodeInfoWithStorage[127.0.0.1:44834,DS-dc1102d4-1436-4bb9-9e9f-a7e800ad49fd,DISK], DatanodeInfoWithStorage[127.0.0.1:42864,DS-7bee98a3-9dc7-459f-b2ff-4079b3647874,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-370892247-172.17.0.9-1598382095940:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42757,DS-78aea167-29af-4716-8fc1-1c70b00e24e7,DISK], DatanodeInfoWithStorage[127.0.0.1:44747,DS-56762003-2dd3-4e25-9dbf-1559a652ccb6,DISK], DatanodeInfoWithStorage[127.0.0.1:44541,DS-1ae06fb2-61e7-496f-b530-89072eb58f0c,DISK], DatanodeInfoWithStorage[127.0.0.1:38062,DS-ddc3ece6-0151-429f-a235-6f7c103caca4,DISK], DatanodeInfoWithStorage[127.0.0.1:46875,DS-cdfa47fd-e5d8-4db5-9dd3-b176e853780e,DISK], DatanodeInfoWithStorage[127.0.0.1:45908,DS-df4a50c2-2773-41e8-8454-8f157579b4a0,DISK], DatanodeInfoWithStorage[127.0.0.1:44834,DS-dc1102d4-1436-4bb9-9e9f-a7e800ad49fd,DISK], DatanodeInfoWithStorage[127.0.0.1:42864,DS-7bee98a3-9dc7-459f-b2ff-4079b3647874,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1105065031-172.17.0.9-1598382345425:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34075,DS-da639a58-62f7-4a41-9363-487408c234b8,DISK], DatanodeInfoWithStorage[127.0.0.1:45555,DS-848884ed-e37f-41b5-a015-86d6601a3cbe,DISK], DatanodeInfoWithStorage[127.0.0.1:36246,DS-807a5b57-f936-4d1c-9a8b-c542a6bcc7ff,DISK], DatanodeInfoWithStorage[127.0.0.1:45000,DS-e91c57aa-b055-40a3-89b1-a2042729f207,DISK], DatanodeInfoWithStorage[127.0.0.1:44818,DS-81719fa2-d366-4152-9623-8237b1fa82a2,DISK], DatanodeInfoWithStorage[127.0.0.1:35278,DS-8f03a2cf-1425-4549-96de-a1fb122a9aef,DISK], DatanodeInfoWithStorage[127.0.0.1:39505,DS-538afce0-284b-43e8-a235-773bd88945a7,DISK], DatanodeInfoWithStorage[127.0.0.1:36369,DS-00883625-6083-41e7-82da-2144fbd0c4e8,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1105065031-172.17.0.9-1598382345425:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34075,DS-da639a58-62f7-4a41-9363-487408c234b8,DISK], DatanodeInfoWithStorage[127.0.0.1:45555,DS-848884ed-e37f-41b5-a015-86d6601a3cbe,DISK], DatanodeInfoWithStorage[127.0.0.1:36246,DS-807a5b57-f936-4d1c-9a8b-c542a6bcc7ff,DISK], DatanodeInfoWithStorage[127.0.0.1:45000,DS-e91c57aa-b055-40a3-89b1-a2042729f207,DISK], DatanodeInfoWithStorage[127.0.0.1:44818,DS-81719fa2-d366-4152-9623-8237b1fa82a2,DISK], DatanodeInfoWithStorage[127.0.0.1:35278,DS-8f03a2cf-1425-4549-96de-a1fb122a9aef,DISK], DatanodeInfoWithStorage[127.0.0.1:39505,DS-538afce0-284b-43e8-a235-773bd88945a7,DISK], DatanodeInfoWithStorage[127.0.0.1:36369,DS-00883625-6083-41e7-82da-2144fbd0c4e8,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-711758764-172.17.0.9-1598382502167:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40571,DS-96019df2-52fe-421d-b731-1ec7deafe3e4,DISK], DatanodeInfoWithStorage[127.0.0.1:42379,DS-d8e542d6-fa48-4a5a-b920-7b4b11fface0,DISK], DatanodeInfoWithStorage[127.0.0.1:34332,DS-64d1b66e-1215-4f24-85e3-bb7a730dcc04,DISK], DatanodeInfoWithStorage[127.0.0.1:39134,DS-fd06f3f5-51cd-4068-a515-0ed90c261552,DISK], DatanodeInfoWithStorage[127.0.0.1:32962,DS-32fbe00d-92f8-47e8-9cc3-a7cd9012dedf,DISK], DatanodeInfoWithStorage[127.0.0.1:36534,DS-5bd5c3fc-f85a-4060-84f6-fd6300f75502,DISK], DatanodeInfoWithStorage[127.0.0.1:33928,DS-6299f97f-d6d7-4652-a799-f1fa68587651,DISK], DatanodeInfoWithStorage[127.0.0.1:37201,DS-c450ac9d-c35d-4e27-bea5-c6550a6ed2c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-711758764-172.17.0.9-1598382502167:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40571,DS-96019df2-52fe-421d-b731-1ec7deafe3e4,DISK], DatanodeInfoWithStorage[127.0.0.1:42379,DS-d8e542d6-fa48-4a5a-b920-7b4b11fface0,DISK], DatanodeInfoWithStorage[127.0.0.1:34332,DS-64d1b66e-1215-4f24-85e3-bb7a730dcc04,DISK], DatanodeInfoWithStorage[127.0.0.1:39134,DS-fd06f3f5-51cd-4068-a515-0ed90c261552,DISK], DatanodeInfoWithStorage[127.0.0.1:32962,DS-32fbe00d-92f8-47e8-9cc3-a7cd9012dedf,DISK], DatanodeInfoWithStorage[127.0.0.1:36534,DS-5bd5c3fc-f85a-4060-84f6-fd6300f75502,DISK], DatanodeInfoWithStorage[127.0.0.1:33928,DS-6299f97f-d6d7-4652-a799-f1fa68587651,DISK], DatanodeInfoWithStorage[127.0.0.1:37201,DS-c450ac9d-c35d-4e27-bea5-c6550a6ed2c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1031773146-172.17.0.9-1598382753897:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38648,DS-65f56384-3bd2-440f-b2c4-0f166ebcf684,DISK], DatanodeInfoWithStorage[127.0.0.1:42211,DS-e87a0fb4-f90b-487a-8a5f-2d7e38a00182,DISK], DatanodeInfoWithStorage[127.0.0.1:34113,DS-a10e3e93-fda0-42be-8168-2af171eaca6b,DISK], DatanodeInfoWithStorage[127.0.0.1:36524,DS-e4860e73-06ce-4fd4-ad4a-685cb8d8400e,DISK], DatanodeInfoWithStorage[127.0.0.1:45272,DS-f75e808d-3389-4ddc-a00e-f6a5113fb2b2,DISK], DatanodeInfoWithStorage[127.0.0.1:45495,DS-b3fcde56-4267-4076-be5b-1272a0b03cdd,DISK], DatanodeInfoWithStorage[127.0.0.1:36782,DS-6bc3c510-faa4-4526-963b-bdf641b9d611,DISK], DatanodeInfoWithStorage[127.0.0.1:37728,DS-b758b758-2ccb-44b8-b023-13a7f4565986,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1031773146-172.17.0.9-1598382753897:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38648,DS-65f56384-3bd2-440f-b2c4-0f166ebcf684,DISK], DatanodeInfoWithStorage[127.0.0.1:42211,DS-e87a0fb4-f90b-487a-8a5f-2d7e38a00182,DISK], DatanodeInfoWithStorage[127.0.0.1:34113,DS-a10e3e93-fda0-42be-8168-2af171eaca6b,DISK], DatanodeInfoWithStorage[127.0.0.1:36524,DS-e4860e73-06ce-4fd4-ad4a-685cb8d8400e,DISK], DatanodeInfoWithStorage[127.0.0.1:45272,DS-f75e808d-3389-4ddc-a00e-f6a5113fb2b2,DISK], DatanodeInfoWithStorage[127.0.0.1:45495,DS-b3fcde56-4267-4076-be5b-1272a0b03cdd,DISK], DatanodeInfoWithStorage[127.0.0.1:36782,DS-6bc3c510-faa4-4526-963b-bdf641b9d611,DISK], DatanodeInfoWithStorage[127.0.0.1:37728,DS-b758b758-2ccb-44b8-b023-13a7f4565986,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-472953984-172.17.0.9-1598382864796:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34532,DS-272daef5-11a8-40b5-b7d0-d55be6106c99,DISK], DatanodeInfoWithStorage[127.0.0.1:40657,DS-db944879-365d-4e46-ab55-fff755e41ed6,DISK], DatanodeInfoWithStorage[127.0.0.1:43445,DS-8347f313-6eb5-4ec5-963a-3b4c03f31e44,DISK], DatanodeInfoWithStorage[127.0.0.1:43865,DS-f03d1d14-5239-4262-8c84-130b18701899,DISK], DatanodeInfoWithStorage[127.0.0.1:39398,DS-73fd887f-d5e0-421c-9bd5-8f4b57bb48ea,DISK], DatanodeInfoWithStorage[127.0.0.1:35517,DS-bdc180e6-33de-4445-806a-c5458aa40c1e,DISK], DatanodeInfoWithStorage[127.0.0.1:45270,DS-2e226102-c402-443b-8660-d46b780fe27f,DISK], DatanodeInfoWithStorage[127.0.0.1:40770,DS-9fd78180-858e-4f09-ab31-87e832f72a8d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-472953984-172.17.0.9-1598382864796:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34532,DS-272daef5-11a8-40b5-b7d0-d55be6106c99,DISK], DatanodeInfoWithStorage[127.0.0.1:40657,DS-db944879-365d-4e46-ab55-fff755e41ed6,DISK], DatanodeInfoWithStorage[127.0.0.1:43445,DS-8347f313-6eb5-4ec5-963a-3b4c03f31e44,DISK], DatanodeInfoWithStorage[127.0.0.1:43865,DS-f03d1d14-5239-4262-8c84-130b18701899,DISK], DatanodeInfoWithStorage[127.0.0.1:39398,DS-73fd887f-d5e0-421c-9bd5-8f4b57bb48ea,DISK], DatanodeInfoWithStorage[127.0.0.1:35517,DS-bdc180e6-33de-4445-806a-c5458aa40c1e,DISK], DatanodeInfoWithStorage[127.0.0.1:45270,DS-2e226102-c402-443b-8660-d46b780fe27f,DISK], DatanodeInfoWithStorage[127.0.0.1:40770,DS-9fd78180-858e-4f09-ab31-87e832f72a8d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-963202791-172.17.0.9-1598382947141:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42702,DS-da7f81c8-8963-479a-ace8-b257b22bdd96,DISK], DatanodeInfoWithStorage[127.0.0.1:38147,DS-a7c8d40e-410a-4ebd-8e74-7c560b78e37e,DISK], DatanodeInfoWithStorage[127.0.0.1:43274,DS-3481f527-f424-44dc-930d-bd6a41616891,DISK], DatanodeInfoWithStorage[127.0.0.1:33028,DS-c980e373-f4c8-43a8-bf8c-5afb6744c5c6,DISK], DatanodeInfoWithStorage[127.0.0.1:46468,DS-43c9e458-b7ee-4cbc-a60a-a8e7a0fddd9a,DISK], DatanodeInfoWithStorage[127.0.0.1:41517,DS-dc1f1358-be84-45ce-9bf1-c1d5ccb15b4e,DISK], DatanodeInfoWithStorage[127.0.0.1:35383,DS-078e2174-6e9c-42d7-abcb-f485dcb2f82a,DISK], DatanodeInfoWithStorage[127.0.0.1:45139,DS-4658a4c9-8073-4fd2-a841-4b2901dbc10b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-963202791-172.17.0.9-1598382947141:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42702,DS-da7f81c8-8963-479a-ace8-b257b22bdd96,DISK], DatanodeInfoWithStorage[127.0.0.1:38147,DS-a7c8d40e-410a-4ebd-8e74-7c560b78e37e,DISK], DatanodeInfoWithStorage[127.0.0.1:43274,DS-3481f527-f424-44dc-930d-bd6a41616891,DISK], DatanodeInfoWithStorage[127.0.0.1:33028,DS-c980e373-f4c8-43a8-bf8c-5afb6744c5c6,DISK], DatanodeInfoWithStorage[127.0.0.1:46468,DS-43c9e458-b7ee-4cbc-a60a-a8e7a0fddd9a,DISK], DatanodeInfoWithStorage[127.0.0.1:41517,DS-dc1f1358-be84-45ce-9bf1-c1d5ccb15b4e,DISK], DatanodeInfoWithStorage[127.0.0.1:35383,DS-078e2174-6e9c-42d7-abcb-f485dcb2f82a,DISK], DatanodeInfoWithStorage[127.0.0.1:45139,DS-4658a4c9-8073-4fd2-a841-4b2901dbc10b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-255007659-172.17.0.9-1598383105487:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45521,DS-4ec5b3a7-b8ff-4633-908c-3429242c35fa,DISK], DatanodeInfoWithStorage[127.0.0.1:36746,DS-75f55622-93e1-4c70-8a52-6a53a4842bde,DISK], DatanodeInfoWithStorage[127.0.0.1:39795,DS-b261dd8b-5f55-429f-b8a6-99452ac66dec,DISK], DatanodeInfoWithStorage[127.0.0.1:45394,DS-7b2d5c2e-1ad5-4f16-9008-9684cb145a06,DISK], DatanodeInfoWithStorage[127.0.0.1:42634,DS-9ee98a2e-daa4-4080-a3fc-84c5c4db7ae5,DISK], DatanodeInfoWithStorage[127.0.0.1:46546,DS-33d40778-9a00-48dc-bffa-3e916d318ce7,DISK], DatanodeInfoWithStorage[127.0.0.1:41703,DS-66cabb3f-c8c2-41ba-b1b7-71fdea9b3066,DISK], DatanodeInfoWithStorage[127.0.0.1:46860,DS-404c903b-8c58-4805-ab4d-a74120686ee0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-255007659-172.17.0.9-1598383105487:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45521,DS-4ec5b3a7-b8ff-4633-908c-3429242c35fa,DISK], DatanodeInfoWithStorage[127.0.0.1:36746,DS-75f55622-93e1-4c70-8a52-6a53a4842bde,DISK], DatanodeInfoWithStorage[127.0.0.1:39795,DS-b261dd8b-5f55-429f-b8a6-99452ac66dec,DISK], DatanodeInfoWithStorage[127.0.0.1:45394,DS-7b2d5c2e-1ad5-4f16-9008-9684cb145a06,DISK], DatanodeInfoWithStorage[127.0.0.1:42634,DS-9ee98a2e-daa4-4080-a3fc-84c5c4db7ae5,DISK], DatanodeInfoWithStorage[127.0.0.1:46546,DS-33d40778-9a00-48dc-bffa-3e916d318ce7,DISK], DatanodeInfoWithStorage[127.0.0.1:41703,DS-66cabb3f-c8c2-41ba-b1b7-71fdea9b3066,DISK], DatanodeInfoWithStorage[127.0.0.1:46860,DS-404c903b-8c58-4805-ab4d-a74120686ee0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-547362325-172.17.0.9-1598383173044:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40163,DS-e857aae4-7ba3-4edc-bc0d-543b0fa3385d,DISK], DatanodeInfoWithStorage[127.0.0.1:39558,DS-cc46a2fa-39b1-4dae-bcf8-35fdbe089f7e,DISK], DatanodeInfoWithStorage[127.0.0.1:35532,DS-1b619bd1-7a0e-4fbe-baa3-e8f82e7a815e,DISK], DatanodeInfoWithStorage[127.0.0.1:34033,DS-8ace867c-d037-465f-b0d8-5d40da8e800c,DISK], DatanodeInfoWithStorage[127.0.0.1:36333,DS-5fe3a237-da77-4c50-b42e-7ac33aefab05,DISK], DatanodeInfoWithStorage[127.0.0.1:45467,DS-10982001-3f10-44c3-a8a1-f7a96e5508e7,DISK], DatanodeInfoWithStorage[127.0.0.1:42652,DS-b5e77cd4-9cac-49d6-be4f-2157f422434c,DISK], DatanodeInfoWithStorage[127.0.0.1:38703,DS-80c9eedf-72b7-4626-bfe6-7b492e5b4218,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-547362325-172.17.0.9-1598383173044:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40163,DS-e857aae4-7ba3-4edc-bc0d-543b0fa3385d,DISK], DatanodeInfoWithStorage[127.0.0.1:39558,DS-cc46a2fa-39b1-4dae-bcf8-35fdbe089f7e,DISK], DatanodeInfoWithStorage[127.0.0.1:35532,DS-1b619bd1-7a0e-4fbe-baa3-e8f82e7a815e,DISK], DatanodeInfoWithStorage[127.0.0.1:34033,DS-8ace867c-d037-465f-b0d8-5d40da8e800c,DISK], DatanodeInfoWithStorage[127.0.0.1:36333,DS-5fe3a237-da77-4c50-b42e-7ac33aefab05,DISK], DatanodeInfoWithStorage[127.0.0.1:45467,DS-10982001-3f10-44c3-a8a1-f7a96e5508e7,DISK], DatanodeInfoWithStorage[127.0.0.1:42652,DS-b5e77cd4-9cac-49d6-be4f-2157f422434c,DISK], DatanodeInfoWithStorage[127.0.0.1:38703,DS-80c9eedf-72b7-4626-bfe6-7b492e5b4218,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-162659440-172.17.0.9-1598383337355:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37647,DS-7fb890dc-0dfe-42dc-ac4e-31bbfa07cfc7,DISK], DatanodeInfoWithStorage[127.0.0.1:33189,DS-d8ecbedc-5d88-4042-bd14-7b3e7197b0b8,DISK], DatanodeInfoWithStorage[127.0.0.1:36896,DS-fd886d6d-9d45-43a4-9572-df609d7fce3b,DISK], DatanodeInfoWithStorage[127.0.0.1:41552,DS-80be54cf-e406-44e9-b72d-c4624e4d60c3,DISK], DatanodeInfoWithStorage[127.0.0.1:42463,DS-2fb2f14d-c37d-44f9-a5c7-9928ed689bfa,DISK], DatanodeInfoWithStorage[127.0.0.1:33644,DS-c5688e81-681a-48b2-af29-3888d596fabf,DISK], DatanodeInfoWithStorage[127.0.0.1:35231,DS-db7ba23f-7965-4eb8-aabe-9e47f0ef96d4,DISK], DatanodeInfoWithStorage[127.0.0.1:42580,DS-cd60d007-c75b-4323-a269-52c4edb57258,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-162659440-172.17.0.9-1598383337355:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37647,DS-7fb890dc-0dfe-42dc-ac4e-31bbfa07cfc7,DISK], DatanodeInfoWithStorage[127.0.0.1:33189,DS-d8ecbedc-5d88-4042-bd14-7b3e7197b0b8,DISK], DatanodeInfoWithStorage[127.0.0.1:36896,DS-fd886d6d-9d45-43a4-9572-df609d7fce3b,DISK], DatanodeInfoWithStorage[127.0.0.1:41552,DS-80be54cf-e406-44e9-b72d-c4624e4d60c3,DISK], DatanodeInfoWithStorage[127.0.0.1:42463,DS-2fb2f14d-c37d-44f9-a5c7-9928ed689bfa,DISK], DatanodeInfoWithStorage[127.0.0.1:33644,DS-c5688e81-681a-48b2-af29-3888d596fabf,DISK], DatanodeInfoWithStorage[127.0.0.1:35231,DS-db7ba23f-7965-4eb8-aabe-9e47f0ef96d4,DISK], DatanodeInfoWithStorage[127.0.0.1:42580,DS-cd60d007-c75b-4323-a269-52c4edb57258,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-764196179-172.17.0.9-1598383458089:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45958,DS-21d0bfcf-b48e-486a-a9b4-6be7752da59a,DISK], DatanodeInfoWithStorage[127.0.0.1:34228,DS-2930bb57-d650-476b-a429-518ec60ee59d,DISK], DatanodeInfoWithStorage[127.0.0.1:44768,DS-12250dfe-9bca-4e54-92d4-c49adfaa2164,DISK], DatanodeInfoWithStorage[127.0.0.1:44942,DS-29a57b1e-3203-44f1-9f27-f214092c5926,DISK], DatanodeInfoWithStorage[127.0.0.1:43800,DS-81af1e66-e98c-4547-ae70-212833c6bda6,DISK], DatanodeInfoWithStorage[127.0.0.1:42892,DS-727bafb3-0be4-4c8d-9e74-55655c2d71ef,DISK], DatanodeInfoWithStorage[127.0.0.1:36773,DS-7f25737d-4215-4145-a325-8d29a42e1edf,DISK], DatanodeInfoWithStorage[127.0.0.1:39713,DS-a16fee6a-6d2f-4119-9c67-d009b999378b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-764196179-172.17.0.9-1598383458089:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45958,DS-21d0bfcf-b48e-486a-a9b4-6be7752da59a,DISK], DatanodeInfoWithStorage[127.0.0.1:34228,DS-2930bb57-d650-476b-a429-518ec60ee59d,DISK], DatanodeInfoWithStorage[127.0.0.1:44768,DS-12250dfe-9bca-4e54-92d4-c49adfaa2164,DISK], DatanodeInfoWithStorage[127.0.0.1:44942,DS-29a57b1e-3203-44f1-9f27-f214092c5926,DISK], DatanodeInfoWithStorage[127.0.0.1:43800,DS-81af1e66-e98c-4547-ae70-212833c6bda6,DISK], DatanodeInfoWithStorage[127.0.0.1:42892,DS-727bafb3-0be4-4c8d-9e74-55655c2d71ef,DISK], DatanodeInfoWithStorage[127.0.0.1:36773,DS-7f25737d-4215-4145-a325-8d29a42e1edf,DISK], DatanodeInfoWithStorage[127.0.0.1:39713,DS-a16fee6a-6d2f-4119-9c67-d009b999378b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1241059683-172.17.0.9-1598383632707:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36284,DS-918772a6-8f0c-4a5f-85d8-fc68ddbcc52a,DISK], DatanodeInfoWithStorage[127.0.0.1:34491,DS-b2dc2fde-50e9-4164-9ab6-6502612c3855,DISK], DatanodeInfoWithStorage[127.0.0.1:39866,DS-49c930a3-55f2-421d-b43a-49b2ed57a0ee,DISK], DatanodeInfoWithStorage[127.0.0.1:33412,DS-074f14ae-f3f9-4d3e-acd7-d4742033f268,DISK], DatanodeInfoWithStorage[127.0.0.1:35225,DS-e81ac7a5-8849-418d-b7c7-c5707ad18eed,DISK], DatanodeInfoWithStorage[127.0.0.1:32826,DS-5f9896a0-936e-4fe3-b4bb-940b868c3578,DISK], DatanodeInfoWithStorage[127.0.0.1:34881,DS-c201c5c6-2085-4a3f-83e0-1df32ef1f3a1,DISK], DatanodeInfoWithStorage[127.0.0.1:46228,DS-aa5139d2-2f44-44e9-9df5-c923e7754b97,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1241059683-172.17.0.9-1598383632707:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36284,DS-918772a6-8f0c-4a5f-85d8-fc68ddbcc52a,DISK], DatanodeInfoWithStorage[127.0.0.1:34491,DS-b2dc2fde-50e9-4164-9ab6-6502612c3855,DISK], DatanodeInfoWithStorage[127.0.0.1:39866,DS-49c930a3-55f2-421d-b43a-49b2ed57a0ee,DISK], DatanodeInfoWithStorage[127.0.0.1:33412,DS-074f14ae-f3f9-4d3e-acd7-d4742033f268,DISK], DatanodeInfoWithStorage[127.0.0.1:35225,DS-e81ac7a5-8849-418d-b7c7-c5707ad18eed,DISK], DatanodeInfoWithStorage[127.0.0.1:32826,DS-5f9896a0-936e-4fe3-b4bb-940b868c3578,DISK], DatanodeInfoWithStorage[127.0.0.1:34881,DS-c201c5c6-2085-4a3f-83e0-1df32ef1f3a1,DISK], DatanodeInfoWithStorage[127.0.0.1:46228,DS-aa5139d2-2f44-44e9-9df5-c923e7754b97,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1119330355-172.17.0.9-1598383813173:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44771,DS-dddbca56-e971-4f3b-9694-1f18f7a40814,DISK], DatanodeInfoWithStorage[127.0.0.1:43428,DS-7d228a8d-e39f-46ab-9400-af35f887d51b,DISK], DatanodeInfoWithStorage[127.0.0.1:34898,DS-f055e303-d232-434d-9917-d4a5474bdbec,DISK], DatanodeInfoWithStorage[127.0.0.1:32811,DS-ddc53698-2c0c-46ec-b9bd-65de029800d9,DISK], DatanodeInfoWithStorage[127.0.0.1:45015,DS-a858365c-6658-4dad-aef4-ac943902611b,DISK], DatanodeInfoWithStorage[127.0.0.1:32921,DS-ac242b17-de9f-44cb-a653-3814f6015984,DISK], DatanodeInfoWithStorage[127.0.0.1:43147,DS-10082fca-f830-4795-a681-80958ff4e136,DISK], DatanodeInfoWithStorage[127.0.0.1:33308,DS-7c7d845f-b396-4442-ba1b-b3acfbce5be2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1119330355-172.17.0.9-1598383813173:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44771,DS-dddbca56-e971-4f3b-9694-1f18f7a40814,DISK], DatanodeInfoWithStorage[127.0.0.1:43428,DS-7d228a8d-e39f-46ab-9400-af35f887d51b,DISK], DatanodeInfoWithStorage[127.0.0.1:34898,DS-f055e303-d232-434d-9917-d4a5474bdbec,DISK], DatanodeInfoWithStorage[127.0.0.1:32811,DS-ddc53698-2c0c-46ec-b9bd-65de029800d9,DISK], DatanodeInfoWithStorage[127.0.0.1:45015,DS-a858365c-6658-4dad-aef4-ac943902611b,DISK], DatanodeInfoWithStorage[127.0.0.1:32921,DS-ac242b17-de9f-44cb-a653-3814f6015984,DISK], DatanodeInfoWithStorage[127.0.0.1:43147,DS-10082fca-f830-4795-a681-80958ff4e136,DISK], DatanodeInfoWithStorage[127.0.0.1:33308,DS-7c7d845f-b396-4442-ba1b-b3acfbce5be2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1312258198-172.17.0.9-1598383923240:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35904,DS-23cff71a-90a4-4822-8dbb-752a081bbbed,DISK], DatanodeInfoWithStorage[127.0.0.1:33930,DS-62ac192c-ce4f-4fbc-9a70-3c1d9ba0dea4,DISK], DatanodeInfoWithStorage[127.0.0.1:46570,DS-4a157aab-913c-4567-976c-46c6dce9330f,DISK], DatanodeInfoWithStorage[127.0.0.1:44841,DS-142d1910-a49e-45f1-995e-00976bbfe4ac,DISK], DatanodeInfoWithStorage[127.0.0.1:40910,DS-1fc93888-fde8-4ad9-a9f1-2240e98c6484,DISK], DatanodeInfoWithStorage[127.0.0.1:38120,DS-90abdd05-f84a-43f0-b810-e010c12b53e7,DISK], DatanodeInfoWithStorage[127.0.0.1:34952,DS-7e2f30c5-df6e-4de3-a3df-9111e9c23e7f,DISK], DatanodeInfoWithStorage[127.0.0.1:36722,DS-954ff6e3-a709-43a2-81f7-ef2952a93885,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1312258198-172.17.0.9-1598383923240:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35904,DS-23cff71a-90a4-4822-8dbb-752a081bbbed,DISK], DatanodeInfoWithStorage[127.0.0.1:33930,DS-62ac192c-ce4f-4fbc-9a70-3c1d9ba0dea4,DISK], DatanodeInfoWithStorage[127.0.0.1:46570,DS-4a157aab-913c-4567-976c-46c6dce9330f,DISK], DatanodeInfoWithStorage[127.0.0.1:44841,DS-142d1910-a49e-45f1-995e-00976bbfe4ac,DISK], DatanodeInfoWithStorage[127.0.0.1:40910,DS-1fc93888-fde8-4ad9-a9f1-2240e98c6484,DISK], DatanodeInfoWithStorage[127.0.0.1:38120,DS-90abdd05-f84a-43f0-b810-e010c12b53e7,DISK], DatanodeInfoWithStorage[127.0.0.1:34952,DS-7e2f30c5-df6e-4de3-a3df-9111e9c23e7f,DISK], DatanodeInfoWithStorage[127.0.0.1:36722,DS-954ff6e3-a709-43a2-81f7-ef2952a93885,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1294852310-172.17.0.9-1598384081906:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46645,DS-28666300-5a87-418e-9df9-2509ff6c50f2,DISK], DatanodeInfoWithStorage[127.0.0.1:34601,DS-ebdec734-1121-4a81-bd8c-bcb71c033b74,DISK], DatanodeInfoWithStorage[127.0.0.1:34062,DS-1b55bd66-cbec-419b-b982-027256a6f2ad,DISK], DatanodeInfoWithStorage[127.0.0.1:45346,DS-3925b482-1e2f-4b83-9372-decef2db9e1a,DISK], DatanodeInfoWithStorage[127.0.0.1:41254,DS-4105027f-f5da-4b38-a70d-151001e436ec,DISK], DatanodeInfoWithStorage[127.0.0.1:41859,DS-779bdc50-99d6-4b56-8965-7c56407a98f2,DISK], DatanodeInfoWithStorage[127.0.0.1:36173,DS-f75d1bf1-7eaa-47e8-89e3-77a33eebf640,DISK], DatanodeInfoWithStorage[127.0.0.1:36536,DS-24df91e3-6806-48ac-84f6-b8ccd2cffd01,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1294852310-172.17.0.9-1598384081906:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46645,DS-28666300-5a87-418e-9df9-2509ff6c50f2,DISK], DatanodeInfoWithStorage[127.0.0.1:34601,DS-ebdec734-1121-4a81-bd8c-bcb71c033b74,DISK], DatanodeInfoWithStorage[127.0.0.1:34062,DS-1b55bd66-cbec-419b-b982-027256a6f2ad,DISK], DatanodeInfoWithStorage[127.0.0.1:45346,DS-3925b482-1e2f-4b83-9372-decef2db9e1a,DISK], DatanodeInfoWithStorage[127.0.0.1:41254,DS-4105027f-f5da-4b38-a70d-151001e436ec,DISK], DatanodeInfoWithStorage[127.0.0.1:41859,DS-779bdc50-99d6-4b56-8965-7c56407a98f2,DISK], DatanodeInfoWithStorage[127.0.0.1:36173,DS-f75d1bf1-7eaa-47e8-89e3-77a33eebf640,DISK], DatanodeInfoWithStorage[127.0.0.1:36536,DS-24df91e3-6806-48ac-84f6-b8ccd2cffd01,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1053251380-172.17.0.9-1598384155979:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42919,DS-ce23f27b-6eeb-430c-a4d2-2df7c0680680,DISK], DatanodeInfoWithStorage[127.0.0.1:45271,DS-420ef4de-ab60-4798-9416-17def41faec4,DISK], DatanodeInfoWithStorage[127.0.0.1:45008,DS-269eb20b-0d3a-43eb-9f2f-5bb0e3389f94,DISK], DatanodeInfoWithStorage[127.0.0.1:46874,DS-843c3f41-103f-4086-8261-3a2c6a5566a0,DISK], DatanodeInfoWithStorage[127.0.0.1:44853,DS-78e6cb2e-4704-4f07-94b5-af78a69e5ca2,DISK], DatanodeInfoWithStorage[127.0.0.1:37683,DS-ec0f6004-390c-4bcf-af93-789403c214a4,DISK], DatanodeInfoWithStorage[127.0.0.1:36371,DS-d02e7ee6-ae2f-4563-9d83-c17d9c5e3725,DISK], DatanodeInfoWithStorage[127.0.0.1:46548,DS-ac4f3085-aade-4033-8e5b-75734f2c8fd8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1053251380-172.17.0.9-1598384155979:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42919,DS-ce23f27b-6eeb-430c-a4d2-2df7c0680680,DISK], DatanodeInfoWithStorage[127.0.0.1:45271,DS-420ef4de-ab60-4798-9416-17def41faec4,DISK], DatanodeInfoWithStorage[127.0.0.1:45008,DS-269eb20b-0d3a-43eb-9f2f-5bb0e3389f94,DISK], DatanodeInfoWithStorage[127.0.0.1:46874,DS-843c3f41-103f-4086-8261-3a2c6a5566a0,DISK], DatanodeInfoWithStorage[127.0.0.1:44853,DS-78e6cb2e-4704-4f07-94b5-af78a69e5ca2,DISK], DatanodeInfoWithStorage[127.0.0.1:37683,DS-ec0f6004-390c-4bcf-af93-789403c214a4,DISK], DatanodeInfoWithStorage[127.0.0.1:36371,DS-d02e7ee6-ae2f-4563-9d83-c17d9c5e3725,DISK], DatanodeInfoWithStorage[127.0.0.1:46548,DS-ac4f3085-aade-4033-8e5b-75734f2c8fd8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-268148340-172.17.0.9-1598384646966:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33499,DS-169de91c-e620-461e-8156-9653547bf77e,DISK], DatanodeInfoWithStorage[127.0.0.1:46588,DS-b13af736-4e7b-4a46-8778-948fcf25c1e9,DISK], DatanodeInfoWithStorage[127.0.0.1:38804,DS-e8c24328-8aeb-4efd-8b34-9670579744cc,DISK], DatanodeInfoWithStorage[127.0.0.1:35384,DS-534b4b53-ccf0-4b5a-8721-6a1210b8b0d2,DISK], DatanodeInfoWithStorage[127.0.0.1:44698,DS-03a7524d-f161-44a1-aa66-9f293c8c1593,DISK], DatanodeInfoWithStorage[127.0.0.1:41149,DS-dd575cc6-8346-4687-87d6-39cefd73ac22,DISK], DatanodeInfoWithStorage[127.0.0.1:33130,DS-2785f9b5-00f3-4d69-a596-f276bbcfb544,DISK], DatanodeInfoWithStorage[127.0.0.1:35584,DS-62b410c7-dd10-4971-9e70-6497d76bb2f3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-268148340-172.17.0.9-1598384646966:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33499,DS-169de91c-e620-461e-8156-9653547bf77e,DISK], DatanodeInfoWithStorage[127.0.0.1:46588,DS-b13af736-4e7b-4a46-8778-948fcf25c1e9,DISK], DatanodeInfoWithStorage[127.0.0.1:38804,DS-e8c24328-8aeb-4efd-8b34-9670579744cc,DISK], DatanodeInfoWithStorage[127.0.0.1:35384,DS-534b4b53-ccf0-4b5a-8721-6a1210b8b0d2,DISK], DatanodeInfoWithStorage[127.0.0.1:44698,DS-03a7524d-f161-44a1-aa66-9f293c8c1593,DISK], DatanodeInfoWithStorage[127.0.0.1:41149,DS-dd575cc6-8346-4687-87d6-39cefd73ac22,DISK], DatanodeInfoWithStorage[127.0.0.1:33130,DS-2785f9b5-00f3-4d69-a596-f276bbcfb544,DISK], DatanodeInfoWithStorage[127.0.0.1:35584,DS-62b410c7-dd10-4971-9e70-6497d76bb2f3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1231035610-172.17.0.9-1598384724760:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43974,DS-dbbf3336-06f2-4e76-bd68-4cfd43bad7bb,DISK], DatanodeInfoWithStorage[127.0.0.1:38178,DS-17187f12-9983-4d23-a0d2-139840c00096,DISK], DatanodeInfoWithStorage[127.0.0.1:35896,DS-1227a343-dba4-4f6d-adee-78628d1ee951,DISK], DatanodeInfoWithStorage[127.0.0.1:38583,DS-bbb79c6b-bff9-4a2f-bd57-f00814bed917,DISK], DatanodeInfoWithStorage[127.0.0.1:38086,DS-cd8a0f87-3275-4937-ad17-160365444fee,DISK], DatanodeInfoWithStorage[127.0.0.1:41387,DS-53f87f7a-3f25-49b4-a6dd-f1ed310d24b6,DISK], DatanodeInfoWithStorage[127.0.0.1:42490,DS-c9eb40b4-417d-4972-a129-50afa70e1b35,DISK], DatanodeInfoWithStorage[127.0.0.1:36873,DS-e5639e85-53e9-4261-9eeb-2aaccd57a30c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1231035610-172.17.0.9-1598384724760:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43974,DS-dbbf3336-06f2-4e76-bd68-4cfd43bad7bb,DISK], DatanodeInfoWithStorage[127.0.0.1:38178,DS-17187f12-9983-4d23-a0d2-139840c00096,DISK], DatanodeInfoWithStorage[127.0.0.1:35896,DS-1227a343-dba4-4f6d-adee-78628d1ee951,DISK], DatanodeInfoWithStorage[127.0.0.1:38583,DS-bbb79c6b-bff9-4a2f-bd57-f00814bed917,DISK], DatanodeInfoWithStorage[127.0.0.1:38086,DS-cd8a0f87-3275-4937-ad17-160365444fee,DISK], DatanodeInfoWithStorage[127.0.0.1:41387,DS-53f87f7a-3f25-49b4-a6dd-f1ed310d24b6,DISK], DatanodeInfoWithStorage[127.0.0.1:42490,DS-c9eb40b4-417d-4972-a129-50afa70e1b35,DISK], DatanodeInfoWithStorage[127.0.0.1:36873,DS-e5639e85-53e9-4261-9eeb-2aaccd57a30c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-106574556-172.17.0.9-1598384833856:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38894,DS-41f76097-37cf-4504-aff3-35409941bed6,DISK], DatanodeInfoWithStorage[127.0.0.1:37789,DS-33e5d77c-96b8-4096-9004-68bab5e221f3,DISK], DatanodeInfoWithStorage[127.0.0.1:42597,DS-49be6471-2ba5-4c49-907c-4d2ba1bd3296,DISK], DatanodeInfoWithStorage[127.0.0.1:36275,DS-f3a7d05f-a262-46ff-bee0-2dcc46cd2b47,DISK], DatanodeInfoWithStorage[127.0.0.1:39002,DS-90893ee2-98df-4076-92f1-5efedd0cbb6a,DISK], DatanodeInfoWithStorage[127.0.0.1:35748,DS-5208fbfe-478f-4b94-a861-6428c41347a6,DISK], DatanodeInfoWithStorage[127.0.0.1:43868,DS-d90b5c0b-72e7-44ca-a0df-d9bc15b9ccc5,DISK], DatanodeInfoWithStorage[127.0.0.1:33833,DS-d9f509ee-62a2-4af0-8d64-bb37ac40dc54,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-106574556-172.17.0.9-1598384833856:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38894,DS-41f76097-37cf-4504-aff3-35409941bed6,DISK], DatanodeInfoWithStorage[127.0.0.1:37789,DS-33e5d77c-96b8-4096-9004-68bab5e221f3,DISK], DatanodeInfoWithStorage[127.0.0.1:42597,DS-49be6471-2ba5-4c49-907c-4d2ba1bd3296,DISK], DatanodeInfoWithStorage[127.0.0.1:36275,DS-f3a7d05f-a262-46ff-bee0-2dcc46cd2b47,DISK], DatanodeInfoWithStorage[127.0.0.1:39002,DS-90893ee2-98df-4076-92f1-5efedd0cbb6a,DISK], DatanodeInfoWithStorage[127.0.0.1:35748,DS-5208fbfe-478f-4b94-a861-6428c41347a6,DISK], DatanodeInfoWithStorage[127.0.0.1:43868,DS-d90b5c0b-72e7-44ca-a0df-d9bc15b9ccc5,DISK], DatanodeInfoWithStorage[127.0.0.1:33833,DS-d9f509ee-62a2-4af0-8d64-bb37ac40dc54,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-665698283-172.17.0.9-1598384919406:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37658,DS-92d71b5d-6078-4913-9f6c-4706a056e6d0,DISK], DatanodeInfoWithStorage[127.0.0.1:39997,DS-88b899c7-8ab5-41ea-93ef-63548427bb2b,DISK], DatanodeInfoWithStorage[127.0.0.1:44239,DS-25444e47-03ae-4dc1-baeb-460171f1a675,DISK], DatanodeInfoWithStorage[127.0.0.1:42783,DS-88d4bde7-f6cb-45df-bb98-e8ed3a9d1134,DISK], DatanodeInfoWithStorage[127.0.0.1:36708,DS-624633c9-bca8-4e2a-a5c7-1611fc3d92d3,DISK], DatanodeInfoWithStorage[127.0.0.1:40524,DS-0a59d0d1-a566-48a5-8b38-4df09250fbae,DISK], DatanodeInfoWithStorage[127.0.0.1:36952,DS-9de18f04-ee2b-4883-a82e-1c950c9b3478,DISK], DatanodeInfoWithStorage[127.0.0.1:36393,DS-7243e64c-1068-4bd3-abbe-440d69d4d93f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-665698283-172.17.0.9-1598384919406:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37658,DS-92d71b5d-6078-4913-9f6c-4706a056e6d0,DISK], DatanodeInfoWithStorage[127.0.0.1:39997,DS-88b899c7-8ab5-41ea-93ef-63548427bb2b,DISK], DatanodeInfoWithStorage[127.0.0.1:44239,DS-25444e47-03ae-4dc1-baeb-460171f1a675,DISK], DatanodeInfoWithStorage[127.0.0.1:42783,DS-88d4bde7-f6cb-45df-bb98-e8ed3a9d1134,DISK], DatanodeInfoWithStorage[127.0.0.1:36708,DS-624633c9-bca8-4e2a-a5c7-1611fc3d92d3,DISK], DatanodeInfoWithStorage[127.0.0.1:40524,DS-0a59d0d1-a566-48a5-8b38-4df09250fbae,DISK], DatanodeInfoWithStorage[127.0.0.1:36952,DS-9de18f04-ee2b-4883-a82e-1c950c9b3478,DISK], DatanodeInfoWithStorage[127.0.0.1:36393,DS-7243e64c-1068-4bd3-abbe-440d69d4d93f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-390961908-172.17.0.9-1598385001851:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40616,DS-c07bcacc-3a9f-43b4-9672-d6a9846321ee,DISK], DatanodeInfoWithStorage[127.0.0.1:34347,DS-f5deeb1c-6a3f-4ee0-919b-b017c84f5837,DISK], DatanodeInfoWithStorage[127.0.0.1:34014,DS-3d7fa0d5-6182-43d3-889b-b5061b8a0a34,DISK], DatanodeInfoWithStorage[127.0.0.1:42730,DS-6e594750-af23-46c2-8ee8-52ad69386b6d,DISK], DatanodeInfoWithStorage[127.0.0.1:35731,DS-15e404ff-64a9-456c-a94f-a30798aea609,DISK], DatanodeInfoWithStorage[127.0.0.1:37438,DS-afc3a3cf-166c-4e4d-84af-fb5dc12b5e74,DISK], DatanodeInfoWithStorage[127.0.0.1:38075,DS-ccfb07c6-66b9-4486-9790-f694ff11a7eb,DISK], DatanodeInfoWithStorage[127.0.0.1:37374,DS-22ccb99b-33da-4f00-9d53-b34596fca923,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-390961908-172.17.0.9-1598385001851:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40616,DS-c07bcacc-3a9f-43b4-9672-d6a9846321ee,DISK], DatanodeInfoWithStorage[127.0.0.1:34347,DS-f5deeb1c-6a3f-4ee0-919b-b017c84f5837,DISK], DatanodeInfoWithStorage[127.0.0.1:34014,DS-3d7fa0d5-6182-43d3-889b-b5061b8a0a34,DISK], DatanodeInfoWithStorage[127.0.0.1:42730,DS-6e594750-af23-46c2-8ee8-52ad69386b6d,DISK], DatanodeInfoWithStorage[127.0.0.1:35731,DS-15e404ff-64a9-456c-a94f-a30798aea609,DISK], DatanodeInfoWithStorage[127.0.0.1:37438,DS-afc3a3cf-166c-4e4d-84af-fb5dc12b5e74,DISK], DatanodeInfoWithStorage[127.0.0.1:38075,DS-ccfb07c6-66b9-4486-9790-f694ff11a7eb,DISK], DatanodeInfoWithStorage[127.0.0.1:37374,DS-22ccb99b-33da-4f00-9d53-b34596fca923,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-21614208-172.17.0.9-1598385082397:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41097,DS-27858c31-e873-4e66-98fa-765951f79fce,DISK], DatanodeInfoWithStorage[127.0.0.1:40330,DS-1e84e450-09da-4695-bb40-769fda297256,DISK], DatanodeInfoWithStorage[127.0.0.1:38960,DS-71837d6f-603c-4e6c-a1b4-3ba66f9d112d,DISK], DatanodeInfoWithStorage[127.0.0.1:42557,DS-dcc25987-2357-4b94-a5c5-77fa8ac5d276,DISK], DatanodeInfoWithStorage[127.0.0.1:46065,DS-4bea44ee-ce19-445c-8145-e239018f44c9,DISK], DatanodeInfoWithStorage[127.0.0.1:42189,DS-f88b28ed-9d17-4fc0-9ecb-280305c260fb,DISK], DatanodeInfoWithStorage[127.0.0.1:34920,DS-2cc7b025-dfbb-44bf-b3b2-6c0f630472ff,DISK], DatanodeInfoWithStorage[127.0.0.1:39383,DS-69cdd319-c61e-48fd-b264-219787b517ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-21614208-172.17.0.9-1598385082397:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41097,DS-27858c31-e873-4e66-98fa-765951f79fce,DISK], DatanodeInfoWithStorage[127.0.0.1:40330,DS-1e84e450-09da-4695-bb40-769fda297256,DISK], DatanodeInfoWithStorage[127.0.0.1:38960,DS-71837d6f-603c-4e6c-a1b4-3ba66f9d112d,DISK], DatanodeInfoWithStorage[127.0.0.1:42557,DS-dcc25987-2357-4b94-a5c5-77fa8ac5d276,DISK], DatanodeInfoWithStorage[127.0.0.1:46065,DS-4bea44ee-ce19-445c-8145-e239018f44c9,DISK], DatanodeInfoWithStorage[127.0.0.1:42189,DS-f88b28ed-9d17-4fc0-9ecb-280305c260fb,DISK], DatanodeInfoWithStorage[127.0.0.1:34920,DS-2cc7b025-dfbb-44bf-b3b2-6c0f630472ff,DISK], DatanodeInfoWithStorage[127.0.0.1:39383,DS-69cdd319-c61e-48fd-b264-219787b517ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-479325687-172.17.0.9-1598385367346:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36792,DS-e006cd5e-521d-4802-9aee-cb4ee4121d0a,DISK], DatanodeInfoWithStorage[127.0.0.1:39923,DS-acddb5a8-38a0-4c95-b611-1415490e5e90,DISK], DatanodeInfoWithStorage[127.0.0.1:38032,DS-1514f8dd-4164-4a39-b641-9d3a190b17bd,DISK], DatanodeInfoWithStorage[127.0.0.1:33125,DS-4fab447c-c24a-45f7-8817-6f452e747f39,DISK], DatanodeInfoWithStorage[127.0.0.1:43528,DS-c2796996-d2c4-4e7a-a876-5dad9e46ccd6,DISK], DatanodeInfoWithStorage[127.0.0.1:39599,DS-dd1bc0eb-8be5-40c2-a748-50a93d959404,DISK], DatanodeInfoWithStorage[127.0.0.1:45277,DS-36f6292e-b9db-44e8-9a57-457e25546fdb,DISK], DatanodeInfoWithStorage[127.0.0.1:41543,DS-74de1b48-fc23-47dd-ab5d-89fd3603cb29,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-479325687-172.17.0.9-1598385367346:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36792,DS-e006cd5e-521d-4802-9aee-cb4ee4121d0a,DISK], DatanodeInfoWithStorage[127.0.0.1:39923,DS-acddb5a8-38a0-4c95-b611-1415490e5e90,DISK], DatanodeInfoWithStorage[127.0.0.1:38032,DS-1514f8dd-4164-4a39-b641-9d3a190b17bd,DISK], DatanodeInfoWithStorage[127.0.0.1:33125,DS-4fab447c-c24a-45f7-8817-6f452e747f39,DISK], DatanodeInfoWithStorage[127.0.0.1:43528,DS-c2796996-d2c4-4e7a-a876-5dad9e46ccd6,DISK], DatanodeInfoWithStorage[127.0.0.1:39599,DS-dd1bc0eb-8be5-40c2-a748-50a93d959404,DISK], DatanodeInfoWithStorage[127.0.0.1:45277,DS-36f6292e-b9db-44e8-9a57-457e25546fdb,DISK], DatanodeInfoWithStorage[127.0.0.1:41543,DS-74de1b48-fc23-47dd-ab5d-89fd3603cb29,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-744367679-172.17.0.9-1598385786068:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42135,DS-70c71a1b-ee7c-4caf-b1dd-cf526af21103,DISK], DatanodeInfoWithStorage[127.0.0.1:41731,DS-f15a5cf7-aa0c-4eb0-a820-7337c0daa9a9,DISK], DatanodeInfoWithStorage[127.0.0.1:38896,DS-d10164bb-efad-4a88-9bd3-2b0035c2d547,DISK], DatanodeInfoWithStorage[127.0.0.1:38455,DS-edeb29e5-a096-4dc0-b3ee-866a73c50d97,DISK], DatanodeInfoWithStorage[127.0.0.1:42420,DS-6db07f47-01f8-4c40-906e-080edfdb336a,DISK], DatanodeInfoWithStorage[127.0.0.1:35733,DS-da74c05c-623e-4b4a-a215-e4ca5ff43346,DISK], DatanodeInfoWithStorage[127.0.0.1:41515,DS-0f50e0fd-721f-4414-9810-74d2c0510255,DISK], DatanodeInfoWithStorage[127.0.0.1:38928,DS-2fa8b475-88fa-48ac-8152-16ee22e1aa50,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-744367679-172.17.0.9-1598385786068:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42135,DS-70c71a1b-ee7c-4caf-b1dd-cf526af21103,DISK], DatanodeInfoWithStorage[127.0.0.1:41731,DS-f15a5cf7-aa0c-4eb0-a820-7337c0daa9a9,DISK], DatanodeInfoWithStorage[127.0.0.1:38896,DS-d10164bb-efad-4a88-9bd3-2b0035c2d547,DISK], DatanodeInfoWithStorage[127.0.0.1:38455,DS-edeb29e5-a096-4dc0-b3ee-866a73c50d97,DISK], DatanodeInfoWithStorage[127.0.0.1:42420,DS-6db07f47-01f8-4c40-906e-080edfdb336a,DISK], DatanodeInfoWithStorage[127.0.0.1:35733,DS-da74c05c-623e-4b4a-a215-e4ca5ff43346,DISK], DatanodeInfoWithStorage[127.0.0.1:41515,DS-0f50e0fd-721f-4414-9810-74d2c0510255,DISK], DatanodeInfoWithStorage[127.0.0.1:38928,DS-2fa8b475-88fa-48ac-8152-16ee22e1aa50,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1572114832-172.17.0.9-1598385945582:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38484,DS-9eaa088f-1c24-47c7-9c8a-5cdd4d0e8e7e,DISK], DatanodeInfoWithStorage[127.0.0.1:41761,DS-95b40a5d-cf26-4c9f-b75d-a14031ce2016,DISK], DatanodeInfoWithStorage[127.0.0.1:33554,DS-3084e7de-1816-4501-834a-3ae5fa104a00,DISK], DatanodeInfoWithStorage[127.0.0.1:39452,DS-38c71a5f-3de4-4296-ac87-fa5574179f48,DISK], DatanodeInfoWithStorage[127.0.0.1:39330,DS-4058b24d-8d61-48da-a851-21f1f06cf5b8,DISK], DatanodeInfoWithStorage[127.0.0.1:40816,DS-1feffd59-e76e-4955-a807-2615e0e6822c,DISK], DatanodeInfoWithStorage[127.0.0.1:36236,DS-b21a9bfc-5335-4675-9a39-de10cf23faf0,DISK], DatanodeInfoWithStorage[127.0.0.1:44053,DS-590548d2-dfda-4daa-a2b8-1dd8b6332c80,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1572114832-172.17.0.9-1598385945582:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38484,DS-9eaa088f-1c24-47c7-9c8a-5cdd4d0e8e7e,DISK], DatanodeInfoWithStorage[127.0.0.1:41761,DS-95b40a5d-cf26-4c9f-b75d-a14031ce2016,DISK], DatanodeInfoWithStorage[127.0.0.1:33554,DS-3084e7de-1816-4501-834a-3ae5fa104a00,DISK], DatanodeInfoWithStorage[127.0.0.1:39452,DS-38c71a5f-3de4-4296-ac87-fa5574179f48,DISK], DatanodeInfoWithStorage[127.0.0.1:39330,DS-4058b24d-8d61-48da-a851-21f1f06cf5b8,DISK], DatanodeInfoWithStorage[127.0.0.1:40816,DS-1feffd59-e76e-4955-a807-2615e0e6822c,DISK], DatanodeInfoWithStorage[127.0.0.1:36236,DS-b21a9bfc-5335-4675-9a39-de10cf23faf0,DISK], DatanodeInfoWithStorage[127.0.0.1:44053,DS-590548d2-dfda-4daa-a2b8-1dd8b6332c80,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 12 out of 50
v1v1v2v2 failed with probability 19 out of 50
result: false positive !!!
Total execution time in seconds : 5638
