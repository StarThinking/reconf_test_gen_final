reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1841855447-172.17.0.5-1598339644059:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34099,DS-3e9498f6-9d41-41d4-abd0-fd03c21abd34,DISK], DatanodeInfoWithStorage[127.0.0.1:32868,DS-61c5fecd-4f25-4015-89e6-f1b02d6ccf81,DISK], DatanodeInfoWithStorage[127.0.0.1:39728,DS-68f75769-410f-45d7-94e2-441706cd7723,DISK], DatanodeInfoWithStorage[127.0.0.1:36790,DS-d28ee659-9ba1-4de8-8b00-70c2b911fb5f,DISK], DatanodeInfoWithStorage[127.0.0.1:32782,DS-519dde22-14f4-40f7-8552-e14e845e54be,DISK], DatanodeInfoWithStorage[127.0.0.1:40392,DS-aecd2a80-a102-4886-a020-25aab0c9caa1,DISK], DatanodeInfoWithStorage[127.0.0.1:45414,DS-122081da-2132-402e-a072-453a5302c97a,DISK], DatanodeInfoWithStorage[127.0.0.1:39197,DS-cf525798-a783-4714-8a1f-bf330bf0a2a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1841855447-172.17.0.5-1598339644059:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34099,DS-3e9498f6-9d41-41d4-abd0-fd03c21abd34,DISK], DatanodeInfoWithStorage[127.0.0.1:32868,DS-61c5fecd-4f25-4015-89e6-f1b02d6ccf81,DISK], DatanodeInfoWithStorage[127.0.0.1:39728,DS-68f75769-410f-45d7-94e2-441706cd7723,DISK], DatanodeInfoWithStorage[127.0.0.1:36790,DS-d28ee659-9ba1-4de8-8b00-70c2b911fb5f,DISK], DatanodeInfoWithStorage[127.0.0.1:32782,DS-519dde22-14f4-40f7-8552-e14e845e54be,DISK], DatanodeInfoWithStorage[127.0.0.1:40392,DS-aecd2a80-a102-4886-a020-25aab0c9caa1,DISK], DatanodeInfoWithStorage[127.0.0.1:45414,DS-122081da-2132-402e-a072-453a5302c97a,DISK], DatanodeInfoWithStorage[127.0.0.1:39197,DS-cf525798-a783-4714-8a1f-bf330bf0a2a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-120942854-172.17.0.5-1598339703691:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46382,DS-3b5d925a-67d4-473c-a44f-e9d1d0b34eee,DISK], DatanodeInfoWithStorage[127.0.0.1:38796,DS-c6a0e87a-f7e8-4aca-b86f-06623dc84ee1,DISK], DatanodeInfoWithStorage[127.0.0.1:39962,DS-1c7febb8-b04e-4bf6-aef0-274b06204030,DISK], DatanodeInfoWithStorage[127.0.0.1:39418,DS-86d66045-6d81-471c-98dc-60efedc4d1fc,DISK], DatanodeInfoWithStorage[127.0.0.1:35838,DS-f19b783b-95d6-47a7-8433-7aeb598fe939,DISK], DatanodeInfoWithStorage[127.0.0.1:46162,DS-ae0cee19-f4bd-4b2b-a95d-501e911d64fe,DISK], DatanodeInfoWithStorage[127.0.0.1:40137,DS-ff713566-da98-4add-8ba8-948a749ffcf7,DISK], DatanodeInfoWithStorage[127.0.0.1:36098,DS-0535745c-4c48-4b7a-bf81-bae2014539b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-120942854-172.17.0.5-1598339703691:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46382,DS-3b5d925a-67d4-473c-a44f-e9d1d0b34eee,DISK], DatanodeInfoWithStorage[127.0.0.1:38796,DS-c6a0e87a-f7e8-4aca-b86f-06623dc84ee1,DISK], DatanodeInfoWithStorage[127.0.0.1:39962,DS-1c7febb8-b04e-4bf6-aef0-274b06204030,DISK], DatanodeInfoWithStorage[127.0.0.1:39418,DS-86d66045-6d81-471c-98dc-60efedc4d1fc,DISK], DatanodeInfoWithStorage[127.0.0.1:35838,DS-f19b783b-95d6-47a7-8433-7aeb598fe939,DISK], DatanodeInfoWithStorage[127.0.0.1:46162,DS-ae0cee19-f4bd-4b2b-a95d-501e911d64fe,DISK], DatanodeInfoWithStorage[127.0.0.1:40137,DS-ff713566-da98-4add-8ba8-948a749ffcf7,DISK], DatanodeInfoWithStorage[127.0.0.1:36098,DS-0535745c-4c48-4b7a-bf81-bae2014539b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-288295676-172.17.0.5-1598340264191:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43105,DS-860a447d-933b-4dfa-bc6e-ae8d40682f82,DISK], DatanodeInfoWithStorage[127.0.0.1:40521,DS-d6ee659e-dbba-4b27-b404-1a9ffe5c4f61,DISK], DatanodeInfoWithStorage[127.0.0.1:41353,DS-9532879b-c6cf-4158-8c31-476e1027b4a5,DISK], DatanodeInfoWithStorage[127.0.0.1:34798,DS-aeab1b3a-726a-463e-95da-8cc9f68ef7e7,DISK], DatanodeInfoWithStorage[127.0.0.1:36213,DS-6bfc0b55-1245-43c3-9242-3d7fb9c2a088,DISK], DatanodeInfoWithStorage[127.0.0.1:39140,DS-392f987c-fe7f-4afd-82f5-210234560017,DISK], DatanodeInfoWithStorage[127.0.0.1:40330,DS-f88e8470-b4e8-4bd4-9ad0-5c468ad9eaf5,DISK], DatanodeInfoWithStorage[127.0.0.1:46370,DS-f1e450f5-dacb-467e-9c50-42342fd538be,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-288295676-172.17.0.5-1598340264191:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43105,DS-860a447d-933b-4dfa-bc6e-ae8d40682f82,DISK], DatanodeInfoWithStorage[127.0.0.1:40521,DS-d6ee659e-dbba-4b27-b404-1a9ffe5c4f61,DISK], DatanodeInfoWithStorage[127.0.0.1:41353,DS-9532879b-c6cf-4158-8c31-476e1027b4a5,DISK], DatanodeInfoWithStorage[127.0.0.1:34798,DS-aeab1b3a-726a-463e-95da-8cc9f68ef7e7,DISK], DatanodeInfoWithStorage[127.0.0.1:36213,DS-6bfc0b55-1245-43c3-9242-3d7fb9c2a088,DISK], DatanodeInfoWithStorage[127.0.0.1:39140,DS-392f987c-fe7f-4afd-82f5-210234560017,DISK], DatanodeInfoWithStorage[127.0.0.1:40330,DS-f88e8470-b4e8-4bd4-9ad0-5c468ad9eaf5,DISK], DatanodeInfoWithStorage[127.0.0.1:46370,DS-f1e450f5-dacb-467e-9c50-42342fd538be,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1299498592-172.17.0.5-1598340331232:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36148,DS-3e785b5e-997d-4a59-a361-fac8708e9c8d,DISK], DatanodeInfoWithStorage[127.0.0.1:36943,DS-e3f8f505-10ab-4d29-ac6a-cbf2cf8ab5f2,DISK], DatanodeInfoWithStorage[127.0.0.1:38075,DS-4b05e028-247a-41f3-a41f-dc7d99192dec,DISK], DatanodeInfoWithStorage[127.0.0.1:39082,DS-86f3ab35-6578-4a92-9277-92f514d91719,DISK], DatanodeInfoWithStorage[127.0.0.1:36361,DS-c224a9e7-d67a-4d73-97d9-bbc4f608270a,DISK], DatanodeInfoWithStorage[127.0.0.1:35684,DS-ad9aaacb-44ca-4986-a27f-5083273b8d31,DISK], DatanodeInfoWithStorage[127.0.0.1:42704,DS-17726f1b-801f-4832-a8e6-46e18e6b8986,DISK], DatanodeInfoWithStorage[127.0.0.1:36376,DS-43cf95d6-3628-4e81-8f4b-7b58e465b2fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1299498592-172.17.0.5-1598340331232:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36148,DS-3e785b5e-997d-4a59-a361-fac8708e9c8d,DISK], DatanodeInfoWithStorage[127.0.0.1:36943,DS-e3f8f505-10ab-4d29-ac6a-cbf2cf8ab5f2,DISK], DatanodeInfoWithStorage[127.0.0.1:38075,DS-4b05e028-247a-41f3-a41f-dc7d99192dec,DISK], DatanodeInfoWithStorage[127.0.0.1:39082,DS-86f3ab35-6578-4a92-9277-92f514d91719,DISK], DatanodeInfoWithStorage[127.0.0.1:36361,DS-c224a9e7-d67a-4d73-97d9-bbc4f608270a,DISK], DatanodeInfoWithStorage[127.0.0.1:35684,DS-ad9aaacb-44ca-4986-a27f-5083273b8d31,DISK], DatanodeInfoWithStorage[127.0.0.1:42704,DS-17726f1b-801f-4832-a8e6-46e18e6b8986,DISK], DatanodeInfoWithStorage[127.0.0.1:36376,DS-43cf95d6-3628-4e81-8f4b-7b58e465b2fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-222167601-172.17.0.5-1598340953201:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41010,DS-ee8de892-20d0-4f67-8534-1074e5600c54,DISK], DatanodeInfoWithStorage[127.0.0.1:44231,DS-93d90e88-1414-471d-a061-143eb4573631,DISK], DatanodeInfoWithStorage[127.0.0.1:38079,DS-27469a62-df59-4706-89c4-8633271da31f,DISK], DatanodeInfoWithStorage[127.0.0.1:45012,DS-33b53f30-6d26-484d-b790-412ba0944872,DISK], DatanodeInfoWithStorage[127.0.0.1:39189,DS-94bbb189-696f-4211-8ff0-6ad31f1c140b,DISK], DatanodeInfoWithStorage[127.0.0.1:37637,DS-e66201ad-420b-4b2b-b1d1-65c560aa397c,DISK], DatanodeInfoWithStorage[127.0.0.1:37416,DS-d8ea9b62-4a76-4ff8-bdc0-ca5d63e9d102,DISK], DatanodeInfoWithStorage[127.0.0.1:40446,DS-5bf66c9c-b419-4c69-8b7c-c82ea1114968,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-222167601-172.17.0.5-1598340953201:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41010,DS-ee8de892-20d0-4f67-8534-1074e5600c54,DISK], DatanodeInfoWithStorage[127.0.0.1:44231,DS-93d90e88-1414-471d-a061-143eb4573631,DISK], DatanodeInfoWithStorage[127.0.0.1:38079,DS-27469a62-df59-4706-89c4-8633271da31f,DISK], DatanodeInfoWithStorage[127.0.0.1:45012,DS-33b53f30-6d26-484d-b790-412ba0944872,DISK], DatanodeInfoWithStorage[127.0.0.1:39189,DS-94bbb189-696f-4211-8ff0-6ad31f1c140b,DISK], DatanodeInfoWithStorage[127.0.0.1:37637,DS-e66201ad-420b-4b2b-b1d1-65c560aa397c,DISK], DatanodeInfoWithStorage[127.0.0.1:37416,DS-d8ea9b62-4a76-4ff8-bdc0-ca5d63e9d102,DISK], DatanodeInfoWithStorage[127.0.0.1:40446,DS-5bf66c9c-b419-4c69-8b7c-c82ea1114968,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-798209164-172.17.0.5-1598341265123:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44929,DS-4dba70f5-a9b0-4742-a7d0-aea7d75534f7,DISK], DatanodeInfoWithStorage[127.0.0.1:45672,DS-d91242b1-e04c-4a35-9971-f3aabe1ce5eb,DISK], DatanodeInfoWithStorage[127.0.0.1:46869,DS-8f1d14f1-d5bb-4a7b-9de7-f95027dffa41,DISK], DatanodeInfoWithStorage[127.0.0.1:33723,DS-6f057fab-6229-4dcc-ab34-3c14d36f0c08,DISK], DatanodeInfoWithStorage[127.0.0.1:40279,DS-7d2f271c-4449-4e75-9692-d455a3c9ea5c,DISK], DatanodeInfoWithStorage[127.0.0.1:34557,DS-b0001a97-41b4-46ae-a0df-192e48471f31,DISK], DatanodeInfoWithStorage[127.0.0.1:46847,DS-538f93c2-1eb4-461c-be04-9e68fde62d1f,DISK], DatanodeInfoWithStorage[127.0.0.1:46029,DS-43eebd5a-1ebc-4c8a-87f9-a3276c46d00e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-798209164-172.17.0.5-1598341265123:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44929,DS-4dba70f5-a9b0-4742-a7d0-aea7d75534f7,DISK], DatanodeInfoWithStorage[127.0.0.1:45672,DS-d91242b1-e04c-4a35-9971-f3aabe1ce5eb,DISK], DatanodeInfoWithStorage[127.0.0.1:46869,DS-8f1d14f1-d5bb-4a7b-9de7-f95027dffa41,DISK], DatanodeInfoWithStorage[127.0.0.1:33723,DS-6f057fab-6229-4dcc-ab34-3c14d36f0c08,DISK], DatanodeInfoWithStorage[127.0.0.1:40279,DS-7d2f271c-4449-4e75-9692-d455a3c9ea5c,DISK], DatanodeInfoWithStorage[127.0.0.1:34557,DS-b0001a97-41b4-46ae-a0df-192e48471f31,DISK], DatanodeInfoWithStorage[127.0.0.1:46847,DS-538f93c2-1eb4-461c-be04-9e68fde62d1f,DISK], DatanodeInfoWithStorage[127.0.0.1:46029,DS-43eebd5a-1ebc-4c8a-87f9-a3276c46d00e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1146444255-172.17.0.5-1598341539248:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36806,DS-8ac78375-669d-4358-85a3-57277ac6de59,DISK], DatanodeInfoWithStorage[127.0.0.1:39087,DS-01250393-6b4c-48a8-bb80-65d41ef1891e,DISK], DatanodeInfoWithStorage[127.0.0.1:43418,DS-ba7851e7-3a1f-4460-9d0d-90b7ee7dbdae,DISK], DatanodeInfoWithStorage[127.0.0.1:46132,DS-5dfae1f5-d0ca-4be2-adf5-8fdb46d32ee6,DISK], DatanodeInfoWithStorage[127.0.0.1:37380,DS-238fac07-6ca9-483a-9ddd-3d49d276a859,DISK], DatanodeInfoWithStorage[127.0.0.1:35709,DS-25a5c0d4-d516-423a-9556-d856d23e0fda,DISK], DatanodeInfoWithStorage[127.0.0.1:43378,DS-5a75ce8c-6061-4b09-a80c-c8b10c4d843c,DISK], DatanodeInfoWithStorage[127.0.0.1:38561,DS-8968423a-e73b-4f65-88e3-7e67f0fcfbbe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1146444255-172.17.0.5-1598341539248:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36806,DS-8ac78375-669d-4358-85a3-57277ac6de59,DISK], DatanodeInfoWithStorage[127.0.0.1:39087,DS-01250393-6b4c-48a8-bb80-65d41ef1891e,DISK], DatanodeInfoWithStorage[127.0.0.1:43418,DS-ba7851e7-3a1f-4460-9d0d-90b7ee7dbdae,DISK], DatanodeInfoWithStorage[127.0.0.1:46132,DS-5dfae1f5-d0ca-4be2-adf5-8fdb46d32ee6,DISK], DatanodeInfoWithStorage[127.0.0.1:37380,DS-238fac07-6ca9-483a-9ddd-3d49d276a859,DISK], DatanodeInfoWithStorage[127.0.0.1:35709,DS-25a5c0d4-d516-423a-9556-d856d23e0fda,DISK], DatanodeInfoWithStorage[127.0.0.1:43378,DS-5a75ce8c-6061-4b09-a80c-c8b10c4d843c,DISK], DatanodeInfoWithStorage[127.0.0.1:38561,DS-8968423a-e73b-4f65-88e3-7e67f0fcfbbe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1817211812-172.17.0.5-1598341836448:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40717,DS-97ecb5bd-9216-4824-9edd-eac6bfca0028,DISK], DatanodeInfoWithStorage[127.0.0.1:44460,DS-e0638b0b-729f-462e-8ee5-5d0be1111aa3,DISK], DatanodeInfoWithStorage[127.0.0.1:39360,DS-a97f954c-39fb-4f54-a478-239162c5ff04,DISK], DatanodeInfoWithStorage[127.0.0.1:37178,DS-e9447281-a526-4330-862c-d8d228135a5d,DISK], DatanodeInfoWithStorage[127.0.0.1:38667,DS-ac30d074-8ba3-4ce5-a721-5bc7f546007c,DISK], DatanodeInfoWithStorage[127.0.0.1:44960,DS-b72dace8-84d3-4219-85a1-2582ffe6a2ca,DISK], DatanodeInfoWithStorage[127.0.0.1:43506,DS-5e11a8ff-d434-4d2d-b7da-d509f801613f,DISK], DatanodeInfoWithStorage[127.0.0.1:34393,DS-a4dcce86-d427-4ff3-a9d1-86e5d5a381f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1817211812-172.17.0.5-1598341836448:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40717,DS-97ecb5bd-9216-4824-9edd-eac6bfca0028,DISK], DatanodeInfoWithStorage[127.0.0.1:44460,DS-e0638b0b-729f-462e-8ee5-5d0be1111aa3,DISK], DatanodeInfoWithStorage[127.0.0.1:39360,DS-a97f954c-39fb-4f54-a478-239162c5ff04,DISK], DatanodeInfoWithStorage[127.0.0.1:37178,DS-e9447281-a526-4330-862c-d8d228135a5d,DISK], DatanodeInfoWithStorage[127.0.0.1:38667,DS-ac30d074-8ba3-4ce5-a721-5bc7f546007c,DISK], DatanodeInfoWithStorage[127.0.0.1:44960,DS-b72dace8-84d3-4219-85a1-2582ffe6a2ca,DISK], DatanodeInfoWithStorage[127.0.0.1:43506,DS-5e11a8ff-d434-4d2d-b7da-d509f801613f,DISK], DatanodeInfoWithStorage[127.0.0.1:34393,DS-a4dcce86-d427-4ff3-a9d1-86e5d5a381f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1883822560-172.17.0.5-1598341915428:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39954,DS-da25df18-32be-438e-ac2f-6e03e1ab4576,DISK], DatanodeInfoWithStorage[127.0.0.1:42508,DS-eb2eb752-b062-486a-8bae-3c5f84253178,DISK], DatanodeInfoWithStorage[127.0.0.1:35319,DS-0db78164-1df9-4662-a5f3-114583c194fe,DISK], DatanodeInfoWithStorage[127.0.0.1:36707,DS-0695012a-477a-49c6-ae80-a6ab52073848,DISK], DatanodeInfoWithStorage[127.0.0.1:45088,DS-ef48fe7e-bd3f-470a-9cbb-21b2ef4957ad,DISK], DatanodeInfoWithStorage[127.0.0.1:45581,DS-2697bcc5-3c6e-480d-b399-4945d3ba6820,DISK], DatanodeInfoWithStorage[127.0.0.1:35481,DS-e31c39c3-590b-4860-ba2e-031808805c77,DISK], DatanodeInfoWithStorage[127.0.0.1:38470,DS-758740d1-f202-4474-9862-7f71d75c949c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1883822560-172.17.0.5-1598341915428:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39954,DS-da25df18-32be-438e-ac2f-6e03e1ab4576,DISK], DatanodeInfoWithStorage[127.0.0.1:42508,DS-eb2eb752-b062-486a-8bae-3c5f84253178,DISK], DatanodeInfoWithStorage[127.0.0.1:35319,DS-0db78164-1df9-4662-a5f3-114583c194fe,DISK], DatanodeInfoWithStorage[127.0.0.1:36707,DS-0695012a-477a-49c6-ae80-a6ab52073848,DISK], DatanodeInfoWithStorage[127.0.0.1:45088,DS-ef48fe7e-bd3f-470a-9cbb-21b2ef4957ad,DISK], DatanodeInfoWithStorage[127.0.0.1:45581,DS-2697bcc5-3c6e-480d-b399-4945d3ba6820,DISK], DatanodeInfoWithStorage[127.0.0.1:35481,DS-e31c39c3-590b-4860-ba2e-031808805c77,DISK], DatanodeInfoWithStorage[127.0.0.1:38470,DS-758740d1-f202-4474-9862-7f71d75c949c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2098655673-172.17.0.5-1598342013298:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41977,DS-92788eb3-eb55-4feb-9e4c-525f3be75935,DISK], DatanodeInfoWithStorage[127.0.0.1:33005,DS-b0c443a4-582e-47d7-a070-602064b5eb44,DISK], DatanodeInfoWithStorage[127.0.0.1:43759,DS-1e7a3396-f751-4816-847c-ad035bb4d54a,DISK], DatanodeInfoWithStorage[127.0.0.1:45316,DS-b8ec7865-d449-4315-bbf0-d7d64e728962,DISK], DatanodeInfoWithStorage[127.0.0.1:39471,DS-e3ee610e-bf2e-4777-a664-a4845c43cd83,DISK], DatanodeInfoWithStorage[127.0.0.1:35436,DS-76c91409-8fda-48b6-83c8-c9d5973f40ea,DISK], DatanodeInfoWithStorage[127.0.0.1:40369,DS-dd105a35-b429-4d57-9956-14de0957bcac,DISK], DatanodeInfoWithStorage[127.0.0.1:36796,DS-3ad618cd-2910-437c-967b-e31e2d9034f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2098655673-172.17.0.5-1598342013298:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41977,DS-92788eb3-eb55-4feb-9e4c-525f3be75935,DISK], DatanodeInfoWithStorage[127.0.0.1:33005,DS-b0c443a4-582e-47d7-a070-602064b5eb44,DISK], DatanodeInfoWithStorage[127.0.0.1:43759,DS-1e7a3396-f751-4816-847c-ad035bb4d54a,DISK], DatanodeInfoWithStorage[127.0.0.1:45316,DS-b8ec7865-d449-4315-bbf0-d7d64e728962,DISK], DatanodeInfoWithStorage[127.0.0.1:39471,DS-e3ee610e-bf2e-4777-a664-a4845c43cd83,DISK], DatanodeInfoWithStorage[127.0.0.1:35436,DS-76c91409-8fda-48b6-83c8-c9d5973f40ea,DISK], DatanodeInfoWithStorage[127.0.0.1:40369,DS-dd105a35-b429-4d57-9956-14de0957bcac,DISK], DatanodeInfoWithStorage[127.0.0.1:36796,DS-3ad618cd-2910-437c-967b-e31e2d9034f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-410793173-172.17.0.5-1598342217074:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41281,DS-75218d71-9be2-403c-be37-d18ba6b5cf26,DISK], DatanodeInfoWithStorage[127.0.0.1:34260,DS-73f2f3b3-f585-44c6-86f9-7dd858c3360d,DISK], DatanodeInfoWithStorage[127.0.0.1:45380,DS-8b4281ec-7407-419a-8093-4526ef57b065,DISK], DatanodeInfoWithStorage[127.0.0.1:35731,DS-7f50a387-fd6a-446a-8248-d4971f2afc53,DISK], DatanodeInfoWithStorage[127.0.0.1:41302,DS-7f88a702-627e-4022-817d-0d679568c06d,DISK], DatanodeInfoWithStorage[127.0.0.1:34207,DS-f31353bd-fdc0-46f7-9277-c9627e24220a,DISK], DatanodeInfoWithStorage[127.0.0.1:34854,DS-566aa8f5-602a-4578-94f1-407644d03010,DISK], DatanodeInfoWithStorage[127.0.0.1:34200,DS-8b56d3a9-2227-41dd-9d5b-0b468c0bea60,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-410793173-172.17.0.5-1598342217074:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41281,DS-75218d71-9be2-403c-be37-d18ba6b5cf26,DISK], DatanodeInfoWithStorage[127.0.0.1:34260,DS-73f2f3b3-f585-44c6-86f9-7dd858c3360d,DISK], DatanodeInfoWithStorage[127.0.0.1:45380,DS-8b4281ec-7407-419a-8093-4526ef57b065,DISK], DatanodeInfoWithStorage[127.0.0.1:35731,DS-7f50a387-fd6a-446a-8248-d4971f2afc53,DISK], DatanodeInfoWithStorage[127.0.0.1:41302,DS-7f88a702-627e-4022-817d-0d679568c06d,DISK], DatanodeInfoWithStorage[127.0.0.1:34207,DS-f31353bd-fdc0-46f7-9277-c9627e24220a,DISK], DatanodeInfoWithStorage[127.0.0.1:34854,DS-566aa8f5-602a-4578-94f1-407644d03010,DISK], DatanodeInfoWithStorage[127.0.0.1:34200,DS-8b56d3a9-2227-41dd-9d5b-0b468c0bea60,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-548746328-172.17.0.5-1598342594174:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37047,DS-a4cdfd8b-195d-41b0-bc6f-2fdd8a8994f5,DISK], DatanodeInfoWithStorage[127.0.0.1:39610,DS-67458d66-cac6-44da-9496-0f7c76fa0b34,DISK], DatanodeInfoWithStorage[127.0.0.1:45700,DS-155d995f-44ac-42c3-8f7b-6a5a481e66bd,DISK], DatanodeInfoWithStorage[127.0.0.1:38783,DS-c13d9a55-3d38-4b87-9b33-1530bd2d6c5f,DISK], DatanodeInfoWithStorage[127.0.0.1:35448,DS-7bdb0628-ce80-43f2-a244-c210e5b4c34e,DISK], DatanodeInfoWithStorage[127.0.0.1:38192,DS-8d4e60a2-8fcb-4b51-b50d-953c75ef2458,DISK], DatanodeInfoWithStorage[127.0.0.1:41955,DS-6fa3a207-ba1a-4260-9e63-5cb1d28df73b,DISK], DatanodeInfoWithStorage[127.0.0.1:41430,DS-f2aec320-00f5-4237-b98e-38273561ca9c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-548746328-172.17.0.5-1598342594174:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37047,DS-a4cdfd8b-195d-41b0-bc6f-2fdd8a8994f5,DISK], DatanodeInfoWithStorage[127.0.0.1:39610,DS-67458d66-cac6-44da-9496-0f7c76fa0b34,DISK], DatanodeInfoWithStorage[127.0.0.1:45700,DS-155d995f-44ac-42c3-8f7b-6a5a481e66bd,DISK], DatanodeInfoWithStorage[127.0.0.1:38783,DS-c13d9a55-3d38-4b87-9b33-1530bd2d6c5f,DISK], DatanodeInfoWithStorage[127.0.0.1:35448,DS-7bdb0628-ce80-43f2-a244-c210e5b4c34e,DISK], DatanodeInfoWithStorage[127.0.0.1:38192,DS-8d4e60a2-8fcb-4b51-b50d-953c75ef2458,DISK], DatanodeInfoWithStorage[127.0.0.1:41955,DS-6fa3a207-ba1a-4260-9e63-5cb1d28df73b,DISK], DatanodeInfoWithStorage[127.0.0.1:41430,DS-f2aec320-00f5-4237-b98e-38273561ca9c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1156645978-172.17.0.5-1598342834469:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41864,DS-8e190af5-58ba-44bd-bd42-1b9dfa170d6c,DISK], DatanodeInfoWithStorage[127.0.0.1:37322,DS-9753fa16-86ba-4e0f-96c1-9db9a1842014,DISK], DatanodeInfoWithStorage[127.0.0.1:45252,DS-13b3b544-2ace-4461-84d9-985b9666e57c,DISK], DatanodeInfoWithStorage[127.0.0.1:41770,DS-fab3dc79-c418-4b5b-971b-5433591cb598,DISK], DatanodeInfoWithStorage[127.0.0.1:38986,DS-cfa2a06c-a42a-41a1-a965-0fa6661ab03a,DISK], DatanodeInfoWithStorage[127.0.0.1:33510,DS-6b71f5db-d4f0-46e5-b8f8-3f571fd52c10,DISK], DatanodeInfoWithStorage[127.0.0.1:33285,DS-499be757-c331-454d-b381-777677caf11d,DISK], DatanodeInfoWithStorage[127.0.0.1:38657,DS-f23dc2e8-1c2d-4659-a5dc-3c7082da668c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1156645978-172.17.0.5-1598342834469:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41864,DS-8e190af5-58ba-44bd-bd42-1b9dfa170d6c,DISK], DatanodeInfoWithStorage[127.0.0.1:37322,DS-9753fa16-86ba-4e0f-96c1-9db9a1842014,DISK], DatanodeInfoWithStorage[127.0.0.1:45252,DS-13b3b544-2ace-4461-84d9-985b9666e57c,DISK], DatanodeInfoWithStorage[127.0.0.1:41770,DS-fab3dc79-c418-4b5b-971b-5433591cb598,DISK], DatanodeInfoWithStorage[127.0.0.1:38986,DS-cfa2a06c-a42a-41a1-a965-0fa6661ab03a,DISK], DatanodeInfoWithStorage[127.0.0.1:33510,DS-6b71f5db-d4f0-46e5-b8f8-3f571fd52c10,DISK], DatanodeInfoWithStorage[127.0.0.1:33285,DS-499be757-c331-454d-b381-777677caf11d,DISK], DatanodeInfoWithStorage[127.0.0.1:38657,DS-f23dc2e8-1c2d-4659-a5dc-3c7082da668c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-93260692-172.17.0.5-1598342965405:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33379,DS-0ee3978c-02e6-408f-a381-b33bcf630fa0,DISK], DatanodeInfoWithStorage[127.0.0.1:35286,DS-37c458e4-6935-4343-b663-5565128a01fb,DISK], DatanodeInfoWithStorage[127.0.0.1:36443,DS-87e6b8f5-2c62-449d-9893-61f8c33ec17e,DISK], DatanodeInfoWithStorage[127.0.0.1:44447,DS-d7964153-0440-4cad-932b-fb331689592c,DISK], DatanodeInfoWithStorage[127.0.0.1:42812,DS-b38dfa47-9157-4cd6-a05a-987bd30ca899,DISK], DatanodeInfoWithStorage[127.0.0.1:41581,DS-3e5ee96e-33db-429b-ae01-fff30590a916,DISK], DatanodeInfoWithStorage[127.0.0.1:35262,DS-b05b1d1d-377f-4269-a810-ab14a685f89b,DISK], DatanodeInfoWithStorage[127.0.0.1:41125,DS-44138604-a655-4189-84ed-d4beb4341eaf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-93260692-172.17.0.5-1598342965405:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33379,DS-0ee3978c-02e6-408f-a381-b33bcf630fa0,DISK], DatanodeInfoWithStorage[127.0.0.1:35286,DS-37c458e4-6935-4343-b663-5565128a01fb,DISK], DatanodeInfoWithStorage[127.0.0.1:36443,DS-87e6b8f5-2c62-449d-9893-61f8c33ec17e,DISK], DatanodeInfoWithStorage[127.0.0.1:44447,DS-d7964153-0440-4cad-932b-fb331689592c,DISK], DatanodeInfoWithStorage[127.0.0.1:42812,DS-b38dfa47-9157-4cd6-a05a-987bd30ca899,DISK], DatanodeInfoWithStorage[127.0.0.1:41581,DS-3e5ee96e-33db-429b-ae01-fff30590a916,DISK], DatanodeInfoWithStorage[127.0.0.1:35262,DS-b05b1d1d-377f-4269-a810-ab14a685f89b,DISK], DatanodeInfoWithStorage[127.0.0.1:41125,DS-44138604-a655-4189-84ed-d4beb4341eaf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1879101188-172.17.0.5-1598343091619:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32996,DS-12168875-160d-41b9-af95-e61f00807649,DISK], DatanodeInfoWithStorage[127.0.0.1:35504,DS-aaf2c055-6dc4-470e-aeea-e3af99b61d45,DISK], DatanodeInfoWithStorage[127.0.0.1:36934,DS-ddc9f710-da58-41b6-a545-5b9de370ab12,DISK], DatanodeInfoWithStorage[127.0.0.1:36285,DS-bad9f579-020e-4bd1-b962-f2a35886b65c,DISK], DatanodeInfoWithStorage[127.0.0.1:44127,DS-ed2d5a76-adbb-45bd-a4c4-68830699e772,DISK], DatanodeInfoWithStorage[127.0.0.1:43277,DS-2cbe2289-29f8-4f88-af7f-672721bb4f55,DISK], DatanodeInfoWithStorage[127.0.0.1:44148,DS-261d320f-3b36-4165-b51b-2c13e586bbc7,DISK], DatanodeInfoWithStorage[127.0.0.1:43175,DS-d43d4a94-a708-4215-821e-8b8d8d6bf731,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1879101188-172.17.0.5-1598343091619:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32996,DS-12168875-160d-41b9-af95-e61f00807649,DISK], DatanodeInfoWithStorage[127.0.0.1:35504,DS-aaf2c055-6dc4-470e-aeea-e3af99b61d45,DISK], DatanodeInfoWithStorage[127.0.0.1:36934,DS-ddc9f710-da58-41b6-a545-5b9de370ab12,DISK], DatanodeInfoWithStorage[127.0.0.1:36285,DS-bad9f579-020e-4bd1-b962-f2a35886b65c,DISK], DatanodeInfoWithStorage[127.0.0.1:44127,DS-ed2d5a76-adbb-45bd-a4c4-68830699e772,DISK], DatanodeInfoWithStorage[127.0.0.1:43277,DS-2cbe2289-29f8-4f88-af7f-672721bb4f55,DISK], DatanodeInfoWithStorage[127.0.0.1:44148,DS-261d320f-3b36-4165-b51b-2c13e586bbc7,DISK], DatanodeInfoWithStorage[127.0.0.1:43175,DS-d43d4a94-a708-4215-821e-8b8d8d6bf731,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1301439380-172.17.0.5-1598343132051:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40117,DS-c42ba49b-c184-4ddc-a2fc-bd91216d4c86,DISK], DatanodeInfoWithStorage[127.0.0.1:37852,DS-e0782616-5bad-42ac-8817-3eba65b5ca8f,DISK], DatanodeInfoWithStorage[127.0.0.1:45696,DS-18619984-232f-4ccb-8e8b-2c66e92bc22a,DISK], DatanodeInfoWithStorage[127.0.0.1:38181,DS-f7df960b-4f0d-419e-8da0-59f923c666a3,DISK], DatanodeInfoWithStorage[127.0.0.1:36327,DS-0d60272d-b3ba-473c-8dd1-2bdd5bf4895f,DISK], DatanodeInfoWithStorage[127.0.0.1:45116,DS-006531cd-20ac-4a7f-befd-681798089405,DISK], DatanodeInfoWithStorage[127.0.0.1:43250,DS-192243c2-94be-43f6-902d-9c315e922203,DISK], DatanodeInfoWithStorage[127.0.0.1:37656,DS-a8872397-0f38-4f8e-bea3-f0e5c259df9c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1301439380-172.17.0.5-1598343132051:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40117,DS-c42ba49b-c184-4ddc-a2fc-bd91216d4c86,DISK], DatanodeInfoWithStorage[127.0.0.1:37852,DS-e0782616-5bad-42ac-8817-3eba65b5ca8f,DISK], DatanodeInfoWithStorage[127.0.0.1:45696,DS-18619984-232f-4ccb-8e8b-2c66e92bc22a,DISK], DatanodeInfoWithStorage[127.0.0.1:38181,DS-f7df960b-4f0d-419e-8da0-59f923c666a3,DISK], DatanodeInfoWithStorage[127.0.0.1:36327,DS-0d60272d-b3ba-473c-8dd1-2bdd5bf4895f,DISK], DatanodeInfoWithStorage[127.0.0.1:45116,DS-006531cd-20ac-4a7f-befd-681798089405,DISK], DatanodeInfoWithStorage[127.0.0.1:43250,DS-192243c2-94be-43f6-902d-9c315e922203,DISK], DatanodeInfoWithStorage[127.0.0.1:37656,DS-a8872397-0f38-4f8e-bea3-f0e5c259df9c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-481758770-172.17.0.5-1598343325982:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39335,DS-c0890350-f5a6-4c4e-a3cf-9690d200a7f7,DISK], DatanodeInfoWithStorage[127.0.0.1:44109,DS-197627ec-f07b-476a-a0ba-c441ab4b77c1,DISK], DatanodeInfoWithStorage[127.0.0.1:37709,DS-f6bdf3fd-864b-4660-8518-cd4b22e4ddad,DISK], DatanodeInfoWithStorage[127.0.0.1:45121,DS-7a04d7de-75d3-4e20-924d-15ad45159500,DISK], DatanodeInfoWithStorage[127.0.0.1:39001,DS-12430c68-c2cd-48e5-81c0-df6506d19989,DISK], DatanodeInfoWithStorage[127.0.0.1:38744,DS-d9919458-2681-40f6-a6b7-c22f3c66d97d,DISK], DatanodeInfoWithStorage[127.0.0.1:40107,DS-78f55837-2ee3-4ae7-a85d-11a19c9b8f1b,DISK], DatanodeInfoWithStorage[127.0.0.1:42418,DS-dee77fd7-0389-4ba9-b968-42e081447b38,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-481758770-172.17.0.5-1598343325982:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39335,DS-c0890350-f5a6-4c4e-a3cf-9690d200a7f7,DISK], DatanodeInfoWithStorage[127.0.0.1:44109,DS-197627ec-f07b-476a-a0ba-c441ab4b77c1,DISK], DatanodeInfoWithStorage[127.0.0.1:37709,DS-f6bdf3fd-864b-4660-8518-cd4b22e4ddad,DISK], DatanodeInfoWithStorage[127.0.0.1:45121,DS-7a04d7de-75d3-4e20-924d-15ad45159500,DISK], DatanodeInfoWithStorage[127.0.0.1:39001,DS-12430c68-c2cd-48e5-81c0-df6506d19989,DISK], DatanodeInfoWithStorage[127.0.0.1:38744,DS-d9919458-2681-40f6-a6b7-c22f3c66d97d,DISK], DatanodeInfoWithStorage[127.0.0.1:40107,DS-78f55837-2ee3-4ae7-a85d-11a19c9b8f1b,DISK], DatanodeInfoWithStorage[127.0.0.1:42418,DS-dee77fd7-0389-4ba9-b968-42e081447b38,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1002066812-172.17.0.5-1598343364893:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46501,DS-449fff68-fa91-4631-a033-92a815ad08d9,DISK], DatanodeInfoWithStorage[127.0.0.1:39331,DS-bae2e4ef-aa05-404c-a57d-48e79fd07c10,DISK], DatanodeInfoWithStorage[127.0.0.1:36670,DS-64581c3c-3360-4c91-bea5-97af64d8ebd1,DISK], DatanodeInfoWithStorage[127.0.0.1:43965,DS-ae3af908-c286-4ebc-a7b4-88ad27bf74b0,DISK], DatanodeInfoWithStorage[127.0.0.1:36726,DS-804bd9f6-2b3b-4d4f-a4f3-58557ebf5f3d,DISK], DatanodeInfoWithStorage[127.0.0.1:39431,DS-fb99fb88-85c5-4cbd-b039-9fda7c7051cb,DISK], DatanodeInfoWithStorage[127.0.0.1:38385,DS-fb8cea1b-7173-4e61-b6c7-b923779094fe,DISK], DatanodeInfoWithStorage[127.0.0.1:33581,DS-5d975d46-c448-44c5-bf28-efadf5acb57b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1002066812-172.17.0.5-1598343364893:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46501,DS-449fff68-fa91-4631-a033-92a815ad08d9,DISK], DatanodeInfoWithStorage[127.0.0.1:39331,DS-bae2e4ef-aa05-404c-a57d-48e79fd07c10,DISK], DatanodeInfoWithStorage[127.0.0.1:36670,DS-64581c3c-3360-4c91-bea5-97af64d8ebd1,DISK], DatanodeInfoWithStorage[127.0.0.1:43965,DS-ae3af908-c286-4ebc-a7b4-88ad27bf74b0,DISK], DatanodeInfoWithStorage[127.0.0.1:36726,DS-804bd9f6-2b3b-4d4f-a4f3-58557ebf5f3d,DISK], DatanodeInfoWithStorage[127.0.0.1:39431,DS-fb99fb88-85c5-4cbd-b039-9fda7c7051cb,DISK], DatanodeInfoWithStorage[127.0.0.1:38385,DS-fb8cea1b-7173-4e61-b6c7-b923779094fe,DISK], DatanodeInfoWithStorage[127.0.0.1:33581,DS-5d975d46-c448-44c5-bf28-efadf5acb57b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-680167656-172.17.0.5-1598343434033:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32774,DS-691f3432-fbae-4107-ab44-0af34d61b8a8,DISK], DatanodeInfoWithStorage[127.0.0.1:42725,DS-71d5b43a-273e-48d7-be24-6387dafd10af,DISK], DatanodeInfoWithStorage[127.0.0.1:45868,DS-7f8b3bfe-f1ae-407e-989d-4d93a2ecd709,DISK], DatanodeInfoWithStorage[127.0.0.1:39439,DS-e08a4d1d-d09b-4ddc-b877-f03f03fc6e72,DISK], DatanodeInfoWithStorage[127.0.0.1:37389,DS-65d2ef5f-48ae-44f0-9c61-225836ca50b3,DISK], DatanodeInfoWithStorage[127.0.0.1:41993,DS-f8397c28-e863-4fab-b377-dc7e00abae2a,DISK], DatanodeInfoWithStorage[127.0.0.1:34209,DS-79e3bafb-bd33-427c-affc-6101a74a5125,DISK], DatanodeInfoWithStorage[127.0.0.1:36148,DS-6939165c-7e16-4d6e-8d4b-46892360c490,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-680167656-172.17.0.5-1598343434033:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32774,DS-691f3432-fbae-4107-ab44-0af34d61b8a8,DISK], DatanodeInfoWithStorage[127.0.0.1:42725,DS-71d5b43a-273e-48d7-be24-6387dafd10af,DISK], DatanodeInfoWithStorage[127.0.0.1:45868,DS-7f8b3bfe-f1ae-407e-989d-4d93a2ecd709,DISK], DatanodeInfoWithStorage[127.0.0.1:39439,DS-e08a4d1d-d09b-4ddc-b877-f03f03fc6e72,DISK], DatanodeInfoWithStorage[127.0.0.1:37389,DS-65d2ef5f-48ae-44f0-9c61-225836ca50b3,DISK], DatanodeInfoWithStorage[127.0.0.1:41993,DS-f8397c28-e863-4fab-b377-dc7e00abae2a,DISK], DatanodeInfoWithStorage[127.0.0.1:34209,DS-79e3bafb-bd33-427c-affc-6101a74a5125,DISK], DatanodeInfoWithStorage[127.0.0.1:36148,DS-6939165c-7e16-4d6e-8d4b-46892360c490,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1636866626-172.17.0.5-1598343695961:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35115,DS-2ee3b4b5-0d21-48c8-86ec-a23cd4254d8f,DISK], DatanodeInfoWithStorage[127.0.0.1:35011,DS-22cc6195-1602-447b-b72c-353c010cee5f,DISK], DatanodeInfoWithStorage[127.0.0.1:42210,DS-47abd434-5da7-44a4-a39d-b31cfcc293d7,DISK], DatanodeInfoWithStorage[127.0.0.1:38235,DS-23381387-202c-4f33-82f5-6e58e5dd9d4a,DISK], DatanodeInfoWithStorage[127.0.0.1:42020,DS-c423d97c-c662-4b12-a3ba-3498acdf9390,DISK], DatanodeInfoWithStorage[127.0.0.1:36493,DS-58744499-3093-4ce5-96ca-364e222f1a59,DISK], DatanodeInfoWithStorage[127.0.0.1:45530,DS-9cca6a03-272d-4822-8c44-6548bb159719,DISK], DatanodeInfoWithStorage[127.0.0.1:35586,DS-59ba68b9-e9f9-4b95-bb83-eb6531a5477a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1636866626-172.17.0.5-1598343695961:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35115,DS-2ee3b4b5-0d21-48c8-86ec-a23cd4254d8f,DISK], DatanodeInfoWithStorage[127.0.0.1:35011,DS-22cc6195-1602-447b-b72c-353c010cee5f,DISK], DatanodeInfoWithStorage[127.0.0.1:42210,DS-47abd434-5da7-44a4-a39d-b31cfcc293d7,DISK], DatanodeInfoWithStorage[127.0.0.1:38235,DS-23381387-202c-4f33-82f5-6e58e5dd9d4a,DISK], DatanodeInfoWithStorage[127.0.0.1:42020,DS-c423d97c-c662-4b12-a3ba-3498acdf9390,DISK], DatanodeInfoWithStorage[127.0.0.1:36493,DS-58744499-3093-4ce5-96ca-364e222f1a59,DISK], DatanodeInfoWithStorage[127.0.0.1:45530,DS-9cca6a03-272d-4822-8c44-6548bb159719,DISK], DatanodeInfoWithStorage[127.0.0.1:35586,DS-59ba68b9-e9f9-4b95-bb83-eb6531a5477a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 5249
