reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2042698927-172.17.0.5-1598095461685:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43736,DS-4d9f6c24-e2c9-48fe-9379-df3c0e1b54df,DISK], DatanodeInfoWithStorage[127.0.0.1:36716,DS-d8999591-6e9d-405b-a51b-d07d6382013f,DISK], DatanodeInfoWithStorage[127.0.0.1:36001,DS-4661c4cb-f198-45ea-b4a5-ff7afc4c5117,DISK], DatanodeInfoWithStorage[127.0.0.1:43827,DS-16def0ec-7a01-49f4-b037-93429f0aca8d,DISK], DatanodeInfoWithStorage[127.0.0.1:41017,DS-f6dc3211-9eec-4133-8db6-3bea011293a8,DISK], DatanodeInfoWithStorage[127.0.0.1:40271,DS-f5af1385-ffcf-45bb-be48-3fce0627eb2f,DISK], DatanodeInfoWithStorage[127.0.0.1:37580,DS-56e18310-7c67-4b8a-831b-0bf2bb12f602,DISK], DatanodeInfoWithStorage[127.0.0.1:39194,DS-e9c6184e-e32a-417b-80e4-6cf0da883b8c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2042698927-172.17.0.5-1598095461685:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43736,DS-4d9f6c24-e2c9-48fe-9379-df3c0e1b54df,DISK], DatanodeInfoWithStorage[127.0.0.1:36716,DS-d8999591-6e9d-405b-a51b-d07d6382013f,DISK], DatanodeInfoWithStorage[127.0.0.1:36001,DS-4661c4cb-f198-45ea-b4a5-ff7afc4c5117,DISK], DatanodeInfoWithStorage[127.0.0.1:43827,DS-16def0ec-7a01-49f4-b037-93429f0aca8d,DISK], DatanodeInfoWithStorage[127.0.0.1:41017,DS-f6dc3211-9eec-4133-8db6-3bea011293a8,DISK], DatanodeInfoWithStorage[127.0.0.1:40271,DS-f5af1385-ffcf-45bb-be48-3fce0627eb2f,DISK], DatanodeInfoWithStorage[127.0.0.1:37580,DS-56e18310-7c67-4b8a-831b-0bf2bb12f602,DISK], DatanodeInfoWithStorage[127.0.0.1:39194,DS-e9c6184e-e32a-417b-80e4-6cf0da883b8c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1610423220-172.17.0.5-1598095837918:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34730,DS-2b46bed0-7da7-4cb1-9ae3-b36326dd79de,DISK], DatanodeInfoWithStorage[127.0.0.1:38474,DS-0cca6d22-f8f7-4c87-bb23-807eebaaede3,DISK], DatanodeInfoWithStorage[127.0.0.1:37838,DS-b4a8e0aa-85e9-4c4e-ab03-dc228925ef1a,DISK], DatanodeInfoWithStorage[127.0.0.1:40753,DS-8b41d64e-f076-4628-b570-62e5d3924141,DISK], DatanodeInfoWithStorage[127.0.0.1:46560,DS-b5285b24-6e19-4392-b5c3-f416bb59f807,DISK], DatanodeInfoWithStorage[127.0.0.1:35217,DS-ca24dd61-83b6-484a-b149-8036980848a5,DISK], DatanodeInfoWithStorage[127.0.0.1:41032,DS-3ff58ad3-54a1-47ba-ac22-0262a4a0f2bf,DISK], DatanodeInfoWithStorage[127.0.0.1:40989,DS-c2590668-ddbe-46fd-a36c-842a4534e69d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1610423220-172.17.0.5-1598095837918:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34730,DS-2b46bed0-7da7-4cb1-9ae3-b36326dd79de,DISK], DatanodeInfoWithStorage[127.0.0.1:38474,DS-0cca6d22-f8f7-4c87-bb23-807eebaaede3,DISK], DatanodeInfoWithStorage[127.0.0.1:37838,DS-b4a8e0aa-85e9-4c4e-ab03-dc228925ef1a,DISK], DatanodeInfoWithStorage[127.0.0.1:40753,DS-8b41d64e-f076-4628-b570-62e5d3924141,DISK], DatanodeInfoWithStorage[127.0.0.1:46560,DS-b5285b24-6e19-4392-b5c3-f416bb59f807,DISK], DatanodeInfoWithStorage[127.0.0.1:35217,DS-ca24dd61-83b6-484a-b149-8036980848a5,DISK], DatanodeInfoWithStorage[127.0.0.1:41032,DS-3ff58ad3-54a1-47ba-ac22-0262a4a0f2bf,DISK], DatanodeInfoWithStorage[127.0.0.1:40989,DS-c2590668-ddbe-46fd-a36c-842a4534e69d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2095796189-172.17.0.5-1598096884137:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42359,DS-5961f796-eb95-4cbc-b869-70e280f4ba12,DISK], DatanodeInfoWithStorage[127.0.0.1:39625,DS-37b714ce-79f1-42a5-b99f-b44fff04a2a8,DISK], DatanodeInfoWithStorage[127.0.0.1:34910,DS-e3abc37c-bdee-4d53-aee5-05099f25a0bd,DISK], DatanodeInfoWithStorage[127.0.0.1:35022,DS-917724ef-d983-4fcc-9e56-6d9b6fb48325,DISK], DatanodeInfoWithStorage[127.0.0.1:37441,DS-a07c6e76-10a8-4b19-9429-5d5bd795efda,DISK], DatanodeInfoWithStorage[127.0.0.1:39913,DS-28cc11d7-aeb1-494d-a397-0c63d8f9f8db,DISK], DatanodeInfoWithStorage[127.0.0.1:42082,DS-e097f6f7-6cca-4838-99e5-cfb50b47b2a0,DISK], DatanodeInfoWithStorage[127.0.0.1:46671,DS-87e7f5cd-1691-4956-b5f4-b2beff511b3d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2095796189-172.17.0.5-1598096884137:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42359,DS-5961f796-eb95-4cbc-b869-70e280f4ba12,DISK], DatanodeInfoWithStorage[127.0.0.1:39625,DS-37b714ce-79f1-42a5-b99f-b44fff04a2a8,DISK], DatanodeInfoWithStorage[127.0.0.1:34910,DS-e3abc37c-bdee-4d53-aee5-05099f25a0bd,DISK], DatanodeInfoWithStorage[127.0.0.1:35022,DS-917724ef-d983-4fcc-9e56-6d9b6fb48325,DISK], DatanodeInfoWithStorage[127.0.0.1:37441,DS-a07c6e76-10a8-4b19-9429-5d5bd795efda,DISK], DatanodeInfoWithStorage[127.0.0.1:39913,DS-28cc11d7-aeb1-494d-a397-0c63d8f9f8db,DISK], DatanodeInfoWithStorage[127.0.0.1:42082,DS-e097f6f7-6cca-4838-99e5-cfb50b47b2a0,DISK], DatanodeInfoWithStorage[127.0.0.1:46671,DS-87e7f5cd-1691-4956-b5f4-b2beff511b3d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-148291323-172.17.0.5-1598097120666:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37631,DS-5b690c15-26e0-49fd-91eb-f57f13d5c1e2,DISK], DatanodeInfoWithStorage[127.0.0.1:33619,DS-25fb2694-baab-40ed-b544-7ee4a795b32b,DISK], DatanodeInfoWithStorage[127.0.0.1:40284,DS-f656d873-c989-422a-869e-df3c01d4e79f,DISK], DatanodeInfoWithStorage[127.0.0.1:37023,DS-cb4fe976-44d9-441f-bd1b-af923c8623e6,DISK], DatanodeInfoWithStorage[127.0.0.1:35858,DS-4a19566d-d7c3-4d02-a9ed-ca65372eff7c,DISK], DatanodeInfoWithStorage[127.0.0.1:42505,DS-5dddfd36-693e-45af-8915-d8d6bc677a63,DISK], DatanodeInfoWithStorage[127.0.0.1:45453,DS-2381e6ae-5250-4291-85eb-ca38bcf0963e,DISK], DatanodeInfoWithStorage[127.0.0.1:37085,DS-fed5d93b-7c0e-49d9-b6a5-4b93b9be3aad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-148291323-172.17.0.5-1598097120666:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37631,DS-5b690c15-26e0-49fd-91eb-f57f13d5c1e2,DISK], DatanodeInfoWithStorage[127.0.0.1:33619,DS-25fb2694-baab-40ed-b544-7ee4a795b32b,DISK], DatanodeInfoWithStorage[127.0.0.1:40284,DS-f656d873-c989-422a-869e-df3c01d4e79f,DISK], DatanodeInfoWithStorage[127.0.0.1:37023,DS-cb4fe976-44d9-441f-bd1b-af923c8623e6,DISK], DatanodeInfoWithStorage[127.0.0.1:35858,DS-4a19566d-d7c3-4d02-a9ed-ca65372eff7c,DISK], DatanodeInfoWithStorage[127.0.0.1:42505,DS-5dddfd36-693e-45af-8915-d8d6bc677a63,DISK], DatanodeInfoWithStorage[127.0.0.1:45453,DS-2381e6ae-5250-4291-85eb-ca38bcf0963e,DISK], DatanodeInfoWithStorage[127.0.0.1:37085,DS-fed5d93b-7c0e-49d9-b6a5-4b93b9be3aad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1018869974-172.17.0.5-1598097361255:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36713,DS-a20011db-8236-4815-99af-202e6ddb8a2b,DISK], DatanodeInfoWithStorage[127.0.0.1:42058,DS-db2b0269-4077-4841-bec1-36a3cf1e3168,DISK], DatanodeInfoWithStorage[127.0.0.1:32946,DS-6fb322a3-85ac-40e7-a583-426bbb653cb3,DISK], DatanodeInfoWithStorage[127.0.0.1:35126,DS-328e1b1d-a763-46ff-8ef0-15a93da3f4b2,DISK], DatanodeInfoWithStorage[127.0.0.1:35809,DS-2b775677-b0de-4ddf-9ebf-67da898340f8,DISK], DatanodeInfoWithStorage[127.0.0.1:46717,DS-7cfda669-d46b-4f6a-8e03-f82cfed7bfc4,DISK], DatanodeInfoWithStorage[127.0.0.1:44859,DS-8cdcaed3-420b-463d-9ace-d41b490598dd,DISK], DatanodeInfoWithStorage[127.0.0.1:40900,DS-851ee431-f049-463a-8e53-3d6613a152f4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1018869974-172.17.0.5-1598097361255:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36713,DS-a20011db-8236-4815-99af-202e6ddb8a2b,DISK], DatanodeInfoWithStorage[127.0.0.1:42058,DS-db2b0269-4077-4841-bec1-36a3cf1e3168,DISK], DatanodeInfoWithStorage[127.0.0.1:32946,DS-6fb322a3-85ac-40e7-a583-426bbb653cb3,DISK], DatanodeInfoWithStorage[127.0.0.1:35126,DS-328e1b1d-a763-46ff-8ef0-15a93da3f4b2,DISK], DatanodeInfoWithStorage[127.0.0.1:35809,DS-2b775677-b0de-4ddf-9ebf-67da898340f8,DISK], DatanodeInfoWithStorage[127.0.0.1:46717,DS-7cfda669-d46b-4f6a-8e03-f82cfed7bfc4,DISK], DatanodeInfoWithStorage[127.0.0.1:44859,DS-8cdcaed3-420b-463d-9ace-d41b490598dd,DISK], DatanodeInfoWithStorage[127.0.0.1:40900,DS-851ee431-f049-463a-8e53-3d6613a152f4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1372250827-172.17.0.5-1598097503036:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44388,DS-04615f18-e1a9-444a-9ba3-6ef2ba7f7165,DISK], DatanodeInfoWithStorage[127.0.0.1:43353,DS-a712b604-58cd-4142-8e9b-8dbf7720a6d2,DISK], DatanodeInfoWithStorage[127.0.0.1:35531,DS-cf4e1466-4ad6-4ec7-af13-920d0437792f,DISK], DatanodeInfoWithStorage[127.0.0.1:41143,DS-a69c44e9-6d03-4363-b63c-7504764008af,DISK], DatanodeInfoWithStorage[127.0.0.1:35217,DS-cea8864d-8af1-4ebb-9c78-d389ed18550f,DISK], DatanodeInfoWithStorage[127.0.0.1:35289,DS-f412fbdf-703a-481c-a9f5-ef355b72ef00,DISK], DatanodeInfoWithStorage[127.0.0.1:46591,DS-879ca8b5-cd46-45ce-8450-711d695959e3,DISK], DatanodeInfoWithStorage[127.0.0.1:34435,DS-d149bd5d-ab13-4fbb-877f-ece67ac0b700,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1372250827-172.17.0.5-1598097503036:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44388,DS-04615f18-e1a9-444a-9ba3-6ef2ba7f7165,DISK], DatanodeInfoWithStorage[127.0.0.1:43353,DS-a712b604-58cd-4142-8e9b-8dbf7720a6d2,DISK], DatanodeInfoWithStorage[127.0.0.1:35531,DS-cf4e1466-4ad6-4ec7-af13-920d0437792f,DISK], DatanodeInfoWithStorage[127.0.0.1:41143,DS-a69c44e9-6d03-4363-b63c-7504764008af,DISK], DatanodeInfoWithStorage[127.0.0.1:35217,DS-cea8864d-8af1-4ebb-9c78-d389ed18550f,DISK], DatanodeInfoWithStorage[127.0.0.1:35289,DS-f412fbdf-703a-481c-a9f5-ef355b72ef00,DISK], DatanodeInfoWithStorage[127.0.0.1:46591,DS-879ca8b5-cd46-45ce-8450-711d695959e3,DISK], DatanodeInfoWithStorage[127.0.0.1:34435,DS-d149bd5d-ab13-4fbb-877f-ece67ac0b700,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1877600978-172.17.0.5-1598098106881:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45682,DS-c922c89d-28fe-4487-94da-9949752c6087,DISK], DatanodeInfoWithStorage[127.0.0.1:33160,DS-577ed341-6ff2-4199-a7f1-4d3b4ca12df9,DISK], DatanodeInfoWithStorage[127.0.0.1:33851,DS-16d6a1fe-3749-4079-97d9-5dbc14f75dcb,DISK], DatanodeInfoWithStorage[127.0.0.1:39856,DS-db8fde83-e46a-4481-930c-8131671e0d03,DISK], DatanodeInfoWithStorage[127.0.0.1:39996,DS-e2b4a690-1cfb-47bb-8391-bec803ba1e18,DISK], DatanodeInfoWithStorage[127.0.0.1:42250,DS-851e4dd1-cf3c-4698-90eb-449bf00bb149,DISK], DatanodeInfoWithStorage[127.0.0.1:40106,DS-8f93a7b3-1cc3-4b34-b732-1d2ad954cabc,DISK], DatanodeInfoWithStorage[127.0.0.1:38949,DS-73caf59b-e1df-44be-a81f-01f4b58e08bd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1877600978-172.17.0.5-1598098106881:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45682,DS-c922c89d-28fe-4487-94da-9949752c6087,DISK], DatanodeInfoWithStorage[127.0.0.1:33160,DS-577ed341-6ff2-4199-a7f1-4d3b4ca12df9,DISK], DatanodeInfoWithStorage[127.0.0.1:33851,DS-16d6a1fe-3749-4079-97d9-5dbc14f75dcb,DISK], DatanodeInfoWithStorage[127.0.0.1:39856,DS-db8fde83-e46a-4481-930c-8131671e0d03,DISK], DatanodeInfoWithStorage[127.0.0.1:39996,DS-e2b4a690-1cfb-47bb-8391-bec803ba1e18,DISK], DatanodeInfoWithStorage[127.0.0.1:42250,DS-851e4dd1-cf3c-4698-90eb-449bf00bb149,DISK], DatanodeInfoWithStorage[127.0.0.1:40106,DS-8f93a7b3-1cc3-4b34-b732-1d2ad954cabc,DISK], DatanodeInfoWithStorage[127.0.0.1:38949,DS-73caf59b-e1df-44be-a81f-01f4b58e08bd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1575750820-172.17.0.5-1598098599531:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44546,DS-27bd1dfb-d9ab-4dfd-b0c0-7564367b71fb,DISK], DatanodeInfoWithStorage[127.0.0.1:43746,DS-63b3051a-d711-485c-b076-22c6e0c68af0,DISK], DatanodeInfoWithStorage[127.0.0.1:45229,DS-61c8b93e-c118-4544-a142-5d588cc6523c,DISK], DatanodeInfoWithStorage[127.0.0.1:33207,DS-5ffe1a87-c35f-42dc-9508-4a3617926f1b,DISK], DatanodeInfoWithStorage[127.0.0.1:44982,DS-f62205ed-3536-4a45-a6c8-1287fa4f5aaf,DISK], DatanodeInfoWithStorage[127.0.0.1:39263,DS-0ec3ce50-299b-4f8b-9cc9-726efac8af5b,DISK], DatanodeInfoWithStorage[127.0.0.1:37614,DS-4824d65e-eb3f-4026-9a6e-263f754816f9,DISK], DatanodeInfoWithStorage[127.0.0.1:42092,DS-9085fb4b-8b7f-4902-8aa1-91fc593912aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1575750820-172.17.0.5-1598098599531:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44546,DS-27bd1dfb-d9ab-4dfd-b0c0-7564367b71fb,DISK], DatanodeInfoWithStorage[127.0.0.1:43746,DS-63b3051a-d711-485c-b076-22c6e0c68af0,DISK], DatanodeInfoWithStorage[127.0.0.1:45229,DS-61c8b93e-c118-4544-a142-5d588cc6523c,DISK], DatanodeInfoWithStorage[127.0.0.1:33207,DS-5ffe1a87-c35f-42dc-9508-4a3617926f1b,DISK], DatanodeInfoWithStorage[127.0.0.1:44982,DS-f62205ed-3536-4a45-a6c8-1287fa4f5aaf,DISK], DatanodeInfoWithStorage[127.0.0.1:39263,DS-0ec3ce50-299b-4f8b-9cc9-726efac8af5b,DISK], DatanodeInfoWithStorage[127.0.0.1:37614,DS-4824d65e-eb3f-4026-9a6e-263f754816f9,DISK], DatanodeInfoWithStorage[127.0.0.1:42092,DS-9085fb4b-8b7f-4902-8aa1-91fc593912aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2041219813-172.17.0.5-1598099228185:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39950,DS-72842e8d-6481-4438-baae-087fa8347698,DISK], DatanodeInfoWithStorage[127.0.0.1:38718,DS-a0cb4cf3-e0e2-41a6-9eac-d8c9124d53bc,DISK], DatanodeInfoWithStorage[127.0.0.1:42030,DS-0ca47b9b-8536-46d4-8192-b6a9c32e1303,DISK], DatanodeInfoWithStorage[127.0.0.1:35133,DS-e668d6bb-e400-4840-b3b0-76f836fe20dd,DISK], DatanodeInfoWithStorage[127.0.0.1:38528,DS-e0b30f9e-bb9f-4883-b2c2-8d03aa931439,DISK], DatanodeInfoWithStorage[127.0.0.1:33384,DS-df7acb2b-41e0-4b58-802a-d323f085f847,DISK], DatanodeInfoWithStorage[127.0.0.1:38729,DS-a970139a-944b-446a-8c5d-54b1337442da,DISK], DatanodeInfoWithStorage[127.0.0.1:41069,DS-8c8e3aca-dd2c-4f82-bce0-b924ac76f909,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2041219813-172.17.0.5-1598099228185:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39950,DS-72842e8d-6481-4438-baae-087fa8347698,DISK], DatanodeInfoWithStorage[127.0.0.1:38718,DS-a0cb4cf3-e0e2-41a6-9eac-d8c9124d53bc,DISK], DatanodeInfoWithStorage[127.0.0.1:42030,DS-0ca47b9b-8536-46d4-8192-b6a9c32e1303,DISK], DatanodeInfoWithStorage[127.0.0.1:35133,DS-e668d6bb-e400-4840-b3b0-76f836fe20dd,DISK], DatanodeInfoWithStorage[127.0.0.1:38528,DS-e0b30f9e-bb9f-4883-b2c2-8d03aa931439,DISK], DatanodeInfoWithStorage[127.0.0.1:33384,DS-df7acb2b-41e0-4b58-802a-d323f085f847,DISK], DatanodeInfoWithStorage[127.0.0.1:38729,DS-a970139a-944b-446a-8c5d-54b1337442da,DISK], DatanodeInfoWithStorage[127.0.0.1:41069,DS-8c8e3aca-dd2c-4f82-bce0-b924ac76f909,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-690899307-172.17.0.5-1598099732430:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33877,DS-7b6dc5d1-ad4c-456a-b262-6c455b696645,DISK], DatanodeInfoWithStorage[127.0.0.1:46763,DS-2b85302d-d740-4b1d-86c7-4c8863df40ef,DISK], DatanodeInfoWithStorage[127.0.0.1:39280,DS-98d7a9c9-a7d0-4dbb-8736-3b73c225ccbf,DISK], DatanodeInfoWithStorage[127.0.0.1:40570,DS-888b8ad6-bf7a-4a61-90f8-c2f0b71acaf2,DISK], DatanodeInfoWithStorage[127.0.0.1:34726,DS-0eecfd35-3cf6-457f-9050-b7bc0a27cf21,DISK], DatanodeInfoWithStorage[127.0.0.1:40540,DS-cdf6276c-eef1-4842-9cd1-98eb7b1181d0,DISK], DatanodeInfoWithStorage[127.0.0.1:46638,DS-f92f0ba9-2a9e-4bec-8f90-8a859c4fbda7,DISK], DatanodeInfoWithStorage[127.0.0.1:35861,DS-8983d361-3746-41ff-96b5-a24498a71f2e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-690899307-172.17.0.5-1598099732430:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33877,DS-7b6dc5d1-ad4c-456a-b262-6c455b696645,DISK], DatanodeInfoWithStorage[127.0.0.1:46763,DS-2b85302d-d740-4b1d-86c7-4c8863df40ef,DISK], DatanodeInfoWithStorage[127.0.0.1:39280,DS-98d7a9c9-a7d0-4dbb-8736-3b73c225ccbf,DISK], DatanodeInfoWithStorage[127.0.0.1:40570,DS-888b8ad6-bf7a-4a61-90f8-c2f0b71acaf2,DISK], DatanodeInfoWithStorage[127.0.0.1:34726,DS-0eecfd35-3cf6-457f-9050-b7bc0a27cf21,DISK], DatanodeInfoWithStorage[127.0.0.1:40540,DS-cdf6276c-eef1-4842-9cd1-98eb7b1181d0,DISK], DatanodeInfoWithStorage[127.0.0.1:46638,DS-f92f0ba9-2a9e-4bec-8f90-8a859c4fbda7,DISK], DatanodeInfoWithStorage[127.0.0.1:35861,DS-8983d361-3746-41ff-96b5-a24498a71f2e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-625825459-172.17.0.5-1598100755054:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40163,DS-405d093e-655c-4ebe-9de6-8460c612f178,DISK], DatanodeInfoWithStorage[127.0.0.1:46831,DS-8e86a72d-1641-40da-81d1-b417d8d24b2e,DISK], DatanodeInfoWithStorage[127.0.0.1:41653,DS-d99c0c99-06be-432c-a486-be5345688bcc,DISK], DatanodeInfoWithStorage[127.0.0.1:42399,DS-35d06e9f-1f46-4172-9654-d427a70c1ead,DISK], DatanodeInfoWithStorage[127.0.0.1:41412,DS-41fb89eb-4710-452d-a426-31859052d6c9,DISK], DatanodeInfoWithStorage[127.0.0.1:44691,DS-7b28b043-a2ec-4a23-80d4-6d894866a1b8,DISK], DatanodeInfoWithStorage[127.0.0.1:35456,DS-cde7b7a8-06b1-4f7f-aae9-1f27dc75df8a,DISK], DatanodeInfoWithStorage[127.0.0.1:37717,DS-3a53254d-157d-41c5-9d1d-dba1fbde9c5f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-625825459-172.17.0.5-1598100755054:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40163,DS-405d093e-655c-4ebe-9de6-8460c612f178,DISK], DatanodeInfoWithStorage[127.0.0.1:46831,DS-8e86a72d-1641-40da-81d1-b417d8d24b2e,DISK], DatanodeInfoWithStorage[127.0.0.1:41653,DS-d99c0c99-06be-432c-a486-be5345688bcc,DISK], DatanodeInfoWithStorage[127.0.0.1:42399,DS-35d06e9f-1f46-4172-9654-d427a70c1ead,DISK], DatanodeInfoWithStorage[127.0.0.1:41412,DS-41fb89eb-4710-452d-a426-31859052d6c9,DISK], DatanodeInfoWithStorage[127.0.0.1:44691,DS-7b28b043-a2ec-4a23-80d4-6d894866a1b8,DISK], DatanodeInfoWithStorage[127.0.0.1:35456,DS-cde7b7a8-06b1-4f7f-aae9-1f27dc75df8a,DISK], DatanodeInfoWithStorage[127.0.0.1:37717,DS-3a53254d-157d-41c5-9d1d-dba1fbde9c5f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1749692586-172.17.0.5-1598100792581:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33633,DS-009d1dc9-91c6-48bc-8c3c-825e7adbae27,DISK], DatanodeInfoWithStorage[127.0.0.1:40663,DS-416cee5f-f2d2-4f5c-abea-0fd12c2069a6,DISK], DatanodeInfoWithStorage[127.0.0.1:36962,DS-288a937f-3d8a-4b88-969c-39a4296f3d30,DISK], DatanodeInfoWithStorage[127.0.0.1:40841,DS-a552474e-0ad5-4ab1-a83d-4fd0e325f74e,DISK], DatanodeInfoWithStorage[127.0.0.1:34134,DS-3919bab6-a532-4d5b-85b2-0549fda72bfa,DISK], DatanodeInfoWithStorage[127.0.0.1:43656,DS-608ff0c3-ab30-4bb6-bb70-cd69e8d9dbdb,DISK], DatanodeInfoWithStorage[127.0.0.1:44928,DS-4f04e18f-cc55-4fb0-a9e6-ea0c1f6ee378,DISK], DatanodeInfoWithStorage[127.0.0.1:39986,DS-780d4929-956d-499f-aeb3-e09157707048,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1749692586-172.17.0.5-1598100792581:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33633,DS-009d1dc9-91c6-48bc-8c3c-825e7adbae27,DISK], DatanodeInfoWithStorage[127.0.0.1:40663,DS-416cee5f-f2d2-4f5c-abea-0fd12c2069a6,DISK], DatanodeInfoWithStorage[127.0.0.1:36962,DS-288a937f-3d8a-4b88-969c-39a4296f3d30,DISK], DatanodeInfoWithStorage[127.0.0.1:40841,DS-a552474e-0ad5-4ab1-a83d-4fd0e325f74e,DISK], DatanodeInfoWithStorage[127.0.0.1:34134,DS-3919bab6-a532-4d5b-85b2-0549fda72bfa,DISK], DatanodeInfoWithStorage[127.0.0.1:43656,DS-608ff0c3-ab30-4bb6-bb70-cd69e8d9dbdb,DISK], DatanodeInfoWithStorage[127.0.0.1:44928,DS-4f04e18f-cc55-4fb0-a9e6-ea0c1f6ee378,DISK], DatanodeInfoWithStorage[127.0.0.1:39986,DS-780d4929-956d-499f-aeb3-e09157707048,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2106920886-172.17.0.5-1598100967709:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42787,DS-780dda0c-d2f5-4a14-80dc-42546de362c8,DISK], DatanodeInfoWithStorage[127.0.0.1:35060,DS-2503268d-af35-49ab-9d08-9c080f8280d6,DISK], DatanodeInfoWithStorage[127.0.0.1:44250,DS-c12197e1-b6b3-4aac-bcad-de3a398e75f6,DISK], DatanodeInfoWithStorage[127.0.0.1:44673,DS-a3f95e01-122b-4a8d-8d17-f97f758ada3a,DISK], DatanodeInfoWithStorage[127.0.0.1:32982,DS-8ca332a6-b55f-41e5-97bf-871ee690c2a5,DISK], DatanodeInfoWithStorage[127.0.0.1:42115,DS-7c1829fa-3cb5-4784-91f0-8a0ad266e5a1,DISK], DatanodeInfoWithStorage[127.0.0.1:43303,DS-085d59b5-0cf1-49a3-8874-3a59059ae588,DISK], DatanodeInfoWithStorage[127.0.0.1:37105,DS-ad05b4f3-0bf0-4d72-8d59-3866bda3b441,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2106920886-172.17.0.5-1598100967709:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42787,DS-780dda0c-d2f5-4a14-80dc-42546de362c8,DISK], DatanodeInfoWithStorage[127.0.0.1:35060,DS-2503268d-af35-49ab-9d08-9c080f8280d6,DISK], DatanodeInfoWithStorage[127.0.0.1:44250,DS-c12197e1-b6b3-4aac-bcad-de3a398e75f6,DISK], DatanodeInfoWithStorage[127.0.0.1:44673,DS-a3f95e01-122b-4a8d-8d17-f97f758ada3a,DISK], DatanodeInfoWithStorage[127.0.0.1:32982,DS-8ca332a6-b55f-41e5-97bf-871ee690c2a5,DISK], DatanodeInfoWithStorage[127.0.0.1:42115,DS-7c1829fa-3cb5-4784-91f0-8a0ad266e5a1,DISK], DatanodeInfoWithStorage[127.0.0.1:43303,DS-085d59b5-0cf1-49a3-8874-3a59059ae588,DISK], DatanodeInfoWithStorage[127.0.0.1:37105,DS-ad05b4f3-0bf0-4d72-8d59-3866bda3b441,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2039041492-172.17.0.5-1598101247220:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33342,DS-77f7ac10-9917-49a9-a323-381ef8b77e9d,DISK], DatanodeInfoWithStorage[127.0.0.1:43136,DS-2af0ca58-3885-4f74-8c27-2acb4cde5b78,DISK], DatanodeInfoWithStorage[127.0.0.1:34458,DS-a4d704f6-aa33-4880-a788-f1efa98d06dd,DISK], DatanodeInfoWithStorage[127.0.0.1:41692,DS-1c5c1022-63b0-40fe-8b99-d7a76781fc33,DISK], DatanodeInfoWithStorage[127.0.0.1:41870,DS-4ffd57f1-033f-4d66-b51d-39e14de9f675,DISK], DatanodeInfoWithStorage[127.0.0.1:43804,DS-1958df8e-fd00-4822-afc7-001c1423166d,DISK], DatanodeInfoWithStorage[127.0.0.1:45780,DS-0295532d-42b7-4bf5-8da1-a932e99118d3,DISK], DatanodeInfoWithStorage[127.0.0.1:38366,DS-38c7b057-0885-4e67-b127-4015e790741e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2039041492-172.17.0.5-1598101247220:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33342,DS-77f7ac10-9917-49a9-a323-381ef8b77e9d,DISK], DatanodeInfoWithStorage[127.0.0.1:43136,DS-2af0ca58-3885-4f74-8c27-2acb4cde5b78,DISK], DatanodeInfoWithStorage[127.0.0.1:34458,DS-a4d704f6-aa33-4880-a788-f1efa98d06dd,DISK], DatanodeInfoWithStorage[127.0.0.1:41692,DS-1c5c1022-63b0-40fe-8b99-d7a76781fc33,DISK], DatanodeInfoWithStorage[127.0.0.1:41870,DS-4ffd57f1-033f-4d66-b51d-39e14de9f675,DISK], DatanodeInfoWithStorage[127.0.0.1:43804,DS-1958df8e-fd00-4822-afc7-001c1423166d,DISK], DatanodeInfoWithStorage[127.0.0.1:45780,DS-0295532d-42b7-4bf5-8da1-a932e99118d3,DISK], DatanodeInfoWithStorage[127.0.0.1:38366,DS-38c7b057-0885-4e67-b127-4015e790741e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1180098956-172.17.0.5-1598101559626:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44483,DS-dca19e56-ac34-48d3-9212-7dae97d633b5,DISK], DatanodeInfoWithStorage[127.0.0.1:38433,DS-25f45c33-052c-494b-a286-46eb27caf612,DISK], DatanodeInfoWithStorage[127.0.0.1:36405,DS-cb30157f-9758-4196-aa6a-01c187777030,DISK], DatanodeInfoWithStorage[127.0.0.1:42951,DS-e9d47b8b-abb3-4bb9-a9be-9ba8f66d5844,DISK], DatanodeInfoWithStorage[127.0.0.1:34011,DS-9cd9c96b-6221-4092-b955-fc76ac6fe2c2,DISK], DatanodeInfoWithStorage[127.0.0.1:43212,DS-808c4605-62d4-4ee5-9993-151b6710c5e2,DISK], DatanodeInfoWithStorage[127.0.0.1:36313,DS-eb2cb720-3462-47de-b21c-9d4e5e294300,DISK], DatanodeInfoWithStorage[127.0.0.1:36845,DS-3c20f016-6823-4671-8f46-014966fcc4d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1180098956-172.17.0.5-1598101559626:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44483,DS-dca19e56-ac34-48d3-9212-7dae97d633b5,DISK], DatanodeInfoWithStorage[127.0.0.1:38433,DS-25f45c33-052c-494b-a286-46eb27caf612,DISK], DatanodeInfoWithStorage[127.0.0.1:36405,DS-cb30157f-9758-4196-aa6a-01c187777030,DISK], DatanodeInfoWithStorage[127.0.0.1:42951,DS-e9d47b8b-abb3-4bb9-a9be-9ba8f66d5844,DISK], DatanodeInfoWithStorage[127.0.0.1:34011,DS-9cd9c96b-6221-4092-b955-fc76ac6fe2c2,DISK], DatanodeInfoWithStorage[127.0.0.1:43212,DS-808c4605-62d4-4ee5-9993-151b6710c5e2,DISK], DatanodeInfoWithStorage[127.0.0.1:36313,DS-eb2cb720-3462-47de-b21c-9d4e5e294300,DISK], DatanodeInfoWithStorage[127.0.0.1:36845,DS-3c20f016-6823-4671-8f46-014966fcc4d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1603193312-172.17.0.5-1598101690551:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45288,DS-e3237a6b-ceef-4dfa-8909-ebb0e8e564de,DISK], DatanodeInfoWithStorage[127.0.0.1:38505,DS-07e24198-4ad0-4f32-8403-4b063c92fc99,DISK], DatanodeInfoWithStorage[127.0.0.1:39491,DS-f5163808-ac9f-434a-9113-a86c0b073a80,DISK], DatanodeInfoWithStorage[127.0.0.1:43450,DS-38daef99-e5c8-4df2-988e-2ebe00838e0e,DISK], DatanodeInfoWithStorage[127.0.0.1:32778,DS-49612887-9dc2-4c73-a363-b6bd1fe12137,DISK], DatanodeInfoWithStorage[127.0.0.1:37195,DS-2ccf06b4-f8e1-4dc0-945a-a065ac3ab36d,DISK], DatanodeInfoWithStorage[127.0.0.1:33795,DS-aa5be365-8fcf-4d96-972e-74ea650acdf1,DISK], DatanodeInfoWithStorage[127.0.0.1:37887,DS-d14db8aa-dc34-43e9-8829-e1385fb1f854,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1603193312-172.17.0.5-1598101690551:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45288,DS-e3237a6b-ceef-4dfa-8909-ebb0e8e564de,DISK], DatanodeInfoWithStorage[127.0.0.1:38505,DS-07e24198-4ad0-4f32-8403-4b063c92fc99,DISK], DatanodeInfoWithStorage[127.0.0.1:39491,DS-f5163808-ac9f-434a-9113-a86c0b073a80,DISK], DatanodeInfoWithStorage[127.0.0.1:43450,DS-38daef99-e5c8-4df2-988e-2ebe00838e0e,DISK], DatanodeInfoWithStorage[127.0.0.1:32778,DS-49612887-9dc2-4c73-a363-b6bd1fe12137,DISK], DatanodeInfoWithStorage[127.0.0.1:37195,DS-2ccf06b4-f8e1-4dc0-945a-a065ac3ab36d,DISK], DatanodeInfoWithStorage[127.0.0.1:33795,DS-aa5be365-8fcf-4d96-972e-74ea650acdf1,DISK], DatanodeInfoWithStorage[127.0.0.1:37887,DS-d14db8aa-dc34-43e9-8829-e1385fb1f854,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2014759573-172.17.0.5-1598101776751:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38238,DS-2d510130-36b9-4f7b-aeaf-948c76a5e28a,DISK], DatanodeInfoWithStorage[127.0.0.1:42987,DS-9eb5b800-b6c2-4d2b-840e-c27039a07801,DISK], DatanodeInfoWithStorage[127.0.0.1:40350,DS-941b137e-3962-42ac-870d-70eed31c4364,DISK], DatanodeInfoWithStorage[127.0.0.1:38503,DS-6861dc13-a2cf-4301-9c45-c5cfa0f6fcd8,DISK], DatanodeInfoWithStorage[127.0.0.1:38452,DS-afa7f994-daa0-4959-9a28-2e8fce5b3f5f,DISK], DatanodeInfoWithStorage[127.0.0.1:41105,DS-2d07ff8c-b8a9-47ce-98a7-14f0d8c3059d,DISK], DatanodeInfoWithStorage[127.0.0.1:36895,DS-b7f7119d-e335-44dc-96bf-d7d0eb878695,DISK], DatanodeInfoWithStorage[127.0.0.1:41179,DS-a1a120e0-c6f8-4f60-80d7-f14dca774796,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2014759573-172.17.0.5-1598101776751:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38238,DS-2d510130-36b9-4f7b-aeaf-948c76a5e28a,DISK], DatanodeInfoWithStorage[127.0.0.1:42987,DS-9eb5b800-b6c2-4d2b-840e-c27039a07801,DISK], DatanodeInfoWithStorage[127.0.0.1:40350,DS-941b137e-3962-42ac-870d-70eed31c4364,DISK], DatanodeInfoWithStorage[127.0.0.1:38503,DS-6861dc13-a2cf-4301-9c45-c5cfa0f6fcd8,DISK], DatanodeInfoWithStorage[127.0.0.1:38452,DS-afa7f994-daa0-4959-9a28-2e8fce5b3f5f,DISK], DatanodeInfoWithStorage[127.0.0.1:41105,DS-2d07ff8c-b8a9-47ce-98a7-14f0d8c3059d,DISK], DatanodeInfoWithStorage[127.0.0.1:36895,DS-b7f7119d-e335-44dc-96bf-d7d0eb878695,DISK], DatanodeInfoWithStorage[127.0.0.1:41179,DS-a1a120e0-c6f8-4f60-80d7-f14dca774796,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-812355730-172.17.0.5-1598102030986:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42576,DS-fb426b96-33ad-40e5-8310-5fa2d32dd6e2,DISK], DatanodeInfoWithStorage[127.0.0.1:42648,DS-886682a8-291c-4934-935e-8b97a127304b,DISK], DatanodeInfoWithStorage[127.0.0.1:41220,DS-886fc6fc-f7f0-4c2f-99c0-d2c0b8687173,DISK], DatanodeInfoWithStorage[127.0.0.1:45638,DS-4cf4ab9a-56cb-4067-b1c2-32f6a87b0da4,DISK], DatanodeInfoWithStorage[127.0.0.1:45982,DS-f80a0ff2-b9f5-47c9-8261-bd5d45655bb1,DISK], DatanodeInfoWithStorage[127.0.0.1:42282,DS-03f563d4-ed3a-4521-9166-79d7c08df914,DISK], DatanodeInfoWithStorage[127.0.0.1:34557,DS-53c82dcf-6ea0-47da-9c0c-a2204b834cbf,DISK], DatanodeInfoWithStorage[127.0.0.1:44891,DS-5b2c7c77-3ff1-4f63-9ff6-fbf3b2cf1df3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-812355730-172.17.0.5-1598102030986:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42576,DS-fb426b96-33ad-40e5-8310-5fa2d32dd6e2,DISK], DatanodeInfoWithStorage[127.0.0.1:42648,DS-886682a8-291c-4934-935e-8b97a127304b,DISK], DatanodeInfoWithStorage[127.0.0.1:41220,DS-886fc6fc-f7f0-4c2f-99c0-d2c0b8687173,DISK], DatanodeInfoWithStorage[127.0.0.1:45638,DS-4cf4ab9a-56cb-4067-b1c2-32f6a87b0da4,DISK], DatanodeInfoWithStorage[127.0.0.1:45982,DS-f80a0ff2-b9f5-47c9-8261-bd5d45655bb1,DISK], DatanodeInfoWithStorage[127.0.0.1:42282,DS-03f563d4-ed3a-4521-9166-79d7c08df914,DISK], DatanodeInfoWithStorage[127.0.0.1:34557,DS-53c82dcf-6ea0-47da-9c0c-a2204b834cbf,DISK], DatanodeInfoWithStorage[127.0.0.1:44891,DS-5b2c7c77-3ff1-4f63-9ff6-fbf3b2cf1df3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 6871
