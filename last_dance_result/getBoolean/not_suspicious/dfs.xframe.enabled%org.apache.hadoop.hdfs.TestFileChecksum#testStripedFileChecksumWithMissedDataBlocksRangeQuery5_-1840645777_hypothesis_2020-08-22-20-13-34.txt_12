reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1231394926-172.17.0.14-1598127535507:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39637,DS-866e28ad-00f7-4ffa-aaf3-6b9d819bd838,DISK], DatanodeInfoWithStorage[127.0.0.1:44614,DS-40a6acdb-2e87-4416-9518-c09726e2fb7c,DISK], DatanodeInfoWithStorage[127.0.0.1:42887,DS-dc65c25e-f752-4b60-b219-411948522a9d,DISK], DatanodeInfoWithStorage[127.0.0.1:36355,DS-8d2ef748-7a0a-49db-b88d-2c5a235ba85f,DISK], DatanodeInfoWithStorage[127.0.0.1:40197,DS-c68406b4-e5ff-49a2-aa18-334d0d0c5a5f,DISK], DatanodeInfoWithStorage[127.0.0.1:34232,DS-65e19b0d-33c3-4ded-9dbc-a98367505270,DISK], DatanodeInfoWithStorage[127.0.0.1:42180,DS-dd6f4b9b-10d9-4228-8525-2b586802d4ff,DISK], DatanodeInfoWithStorage[127.0.0.1:37058,DS-b0c930b4-d153-4ad8-84e1-7981775d5123,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1231394926-172.17.0.14-1598127535507:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39637,DS-866e28ad-00f7-4ffa-aaf3-6b9d819bd838,DISK], DatanodeInfoWithStorage[127.0.0.1:44614,DS-40a6acdb-2e87-4416-9518-c09726e2fb7c,DISK], DatanodeInfoWithStorage[127.0.0.1:42887,DS-dc65c25e-f752-4b60-b219-411948522a9d,DISK], DatanodeInfoWithStorage[127.0.0.1:36355,DS-8d2ef748-7a0a-49db-b88d-2c5a235ba85f,DISK], DatanodeInfoWithStorage[127.0.0.1:40197,DS-c68406b4-e5ff-49a2-aa18-334d0d0c5a5f,DISK], DatanodeInfoWithStorage[127.0.0.1:34232,DS-65e19b0d-33c3-4ded-9dbc-a98367505270,DISK], DatanodeInfoWithStorage[127.0.0.1:42180,DS-dd6f4b9b-10d9-4228-8525-2b586802d4ff,DISK], DatanodeInfoWithStorage[127.0.0.1:37058,DS-b0c930b4-d153-4ad8-84e1-7981775d5123,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-252410236-172.17.0.14-1598127806794:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43592,DS-3faeb738-68f1-47c4-bf10-d4d4bb031b53,DISK], DatanodeInfoWithStorage[127.0.0.1:44816,DS-9955d95a-d03b-4864-be2f-54bb330c9842,DISK], DatanodeInfoWithStorage[127.0.0.1:45187,DS-b4d6af77-c6c8-475c-84c9-cd98a647d185,DISK], DatanodeInfoWithStorage[127.0.0.1:43868,DS-fac81135-81b1-4948-839a-d01dfad03810,DISK], DatanodeInfoWithStorage[127.0.0.1:46224,DS-c95a5be3-b724-49c2-84b4-8efcae707ca1,DISK], DatanodeInfoWithStorage[127.0.0.1:36501,DS-e85378ec-16b0-4503-9898-6840195b20c7,DISK], DatanodeInfoWithStorage[127.0.0.1:42253,DS-a8d897be-4e33-4428-ac13-f3695731e1ab,DISK], DatanodeInfoWithStorage[127.0.0.1:33004,DS-50c7c97d-a532-4e96-90f4-9c408de10520,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-252410236-172.17.0.14-1598127806794:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43592,DS-3faeb738-68f1-47c4-bf10-d4d4bb031b53,DISK], DatanodeInfoWithStorage[127.0.0.1:44816,DS-9955d95a-d03b-4864-be2f-54bb330c9842,DISK], DatanodeInfoWithStorage[127.0.0.1:45187,DS-b4d6af77-c6c8-475c-84c9-cd98a647d185,DISK], DatanodeInfoWithStorage[127.0.0.1:43868,DS-fac81135-81b1-4948-839a-d01dfad03810,DISK], DatanodeInfoWithStorage[127.0.0.1:46224,DS-c95a5be3-b724-49c2-84b4-8efcae707ca1,DISK], DatanodeInfoWithStorage[127.0.0.1:36501,DS-e85378ec-16b0-4503-9898-6840195b20c7,DISK], DatanodeInfoWithStorage[127.0.0.1:42253,DS-a8d897be-4e33-4428-ac13-f3695731e1ab,DISK], DatanodeInfoWithStorage[127.0.0.1:33004,DS-50c7c97d-a532-4e96-90f4-9c408de10520,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2142805529-172.17.0.14-1598128059058:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32921,DS-0609c728-b859-4aeb-bea1-9e9601469292,DISK], DatanodeInfoWithStorage[127.0.0.1:37289,DS-89342a8b-6efa-44b4-a435-9e6cc7f7867e,DISK], DatanodeInfoWithStorage[127.0.0.1:44924,DS-0c87f287-4e9b-4798-9721-ddceede50236,DISK], DatanodeInfoWithStorage[127.0.0.1:45545,DS-4af98c3f-5cfc-4df7-9398-b7d0fa9701bf,DISK], DatanodeInfoWithStorage[127.0.0.1:38644,DS-881b8c58-58cb-4936-a1b2-57c0a1aa5c4c,DISK], DatanodeInfoWithStorage[127.0.0.1:39781,DS-bd9d0c20-cfee-4634-a9c3-93c1bd247ff7,DISK], DatanodeInfoWithStorage[127.0.0.1:36209,DS-eefaeca0-76fc-4c6d-8b3b-70bad853eba6,DISK], DatanodeInfoWithStorage[127.0.0.1:39473,DS-5d0897ea-51eb-479b-ad89-c905a7ee5cc7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2142805529-172.17.0.14-1598128059058:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32921,DS-0609c728-b859-4aeb-bea1-9e9601469292,DISK], DatanodeInfoWithStorage[127.0.0.1:37289,DS-89342a8b-6efa-44b4-a435-9e6cc7f7867e,DISK], DatanodeInfoWithStorage[127.0.0.1:44924,DS-0c87f287-4e9b-4798-9721-ddceede50236,DISK], DatanodeInfoWithStorage[127.0.0.1:45545,DS-4af98c3f-5cfc-4df7-9398-b7d0fa9701bf,DISK], DatanodeInfoWithStorage[127.0.0.1:38644,DS-881b8c58-58cb-4936-a1b2-57c0a1aa5c4c,DISK], DatanodeInfoWithStorage[127.0.0.1:39781,DS-bd9d0c20-cfee-4634-a9c3-93c1bd247ff7,DISK], DatanodeInfoWithStorage[127.0.0.1:36209,DS-eefaeca0-76fc-4c6d-8b3b-70bad853eba6,DISK], DatanodeInfoWithStorage[127.0.0.1:39473,DS-5d0897ea-51eb-479b-ad89-c905a7ee5cc7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2125084245-172.17.0.14-1598128206389:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33273,DS-ee95522a-adb8-48d0-8b0c-afe33ae5c28b,DISK], DatanodeInfoWithStorage[127.0.0.1:46227,DS-888cee0d-047b-485b-88d4-81c763dbf5dc,DISK], DatanodeInfoWithStorage[127.0.0.1:34095,DS-43504b51-87ff-4588-a9a7-9f4aea9c1c7c,DISK], DatanodeInfoWithStorage[127.0.0.1:42755,DS-55a1b196-a5da-48bd-9289-85d050a8380c,DISK], DatanodeInfoWithStorage[127.0.0.1:45600,DS-8fd39328-6915-4599-924f-5552e9cac494,DISK], DatanodeInfoWithStorage[127.0.0.1:40935,DS-93405425-84aa-4dde-834f-3a30949df498,DISK], DatanodeInfoWithStorage[127.0.0.1:43682,DS-60c6485c-a392-4135-ae9b-c40bc32ba540,DISK], DatanodeInfoWithStorage[127.0.0.1:37202,DS-7dfc16d0-6292-40c8-857d-ea1af5246904,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2125084245-172.17.0.14-1598128206389:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33273,DS-ee95522a-adb8-48d0-8b0c-afe33ae5c28b,DISK], DatanodeInfoWithStorage[127.0.0.1:46227,DS-888cee0d-047b-485b-88d4-81c763dbf5dc,DISK], DatanodeInfoWithStorage[127.0.0.1:34095,DS-43504b51-87ff-4588-a9a7-9f4aea9c1c7c,DISK], DatanodeInfoWithStorage[127.0.0.1:42755,DS-55a1b196-a5da-48bd-9289-85d050a8380c,DISK], DatanodeInfoWithStorage[127.0.0.1:45600,DS-8fd39328-6915-4599-924f-5552e9cac494,DISK], DatanodeInfoWithStorage[127.0.0.1:40935,DS-93405425-84aa-4dde-834f-3a30949df498,DISK], DatanodeInfoWithStorage[127.0.0.1:43682,DS-60c6485c-a392-4135-ae9b-c40bc32ba540,DISK], DatanodeInfoWithStorage[127.0.0.1:37202,DS-7dfc16d0-6292-40c8-857d-ea1af5246904,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2113325031-172.17.0.14-1598128501047:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40091,DS-6a16f637-1cec-4f7e-9366-9027c8885b8f,DISK], DatanodeInfoWithStorage[127.0.0.1:43805,DS-a9fb9b55-67cd-434b-9ef5-e1bd0b669af0,DISK], DatanodeInfoWithStorage[127.0.0.1:33578,DS-7ff7ff9c-e3a8-44fe-880f-9d0348ab610c,DISK], DatanodeInfoWithStorage[127.0.0.1:40226,DS-76e272e7-545b-49b1-868c-21117a203b6b,DISK], DatanodeInfoWithStorage[127.0.0.1:43874,DS-e6d6f950-e3d3-49fc-845a-5a7cca4e4561,DISK], DatanodeInfoWithStorage[127.0.0.1:46509,DS-fcf0dedd-00f0-4cc7-aae8-d0c4adc00933,DISK], DatanodeInfoWithStorage[127.0.0.1:44198,DS-eabff621-9f32-4562-9866-fee10638a714,DISK], DatanodeInfoWithStorage[127.0.0.1:36586,DS-566e5402-fc5c-4833-a00c-f6c1ccac1675,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2113325031-172.17.0.14-1598128501047:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40091,DS-6a16f637-1cec-4f7e-9366-9027c8885b8f,DISK], DatanodeInfoWithStorage[127.0.0.1:43805,DS-a9fb9b55-67cd-434b-9ef5-e1bd0b669af0,DISK], DatanodeInfoWithStorage[127.0.0.1:33578,DS-7ff7ff9c-e3a8-44fe-880f-9d0348ab610c,DISK], DatanodeInfoWithStorage[127.0.0.1:40226,DS-76e272e7-545b-49b1-868c-21117a203b6b,DISK], DatanodeInfoWithStorage[127.0.0.1:43874,DS-e6d6f950-e3d3-49fc-845a-5a7cca4e4561,DISK], DatanodeInfoWithStorage[127.0.0.1:46509,DS-fcf0dedd-00f0-4cc7-aae8-d0c4adc00933,DISK], DatanodeInfoWithStorage[127.0.0.1:44198,DS-eabff621-9f32-4562-9866-fee10638a714,DISK], DatanodeInfoWithStorage[127.0.0.1:36586,DS-566e5402-fc5c-4833-a00c-f6c1ccac1675,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1082816138-172.17.0.14-1598128857635:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39890,DS-9690e413-cb80-42ce-8000-a9823afff188,DISK], DatanodeInfoWithStorage[127.0.0.1:35451,DS-2a41e4d8-3640-4bb1-97eb-abd4cd038d83,DISK], DatanodeInfoWithStorage[127.0.0.1:45738,DS-73abdc69-3f13-4fa2-9ce0-90827f6493c7,DISK], DatanodeInfoWithStorage[127.0.0.1:41826,DS-f5bc4b07-b9dc-446d-be1a-b62441a6e6ff,DISK], DatanodeInfoWithStorage[127.0.0.1:35583,DS-b092a5f1-2f99-4e05-b2ac-7207c25fc4b3,DISK], DatanodeInfoWithStorage[127.0.0.1:34543,DS-fa2dd479-a58e-436d-80cd-1fde504bb34d,DISK], DatanodeInfoWithStorage[127.0.0.1:36061,DS-ca5044bf-9528-4aaa-af84-a79fa4c4052e,DISK], DatanodeInfoWithStorage[127.0.0.1:41972,DS-55273db8-c816-42ff-a045-6bb7e0616b39,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1082816138-172.17.0.14-1598128857635:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39890,DS-9690e413-cb80-42ce-8000-a9823afff188,DISK], DatanodeInfoWithStorage[127.0.0.1:35451,DS-2a41e4d8-3640-4bb1-97eb-abd4cd038d83,DISK], DatanodeInfoWithStorage[127.0.0.1:45738,DS-73abdc69-3f13-4fa2-9ce0-90827f6493c7,DISK], DatanodeInfoWithStorage[127.0.0.1:41826,DS-f5bc4b07-b9dc-446d-be1a-b62441a6e6ff,DISK], DatanodeInfoWithStorage[127.0.0.1:35583,DS-b092a5f1-2f99-4e05-b2ac-7207c25fc4b3,DISK], DatanodeInfoWithStorage[127.0.0.1:34543,DS-fa2dd479-a58e-436d-80cd-1fde504bb34d,DISK], DatanodeInfoWithStorage[127.0.0.1:36061,DS-ca5044bf-9528-4aaa-af84-a79fa4c4052e,DISK], DatanodeInfoWithStorage[127.0.0.1:41972,DS-55273db8-c816-42ff-a045-6bb7e0616b39,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-620059070-172.17.0.14-1598129000369:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35474,DS-7c2fd6cc-ee0d-441f-b51a-b6ade9d27604,DISK], DatanodeInfoWithStorage[127.0.0.1:45713,DS-4b4298b8-6291-4b04-8b17-08e741591ebb,DISK], DatanodeInfoWithStorage[127.0.0.1:32930,DS-65a05abc-c446-48a1-a381-8c0aef6a808e,DISK], DatanodeInfoWithStorage[127.0.0.1:43373,DS-e5560af1-20ef-4cb0-84c2-66699e05f711,DISK], DatanodeInfoWithStorage[127.0.0.1:35949,DS-6d989431-196a-48a3-9502-5e8773a0178e,DISK], DatanodeInfoWithStorage[127.0.0.1:34172,DS-9412846c-5caf-4f33-bebf-394d34d1b6a5,DISK], DatanodeInfoWithStorage[127.0.0.1:46116,DS-01dc7652-7623-43e3-a565-d92f995082c5,DISK], DatanodeInfoWithStorage[127.0.0.1:45328,DS-fc535ee2-1ecc-4a6d-bea5-5bfe431d6be6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-620059070-172.17.0.14-1598129000369:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35474,DS-7c2fd6cc-ee0d-441f-b51a-b6ade9d27604,DISK], DatanodeInfoWithStorage[127.0.0.1:45713,DS-4b4298b8-6291-4b04-8b17-08e741591ebb,DISK], DatanodeInfoWithStorage[127.0.0.1:32930,DS-65a05abc-c446-48a1-a381-8c0aef6a808e,DISK], DatanodeInfoWithStorage[127.0.0.1:43373,DS-e5560af1-20ef-4cb0-84c2-66699e05f711,DISK], DatanodeInfoWithStorage[127.0.0.1:35949,DS-6d989431-196a-48a3-9502-5e8773a0178e,DISK], DatanodeInfoWithStorage[127.0.0.1:34172,DS-9412846c-5caf-4f33-bebf-394d34d1b6a5,DISK], DatanodeInfoWithStorage[127.0.0.1:46116,DS-01dc7652-7623-43e3-a565-d92f995082c5,DISK], DatanodeInfoWithStorage[127.0.0.1:45328,DS-fc535ee2-1ecc-4a6d-bea5-5bfe431d6be6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-843828886-172.17.0.14-1598129038174:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34319,DS-3d637ea9-678a-4f14-aea2-c2a1b447f3d9,DISK], DatanodeInfoWithStorage[127.0.0.1:45391,DS-84f75e73-3e0a-4465-bbeb-01ce03e75c0e,DISK], DatanodeInfoWithStorage[127.0.0.1:41458,DS-e55155f2-81b9-4f55-b9d1-07b93543539b,DISK], DatanodeInfoWithStorage[127.0.0.1:37756,DS-9649fe84-f040-4f50-80b3-369671e002b5,DISK], DatanodeInfoWithStorage[127.0.0.1:36587,DS-6da57740-d994-4e42-b422-324b7ddc182a,DISK], DatanodeInfoWithStorage[127.0.0.1:45641,DS-a46f4f00-152f-43ae-80be-d85689c66e76,DISK], DatanodeInfoWithStorage[127.0.0.1:46529,DS-4fc997a5-b7b2-42d3-8c91-1614fdf69a9a,DISK], DatanodeInfoWithStorage[127.0.0.1:44980,DS-860d057b-e36f-4144-aabc-e03a35a4c49d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-843828886-172.17.0.14-1598129038174:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34319,DS-3d637ea9-678a-4f14-aea2-c2a1b447f3d9,DISK], DatanodeInfoWithStorage[127.0.0.1:45391,DS-84f75e73-3e0a-4465-bbeb-01ce03e75c0e,DISK], DatanodeInfoWithStorage[127.0.0.1:41458,DS-e55155f2-81b9-4f55-b9d1-07b93543539b,DISK], DatanodeInfoWithStorage[127.0.0.1:37756,DS-9649fe84-f040-4f50-80b3-369671e002b5,DISK], DatanodeInfoWithStorage[127.0.0.1:36587,DS-6da57740-d994-4e42-b422-324b7ddc182a,DISK], DatanodeInfoWithStorage[127.0.0.1:45641,DS-a46f4f00-152f-43ae-80be-d85689c66e76,DISK], DatanodeInfoWithStorage[127.0.0.1:46529,DS-4fc997a5-b7b2-42d3-8c91-1614fdf69a9a,DISK], DatanodeInfoWithStorage[127.0.0.1:44980,DS-860d057b-e36f-4144-aabc-e03a35a4c49d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-220613793-172.17.0.14-1598129724963:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38094,DS-78fe6c42-67d1-417e-9440-c8c558164027,DISK], DatanodeInfoWithStorage[127.0.0.1:40257,DS-40c24569-6012-45b4-b6e2-0ed30b1d03b3,DISK], DatanodeInfoWithStorage[127.0.0.1:37501,DS-826db854-01c4-4042-b9be-1606fb10f0ed,DISK], DatanodeInfoWithStorage[127.0.0.1:45412,DS-fba34c48-c243-4c46-9877-c1b02f8ecb04,DISK], DatanodeInfoWithStorage[127.0.0.1:37225,DS-bd82fa1d-3166-417a-a7cc-da1965748aec,DISK], DatanodeInfoWithStorage[127.0.0.1:37227,DS-b7bfb869-b824-4b64-9485-52e943dcbf2a,DISK], DatanodeInfoWithStorage[127.0.0.1:41557,DS-43e1975c-ec66-40b2-a7c5-97d62d59f63d,DISK], DatanodeInfoWithStorage[127.0.0.1:35896,DS-092850af-4e18-45f2-a7f8-cd1751556946,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-220613793-172.17.0.14-1598129724963:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38094,DS-78fe6c42-67d1-417e-9440-c8c558164027,DISK], DatanodeInfoWithStorage[127.0.0.1:40257,DS-40c24569-6012-45b4-b6e2-0ed30b1d03b3,DISK], DatanodeInfoWithStorage[127.0.0.1:37501,DS-826db854-01c4-4042-b9be-1606fb10f0ed,DISK], DatanodeInfoWithStorage[127.0.0.1:45412,DS-fba34c48-c243-4c46-9877-c1b02f8ecb04,DISK], DatanodeInfoWithStorage[127.0.0.1:37225,DS-bd82fa1d-3166-417a-a7cc-da1965748aec,DISK], DatanodeInfoWithStorage[127.0.0.1:37227,DS-b7bfb869-b824-4b64-9485-52e943dcbf2a,DISK], DatanodeInfoWithStorage[127.0.0.1:41557,DS-43e1975c-ec66-40b2-a7c5-97d62d59f63d,DISK], DatanodeInfoWithStorage[127.0.0.1:35896,DS-092850af-4e18-45f2-a7f8-cd1751556946,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-606205952-172.17.0.14-1598129915845:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45853,DS-8979a309-15b7-4497-b2c2-c752e9542433,DISK], DatanodeInfoWithStorage[127.0.0.1:36859,DS-e7fb2ab4-e5c6-4fd7-9a4a-77ca08c90862,DISK], DatanodeInfoWithStorage[127.0.0.1:39916,DS-42c4d72e-9d89-4ec8-81ce-c8e37b0e7f6a,DISK], DatanodeInfoWithStorage[127.0.0.1:39687,DS-cbd23425-886a-408c-bfc4-e2df4bf6148d,DISK], DatanodeInfoWithStorage[127.0.0.1:40646,DS-d41ce5db-3b23-4d45-94cd-4ced48f4f9d4,DISK], DatanodeInfoWithStorage[127.0.0.1:44466,DS-e84044a4-5aa0-4d1e-9ab7-9ad0db4e5331,DISK], DatanodeInfoWithStorage[127.0.0.1:44663,DS-9e42f435-1364-4fd8-8457-011b6fa58bd9,DISK], DatanodeInfoWithStorage[127.0.0.1:33659,DS-330e1e3a-3d80-4fb1-bfb3-a82e23459c5d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-606205952-172.17.0.14-1598129915845:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45853,DS-8979a309-15b7-4497-b2c2-c752e9542433,DISK], DatanodeInfoWithStorage[127.0.0.1:36859,DS-e7fb2ab4-e5c6-4fd7-9a4a-77ca08c90862,DISK], DatanodeInfoWithStorage[127.0.0.1:39916,DS-42c4d72e-9d89-4ec8-81ce-c8e37b0e7f6a,DISK], DatanodeInfoWithStorage[127.0.0.1:39687,DS-cbd23425-886a-408c-bfc4-e2df4bf6148d,DISK], DatanodeInfoWithStorage[127.0.0.1:40646,DS-d41ce5db-3b23-4d45-94cd-4ced48f4f9d4,DISK], DatanodeInfoWithStorage[127.0.0.1:44466,DS-e84044a4-5aa0-4d1e-9ab7-9ad0db4e5331,DISK], DatanodeInfoWithStorage[127.0.0.1:44663,DS-9e42f435-1364-4fd8-8457-011b6fa58bd9,DISK], DatanodeInfoWithStorage[127.0.0.1:33659,DS-330e1e3a-3d80-4fb1-bfb3-a82e23459c5d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-409087551-172.17.0.14-1598130334713:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33278,DS-e514694f-d86d-486f-8b5e-dfda321cd181,DISK], DatanodeInfoWithStorage[127.0.0.1:46111,DS-78d5a825-10fc-4e71-b348-72adb2b6ca91,DISK], DatanodeInfoWithStorage[127.0.0.1:46191,DS-c7b2711f-e75a-4273-8f09-bc52ef50525f,DISK], DatanodeInfoWithStorage[127.0.0.1:44895,DS-8693f057-f7b5-4b6e-a1c5-2f9442fed312,DISK], DatanodeInfoWithStorage[127.0.0.1:40390,DS-db24ce99-729e-4474-8fa4-9afbcdf55fd8,DISK], DatanodeInfoWithStorage[127.0.0.1:40259,DS-37d1a43b-09ab-4a9e-b983-5685ae67be79,DISK], DatanodeInfoWithStorage[127.0.0.1:33479,DS-e320ed0b-0166-4d5c-819c-a165d2943851,DISK], DatanodeInfoWithStorage[127.0.0.1:46810,DS-5aa83f05-5d99-4c87-8fc4-857917dbff54,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-409087551-172.17.0.14-1598130334713:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33278,DS-e514694f-d86d-486f-8b5e-dfda321cd181,DISK], DatanodeInfoWithStorage[127.0.0.1:46111,DS-78d5a825-10fc-4e71-b348-72adb2b6ca91,DISK], DatanodeInfoWithStorage[127.0.0.1:46191,DS-c7b2711f-e75a-4273-8f09-bc52ef50525f,DISK], DatanodeInfoWithStorage[127.0.0.1:44895,DS-8693f057-f7b5-4b6e-a1c5-2f9442fed312,DISK], DatanodeInfoWithStorage[127.0.0.1:40390,DS-db24ce99-729e-4474-8fa4-9afbcdf55fd8,DISK], DatanodeInfoWithStorage[127.0.0.1:40259,DS-37d1a43b-09ab-4a9e-b983-5685ae67be79,DISK], DatanodeInfoWithStorage[127.0.0.1:33479,DS-e320ed0b-0166-4d5c-819c-a165d2943851,DISK], DatanodeInfoWithStorage[127.0.0.1:46810,DS-5aa83f05-5d99-4c87-8fc4-857917dbff54,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-798817465-172.17.0.14-1598130369151:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45541,DS-5b8e4593-e5b4-4069-8ce4-5b9165018baa,DISK], DatanodeInfoWithStorage[127.0.0.1:44092,DS-81b0dc85-2f6d-4a9d-9f28-45a6b993c378,DISK], DatanodeInfoWithStorage[127.0.0.1:35173,DS-56da5f18-61a4-4feb-a532-05edfd77a086,DISK], DatanodeInfoWithStorage[127.0.0.1:37448,DS-c2e60992-b67a-4e38-80ca-6316f868d48c,DISK], DatanodeInfoWithStorage[127.0.0.1:34150,DS-ddcb7a0f-c6c4-425a-abec-1e68d67d6da8,DISK], DatanodeInfoWithStorage[127.0.0.1:41663,DS-e032f14b-8ef8-4d54-bea7-ab4dbfd131e5,DISK], DatanodeInfoWithStorage[127.0.0.1:44581,DS-6f4d9389-2c08-4cf6-88a9-ff2ce686e5fa,DISK], DatanodeInfoWithStorage[127.0.0.1:38870,DS-bc056464-65d8-43f9-821a-ce91d3977bc0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-798817465-172.17.0.14-1598130369151:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45541,DS-5b8e4593-e5b4-4069-8ce4-5b9165018baa,DISK], DatanodeInfoWithStorage[127.0.0.1:44092,DS-81b0dc85-2f6d-4a9d-9f28-45a6b993c378,DISK], DatanodeInfoWithStorage[127.0.0.1:35173,DS-56da5f18-61a4-4feb-a532-05edfd77a086,DISK], DatanodeInfoWithStorage[127.0.0.1:37448,DS-c2e60992-b67a-4e38-80ca-6316f868d48c,DISK], DatanodeInfoWithStorage[127.0.0.1:34150,DS-ddcb7a0f-c6c4-425a-abec-1e68d67d6da8,DISK], DatanodeInfoWithStorage[127.0.0.1:41663,DS-e032f14b-8ef8-4d54-bea7-ab4dbfd131e5,DISK], DatanodeInfoWithStorage[127.0.0.1:44581,DS-6f4d9389-2c08-4cf6-88a9-ff2ce686e5fa,DISK], DatanodeInfoWithStorage[127.0.0.1:38870,DS-bc056464-65d8-43f9-821a-ce91d3977bc0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-151080830-172.17.0.14-1598130433293:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39896,DS-70a07f32-a990-438c-a8ea-8b4ae3e29879,DISK], DatanodeInfoWithStorage[127.0.0.1:44704,DS-134a4adc-0862-447d-970c-3a62fcb9ea50,DISK], DatanodeInfoWithStorage[127.0.0.1:38618,DS-e68c77c9-27c9-45fe-84ed-29c21f9be6c6,DISK], DatanodeInfoWithStorage[127.0.0.1:34339,DS-0fb67246-7cc8-48b8-af53-760be8c029fe,DISK], DatanodeInfoWithStorage[127.0.0.1:39045,DS-f5872207-fcda-4fbf-a983-aa470fae1411,DISK], DatanodeInfoWithStorage[127.0.0.1:46718,DS-6567dad3-50f6-41a7-9551-1212de88df90,DISK], DatanodeInfoWithStorage[127.0.0.1:37312,DS-fb61196b-9631-44ed-b6d6-1820c2c85ea7,DISK], DatanodeInfoWithStorage[127.0.0.1:43573,DS-8b460bb9-c5e4-4df4-87c3-92ccc9c5e9e9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-151080830-172.17.0.14-1598130433293:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39896,DS-70a07f32-a990-438c-a8ea-8b4ae3e29879,DISK], DatanodeInfoWithStorage[127.0.0.1:44704,DS-134a4adc-0862-447d-970c-3a62fcb9ea50,DISK], DatanodeInfoWithStorage[127.0.0.1:38618,DS-e68c77c9-27c9-45fe-84ed-29c21f9be6c6,DISK], DatanodeInfoWithStorage[127.0.0.1:34339,DS-0fb67246-7cc8-48b8-af53-760be8c029fe,DISK], DatanodeInfoWithStorage[127.0.0.1:39045,DS-f5872207-fcda-4fbf-a983-aa470fae1411,DISK], DatanodeInfoWithStorage[127.0.0.1:46718,DS-6567dad3-50f6-41a7-9551-1212de88df90,DISK], DatanodeInfoWithStorage[127.0.0.1:37312,DS-fb61196b-9631-44ed-b6d6-1820c2c85ea7,DISK], DatanodeInfoWithStorage[127.0.0.1:43573,DS-8b460bb9-c5e4-4df4-87c3-92ccc9c5e9e9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1061366117-172.17.0.14-1598130497520:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44229,DS-9904b9e9-c2dd-4c3c-a60c-fa3b412c2c04,DISK], DatanodeInfoWithStorage[127.0.0.1:43762,DS-badf7767-b4bf-4e69-bc7e-77a200dc3f6c,DISK], DatanodeInfoWithStorage[127.0.0.1:43510,DS-2f82aea1-1431-4f07-aae2-022c2d22d0de,DISK], DatanodeInfoWithStorage[127.0.0.1:33362,DS-59cc99b4-7d2b-4442-aeb4-a058983db302,DISK], DatanodeInfoWithStorage[127.0.0.1:35331,DS-394ecf53-5f51-4cfe-81b3-5596df35320d,DISK], DatanodeInfoWithStorage[127.0.0.1:41144,DS-62254e10-150f-4ca3-8843-2e38599c843f,DISK], DatanodeInfoWithStorage[127.0.0.1:44624,DS-47aa8d02-343c-4f5f-a98b-40e271a82588,DISK], DatanodeInfoWithStorage[127.0.0.1:45437,DS-a8f4c236-4818-40c7-b8be-56281aca32d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1061366117-172.17.0.14-1598130497520:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44229,DS-9904b9e9-c2dd-4c3c-a60c-fa3b412c2c04,DISK], DatanodeInfoWithStorage[127.0.0.1:43762,DS-badf7767-b4bf-4e69-bc7e-77a200dc3f6c,DISK], DatanodeInfoWithStorage[127.0.0.1:43510,DS-2f82aea1-1431-4f07-aae2-022c2d22d0de,DISK], DatanodeInfoWithStorage[127.0.0.1:33362,DS-59cc99b4-7d2b-4442-aeb4-a058983db302,DISK], DatanodeInfoWithStorage[127.0.0.1:35331,DS-394ecf53-5f51-4cfe-81b3-5596df35320d,DISK], DatanodeInfoWithStorage[127.0.0.1:41144,DS-62254e10-150f-4ca3-8843-2e38599c843f,DISK], DatanodeInfoWithStorage[127.0.0.1:44624,DS-47aa8d02-343c-4f5f-a98b-40e271a82588,DISK], DatanodeInfoWithStorage[127.0.0.1:45437,DS-a8f4c236-4818-40c7-b8be-56281aca32d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-98751077-172.17.0.14-1598131171823:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35852,DS-aace2071-9897-41b4-82d6-8c300bba0d80,DISK], DatanodeInfoWithStorage[127.0.0.1:35354,DS-e3816b4b-dbe6-4176-9d78-90eaa63cff18,DISK], DatanodeInfoWithStorage[127.0.0.1:46621,DS-51f02ff6-b2c5-4871-9402-4dde655d2e49,DISK], DatanodeInfoWithStorage[127.0.0.1:32816,DS-69c1a186-05a3-4a2b-a42c-f7569c9f2072,DISK], DatanodeInfoWithStorage[127.0.0.1:45678,DS-cbc79d07-9d57-45bf-b95f-08f5f2d8d928,DISK], DatanodeInfoWithStorage[127.0.0.1:36479,DS-82fc8667-5a9a-4bb0-88f3-b4022905c0e7,DISK], DatanodeInfoWithStorage[127.0.0.1:40002,DS-b3fe8778-1478-4906-8c72-d626d57de2d7,DISK], DatanodeInfoWithStorage[127.0.0.1:44035,DS-543a4d7e-2dce-47fe-bb6e-6c78357d5fe0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-98751077-172.17.0.14-1598131171823:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35852,DS-aace2071-9897-41b4-82d6-8c300bba0d80,DISK], DatanodeInfoWithStorage[127.0.0.1:35354,DS-e3816b4b-dbe6-4176-9d78-90eaa63cff18,DISK], DatanodeInfoWithStorage[127.0.0.1:46621,DS-51f02ff6-b2c5-4871-9402-4dde655d2e49,DISK], DatanodeInfoWithStorage[127.0.0.1:32816,DS-69c1a186-05a3-4a2b-a42c-f7569c9f2072,DISK], DatanodeInfoWithStorage[127.0.0.1:45678,DS-cbc79d07-9d57-45bf-b95f-08f5f2d8d928,DISK], DatanodeInfoWithStorage[127.0.0.1:36479,DS-82fc8667-5a9a-4bb0-88f3-b4022905c0e7,DISK], DatanodeInfoWithStorage[127.0.0.1:40002,DS-b3fe8778-1478-4906-8c72-d626d57de2d7,DISK], DatanodeInfoWithStorage[127.0.0.1:44035,DS-543a4d7e-2dce-47fe-bb6e-6c78357d5fe0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-739055151-172.17.0.14-1598131269872:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42356,DS-24b5cce2-96e6-435f-a496-d6de48d04b73,DISK], DatanodeInfoWithStorage[127.0.0.1:41657,DS-ca2267e3-c06a-452b-ab41-47bf7bc2c16e,DISK], DatanodeInfoWithStorage[127.0.0.1:38964,DS-a4658dc2-aab6-40e8-b5ed-d9a3a24c6b8b,DISK], DatanodeInfoWithStorage[127.0.0.1:37327,DS-02158513-5b6b-4fdc-87e9-17a01ca2903c,DISK], DatanodeInfoWithStorage[127.0.0.1:42134,DS-3838ad86-294f-4180-b921-ec50a0d35f06,DISK], DatanodeInfoWithStorage[127.0.0.1:36680,DS-9a6ded6f-0389-4426-bd0f-07ce26b721fd,DISK], DatanodeInfoWithStorage[127.0.0.1:39368,DS-cf9b264a-e6b9-4b71-b244-93aaff739078,DISK], DatanodeInfoWithStorage[127.0.0.1:37646,DS-2a0c5d6b-2929-474e-a44d-afe15b415be1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-739055151-172.17.0.14-1598131269872:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42356,DS-24b5cce2-96e6-435f-a496-d6de48d04b73,DISK], DatanodeInfoWithStorage[127.0.0.1:41657,DS-ca2267e3-c06a-452b-ab41-47bf7bc2c16e,DISK], DatanodeInfoWithStorage[127.0.0.1:38964,DS-a4658dc2-aab6-40e8-b5ed-d9a3a24c6b8b,DISK], DatanodeInfoWithStorage[127.0.0.1:37327,DS-02158513-5b6b-4fdc-87e9-17a01ca2903c,DISK], DatanodeInfoWithStorage[127.0.0.1:42134,DS-3838ad86-294f-4180-b921-ec50a0d35f06,DISK], DatanodeInfoWithStorage[127.0.0.1:36680,DS-9a6ded6f-0389-4426-bd0f-07ce26b721fd,DISK], DatanodeInfoWithStorage[127.0.0.1:39368,DS-cf9b264a-e6b9-4b71-b244-93aaff739078,DISK], DatanodeInfoWithStorage[127.0.0.1:37646,DS-2a0c5d6b-2929-474e-a44d-afe15b415be1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1049029703-172.17.0.14-1598131430761:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36988,DS-6e63b1e4-341a-40bb-9780-afe17ce3611d,DISK], DatanodeInfoWithStorage[127.0.0.1:37073,DS-dd8f3d17-5b72-451b-8218-cccd3974c827,DISK], DatanodeInfoWithStorage[127.0.0.1:42646,DS-8df68b81-1c81-4dac-865e-49da46df93bf,DISK], DatanodeInfoWithStorage[127.0.0.1:43131,DS-c8d8f8f2-f3b8-4228-a758-97c9da6e82ce,DISK], DatanodeInfoWithStorage[127.0.0.1:44714,DS-aff3e435-1a82-4a52-bbc8-8db5894cde73,DISK], DatanodeInfoWithStorage[127.0.0.1:43068,DS-ea40007a-cbea-4bc3-847a-059df666ad88,DISK], DatanodeInfoWithStorage[127.0.0.1:36195,DS-5b8bfdcc-ee63-4ee1-b3c1-356ee1f0fbff,DISK], DatanodeInfoWithStorage[127.0.0.1:35442,DS-d3afc09f-7914-4ce9-ac91-d0c3d7ef5674,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1049029703-172.17.0.14-1598131430761:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36988,DS-6e63b1e4-341a-40bb-9780-afe17ce3611d,DISK], DatanodeInfoWithStorage[127.0.0.1:37073,DS-dd8f3d17-5b72-451b-8218-cccd3974c827,DISK], DatanodeInfoWithStorage[127.0.0.1:42646,DS-8df68b81-1c81-4dac-865e-49da46df93bf,DISK], DatanodeInfoWithStorage[127.0.0.1:43131,DS-c8d8f8f2-f3b8-4228-a758-97c9da6e82ce,DISK], DatanodeInfoWithStorage[127.0.0.1:44714,DS-aff3e435-1a82-4a52-bbc8-8db5894cde73,DISK], DatanodeInfoWithStorage[127.0.0.1:43068,DS-ea40007a-cbea-4bc3-847a-059df666ad88,DISK], DatanodeInfoWithStorage[127.0.0.1:36195,DS-5b8bfdcc-ee63-4ee1-b3c1-356ee1f0fbff,DISK], DatanodeInfoWithStorage[127.0.0.1:35442,DS-d3afc09f-7914-4ce9-ac91-d0c3d7ef5674,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-831345232-172.17.0.14-1598131739281:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37652,DS-4e65dae0-1b59-4c03-9acc-f34c0868b6ee,DISK], DatanodeInfoWithStorage[127.0.0.1:34191,DS-eca0b04d-c6cd-4bb6-b633-d12bd6f6564a,DISK], DatanodeInfoWithStorage[127.0.0.1:41839,DS-24f1d700-3d15-446a-8a83-f611cd6b3437,DISK], DatanodeInfoWithStorage[127.0.0.1:46585,DS-e0165000-66a1-4999-a54d-b1d26602d8f2,DISK], DatanodeInfoWithStorage[127.0.0.1:46178,DS-1175bcf6-ea32-4c5b-8083-2bd440ce776b,DISK], DatanodeInfoWithStorage[127.0.0.1:45801,DS-3c54be35-a304-48f1-91a7-039d1e9a9b14,DISK], DatanodeInfoWithStorage[127.0.0.1:42188,DS-50f0558c-9c10-4ac0-8dc8-a4426840fea6,DISK], DatanodeInfoWithStorage[127.0.0.1:43602,DS-87bb26a1-093c-4556-a829-3df1acff3d59,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-831345232-172.17.0.14-1598131739281:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37652,DS-4e65dae0-1b59-4c03-9acc-f34c0868b6ee,DISK], DatanodeInfoWithStorage[127.0.0.1:34191,DS-eca0b04d-c6cd-4bb6-b633-d12bd6f6564a,DISK], DatanodeInfoWithStorage[127.0.0.1:41839,DS-24f1d700-3d15-446a-8a83-f611cd6b3437,DISK], DatanodeInfoWithStorage[127.0.0.1:46585,DS-e0165000-66a1-4999-a54d-b1d26602d8f2,DISK], DatanodeInfoWithStorage[127.0.0.1:46178,DS-1175bcf6-ea32-4c5b-8083-2bd440ce776b,DISK], DatanodeInfoWithStorage[127.0.0.1:45801,DS-3c54be35-a304-48f1-91a7-039d1e9a9b14,DISK], DatanodeInfoWithStorage[127.0.0.1:42188,DS-50f0558c-9c10-4ac0-8dc8-a4426840fea6,DISK], DatanodeInfoWithStorage[127.0.0.1:43602,DS-87bb26a1-093c-4556-a829-3df1acff3d59,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-293744089-172.17.0.14-1598131769834:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46457,DS-89c3e05c-1a89-4fba-8834-df1055741f93,DISK], DatanodeInfoWithStorage[127.0.0.1:37168,DS-7ad92902-4db9-4526-b138-d677bcf7170f,DISK], DatanodeInfoWithStorage[127.0.0.1:37890,DS-367d58c6-34a6-44f6-8a95-0543b41be6fb,DISK], DatanodeInfoWithStorage[127.0.0.1:45060,DS-8ed5b974-0008-4a3d-ba79-e58b4794ebd1,DISK], DatanodeInfoWithStorage[127.0.0.1:33495,DS-cc3a6275-0c5b-448f-aebc-d1a25b33724d,DISK], DatanodeInfoWithStorage[127.0.0.1:39017,DS-5a34aa24-fb5b-4da5-9807-f37eb9993c19,DISK], DatanodeInfoWithStorage[127.0.0.1:35242,DS-d49922ec-9584-4d3f-9f15-608b31bbe1a1,DISK], DatanodeInfoWithStorage[127.0.0.1:39042,DS-54d23cec-f0e8-40fd-9910-7b17ffe67997,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-293744089-172.17.0.14-1598131769834:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46457,DS-89c3e05c-1a89-4fba-8834-df1055741f93,DISK], DatanodeInfoWithStorage[127.0.0.1:37168,DS-7ad92902-4db9-4526-b138-d677bcf7170f,DISK], DatanodeInfoWithStorage[127.0.0.1:37890,DS-367d58c6-34a6-44f6-8a95-0543b41be6fb,DISK], DatanodeInfoWithStorage[127.0.0.1:45060,DS-8ed5b974-0008-4a3d-ba79-e58b4794ebd1,DISK], DatanodeInfoWithStorage[127.0.0.1:33495,DS-cc3a6275-0c5b-448f-aebc-d1a25b33724d,DISK], DatanodeInfoWithStorage[127.0.0.1:39017,DS-5a34aa24-fb5b-4da5-9807-f37eb9993c19,DISK], DatanodeInfoWithStorage[127.0.0.1:35242,DS-d49922ec-9584-4d3f-9f15-608b31bbe1a1,DISK], DatanodeInfoWithStorage[127.0.0.1:39042,DS-54d23cec-f0e8-40fd-9910-7b17ffe67997,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 4903
