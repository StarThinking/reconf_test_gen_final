reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-904727475-172.17.0.12-1598102206589:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39596,DS-050c8f36-5fe5-4c07-b202-af65bc977a84,DISK], DatanodeInfoWithStorage[127.0.0.1:36687,DS-bc967f2d-ca29-4b9c-876d-8dc2830679fa,DISK], DatanodeInfoWithStorage[127.0.0.1:37409,DS-4b1fcf03-175e-4297-a3ca-fed0a07cb4e0,DISK], DatanodeInfoWithStorage[127.0.0.1:38724,DS-10bcbb44-b98a-4ee6-96c0-e9b94addcc54,DISK], DatanodeInfoWithStorage[127.0.0.1:39107,DS-8bf58322-1d29-4efc-8f1a-d118c337c2a8,DISK], DatanodeInfoWithStorage[127.0.0.1:34489,DS-2b8ee8c4-7570-4a28-b5e2-b8b28936ce16,DISK], DatanodeInfoWithStorage[127.0.0.1:43202,DS-c59bfe55-3266-4027-976d-964202252943,DISK], DatanodeInfoWithStorage[127.0.0.1:44550,DS-309018b1-71fb-43d8-892d-9886a57cf5bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-904727475-172.17.0.12-1598102206589:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39596,DS-050c8f36-5fe5-4c07-b202-af65bc977a84,DISK], DatanodeInfoWithStorage[127.0.0.1:36687,DS-bc967f2d-ca29-4b9c-876d-8dc2830679fa,DISK], DatanodeInfoWithStorage[127.0.0.1:37409,DS-4b1fcf03-175e-4297-a3ca-fed0a07cb4e0,DISK], DatanodeInfoWithStorage[127.0.0.1:38724,DS-10bcbb44-b98a-4ee6-96c0-e9b94addcc54,DISK], DatanodeInfoWithStorage[127.0.0.1:39107,DS-8bf58322-1d29-4efc-8f1a-d118c337c2a8,DISK], DatanodeInfoWithStorage[127.0.0.1:34489,DS-2b8ee8c4-7570-4a28-b5e2-b8b28936ce16,DISK], DatanodeInfoWithStorage[127.0.0.1:43202,DS-c59bfe55-3266-4027-976d-964202252943,DISK], DatanodeInfoWithStorage[127.0.0.1:44550,DS-309018b1-71fb-43d8-892d-9886a57cf5bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1945058568-172.17.0.12-1598102335265:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34384,DS-f6a46edd-9aef-428e-9451-5a9fc0e287aa,DISK], DatanodeInfoWithStorage[127.0.0.1:34912,DS-60ea393b-c6c5-4b34-bdb8-c84c34959da7,DISK], DatanodeInfoWithStorage[127.0.0.1:39849,DS-68cbe8df-96a7-4b78-8509-0471f909aae5,DISK], DatanodeInfoWithStorage[127.0.0.1:34866,DS-01d22dc4-66a3-48eb-bc44-94a7dbf28392,DISK], DatanodeInfoWithStorage[127.0.0.1:41119,DS-1de93e81-00f8-41db-8d4e-7567941e4383,DISK], DatanodeInfoWithStorage[127.0.0.1:43836,DS-d28f5109-f380-474e-8743-a5df449792f4,DISK], DatanodeInfoWithStorage[127.0.0.1:40057,DS-41888082-3035-416f-a8ae-47f0c6932455,DISK], DatanodeInfoWithStorage[127.0.0.1:40306,DS-3c92e437-78e7-4e98-93ed-0d6ac9ed8601,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1945058568-172.17.0.12-1598102335265:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34384,DS-f6a46edd-9aef-428e-9451-5a9fc0e287aa,DISK], DatanodeInfoWithStorage[127.0.0.1:34912,DS-60ea393b-c6c5-4b34-bdb8-c84c34959da7,DISK], DatanodeInfoWithStorage[127.0.0.1:39849,DS-68cbe8df-96a7-4b78-8509-0471f909aae5,DISK], DatanodeInfoWithStorage[127.0.0.1:34866,DS-01d22dc4-66a3-48eb-bc44-94a7dbf28392,DISK], DatanodeInfoWithStorage[127.0.0.1:41119,DS-1de93e81-00f8-41db-8d4e-7567941e4383,DISK], DatanodeInfoWithStorage[127.0.0.1:43836,DS-d28f5109-f380-474e-8743-a5df449792f4,DISK], DatanodeInfoWithStorage[127.0.0.1:40057,DS-41888082-3035-416f-a8ae-47f0c6932455,DISK], DatanodeInfoWithStorage[127.0.0.1:40306,DS-3c92e437-78e7-4e98-93ed-0d6ac9ed8601,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1238736861-172.17.0.12-1598102736422:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33391,DS-28c8a989-9f60-44e3-a1d2-5e197339881e,DISK], DatanodeInfoWithStorage[127.0.0.1:36330,DS-e59da206-5bd2-4d4a-9e10-447bcc03b4c4,DISK], DatanodeInfoWithStorage[127.0.0.1:37279,DS-7e3d5f73-b5de-4696-97d9-a75cb697ab1b,DISK], DatanodeInfoWithStorage[127.0.0.1:45643,DS-32b0b190-2b3f-40e1-9dfc-406be8127512,DISK], DatanodeInfoWithStorage[127.0.0.1:40279,DS-a5aa18af-f41d-4578-90e4-adf101873151,DISK], DatanodeInfoWithStorage[127.0.0.1:33102,DS-1101847f-2481-46cb-93a4-b21a721d6177,DISK], DatanodeInfoWithStorage[127.0.0.1:46305,DS-c872a922-1ea8-4cfd-a051-00761536f178,DISK], DatanodeInfoWithStorage[127.0.0.1:41797,DS-32608e6a-b39c-4ed3-bfd8-9c46addd4c5e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1238736861-172.17.0.12-1598102736422:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33391,DS-28c8a989-9f60-44e3-a1d2-5e197339881e,DISK], DatanodeInfoWithStorage[127.0.0.1:36330,DS-e59da206-5bd2-4d4a-9e10-447bcc03b4c4,DISK], DatanodeInfoWithStorage[127.0.0.1:37279,DS-7e3d5f73-b5de-4696-97d9-a75cb697ab1b,DISK], DatanodeInfoWithStorage[127.0.0.1:45643,DS-32b0b190-2b3f-40e1-9dfc-406be8127512,DISK], DatanodeInfoWithStorage[127.0.0.1:40279,DS-a5aa18af-f41d-4578-90e4-adf101873151,DISK], DatanodeInfoWithStorage[127.0.0.1:33102,DS-1101847f-2481-46cb-93a4-b21a721d6177,DISK], DatanodeInfoWithStorage[127.0.0.1:46305,DS-c872a922-1ea8-4cfd-a051-00761536f178,DISK], DatanodeInfoWithStorage[127.0.0.1:41797,DS-32608e6a-b39c-4ed3-bfd8-9c46addd4c5e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1053990681-172.17.0.12-1598102812029:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41224,DS-3f641a74-c0f0-4e50-865e-ba1050720de8,DISK], DatanodeInfoWithStorage[127.0.0.1:33059,DS-e1707a5e-f91d-44c8-8cad-7895f276895c,DISK], DatanodeInfoWithStorage[127.0.0.1:45205,DS-f6329772-959c-42fc-b314-c7a719dc540a,DISK], DatanodeInfoWithStorage[127.0.0.1:39755,DS-7653a4af-e9b0-4462-9249-07e838068769,DISK], DatanodeInfoWithStorage[127.0.0.1:40293,DS-61ee9dc1-73f9-4f11-8a0e-64a76cc6c9d1,DISK], DatanodeInfoWithStorage[127.0.0.1:41894,DS-1880c639-0e02-4ea0-9832-325ce6e02a9e,DISK], DatanodeInfoWithStorage[127.0.0.1:34185,DS-9cb53af5-6838-4bec-a2f0-f3695e785800,DISK], DatanodeInfoWithStorage[127.0.0.1:40842,DS-ac9dd14d-2206-49b0-85a9-4767d5dea260,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1053990681-172.17.0.12-1598102812029:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41224,DS-3f641a74-c0f0-4e50-865e-ba1050720de8,DISK], DatanodeInfoWithStorage[127.0.0.1:33059,DS-e1707a5e-f91d-44c8-8cad-7895f276895c,DISK], DatanodeInfoWithStorage[127.0.0.1:45205,DS-f6329772-959c-42fc-b314-c7a719dc540a,DISK], DatanodeInfoWithStorage[127.0.0.1:39755,DS-7653a4af-e9b0-4462-9249-07e838068769,DISK], DatanodeInfoWithStorage[127.0.0.1:40293,DS-61ee9dc1-73f9-4f11-8a0e-64a76cc6c9d1,DISK], DatanodeInfoWithStorage[127.0.0.1:41894,DS-1880c639-0e02-4ea0-9832-325ce6e02a9e,DISK], DatanodeInfoWithStorage[127.0.0.1:34185,DS-9cb53af5-6838-4bec-a2f0-f3695e785800,DISK], DatanodeInfoWithStorage[127.0.0.1:40842,DS-ac9dd14d-2206-49b0-85a9-4767d5dea260,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-994280965-172.17.0.12-1598103334102:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45458,DS-6d9b5408-ddee-443e-bb73-e0842a25fc0d,DISK], DatanodeInfoWithStorage[127.0.0.1:46196,DS-d9c7c4b0-cbb8-4f74-8de4-703f8c72c388,DISK], DatanodeInfoWithStorage[127.0.0.1:39072,DS-3f64d3f0-905e-420e-9b96-21b7c5db8f87,DISK], DatanodeInfoWithStorage[127.0.0.1:43018,DS-cadaa92d-cd0b-4330-9c30-33dd635b682f,DISK], DatanodeInfoWithStorage[127.0.0.1:34782,DS-cf759369-0a6b-40b7-ac52-3c9234574cd0,DISK], DatanodeInfoWithStorage[127.0.0.1:45356,DS-87fa26ba-e603-4918-8dde-9b8ebf6a599b,DISK], DatanodeInfoWithStorage[127.0.0.1:42764,DS-6b49c79c-d371-4951-aa9c-02e73fc762ec,DISK], DatanodeInfoWithStorage[127.0.0.1:39772,DS-9c71ec6c-1c96-4221-9ad6-09785f89a619,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-994280965-172.17.0.12-1598103334102:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45458,DS-6d9b5408-ddee-443e-bb73-e0842a25fc0d,DISK], DatanodeInfoWithStorage[127.0.0.1:46196,DS-d9c7c4b0-cbb8-4f74-8de4-703f8c72c388,DISK], DatanodeInfoWithStorage[127.0.0.1:39072,DS-3f64d3f0-905e-420e-9b96-21b7c5db8f87,DISK], DatanodeInfoWithStorage[127.0.0.1:43018,DS-cadaa92d-cd0b-4330-9c30-33dd635b682f,DISK], DatanodeInfoWithStorage[127.0.0.1:34782,DS-cf759369-0a6b-40b7-ac52-3c9234574cd0,DISK], DatanodeInfoWithStorage[127.0.0.1:45356,DS-87fa26ba-e603-4918-8dde-9b8ebf6a599b,DISK], DatanodeInfoWithStorage[127.0.0.1:42764,DS-6b49c79c-d371-4951-aa9c-02e73fc762ec,DISK], DatanodeInfoWithStorage[127.0.0.1:39772,DS-9c71ec6c-1c96-4221-9ad6-09785f89a619,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2145632428-172.17.0.12-1598103371633:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41059,DS-c2044f8d-9b1c-4c8b-aaae-544d9c9750eb,DISK], DatanodeInfoWithStorage[127.0.0.1:42498,DS-96cf505d-766e-44e9-aa58-58024bb4bfea,DISK], DatanodeInfoWithStorage[127.0.0.1:43573,DS-9386fd6b-6de1-45f4-944c-d7b210e62b61,DISK], DatanodeInfoWithStorage[127.0.0.1:38048,DS-2b739f36-491a-4366-bd36-54a170c5697a,DISK], DatanodeInfoWithStorage[127.0.0.1:41533,DS-1ce0d855-f87b-45f7-8619-9b307c143785,DISK], DatanodeInfoWithStorage[127.0.0.1:41286,DS-da74b0f5-0aae-429f-8b4c-7e26ea51e87c,DISK], DatanodeInfoWithStorage[127.0.0.1:45140,DS-808457f5-e5fe-4e51-a9b5-13fdb176fd26,DISK], DatanodeInfoWithStorage[127.0.0.1:42693,DS-a5124f73-6789-4e5f-9736-184789ad46fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2145632428-172.17.0.12-1598103371633:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41059,DS-c2044f8d-9b1c-4c8b-aaae-544d9c9750eb,DISK], DatanodeInfoWithStorage[127.0.0.1:42498,DS-96cf505d-766e-44e9-aa58-58024bb4bfea,DISK], DatanodeInfoWithStorage[127.0.0.1:43573,DS-9386fd6b-6de1-45f4-944c-d7b210e62b61,DISK], DatanodeInfoWithStorage[127.0.0.1:38048,DS-2b739f36-491a-4366-bd36-54a170c5697a,DISK], DatanodeInfoWithStorage[127.0.0.1:41533,DS-1ce0d855-f87b-45f7-8619-9b307c143785,DISK], DatanodeInfoWithStorage[127.0.0.1:41286,DS-da74b0f5-0aae-429f-8b4c-7e26ea51e87c,DISK], DatanodeInfoWithStorage[127.0.0.1:45140,DS-808457f5-e5fe-4e51-a9b5-13fdb176fd26,DISK], DatanodeInfoWithStorage[127.0.0.1:42693,DS-a5124f73-6789-4e5f-9736-184789ad46fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-753763441-172.17.0.12-1598104251969:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35637,DS-ab66a9f3-d7e0-444a-a617-345f411fdb91,DISK], DatanodeInfoWithStorage[127.0.0.1:44959,DS-570b4a85-9aa1-4d34-9663-ad90521f5ce2,DISK], DatanodeInfoWithStorage[127.0.0.1:42829,DS-19e62278-7a8c-46d4-8ab0-53a7f93a8edf,DISK], DatanodeInfoWithStorage[127.0.0.1:33977,DS-4344e6d0-b7d5-494e-beac-f0537ee9391e,DISK], DatanodeInfoWithStorage[127.0.0.1:36142,DS-1c5f45fc-9083-4cec-9f2a-fa7730316d6d,DISK], DatanodeInfoWithStorage[127.0.0.1:36404,DS-a634c9c1-ca6e-4725-9d9b-edc77700ca8c,DISK], DatanodeInfoWithStorage[127.0.0.1:33479,DS-a7142278-08ab-4b95-88ca-8edd11f7b807,DISK], DatanodeInfoWithStorage[127.0.0.1:34820,DS-d12e0dc4-5f2e-43e6-967f-57e254386c46,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-753763441-172.17.0.12-1598104251969:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35637,DS-ab66a9f3-d7e0-444a-a617-345f411fdb91,DISK], DatanodeInfoWithStorage[127.0.0.1:44959,DS-570b4a85-9aa1-4d34-9663-ad90521f5ce2,DISK], DatanodeInfoWithStorage[127.0.0.1:42829,DS-19e62278-7a8c-46d4-8ab0-53a7f93a8edf,DISK], DatanodeInfoWithStorage[127.0.0.1:33977,DS-4344e6d0-b7d5-494e-beac-f0537ee9391e,DISK], DatanodeInfoWithStorage[127.0.0.1:36142,DS-1c5f45fc-9083-4cec-9f2a-fa7730316d6d,DISK], DatanodeInfoWithStorage[127.0.0.1:36404,DS-a634c9c1-ca6e-4725-9d9b-edc77700ca8c,DISK], DatanodeInfoWithStorage[127.0.0.1:33479,DS-a7142278-08ab-4b95-88ca-8edd11f7b807,DISK], DatanodeInfoWithStorage[127.0.0.1:34820,DS-d12e0dc4-5f2e-43e6-967f-57e254386c46,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1192182444-172.17.0.12-1598104662755:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33888,DS-675f4935-988d-4ea8-a441-fb7dd123da1a,DISK], DatanodeInfoWithStorage[127.0.0.1:34280,DS-a56993eb-01a8-42eb-8a91-059d85a7263a,DISK], DatanodeInfoWithStorage[127.0.0.1:37910,DS-5290c374-0694-48c2-8ab2-ca06fb311661,DISK], DatanodeInfoWithStorage[127.0.0.1:42514,DS-7c6f4786-bb44-45db-8891-67ef1a05bafd,DISK], DatanodeInfoWithStorage[127.0.0.1:32979,DS-44b3255a-a059-4580-b68e-b22e28c0f15a,DISK], DatanodeInfoWithStorage[127.0.0.1:45282,DS-1845bcac-5612-4e1b-af8d-41058d7d8054,DISK], DatanodeInfoWithStorage[127.0.0.1:34833,DS-f7998378-7322-450f-9e02-8a08a9b31d0f,DISK], DatanodeInfoWithStorage[127.0.0.1:36536,DS-6e6cb7ef-9e34-4a87-9622-32cf50a756a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1192182444-172.17.0.12-1598104662755:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33888,DS-675f4935-988d-4ea8-a441-fb7dd123da1a,DISK], DatanodeInfoWithStorage[127.0.0.1:34280,DS-a56993eb-01a8-42eb-8a91-059d85a7263a,DISK], DatanodeInfoWithStorage[127.0.0.1:37910,DS-5290c374-0694-48c2-8ab2-ca06fb311661,DISK], DatanodeInfoWithStorage[127.0.0.1:42514,DS-7c6f4786-bb44-45db-8891-67ef1a05bafd,DISK], DatanodeInfoWithStorage[127.0.0.1:32979,DS-44b3255a-a059-4580-b68e-b22e28c0f15a,DISK], DatanodeInfoWithStorage[127.0.0.1:45282,DS-1845bcac-5612-4e1b-af8d-41058d7d8054,DISK], DatanodeInfoWithStorage[127.0.0.1:34833,DS-f7998378-7322-450f-9e02-8a08a9b31d0f,DISK], DatanodeInfoWithStorage[127.0.0.1:36536,DS-6e6cb7ef-9e34-4a87-9622-32cf50a756a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1388211700-172.17.0.12-1598104952572:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33197,DS-12ac5950-3be0-4523-8965-0367654e1af8,DISK], DatanodeInfoWithStorage[127.0.0.1:39671,DS-f1120300-a4fa-47ae-80a8-2abeaafe6882,DISK], DatanodeInfoWithStorage[127.0.0.1:36464,DS-1a400ad4-399c-4790-b23a-fdba589aaf01,DISK], DatanodeInfoWithStorage[127.0.0.1:35057,DS-3af90b88-9ecb-4b17-bdf7-0e20abe74577,DISK], DatanodeInfoWithStorage[127.0.0.1:46345,DS-389c8882-3f15-437d-91c3-3da1030d3efe,DISK], DatanodeInfoWithStorage[127.0.0.1:40533,DS-02798356-74de-4aed-8260-57a07c865080,DISK], DatanodeInfoWithStorage[127.0.0.1:38422,DS-65a5ea62-f041-4579-bd0e-cd8f4845adeb,DISK], DatanodeInfoWithStorage[127.0.0.1:37609,DS-99ff54b5-88ff-4f0c-8faa-ce983cf9468a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1388211700-172.17.0.12-1598104952572:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33197,DS-12ac5950-3be0-4523-8965-0367654e1af8,DISK], DatanodeInfoWithStorage[127.0.0.1:39671,DS-f1120300-a4fa-47ae-80a8-2abeaafe6882,DISK], DatanodeInfoWithStorage[127.0.0.1:36464,DS-1a400ad4-399c-4790-b23a-fdba589aaf01,DISK], DatanodeInfoWithStorage[127.0.0.1:35057,DS-3af90b88-9ecb-4b17-bdf7-0e20abe74577,DISK], DatanodeInfoWithStorage[127.0.0.1:46345,DS-389c8882-3f15-437d-91c3-3da1030d3efe,DISK], DatanodeInfoWithStorage[127.0.0.1:40533,DS-02798356-74de-4aed-8260-57a07c865080,DISK], DatanodeInfoWithStorage[127.0.0.1:38422,DS-65a5ea62-f041-4579-bd0e-cd8f4845adeb,DISK], DatanodeInfoWithStorage[127.0.0.1:37609,DS-99ff54b5-88ff-4f0c-8faa-ce983cf9468a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-529705093-172.17.0.12-1598105095309:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43033,DS-fd6f6145-24b0-447a-a300-26b349660de4,DISK], DatanodeInfoWithStorage[127.0.0.1:42554,DS-0591e5d1-aa0f-4a39-a443-93be08bc5bb7,DISK], DatanodeInfoWithStorage[127.0.0.1:33241,DS-85cd30d6-d0c5-4d59-9442-afca894804de,DISK], DatanodeInfoWithStorage[127.0.0.1:38954,DS-201fa5c5-6e0f-4c5f-95a4-543a47ee7a7f,DISK], DatanodeInfoWithStorage[127.0.0.1:38456,DS-2bf631c2-d75a-4ac3-84d2-5519ec3731a1,DISK], DatanodeInfoWithStorage[127.0.0.1:38635,DS-c568ff78-689b-45ef-9628-1eea86658386,DISK], DatanodeInfoWithStorage[127.0.0.1:46252,DS-7988ba7f-61e1-44fe-b2e1-3d0a355d7368,DISK], DatanodeInfoWithStorage[127.0.0.1:33176,DS-9782b0b6-26dc-4679-9b8b-d15fbbb0f13f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-529705093-172.17.0.12-1598105095309:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43033,DS-fd6f6145-24b0-447a-a300-26b349660de4,DISK], DatanodeInfoWithStorage[127.0.0.1:42554,DS-0591e5d1-aa0f-4a39-a443-93be08bc5bb7,DISK], DatanodeInfoWithStorage[127.0.0.1:33241,DS-85cd30d6-d0c5-4d59-9442-afca894804de,DISK], DatanodeInfoWithStorage[127.0.0.1:38954,DS-201fa5c5-6e0f-4c5f-95a4-543a47ee7a7f,DISK], DatanodeInfoWithStorage[127.0.0.1:38456,DS-2bf631c2-d75a-4ac3-84d2-5519ec3731a1,DISK], DatanodeInfoWithStorage[127.0.0.1:38635,DS-c568ff78-689b-45ef-9628-1eea86658386,DISK], DatanodeInfoWithStorage[127.0.0.1:46252,DS-7988ba7f-61e1-44fe-b2e1-3d0a355d7368,DISK], DatanodeInfoWithStorage[127.0.0.1:33176,DS-9782b0b6-26dc-4679-9b8b-d15fbbb0f13f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1976790272-172.17.0.12-1598105196391:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36686,DS-9ccf65e6-0986-45dd-9d33-22a22fa79e52,DISK], DatanodeInfoWithStorage[127.0.0.1:40006,DS-4b3252e6-8998-49a5-9222-d82d9ea48acc,DISK], DatanodeInfoWithStorage[127.0.0.1:44619,DS-02e8015f-aa7d-413f-bb73-8c8cdde2ee07,DISK], DatanodeInfoWithStorage[127.0.0.1:46572,DS-da38e9d5-523d-4e24-a438-8e475510e4bf,DISK], DatanodeInfoWithStorage[127.0.0.1:36657,DS-f349f753-5bf2-4c21-8e04-72725241417c,DISK], DatanodeInfoWithStorage[127.0.0.1:42674,DS-78f72812-45d6-4db8-8c0c-214dfaaafc87,DISK], DatanodeInfoWithStorage[127.0.0.1:38916,DS-5f20956d-84f0-4902-9d39-fde35543fb9f,DISK], DatanodeInfoWithStorage[127.0.0.1:37125,DS-b3896f20-2161-4c55-bcb9-6f9b746e7c16,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1976790272-172.17.0.12-1598105196391:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36686,DS-9ccf65e6-0986-45dd-9d33-22a22fa79e52,DISK], DatanodeInfoWithStorage[127.0.0.1:40006,DS-4b3252e6-8998-49a5-9222-d82d9ea48acc,DISK], DatanodeInfoWithStorage[127.0.0.1:44619,DS-02e8015f-aa7d-413f-bb73-8c8cdde2ee07,DISK], DatanodeInfoWithStorage[127.0.0.1:46572,DS-da38e9d5-523d-4e24-a438-8e475510e4bf,DISK], DatanodeInfoWithStorage[127.0.0.1:36657,DS-f349f753-5bf2-4c21-8e04-72725241417c,DISK], DatanodeInfoWithStorage[127.0.0.1:42674,DS-78f72812-45d6-4db8-8c0c-214dfaaafc87,DISK], DatanodeInfoWithStorage[127.0.0.1:38916,DS-5f20956d-84f0-4902-9d39-fde35543fb9f,DISK], DatanodeInfoWithStorage[127.0.0.1:37125,DS-b3896f20-2161-4c55-bcb9-6f9b746e7c16,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-668483261-172.17.0.12-1598105436800:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37729,DS-1837eb7a-63b2-4a70-b43f-fab2bd96e0e8,DISK], DatanodeInfoWithStorage[127.0.0.1:40778,DS-0d8ca520-d76c-42c4-a627-95817cf7fa8a,DISK], DatanodeInfoWithStorage[127.0.0.1:34353,DS-9f2e1f32-d22e-4c8c-83d5-8a62c8bfccbb,DISK], DatanodeInfoWithStorage[127.0.0.1:43437,DS-93c590ab-a725-450d-8d9c-120a96506cc8,DISK], DatanodeInfoWithStorage[127.0.0.1:42019,DS-7e61db77-63bd-4d94-89d4-45a57f1944d4,DISK], DatanodeInfoWithStorage[127.0.0.1:40758,DS-5cce58b0-256a-4eaa-9ea9-54502911d054,DISK], DatanodeInfoWithStorage[127.0.0.1:33545,DS-4985dc79-b595-4f04-b391-a71c666c0af7,DISK], DatanodeInfoWithStorage[127.0.0.1:45469,DS-0e10f800-3145-4a62-aba9-1e659399117d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-668483261-172.17.0.12-1598105436800:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37729,DS-1837eb7a-63b2-4a70-b43f-fab2bd96e0e8,DISK], DatanodeInfoWithStorage[127.0.0.1:40778,DS-0d8ca520-d76c-42c4-a627-95817cf7fa8a,DISK], DatanodeInfoWithStorage[127.0.0.1:34353,DS-9f2e1f32-d22e-4c8c-83d5-8a62c8bfccbb,DISK], DatanodeInfoWithStorage[127.0.0.1:43437,DS-93c590ab-a725-450d-8d9c-120a96506cc8,DISK], DatanodeInfoWithStorage[127.0.0.1:42019,DS-7e61db77-63bd-4d94-89d4-45a57f1944d4,DISK], DatanodeInfoWithStorage[127.0.0.1:40758,DS-5cce58b0-256a-4eaa-9ea9-54502911d054,DISK], DatanodeInfoWithStorage[127.0.0.1:33545,DS-4985dc79-b595-4f04-b391-a71c666c0af7,DISK], DatanodeInfoWithStorage[127.0.0.1:45469,DS-0e10f800-3145-4a62-aba9-1e659399117d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1658426656-172.17.0.12-1598105480247:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39329,DS-8d4c5a97-0ac4-43b5-8b16-fb1c4d4be73f,DISK], DatanodeInfoWithStorage[127.0.0.1:43200,DS-25df15ce-bd10-420b-bde7-96195a4c76be,DISK], DatanodeInfoWithStorage[127.0.0.1:36013,DS-2320efa6-7818-4c11-8788-294421553718,DISK], DatanodeInfoWithStorage[127.0.0.1:38077,DS-1d7d5cb8-37c4-4564-a80c-ce384be06925,DISK], DatanodeInfoWithStorage[127.0.0.1:36960,DS-9b82f981-058a-426c-8545-62c41cf0741c,DISK], DatanodeInfoWithStorage[127.0.0.1:41057,DS-0a86da92-c403-4e99-a9a7-b18c41a9db0c,DISK], DatanodeInfoWithStorage[127.0.0.1:35137,DS-1808fb0f-8232-4acc-b12f-5d9f770f94c6,DISK], DatanodeInfoWithStorage[127.0.0.1:44950,DS-d8641365-fd9a-4f54-a91e-7cbb2db4a6cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1658426656-172.17.0.12-1598105480247:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39329,DS-8d4c5a97-0ac4-43b5-8b16-fb1c4d4be73f,DISK], DatanodeInfoWithStorage[127.0.0.1:43200,DS-25df15ce-bd10-420b-bde7-96195a4c76be,DISK], DatanodeInfoWithStorage[127.0.0.1:36013,DS-2320efa6-7818-4c11-8788-294421553718,DISK], DatanodeInfoWithStorage[127.0.0.1:38077,DS-1d7d5cb8-37c4-4564-a80c-ce384be06925,DISK], DatanodeInfoWithStorage[127.0.0.1:36960,DS-9b82f981-058a-426c-8545-62c41cf0741c,DISK], DatanodeInfoWithStorage[127.0.0.1:41057,DS-0a86da92-c403-4e99-a9a7-b18c41a9db0c,DISK], DatanodeInfoWithStorage[127.0.0.1:35137,DS-1808fb0f-8232-4acc-b12f-5d9f770f94c6,DISK], DatanodeInfoWithStorage[127.0.0.1:44950,DS-d8641365-fd9a-4f54-a91e-7cbb2db4a6cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-347402940-172.17.0.12-1598105979033:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37185,DS-5153ee1c-b392-4c29-bf32-08df8482b019,DISK], DatanodeInfoWithStorage[127.0.0.1:35940,DS-f7e8ce90-d76d-41d6-8cc6-aff4b4a286f2,DISK], DatanodeInfoWithStorage[127.0.0.1:45303,DS-d3bd71a0-405d-487b-9477-cbf9110cd883,DISK], DatanodeInfoWithStorage[127.0.0.1:33821,DS-d0b69e6a-ab4f-42ee-8357-ac1e608e442d,DISK], DatanodeInfoWithStorage[127.0.0.1:44196,DS-857ec998-049e-493d-b1b3-a6e99331760e,DISK], DatanodeInfoWithStorage[127.0.0.1:33513,DS-ae0bbb08-09b4-4758-b462-656d24f11be2,DISK], DatanodeInfoWithStorage[127.0.0.1:34887,DS-53c1bea9-b85d-4261-8dbe-8b016d5079a5,DISK], DatanodeInfoWithStorage[127.0.0.1:40932,DS-cfed02c3-6673-4c34-a646-5b630042c491,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-347402940-172.17.0.12-1598105979033:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37185,DS-5153ee1c-b392-4c29-bf32-08df8482b019,DISK], DatanodeInfoWithStorage[127.0.0.1:35940,DS-f7e8ce90-d76d-41d6-8cc6-aff4b4a286f2,DISK], DatanodeInfoWithStorage[127.0.0.1:45303,DS-d3bd71a0-405d-487b-9477-cbf9110cd883,DISK], DatanodeInfoWithStorage[127.0.0.1:33821,DS-d0b69e6a-ab4f-42ee-8357-ac1e608e442d,DISK], DatanodeInfoWithStorage[127.0.0.1:44196,DS-857ec998-049e-493d-b1b3-a6e99331760e,DISK], DatanodeInfoWithStorage[127.0.0.1:33513,DS-ae0bbb08-09b4-4758-b462-656d24f11be2,DISK], DatanodeInfoWithStorage[127.0.0.1:34887,DS-53c1bea9-b85d-4261-8dbe-8b016d5079a5,DISK], DatanodeInfoWithStorage[127.0.0.1:40932,DS-cfed02c3-6673-4c34-a646-5b630042c491,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-421730237-172.17.0.12-1598106307381:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36996,DS-f88777c8-93be-474b-8dfb-8900cc0662b6,DISK], DatanodeInfoWithStorage[127.0.0.1:46376,DS-0edf5bf5-cd73-41f0-892b-300fa6b0e161,DISK], DatanodeInfoWithStorage[127.0.0.1:45080,DS-88e9915a-1b11-48ae-a60d-134ea35c0d66,DISK], DatanodeInfoWithStorage[127.0.0.1:44527,DS-b0df4c15-68a6-45c9-9761-bde12a9a2f6c,DISK], DatanodeInfoWithStorage[127.0.0.1:40252,DS-673f6735-e794-49ac-bb43-513b5b16e23e,DISK], DatanodeInfoWithStorage[127.0.0.1:44978,DS-773d387e-f711-4d7c-b716-991fef3f9bd0,DISK], DatanodeInfoWithStorage[127.0.0.1:34754,DS-9e8553c3-e707-4173-9401-ea38e96ed97b,DISK], DatanodeInfoWithStorage[127.0.0.1:33984,DS-b16950ff-1248-4cdc-baaf-074c4a834569,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-421730237-172.17.0.12-1598106307381:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36996,DS-f88777c8-93be-474b-8dfb-8900cc0662b6,DISK], DatanodeInfoWithStorage[127.0.0.1:46376,DS-0edf5bf5-cd73-41f0-892b-300fa6b0e161,DISK], DatanodeInfoWithStorage[127.0.0.1:45080,DS-88e9915a-1b11-48ae-a60d-134ea35c0d66,DISK], DatanodeInfoWithStorage[127.0.0.1:44527,DS-b0df4c15-68a6-45c9-9761-bde12a9a2f6c,DISK], DatanodeInfoWithStorage[127.0.0.1:40252,DS-673f6735-e794-49ac-bb43-513b5b16e23e,DISK], DatanodeInfoWithStorage[127.0.0.1:44978,DS-773d387e-f711-4d7c-b716-991fef3f9bd0,DISK], DatanodeInfoWithStorage[127.0.0.1:34754,DS-9e8553c3-e707-4173-9401-ea38e96ed97b,DISK], DatanodeInfoWithStorage[127.0.0.1:33984,DS-b16950ff-1248-4cdc-baaf-074c4a834569,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2074894594-172.17.0.12-1598106717257:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41186,DS-ec96cbfa-2e66-4d5a-8a04-9381c42efb65,DISK], DatanodeInfoWithStorage[127.0.0.1:42467,DS-90de58cb-c8b2-4018-aa09-1052bbfbaa74,DISK], DatanodeInfoWithStorage[127.0.0.1:42357,DS-2a271e52-ec7a-4a38-8a9b-db08aecde4be,DISK], DatanodeInfoWithStorage[127.0.0.1:43811,DS-7239887d-7093-413e-a95f-1e519d981d13,DISK], DatanodeInfoWithStorage[127.0.0.1:38979,DS-092586e2-3c52-47e0-b884-bbd8bbf2a833,DISK], DatanodeInfoWithStorage[127.0.0.1:43212,DS-a5b0a0bc-6302-4541-b5b8-3665445434ac,DISK], DatanodeInfoWithStorage[127.0.0.1:40232,DS-01ea1dc8-93a1-412b-a9f6-d33455732428,DISK], DatanodeInfoWithStorage[127.0.0.1:45392,DS-b2029150-3268-4a67-ab89-3cfc5008493a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2074894594-172.17.0.12-1598106717257:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41186,DS-ec96cbfa-2e66-4d5a-8a04-9381c42efb65,DISK], DatanodeInfoWithStorage[127.0.0.1:42467,DS-90de58cb-c8b2-4018-aa09-1052bbfbaa74,DISK], DatanodeInfoWithStorage[127.0.0.1:42357,DS-2a271e52-ec7a-4a38-8a9b-db08aecde4be,DISK], DatanodeInfoWithStorage[127.0.0.1:43811,DS-7239887d-7093-413e-a95f-1e519d981d13,DISK], DatanodeInfoWithStorage[127.0.0.1:38979,DS-092586e2-3c52-47e0-b884-bbd8bbf2a833,DISK], DatanodeInfoWithStorage[127.0.0.1:43212,DS-a5b0a0bc-6302-4541-b5b8-3665445434ac,DISK], DatanodeInfoWithStorage[127.0.0.1:40232,DS-01ea1dc8-93a1-412b-a9f6-d33455732428,DISK], DatanodeInfoWithStorage[127.0.0.1:45392,DS-b2029150-3268-4a67-ab89-3cfc5008493a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-283369024-172.17.0.12-1598107093334:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40425,DS-a548a755-d88d-49d4-86c6-e02c7e79da7b,DISK], DatanodeInfoWithStorage[127.0.0.1:33570,DS-96d9458f-987f-40aa-b1f8-f824e33e0fcc,DISK], DatanodeInfoWithStorage[127.0.0.1:35718,DS-b4915c04-a771-4899-b88f-4a4e20427a6f,DISK], DatanodeInfoWithStorage[127.0.0.1:45311,DS-d2fa35e0-396f-440b-9d9c-d60446a39969,DISK], DatanodeInfoWithStorage[127.0.0.1:45892,DS-734475e3-7626-43c5-9c09-196a1d0a226f,DISK], DatanodeInfoWithStorage[127.0.0.1:43290,DS-71204c25-58cb-4737-a5da-5026dbc4b586,DISK], DatanodeInfoWithStorage[127.0.0.1:37641,DS-6b415c33-81a4-4a67-b2a8-6e9ea625a3e3,DISK], DatanodeInfoWithStorage[127.0.0.1:37725,DS-7a89c74e-31e8-4353-acba-09437db75ad7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-283369024-172.17.0.12-1598107093334:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40425,DS-a548a755-d88d-49d4-86c6-e02c7e79da7b,DISK], DatanodeInfoWithStorage[127.0.0.1:33570,DS-96d9458f-987f-40aa-b1f8-f824e33e0fcc,DISK], DatanodeInfoWithStorage[127.0.0.1:35718,DS-b4915c04-a771-4899-b88f-4a4e20427a6f,DISK], DatanodeInfoWithStorage[127.0.0.1:45311,DS-d2fa35e0-396f-440b-9d9c-d60446a39969,DISK], DatanodeInfoWithStorage[127.0.0.1:45892,DS-734475e3-7626-43c5-9c09-196a1d0a226f,DISK], DatanodeInfoWithStorage[127.0.0.1:43290,DS-71204c25-58cb-4737-a5da-5026dbc4b586,DISK], DatanodeInfoWithStorage[127.0.0.1:37641,DS-6b415c33-81a4-4a67-b2a8-6e9ea625a3e3,DISK], DatanodeInfoWithStorage[127.0.0.1:37725,DS-7a89c74e-31e8-4353-acba-09437db75ad7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1847362586-172.17.0.12-1598107431329:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37657,DS-5c1931c5-5a4a-4fe3-9362-49275bb79d8f,DISK], DatanodeInfoWithStorage[127.0.0.1:34550,DS-034ec1f7-6aa0-4ce5-b285-78ca046fda16,DISK], DatanodeInfoWithStorage[127.0.0.1:38370,DS-6cf5e78e-c891-4268-a433-d89106d167b3,DISK], DatanodeInfoWithStorage[127.0.0.1:41958,DS-dd59319c-af50-49b7-836b-cbcb542adeb7,DISK], DatanodeInfoWithStorage[127.0.0.1:46362,DS-a367f260-56d6-43d2-b3ba-e7eb09c808dc,DISK], DatanodeInfoWithStorage[127.0.0.1:45779,DS-4aeba2ba-16a7-446d-8b03-3881641f6cd4,DISK], DatanodeInfoWithStorage[127.0.0.1:35803,DS-1d738e41-f459-4d8c-8a18-ec6c0d1dcfde,DISK], DatanodeInfoWithStorage[127.0.0.1:41102,DS-424fc469-4d46-4f40-af7e-99ae464146ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1847362586-172.17.0.12-1598107431329:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37657,DS-5c1931c5-5a4a-4fe3-9362-49275bb79d8f,DISK], DatanodeInfoWithStorage[127.0.0.1:34550,DS-034ec1f7-6aa0-4ce5-b285-78ca046fda16,DISK], DatanodeInfoWithStorage[127.0.0.1:38370,DS-6cf5e78e-c891-4268-a433-d89106d167b3,DISK], DatanodeInfoWithStorage[127.0.0.1:41958,DS-dd59319c-af50-49b7-836b-cbcb542adeb7,DISK], DatanodeInfoWithStorage[127.0.0.1:46362,DS-a367f260-56d6-43d2-b3ba-e7eb09c808dc,DISK], DatanodeInfoWithStorage[127.0.0.1:45779,DS-4aeba2ba-16a7-446d-8b03-3881641f6cd4,DISK], DatanodeInfoWithStorage[127.0.0.1:35803,DS-1d738e41-f459-4d8c-8a18-ec6c0d1dcfde,DISK], DatanodeInfoWithStorage[127.0.0.1:41102,DS-424fc469-4d46-4f40-af7e-99ae464146ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 10 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: might be true error
Total execution time in seconds : 5644
