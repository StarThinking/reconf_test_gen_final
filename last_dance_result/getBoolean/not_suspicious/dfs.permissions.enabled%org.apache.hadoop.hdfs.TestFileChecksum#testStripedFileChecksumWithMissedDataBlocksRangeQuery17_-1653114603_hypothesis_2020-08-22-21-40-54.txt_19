reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2139367024-172.17.0.17-1598132610858:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37818,DS-e685c7ce-1219-4f2b-a836-06aebac3c76e,DISK], DatanodeInfoWithStorage[127.0.0.1:35745,DS-bcda86a6-956e-4c09-96e5-a4f7fec16807,DISK], DatanodeInfoWithStorage[127.0.0.1:42205,DS-11d99bb5-b1a4-45f5-ab11-8934847d204b,DISK], DatanodeInfoWithStorage[127.0.0.1:36417,DS-26521c90-0715-40ff-b5ed-718b627c13cc,DISK], DatanodeInfoWithStorage[127.0.0.1:45614,DS-2149732a-6144-4867-ba28-76b93fffbafc,DISK], DatanodeInfoWithStorage[127.0.0.1:35424,DS-cde63a5b-0729-4137-85ba-1f93f3adc94f,DISK], DatanodeInfoWithStorage[127.0.0.1:45895,DS-0b6b3989-db6c-4aee-a167-7c619132c897,DISK], DatanodeInfoWithStorage[127.0.0.1:34101,DS-6c95cccf-63cc-4b50-926e-765c7381d0b4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2139367024-172.17.0.17-1598132610858:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37818,DS-e685c7ce-1219-4f2b-a836-06aebac3c76e,DISK], DatanodeInfoWithStorage[127.0.0.1:35745,DS-bcda86a6-956e-4c09-96e5-a4f7fec16807,DISK], DatanodeInfoWithStorage[127.0.0.1:42205,DS-11d99bb5-b1a4-45f5-ab11-8934847d204b,DISK], DatanodeInfoWithStorage[127.0.0.1:36417,DS-26521c90-0715-40ff-b5ed-718b627c13cc,DISK], DatanodeInfoWithStorage[127.0.0.1:45614,DS-2149732a-6144-4867-ba28-76b93fffbafc,DISK], DatanodeInfoWithStorage[127.0.0.1:35424,DS-cde63a5b-0729-4137-85ba-1f93f3adc94f,DISK], DatanodeInfoWithStorage[127.0.0.1:45895,DS-0b6b3989-db6c-4aee-a167-7c619132c897,DISK], DatanodeInfoWithStorage[127.0.0.1:34101,DS-6c95cccf-63cc-4b50-926e-765c7381d0b4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-714294716-172.17.0.17-1598132753230:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43327,DS-c3f8d9bf-c63a-4a76-8878-b023b45a5743,DISK], DatanodeInfoWithStorage[127.0.0.1:44198,DS-0d840dbd-6e3a-4501-929c-6d5cc45568df,DISK], DatanodeInfoWithStorage[127.0.0.1:39966,DS-e5a63193-5694-478c-a5f4-783b0cc8c368,DISK], DatanodeInfoWithStorage[127.0.0.1:37381,DS-bec1c5a9-6010-4dca-9747-2d53a381fb43,DISK], DatanodeInfoWithStorage[127.0.0.1:34901,DS-4f9406af-92fe-4c2e-aadf-9659141f3d80,DISK], DatanodeInfoWithStorage[127.0.0.1:44482,DS-c4cbb136-803d-4d72-8721-cd06282a2e31,DISK], DatanodeInfoWithStorage[127.0.0.1:32949,DS-6c7852b0-f548-474b-9a6d-7dc7595de18f,DISK], DatanodeInfoWithStorage[127.0.0.1:42916,DS-563a00c8-a998-4c26-9ea7-1face067a0b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-714294716-172.17.0.17-1598132753230:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43327,DS-c3f8d9bf-c63a-4a76-8878-b023b45a5743,DISK], DatanodeInfoWithStorage[127.0.0.1:44198,DS-0d840dbd-6e3a-4501-929c-6d5cc45568df,DISK], DatanodeInfoWithStorage[127.0.0.1:39966,DS-e5a63193-5694-478c-a5f4-783b0cc8c368,DISK], DatanodeInfoWithStorage[127.0.0.1:37381,DS-bec1c5a9-6010-4dca-9747-2d53a381fb43,DISK], DatanodeInfoWithStorage[127.0.0.1:34901,DS-4f9406af-92fe-4c2e-aadf-9659141f3d80,DISK], DatanodeInfoWithStorage[127.0.0.1:44482,DS-c4cbb136-803d-4d72-8721-cd06282a2e31,DISK], DatanodeInfoWithStorage[127.0.0.1:32949,DS-6c7852b0-f548-474b-9a6d-7dc7595de18f,DISK], DatanodeInfoWithStorage[127.0.0.1:42916,DS-563a00c8-a998-4c26-9ea7-1face067a0b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1577035069-172.17.0.17-1598132991752:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38648,DS-056ddf03-daf1-4cb4-b857-c8cfbbc04529,DISK], DatanodeInfoWithStorage[127.0.0.1:42427,DS-eb3c62fd-8ecb-40b0-b2c6-15280a4d09dd,DISK], DatanodeInfoWithStorage[127.0.0.1:42872,DS-c40a9d8e-9d56-41cc-bb1b-e5508f3bb9d3,DISK], DatanodeInfoWithStorage[127.0.0.1:33289,DS-9674b809-1a73-488f-95b3-b6ce78a3b6ec,DISK], DatanodeInfoWithStorage[127.0.0.1:35358,DS-0f34b4f0-3a39-4501-a11e-eb46be76576d,DISK], DatanodeInfoWithStorage[127.0.0.1:46177,DS-12410019-c990-42b9-85cd-eed4c255e395,DISK], DatanodeInfoWithStorage[127.0.0.1:38341,DS-880d70ae-c1e3-4476-b749-c4a48fa29b08,DISK], DatanodeInfoWithStorage[127.0.0.1:42494,DS-11b793a9-f865-41b1-b2e7-55587eef45f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1577035069-172.17.0.17-1598132991752:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38648,DS-056ddf03-daf1-4cb4-b857-c8cfbbc04529,DISK], DatanodeInfoWithStorage[127.0.0.1:42427,DS-eb3c62fd-8ecb-40b0-b2c6-15280a4d09dd,DISK], DatanodeInfoWithStorage[127.0.0.1:42872,DS-c40a9d8e-9d56-41cc-bb1b-e5508f3bb9d3,DISK], DatanodeInfoWithStorage[127.0.0.1:33289,DS-9674b809-1a73-488f-95b3-b6ce78a3b6ec,DISK], DatanodeInfoWithStorage[127.0.0.1:35358,DS-0f34b4f0-3a39-4501-a11e-eb46be76576d,DISK], DatanodeInfoWithStorage[127.0.0.1:46177,DS-12410019-c990-42b9-85cd-eed4c255e395,DISK], DatanodeInfoWithStorage[127.0.0.1:38341,DS-880d70ae-c1e3-4476-b749-c4a48fa29b08,DISK], DatanodeInfoWithStorage[127.0.0.1:42494,DS-11b793a9-f865-41b1-b2e7-55587eef45f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-510039015-172.17.0.17-1598133039601:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46826,DS-36be413a-aeda-4324-860b-3e4341fbbee9,DISK], DatanodeInfoWithStorage[127.0.0.1:38059,DS-2eebd7c7-f1fa-47da-bfac-4797a8c023b7,DISK], DatanodeInfoWithStorage[127.0.0.1:36397,DS-499a4706-31dc-4c0e-9301-d9bf83b7f77c,DISK], DatanodeInfoWithStorage[127.0.0.1:41738,DS-dc0fd925-8893-4341-b47b-c1ecd56b7357,DISK], DatanodeInfoWithStorage[127.0.0.1:41240,DS-7147d7b1-c9b1-446c-b4e2-fd55ba4415bf,DISK], DatanodeInfoWithStorage[127.0.0.1:46303,DS-5c3cff18-5bfa-452f-9ecf-053bfa73af5b,DISK], DatanodeInfoWithStorage[127.0.0.1:38480,DS-bdb3c55f-0102-4b65-99c4-1f6fcf6246c8,DISK], DatanodeInfoWithStorage[127.0.0.1:44869,DS-ab2a5503-d831-4c85-ac85-e14c6df69f2a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-510039015-172.17.0.17-1598133039601:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46826,DS-36be413a-aeda-4324-860b-3e4341fbbee9,DISK], DatanodeInfoWithStorage[127.0.0.1:38059,DS-2eebd7c7-f1fa-47da-bfac-4797a8c023b7,DISK], DatanodeInfoWithStorage[127.0.0.1:36397,DS-499a4706-31dc-4c0e-9301-d9bf83b7f77c,DISK], DatanodeInfoWithStorage[127.0.0.1:41738,DS-dc0fd925-8893-4341-b47b-c1ecd56b7357,DISK], DatanodeInfoWithStorage[127.0.0.1:41240,DS-7147d7b1-c9b1-446c-b4e2-fd55ba4415bf,DISK], DatanodeInfoWithStorage[127.0.0.1:46303,DS-5c3cff18-5bfa-452f-9ecf-053bfa73af5b,DISK], DatanodeInfoWithStorage[127.0.0.1:38480,DS-bdb3c55f-0102-4b65-99c4-1f6fcf6246c8,DISK], DatanodeInfoWithStorage[127.0.0.1:44869,DS-ab2a5503-d831-4c85-ac85-e14c6df69f2a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1977949439-172.17.0.17-1598133358193:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38801,DS-dbfca4fb-de12-4662-a340-1b32a2bf7563,DISK], DatanodeInfoWithStorage[127.0.0.1:34834,DS-5a5cdaf1-feaf-4003-afe9-d9d9f17a4cb0,DISK], DatanodeInfoWithStorage[127.0.0.1:33434,DS-cab23b0d-4f08-4569-96b6-bd9e21d4cd32,DISK], DatanodeInfoWithStorage[127.0.0.1:43943,DS-6fcfab66-aeaf-432c-9c3f-7ee0aba4dfd7,DISK], DatanodeInfoWithStorage[127.0.0.1:35262,DS-1dace07b-63c3-4573-9c43-d8e58b64d8ac,DISK], DatanodeInfoWithStorage[127.0.0.1:37324,DS-24b34318-a692-4bea-81bd-03062e984f01,DISK], DatanodeInfoWithStorage[127.0.0.1:40830,DS-c9d13aa1-ed8c-4b2d-bef3-b66686fbfc7d,DISK], DatanodeInfoWithStorage[127.0.0.1:37832,DS-7b4b76ae-5dbf-46fa-92e8-d5cbe3c4c4df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1977949439-172.17.0.17-1598133358193:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38801,DS-dbfca4fb-de12-4662-a340-1b32a2bf7563,DISK], DatanodeInfoWithStorage[127.0.0.1:34834,DS-5a5cdaf1-feaf-4003-afe9-d9d9f17a4cb0,DISK], DatanodeInfoWithStorage[127.0.0.1:33434,DS-cab23b0d-4f08-4569-96b6-bd9e21d4cd32,DISK], DatanodeInfoWithStorage[127.0.0.1:43943,DS-6fcfab66-aeaf-432c-9c3f-7ee0aba4dfd7,DISK], DatanodeInfoWithStorage[127.0.0.1:35262,DS-1dace07b-63c3-4573-9c43-d8e58b64d8ac,DISK], DatanodeInfoWithStorage[127.0.0.1:37324,DS-24b34318-a692-4bea-81bd-03062e984f01,DISK], DatanodeInfoWithStorage[127.0.0.1:40830,DS-c9d13aa1-ed8c-4b2d-bef3-b66686fbfc7d,DISK], DatanodeInfoWithStorage[127.0.0.1:37832,DS-7b4b76ae-5dbf-46fa-92e8-d5cbe3c4c4df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1494208481-172.17.0.17-1598133893337:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38313,DS-b8f864d3-f194-4a34-b03d-8d429ff02e60,DISK], DatanodeInfoWithStorage[127.0.0.1:39811,DS-170c4e85-28f2-4329-a733-3f5f86d653d3,DISK], DatanodeInfoWithStorage[127.0.0.1:37322,DS-0638fdf3-ba10-4560-9013-070a481e6bd5,DISK], DatanodeInfoWithStorage[127.0.0.1:38934,DS-50c0ac02-aa80-4425-bad4-f9388d5d1035,DISK], DatanodeInfoWithStorage[127.0.0.1:35454,DS-2882e1cf-73ac-4f50-be13-a82bf5a5ee4c,DISK], DatanodeInfoWithStorage[127.0.0.1:43188,DS-5c29e3c4-ac9d-4841-a066-f119348b2a07,DISK], DatanodeInfoWithStorage[127.0.0.1:43034,DS-4a6f6234-04ce-4ed6-b9fa-41e79245a710,DISK], DatanodeInfoWithStorage[127.0.0.1:33479,DS-ce6960c6-bdd8-497f-9bce-18c05254afa1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1494208481-172.17.0.17-1598133893337:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38313,DS-b8f864d3-f194-4a34-b03d-8d429ff02e60,DISK], DatanodeInfoWithStorage[127.0.0.1:39811,DS-170c4e85-28f2-4329-a733-3f5f86d653d3,DISK], DatanodeInfoWithStorage[127.0.0.1:37322,DS-0638fdf3-ba10-4560-9013-070a481e6bd5,DISK], DatanodeInfoWithStorage[127.0.0.1:38934,DS-50c0ac02-aa80-4425-bad4-f9388d5d1035,DISK], DatanodeInfoWithStorage[127.0.0.1:35454,DS-2882e1cf-73ac-4f50-be13-a82bf5a5ee4c,DISK], DatanodeInfoWithStorage[127.0.0.1:43188,DS-5c29e3c4-ac9d-4841-a066-f119348b2a07,DISK], DatanodeInfoWithStorage[127.0.0.1:43034,DS-4a6f6234-04ce-4ed6-b9fa-41e79245a710,DISK], DatanodeInfoWithStorage[127.0.0.1:33479,DS-ce6960c6-bdd8-497f-9bce-18c05254afa1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1733723-172.17.0.17-1598134754183:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44965,DS-f944bbd0-a936-4a2f-83fc-c748bd518ab8,DISK], DatanodeInfoWithStorage[127.0.0.1:45208,DS-f5013b06-8435-4c1e-ae3b-ac8df49da931,DISK], DatanodeInfoWithStorage[127.0.0.1:46250,DS-87928d5e-a007-4425-bec8-66e58045a38a,DISK], DatanodeInfoWithStorage[127.0.0.1:37826,DS-49bccf7b-b57a-4930-8512-72c0a052d12d,DISK], DatanodeInfoWithStorage[127.0.0.1:46619,DS-ee2a85f6-7369-45bb-85f0-4c70af60074b,DISK], DatanodeInfoWithStorage[127.0.0.1:39859,DS-8935f37a-4194-4084-b4f4-7114214cf8f9,DISK], DatanodeInfoWithStorage[127.0.0.1:45820,DS-d5a59cb6-a5ee-4377-a56e-fb28d0594fe5,DISK], DatanodeInfoWithStorage[127.0.0.1:46270,DS-e93991b1-b055-44e9-b48c-e0b6cf8c921d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1733723-172.17.0.17-1598134754183:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44965,DS-f944bbd0-a936-4a2f-83fc-c748bd518ab8,DISK], DatanodeInfoWithStorage[127.0.0.1:45208,DS-f5013b06-8435-4c1e-ae3b-ac8df49da931,DISK], DatanodeInfoWithStorage[127.0.0.1:46250,DS-87928d5e-a007-4425-bec8-66e58045a38a,DISK], DatanodeInfoWithStorage[127.0.0.1:37826,DS-49bccf7b-b57a-4930-8512-72c0a052d12d,DISK], DatanodeInfoWithStorage[127.0.0.1:46619,DS-ee2a85f6-7369-45bb-85f0-4c70af60074b,DISK], DatanodeInfoWithStorage[127.0.0.1:39859,DS-8935f37a-4194-4084-b4f4-7114214cf8f9,DISK], DatanodeInfoWithStorage[127.0.0.1:45820,DS-d5a59cb6-a5ee-4377-a56e-fb28d0594fe5,DISK], DatanodeInfoWithStorage[127.0.0.1:46270,DS-e93991b1-b055-44e9-b48c-e0b6cf8c921d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1333137872-172.17.0.17-1598135077081:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43187,DS-f447ffe2-82c5-4176-a76c-91f682607d64,DISK], DatanodeInfoWithStorage[127.0.0.1:43618,DS-13ecf62e-b755-4be0-97be-a29a39b60bc4,DISK], DatanodeInfoWithStorage[127.0.0.1:42049,DS-b3366cc1-3562-4de6-bcf9-c8250594f43d,DISK], DatanodeInfoWithStorage[127.0.0.1:39326,DS-15f9ba79-f85e-4841-a73b-23d72120f87a,DISK], DatanodeInfoWithStorage[127.0.0.1:45174,DS-3a252080-e9f4-4998-acd8-0f1edb9cd4b3,DISK], DatanodeInfoWithStorage[127.0.0.1:39437,DS-c718147d-9def-4ac0-b851-f885cbcfb044,DISK], DatanodeInfoWithStorage[127.0.0.1:37874,DS-3b2b140f-6c97-45b6-bed5-0d92747b5fa5,DISK], DatanodeInfoWithStorage[127.0.0.1:36809,DS-b0366e97-2114-4ff8-8545-e98c862714d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1333137872-172.17.0.17-1598135077081:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43187,DS-f447ffe2-82c5-4176-a76c-91f682607d64,DISK], DatanodeInfoWithStorage[127.0.0.1:43618,DS-13ecf62e-b755-4be0-97be-a29a39b60bc4,DISK], DatanodeInfoWithStorage[127.0.0.1:42049,DS-b3366cc1-3562-4de6-bcf9-c8250594f43d,DISK], DatanodeInfoWithStorage[127.0.0.1:39326,DS-15f9ba79-f85e-4841-a73b-23d72120f87a,DISK], DatanodeInfoWithStorage[127.0.0.1:45174,DS-3a252080-e9f4-4998-acd8-0f1edb9cd4b3,DISK], DatanodeInfoWithStorage[127.0.0.1:39437,DS-c718147d-9def-4ac0-b851-f885cbcfb044,DISK], DatanodeInfoWithStorage[127.0.0.1:37874,DS-3b2b140f-6c97-45b6-bed5-0d92747b5fa5,DISK], DatanodeInfoWithStorage[127.0.0.1:36809,DS-b0366e97-2114-4ff8-8545-e98c862714d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-257751786-172.17.0.17-1598135501028:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38090,DS-9bec07c4-b463-47e8-a21f-b1c1b353a1d7,DISK], DatanodeInfoWithStorage[127.0.0.1:36223,DS-11d2e894-9580-4816-9d4e-14f3fb7037ac,DISK], DatanodeInfoWithStorage[127.0.0.1:38587,DS-99bfe18c-6f32-4aac-9bd2-d50acdc9e5cf,DISK], DatanodeInfoWithStorage[127.0.0.1:35949,DS-734d0ebb-be85-4d7c-aaee-c2f3249a5542,DISK], DatanodeInfoWithStorage[127.0.0.1:36896,DS-56993ecc-e80e-4074-9963-551af0303d53,DISK], DatanodeInfoWithStorage[127.0.0.1:38971,DS-5115cfc2-ae84-4544-ba5a-2b2bd0bbdf71,DISK], DatanodeInfoWithStorage[127.0.0.1:43410,DS-88a6c973-16cc-4545-8446-1a13f0a23cb0,DISK], DatanodeInfoWithStorage[127.0.0.1:36233,DS-49a82481-cb1d-46a7-94c1-89a6b89a27aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-257751786-172.17.0.17-1598135501028:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38090,DS-9bec07c4-b463-47e8-a21f-b1c1b353a1d7,DISK], DatanodeInfoWithStorage[127.0.0.1:36223,DS-11d2e894-9580-4816-9d4e-14f3fb7037ac,DISK], DatanodeInfoWithStorage[127.0.0.1:38587,DS-99bfe18c-6f32-4aac-9bd2-d50acdc9e5cf,DISK], DatanodeInfoWithStorage[127.0.0.1:35949,DS-734d0ebb-be85-4d7c-aaee-c2f3249a5542,DISK], DatanodeInfoWithStorage[127.0.0.1:36896,DS-56993ecc-e80e-4074-9963-551af0303d53,DISK], DatanodeInfoWithStorage[127.0.0.1:38971,DS-5115cfc2-ae84-4544-ba5a-2b2bd0bbdf71,DISK], DatanodeInfoWithStorage[127.0.0.1:43410,DS-88a6c973-16cc-4545-8446-1a13f0a23cb0,DISK], DatanodeInfoWithStorage[127.0.0.1:36233,DS-49a82481-cb1d-46a7-94c1-89a6b89a27aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2146783813-172.17.0.17-1598135542232:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34154,DS-e5011055-146f-4e9a-9947-cb4a682761c6,DISK], DatanodeInfoWithStorage[127.0.0.1:35811,DS-b2f2a406-f8b0-403c-aa14-69e195d9e9a5,DISK], DatanodeInfoWithStorage[127.0.0.1:44651,DS-f8228c48-1400-469c-b48c-d62eeb9c2fff,DISK], DatanodeInfoWithStorage[127.0.0.1:35558,DS-8f8e14e5-236c-4074-b24b-b5d3dddd008b,DISK], DatanodeInfoWithStorage[127.0.0.1:42173,DS-6cfd7998-ddf8-49d3-9b4e-ab0e6d7021ed,DISK], DatanodeInfoWithStorage[127.0.0.1:46002,DS-2e8a0ff7-eec6-430d-81d6-5706048bb7a6,DISK], DatanodeInfoWithStorage[127.0.0.1:45187,DS-7d402d5d-1e10-4ad1-9a32-24d77695094c,DISK], DatanodeInfoWithStorage[127.0.0.1:42725,DS-7970b926-7c37-40c1-844f-bb5805de363c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2146783813-172.17.0.17-1598135542232:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34154,DS-e5011055-146f-4e9a-9947-cb4a682761c6,DISK], DatanodeInfoWithStorage[127.0.0.1:35811,DS-b2f2a406-f8b0-403c-aa14-69e195d9e9a5,DISK], DatanodeInfoWithStorage[127.0.0.1:44651,DS-f8228c48-1400-469c-b48c-d62eeb9c2fff,DISK], DatanodeInfoWithStorage[127.0.0.1:35558,DS-8f8e14e5-236c-4074-b24b-b5d3dddd008b,DISK], DatanodeInfoWithStorage[127.0.0.1:42173,DS-6cfd7998-ddf8-49d3-9b4e-ab0e6d7021ed,DISK], DatanodeInfoWithStorage[127.0.0.1:46002,DS-2e8a0ff7-eec6-430d-81d6-5706048bb7a6,DISK], DatanodeInfoWithStorage[127.0.0.1:45187,DS-7d402d5d-1e10-4ad1-9a32-24d77695094c,DISK], DatanodeInfoWithStorage[127.0.0.1:42725,DS-7970b926-7c37-40c1-844f-bb5805de363c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-613036019-172.17.0.17-1598135774343:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45433,DS-3dd0cce8-f737-45f0-99b8-e2beaec9cd51,DISK], DatanodeInfoWithStorage[127.0.0.1:34955,DS-0605a4d3-6d1a-430b-bcf4-06c494a65cfc,DISK], DatanodeInfoWithStorage[127.0.0.1:35505,DS-fb7980bd-eaad-4ce9-88f2-dea6a658023c,DISK], DatanodeInfoWithStorage[127.0.0.1:40056,DS-8a4d3c1c-7070-44bb-9379-760afeaf2d67,DISK], DatanodeInfoWithStorage[127.0.0.1:41401,DS-04f5e3ef-44d4-4a5f-a86e-b8386612ba55,DISK], DatanodeInfoWithStorage[127.0.0.1:43945,DS-fad88ea3-e5d0-4689-b2a9-809d521b7f2f,DISK], DatanodeInfoWithStorage[127.0.0.1:36747,DS-dcccffb4-ccb4-4afe-b83a-a3b1c6342d2a,DISK], DatanodeInfoWithStorage[127.0.0.1:44902,DS-f5b1103d-7436-4c81-a060-56393cf76efb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-613036019-172.17.0.17-1598135774343:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45433,DS-3dd0cce8-f737-45f0-99b8-e2beaec9cd51,DISK], DatanodeInfoWithStorage[127.0.0.1:34955,DS-0605a4d3-6d1a-430b-bcf4-06c494a65cfc,DISK], DatanodeInfoWithStorage[127.0.0.1:35505,DS-fb7980bd-eaad-4ce9-88f2-dea6a658023c,DISK], DatanodeInfoWithStorage[127.0.0.1:40056,DS-8a4d3c1c-7070-44bb-9379-760afeaf2d67,DISK], DatanodeInfoWithStorage[127.0.0.1:41401,DS-04f5e3ef-44d4-4a5f-a86e-b8386612ba55,DISK], DatanodeInfoWithStorage[127.0.0.1:43945,DS-fad88ea3-e5d0-4689-b2a9-809d521b7f2f,DISK], DatanodeInfoWithStorage[127.0.0.1:36747,DS-dcccffb4-ccb4-4afe-b83a-a3b1c6342d2a,DISK], DatanodeInfoWithStorage[127.0.0.1:44902,DS-f5b1103d-7436-4c81-a060-56393cf76efb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-223788917-172.17.0.17-1598135817436:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44232,DS-9bfac6e8-0e2b-4677-96b8-a77ea2a11f13,DISK], DatanodeInfoWithStorage[127.0.0.1:42267,DS-e5f716e2-9038-4bbe-86f5-700ba29428db,DISK], DatanodeInfoWithStorage[127.0.0.1:33491,DS-cdae8a00-556f-4b6d-9ca1-04e21558b8c9,DISK], DatanodeInfoWithStorage[127.0.0.1:41368,DS-2a8adca6-98e9-4bab-89da-7dfdc34a6208,DISK], DatanodeInfoWithStorage[127.0.0.1:46833,DS-e80f56f8-0711-4b8e-8b91-f0b8e62b99e8,DISK], DatanodeInfoWithStorage[127.0.0.1:41224,DS-f58f728f-287b-479b-b3c0-b67d58dfb9e3,DISK], DatanodeInfoWithStorage[127.0.0.1:39236,DS-48558f65-2477-4d9b-9444-176de3ed519b,DISK], DatanodeInfoWithStorage[127.0.0.1:36957,DS-06c13ea2-b634-4470-ac58-b652df626243,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-223788917-172.17.0.17-1598135817436:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44232,DS-9bfac6e8-0e2b-4677-96b8-a77ea2a11f13,DISK], DatanodeInfoWithStorage[127.0.0.1:42267,DS-e5f716e2-9038-4bbe-86f5-700ba29428db,DISK], DatanodeInfoWithStorage[127.0.0.1:33491,DS-cdae8a00-556f-4b6d-9ca1-04e21558b8c9,DISK], DatanodeInfoWithStorage[127.0.0.1:41368,DS-2a8adca6-98e9-4bab-89da-7dfdc34a6208,DISK], DatanodeInfoWithStorage[127.0.0.1:46833,DS-e80f56f8-0711-4b8e-8b91-f0b8e62b99e8,DISK], DatanodeInfoWithStorage[127.0.0.1:41224,DS-f58f728f-287b-479b-b3c0-b67d58dfb9e3,DISK], DatanodeInfoWithStorage[127.0.0.1:39236,DS-48558f65-2477-4d9b-9444-176de3ed519b,DISK], DatanodeInfoWithStorage[127.0.0.1:36957,DS-06c13ea2-b634-4470-ac58-b652df626243,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-385117569-172.17.0.17-1598136426431:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33396,DS-767d651b-c779-4460-a1ca-ffbb2f51c854,DISK], DatanodeInfoWithStorage[127.0.0.1:43769,DS-9b463194-4f09-47eb-a4da-949790682cf1,DISK], DatanodeInfoWithStorage[127.0.0.1:39377,DS-cb5c474f-e9a7-449c-85e9-eb53e5f1f95a,DISK], DatanodeInfoWithStorage[127.0.0.1:39472,DS-f87cafd9-52c6-4de8-a4c1-b08e7a6ab057,DISK], DatanodeInfoWithStorage[127.0.0.1:46720,DS-13a49ef8-8b7c-41ab-8b49-b3740bfac4a6,DISK], DatanodeInfoWithStorage[127.0.0.1:45656,DS-da7bf596-a6d5-4bcf-9dc4-13fa6cfd60ba,DISK], DatanodeInfoWithStorage[127.0.0.1:46375,DS-ffd05d78-e530-4a4d-a2f5-5e5c2c92dec5,DISK], DatanodeInfoWithStorage[127.0.0.1:40644,DS-0e80544d-bc1c-43b0-b670-07724e7f58d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-385117569-172.17.0.17-1598136426431:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33396,DS-767d651b-c779-4460-a1ca-ffbb2f51c854,DISK], DatanodeInfoWithStorage[127.0.0.1:43769,DS-9b463194-4f09-47eb-a4da-949790682cf1,DISK], DatanodeInfoWithStorage[127.0.0.1:39377,DS-cb5c474f-e9a7-449c-85e9-eb53e5f1f95a,DISK], DatanodeInfoWithStorage[127.0.0.1:39472,DS-f87cafd9-52c6-4de8-a4c1-b08e7a6ab057,DISK], DatanodeInfoWithStorage[127.0.0.1:46720,DS-13a49ef8-8b7c-41ab-8b49-b3740bfac4a6,DISK], DatanodeInfoWithStorage[127.0.0.1:45656,DS-da7bf596-a6d5-4bcf-9dc4-13fa6cfd60ba,DISK], DatanodeInfoWithStorage[127.0.0.1:46375,DS-ffd05d78-e530-4a4d-a2f5-5e5c2c92dec5,DISK], DatanodeInfoWithStorage[127.0.0.1:40644,DS-0e80544d-bc1c-43b0-b670-07724e7f58d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1391509966-172.17.0.17-1598136619818:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40358,DS-1338f74c-b694-4d83-9ea1-5bf40f8eab31,DISK], DatanodeInfoWithStorage[127.0.0.1:35593,DS-f201e910-5bd7-4b78-b684-11b39f7e3e4a,DISK], DatanodeInfoWithStorage[127.0.0.1:34396,DS-facf19ca-38c9-4aa4-a0b3-36e254eb6ee1,DISK], DatanodeInfoWithStorage[127.0.0.1:39730,DS-6226e6f4-61c2-4482-84bb-fb7f01e6ab11,DISK], DatanodeInfoWithStorage[127.0.0.1:45457,DS-3137f0e8-7cba-4db0-bb07-ca0911428b8f,DISK], DatanodeInfoWithStorage[127.0.0.1:43672,DS-8f8569af-40d7-42c7-ab9a-c8ccb1d73cc2,DISK], DatanodeInfoWithStorage[127.0.0.1:34243,DS-c97878c3-5a62-42f4-bfac-c00c578b2daa,DISK], DatanodeInfoWithStorage[127.0.0.1:43284,DS-65694b6b-2073-49c1-a72d-023f0014ea72,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1391509966-172.17.0.17-1598136619818:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40358,DS-1338f74c-b694-4d83-9ea1-5bf40f8eab31,DISK], DatanodeInfoWithStorage[127.0.0.1:35593,DS-f201e910-5bd7-4b78-b684-11b39f7e3e4a,DISK], DatanodeInfoWithStorage[127.0.0.1:34396,DS-facf19ca-38c9-4aa4-a0b3-36e254eb6ee1,DISK], DatanodeInfoWithStorage[127.0.0.1:39730,DS-6226e6f4-61c2-4482-84bb-fb7f01e6ab11,DISK], DatanodeInfoWithStorage[127.0.0.1:45457,DS-3137f0e8-7cba-4db0-bb07-ca0911428b8f,DISK], DatanodeInfoWithStorage[127.0.0.1:43672,DS-8f8569af-40d7-42c7-ab9a-c8ccb1d73cc2,DISK], DatanodeInfoWithStorage[127.0.0.1:34243,DS-c97878c3-5a62-42f4-bfac-c00c578b2daa,DISK], DatanodeInfoWithStorage[127.0.0.1:43284,DS-65694b6b-2073-49c1-a72d-023f0014ea72,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2063552384-172.17.0.17-1598136752855:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34296,DS-c559cc87-fadc-4137-a8f2-524f434cc128,DISK], DatanodeInfoWithStorage[127.0.0.1:38203,DS-289bd0b2-a73d-4e56-ad97-350478b35501,DISK], DatanodeInfoWithStorage[127.0.0.1:41785,DS-7869b0c5-c424-4d56-bdf7-c3015803a6d4,DISK], DatanodeInfoWithStorage[127.0.0.1:45287,DS-8ea74d3b-a5ca-4f97-990f-1a71506f235b,DISK], DatanodeInfoWithStorage[127.0.0.1:39444,DS-71fa98ff-4c55-431e-89f8-d2402167f564,DISK], DatanodeInfoWithStorage[127.0.0.1:38012,DS-348b6fe3-34b2-40cd-bd9d-af36874005af,DISK], DatanodeInfoWithStorage[127.0.0.1:45676,DS-bf4d1b2c-dd74-4220-a8e0-db6878ec6955,DISK], DatanodeInfoWithStorage[127.0.0.1:38880,DS-fe82161c-8474-492a-bc3e-d76961c96c08,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2063552384-172.17.0.17-1598136752855:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34296,DS-c559cc87-fadc-4137-a8f2-524f434cc128,DISK], DatanodeInfoWithStorage[127.0.0.1:38203,DS-289bd0b2-a73d-4e56-ad97-350478b35501,DISK], DatanodeInfoWithStorage[127.0.0.1:41785,DS-7869b0c5-c424-4d56-bdf7-c3015803a6d4,DISK], DatanodeInfoWithStorage[127.0.0.1:45287,DS-8ea74d3b-a5ca-4f97-990f-1a71506f235b,DISK], DatanodeInfoWithStorage[127.0.0.1:39444,DS-71fa98ff-4c55-431e-89f8-d2402167f564,DISK], DatanodeInfoWithStorage[127.0.0.1:38012,DS-348b6fe3-34b2-40cd-bd9d-af36874005af,DISK], DatanodeInfoWithStorage[127.0.0.1:45676,DS-bf4d1b2c-dd74-4220-a8e0-db6878ec6955,DISK], DatanodeInfoWithStorage[127.0.0.1:38880,DS-fe82161c-8474-492a-bc3e-d76961c96c08,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-325136574-172.17.0.17-1598136976723:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34937,DS-9bab38d6-6f00-40cd-9afc-b08d9f2b1737,DISK], DatanodeInfoWithStorage[127.0.0.1:41274,DS-0ca9f7e6-70c1-440a-8b02-6b47b579cc70,DISK], DatanodeInfoWithStorage[127.0.0.1:42603,DS-849336a0-43e0-486b-875d-73526b755dee,DISK], DatanodeInfoWithStorage[127.0.0.1:40786,DS-fac74747-e1f8-4864-a8a2-9406745b9a3e,DISK], DatanodeInfoWithStorage[127.0.0.1:44910,DS-8b02bf34-83f6-4703-b2ba-27665170d127,DISK], DatanodeInfoWithStorage[127.0.0.1:39746,DS-5ff807ff-abfb-488a-b2ac-80955828cf97,DISK], DatanodeInfoWithStorage[127.0.0.1:46842,DS-f732a213-d630-4588-8bc9-72e22fc62981,DISK], DatanodeInfoWithStorage[127.0.0.1:44783,DS-ea7d5ea9-4966-4d5a-b85c-af16d4b95521,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-325136574-172.17.0.17-1598136976723:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34937,DS-9bab38d6-6f00-40cd-9afc-b08d9f2b1737,DISK], DatanodeInfoWithStorage[127.0.0.1:41274,DS-0ca9f7e6-70c1-440a-8b02-6b47b579cc70,DISK], DatanodeInfoWithStorage[127.0.0.1:42603,DS-849336a0-43e0-486b-875d-73526b755dee,DISK], DatanodeInfoWithStorage[127.0.0.1:40786,DS-fac74747-e1f8-4864-a8a2-9406745b9a3e,DISK], DatanodeInfoWithStorage[127.0.0.1:44910,DS-8b02bf34-83f6-4703-b2ba-27665170d127,DISK], DatanodeInfoWithStorage[127.0.0.1:39746,DS-5ff807ff-abfb-488a-b2ac-80955828cf97,DISK], DatanodeInfoWithStorage[127.0.0.1:46842,DS-f732a213-d630-4588-8bc9-72e22fc62981,DISK], DatanodeInfoWithStorage[127.0.0.1:44783,DS-ea7d5ea9-4966-4d5a-b85c-af16d4b95521,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1407242711-172.17.0.17-1598137446327:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42836,DS-51b86826-f346-436b-a493-51b2ebb31bf5,DISK], DatanodeInfoWithStorage[127.0.0.1:44579,DS-cad7671e-fe39-4d76-9c3a-3b4765b93653,DISK], DatanodeInfoWithStorage[127.0.0.1:35882,DS-2c552c72-ed25-4313-8202-4bc8ddc71542,DISK], DatanodeInfoWithStorage[127.0.0.1:33337,DS-53a51de4-ce1c-44c9-b9b6-a62423eef471,DISK], DatanodeInfoWithStorage[127.0.0.1:43497,DS-279bd671-36a0-482d-9a1f-ae5d333c3d20,DISK], DatanodeInfoWithStorage[127.0.0.1:33254,DS-795fb134-c532-42f4-b24a-3acb97d908f8,DISK], DatanodeInfoWithStorage[127.0.0.1:40482,DS-98e3df56-63b0-4c21-aa41-00841debc947,DISK], DatanodeInfoWithStorage[127.0.0.1:45456,DS-cd53fd8d-7ad5-4ffe-9187-e6b597dc695f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1407242711-172.17.0.17-1598137446327:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42836,DS-51b86826-f346-436b-a493-51b2ebb31bf5,DISK], DatanodeInfoWithStorage[127.0.0.1:44579,DS-cad7671e-fe39-4d76-9c3a-3b4765b93653,DISK], DatanodeInfoWithStorage[127.0.0.1:35882,DS-2c552c72-ed25-4313-8202-4bc8ddc71542,DISK], DatanodeInfoWithStorage[127.0.0.1:33337,DS-53a51de4-ce1c-44c9-b9b6-a62423eef471,DISK], DatanodeInfoWithStorage[127.0.0.1:43497,DS-279bd671-36a0-482d-9a1f-ae5d333c3d20,DISK], DatanodeInfoWithStorage[127.0.0.1:33254,DS-795fb134-c532-42f4-b24a-3acb97d908f8,DISK], DatanodeInfoWithStorage[127.0.0.1:40482,DS-98e3df56-63b0-4c21-aa41-00841debc947,DISK], DatanodeInfoWithStorage[127.0.0.1:45456,DS-cd53fd8d-7ad5-4ffe-9187-e6b597dc695f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1626097180-172.17.0.17-1598137709020:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39155,DS-ea72d87f-9245-4ff4-b316-a52da2953dd5,DISK], DatanodeInfoWithStorage[127.0.0.1:34020,DS-3eb067fa-704b-4097-952d-b71ed5de82bf,DISK], DatanodeInfoWithStorage[127.0.0.1:41434,DS-7de94766-a808-4ce2-a298-69cc61ea04ab,DISK], DatanodeInfoWithStorage[127.0.0.1:43071,DS-d85bf77e-ffea-489b-bcb3-122a099ef3fe,DISK], DatanodeInfoWithStorage[127.0.0.1:43568,DS-f42d7cec-eaf7-4a24-a3c9-66ded002ce8e,DISK], DatanodeInfoWithStorage[127.0.0.1:40680,DS-61df10fa-42e7-4d1d-bfd5-64d1792dd89e,DISK], DatanodeInfoWithStorage[127.0.0.1:32905,DS-c627cd77-394a-4746-854f-e258393e7f3c,DISK], DatanodeInfoWithStorage[127.0.0.1:38297,DS-0c6b0304-a3fd-4da5-a5ae-895f2531b131,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1626097180-172.17.0.17-1598137709020:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39155,DS-ea72d87f-9245-4ff4-b316-a52da2953dd5,DISK], DatanodeInfoWithStorage[127.0.0.1:34020,DS-3eb067fa-704b-4097-952d-b71ed5de82bf,DISK], DatanodeInfoWithStorage[127.0.0.1:41434,DS-7de94766-a808-4ce2-a298-69cc61ea04ab,DISK], DatanodeInfoWithStorage[127.0.0.1:43071,DS-d85bf77e-ffea-489b-bcb3-122a099ef3fe,DISK], DatanodeInfoWithStorage[127.0.0.1:43568,DS-f42d7cec-eaf7-4a24-a3c9-66ded002ce8e,DISK], DatanodeInfoWithStorage[127.0.0.1:40680,DS-61df10fa-42e7-4d1d-bfd5-64d1792dd89e,DISK], DatanodeInfoWithStorage[127.0.0.1:32905,DS-c627cd77-394a-4746-854f-e258393e7f3c,DISK], DatanodeInfoWithStorage[127.0.0.1:38297,DS-0c6b0304-a3fd-4da5-a5ae-895f2531b131,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1166277346-172.17.0.17-1598137917752:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43092,DS-ae677fa8-028a-4b16-8ad3-377b0941a322,DISK], DatanodeInfoWithStorage[127.0.0.1:41188,DS-28b68857-301b-4fb0-b39f-def94a3496e8,DISK], DatanodeInfoWithStorage[127.0.0.1:40752,DS-b6a950f9-9a81-413f-bb2c-e04de283f249,DISK], DatanodeInfoWithStorage[127.0.0.1:43563,DS-1c3bbd3e-eae6-4254-8943-3158d7b03763,DISK], DatanodeInfoWithStorage[127.0.0.1:43916,DS-37b95468-82c6-46c4-acfd-6d17ce5d78ae,DISK], DatanodeInfoWithStorage[127.0.0.1:33153,DS-e7e0c910-6137-4e6c-b00c-98b4e0c9fb19,DISK], DatanodeInfoWithStorage[127.0.0.1:37485,DS-69cd7f42-ffe1-4f83-a3ad-3c9772ea281f,DISK], DatanodeInfoWithStorage[127.0.0.1:37469,DS-eca9857d-d60c-4361-ace7-836ccbdffa7b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1166277346-172.17.0.17-1598137917752:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43092,DS-ae677fa8-028a-4b16-8ad3-377b0941a322,DISK], DatanodeInfoWithStorage[127.0.0.1:41188,DS-28b68857-301b-4fb0-b39f-def94a3496e8,DISK], DatanodeInfoWithStorage[127.0.0.1:40752,DS-b6a950f9-9a81-413f-bb2c-e04de283f249,DISK], DatanodeInfoWithStorage[127.0.0.1:43563,DS-1c3bbd3e-eae6-4254-8943-3158d7b03763,DISK], DatanodeInfoWithStorage[127.0.0.1:43916,DS-37b95468-82c6-46c4-acfd-6d17ce5d78ae,DISK], DatanodeInfoWithStorage[127.0.0.1:33153,DS-e7e0c910-6137-4e6c-b00c-98b4e0c9fb19,DISK], DatanodeInfoWithStorage[127.0.0.1:37485,DS-69cd7f42-ffe1-4f83-a3ad-3c9772ea281f,DISK], DatanodeInfoWithStorage[127.0.0.1:37469,DS-eca9857d-d60c-4361-ace7-836ccbdffa7b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1180345073-172.17.0.17-1598138076919:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39152,DS-e5a79ea5-c971-4492-ba64-dc177c7f510e,DISK], DatanodeInfoWithStorage[127.0.0.1:46760,DS-cc668459-2dab-4c7c-a22d-d1acbb95afba,DISK], DatanodeInfoWithStorage[127.0.0.1:36987,DS-b992cb1c-41a9-4921-861d-435e5ae435e1,DISK], DatanodeInfoWithStorage[127.0.0.1:45022,DS-bb965b90-93a1-4fc8-b7e6-75bde6173b68,DISK], DatanodeInfoWithStorage[127.0.0.1:37731,DS-092eeb1d-b928-44b0-a5a0-e6bb9367f3c7,DISK], DatanodeInfoWithStorage[127.0.0.1:38034,DS-a7c9bab7-f163-4a3e-8274-46fae0462beb,DISK], DatanodeInfoWithStorage[127.0.0.1:46603,DS-0b36c9c9-d337-4bb8-b884-93b2395d16fc,DISK], DatanodeInfoWithStorage[127.0.0.1:42000,DS-ad83818b-1262-4cda-bd04-dc134b7314d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1180345073-172.17.0.17-1598138076919:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39152,DS-e5a79ea5-c971-4492-ba64-dc177c7f510e,DISK], DatanodeInfoWithStorage[127.0.0.1:46760,DS-cc668459-2dab-4c7c-a22d-d1acbb95afba,DISK], DatanodeInfoWithStorage[127.0.0.1:36987,DS-b992cb1c-41a9-4921-861d-435e5ae435e1,DISK], DatanodeInfoWithStorage[127.0.0.1:45022,DS-bb965b90-93a1-4fc8-b7e6-75bde6173b68,DISK], DatanodeInfoWithStorage[127.0.0.1:37731,DS-092eeb1d-b928-44b0-a5a0-e6bb9367f3c7,DISK], DatanodeInfoWithStorage[127.0.0.1:38034,DS-a7c9bab7-f163-4a3e-8274-46fae0462beb,DISK], DatanodeInfoWithStorage[127.0.0.1:46603,DS-0b36c9c9-d337-4bb8-b884-93b2395d16fc,DISK], DatanodeInfoWithStorage[127.0.0.1:42000,DS-ad83818b-1262-4cda-bd04-dc134b7314d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1991299276-172.17.0.17-1598138344121:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43914,DS-314c74cf-a1e2-47e6-995f-a1b5394d38db,DISK], DatanodeInfoWithStorage[127.0.0.1:44066,DS-5f5b6019-1524-4b96-9763-9e34b36b7e39,DISK], DatanodeInfoWithStorage[127.0.0.1:37038,DS-4fe493b7-b965-47f5-b363-f012e4408cce,DISK], DatanodeInfoWithStorage[127.0.0.1:36795,DS-27805664-5c95-4ffd-a86e-8e85fe6caa0a,DISK], DatanodeInfoWithStorage[127.0.0.1:43654,DS-ffffe368-7207-49db-868f-0a3237b2de6a,DISK], DatanodeInfoWithStorage[127.0.0.1:35535,DS-478ce097-94d8-48e5-ad95-7e73a0ad6dc3,DISK], DatanodeInfoWithStorage[127.0.0.1:40743,DS-c704da46-aa8e-4785-8ff2-e876ed569abe,DISK], DatanodeInfoWithStorage[127.0.0.1:46340,DS-297ad6d3-20c1-496a-87fc-629e07eb3edb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1991299276-172.17.0.17-1598138344121:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43914,DS-314c74cf-a1e2-47e6-995f-a1b5394d38db,DISK], DatanodeInfoWithStorage[127.0.0.1:44066,DS-5f5b6019-1524-4b96-9763-9e34b36b7e39,DISK], DatanodeInfoWithStorage[127.0.0.1:37038,DS-4fe493b7-b965-47f5-b363-f012e4408cce,DISK], DatanodeInfoWithStorage[127.0.0.1:36795,DS-27805664-5c95-4ffd-a86e-8e85fe6caa0a,DISK], DatanodeInfoWithStorage[127.0.0.1:43654,DS-ffffe368-7207-49db-868f-0a3237b2de6a,DISK], DatanodeInfoWithStorage[127.0.0.1:35535,DS-478ce097-94d8-48e5-ad95-7e73a0ad6dc3,DISK], DatanodeInfoWithStorage[127.0.0.1:40743,DS-c704da46-aa8e-4785-8ff2-e876ed569abe,DISK], DatanodeInfoWithStorage[127.0.0.1:46340,DS-297ad6d3-20c1-496a-87fc-629e07eb3edb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-176699803-172.17.0.17-1598138510471:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33385,DS-9233ede4-dc53-489c-b70b-061ec9dc60a9,DISK], DatanodeInfoWithStorage[127.0.0.1:35873,DS-267a3d76-6828-4a59-a8a2-1d14221d9b4b,DISK], DatanodeInfoWithStorage[127.0.0.1:35269,DS-ce5cdb45-6856-4dd8-a7e3-84e8e7ed7839,DISK], DatanodeInfoWithStorage[127.0.0.1:42281,DS-de5c7aed-650c-4c0c-b46d-8237a6f61a3f,DISK], DatanodeInfoWithStorage[127.0.0.1:40956,DS-800f30a0-535f-45e4-84aa-71aeef6a0396,DISK], DatanodeInfoWithStorage[127.0.0.1:34046,DS-9073c5db-a3e2-4092-b8dd-f1b8d8fd5ed6,DISK], DatanodeInfoWithStorage[127.0.0.1:41640,DS-37b11e97-f93e-4f0a-820e-a51e33bfbc7e,DISK], DatanodeInfoWithStorage[127.0.0.1:46076,DS-e1ccbdf0-9295-481b-94ce-7fb2e719d396,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-176699803-172.17.0.17-1598138510471:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33385,DS-9233ede4-dc53-489c-b70b-061ec9dc60a9,DISK], DatanodeInfoWithStorage[127.0.0.1:35873,DS-267a3d76-6828-4a59-a8a2-1d14221d9b4b,DISK], DatanodeInfoWithStorage[127.0.0.1:35269,DS-ce5cdb45-6856-4dd8-a7e3-84e8e7ed7839,DISK], DatanodeInfoWithStorage[127.0.0.1:42281,DS-de5c7aed-650c-4c0c-b46d-8237a6f61a3f,DISK], DatanodeInfoWithStorage[127.0.0.1:40956,DS-800f30a0-535f-45e4-84aa-71aeef6a0396,DISK], DatanodeInfoWithStorage[127.0.0.1:34046,DS-9073c5db-a3e2-4092-b8dd-f1b8d8fd5ed6,DISK], DatanodeInfoWithStorage[127.0.0.1:41640,DS-37b11e97-f93e-4f0a-820e-a51e33bfbc7e,DISK], DatanodeInfoWithStorage[127.0.0.1:46076,DS-e1ccbdf0-9295-481b-94ce-7fb2e719d396,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1983558418-172.17.0.17-1598138638329:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42995,DS-f926fca7-3482-4706-9296-fcabee5216b3,DISK], DatanodeInfoWithStorage[127.0.0.1:40431,DS-a2a2dca4-6a09-4fba-8443-0de1e6ac85b9,DISK], DatanodeInfoWithStorage[127.0.0.1:39069,DS-4575b1a5-66e5-4b05-b49e-0ab1c5ac5dfe,DISK], DatanodeInfoWithStorage[127.0.0.1:41119,DS-a900b75a-74f0-499a-b242-1e146c235c6c,DISK], DatanodeInfoWithStorage[127.0.0.1:38168,DS-af1d0228-4d93-4172-b0aa-966d5205980b,DISK], DatanodeInfoWithStorage[127.0.0.1:45390,DS-afd416cf-8c54-4a79-8b07-9eb51ea351f3,DISK], DatanodeInfoWithStorage[127.0.0.1:43766,DS-186ed583-9f87-4d64-bab6-88e99597a360,DISK], DatanodeInfoWithStorage[127.0.0.1:39878,DS-b7c1b65c-5759-40ae-b573-9a1e801a5a51,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1983558418-172.17.0.17-1598138638329:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42995,DS-f926fca7-3482-4706-9296-fcabee5216b3,DISK], DatanodeInfoWithStorage[127.0.0.1:40431,DS-a2a2dca4-6a09-4fba-8443-0de1e6ac85b9,DISK], DatanodeInfoWithStorage[127.0.0.1:39069,DS-4575b1a5-66e5-4b05-b49e-0ab1c5ac5dfe,DISK], DatanodeInfoWithStorage[127.0.0.1:41119,DS-a900b75a-74f0-499a-b242-1e146c235c6c,DISK], DatanodeInfoWithStorage[127.0.0.1:38168,DS-af1d0228-4d93-4172-b0aa-966d5205980b,DISK], DatanodeInfoWithStorage[127.0.0.1:45390,DS-afd416cf-8c54-4a79-8b07-9eb51ea351f3,DISK], DatanodeInfoWithStorage[127.0.0.1:43766,DS-186ed583-9f87-4d64-bab6-88e99597a360,DISK], DatanodeInfoWithStorage[127.0.0.1:39878,DS-b7c1b65c-5759-40ae-b573-9a1e801a5a51,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 10 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 6691
