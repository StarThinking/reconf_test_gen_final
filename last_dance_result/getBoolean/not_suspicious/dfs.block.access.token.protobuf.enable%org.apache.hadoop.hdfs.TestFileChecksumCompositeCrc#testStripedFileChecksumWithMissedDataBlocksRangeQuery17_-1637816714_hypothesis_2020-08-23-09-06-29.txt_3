reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1169652517-172.17.0.17-1598173748784:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35645,DS-a4860436-a6cf-4865-bfae-cd5b898e2483,DISK], DatanodeInfoWithStorage[127.0.0.1:35816,DS-596d1d96-cd09-4357-8eee-401afb47e3be,DISK], DatanodeInfoWithStorage[127.0.0.1:41005,DS-37a1ada9-f98a-4a29-a8d6-03849c3286b3,DISK], DatanodeInfoWithStorage[127.0.0.1:37307,DS-813b1bec-ee13-4417-b009-86077d30e338,DISK], DatanodeInfoWithStorage[127.0.0.1:37961,DS-ce571059-fd8d-4e03-a604-850fcc130750,DISK], DatanodeInfoWithStorage[127.0.0.1:38362,DS-bd171030-66a9-4db9-b113-fce74377b34a,DISK], DatanodeInfoWithStorage[127.0.0.1:42420,DS-df06c255-cda9-4fde-b5aa-3d58f2bab92b,DISK], DatanodeInfoWithStorage[127.0.0.1:39704,DS-73ae4610-76aa-46bc-9d20-6849a5fdbed3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1169652517-172.17.0.17-1598173748784:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35645,DS-a4860436-a6cf-4865-bfae-cd5b898e2483,DISK], DatanodeInfoWithStorage[127.0.0.1:35816,DS-596d1d96-cd09-4357-8eee-401afb47e3be,DISK], DatanodeInfoWithStorage[127.0.0.1:41005,DS-37a1ada9-f98a-4a29-a8d6-03849c3286b3,DISK], DatanodeInfoWithStorage[127.0.0.1:37307,DS-813b1bec-ee13-4417-b009-86077d30e338,DISK], DatanodeInfoWithStorage[127.0.0.1:37961,DS-ce571059-fd8d-4e03-a604-850fcc130750,DISK], DatanodeInfoWithStorage[127.0.0.1:38362,DS-bd171030-66a9-4db9-b113-fce74377b34a,DISK], DatanodeInfoWithStorage[127.0.0.1:42420,DS-df06c255-cda9-4fde-b5aa-3d58f2bab92b,DISK], DatanodeInfoWithStorage[127.0.0.1:39704,DS-73ae4610-76aa-46bc-9d20-6849a5fdbed3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-718312648-172.17.0.17-1598174011910:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45774,DS-d5500a48-3bd3-44d6-a4f2-ac25e96589f3,DISK], DatanodeInfoWithStorage[127.0.0.1:36463,DS-65d45017-c3ca-46be-aed6-6d1e09285ff1,DISK], DatanodeInfoWithStorage[127.0.0.1:45064,DS-a448e718-3034-4a33-94d2-f3385c2ae303,DISK], DatanodeInfoWithStorage[127.0.0.1:43414,DS-f7025f83-d217-4ff2-bd45-dbe83b3c11d9,DISK], DatanodeInfoWithStorage[127.0.0.1:44757,DS-b4cfb169-c350-4cca-ba54-eb2d57c9d572,DISK], DatanodeInfoWithStorage[127.0.0.1:36382,DS-5b6906ce-622f-4a37-8c9b-bbf8363c4e29,DISK], DatanodeInfoWithStorage[127.0.0.1:44204,DS-e33c0998-33e3-4ce6-9a69-50bbe9869542,DISK], DatanodeInfoWithStorage[127.0.0.1:45253,DS-7230ab28-f551-460a-9447-0b39f8c8381f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-718312648-172.17.0.17-1598174011910:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45774,DS-d5500a48-3bd3-44d6-a4f2-ac25e96589f3,DISK], DatanodeInfoWithStorage[127.0.0.1:36463,DS-65d45017-c3ca-46be-aed6-6d1e09285ff1,DISK], DatanodeInfoWithStorage[127.0.0.1:45064,DS-a448e718-3034-4a33-94d2-f3385c2ae303,DISK], DatanodeInfoWithStorage[127.0.0.1:43414,DS-f7025f83-d217-4ff2-bd45-dbe83b3c11d9,DISK], DatanodeInfoWithStorage[127.0.0.1:44757,DS-b4cfb169-c350-4cca-ba54-eb2d57c9d572,DISK], DatanodeInfoWithStorage[127.0.0.1:36382,DS-5b6906ce-622f-4a37-8c9b-bbf8363c4e29,DISK], DatanodeInfoWithStorage[127.0.0.1:44204,DS-e33c0998-33e3-4ce6-9a69-50bbe9869542,DISK], DatanodeInfoWithStorage[127.0.0.1:45253,DS-7230ab28-f551-460a-9447-0b39f8c8381f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-388207492-172.17.0.17-1598174071749:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40313,DS-36399502-3d53-4fb6-b733-568e9aecc33f,DISK], DatanodeInfoWithStorage[127.0.0.1:45002,DS-5d608166-4b19-400f-bd39-692fa82c26e6,DISK], DatanodeInfoWithStorage[127.0.0.1:40852,DS-243bd9bb-1055-4dcd-94d6-61fe4f7ffca8,DISK], DatanodeInfoWithStorage[127.0.0.1:34917,DS-66217f6c-d0fd-4389-9a00-2a39208f332b,DISK], DatanodeInfoWithStorage[127.0.0.1:40492,DS-0dc1f81d-4ee7-4815-b4a3-8a8c3637197f,DISK], DatanodeInfoWithStorage[127.0.0.1:33176,DS-ddcb9bcf-583b-4660-8d87-b0eefbc0b7bb,DISK], DatanodeInfoWithStorage[127.0.0.1:34206,DS-d170a871-4dac-4817-8690-0b668014bd36,DISK], DatanodeInfoWithStorage[127.0.0.1:33340,DS-19c386a6-4947-41f9-9eda-74ee4c6779d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-388207492-172.17.0.17-1598174071749:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40313,DS-36399502-3d53-4fb6-b733-568e9aecc33f,DISK], DatanodeInfoWithStorage[127.0.0.1:45002,DS-5d608166-4b19-400f-bd39-692fa82c26e6,DISK], DatanodeInfoWithStorage[127.0.0.1:40852,DS-243bd9bb-1055-4dcd-94d6-61fe4f7ffca8,DISK], DatanodeInfoWithStorage[127.0.0.1:34917,DS-66217f6c-d0fd-4389-9a00-2a39208f332b,DISK], DatanodeInfoWithStorage[127.0.0.1:40492,DS-0dc1f81d-4ee7-4815-b4a3-8a8c3637197f,DISK], DatanodeInfoWithStorage[127.0.0.1:33176,DS-ddcb9bcf-583b-4660-8d87-b0eefbc0b7bb,DISK], DatanodeInfoWithStorage[127.0.0.1:34206,DS-d170a871-4dac-4817-8690-0b668014bd36,DISK], DatanodeInfoWithStorage[127.0.0.1:33340,DS-19c386a6-4947-41f9-9eda-74ee4c6779d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1073532618-172.17.0.17-1598174282188:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34058,DS-2d448eee-d21e-4b73-9947-87b847746ee6,DISK], DatanodeInfoWithStorage[127.0.0.1:42174,DS-410b4ec8-2105-497c-b8b4-b1585d944381,DISK], DatanodeInfoWithStorage[127.0.0.1:39661,DS-4ff06b11-3686-459f-8bc5-1c457be218bc,DISK], DatanodeInfoWithStorage[127.0.0.1:40657,DS-173cb2ea-8c34-4cc4-82f0-d93a072ab75a,DISK], DatanodeInfoWithStorage[127.0.0.1:41031,DS-2a40f3bb-d172-4e77-8a53-51a497e6022d,DISK], DatanodeInfoWithStorage[127.0.0.1:41056,DS-a55fd60a-a7c9-4422-9eb0-4106c60522d6,DISK], DatanodeInfoWithStorage[127.0.0.1:44902,DS-3d5f9f02-1a7e-49d0-8a4c-06e3df7e82f7,DISK], DatanodeInfoWithStorage[127.0.0.1:45553,DS-c1ea83ff-c563-4765-a399-045e4a5a63a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1073532618-172.17.0.17-1598174282188:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34058,DS-2d448eee-d21e-4b73-9947-87b847746ee6,DISK], DatanodeInfoWithStorage[127.0.0.1:42174,DS-410b4ec8-2105-497c-b8b4-b1585d944381,DISK], DatanodeInfoWithStorage[127.0.0.1:39661,DS-4ff06b11-3686-459f-8bc5-1c457be218bc,DISK], DatanodeInfoWithStorage[127.0.0.1:40657,DS-173cb2ea-8c34-4cc4-82f0-d93a072ab75a,DISK], DatanodeInfoWithStorage[127.0.0.1:41031,DS-2a40f3bb-d172-4e77-8a53-51a497e6022d,DISK], DatanodeInfoWithStorage[127.0.0.1:41056,DS-a55fd60a-a7c9-4422-9eb0-4106c60522d6,DISK], DatanodeInfoWithStorage[127.0.0.1:44902,DS-3d5f9f02-1a7e-49d0-8a4c-06e3df7e82f7,DISK], DatanodeInfoWithStorage[127.0.0.1:45553,DS-c1ea83ff-c563-4765-a399-045e4a5a63a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2127905169-172.17.0.17-1598174311166:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41011,DS-03a55704-bba8-464c-af69-beee0acad282,DISK], DatanodeInfoWithStorage[127.0.0.1:40404,DS-de83708b-8e2a-4f55-a011-4a45b1e07eb4,DISK], DatanodeInfoWithStorage[127.0.0.1:36290,DS-1cbcd2e5-0251-41e1-9cea-f5bbe6aeeb3a,DISK], DatanodeInfoWithStorage[127.0.0.1:39718,DS-8b86c0e0-fc58-4330-9bf3-59b96cbea246,DISK], DatanodeInfoWithStorage[127.0.0.1:33884,DS-2a58a115-4acd-42c8-8357-7b7e1b8c38b4,DISK], DatanodeInfoWithStorage[127.0.0.1:36538,DS-dcadaf50-3daa-46dc-9281-b1aa4259b127,DISK], DatanodeInfoWithStorage[127.0.0.1:42453,DS-91a45cba-b2cc-48d7-a0d7-5e7018966ffc,DISK], DatanodeInfoWithStorage[127.0.0.1:34269,DS-0f9dffac-f831-4944-afc0-15be304c30d9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2127905169-172.17.0.17-1598174311166:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41011,DS-03a55704-bba8-464c-af69-beee0acad282,DISK], DatanodeInfoWithStorage[127.0.0.1:40404,DS-de83708b-8e2a-4f55-a011-4a45b1e07eb4,DISK], DatanodeInfoWithStorage[127.0.0.1:36290,DS-1cbcd2e5-0251-41e1-9cea-f5bbe6aeeb3a,DISK], DatanodeInfoWithStorage[127.0.0.1:39718,DS-8b86c0e0-fc58-4330-9bf3-59b96cbea246,DISK], DatanodeInfoWithStorage[127.0.0.1:33884,DS-2a58a115-4acd-42c8-8357-7b7e1b8c38b4,DISK], DatanodeInfoWithStorage[127.0.0.1:36538,DS-dcadaf50-3daa-46dc-9281-b1aa4259b127,DISK], DatanodeInfoWithStorage[127.0.0.1:42453,DS-91a45cba-b2cc-48d7-a0d7-5e7018966ffc,DISK], DatanodeInfoWithStorage[127.0.0.1:34269,DS-0f9dffac-f831-4944-afc0-15be304c30d9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-373347631-172.17.0.17-1598174372528:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45756,DS-df4b6686-8271-4b6d-9852-2c8206351c13,DISK], DatanodeInfoWithStorage[127.0.0.1:37343,DS-f7547288-00c5-415c-83fe-aab14163bd5a,DISK], DatanodeInfoWithStorage[127.0.0.1:40518,DS-354a0b99-0ae5-441b-a367-76b5777f6625,DISK], DatanodeInfoWithStorage[127.0.0.1:34703,DS-53cf6ae2-e056-45e1-a1fa-6d637a0cd4d6,DISK], DatanodeInfoWithStorage[127.0.0.1:40153,DS-3d27cf50-72c1-4551-b41e-b5817b951cb2,DISK], DatanodeInfoWithStorage[127.0.0.1:42143,DS-609cf801-747e-4ba1-a464-5b9596026ef6,DISK], DatanodeInfoWithStorage[127.0.0.1:37698,DS-e22f5827-4bd6-46e9-a56e-7cbb37813844,DISK], DatanodeInfoWithStorage[127.0.0.1:40459,DS-ab7045ba-9b9b-400f-970a-b380b73c239a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-373347631-172.17.0.17-1598174372528:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45756,DS-df4b6686-8271-4b6d-9852-2c8206351c13,DISK], DatanodeInfoWithStorage[127.0.0.1:37343,DS-f7547288-00c5-415c-83fe-aab14163bd5a,DISK], DatanodeInfoWithStorage[127.0.0.1:40518,DS-354a0b99-0ae5-441b-a367-76b5777f6625,DISK], DatanodeInfoWithStorage[127.0.0.1:34703,DS-53cf6ae2-e056-45e1-a1fa-6d637a0cd4d6,DISK], DatanodeInfoWithStorage[127.0.0.1:40153,DS-3d27cf50-72c1-4551-b41e-b5817b951cb2,DISK], DatanodeInfoWithStorage[127.0.0.1:42143,DS-609cf801-747e-4ba1-a464-5b9596026ef6,DISK], DatanodeInfoWithStorage[127.0.0.1:37698,DS-e22f5827-4bd6-46e9-a56e-7cbb37813844,DISK], DatanodeInfoWithStorage[127.0.0.1:40459,DS-ab7045ba-9b9b-400f-970a-b380b73c239a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1375641159-172.17.0.17-1598174680338:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43883,DS-d7a26d83-7661-4949-9052-fc23caa8a0f2,DISK], DatanodeInfoWithStorage[127.0.0.1:36793,DS-afe2a9d7-6c50-4411-963c-8a5191ad2c50,DISK], DatanodeInfoWithStorage[127.0.0.1:46073,DS-d586f430-d52e-4cfb-b141-88449d616241,DISK], DatanodeInfoWithStorage[127.0.0.1:37292,DS-ca76fbcc-983f-4e77-8deb-3e213b71ed68,DISK], DatanodeInfoWithStorage[127.0.0.1:33050,DS-322c6d2d-7594-4299-a3a1-caeaef021abe,DISK], DatanodeInfoWithStorage[127.0.0.1:38016,DS-41394ac5-802d-4ab9-8e76-8947a403b4fb,DISK], DatanodeInfoWithStorage[127.0.0.1:40573,DS-62fd892f-51dd-47e2-bd50-3dcaebf451c1,DISK], DatanodeInfoWithStorage[127.0.0.1:42157,DS-c1dc9fe0-f3ba-498e-871b-31a725d1c54c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1375641159-172.17.0.17-1598174680338:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43883,DS-d7a26d83-7661-4949-9052-fc23caa8a0f2,DISK], DatanodeInfoWithStorage[127.0.0.1:36793,DS-afe2a9d7-6c50-4411-963c-8a5191ad2c50,DISK], DatanodeInfoWithStorage[127.0.0.1:46073,DS-d586f430-d52e-4cfb-b141-88449d616241,DISK], DatanodeInfoWithStorage[127.0.0.1:37292,DS-ca76fbcc-983f-4e77-8deb-3e213b71ed68,DISK], DatanodeInfoWithStorage[127.0.0.1:33050,DS-322c6d2d-7594-4299-a3a1-caeaef021abe,DISK], DatanodeInfoWithStorage[127.0.0.1:38016,DS-41394ac5-802d-4ab9-8e76-8947a403b4fb,DISK], DatanodeInfoWithStorage[127.0.0.1:40573,DS-62fd892f-51dd-47e2-bd50-3dcaebf451c1,DISK], DatanodeInfoWithStorage[127.0.0.1:42157,DS-c1dc9fe0-f3ba-498e-871b-31a725d1c54c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-59882717-172.17.0.17-1598174895827:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40323,DS-d9acde25-6fb7-43cc-ace0-62ccbc0510b4,DISK], DatanodeInfoWithStorage[127.0.0.1:39482,DS-9a9c78ec-58b0-4fd9-98d5-f8f48e6d6464,DISK], DatanodeInfoWithStorage[127.0.0.1:43549,DS-cedb2807-7863-4e8a-9124-9162645fa3ed,DISK], DatanodeInfoWithStorage[127.0.0.1:37433,DS-4bf0cd24-f6a8-4f50-a34e-4125750b7a59,DISK], DatanodeInfoWithStorage[127.0.0.1:41649,DS-90e72981-089b-4c54-ac4f-12a7fcffe3cb,DISK], DatanodeInfoWithStorage[127.0.0.1:46576,DS-9532d2f2-5851-4e86-8192-abfe2ee4c59a,DISK], DatanodeInfoWithStorage[127.0.0.1:43960,DS-4e863ec0-368f-4b3e-95d0-bc0270e06c88,DISK], DatanodeInfoWithStorage[127.0.0.1:43414,DS-9d859aa9-5eaf-4a2f-9647-5575bbfb3d2d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-59882717-172.17.0.17-1598174895827:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40323,DS-d9acde25-6fb7-43cc-ace0-62ccbc0510b4,DISK], DatanodeInfoWithStorage[127.0.0.1:39482,DS-9a9c78ec-58b0-4fd9-98d5-f8f48e6d6464,DISK], DatanodeInfoWithStorage[127.0.0.1:43549,DS-cedb2807-7863-4e8a-9124-9162645fa3ed,DISK], DatanodeInfoWithStorage[127.0.0.1:37433,DS-4bf0cd24-f6a8-4f50-a34e-4125750b7a59,DISK], DatanodeInfoWithStorage[127.0.0.1:41649,DS-90e72981-089b-4c54-ac4f-12a7fcffe3cb,DISK], DatanodeInfoWithStorage[127.0.0.1:46576,DS-9532d2f2-5851-4e86-8192-abfe2ee4c59a,DISK], DatanodeInfoWithStorage[127.0.0.1:43960,DS-4e863ec0-368f-4b3e-95d0-bc0270e06c88,DISK], DatanodeInfoWithStorage[127.0.0.1:43414,DS-9d859aa9-5eaf-4a2f-9647-5575bbfb3d2d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2118070043-172.17.0.17-1598175877825:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37441,DS-cb053bf4-93b9-4da4-9969-aeb423c7f573,DISK], DatanodeInfoWithStorage[127.0.0.1:33574,DS-2ed6bcad-4dcd-43fe-a8cb-9b5c041503ab,DISK], DatanodeInfoWithStorage[127.0.0.1:36456,DS-ff3bb383-6ee7-4807-bde1-b6131eecaa66,DISK], DatanodeInfoWithStorage[127.0.0.1:46672,DS-a9cd829c-71b7-43fb-8a9b-dbe35daa0e33,DISK], DatanodeInfoWithStorage[127.0.0.1:41059,DS-890f3ef2-5c05-4d9e-adb2-222ae820d960,DISK], DatanodeInfoWithStorage[127.0.0.1:36131,DS-b4def1d8-345b-4103-aea9-03bb7ea6e0ef,DISK], DatanodeInfoWithStorage[127.0.0.1:36123,DS-5b8e09f1-4155-40dc-b35f-431c70aab076,DISK], DatanodeInfoWithStorage[127.0.0.1:38220,DS-5dd4f572-e13c-4360-bf30-d61c30947623,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2118070043-172.17.0.17-1598175877825:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37441,DS-cb053bf4-93b9-4da4-9969-aeb423c7f573,DISK], DatanodeInfoWithStorage[127.0.0.1:33574,DS-2ed6bcad-4dcd-43fe-a8cb-9b5c041503ab,DISK], DatanodeInfoWithStorage[127.0.0.1:36456,DS-ff3bb383-6ee7-4807-bde1-b6131eecaa66,DISK], DatanodeInfoWithStorage[127.0.0.1:46672,DS-a9cd829c-71b7-43fb-8a9b-dbe35daa0e33,DISK], DatanodeInfoWithStorage[127.0.0.1:41059,DS-890f3ef2-5c05-4d9e-adb2-222ae820d960,DISK], DatanodeInfoWithStorage[127.0.0.1:36131,DS-b4def1d8-345b-4103-aea9-03bb7ea6e0ef,DISK], DatanodeInfoWithStorage[127.0.0.1:36123,DS-5b8e09f1-4155-40dc-b35f-431c70aab076,DISK], DatanodeInfoWithStorage[127.0.0.1:38220,DS-5dd4f572-e13c-4360-bf30-d61c30947623,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2029250910-172.17.0.17-1598176075099:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36441,DS-3347411f-4986-48dc-9774-fcce9e4a95be,DISK], DatanodeInfoWithStorage[127.0.0.1:46752,DS-fb57eaab-fe4d-4e8c-a16a-e6ef59c4f18c,DISK], DatanodeInfoWithStorage[127.0.0.1:39647,DS-e587a4b7-f3ff-4690-a40a-36b70e613c32,DISK], DatanodeInfoWithStorage[127.0.0.1:46775,DS-88ed9967-47f5-47c4-a0f8-1487999c0dd8,DISK], DatanodeInfoWithStorage[127.0.0.1:41307,DS-7e9838b6-7073-4b58-ae18-c0261673c043,DISK], DatanodeInfoWithStorage[127.0.0.1:33859,DS-05c62aba-c356-4121-9f0f-7ef36e33a51f,DISK], DatanodeInfoWithStorage[127.0.0.1:45177,DS-740116f4-e8e9-497e-882c-a92910c5f3d8,DISK], DatanodeInfoWithStorage[127.0.0.1:42107,DS-eedb6950-45b9-4ce4-a2b5-5edf668f70c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2029250910-172.17.0.17-1598176075099:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36441,DS-3347411f-4986-48dc-9774-fcce9e4a95be,DISK], DatanodeInfoWithStorage[127.0.0.1:46752,DS-fb57eaab-fe4d-4e8c-a16a-e6ef59c4f18c,DISK], DatanodeInfoWithStorage[127.0.0.1:39647,DS-e587a4b7-f3ff-4690-a40a-36b70e613c32,DISK], DatanodeInfoWithStorage[127.0.0.1:46775,DS-88ed9967-47f5-47c4-a0f8-1487999c0dd8,DISK], DatanodeInfoWithStorage[127.0.0.1:41307,DS-7e9838b6-7073-4b58-ae18-c0261673c043,DISK], DatanodeInfoWithStorage[127.0.0.1:33859,DS-05c62aba-c356-4121-9f0f-7ef36e33a51f,DISK], DatanodeInfoWithStorage[127.0.0.1:45177,DS-740116f4-e8e9-497e-882c-a92910c5f3d8,DISK], DatanodeInfoWithStorage[127.0.0.1:42107,DS-eedb6950-45b9-4ce4-a2b5-5edf668f70c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1511747964-172.17.0.17-1598176560160:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39017,DS-eb816c4b-fc36-423c-96c5-dd8d79556f02,DISK], DatanodeInfoWithStorage[127.0.0.1:44728,DS-ec8ee6bd-e994-4862-b967-dd7e4c29dfae,DISK], DatanodeInfoWithStorage[127.0.0.1:36320,DS-5af4a195-7e53-412a-9575-e74e87ef1381,DISK], DatanodeInfoWithStorage[127.0.0.1:42105,DS-14ba177c-033b-42bc-bb2a-d2f0908ca981,DISK], DatanodeInfoWithStorage[127.0.0.1:36322,DS-17716444-fd3b-448f-bed1-3ddce9759b9b,DISK], DatanodeInfoWithStorage[127.0.0.1:45332,DS-e88a1ffe-8cee-4d15-a587-f320e947214d,DISK], DatanodeInfoWithStorage[127.0.0.1:42803,DS-62f42b4e-8f19-45ac-9a12-1a432dcc9bc6,DISK], DatanodeInfoWithStorage[127.0.0.1:45599,DS-3e6f1dff-2a75-4d20-82da-dec132a7e91b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1511747964-172.17.0.17-1598176560160:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39017,DS-eb816c4b-fc36-423c-96c5-dd8d79556f02,DISK], DatanodeInfoWithStorage[127.0.0.1:44728,DS-ec8ee6bd-e994-4862-b967-dd7e4c29dfae,DISK], DatanodeInfoWithStorage[127.0.0.1:36320,DS-5af4a195-7e53-412a-9575-e74e87ef1381,DISK], DatanodeInfoWithStorage[127.0.0.1:42105,DS-14ba177c-033b-42bc-bb2a-d2f0908ca981,DISK], DatanodeInfoWithStorage[127.0.0.1:36322,DS-17716444-fd3b-448f-bed1-3ddce9759b9b,DISK], DatanodeInfoWithStorage[127.0.0.1:45332,DS-e88a1ffe-8cee-4d15-a587-f320e947214d,DISK], DatanodeInfoWithStorage[127.0.0.1:42803,DS-62f42b4e-8f19-45ac-9a12-1a432dcc9bc6,DISK], DatanodeInfoWithStorage[127.0.0.1:45599,DS-3e6f1dff-2a75-4d20-82da-dec132a7e91b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2049963344-172.17.0.17-1598176982517:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40957,DS-22424e5c-e0df-44ed-9a4a-f785298131b8,DISK], DatanodeInfoWithStorage[127.0.0.1:44894,DS-63b9ac74-08ff-4b3a-9d9e-b00617cd3f6b,DISK], DatanodeInfoWithStorage[127.0.0.1:36888,DS-c5e9e6ee-4d2a-4b9e-b4f7-fa0d8f3843d7,DISK], DatanodeInfoWithStorage[127.0.0.1:37101,DS-45cbb484-d637-42c0-83c4-7373ab042791,DISK], DatanodeInfoWithStorage[127.0.0.1:45228,DS-aff03253-d459-4c14-a74e-4c3cf0e9f649,DISK], DatanodeInfoWithStorage[127.0.0.1:37267,DS-89dbf9b0-fa6a-4255-8e9d-1f66995bc227,DISK], DatanodeInfoWithStorage[127.0.0.1:41581,DS-88aae9ae-afe0-4d9e-aefc-8556107532e1,DISK], DatanodeInfoWithStorage[127.0.0.1:40297,DS-b33839dd-d0bd-4dd3-9849-b02f7a9ec258,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2049963344-172.17.0.17-1598176982517:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40957,DS-22424e5c-e0df-44ed-9a4a-f785298131b8,DISK], DatanodeInfoWithStorage[127.0.0.1:44894,DS-63b9ac74-08ff-4b3a-9d9e-b00617cd3f6b,DISK], DatanodeInfoWithStorage[127.0.0.1:36888,DS-c5e9e6ee-4d2a-4b9e-b4f7-fa0d8f3843d7,DISK], DatanodeInfoWithStorage[127.0.0.1:37101,DS-45cbb484-d637-42c0-83c4-7373ab042791,DISK], DatanodeInfoWithStorage[127.0.0.1:45228,DS-aff03253-d459-4c14-a74e-4c3cf0e9f649,DISK], DatanodeInfoWithStorage[127.0.0.1:37267,DS-89dbf9b0-fa6a-4255-8e9d-1f66995bc227,DISK], DatanodeInfoWithStorage[127.0.0.1:41581,DS-88aae9ae-afe0-4d9e-aefc-8556107532e1,DISK], DatanodeInfoWithStorage[127.0.0.1:40297,DS-b33839dd-d0bd-4dd3-9849-b02f7a9ec258,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2042724685-172.17.0.17-1598177871615:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40493,DS-ec23e517-5171-402c-9931-c83fdd0f8e93,DISK], DatanodeInfoWithStorage[127.0.0.1:46168,DS-4034371f-7a2f-4f3c-add9-18a2951d52b4,DISK], DatanodeInfoWithStorage[127.0.0.1:36141,DS-7d64ed49-991a-4d34-8be0-f6b23fb49208,DISK], DatanodeInfoWithStorage[127.0.0.1:43435,DS-d35f0b1f-ad18-4c1c-a225-0f6475cf403a,DISK], DatanodeInfoWithStorage[127.0.0.1:44608,DS-af5cd867-a97e-4022-ae35-5c17948df31e,DISK], DatanodeInfoWithStorage[127.0.0.1:44016,DS-59a840b3-e91c-4319-afc8-e1cae78d8dc5,DISK], DatanodeInfoWithStorage[127.0.0.1:44901,DS-f22a25ac-4dcb-40fb-8be9-fab0997b87d1,DISK], DatanodeInfoWithStorage[127.0.0.1:41687,DS-36d3d4ac-76c7-4279-9808-b8c812f6eaa7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2042724685-172.17.0.17-1598177871615:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40493,DS-ec23e517-5171-402c-9931-c83fdd0f8e93,DISK], DatanodeInfoWithStorage[127.0.0.1:46168,DS-4034371f-7a2f-4f3c-add9-18a2951d52b4,DISK], DatanodeInfoWithStorage[127.0.0.1:36141,DS-7d64ed49-991a-4d34-8be0-f6b23fb49208,DISK], DatanodeInfoWithStorage[127.0.0.1:43435,DS-d35f0b1f-ad18-4c1c-a225-0f6475cf403a,DISK], DatanodeInfoWithStorage[127.0.0.1:44608,DS-af5cd867-a97e-4022-ae35-5c17948df31e,DISK], DatanodeInfoWithStorage[127.0.0.1:44016,DS-59a840b3-e91c-4319-afc8-e1cae78d8dc5,DISK], DatanodeInfoWithStorage[127.0.0.1:44901,DS-f22a25ac-4dcb-40fb-8be9-fab0997b87d1,DISK], DatanodeInfoWithStorage[127.0.0.1:41687,DS-36d3d4ac-76c7-4279-9808-b8c812f6eaa7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-953355993-172.17.0.17-1598178056453:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34159,DS-d957eaba-1c39-4590-b32a-3fc54576e77d,DISK], DatanodeInfoWithStorage[127.0.0.1:40655,DS-bacbbd63-ea98-4c1f-aea0-f2704424fc9a,DISK], DatanodeInfoWithStorage[127.0.0.1:41649,DS-9d0940c5-66be-420c-aae4-69bb0307d3be,DISK], DatanodeInfoWithStorage[127.0.0.1:39009,DS-647d1520-e5e7-4907-9dee-3da0f0466962,DISK], DatanodeInfoWithStorage[127.0.0.1:43737,DS-7ef86a4f-391c-4f20-82ef-965171f87738,DISK], DatanodeInfoWithStorage[127.0.0.1:37446,DS-38b88b8f-945d-4682-a20c-c6f74cb8f75d,DISK], DatanodeInfoWithStorage[127.0.0.1:35532,DS-2148d374-c61b-4d24-be25-5f9f125eebf3,DISK], DatanodeInfoWithStorage[127.0.0.1:36860,DS-85dbb8db-02ed-4d24-8f63-f8503d18594e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-953355993-172.17.0.17-1598178056453:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34159,DS-d957eaba-1c39-4590-b32a-3fc54576e77d,DISK], DatanodeInfoWithStorage[127.0.0.1:40655,DS-bacbbd63-ea98-4c1f-aea0-f2704424fc9a,DISK], DatanodeInfoWithStorage[127.0.0.1:41649,DS-9d0940c5-66be-420c-aae4-69bb0307d3be,DISK], DatanodeInfoWithStorage[127.0.0.1:39009,DS-647d1520-e5e7-4907-9dee-3da0f0466962,DISK], DatanodeInfoWithStorage[127.0.0.1:43737,DS-7ef86a4f-391c-4f20-82ef-965171f87738,DISK], DatanodeInfoWithStorage[127.0.0.1:37446,DS-38b88b8f-945d-4682-a20c-c6f74cb8f75d,DISK], DatanodeInfoWithStorage[127.0.0.1:35532,DS-2148d374-c61b-4d24-be25-5f9f125eebf3,DISK], DatanodeInfoWithStorage[127.0.0.1:36860,DS-85dbb8db-02ed-4d24-8f63-f8503d18594e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 2 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 4699
