reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1779140136-172.17.0.21-1598113275871:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35815,DS-c550d02d-a49e-45a8-ba9a-e1b83c0ad756,DISK], DatanodeInfoWithStorage[127.0.0.1:44194,DS-d51ef4e7-9c3e-4776-8625-46f911eaa08d,DISK], DatanodeInfoWithStorage[127.0.0.1:45329,DS-5a7febef-5c1f-48dc-a621-2343d2dd26d8,DISK], DatanodeInfoWithStorage[127.0.0.1:46742,DS-7b34ce15-fd50-403e-9039-1bd44b74db83,DISK], DatanodeInfoWithStorage[127.0.0.1:34380,DS-b17f88d8-3cae-49d3-b0ef-795c3a1999fc,DISK], DatanodeInfoWithStorage[127.0.0.1:35787,DS-4851fe9a-0a46-4df8-b983-2a3c3f20620e,DISK], DatanodeInfoWithStorage[127.0.0.1:38539,DS-e8024444-6871-4c27-8b06-8cd0892093f6,DISK], DatanodeInfoWithStorage[127.0.0.1:40899,DS-3607c0c0-1db5-4a5b-88cb-90d195218f21,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1779140136-172.17.0.21-1598113275871:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35815,DS-c550d02d-a49e-45a8-ba9a-e1b83c0ad756,DISK], DatanodeInfoWithStorage[127.0.0.1:44194,DS-d51ef4e7-9c3e-4776-8625-46f911eaa08d,DISK], DatanodeInfoWithStorage[127.0.0.1:45329,DS-5a7febef-5c1f-48dc-a621-2343d2dd26d8,DISK], DatanodeInfoWithStorage[127.0.0.1:46742,DS-7b34ce15-fd50-403e-9039-1bd44b74db83,DISK], DatanodeInfoWithStorage[127.0.0.1:34380,DS-b17f88d8-3cae-49d3-b0ef-795c3a1999fc,DISK], DatanodeInfoWithStorage[127.0.0.1:35787,DS-4851fe9a-0a46-4df8-b983-2a3c3f20620e,DISK], DatanodeInfoWithStorage[127.0.0.1:38539,DS-e8024444-6871-4c27-8b06-8cd0892093f6,DISK], DatanodeInfoWithStorage[127.0.0.1:40899,DS-3607c0c0-1db5-4a5b-88cb-90d195218f21,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-350072392-172.17.0.21-1598114049490:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37617,DS-409f9a0f-9c41-4896-a99c-9db046811c11,DISK], DatanodeInfoWithStorage[127.0.0.1:46204,DS-6a6d2b3e-4b40-42b2-b3c1-0aa60db27821,DISK], DatanodeInfoWithStorage[127.0.0.1:46603,DS-821c5c2d-522f-453b-b2e0-28957bde27d0,DISK], DatanodeInfoWithStorage[127.0.0.1:42248,DS-15e40226-62dc-4ba9-bdc0-84a5d5ed5abd,DISK], DatanodeInfoWithStorage[127.0.0.1:42137,DS-56584c43-4c30-4f0b-b9d4-620454feb782,DISK], DatanodeInfoWithStorage[127.0.0.1:37553,DS-3083dfbf-d3f8-4c56-afef-361b7ca36eaf,DISK], DatanodeInfoWithStorage[127.0.0.1:36341,DS-474a6a63-56c0-453a-925d-7ccd0c58b8ce,DISK], DatanodeInfoWithStorage[127.0.0.1:36593,DS-96165db7-4b22-45d3-ac7e-8c79cbb374ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-350072392-172.17.0.21-1598114049490:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37617,DS-409f9a0f-9c41-4896-a99c-9db046811c11,DISK], DatanodeInfoWithStorage[127.0.0.1:46204,DS-6a6d2b3e-4b40-42b2-b3c1-0aa60db27821,DISK], DatanodeInfoWithStorage[127.0.0.1:46603,DS-821c5c2d-522f-453b-b2e0-28957bde27d0,DISK], DatanodeInfoWithStorage[127.0.0.1:42248,DS-15e40226-62dc-4ba9-bdc0-84a5d5ed5abd,DISK], DatanodeInfoWithStorage[127.0.0.1:42137,DS-56584c43-4c30-4f0b-b9d4-620454feb782,DISK], DatanodeInfoWithStorage[127.0.0.1:37553,DS-3083dfbf-d3f8-4c56-afef-361b7ca36eaf,DISK], DatanodeInfoWithStorage[127.0.0.1:36341,DS-474a6a63-56c0-453a-925d-7ccd0c58b8ce,DISK], DatanodeInfoWithStorage[127.0.0.1:36593,DS-96165db7-4b22-45d3-ac7e-8c79cbb374ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1946579464-172.17.0.21-1598114229358:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44980,DS-c39c4181-74ba-42d7-9230-76ad1fd5ce99,DISK], DatanodeInfoWithStorage[127.0.0.1:41746,DS-891f1413-e069-4621-bfc2-6682ad4afe47,DISK], DatanodeInfoWithStorage[127.0.0.1:34749,DS-a9064577-2afb-4f09-bacd-737dac943abf,DISK], DatanodeInfoWithStorage[127.0.0.1:38021,DS-05348b6c-e4b5-4dda-88f2-6b95d53ffcc6,DISK], DatanodeInfoWithStorage[127.0.0.1:45978,DS-17e9b645-662a-499e-ba83-28aaa500b088,DISK], DatanodeInfoWithStorage[127.0.0.1:39499,DS-0154fedc-f572-47f0-8d1c-ee599894f725,DISK], DatanodeInfoWithStorage[127.0.0.1:40758,DS-282afef9-829a-49d4-b942-5bda7c1f9250,DISK], DatanodeInfoWithStorage[127.0.0.1:33452,DS-104e5965-f924-45ed-a249-5e3c38653f6f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1946579464-172.17.0.21-1598114229358:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44980,DS-c39c4181-74ba-42d7-9230-76ad1fd5ce99,DISK], DatanodeInfoWithStorage[127.0.0.1:41746,DS-891f1413-e069-4621-bfc2-6682ad4afe47,DISK], DatanodeInfoWithStorage[127.0.0.1:34749,DS-a9064577-2afb-4f09-bacd-737dac943abf,DISK], DatanodeInfoWithStorage[127.0.0.1:38021,DS-05348b6c-e4b5-4dda-88f2-6b95d53ffcc6,DISK], DatanodeInfoWithStorage[127.0.0.1:45978,DS-17e9b645-662a-499e-ba83-28aaa500b088,DISK], DatanodeInfoWithStorage[127.0.0.1:39499,DS-0154fedc-f572-47f0-8d1c-ee599894f725,DISK], DatanodeInfoWithStorage[127.0.0.1:40758,DS-282afef9-829a-49d4-b942-5bda7c1f9250,DISK], DatanodeInfoWithStorage[127.0.0.1:33452,DS-104e5965-f924-45ed-a249-5e3c38653f6f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1602185000-172.17.0.21-1598114586352:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34201,DS-8913f525-240b-4ff6-a4d9-787ea1ca61e6,DISK], DatanodeInfoWithStorage[127.0.0.1:36129,DS-c4afe12c-9dfb-4432-a5da-dac91ac12ca5,DISK], DatanodeInfoWithStorage[127.0.0.1:46617,DS-0253dd22-f888-4ba7-8615-8388e4a73a67,DISK], DatanodeInfoWithStorage[127.0.0.1:42225,DS-f431725c-e033-4cb0-aaab-f41c0c38a23b,DISK], DatanodeInfoWithStorage[127.0.0.1:45020,DS-f1aef409-567d-41be-81e3-71ee73cf8f7c,DISK], DatanodeInfoWithStorage[127.0.0.1:44066,DS-62bb0495-db4e-4be9-b682-f4a45ce053fa,DISK], DatanodeInfoWithStorage[127.0.0.1:35764,DS-755723e8-0391-40e4-a869-f40ee9f07578,DISK], DatanodeInfoWithStorage[127.0.0.1:45932,DS-901df2f9-ad2e-421f-8178-99641776c664,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1602185000-172.17.0.21-1598114586352:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34201,DS-8913f525-240b-4ff6-a4d9-787ea1ca61e6,DISK], DatanodeInfoWithStorage[127.0.0.1:36129,DS-c4afe12c-9dfb-4432-a5da-dac91ac12ca5,DISK], DatanodeInfoWithStorage[127.0.0.1:46617,DS-0253dd22-f888-4ba7-8615-8388e4a73a67,DISK], DatanodeInfoWithStorage[127.0.0.1:42225,DS-f431725c-e033-4cb0-aaab-f41c0c38a23b,DISK], DatanodeInfoWithStorage[127.0.0.1:45020,DS-f1aef409-567d-41be-81e3-71ee73cf8f7c,DISK], DatanodeInfoWithStorage[127.0.0.1:44066,DS-62bb0495-db4e-4be9-b682-f4a45ce053fa,DISK], DatanodeInfoWithStorage[127.0.0.1:35764,DS-755723e8-0391-40e4-a869-f40ee9f07578,DISK], DatanodeInfoWithStorage[127.0.0.1:45932,DS-901df2f9-ad2e-421f-8178-99641776c664,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1860050985-172.17.0.21-1598114800808:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46827,DS-9d160b78-2e3a-4714-aca5-d217266c449e,DISK], DatanodeInfoWithStorage[127.0.0.1:41099,DS-91a8301b-3b06-408e-9916-92d7ed76a69a,DISK], DatanodeInfoWithStorage[127.0.0.1:42773,DS-422c1e71-dba5-4214-999a-ecd9a43ef6f7,DISK], DatanodeInfoWithStorage[127.0.0.1:34023,DS-ce5c4ee0-f67e-4fad-bf7d-7c1bfac77559,DISK], DatanodeInfoWithStorage[127.0.0.1:38943,DS-d12139a8-d2e9-4994-94bc-2e8d69172239,DISK], DatanodeInfoWithStorage[127.0.0.1:45508,DS-74faf257-5cd6-49b1-9bc2-e979645e7b16,DISK], DatanodeInfoWithStorage[127.0.0.1:36823,DS-5e98de62-3ddf-47db-9245-bbb09c32f312,DISK], DatanodeInfoWithStorage[127.0.0.1:45981,DS-7da9d50c-b0a2-45c7-a617-c29e522174a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1860050985-172.17.0.21-1598114800808:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46827,DS-9d160b78-2e3a-4714-aca5-d217266c449e,DISK], DatanodeInfoWithStorage[127.0.0.1:41099,DS-91a8301b-3b06-408e-9916-92d7ed76a69a,DISK], DatanodeInfoWithStorage[127.0.0.1:42773,DS-422c1e71-dba5-4214-999a-ecd9a43ef6f7,DISK], DatanodeInfoWithStorage[127.0.0.1:34023,DS-ce5c4ee0-f67e-4fad-bf7d-7c1bfac77559,DISK], DatanodeInfoWithStorage[127.0.0.1:38943,DS-d12139a8-d2e9-4994-94bc-2e8d69172239,DISK], DatanodeInfoWithStorage[127.0.0.1:45508,DS-74faf257-5cd6-49b1-9bc2-e979645e7b16,DISK], DatanodeInfoWithStorage[127.0.0.1:36823,DS-5e98de62-3ddf-47db-9245-bbb09c32f312,DISK], DatanodeInfoWithStorage[127.0.0.1:45981,DS-7da9d50c-b0a2-45c7-a617-c29e522174a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1774873827-172.17.0.21-1598115030015:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34587,DS-d31bd81e-7590-4435-a24f-9f79e47a6f83,DISK], DatanodeInfoWithStorage[127.0.0.1:35842,DS-b5ff66a3-145f-434c-8bf0-b5776c396e3f,DISK], DatanodeInfoWithStorage[127.0.0.1:39428,DS-9f023350-3e3f-442c-936e-307eef5dea04,DISK], DatanodeInfoWithStorage[127.0.0.1:46084,DS-555fa61c-a04e-4a7b-8030-38e935700b14,DISK], DatanodeInfoWithStorage[127.0.0.1:35502,DS-e6ef5992-88e1-4ab4-a02a-e45fc03ca30f,DISK], DatanodeInfoWithStorage[127.0.0.1:38515,DS-57977bd4-044a-4d46-860d-87fa63a4437b,DISK], DatanodeInfoWithStorage[127.0.0.1:36076,DS-cbe4678b-0035-4e5c-81fd-d2b66ebeb0b8,DISK], DatanodeInfoWithStorage[127.0.0.1:39550,DS-3e361270-97c0-48dd-b6e7-1c9fdaa9ea60,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1774873827-172.17.0.21-1598115030015:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34587,DS-d31bd81e-7590-4435-a24f-9f79e47a6f83,DISK], DatanodeInfoWithStorage[127.0.0.1:35842,DS-b5ff66a3-145f-434c-8bf0-b5776c396e3f,DISK], DatanodeInfoWithStorage[127.0.0.1:39428,DS-9f023350-3e3f-442c-936e-307eef5dea04,DISK], DatanodeInfoWithStorage[127.0.0.1:46084,DS-555fa61c-a04e-4a7b-8030-38e935700b14,DISK], DatanodeInfoWithStorage[127.0.0.1:35502,DS-e6ef5992-88e1-4ab4-a02a-e45fc03ca30f,DISK], DatanodeInfoWithStorage[127.0.0.1:38515,DS-57977bd4-044a-4d46-860d-87fa63a4437b,DISK], DatanodeInfoWithStorage[127.0.0.1:36076,DS-cbe4678b-0035-4e5c-81fd-d2b66ebeb0b8,DISK], DatanodeInfoWithStorage[127.0.0.1:39550,DS-3e361270-97c0-48dd-b6e7-1c9fdaa9ea60,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1286338134-172.17.0.21-1598115735571:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35343,DS-721b2abd-3f8d-455e-97bf-6bbda0b41d89,DISK], DatanodeInfoWithStorage[127.0.0.1:45212,DS-9c90b77a-8aa1-48f9-86f0-7c844056b1e3,DISK], DatanodeInfoWithStorage[127.0.0.1:34323,DS-af726a18-227f-4d81-a899-4d7653b2fbfa,DISK], DatanodeInfoWithStorage[127.0.0.1:42714,DS-95607224-8c6d-4fa4-8249-856004d0d509,DISK], DatanodeInfoWithStorage[127.0.0.1:46802,DS-8b3f025e-6640-4ad6-9398-5966e41245c9,DISK], DatanodeInfoWithStorage[127.0.0.1:41131,DS-e7b6965f-13e3-44db-8da9-1309039ae6e0,DISK], DatanodeInfoWithStorage[127.0.0.1:33601,DS-ad2eccc9-48ba-406c-8b28-e5ad3eb68b92,DISK], DatanodeInfoWithStorage[127.0.0.1:41652,DS-8925cad9-0ae2-4ed8-a43e-7be9544e7cb2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1286338134-172.17.0.21-1598115735571:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35343,DS-721b2abd-3f8d-455e-97bf-6bbda0b41d89,DISK], DatanodeInfoWithStorage[127.0.0.1:45212,DS-9c90b77a-8aa1-48f9-86f0-7c844056b1e3,DISK], DatanodeInfoWithStorage[127.0.0.1:34323,DS-af726a18-227f-4d81-a899-4d7653b2fbfa,DISK], DatanodeInfoWithStorage[127.0.0.1:42714,DS-95607224-8c6d-4fa4-8249-856004d0d509,DISK], DatanodeInfoWithStorage[127.0.0.1:46802,DS-8b3f025e-6640-4ad6-9398-5966e41245c9,DISK], DatanodeInfoWithStorage[127.0.0.1:41131,DS-e7b6965f-13e3-44db-8da9-1309039ae6e0,DISK], DatanodeInfoWithStorage[127.0.0.1:33601,DS-ad2eccc9-48ba-406c-8b28-e5ad3eb68b92,DISK], DatanodeInfoWithStorage[127.0.0.1:41652,DS-8925cad9-0ae2-4ed8-a43e-7be9544e7cb2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2022557381-172.17.0.21-1598115819487:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42898,DS-c5757ff2-d71c-4a96-a718-23e3478983b3,DISK], DatanodeInfoWithStorage[127.0.0.1:43952,DS-7c555413-d4f1-484b-8fc4-ef0c1c4cb7cb,DISK], DatanodeInfoWithStorage[127.0.0.1:40781,DS-acd864c5-1e85-4f87-812a-c6398fb4eaf1,DISK], DatanodeInfoWithStorage[127.0.0.1:37494,DS-5e504ed0-b5ff-44e4-95c9-98990c0354d5,DISK], DatanodeInfoWithStorage[127.0.0.1:38411,DS-1b4f76e5-5b46-46cf-b9c1-52bdd388fb43,DISK], DatanodeInfoWithStorage[127.0.0.1:44361,DS-3c7c1fc4-06d3-4ca1-9b50-1f8a02aeccea,DISK], DatanodeInfoWithStorage[127.0.0.1:43577,DS-a000e1b4-f5d0-4e02-a137-4aa459255833,DISK], DatanodeInfoWithStorage[127.0.0.1:45808,DS-97021b8b-2f34-4350-b114-5007f15e9983,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2022557381-172.17.0.21-1598115819487:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42898,DS-c5757ff2-d71c-4a96-a718-23e3478983b3,DISK], DatanodeInfoWithStorage[127.0.0.1:43952,DS-7c555413-d4f1-484b-8fc4-ef0c1c4cb7cb,DISK], DatanodeInfoWithStorage[127.0.0.1:40781,DS-acd864c5-1e85-4f87-812a-c6398fb4eaf1,DISK], DatanodeInfoWithStorage[127.0.0.1:37494,DS-5e504ed0-b5ff-44e4-95c9-98990c0354d5,DISK], DatanodeInfoWithStorage[127.0.0.1:38411,DS-1b4f76e5-5b46-46cf-b9c1-52bdd388fb43,DISK], DatanodeInfoWithStorage[127.0.0.1:44361,DS-3c7c1fc4-06d3-4ca1-9b50-1f8a02aeccea,DISK], DatanodeInfoWithStorage[127.0.0.1:43577,DS-a000e1b4-f5d0-4e02-a137-4aa459255833,DISK], DatanodeInfoWithStorage[127.0.0.1:45808,DS-97021b8b-2f34-4350-b114-5007f15e9983,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1904556720-172.17.0.21-1598116115466:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45308,DS-32b02a9f-318c-4776-8710-eab1b24b1075,DISK], DatanodeInfoWithStorage[127.0.0.1:33289,DS-152c75df-4e13-4be9-b168-7689bdebc18a,DISK], DatanodeInfoWithStorage[127.0.0.1:41705,DS-c9cb8a52-c9b7-48a5-a99c-6dfa47d13d41,DISK], DatanodeInfoWithStorage[127.0.0.1:40191,DS-6b1ad313-d35e-47d1-ae5a-3c532ad68428,DISK], DatanodeInfoWithStorage[127.0.0.1:36203,DS-ff4230e1-ad22-45d0-882a-bfd76e8e9c39,DISK], DatanodeInfoWithStorage[127.0.0.1:37391,DS-8e2c9146-d8c0-4abf-b58f-34014fbdcf08,DISK], DatanodeInfoWithStorage[127.0.0.1:37738,DS-bb329377-e864-4c32-a281-c3281e5a3112,DISK], DatanodeInfoWithStorage[127.0.0.1:46426,DS-0530ce51-8be0-43be-a277-14974074fa2d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1904556720-172.17.0.21-1598116115466:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45308,DS-32b02a9f-318c-4776-8710-eab1b24b1075,DISK], DatanodeInfoWithStorage[127.0.0.1:33289,DS-152c75df-4e13-4be9-b168-7689bdebc18a,DISK], DatanodeInfoWithStorage[127.0.0.1:41705,DS-c9cb8a52-c9b7-48a5-a99c-6dfa47d13d41,DISK], DatanodeInfoWithStorage[127.0.0.1:40191,DS-6b1ad313-d35e-47d1-ae5a-3c532ad68428,DISK], DatanodeInfoWithStorage[127.0.0.1:36203,DS-ff4230e1-ad22-45d0-882a-bfd76e8e9c39,DISK], DatanodeInfoWithStorage[127.0.0.1:37391,DS-8e2c9146-d8c0-4abf-b58f-34014fbdcf08,DISK], DatanodeInfoWithStorage[127.0.0.1:37738,DS-bb329377-e864-4c32-a281-c3281e5a3112,DISK], DatanodeInfoWithStorage[127.0.0.1:46426,DS-0530ce51-8be0-43be-a277-14974074fa2d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1348440930-172.17.0.21-1598116484095:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37101,DS-c1808b2a-b8d9-4967-bb59-8ee76a6eb16b,DISK], DatanodeInfoWithStorage[127.0.0.1:40582,DS-3dd3168f-147b-4427-beb3-30291de00205,DISK], DatanodeInfoWithStorage[127.0.0.1:39193,DS-4785e0ea-7893-4e2b-a204-836ed974d3c0,DISK], DatanodeInfoWithStorage[127.0.0.1:42623,DS-393c19ce-05b5-4922-b4af-6520f3458b40,DISK], DatanodeInfoWithStorage[127.0.0.1:38827,DS-0a5c6727-d8eb-45f7-9b4e-abeba6836f24,DISK], DatanodeInfoWithStorage[127.0.0.1:39205,DS-2154e2e7-1844-437a-a7d3-942ac743a588,DISK], DatanodeInfoWithStorage[127.0.0.1:46556,DS-6e97e22d-4ae2-4433-b558-e196245588f6,DISK], DatanodeInfoWithStorage[127.0.0.1:45067,DS-0f67de78-90d7-49f1-a353-4cf0c7dedb8a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1348440930-172.17.0.21-1598116484095:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37101,DS-c1808b2a-b8d9-4967-bb59-8ee76a6eb16b,DISK], DatanodeInfoWithStorage[127.0.0.1:40582,DS-3dd3168f-147b-4427-beb3-30291de00205,DISK], DatanodeInfoWithStorage[127.0.0.1:39193,DS-4785e0ea-7893-4e2b-a204-836ed974d3c0,DISK], DatanodeInfoWithStorage[127.0.0.1:42623,DS-393c19ce-05b5-4922-b4af-6520f3458b40,DISK], DatanodeInfoWithStorage[127.0.0.1:38827,DS-0a5c6727-d8eb-45f7-9b4e-abeba6836f24,DISK], DatanodeInfoWithStorage[127.0.0.1:39205,DS-2154e2e7-1844-437a-a7d3-942ac743a588,DISK], DatanodeInfoWithStorage[127.0.0.1:46556,DS-6e97e22d-4ae2-4433-b558-e196245588f6,DISK], DatanodeInfoWithStorage[127.0.0.1:45067,DS-0f67de78-90d7-49f1-a353-4cf0c7dedb8a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1203338903-172.17.0.21-1598116715845:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33618,DS-f2660ef2-ea6d-48e8-83cc-e9c5a3beabfb,DISK], DatanodeInfoWithStorage[127.0.0.1:42883,DS-190db9cc-7581-406e-b6b5-870d7460f843,DISK], DatanodeInfoWithStorage[127.0.0.1:38878,DS-d8f4b95c-078c-4458-a7d3-869279a2dc7f,DISK], DatanodeInfoWithStorage[127.0.0.1:39374,DS-d45102ed-f23d-4474-91b1-2639afcbcf77,DISK], DatanodeInfoWithStorage[127.0.0.1:37499,DS-08db23c1-b276-417c-8a4c-ca1b1a3f9243,DISK], DatanodeInfoWithStorage[127.0.0.1:42615,DS-398d1515-29ff-44c6-9161-33281c48b322,DISK], DatanodeInfoWithStorage[127.0.0.1:45702,DS-fbaabb8c-d183-47f8-a9cb-4d7127aaf202,DISK], DatanodeInfoWithStorage[127.0.0.1:35194,DS-2a6c9c50-1d12-416d-b1df-a81481b8f786,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1203338903-172.17.0.21-1598116715845:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33618,DS-f2660ef2-ea6d-48e8-83cc-e9c5a3beabfb,DISK], DatanodeInfoWithStorage[127.0.0.1:42883,DS-190db9cc-7581-406e-b6b5-870d7460f843,DISK], DatanodeInfoWithStorage[127.0.0.1:38878,DS-d8f4b95c-078c-4458-a7d3-869279a2dc7f,DISK], DatanodeInfoWithStorage[127.0.0.1:39374,DS-d45102ed-f23d-4474-91b1-2639afcbcf77,DISK], DatanodeInfoWithStorage[127.0.0.1:37499,DS-08db23c1-b276-417c-8a4c-ca1b1a3f9243,DISK], DatanodeInfoWithStorage[127.0.0.1:42615,DS-398d1515-29ff-44c6-9161-33281c48b322,DISK], DatanodeInfoWithStorage[127.0.0.1:45702,DS-fbaabb8c-d183-47f8-a9cb-4d7127aaf202,DISK], DatanodeInfoWithStorage[127.0.0.1:35194,DS-2a6c9c50-1d12-416d-b1df-a81481b8f786,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1695014961-172.17.0.21-1598116780798:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39154,DS-d17d55bd-0af9-4603-a2fb-8c83e43a562e,DISK], DatanodeInfoWithStorage[127.0.0.1:44145,DS-9e31d0a6-a93c-4993-a801-319c763f1032,DISK], DatanodeInfoWithStorage[127.0.0.1:34285,DS-18ec8dc8-6df1-44fd-b16a-9312529253d0,DISK], DatanodeInfoWithStorage[127.0.0.1:39285,DS-76b75703-70a9-437a-b030-9f30990f76b7,DISK], DatanodeInfoWithStorage[127.0.0.1:40466,DS-36fe9244-66b0-4b02-a14f-c5c751625201,DISK], DatanodeInfoWithStorage[127.0.0.1:39828,DS-1ee386ee-2a7b-4a01-8484-bc75ba18dbd3,DISK], DatanodeInfoWithStorage[127.0.0.1:37054,DS-a694ee91-167f-4ca4-8c0d-45af50425046,DISK], DatanodeInfoWithStorage[127.0.0.1:46516,DS-ba2263b6-2533-4fbc-8f7c-96f971bbf9c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1695014961-172.17.0.21-1598116780798:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39154,DS-d17d55bd-0af9-4603-a2fb-8c83e43a562e,DISK], DatanodeInfoWithStorage[127.0.0.1:44145,DS-9e31d0a6-a93c-4993-a801-319c763f1032,DISK], DatanodeInfoWithStorage[127.0.0.1:34285,DS-18ec8dc8-6df1-44fd-b16a-9312529253d0,DISK], DatanodeInfoWithStorage[127.0.0.1:39285,DS-76b75703-70a9-437a-b030-9f30990f76b7,DISK], DatanodeInfoWithStorage[127.0.0.1:40466,DS-36fe9244-66b0-4b02-a14f-c5c751625201,DISK], DatanodeInfoWithStorage[127.0.0.1:39828,DS-1ee386ee-2a7b-4a01-8484-bc75ba18dbd3,DISK], DatanodeInfoWithStorage[127.0.0.1:37054,DS-a694ee91-167f-4ca4-8c0d-45af50425046,DISK], DatanodeInfoWithStorage[127.0.0.1:46516,DS-ba2263b6-2533-4fbc-8f7c-96f971bbf9c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2094596694-172.17.0.21-1598116812068:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33368,DS-05f20162-e955-4cb5-9bdf-30b8e2653058,DISK], DatanodeInfoWithStorage[127.0.0.1:41573,DS-2bc5b70d-fa7e-4788-9215-d4d8b31b5fca,DISK], DatanodeInfoWithStorage[127.0.0.1:36580,DS-290e9189-a6eb-48ca-b661-d119a74c3b92,DISK], DatanodeInfoWithStorage[127.0.0.1:34283,DS-cc62c628-08f6-4479-8496-925cb95039f6,DISK], DatanodeInfoWithStorage[127.0.0.1:36812,DS-c48a2e75-79b1-43cc-8ec1-4246bd2bdc7e,DISK], DatanodeInfoWithStorage[127.0.0.1:43210,DS-b3df6c38-de3b-4d19-85b7-b77ffc82c3c9,DISK], DatanodeInfoWithStorage[127.0.0.1:38800,DS-bd15558b-f3d6-4813-b15c-068aeb6dd41b,DISK], DatanodeInfoWithStorage[127.0.0.1:33594,DS-972f95be-f080-4b89-ba95-e5b83ece623d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2094596694-172.17.0.21-1598116812068:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33368,DS-05f20162-e955-4cb5-9bdf-30b8e2653058,DISK], DatanodeInfoWithStorage[127.0.0.1:41573,DS-2bc5b70d-fa7e-4788-9215-d4d8b31b5fca,DISK], DatanodeInfoWithStorage[127.0.0.1:36580,DS-290e9189-a6eb-48ca-b661-d119a74c3b92,DISK], DatanodeInfoWithStorage[127.0.0.1:34283,DS-cc62c628-08f6-4479-8496-925cb95039f6,DISK], DatanodeInfoWithStorage[127.0.0.1:36812,DS-c48a2e75-79b1-43cc-8ec1-4246bd2bdc7e,DISK], DatanodeInfoWithStorage[127.0.0.1:43210,DS-b3df6c38-de3b-4d19-85b7-b77ffc82c3c9,DISK], DatanodeInfoWithStorage[127.0.0.1:38800,DS-bd15558b-f3d6-4813-b15c-068aeb6dd41b,DISK], DatanodeInfoWithStorage[127.0.0.1:33594,DS-972f95be-f080-4b89-ba95-e5b83ece623d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-620743943-172.17.0.21-1598117487160:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34531,DS-e33b9346-83ce-4f27-a040-cda8bac9daad,DISK], DatanodeInfoWithStorage[127.0.0.1:42577,DS-74983be3-fcf7-4a71-81e1-3a20a0eb913d,DISK], DatanodeInfoWithStorage[127.0.0.1:40018,DS-e27aafaa-6643-4d65-80ea-89c93c35ee68,DISK], DatanodeInfoWithStorage[127.0.0.1:39976,DS-2c20edb2-3691-4efb-9877-bb3e4a2adff8,DISK], DatanodeInfoWithStorage[127.0.0.1:41517,DS-d6f7cb80-2600-4e0d-97be-5b3abb070063,DISK], DatanodeInfoWithStorage[127.0.0.1:43823,DS-8ce0cd10-f0ac-4d56-a618-0f92ba843f62,DISK], DatanodeInfoWithStorage[127.0.0.1:45564,DS-686ec40d-02c2-44d1-ad75-d2178243e9d1,DISK], DatanodeInfoWithStorage[127.0.0.1:36654,DS-996b1066-c278-4a1e-82ef-669d753b020c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-620743943-172.17.0.21-1598117487160:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34531,DS-e33b9346-83ce-4f27-a040-cda8bac9daad,DISK], DatanodeInfoWithStorage[127.0.0.1:42577,DS-74983be3-fcf7-4a71-81e1-3a20a0eb913d,DISK], DatanodeInfoWithStorage[127.0.0.1:40018,DS-e27aafaa-6643-4d65-80ea-89c93c35ee68,DISK], DatanodeInfoWithStorage[127.0.0.1:39976,DS-2c20edb2-3691-4efb-9877-bb3e4a2adff8,DISK], DatanodeInfoWithStorage[127.0.0.1:41517,DS-d6f7cb80-2600-4e0d-97be-5b3abb070063,DISK], DatanodeInfoWithStorage[127.0.0.1:43823,DS-8ce0cd10-f0ac-4d56-a618-0f92ba843f62,DISK], DatanodeInfoWithStorage[127.0.0.1:45564,DS-686ec40d-02c2-44d1-ad75-d2178243e9d1,DISK], DatanodeInfoWithStorage[127.0.0.1:36654,DS-996b1066-c278-4a1e-82ef-669d753b020c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1727218266-172.17.0.21-1598117712619:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43395,DS-aa5692b9-50eb-41a1-abe7-671181eb8485,DISK], DatanodeInfoWithStorage[127.0.0.1:41890,DS-61d765b6-2f3b-45c4-ab78-b05c8fb5fba6,DISK], DatanodeInfoWithStorage[127.0.0.1:34915,DS-fc92a1a5-9ef4-46b2-b1a8-e8f7e8b9a680,DISK], DatanodeInfoWithStorage[127.0.0.1:46283,DS-faf72ff1-9d68-40b3-8bd8-51cd9c29ef7a,DISK], DatanodeInfoWithStorage[127.0.0.1:39785,DS-54dfe21d-54d2-4df1-8b2c-39dc5625d08e,DISK], DatanodeInfoWithStorage[127.0.0.1:33107,DS-41f0b5b3-469d-4022-83d8-c79dccd79de1,DISK], DatanodeInfoWithStorage[127.0.0.1:42057,DS-42e75112-431c-4c1c-afcf-2a53a3097524,DISK], DatanodeInfoWithStorage[127.0.0.1:38828,DS-be209715-34e6-4738-951c-97599b564391,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1727218266-172.17.0.21-1598117712619:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43395,DS-aa5692b9-50eb-41a1-abe7-671181eb8485,DISK], DatanodeInfoWithStorage[127.0.0.1:41890,DS-61d765b6-2f3b-45c4-ab78-b05c8fb5fba6,DISK], DatanodeInfoWithStorage[127.0.0.1:34915,DS-fc92a1a5-9ef4-46b2-b1a8-e8f7e8b9a680,DISK], DatanodeInfoWithStorage[127.0.0.1:46283,DS-faf72ff1-9d68-40b3-8bd8-51cd9c29ef7a,DISK], DatanodeInfoWithStorage[127.0.0.1:39785,DS-54dfe21d-54d2-4df1-8b2c-39dc5625d08e,DISK], DatanodeInfoWithStorage[127.0.0.1:33107,DS-41f0b5b3-469d-4022-83d8-c79dccd79de1,DISK], DatanodeInfoWithStorage[127.0.0.1:42057,DS-42e75112-431c-4c1c-afcf-2a53a3097524,DISK], DatanodeInfoWithStorage[127.0.0.1:38828,DS-be209715-34e6-4738-951c-97599b564391,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5311
