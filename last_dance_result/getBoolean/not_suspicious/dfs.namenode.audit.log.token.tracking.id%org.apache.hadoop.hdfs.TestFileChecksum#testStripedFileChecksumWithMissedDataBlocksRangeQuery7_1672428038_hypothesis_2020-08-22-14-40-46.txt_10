reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-666526415-172.17.0.21-1598107515872:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46439,DS-fb6cb2f8-e5fb-4326-a3a8-15c3bf9d418c,DISK], DatanodeInfoWithStorage[127.0.0.1:39324,DS-ba986602-a94a-4593-a78c-0b658041ad4d,DISK], DatanodeInfoWithStorage[127.0.0.1:40230,DS-130bcfd0-4a3a-4247-b435-c6ab3a138ba3,DISK], DatanodeInfoWithStorage[127.0.0.1:42901,DS-70d25a9b-c666-4a8d-bbeb-1b5b228b121c,DISK], DatanodeInfoWithStorage[127.0.0.1:46241,DS-6003376a-d6f9-496b-8c53-f1e9afe5b82a,DISK], DatanodeInfoWithStorage[127.0.0.1:44958,DS-89f3e8d4-251d-4526-80bf-1fe2bb5f58be,DISK], DatanodeInfoWithStorage[127.0.0.1:42493,DS-7f8ee279-2433-4dff-a7ec-541ed77f31ed,DISK], DatanodeInfoWithStorage[127.0.0.1:39519,DS-8ab77374-acf1-4c65-b0be-748ee3f2888c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-666526415-172.17.0.21-1598107515872:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46439,DS-fb6cb2f8-e5fb-4326-a3a8-15c3bf9d418c,DISK], DatanodeInfoWithStorage[127.0.0.1:39324,DS-ba986602-a94a-4593-a78c-0b658041ad4d,DISK], DatanodeInfoWithStorage[127.0.0.1:40230,DS-130bcfd0-4a3a-4247-b435-c6ab3a138ba3,DISK], DatanodeInfoWithStorage[127.0.0.1:42901,DS-70d25a9b-c666-4a8d-bbeb-1b5b228b121c,DISK], DatanodeInfoWithStorage[127.0.0.1:46241,DS-6003376a-d6f9-496b-8c53-f1e9afe5b82a,DISK], DatanodeInfoWithStorage[127.0.0.1:44958,DS-89f3e8d4-251d-4526-80bf-1fe2bb5f58be,DISK], DatanodeInfoWithStorage[127.0.0.1:42493,DS-7f8ee279-2433-4dff-a7ec-541ed77f31ed,DISK], DatanodeInfoWithStorage[127.0.0.1:39519,DS-8ab77374-acf1-4c65-b0be-748ee3f2888c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1669378468-172.17.0.21-1598107775241:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42041,DS-4991cd47-a3c0-48f7-9286-9748936c9d64,DISK], DatanodeInfoWithStorage[127.0.0.1:44429,DS-be2d7811-c251-4bfa-b592-1a333e1efa6e,DISK], DatanodeInfoWithStorage[127.0.0.1:43464,DS-e32fae61-2a28-40e8-a37d-aa836790c83c,DISK], DatanodeInfoWithStorage[127.0.0.1:36016,DS-745800ce-0ddc-473e-9fcc-7bbf0200b084,DISK], DatanodeInfoWithStorage[127.0.0.1:41214,DS-bc360ad0-98c5-4e19-83a3-30f1c38488c4,DISK], DatanodeInfoWithStorage[127.0.0.1:38304,DS-fce24609-97aa-41a9-b557-19a5f18c7bd8,DISK], DatanodeInfoWithStorage[127.0.0.1:33779,DS-a1f4ec4d-936b-4ec5-bdbf-853df8a8abe7,DISK], DatanodeInfoWithStorage[127.0.0.1:42867,DS-3ae57a57-be1f-4efa-aaff-ec0d4a2c7243,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1669378468-172.17.0.21-1598107775241:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42041,DS-4991cd47-a3c0-48f7-9286-9748936c9d64,DISK], DatanodeInfoWithStorage[127.0.0.1:44429,DS-be2d7811-c251-4bfa-b592-1a333e1efa6e,DISK], DatanodeInfoWithStorage[127.0.0.1:43464,DS-e32fae61-2a28-40e8-a37d-aa836790c83c,DISK], DatanodeInfoWithStorage[127.0.0.1:36016,DS-745800ce-0ddc-473e-9fcc-7bbf0200b084,DISK], DatanodeInfoWithStorage[127.0.0.1:41214,DS-bc360ad0-98c5-4e19-83a3-30f1c38488c4,DISK], DatanodeInfoWithStorage[127.0.0.1:38304,DS-fce24609-97aa-41a9-b557-19a5f18c7bd8,DISK], DatanodeInfoWithStorage[127.0.0.1:33779,DS-a1f4ec4d-936b-4ec5-bdbf-853df8a8abe7,DISK], DatanodeInfoWithStorage[127.0.0.1:42867,DS-3ae57a57-be1f-4efa-aaff-ec0d4a2c7243,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1896611643-172.17.0.21-1598107991721:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41113,DS-7d4aac56-10a9-431c-b642-5159e9a39c09,DISK], DatanodeInfoWithStorage[127.0.0.1:43311,DS-4d18fef9-af91-422b-9800-15072f8aa2ad,DISK], DatanodeInfoWithStorage[127.0.0.1:39205,DS-5e5a5a16-38d8-4cb6-a4af-6a9612448db8,DISK], DatanodeInfoWithStorage[127.0.0.1:35741,DS-2b04abc4-1102-4123-8094-c0eb13448a3d,DISK], DatanodeInfoWithStorage[127.0.0.1:35831,DS-a72f603e-1ef1-47d4-b7bc-3ea83a5b5593,DISK], DatanodeInfoWithStorage[127.0.0.1:32992,DS-b6c60798-e2d9-49d0-8314-c6a805c125bb,DISK], DatanodeInfoWithStorage[127.0.0.1:43006,DS-30d5194c-139c-47c7-8f72-3f791977e4d5,DISK], DatanodeInfoWithStorage[127.0.0.1:34281,DS-edd9237e-dc26-4fe5-80b4-8c2151281715,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1896611643-172.17.0.21-1598107991721:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41113,DS-7d4aac56-10a9-431c-b642-5159e9a39c09,DISK], DatanodeInfoWithStorage[127.0.0.1:43311,DS-4d18fef9-af91-422b-9800-15072f8aa2ad,DISK], DatanodeInfoWithStorage[127.0.0.1:39205,DS-5e5a5a16-38d8-4cb6-a4af-6a9612448db8,DISK], DatanodeInfoWithStorage[127.0.0.1:35741,DS-2b04abc4-1102-4123-8094-c0eb13448a3d,DISK], DatanodeInfoWithStorage[127.0.0.1:35831,DS-a72f603e-1ef1-47d4-b7bc-3ea83a5b5593,DISK], DatanodeInfoWithStorage[127.0.0.1:32992,DS-b6c60798-e2d9-49d0-8314-c6a805c125bb,DISK], DatanodeInfoWithStorage[127.0.0.1:43006,DS-30d5194c-139c-47c7-8f72-3f791977e4d5,DISK], DatanodeInfoWithStorage[127.0.0.1:34281,DS-edd9237e-dc26-4fe5-80b4-8c2151281715,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1913264279-172.17.0.21-1598108132012:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34626,DS-b2160308-88b0-4b59-8b18-865d98b4ca06,DISK], DatanodeInfoWithStorage[127.0.0.1:33048,DS-724ba9c0-2adc-4288-b0eb-36a61bdc0f93,DISK], DatanodeInfoWithStorage[127.0.0.1:38006,DS-ca2ac8f3-145b-45ad-a4b8-85d9d042dad2,DISK], DatanodeInfoWithStorage[127.0.0.1:41307,DS-9c769120-8efa-4478-b550-0144613cb123,DISK], DatanodeInfoWithStorage[127.0.0.1:42197,DS-c10d302b-fc08-4041-8cde-fa20db8ea9b9,DISK], DatanodeInfoWithStorage[127.0.0.1:44419,DS-12131f05-f892-4af1-bce6-8b1eae705fdf,DISK], DatanodeInfoWithStorage[127.0.0.1:37171,DS-6c3399e9-7701-4d7b-bb8f-6ff2c068d45d,DISK], DatanodeInfoWithStorage[127.0.0.1:39960,DS-27f0a677-d98b-4310-9f19-0a12408f3090,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1913264279-172.17.0.21-1598108132012:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34626,DS-b2160308-88b0-4b59-8b18-865d98b4ca06,DISK], DatanodeInfoWithStorage[127.0.0.1:33048,DS-724ba9c0-2adc-4288-b0eb-36a61bdc0f93,DISK], DatanodeInfoWithStorage[127.0.0.1:38006,DS-ca2ac8f3-145b-45ad-a4b8-85d9d042dad2,DISK], DatanodeInfoWithStorage[127.0.0.1:41307,DS-9c769120-8efa-4478-b550-0144613cb123,DISK], DatanodeInfoWithStorage[127.0.0.1:42197,DS-c10d302b-fc08-4041-8cde-fa20db8ea9b9,DISK], DatanodeInfoWithStorage[127.0.0.1:44419,DS-12131f05-f892-4af1-bce6-8b1eae705fdf,DISK], DatanodeInfoWithStorage[127.0.0.1:37171,DS-6c3399e9-7701-4d7b-bb8f-6ff2c068d45d,DISK], DatanodeInfoWithStorage[127.0.0.1:39960,DS-27f0a677-d98b-4310-9f19-0a12408f3090,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1659284260-172.17.0.21-1598108628037:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42684,DS-c45ab5e6-113e-4431-a866-5e5be51d7e15,DISK], DatanodeInfoWithStorage[127.0.0.1:44894,DS-7995ab6f-7680-4696-9474-d88c2d1fd2d8,DISK], DatanodeInfoWithStorage[127.0.0.1:41786,DS-56daf075-e33e-420a-93b6-5326e8a9e98e,DISK], DatanodeInfoWithStorage[127.0.0.1:33154,DS-f07bb4ad-36aa-4465-aae9-94ad25b6d0d9,DISK], DatanodeInfoWithStorage[127.0.0.1:43002,DS-bc3db8f5-e17e-4b2e-93f3-7bf735505cdf,DISK], DatanodeInfoWithStorage[127.0.0.1:42125,DS-243aff18-96f3-4990-8b4a-8a00a4b93103,DISK], DatanodeInfoWithStorage[127.0.0.1:35473,DS-f94e56e4-f343-492c-a517-a356fcae983d,DISK], DatanodeInfoWithStorage[127.0.0.1:38400,DS-5885f57a-1d34-4ac9-b06c-aafe0473a0fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1659284260-172.17.0.21-1598108628037:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42684,DS-c45ab5e6-113e-4431-a866-5e5be51d7e15,DISK], DatanodeInfoWithStorage[127.0.0.1:44894,DS-7995ab6f-7680-4696-9474-d88c2d1fd2d8,DISK], DatanodeInfoWithStorage[127.0.0.1:41786,DS-56daf075-e33e-420a-93b6-5326e8a9e98e,DISK], DatanodeInfoWithStorage[127.0.0.1:33154,DS-f07bb4ad-36aa-4465-aae9-94ad25b6d0d9,DISK], DatanodeInfoWithStorage[127.0.0.1:43002,DS-bc3db8f5-e17e-4b2e-93f3-7bf735505cdf,DISK], DatanodeInfoWithStorage[127.0.0.1:42125,DS-243aff18-96f3-4990-8b4a-8a00a4b93103,DISK], DatanodeInfoWithStorage[127.0.0.1:35473,DS-f94e56e4-f343-492c-a517-a356fcae983d,DISK], DatanodeInfoWithStorage[127.0.0.1:38400,DS-5885f57a-1d34-4ac9-b06c-aafe0473a0fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1499760946-172.17.0.21-1598108961523:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39139,DS-ad97ca88-09da-459f-95e8-98fc56696281,DISK], DatanodeInfoWithStorage[127.0.0.1:36827,DS-11fa4fce-0249-4d4c-8b65-e02250575284,DISK], DatanodeInfoWithStorage[127.0.0.1:46250,DS-ca0027d4-b51f-4cce-adb4-a1db3b1c31d0,DISK], DatanodeInfoWithStorage[127.0.0.1:33546,DS-adcaa921-9cda-46bf-8209-c614252768d5,DISK], DatanodeInfoWithStorage[127.0.0.1:35702,DS-04202fad-af1d-4a9c-92be-5f749072b81c,DISK], DatanodeInfoWithStorage[127.0.0.1:33707,DS-32a5a650-75c5-4682-a094-d76225f31ba6,DISK], DatanodeInfoWithStorage[127.0.0.1:39400,DS-fecbbe9f-6bb0-48f1-8c7c-8a1481083042,DISK], DatanodeInfoWithStorage[127.0.0.1:46628,DS-fd9bd859-f34c-47e8-bab9-3a249f4d6eb7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1499760946-172.17.0.21-1598108961523:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39139,DS-ad97ca88-09da-459f-95e8-98fc56696281,DISK], DatanodeInfoWithStorage[127.0.0.1:36827,DS-11fa4fce-0249-4d4c-8b65-e02250575284,DISK], DatanodeInfoWithStorage[127.0.0.1:46250,DS-ca0027d4-b51f-4cce-adb4-a1db3b1c31d0,DISK], DatanodeInfoWithStorage[127.0.0.1:33546,DS-adcaa921-9cda-46bf-8209-c614252768d5,DISK], DatanodeInfoWithStorage[127.0.0.1:35702,DS-04202fad-af1d-4a9c-92be-5f749072b81c,DISK], DatanodeInfoWithStorage[127.0.0.1:33707,DS-32a5a650-75c5-4682-a094-d76225f31ba6,DISK], DatanodeInfoWithStorage[127.0.0.1:39400,DS-fecbbe9f-6bb0-48f1-8c7c-8a1481083042,DISK], DatanodeInfoWithStorage[127.0.0.1:46628,DS-fd9bd859-f34c-47e8-bab9-3a249f4d6eb7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-751200845-172.17.0.21-1598109035066:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41741,DS-e296d392-e3c6-42b6-9809-aae6f0b3fafa,DISK], DatanodeInfoWithStorage[127.0.0.1:37736,DS-866566e7-b8e5-42ff-a0f0-f1fa61ea40eb,DISK], DatanodeInfoWithStorage[127.0.0.1:39724,DS-78182b4c-8a58-466b-b86d-207c7634134a,DISK], DatanodeInfoWithStorage[127.0.0.1:32934,DS-14c1fa3d-5485-424c-a1d0-afde362f0b04,DISK], DatanodeInfoWithStorage[127.0.0.1:38103,DS-107534f4-d40b-439d-aa0b-21478dceaf52,DISK], DatanodeInfoWithStorage[127.0.0.1:46327,DS-f1cf513e-508e-45df-a83c-7c33d5936eb5,DISK], DatanodeInfoWithStorage[127.0.0.1:33029,DS-12d40429-cff0-4123-943b-d3f3d532fb51,DISK], DatanodeInfoWithStorage[127.0.0.1:39692,DS-bd2dde50-d1df-4cd1-ae19-bb8f91ea7519,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-751200845-172.17.0.21-1598109035066:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41741,DS-e296d392-e3c6-42b6-9809-aae6f0b3fafa,DISK], DatanodeInfoWithStorage[127.0.0.1:37736,DS-866566e7-b8e5-42ff-a0f0-f1fa61ea40eb,DISK], DatanodeInfoWithStorage[127.0.0.1:39724,DS-78182b4c-8a58-466b-b86d-207c7634134a,DISK], DatanodeInfoWithStorage[127.0.0.1:32934,DS-14c1fa3d-5485-424c-a1d0-afde362f0b04,DISK], DatanodeInfoWithStorage[127.0.0.1:38103,DS-107534f4-d40b-439d-aa0b-21478dceaf52,DISK], DatanodeInfoWithStorage[127.0.0.1:46327,DS-f1cf513e-508e-45df-a83c-7c33d5936eb5,DISK], DatanodeInfoWithStorage[127.0.0.1:33029,DS-12d40429-cff0-4123-943b-d3f3d532fb51,DISK], DatanodeInfoWithStorage[127.0.0.1:39692,DS-bd2dde50-d1df-4cd1-ae19-bb8f91ea7519,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-787531749-172.17.0.21-1598109434197:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43385,DS-7c5d3455-ab5a-4fa3-8759-2ead757626dc,DISK], DatanodeInfoWithStorage[127.0.0.1:43875,DS-373c882f-7f59-473d-93ee-8c1f08bf2fb9,DISK], DatanodeInfoWithStorage[127.0.0.1:39833,DS-ace74295-0a2c-4f54-8f74-44860a401b9d,DISK], DatanodeInfoWithStorage[127.0.0.1:45941,DS-cb33a61b-d013-4b9e-b54d-534cc13031e8,DISK], DatanodeInfoWithStorage[127.0.0.1:38755,DS-162711f7-4791-4079-b779-8fa51a4ee579,DISK], DatanodeInfoWithStorage[127.0.0.1:35619,DS-18d51e5c-47a1-47aa-b352-59d81cf9e6e2,DISK], DatanodeInfoWithStorage[127.0.0.1:36999,DS-77257d2d-8f5a-48a3-acb1-7fe2b9c0487e,DISK], DatanodeInfoWithStorage[127.0.0.1:44072,DS-14763c86-e8a1-47ca-91d7-5783008728ab,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-787531749-172.17.0.21-1598109434197:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43385,DS-7c5d3455-ab5a-4fa3-8759-2ead757626dc,DISK], DatanodeInfoWithStorage[127.0.0.1:43875,DS-373c882f-7f59-473d-93ee-8c1f08bf2fb9,DISK], DatanodeInfoWithStorage[127.0.0.1:39833,DS-ace74295-0a2c-4f54-8f74-44860a401b9d,DISK], DatanodeInfoWithStorage[127.0.0.1:45941,DS-cb33a61b-d013-4b9e-b54d-534cc13031e8,DISK], DatanodeInfoWithStorage[127.0.0.1:38755,DS-162711f7-4791-4079-b779-8fa51a4ee579,DISK], DatanodeInfoWithStorage[127.0.0.1:35619,DS-18d51e5c-47a1-47aa-b352-59d81cf9e6e2,DISK], DatanodeInfoWithStorage[127.0.0.1:36999,DS-77257d2d-8f5a-48a3-acb1-7fe2b9c0487e,DISK], DatanodeInfoWithStorage[127.0.0.1:44072,DS-14763c86-e8a1-47ca-91d7-5783008728ab,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1587111663-172.17.0.21-1598109542856:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37924,DS-9d309464-0791-45e8-bdd1-0fe68ca8d5df,DISK], DatanodeInfoWithStorage[127.0.0.1:43467,DS-31a871f1-8bbe-4d3a-b1e3-d2c6aa339694,DISK], DatanodeInfoWithStorage[127.0.0.1:40866,DS-a5951808-e87e-4800-a103-d28fc3432611,DISK], DatanodeInfoWithStorage[127.0.0.1:44976,DS-6730dae9-95d4-40a8-a34e-ef96a30e1e56,DISK], DatanodeInfoWithStorage[127.0.0.1:43124,DS-d814fa1d-8e79-4083-a847-bc736fc741a0,DISK], DatanodeInfoWithStorage[127.0.0.1:33267,DS-de8bb7b4-7723-420f-b5ed-df455c878cd0,DISK], DatanodeInfoWithStorage[127.0.0.1:39512,DS-6026c26e-6885-4b9c-948e-503f1c588517,DISK], DatanodeInfoWithStorage[127.0.0.1:46531,DS-ff01b1e1-2a6b-4405-b6d8-5fa086e09421,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1587111663-172.17.0.21-1598109542856:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37924,DS-9d309464-0791-45e8-bdd1-0fe68ca8d5df,DISK], DatanodeInfoWithStorage[127.0.0.1:43467,DS-31a871f1-8bbe-4d3a-b1e3-d2c6aa339694,DISK], DatanodeInfoWithStorage[127.0.0.1:40866,DS-a5951808-e87e-4800-a103-d28fc3432611,DISK], DatanodeInfoWithStorage[127.0.0.1:44976,DS-6730dae9-95d4-40a8-a34e-ef96a30e1e56,DISK], DatanodeInfoWithStorage[127.0.0.1:43124,DS-d814fa1d-8e79-4083-a847-bc736fc741a0,DISK], DatanodeInfoWithStorage[127.0.0.1:33267,DS-de8bb7b4-7723-420f-b5ed-df455c878cd0,DISK], DatanodeInfoWithStorage[127.0.0.1:39512,DS-6026c26e-6885-4b9c-948e-503f1c588517,DISK], DatanodeInfoWithStorage[127.0.0.1:46531,DS-ff01b1e1-2a6b-4405-b6d8-5fa086e09421,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1663793850-172.17.0.21-1598109624328:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37517,DS-08788bf8-9929-47a2-8fcd-066e6e466305,DISK], DatanodeInfoWithStorage[127.0.0.1:35932,DS-1683b5d7-c783-4ba1-a1c3-936b5905a6ed,DISK], DatanodeInfoWithStorage[127.0.0.1:45256,DS-ddf70979-3b3d-4775-b5d4-ac40fdaf3c62,DISK], DatanodeInfoWithStorage[127.0.0.1:38785,DS-2cd4ac74-00b7-471b-9cb6-a8636db3efd6,DISK], DatanodeInfoWithStorage[127.0.0.1:46119,DS-0529fb01-71a0-413e-bdd0-51a540166fcd,DISK], DatanodeInfoWithStorage[127.0.0.1:43238,DS-103fa52a-dea9-466a-960c-481ad0340248,DISK], DatanodeInfoWithStorage[127.0.0.1:46580,DS-58507d82-bf66-4f07-80f1-28239647805d,DISK], DatanodeInfoWithStorage[127.0.0.1:35664,DS-d139e3a9-3ed7-454b-8bda-172ed3e2d9dc,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1663793850-172.17.0.21-1598109624328:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37517,DS-08788bf8-9929-47a2-8fcd-066e6e466305,DISK], DatanodeInfoWithStorage[127.0.0.1:35932,DS-1683b5d7-c783-4ba1-a1c3-936b5905a6ed,DISK], DatanodeInfoWithStorage[127.0.0.1:45256,DS-ddf70979-3b3d-4775-b5d4-ac40fdaf3c62,DISK], DatanodeInfoWithStorage[127.0.0.1:38785,DS-2cd4ac74-00b7-471b-9cb6-a8636db3efd6,DISK], DatanodeInfoWithStorage[127.0.0.1:46119,DS-0529fb01-71a0-413e-bdd0-51a540166fcd,DISK], DatanodeInfoWithStorage[127.0.0.1:43238,DS-103fa52a-dea9-466a-960c-481ad0340248,DISK], DatanodeInfoWithStorage[127.0.0.1:46580,DS-58507d82-bf66-4f07-80f1-28239647805d,DISK], DatanodeInfoWithStorage[127.0.0.1:35664,DS-d139e3a9-3ed7-454b-8bda-172ed3e2d9dc,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1725460035-172.17.0.21-1598109824674:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39592,DS-7d805d99-4a08-4d41-a36a-b129fba327be,DISK], DatanodeInfoWithStorage[127.0.0.1:44773,DS-af13080c-3fdc-4eb2-81f0-e28c23d00d2a,DISK], DatanodeInfoWithStorage[127.0.0.1:33039,DS-1ee6d070-fc16-47c8-b49e-9b33582d4bb5,DISK], DatanodeInfoWithStorage[127.0.0.1:45810,DS-1fac5d82-54d0-4e63-b0c5-1ad5739134b8,DISK], DatanodeInfoWithStorage[127.0.0.1:39197,DS-68a4e320-50c1-4542-ac05-20dacf1ffb21,DISK], DatanodeInfoWithStorage[127.0.0.1:42064,DS-c8dd941f-b6bf-4074-9f85-a783838e6f0d,DISK], DatanodeInfoWithStorage[127.0.0.1:36715,DS-4863d1a5-505c-4aa3-97cb-be293bb51c17,DISK], DatanodeInfoWithStorage[127.0.0.1:45710,DS-93a86118-ea47-4ba2-b747-4ae72bdad3a4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1725460035-172.17.0.21-1598109824674:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39592,DS-7d805d99-4a08-4d41-a36a-b129fba327be,DISK], DatanodeInfoWithStorage[127.0.0.1:44773,DS-af13080c-3fdc-4eb2-81f0-e28c23d00d2a,DISK], DatanodeInfoWithStorage[127.0.0.1:33039,DS-1ee6d070-fc16-47c8-b49e-9b33582d4bb5,DISK], DatanodeInfoWithStorage[127.0.0.1:45810,DS-1fac5d82-54d0-4e63-b0c5-1ad5739134b8,DISK], DatanodeInfoWithStorage[127.0.0.1:39197,DS-68a4e320-50c1-4542-ac05-20dacf1ffb21,DISK], DatanodeInfoWithStorage[127.0.0.1:42064,DS-c8dd941f-b6bf-4074-9f85-a783838e6f0d,DISK], DatanodeInfoWithStorage[127.0.0.1:36715,DS-4863d1a5-505c-4aa3-97cb-be293bb51c17,DISK], DatanodeInfoWithStorage[127.0.0.1:45710,DS-93a86118-ea47-4ba2-b747-4ae72bdad3a4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-207897534-172.17.0.21-1598110175631:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34445,DS-ca87bca0-51f9-415f-9538-724ec65f9642,DISK], DatanodeInfoWithStorage[127.0.0.1:34873,DS-02b8c740-9b2f-465b-9b1c-9986839c61e3,DISK], DatanodeInfoWithStorage[127.0.0.1:34004,DS-b874433d-79a4-4bbd-a7a7-5308e950ba7a,DISK], DatanodeInfoWithStorage[127.0.0.1:34537,DS-a7ccbe5d-c343-4c62-afb5-9998eff31b7c,DISK], DatanodeInfoWithStorage[127.0.0.1:35511,DS-925fab08-a9d5-4fea-8576-4cad68dd4187,DISK], DatanodeInfoWithStorage[127.0.0.1:44540,DS-2ac897cb-e2ec-459a-9fef-93a01ba33d5d,DISK], DatanodeInfoWithStorage[127.0.0.1:39222,DS-6c7cd22f-2ed8-4d4d-a366-b4cef4de454a,DISK], DatanodeInfoWithStorage[127.0.0.1:39370,DS-82e5e4c4-56a5-4f48-a364-9f249d1fb5ba,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-207897534-172.17.0.21-1598110175631:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34445,DS-ca87bca0-51f9-415f-9538-724ec65f9642,DISK], DatanodeInfoWithStorage[127.0.0.1:34873,DS-02b8c740-9b2f-465b-9b1c-9986839c61e3,DISK], DatanodeInfoWithStorage[127.0.0.1:34004,DS-b874433d-79a4-4bbd-a7a7-5308e950ba7a,DISK], DatanodeInfoWithStorage[127.0.0.1:34537,DS-a7ccbe5d-c343-4c62-afb5-9998eff31b7c,DISK], DatanodeInfoWithStorage[127.0.0.1:35511,DS-925fab08-a9d5-4fea-8576-4cad68dd4187,DISK], DatanodeInfoWithStorage[127.0.0.1:44540,DS-2ac897cb-e2ec-459a-9fef-93a01ba33d5d,DISK], DatanodeInfoWithStorage[127.0.0.1:39222,DS-6c7cd22f-2ed8-4d4d-a366-b4cef4de454a,DISK], DatanodeInfoWithStorage[127.0.0.1:39370,DS-82e5e4c4-56a5-4f48-a364-9f249d1fb5ba,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-954299149-172.17.0.21-1598110804560:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46290,DS-4e3b1f5e-2d32-4b86-902c-9b174089453b,DISK], DatanodeInfoWithStorage[127.0.0.1:37567,DS-4e4842fa-8bd5-451f-8f64-f3ef38115df2,DISK], DatanodeInfoWithStorage[127.0.0.1:36379,DS-f3fb47a7-829d-4b63-b442-9e08693aba3b,DISK], DatanodeInfoWithStorage[127.0.0.1:34777,DS-506ab5b5-057d-4540-90d6-2739e64cf77e,DISK], DatanodeInfoWithStorage[127.0.0.1:40292,DS-86789e35-e59d-4a55-91ed-f6599446eee2,DISK], DatanodeInfoWithStorage[127.0.0.1:41879,DS-262529ce-71e8-41f9-9242-fcbfdd707410,DISK], DatanodeInfoWithStorage[127.0.0.1:39562,DS-d8a87737-1ab8-49c7-88eb-f99dcc317b9e,DISK], DatanodeInfoWithStorage[127.0.0.1:38129,DS-2ccc2dab-63df-4715-8984-9f0dacd60368,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-954299149-172.17.0.21-1598110804560:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46290,DS-4e3b1f5e-2d32-4b86-902c-9b174089453b,DISK], DatanodeInfoWithStorage[127.0.0.1:37567,DS-4e4842fa-8bd5-451f-8f64-f3ef38115df2,DISK], DatanodeInfoWithStorage[127.0.0.1:36379,DS-f3fb47a7-829d-4b63-b442-9e08693aba3b,DISK], DatanodeInfoWithStorage[127.0.0.1:34777,DS-506ab5b5-057d-4540-90d6-2739e64cf77e,DISK], DatanodeInfoWithStorage[127.0.0.1:40292,DS-86789e35-e59d-4a55-91ed-f6599446eee2,DISK], DatanodeInfoWithStorage[127.0.0.1:41879,DS-262529ce-71e8-41f9-9242-fcbfdd707410,DISK], DatanodeInfoWithStorage[127.0.0.1:39562,DS-d8a87737-1ab8-49c7-88eb-f99dcc317b9e,DISK], DatanodeInfoWithStorage[127.0.0.1:38129,DS-2ccc2dab-63df-4715-8984-9f0dacd60368,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-156197747-172.17.0.21-1598110886746:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40215,DS-f38836c3-6d3b-4bf3-a9b1-d52e03a95318,DISK], DatanodeInfoWithStorage[127.0.0.1:45711,DS-f9944722-7b2f-4f8b-990b-b47406c6ef17,DISK], DatanodeInfoWithStorage[127.0.0.1:39702,DS-131645f8-6926-4201-a363-b8b9129c041e,DISK], DatanodeInfoWithStorage[127.0.0.1:34596,DS-b0b10fd0-a97a-419b-b8cd-ef0e6d3127b6,DISK], DatanodeInfoWithStorage[127.0.0.1:36928,DS-f7534739-f044-4f52-bd27-ff970b4dce63,DISK], DatanodeInfoWithStorage[127.0.0.1:42454,DS-753f483b-b0af-4180-a3ae-861d1e0607cc,DISK], DatanodeInfoWithStorage[127.0.0.1:42998,DS-50cb7f9f-1e45-48c5-bf63-887f0cc44c9e,DISK], DatanodeInfoWithStorage[127.0.0.1:39851,DS-e1997d26-b1b7-4ef5-b729-8dade9c70b3c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-156197747-172.17.0.21-1598110886746:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40215,DS-f38836c3-6d3b-4bf3-a9b1-d52e03a95318,DISK], DatanodeInfoWithStorage[127.0.0.1:45711,DS-f9944722-7b2f-4f8b-990b-b47406c6ef17,DISK], DatanodeInfoWithStorage[127.0.0.1:39702,DS-131645f8-6926-4201-a363-b8b9129c041e,DISK], DatanodeInfoWithStorage[127.0.0.1:34596,DS-b0b10fd0-a97a-419b-b8cd-ef0e6d3127b6,DISK], DatanodeInfoWithStorage[127.0.0.1:36928,DS-f7534739-f044-4f52-bd27-ff970b4dce63,DISK], DatanodeInfoWithStorage[127.0.0.1:42454,DS-753f483b-b0af-4180-a3ae-861d1e0607cc,DISK], DatanodeInfoWithStorage[127.0.0.1:42998,DS-50cb7f9f-1e45-48c5-bf63-887f0cc44c9e,DISK], DatanodeInfoWithStorage[127.0.0.1:39851,DS-e1997d26-b1b7-4ef5-b729-8dade9c70b3c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-268373335-172.17.0.21-1598110921400:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36130,DS-4e1e26c4-5939-45b7-bd56-d862d0e7714e,DISK], DatanodeInfoWithStorage[127.0.0.1:33223,DS-30e43f3a-6a86-4b50-9678-c06648e1a15f,DISK], DatanodeInfoWithStorage[127.0.0.1:38621,DS-e12a9bbb-319d-4dd6-8b4a-7b49fa24ff5a,DISK], DatanodeInfoWithStorage[127.0.0.1:44417,DS-42ee4d5a-7ea9-4f23-ae82-ed0a5ab8fcdf,DISK], DatanodeInfoWithStorage[127.0.0.1:36822,DS-a6021109-6475-48f2-a15f-22e1a6549c49,DISK], DatanodeInfoWithStorage[127.0.0.1:41266,DS-fb39854c-fb47-425e-83c4-706e39417ecf,DISK], DatanodeInfoWithStorage[127.0.0.1:40040,DS-66527693-8da3-4ec4-be3a-2f08c9e74715,DISK], DatanodeInfoWithStorage[127.0.0.1:32778,DS-073d6953-0d63-48b8-9117-52b2857495e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-268373335-172.17.0.21-1598110921400:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36130,DS-4e1e26c4-5939-45b7-bd56-d862d0e7714e,DISK], DatanodeInfoWithStorage[127.0.0.1:33223,DS-30e43f3a-6a86-4b50-9678-c06648e1a15f,DISK], DatanodeInfoWithStorage[127.0.0.1:38621,DS-e12a9bbb-319d-4dd6-8b4a-7b49fa24ff5a,DISK], DatanodeInfoWithStorage[127.0.0.1:44417,DS-42ee4d5a-7ea9-4f23-ae82-ed0a5ab8fcdf,DISK], DatanodeInfoWithStorage[127.0.0.1:36822,DS-a6021109-6475-48f2-a15f-22e1a6549c49,DISK], DatanodeInfoWithStorage[127.0.0.1:41266,DS-fb39854c-fb47-425e-83c4-706e39417ecf,DISK], DatanodeInfoWithStorage[127.0.0.1:40040,DS-66527693-8da3-4ec4-be3a-2f08c9e74715,DISK], DatanodeInfoWithStorage[127.0.0.1:32778,DS-073d6953-0d63-48b8-9117-52b2857495e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1783250177-172.17.0.21-1598111259811:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44651,DS-864f38f9-5eae-48d1-8aa7-f803f034dce9,DISK], DatanodeInfoWithStorage[127.0.0.1:32968,DS-c90f2ae2-278f-4e24-a2e8-5db466a3a5d2,DISK], DatanodeInfoWithStorage[127.0.0.1:34742,DS-e45345e2-029e-4148-9d20-db4425c06e5c,DISK], DatanodeInfoWithStorage[127.0.0.1:41543,DS-4168909c-9630-4596-9dc2-beccd9d64280,DISK], DatanodeInfoWithStorage[127.0.0.1:45316,DS-57fce0ec-7bac-42a0-8c3c-e68f1bf53dfa,DISK], DatanodeInfoWithStorage[127.0.0.1:41282,DS-c40bd699-89a2-4b0d-a856-fc08c2af3a2c,DISK], DatanodeInfoWithStorage[127.0.0.1:35609,DS-f1eda783-4b10-498d-992a-4f01af091f7a,DISK], DatanodeInfoWithStorage[127.0.0.1:39501,DS-33f93d03-6f43-48fe-8a7b-2496cf5f3157,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1783250177-172.17.0.21-1598111259811:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44651,DS-864f38f9-5eae-48d1-8aa7-f803f034dce9,DISK], DatanodeInfoWithStorage[127.0.0.1:32968,DS-c90f2ae2-278f-4e24-a2e8-5db466a3a5d2,DISK], DatanodeInfoWithStorage[127.0.0.1:34742,DS-e45345e2-029e-4148-9d20-db4425c06e5c,DISK], DatanodeInfoWithStorage[127.0.0.1:41543,DS-4168909c-9630-4596-9dc2-beccd9d64280,DISK], DatanodeInfoWithStorage[127.0.0.1:45316,DS-57fce0ec-7bac-42a0-8c3c-e68f1bf53dfa,DISK], DatanodeInfoWithStorage[127.0.0.1:41282,DS-c40bd699-89a2-4b0d-a856-fc08c2af3a2c,DISK], DatanodeInfoWithStorage[127.0.0.1:35609,DS-f1eda783-4b10-498d-992a-4f01af091f7a,DISK], DatanodeInfoWithStorage[127.0.0.1:39501,DS-33f93d03-6f43-48fe-8a7b-2496cf5f3157,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1601477712-172.17.0.21-1598111292410:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35696,DS-2ea5e9c7-d282-4f8e-bd4d-7c04bff35244,DISK], DatanodeInfoWithStorage[127.0.0.1:46209,DS-78e1340f-b7a8-4a37-acca-39bb47d88572,DISK], DatanodeInfoWithStorage[127.0.0.1:46404,DS-da0fa0a4-fe62-41f3-8b76-ec98a20b0ec3,DISK], DatanodeInfoWithStorage[127.0.0.1:37046,DS-b8a7ee97-3f8d-40ea-bdb7-614173420186,DISK], DatanodeInfoWithStorage[127.0.0.1:43018,DS-8d4155ec-1446-4490-805c-5bd67ed43ecc,DISK], DatanodeInfoWithStorage[127.0.0.1:40998,DS-1dc9cb91-d1c6-4358-b154-1467a60536c3,DISK], DatanodeInfoWithStorage[127.0.0.1:33943,DS-923c42ec-1b62-488b-b03c-73154d1372d4,DISK], DatanodeInfoWithStorage[127.0.0.1:46154,DS-b424a5a6-d7ca-4862-9c0f-32c7a6248438,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1601477712-172.17.0.21-1598111292410:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35696,DS-2ea5e9c7-d282-4f8e-bd4d-7c04bff35244,DISK], DatanodeInfoWithStorage[127.0.0.1:46209,DS-78e1340f-b7a8-4a37-acca-39bb47d88572,DISK], DatanodeInfoWithStorage[127.0.0.1:46404,DS-da0fa0a4-fe62-41f3-8b76-ec98a20b0ec3,DISK], DatanodeInfoWithStorage[127.0.0.1:37046,DS-b8a7ee97-3f8d-40ea-bdb7-614173420186,DISK], DatanodeInfoWithStorage[127.0.0.1:43018,DS-8d4155ec-1446-4490-805c-5bd67ed43ecc,DISK], DatanodeInfoWithStorage[127.0.0.1:40998,DS-1dc9cb91-d1c6-4358-b154-1467a60536c3,DISK], DatanodeInfoWithStorage[127.0.0.1:33943,DS-923c42ec-1b62-488b-b03c-73154d1372d4,DISK], DatanodeInfoWithStorage[127.0.0.1:46154,DS-b424a5a6-d7ca-4862-9c0f-32c7a6248438,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1294136384-172.17.0.21-1598111324162:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33423,DS-5c232337-26f3-428e-97af-2a08d380dd8c,DISK], DatanodeInfoWithStorage[127.0.0.1:36659,DS-8e680e01-b146-4a4f-bfd8-d0936299b0db,DISK], DatanodeInfoWithStorage[127.0.0.1:36365,DS-65aa4f59-eb0c-47ac-864f-7b0ed146ddb0,DISK], DatanodeInfoWithStorage[127.0.0.1:45441,DS-34ae603e-0c08-4cc6-810a-41d0b2516550,DISK], DatanodeInfoWithStorage[127.0.0.1:39576,DS-436d8822-4a5a-4c90-b286-1dde5c6236c8,DISK], DatanodeInfoWithStorage[127.0.0.1:42193,DS-a599709f-3ca1-4323-a2c2-6e4fa57b569c,DISK], DatanodeInfoWithStorage[127.0.0.1:33246,DS-6e2b6443-3f93-4a59-932a-f9527f00534e,DISK], DatanodeInfoWithStorage[127.0.0.1:36345,DS-7c77a237-502b-4c40-8d33-ea52a84d454c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1294136384-172.17.0.21-1598111324162:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33423,DS-5c232337-26f3-428e-97af-2a08d380dd8c,DISK], DatanodeInfoWithStorage[127.0.0.1:36659,DS-8e680e01-b146-4a4f-bfd8-d0936299b0db,DISK], DatanodeInfoWithStorage[127.0.0.1:36365,DS-65aa4f59-eb0c-47ac-864f-7b0ed146ddb0,DISK], DatanodeInfoWithStorage[127.0.0.1:45441,DS-34ae603e-0c08-4cc6-810a-41d0b2516550,DISK], DatanodeInfoWithStorage[127.0.0.1:39576,DS-436d8822-4a5a-4c90-b286-1dde5c6236c8,DISK], DatanodeInfoWithStorage[127.0.0.1:42193,DS-a599709f-3ca1-4323-a2c2-6e4fa57b569c,DISK], DatanodeInfoWithStorage[127.0.0.1:33246,DS-6e2b6443-3f93-4a59-932a-f9527f00534e,DISK], DatanodeInfoWithStorage[127.0.0.1:36345,DS-7c77a237-502b-4c40-8d33-ea52a84d454c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1179462558-172.17.0.21-1598111429167:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45908,DS-5ab4e8b4-a2b2-4170-b341-607ac45bab6a,DISK], DatanodeInfoWithStorage[127.0.0.1:33576,DS-d9cab48a-0cd0-4d8b-ab43-8c244455d89c,DISK], DatanodeInfoWithStorage[127.0.0.1:46711,DS-b4177edb-9372-47a9-92e2-ebdff5fa9a49,DISK], DatanodeInfoWithStorage[127.0.0.1:37092,DS-40542a89-2173-40a8-a6f7-1749ccce64ac,DISK], DatanodeInfoWithStorage[127.0.0.1:38531,DS-ff34da14-0e68-4ab3-8614-9f8aa9bca013,DISK], DatanodeInfoWithStorage[127.0.0.1:36105,DS-e208cd54-4edb-4fbc-bfa9-cb4be811e3c7,DISK], DatanodeInfoWithStorage[127.0.0.1:37842,DS-9b0a4ad2-806e-4410-931c-dcb99127db9d,DISK], DatanodeInfoWithStorage[127.0.0.1:43042,DS-579f3720-c76e-4bf8-9496-dff5c927c87f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1179462558-172.17.0.21-1598111429167:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45908,DS-5ab4e8b4-a2b2-4170-b341-607ac45bab6a,DISK], DatanodeInfoWithStorage[127.0.0.1:33576,DS-d9cab48a-0cd0-4d8b-ab43-8c244455d89c,DISK], DatanodeInfoWithStorage[127.0.0.1:46711,DS-b4177edb-9372-47a9-92e2-ebdff5fa9a49,DISK], DatanodeInfoWithStorage[127.0.0.1:37092,DS-40542a89-2173-40a8-a6f7-1749ccce64ac,DISK], DatanodeInfoWithStorage[127.0.0.1:38531,DS-ff34da14-0e68-4ab3-8614-9f8aa9bca013,DISK], DatanodeInfoWithStorage[127.0.0.1:36105,DS-e208cd54-4edb-4fbc-bfa9-cb4be811e3c7,DISK], DatanodeInfoWithStorage[127.0.0.1:37842,DS-9b0a4ad2-806e-4410-931c-dcb99127db9d,DISK], DatanodeInfoWithStorage[127.0.0.1:43042,DS-579f3720-c76e-4bf8-9496-dff5c927c87f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1084762767-172.17.0.21-1598111506044:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39029,DS-823fdc53-73c5-453b-867d-4956ef761544,DISK], DatanodeInfoWithStorage[127.0.0.1:38412,DS-17fd23ec-86a7-45f4-8714-a6f9b091d848,DISK], DatanodeInfoWithStorage[127.0.0.1:44948,DS-8ff8e098-525d-4abc-99e6-9c9cf981f04d,DISK], DatanodeInfoWithStorage[127.0.0.1:44307,DS-62f35b5c-98aa-4f32-9dfa-d4f6f13396ee,DISK], DatanodeInfoWithStorage[127.0.0.1:36859,DS-61685e51-e5af-4091-92ad-dde497336d3d,DISK], DatanodeInfoWithStorage[127.0.0.1:39550,DS-a8eee57c-24bf-4710-b4b0-69725da0e66a,DISK], DatanodeInfoWithStorage[127.0.0.1:37941,DS-229cf9ff-6da6-494c-98e4-c4a72675ded7,DISK], DatanodeInfoWithStorage[127.0.0.1:33859,DS-64a090c9-0615-4e89-8ea4-5debb9d15933,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1084762767-172.17.0.21-1598111506044:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39029,DS-823fdc53-73c5-453b-867d-4956ef761544,DISK], DatanodeInfoWithStorage[127.0.0.1:38412,DS-17fd23ec-86a7-45f4-8714-a6f9b091d848,DISK], DatanodeInfoWithStorage[127.0.0.1:44948,DS-8ff8e098-525d-4abc-99e6-9c9cf981f04d,DISK], DatanodeInfoWithStorage[127.0.0.1:44307,DS-62f35b5c-98aa-4f32-9dfa-d4f6f13396ee,DISK], DatanodeInfoWithStorage[127.0.0.1:36859,DS-61685e51-e5af-4091-92ad-dde497336d3d,DISK], DatanodeInfoWithStorage[127.0.0.1:39550,DS-a8eee57c-24bf-4710-b4b0-69725da0e66a,DISK], DatanodeInfoWithStorage[127.0.0.1:37941,DS-229cf9ff-6da6-494c-98e4-c4a72675ded7,DISK], DatanodeInfoWithStorage[127.0.0.1:33859,DS-64a090c9-0615-4e89-8ea4-5debb9d15933,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-852263757-172.17.0.21-1598111541703:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39616,DS-d6f381a1-11e7-43dd-9e00-9ac327893ba4,DISK], DatanodeInfoWithStorage[127.0.0.1:42907,DS-8dca3de6-a8b6-4546-b4a2-1d1ef6a9f7a1,DISK], DatanodeInfoWithStorage[127.0.0.1:38776,DS-16d0f7c0-4398-46fe-9f26-2ddae393b049,DISK], DatanodeInfoWithStorage[127.0.0.1:42832,DS-eb8158fa-1077-4f46-9118-79cd8528841b,DISK], DatanodeInfoWithStorage[127.0.0.1:40370,DS-73d6cbc3-9268-492c-9403-96695072d655,DISK], DatanodeInfoWithStorage[127.0.0.1:37467,DS-059a6be3-6424-4507-a529-87d55701f108,DISK], DatanodeInfoWithStorage[127.0.0.1:40498,DS-4b15e811-c2c9-453f-b82c-eeb3ede128a2,DISK], DatanodeInfoWithStorage[127.0.0.1:39243,DS-591e59ac-dc88-47e7-8f83-16e3886e5bd6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-852263757-172.17.0.21-1598111541703:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39616,DS-d6f381a1-11e7-43dd-9e00-9ac327893ba4,DISK], DatanodeInfoWithStorage[127.0.0.1:42907,DS-8dca3de6-a8b6-4546-b4a2-1d1ef6a9f7a1,DISK], DatanodeInfoWithStorage[127.0.0.1:38776,DS-16d0f7c0-4398-46fe-9f26-2ddae393b049,DISK], DatanodeInfoWithStorage[127.0.0.1:42832,DS-eb8158fa-1077-4f46-9118-79cd8528841b,DISK], DatanodeInfoWithStorage[127.0.0.1:40370,DS-73d6cbc3-9268-492c-9403-96695072d655,DISK], DatanodeInfoWithStorage[127.0.0.1:37467,DS-059a6be3-6424-4507-a529-87d55701f108,DISK], DatanodeInfoWithStorage[127.0.0.1:40498,DS-4b15e811-c2c9-453f-b82c-eeb3ede128a2,DISK], DatanodeInfoWithStorage[127.0.0.1:39243,DS-591e59ac-dc88-47e7-8f83-16e3886e5bd6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-354224385-172.17.0.21-1598111620192:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40759,DS-baaaf21b-a5c3-4afd-b23b-be5ba4b7cd76,DISK], DatanodeInfoWithStorage[127.0.0.1:33666,DS-a67ffc38-9496-441d-b74c-3624e712f0ae,DISK], DatanodeInfoWithStorage[127.0.0.1:34012,DS-30a3f222-ace6-4cbd-8285-29e9b15f6fc5,DISK], DatanodeInfoWithStorage[127.0.0.1:36507,DS-260d5392-c670-4afd-8e57-0bfee79bb347,DISK], DatanodeInfoWithStorage[127.0.0.1:37242,DS-cb786a9e-c29a-4f8b-9828-82a33d1ce73d,DISK], DatanodeInfoWithStorage[127.0.0.1:43208,DS-d242fdf7-8e00-4be1-a51e-a7e98fbbf59c,DISK], DatanodeInfoWithStorage[127.0.0.1:35499,DS-0f705640-cd5c-4c40-b39a-f44e08d5c16f,DISK], DatanodeInfoWithStorage[127.0.0.1:36643,DS-8aeecce9-5d60-4db3-a19b-8874d5918042,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-354224385-172.17.0.21-1598111620192:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40759,DS-baaaf21b-a5c3-4afd-b23b-be5ba4b7cd76,DISK], DatanodeInfoWithStorage[127.0.0.1:33666,DS-a67ffc38-9496-441d-b74c-3624e712f0ae,DISK], DatanodeInfoWithStorage[127.0.0.1:34012,DS-30a3f222-ace6-4cbd-8285-29e9b15f6fc5,DISK], DatanodeInfoWithStorage[127.0.0.1:36507,DS-260d5392-c670-4afd-8e57-0bfee79bb347,DISK], DatanodeInfoWithStorage[127.0.0.1:37242,DS-cb786a9e-c29a-4f8b-9828-82a33d1ce73d,DISK], DatanodeInfoWithStorage[127.0.0.1:43208,DS-d242fdf7-8e00-4be1-a51e-a7e98fbbf59c,DISK], DatanodeInfoWithStorage[127.0.0.1:35499,DS-0f705640-cd5c-4c40-b39a-f44e08d5c16f,DISK], DatanodeInfoWithStorage[127.0.0.1:36643,DS-8aeecce9-5d60-4db3-a19b-8874d5918042,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-784820010-172.17.0.21-1598111655875:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36960,DS-cbd89bf1-d05d-4ac4-bdce-4f183af7c18e,DISK], DatanodeInfoWithStorage[127.0.0.1:39677,DS-1ae10e31-a156-4177-bac8-1060c5490808,DISK], DatanodeInfoWithStorage[127.0.0.1:43674,DS-e9b2bea7-2fa1-491c-a09f-70e85a035ea3,DISK], DatanodeInfoWithStorage[127.0.0.1:35726,DS-bb330974-afc4-4956-9912-1dcabcb3904c,DISK], DatanodeInfoWithStorage[127.0.0.1:41214,DS-627fa4d7-6bd4-4a2f-9e7c-f88c715fb08b,DISK], DatanodeInfoWithStorage[127.0.0.1:45866,DS-696d54ef-8d79-492d-81a4-100359c1299d,DISK], DatanodeInfoWithStorage[127.0.0.1:44484,DS-8dc58713-8f07-4661-97ea-f57775b8f1cb,DISK], DatanodeInfoWithStorage[127.0.0.1:45916,DS-fb3e4bfd-1570-4fae-8317-147f8c645525,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-784820010-172.17.0.21-1598111655875:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36960,DS-cbd89bf1-d05d-4ac4-bdce-4f183af7c18e,DISK], DatanodeInfoWithStorage[127.0.0.1:39677,DS-1ae10e31-a156-4177-bac8-1060c5490808,DISK], DatanodeInfoWithStorage[127.0.0.1:43674,DS-e9b2bea7-2fa1-491c-a09f-70e85a035ea3,DISK], DatanodeInfoWithStorage[127.0.0.1:35726,DS-bb330974-afc4-4956-9912-1dcabcb3904c,DISK], DatanodeInfoWithStorage[127.0.0.1:41214,DS-627fa4d7-6bd4-4a2f-9e7c-f88c715fb08b,DISK], DatanodeInfoWithStorage[127.0.0.1:45866,DS-696d54ef-8d79-492d-81a4-100359c1299d,DISK], DatanodeInfoWithStorage[127.0.0.1:44484,DS-8dc58713-8f07-4661-97ea-f57775b8f1cb,DISK], DatanodeInfoWithStorage[127.0.0.1:45916,DS-fb3e4bfd-1570-4fae-8317-147f8c645525,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1174071713-172.17.0.21-1598111734970:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40471,DS-0cc104e1-dfe1-4a12-9117-8e9799b328f2,DISK], DatanodeInfoWithStorage[127.0.0.1:32927,DS-996808c5-b4d8-40ed-98ef-6c67ae0d3975,DISK], DatanodeInfoWithStorage[127.0.0.1:46029,DS-7523e253-9bdb-441f-85d8-75e7d4f49c2e,DISK], DatanodeInfoWithStorage[127.0.0.1:45876,DS-e9cdc325-2125-4de9-8da8-571434761e9d,DISK], DatanodeInfoWithStorage[127.0.0.1:46247,DS-b422c24f-af37-4b3b-8d6e-211270e5fe47,DISK], DatanodeInfoWithStorage[127.0.0.1:37314,DS-5e7345e0-bf65-4154-b6e9-79c404e27b01,DISK], DatanodeInfoWithStorage[127.0.0.1:37309,DS-0e186f34-478f-4494-a2c4-99d62f861168,DISK], DatanodeInfoWithStorage[127.0.0.1:38788,DS-3e2d20ff-8f4f-46c3-9959-d57c299301ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1174071713-172.17.0.21-1598111734970:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40471,DS-0cc104e1-dfe1-4a12-9117-8e9799b328f2,DISK], DatanodeInfoWithStorage[127.0.0.1:32927,DS-996808c5-b4d8-40ed-98ef-6c67ae0d3975,DISK], DatanodeInfoWithStorage[127.0.0.1:46029,DS-7523e253-9bdb-441f-85d8-75e7d4f49c2e,DISK], DatanodeInfoWithStorage[127.0.0.1:45876,DS-e9cdc325-2125-4de9-8da8-571434761e9d,DISK], DatanodeInfoWithStorage[127.0.0.1:46247,DS-b422c24f-af37-4b3b-8d6e-211270e5fe47,DISK], DatanodeInfoWithStorage[127.0.0.1:37314,DS-5e7345e0-bf65-4154-b6e9-79c404e27b01,DISK], DatanodeInfoWithStorage[127.0.0.1:37309,DS-0e186f34-478f-4494-a2c4-99d62f861168,DISK], DatanodeInfoWithStorage[127.0.0.1:38788,DS-3e2d20ff-8f4f-46c3-9959-d57c299301ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-265219441-172.17.0.21-1598111784225:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42268,DS-590c3c9e-fbc4-44d8-8fd0-548de3fa9f77,DISK], DatanodeInfoWithStorage[127.0.0.1:45040,DS-08aca021-b4bc-41e7-b455-08c7dab0e7f4,DISK], DatanodeInfoWithStorage[127.0.0.1:33980,DS-22b469ae-39d5-4fc5-9a46-c958f58b92c2,DISK], DatanodeInfoWithStorage[127.0.0.1:37664,DS-d370aedb-c987-49ba-9aa0-6d6028823272,DISK], DatanodeInfoWithStorage[127.0.0.1:40713,DS-3776e598-697b-4d4f-9aa8-e99287b6685d,DISK], DatanodeInfoWithStorage[127.0.0.1:45069,DS-38e6071b-5517-4c43-869f-e7382a4024fb,DISK], DatanodeInfoWithStorage[127.0.0.1:37364,DS-14aa002c-99be-47c3-955a-2b2fb66b98f0,DISK], DatanodeInfoWithStorage[127.0.0.1:39099,DS-ef9e8dac-0eea-4161-a3cb-10df04209d5b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-265219441-172.17.0.21-1598111784225:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42268,DS-590c3c9e-fbc4-44d8-8fd0-548de3fa9f77,DISK], DatanodeInfoWithStorage[127.0.0.1:45040,DS-08aca021-b4bc-41e7-b455-08c7dab0e7f4,DISK], DatanodeInfoWithStorage[127.0.0.1:33980,DS-22b469ae-39d5-4fc5-9a46-c958f58b92c2,DISK], DatanodeInfoWithStorage[127.0.0.1:37664,DS-d370aedb-c987-49ba-9aa0-6d6028823272,DISK], DatanodeInfoWithStorage[127.0.0.1:40713,DS-3776e598-697b-4d4f-9aa8-e99287b6685d,DISK], DatanodeInfoWithStorage[127.0.0.1:45069,DS-38e6071b-5517-4c43-869f-e7382a4024fb,DISK], DatanodeInfoWithStorage[127.0.0.1:37364,DS-14aa002c-99be-47c3-955a-2b2fb66b98f0,DISK], DatanodeInfoWithStorage[127.0.0.1:39099,DS-ef9e8dac-0eea-4161-a3cb-10df04209d5b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-221701709-172.17.0.21-1598111965771:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41296,DS-0d73ab58-d165-483c-8a08-08694a5d4fc7,DISK], DatanodeInfoWithStorage[127.0.0.1:38953,DS-17e279fa-a6de-41e6-91e3-d37f23aaf387,DISK], DatanodeInfoWithStorage[127.0.0.1:35451,DS-36bc74cc-1d47-4e5d-bbdf-3b97c8b16898,DISK], DatanodeInfoWithStorage[127.0.0.1:37371,DS-92281b93-0f1b-49e7-9812-bd9a97846e29,DISK], DatanodeInfoWithStorage[127.0.0.1:35328,DS-4fd49221-7e39-4d80-a833-8a108537b6fb,DISK], DatanodeInfoWithStorage[127.0.0.1:37541,DS-f77f84ae-8107-437c-aaa7-ad41df436e79,DISK], DatanodeInfoWithStorage[127.0.0.1:37840,DS-2d43650c-3aee-48c2-8481-42d2aee82881,DISK], DatanodeInfoWithStorage[127.0.0.1:44963,DS-f80ae0a5-4a67-4109-995e-4570c688eb0d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-221701709-172.17.0.21-1598111965771:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41296,DS-0d73ab58-d165-483c-8a08-08694a5d4fc7,DISK], DatanodeInfoWithStorage[127.0.0.1:38953,DS-17e279fa-a6de-41e6-91e3-d37f23aaf387,DISK], DatanodeInfoWithStorage[127.0.0.1:35451,DS-36bc74cc-1d47-4e5d-bbdf-3b97c8b16898,DISK], DatanodeInfoWithStorage[127.0.0.1:37371,DS-92281b93-0f1b-49e7-9812-bd9a97846e29,DISK], DatanodeInfoWithStorage[127.0.0.1:35328,DS-4fd49221-7e39-4d80-a833-8a108537b6fb,DISK], DatanodeInfoWithStorage[127.0.0.1:37541,DS-f77f84ae-8107-437c-aaa7-ad41df436e79,DISK], DatanodeInfoWithStorage[127.0.0.1:37840,DS-2d43650c-3aee-48c2-8481-42d2aee82881,DISK], DatanodeInfoWithStorage[127.0.0.1:44963,DS-f80ae0a5-4a67-4109-995e-4570c688eb0d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2136831180-172.17.0.21-1598111998425:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46397,DS-a14a77c4-be9b-4d6b-951b-6a85067d5151,DISK], DatanodeInfoWithStorage[127.0.0.1:39031,DS-2f164081-6e7d-4d80-ad97-8b96dd75506b,DISK], DatanodeInfoWithStorage[127.0.0.1:40725,DS-5323e9ad-0377-4fd0-8cc5-6b01dca64650,DISK], DatanodeInfoWithStorage[127.0.0.1:38894,DS-5e5d899b-bb99-4b56-9466-ea6679d8d6cf,DISK], DatanodeInfoWithStorage[127.0.0.1:33952,DS-8d4bd99f-82a0-4c05-add1-966163aec460,DISK], DatanodeInfoWithStorage[127.0.0.1:39069,DS-e3a6d2f7-9e34-4511-b279-d85a4fca94c9,DISK], DatanodeInfoWithStorage[127.0.0.1:43416,DS-a9a80e75-d097-4f7f-9f60-00bac65c87e4,DISK], DatanodeInfoWithStorage[127.0.0.1:35249,DS-b3f4f2f8-8e04-4ae0-9e47-c5c5a8aa44de,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2136831180-172.17.0.21-1598111998425:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46397,DS-a14a77c4-be9b-4d6b-951b-6a85067d5151,DISK], DatanodeInfoWithStorage[127.0.0.1:39031,DS-2f164081-6e7d-4d80-ad97-8b96dd75506b,DISK], DatanodeInfoWithStorage[127.0.0.1:40725,DS-5323e9ad-0377-4fd0-8cc5-6b01dca64650,DISK], DatanodeInfoWithStorage[127.0.0.1:38894,DS-5e5d899b-bb99-4b56-9466-ea6679d8d6cf,DISK], DatanodeInfoWithStorage[127.0.0.1:33952,DS-8d4bd99f-82a0-4c05-add1-966163aec460,DISK], DatanodeInfoWithStorage[127.0.0.1:39069,DS-e3a6d2f7-9e34-4511-b279-d85a4fca94c9,DISK], DatanodeInfoWithStorage[127.0.0.1:43416,DS-a9a80e75-d097-4f7f-9f60-00bac65c87e4,DISK], DatanodeInfoWithStorage[127.0.0.1:35249,DS-b3f4f2f8-8e04-4ae0-9e47-c5c5a8aa44de,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1634763694-172.17.0.21-1598112147860:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37892,DS-6b71eae8-b8b0-4308-a2fb-f75ee236a2b4,DISK], DatanodeInfoWithStorage[127.0.0.1:42335,DS-f4eaed55-f0b1-470e-a970-04b1d8bfbc5c,DISK], DatanodeInfoWithStorage[127.0.0.1:45386,DS-662262d7-2956-422f-bffa-219f5684aed1,DISK], DatanodeInfoWithStorage[127.0.0.1:46129,DS-bce6d16f-3a2d-4720-8153-41f07e7999e5,DISK], DatanodeInfoWithStorage[127.0.0.1:43655,DS-b9b85857-acb9-4c02-8b8a-bed195f7c2d0,DISK], DatanodeInfoWithStorage[127.0.0.1:36747,DS-78fef3c1-ba92-4526-9100-48ad73aec5d7,DISK], DatanodeInfoWithStorage[127.0.0.1:36424,DS-4dcb1369-413f-4709-9cdf-5ddc8b15ad2f,DISK], DatanodeInfoWithStorage[127.0.0.1:36735,DS-407c615a-e98d-4c6e-931a-aecb1adb7ae1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1634763694-172.17.0.21-1598112147860:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37892,DS-6b71eae8-b8b0-4308-a2fb-f75ee236a2b4,DISK], DatanodeInfoWithStorage[127.0.0.1:42335,DS-f4eaed55-f0b1-470e-a970-04b1d8bfbc5c,DISK], DatanodeInfoWithStorage[127.0.0.1:45386,DS-662262d7-2956-422f-bffa-219f5684aed1,DISK], DatanodeInfoWithStorage[127.0.0.1:46129,DS-bce6d16f-3a2d-4720-8153-41f07e7999e5,DISK], DatanodeInfoWithStorage[127.0.0.1:43655,DS-b9b85857-acb9-4c02-8b8a-bed195f7c2d0,DISK], DatanodeInfoWithStorage[127.0.0.1:36747,DS-78fef3c1-ba92-4526-9100-48ad73aec5d7,DISK], DatanodeInfoWithStorage[127.0.0.1:36424,DS-4dcb1369-413f-4709-9cdf-5ddc8b15ad2f,DISK], DatanodeInfoWithStorage[127.0.0.1:36735,DS-407c615a-e98d-4c6e-931a-aecb1adb7ae1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1064725683-172.17.0.21-1598112423127:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43407,DS-2c277b81-6aed-4cb1-b0ec-95b2f9c07277,DISK], DatanodeInfoWithStorage[127.0.0.1:40126,DS-bfddd151-2353-4a56-b013-c0e799dc1470,DISK], DatanodeInfoWithStorage[127.0.0.1:45150,DS-8a7ce83d-376f-4ae0-98c4-b6ff1bc9b753,DISK], DatanodeInfoWithStorage[127.0.0.1:33038,DS-fc523461-883b-44ae-ba37-862a14844603,DISK], DatanodeInfoWithStorage[127.0.0.1:35024,DS-e4b32b2f-ca0e-467f-96f9-f907dc3aa2c0,DISK], DatanodeInfoWithStorage[127.0.0.1:45737,DS-070160d0-f638-42d8-b278-d46b2e70a3c7,DISK], DatanodeInfoWithStorage[127.0.0.1:39910,DS-eed0a1ed-5ca7-4be0-a294-bf8ceb2f5e9f,DISK], DatanodeInfoWithStorage[127.0.0.1:35488,DS-5258ccc9-6784-4226-a9e0-22dc8aaeb16f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1064725683-172.17.0.21-1598112423127:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43407,DS-2c277b81-6aed-4cb1-b0ec-95b2f9c07277,DISK], DatanodeInfoWithStorage[127.0.0.1:40126,DS-bfddd151-2353-4a56-b013-c0e799dc1470,DISK], DatanodeInfoWithStorage[127.0.0.1:45150,DS-8a7ce83d-376f-4ae0-98c4-b6ff1bc9b753,DISK], DatanodeInfoWithStorage[127.0.0.1:33038,DS-fc523461-883b-44ae-ba37-862a14844603,DISK], DatanodeInfoWithStorage[127.0.0.1:35024,DS-e4b32b2f-ca0e-467f-96f9-f907dc3aa2c0,DISK], DatanodeInfoWithStorage[127.0.0.1:45737,DS-070160d0-f638-42d8-b278-d46b2e70a3c7,DISK], DatanodeInfoWithStorage[127.0.0.1:39910,DS-eed0a1ed-5ca7-4be0-a294-bf8ceb2f5e9f,DISK], DatanodeInfoWithStorage[127.0.0.1:35488,DS-5258ccc9-6784-4226-a9e0-22dc8aaeb16f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-930377517-172.17.0.21-1598112647304:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33331,DS-3c163f6f-8345-407b-b0c6-f72fab1e0c6d,DISK], DatanodeInfoWithStorage[127.0.0.1:44112,DS-006ce2a9-fc69-46f4-ad03-d3c371a8cc76,DISK], DatanodeInfoWithStorage[127.0.0.1:40479,DS-406c652c-f989-48c9-a821-be23004d5528,DISK], DatanodeInfoWithStorage[127.0.0.1:37480,DS-e6a785df-6b9d-4583-912d-207c61594e90,DISK], DatanodeInfoWithStorage[127.0.0.1:40959,DS-60af6d91-69b5-4368-ad15-e0d10f730354,DISK], DatanodeInfoWithStorage[127.0.0.1:46191,DS-604ef1a3-0b04-41db-ae05-07e725d01b1e,DISK], DatanodeInfoWithStorage[127.0.0.1:42199,DS-21709624-016f-476c-a240-921b1e4ef227,DISK], DatanodeInfoWithStorage[127.0.0.1:42984,DS-611654bc-08b2-4371-b6c1-f629cfe27f46,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-930377517-172.17.0.21-1598112647304:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33331,DS-3c163f6f-8345-407b-b0c6-f72fab1e0c6d,DISK], DatanodeInfoWithStorage[127.0.0.1:44112,DS-006ce2a9-fc69-46f4-ad03-d3c371a8cc76,DISK], DatanodeInfoWithStorage[127.0.0.1:40479,DS-406c652c-f989-48c9-a821-be23004d5528,DISK], DatanodeInfoWithStorage[127.0.0.1:37480,DS-e6a785df-6b9d-4583-912d-207c61594e90,DISK], DatanodeInfoWithStorage[127.0.0.1:40959,DS-60af6d91-69b5-4368-ad15-e0d10f730354,DISK], DatanodeInfoWithStorage[127.0.0.1:46191,DS-604ef1a3-0b04-41db-ae05-07e725d01b1e,DISK], DatanodeInfoWithStorage[127.0.0.1:42199,DS-21709624-016f-476c-a240-921b1e4ef227,DISK], DatanodeInfoWithStorage[127.0.0.1:42984,DS-611654bc-08b2-4371-b6c1-f629cfe27f46,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-889965178-172.17.0.21-1598112762125:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36612,DS-23d1251c-17f1-4462-8d95-b8fa6efd5f40,DISK], DatanodeInfoWithStorage[127.0.0.1:43556,DS-1c87b902-455f-4e3c-b7f5-5cfc4a3f9d46,DISK], DatanodeInfoWithStorage[127.0.0.1:42678,DS-4e171e16-0f56-450a-b9de-c416ff7abc7a,DISK], DatanodeInfoWithStorage[127.0.0.1:36181,DS-6123a0d1-e202-4d16-8640-974616592bba,DISK], DatanodeInfoWithStorage[127.0.0.1:43265,DS-3d33c46e-9f35-4840-85b6-0eb612f7b42f,DISK], DatanodeInfoWithStorage[127.0.0.1:42798,DS-daa4069b-e765-4225-834c-30a52cf365bb,DISK], DatanodeInfoWithStorage[127.0.0.1:38637,DS-ed4e3e34-7711-453f-9241-38847c9ba5ce,DISK], DatanodeInfoWithStorage[127.0.0.1:44402,DS-0168a0d2-e8db-4fa8-baba-cb7f9f7d626a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-889965178-172.17.0.21-1598112762125:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36612,DS-23d1251c-17f1-4462-8d95-b8fa6efd5f40,DISK], DatanodeInfoWithStorage[127.0.0.1:43556,DS-1c87b902-455f-4e3c-b7f5-5cfc4a3f9d46,DISK], DatanodeInfoWithStorage[127.0.0.1:42678,DS-4e171e16-0f56-450a-b9de-c416ff7abc7a,DISK], DatanodeInfoWithStorage[127.0.0.1:36181,DS-6123a0d1-e202-4d16-8640-974616592bba,DISK], DatanodeInfoWithStorage[127.0.0.1:43265,DS-3d33c46e-9f35-4840-85b6-0eb612f7b42f,DISK], DatanodeInfoWithStorage[127.0.0.1:42798,DS-daa4069b-e765-4225-834c-30a52cf365bb,DISK], DatanodeInfoWithStorage[127.0.0.1:38637,DS-ed4e3e34-7711-453f-9241-38847c9ba5ce,DISK], DatanodeInfoWithStorage[127.0.0.1:44402,DS-0168a0d2-e8db-4fa8-baba-cb7f9f7d626a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 11 out of 50
v1v1v2v2 failed with probability 19 out of 50
result: false positive !!!
Total execution time in seconds : 5603
