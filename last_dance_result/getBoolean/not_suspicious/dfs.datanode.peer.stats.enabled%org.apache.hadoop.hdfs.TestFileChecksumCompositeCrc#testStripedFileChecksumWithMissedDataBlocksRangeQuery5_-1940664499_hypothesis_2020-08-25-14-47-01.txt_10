reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-969430312-172.17.0.11-1598366874703:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33854,DS-48f57c8f-4cca-4ce4-b6fc-9268e0c54584,DISK], DatanodeInfoWithStorage[127.0.0.1:38331,DS-2b934a40-b281-4949-9985-940c5403e47a,DISK], DatanodeInfoWithStorage[127.0.0.1:39558,DS-9b519a0b-e82f-4063-be13-7f5ccf92860d,DISK], DatanodeInfoWithStorage[127.0.0.1:40668,DS-bb091016-a39e-42ea-b3eb-6908fe1a3368,DISK], DatanodeInfoWithStorage[127.0.0.1:38512,DS-b357d05d-730c-46d9-b6c5-56997655534c,DISK], DatanodeInfoWithStorage[127.0.0.1:41886,DS-6ec42100-b5ae-4b9f-b367-c9b01475158c,DISK], DatanodeInfoWithStorage[127.0.0.1:41112,DS-0e031b2c-3892-48d5-a1cb-bfd302e4a0a7,DISK], DatanodeInfoWithStorage[127.0.0.1:41734,DS-245d4135-f0f9-4310-9a36-2c2cba030da2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-969430312-172.17.0.11-1598366874703:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33854,DS-48f57c8f-4cca-4ce4-b6fc-9268e0c54584,DISK], DatanodeInfoWithStorage[127.0.0.1:38331,DS-2b934a40-b281-4949-9985-940c5403e47a,DISK], DatanodeInfoWithStorage[127.0.0.1:39558,DS-9b519a0b-e82f-4063-be13-7f5ccf92860d,DISK], DatanodeInfoWithStorage[127.0.0.1:40668,DS-bb091016-a39e-42ea-b3eb-6908fe1a3368,DISK], DatanodeInfoWithStorage[127.0.0.1:38512,DS-b357d05d-730c-46d9-b6c5-56997655534c,DISK], DatanodeInfoWithStorage[127.0.0.1:41886,DS-6ec42100-b5ae-4b9f-b367-c9b01475158c,DISK], DatanodeInfoWithStorage[127.0.0.1:41112,DS-0e031b2c-3892-48d5-a1cb-bfd302e4a0a7,DISK], DatanodeInfoWithStorage[127.0.0.1:41734,DS-245d4135-f0f9-4310-9a36-2c2cba030da2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1695891372-172.17.0.11-1598367521996:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38693,DS-d0f21e0b-6ae7-4fff-9d8b-6513cfe3f2f3,DISK], DatanodeInfoWithStorage[127.0.0.1:35034,DS-140124f8-9e73-468a-b571-959b602a8b15,DISK], DatanodeInfoWithStorage[127.0.0.1:33479,DS-cac5481c-8e89-4007-8a3e-6179c91b2338,DISK], DatanodeInfoWithStorage[127.0.0.1:40154,DS-04f3b974-0038-4cba-9bc3-f466faf250b2,DISK], DatanodeInfoWithStorage[127.0.0.1:45730,DS-05c0e103-520c-4b23-8a48-8a3f350af617,DISK], DatanodeInfoWithStorage[127.0.0.1:40657,DS-2169315a-38df-457a-a265-44fe58eba072,DISK], DatanodeInfoWithStorage[127.0.0.1:41456,DS-58c1787b-7774-4914-9f70-8930576e3d71,DISK], DatanodeInfoWithStorage[127.0.0.1:32930,DS-45bcd73a-01a7-47cf-9832-04a65b0e1bb1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1695891372-172.17.0.11-1598367521996:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38693,DS-d0f21e0b-6ae7-4fff-9d8b-6513cfe3f2f3,DISK], DatanodeInfoWithStorage[127.0.0.1:35034,DS-140124f8-9e73-468a-b571-959b602a8b15,DISK], DatanodeInfoWithStorage[127.0.0.1:33479,DS-cac5481c-8e89-4007-8a3e-6179c91b2338,DISK], DatanodeInfoWithStorage[127.0.0.1:40154,DS-04f3b974-0038-4cba-9bc3-f466faf250b2,DISK], DatanodeInfoWithStorage[127.0.0.1:45730,DS-05c0e103-520c-4b23-8a48-8a3f350af617,DISK], DatanodeInfoWithStorage[127.0.0.1:40657,DS-2169315a-38df-457a-a265-44fe58eba072,DISK], DatanodeInfoWithStorage[127.0.0.1:41456,DS-58c1787b-7774-4914-9f70-8930576e3d71,DISK], DatanodeInfoWithStorage[127.0.0.1:32930,DS-45bcd73a-01a7-47cf-9832-04a65b0e1bb1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2120140495-172.17.0.11-1598367841714:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34557,DS-b21b1ce5-d764-4aa0-8425-aeb48941115a,DISK], DatanodeInfoWithStorage[127.0.0.1:37407,DS-6ba20a28-fd77-4907-802c-3fac5dbc2072,DISK], DatanodeInfoWithStorage[127.0.0.1:36885,DS-619593fb-466c-4d50-bb15-15c15da280c9,DISK], DatanodeInfoWithStorage[127.0.0.1:38089,DS-5ad436c5-188a-49b6-9a81-8fe746af4c23,DISK], DatanodeInfoWithStorage[127.0.0.1:42331,DS-d45b7997-3564-4a8c-aec3-051b80d6b5ef,DISK], DatanodeInfoWithStorage[127.0.0.1:45359,DS-6cbdcb05-06ed-4d4a-93bb-eb584021c2c0,DISK], DatanodeInfoWithStorage[127.0.0.1:40595,DS-7c50aa98-1a05-404b-9b9d-e07a6c46258d,DISK], DatanodeInfoWithStorage[127.0.0.1:34702,DS-c935b7a9-d0cc-477e-b790-210a217430a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2120140495-172.17.0.11-1598367841714:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34557,DS-b21b1ce5-d764-4aa0-8425-aeb48941115a,DISK], DatanodeInfoWithStorage[127.0.0.1:37407,DS-6ba20a28-fd77-4907-802c-3fac5dbc2072,DISK], DatanodeInfoWithStorage[127.0.0.1:36885,DS-619593fb-466c-4d50-bb15-15c15da280c9,DISK], DatanodeInfoWithStorage[127.0.0.1:38089,DS-5ad436c5-188a-49b6-9a81-8fe746af4c23,DISK], DatanodeInfoWithStorage[127.0.0.1:42331,DS-d45b7997-3564-4a8c-aec3-051b80d6b5ef,DISK], DatanodeInfoWithStorage[127.0.0.1:45359,DS-6cbdcb05-06ed-4d4a-93bb-eb584021c2c0,DISK], DatanodeInfoWithStorage[127.0.0.1:40595,DS-7c50aa98-1a05-404b-9b9d-e07a6c46258d,DISK], DatanodeInfoWithStorage[127.0.0.1:34702,DS-c935b7a9-d0cc-477e-b790-210a217430a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1742827228-172.17.0.11-1598367982925:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43111,DS-493923f7-dad3-4a50-ab05-1ba1c30cfaa7,DISK], DatanodeInfoWithStorage[127.0.0.1:38300,DS-5086063d-49cd-4093-9840-0749167d9678,DISK], DatanodeInfoWithStorage[127.0.0.1:36899,DS-bc891870-cb86-4693-8ad5-e523c0475bc5,DISK], DatanodeInfoWithStorage[127.0.0.1:35140,DS-7d2d3918-4eb5-4b0a-accf-893f75866629,DISK], DatanodeInfoWithStorage[127.0.0.1:34254,DS-18d019ab-0bbe-47ee-980d-c8404066f1c2,DISK], DatanodeInfoWithStorage[127.0.0.1:46140,DS-c4bc7ab3-075a-4815-91f1-3ab5305b9e4d,DISK], DatanodeInfoWithStorage[127.0.0.1:40710,DS-7c315e0a-c188-46e0-9500-faf5831674c0,DISK], DatanodeInfoWithStorage[127.0.0.1:42545,DS-e6a180f6-cc80-430f-a820-ede3b23ce966,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1742827228-172.17.0.11-1598367982925:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43111,DS-493923f7-dad3-4a50-ab05-1ba1c30cfaa7,DISK], DatanodeInfoWithStorage[127.0.0.1:38300,DS-5086063d-49cd-4093-9840-0749167d9678,DISK], DatanodeInfoWithStorage[127.0.0.1:36899,DS-bc891870-cb86-4693-8ad5-e523c0475bc5,DISK], DatanodeInfoWithStorage[127.0.0.1:35140,DS-7d2d3918-4eb5-4b0a-accf-893f75866629,DISK], DatanodeInfoWithStorage[127.0.0.1:34254,DS-18d019ab-0bbe-47ee-980d-c8404066f1c2,DISK], DatanodeInfoWithStorage[127.0.0.1:46140,DS-c4bc7ab3-075a-4815-91f1-3ab5305b9e4d,DISK], DatanodeInfoWithStorage[127.0.0.1:40710,DS-7c315e0a-c188-46e0-9500-faf5831674c0,DISK], DatanodeInfoWithStorage[127.0.0.1:42545,DS-e6a180f6-cc80-430f-a820-ede3b23ce966,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-578292211-172.17.0.11-1598368082109:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43249,DS-17ce96fe-21a0-4377-8ed5-9b2cba46e895,DISK], DatanodeInfoWithStorage[127.0.0.1:44830,DS-6b39e445-a8c7-4880-bb03-ec0f1823616a,DISK], DatanodeInfoWithStorage[127.0.0.1:32778,DS-12efda6a-23ed-4640-980e-aed8918600c9,DISK], DatanodeInfoWithStorage[127.0.0.1:34961,DS-ac1dc1f5-7885-4702-8936-4087589ec0e7,DISK], DatanodeInfoWithStorage[127.0.0.1:33012,DS-b82e6105-69a3-4635-8954-1446c59018ad,DISK], DatanodeInfoWithStorage[127.0.0.1:37649,DS-f689e99f-ced4-4c44-ad87-57a602de9cef,DISK], DatanodeInfoWithStorage[127.0.0.1:46703,DS-442515fb-58f0-4cae-9657-cedbb4b52da4,DISK], DatanodeInfoWithStorage[127.0.0.1:40553,DS-88e86eae-fcef-4c2b-bd5b-a45b9cab1505,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-578292211-172.17.0.11-1598368082109:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43249,DS-17ce96fe-21a0-4377-8ed5-9b2cba46e895,DISK], DatanodeInfoWithStorage[127.0.0.1:44830,DS-6b39e445-a8c7-4880-bb03-ec0f1823616a,DISK], DatanodeInfoWithStorage[127.0.0.1:32778,DS-12efda6a-23ed-4640-980e-aed8918600c9,DISK], DatanodeInfoWithStorage[127.0.0.1:34961,DS-ac1dc1f5-7885-4702-8936-4087589ec0e7,DISK], DatanodeInfoWithStorage[127.0.0.1:33012,DS-b82e6105-69a3-4635-8954-1446c59018ad,DISK], DatanodeInfoWithStorage[127.0.0.1:37649,DS-f689e99f-ced4-4c44-ad87-57a602de9cef,DISK], DatanodeInfoWithStorage[127.0.0.1:46703,DS-442515fb-58f0-4cae-9657-cedbb4b52da4,DISK], DatanodeInfoWithStorage[127.0.0.1:40553,DS-88e86eae-fcef-4c2b-bd5b-a45b9cab1505,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-789730397-172.17.0.11-1598368628001:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33043,DS-f8cd6df2-08b9-465b-86c3-94731e4b0c75,DISK], DatanodeInfoWithStorage[127.0.0.1:44596,DS-5ec46937-6208-41bd-a266-3a36bc0da998,DISK], DatanodeInfoWithStorage[127.0.0.1:40792,DS-531fbd70-8932-4e20-805b-dac7a87ce2fc,DISK], DatanodeInfoWithStorage[127.0.0.1:33300,DS-632b1be7-654d-4d47-9de5-116e1636750a,DISK], DatanodeInfoWithStorage[127.0.0.1:34291,DS-49668fe1-a8e0-4dc9-92a5-3ac5f2a18b45,DISK], DatanodeInfoWithStorage[127.0.0.1:46059,DS-535f2bba-2eba-414c-934e-7f876963d6dc,DISK], DatanodeInfoWithStorage[127.0.0.1:43701,DS-b8da33a4-437d-4588-861e-fcea7e061a0f,DISK], DatanodeInfoWithStorage[127.0.0.1:37672,DS-0dcb9314-9ba2-41ff-9e68-f90523a12216,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-789730397-172.17.0.11-1598368628001:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33043,DS-f8cd6df2-08b9-465b-86c3-94731e4b0c75,DISK], DatanodeInfoWithStorage[127.0.0.1:44596,DS-5ec46937-6208-41bd-a266-3a36bc0da998,DISK], DatanodeInfoWithStorage[127.0.0.1:40792,DS-531fbd70-8932-4e20-805b-dac7a87ce2fc,DISK], DatanodeInfoWithStorage[127.0.0.1:33300,DS-632b1be7-654d-4d47-9de5-116e1636750a,DISK], DatanodeInfoWithStorage[127.0.0.1:34291,DS-49668fe1-a8e0-4dc9-92a5-3ac5f2a18b45,DISK], DatanodeInfoWithStorage[127.0.0.1:46059,DS-535f2bba-2eba-414c-934e-7f876963d6dc,DISK], DatanodeInfoWithStorage[127.0.0.1:43701,DS-b8da33a4-437d-4588-861e-fcea7e061a0f,DISK], DatanodeInfoWithStorage[127.0.0.1:37672,DS-0dcb9314-9ba2-41ff-9e68-f90523a12216,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-842973963-172.17.0.11-1598368662075:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38465,DS-74d817d0-5c0f-464f-b703-60bfc91cc428,DISK], DatanodeInfoWithStorage[127.0.0.1:44756,DS-b3ed34bf-17ac-4c60-a34d-c0b4ba290c11,DISK], DatanodeInfoWithStorage[127.0.0.1:45885,DS-fa2fe953-8d22-43d3-910e-902b29fa0d4f,DISK], DatanodeInfoWithStorage[127.0.0.1:43407,DS-f696cff0-f8e0-423f-8af6-92c960ff94f6,DISK], DatanodeInfoWithStorage[127.0.0.1:45922,DS-f71bfda9-c4a5-4629-95e1-fc70e8e0a11c,DISK], DatanodeInfoWithStorage[127.0.0.1:34766,DS-0824ae5a-fec9-4573-8a45-c73c7047cb03,DISK], DatanodeInfoWithStorage[127.0.0.1:37229,DS-5a5539bf-bd1f-44b6-bba6-45e588278f2c,DISK], DatanodeInfoWithStorage[127.0.0.1:33992,DS-6cc0bae2-e86f-42e4-b4af-7702f6147da4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-842973963-172.17.0.11-1598368662075:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38465,DS-74d817d0-5c0f-464f-b703-60bfc91cc428,DISK], DatanodeInfoWithStorage[127.0.0.1:44756,DS-b3ed34bf-17ac-4c60-a34d-c0b4ba290c11,DISK], DatanodeInfoWithStorage[127.0.0.1:45885,DS-fa2fe953-8d22-43d3-910e-902b29fa0d4f,DISK], DatanodeInfoWithStorage[127.0.0.1:43407,DS-f696cff0-f8e0-423f-8af6-92c960ff94f6,DISK], DatanodeInfoWithStorage[127.0.0.1:45922,DS-f71bfda9-c4a5-4629-95e1-fc70e8e0a11c,DISK], DatanodeInfoWithStorage[127.0.0.1:34766,DS-0824ae5a-fec9-4573-8a45-c73c7047cb03,DISK], DatanodeInfoWithStorage[127.0.0.1:37229,DS-5a5539bf-bd1f-44b6-bba6-45e588278f2c,DISK], DatanodeInfoWithStorage[127.0.0.1:33992,DS-6cc0bae2-e86f-42e4-b4af-7702f6147da4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1818813734-172.17.0.11-1598369009357:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44383,DS-44b55d38-1436-4d6e-a27b-949ddf3673ce,DISK], DatanodeInfoWithStorage[127.0.0.1:33594,DS-1ebbff06-1879-4017-bab6-1efa5e2324f8,DISK], DatanodeInfoWithStorage[127.0.0.1:34559,DS-7bf31661-2b0b-4b78-956d-3fe19ec540b1,DISK], DatanodeInfoWithStorage[127.0.0.1:38305,DS-6c7ff30e-0bc4-4e33-8db4-df1c64bb9e1c,DISK], DatanodeInfoWithStorage[127.0.0.1:37993,DS-466a1c53-3ed7-4951-ae98-e2897b7fa87a,DISK], DatanodeInfoWithStorage[127.0.0.1:41519,DS-60041468-b30e-41d8-a707-c09a600f9b41,DISK], DatanodeInfoWithStorage[127.0.0.1:36585,DS-6c89b896-7b5c-4088-b9be-c0f89173e770,DISK], DatanodeInfoWithStorage[127.0.0.1:43953,DS-f528cfe8-60d5-47ba-98d7-130587197edd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1818813734-172.17.0.11-1598369009357:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44383,DS-44b55d38-1436-4d6e-a27b-949ddf3673ce,DISK], DatanodeInfoWithStorage[127.0.0.1:33594,DS-1ebbff06-1879-4017-bab6-1efa5e2324f8,DISK], DatanodeInfoWithStorage[127.0.0.1:34559,DS-7bf31661-2b0b-4b78-956d-3fe19ec540b1,DISK], DatanodeInfoWithStorage[127.0.0.1:38305,DS-6c7ff30e-0bc4-4e33-8db4-df1c64bb9e1c,DISK], DatanodeInfoWithStorage[127.0.0.1:37993,DS-466a1c53-3ed7-4951-ae98-e2897b7fa87a,DISK], DatanodeInfoWithStorage[127.0.0.1:41519,DS-60041468-b30e-41d8-a707-c09a600f9b41,DISK], DatanodeInfoWithStorage[127.0.0.1:36585,DS-6c89b896-7b5c-4088-b9be-c0f89173e770,DISK], DatanodeInfoWithStorage[127.0.0.1:43953,DS-f528cfe8-60d5-47ba-98d7-130587197edd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2110711000-172.17.0.11-1598369381750:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32838,DS-ace920cf-accd-4449-a249-f31994c291f2,DISK], DatanodeInfoWithStorage[127.0.0.1:39386,DS-36ea47aa-a899-410d-8f9b-3544f7719f2d,DISK], DatanodeInfoWithStorage[127.0.0.1:45337,DS-8d9eb809-223f-4661-8d89-ddb1006e940c,DISK], DatanodeInfoWithStorage[127.0.0.1:34821,DS-f85d1b30-536f-4c68-a8a8-5d057656c0e2,DISK], DatanodeInfoWithStorage[127.0.0.1:44709,DS-3a684c67-949c-4196-b135-f64880cefdee,DISK], DatanodeInfoWithStorage[127.0.0.1:37739,DS-4d35f43f-b8ec-431b-a824-435cb1246cab,DISK], DatanodeInfoWithStorage[127.0.0.1:43000,DS-b4cc03fa-568a-4058-8774-23ffab17d4a6,DISK], DatanodeInfoWithStorage[127.0.0.1:46024,DS-0759db63-286c-4b18-a07d-dcdf522dc83d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2110711000-172.17.0.11-1598369381750:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32838,DS-ace920cf-accd-4449-a249-f31994c291f2,DISK], DatanodeInfoWithStorage[127.0.0.1:39386,DS-36ea47aa-a899-410d-8f9b-3544f7719f2d,DISK], DatanodeInfoWithStorage[127.0.0.1:45337,DS-8d9eb809-223f-4661-8d89-ddb1006e940c,DISK], DatanodeInfoWithStorage[127.0.0.1:34821,DS-f85d1b30-536f-4c68-a8a8-5d057656c0e2,DISK], DatanodeInfoWithStorage[127.0.0.1:44709,DS-3a684c67-949c-4196-b135-f64880cefdee,DISK], DatanodeInfoWithStorage[127.0.0.1:37739,DS-4d35f43f-b8ec-431b-a824-435cb1246cab,DISK], DatanodeInfoWithStorage[127.0.0.1:43000,DS-b4cc03fa-568a-4058-8774-23ffab17d4a6,DISK], DatanodeInfoWithStorage[127.0.0.1:46024,DS-0759db63-286c-4b18-a07d-dcdf522dc83d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-818149561-172.17.0.11-1598369426784:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41216,DS-5e58a60b-3a75-4776-b3cf-f31b631fcb1f,DISK], DatanodeInfoWithStorage[127.0.0.1:42351,DS-1b7fffce-5468-476d-a7c0-de312d43c329,DISK], DatanodeInfoWithStorage[127.0.0.1:43639,DS-1de4af85-dd06-4886-bd15-aec0b0c4c5fb,DISK], DatanodeInfoWithStorage[127.0.0.1:42537,DS-cfb5b8df-49d4-4f71-9b84-05ac045de3b2,DISK], DatanodeInfoWithStorage[127.0.0.1:46624,DS-0773ecfd-51c9-4a14-a006-c72ab26ba7ed,DISK], DatanodeInfoWithStorage[127.0.0.1:34910,DS-6cda0e6b-e4ba-4464-9fd1-35584fe9100a,DISK], DatanodeInfoWithStorage[127.0.0.1:39498,DS-a94e2e05-f83f-4231-8ee6-f83f1918ec20,DISK], DatanodeInfoWithStorage[127.0.0.1:35008,DS-636427ce-09bd-4e36-86f0-0e763e95853d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-818149561-172.17.0.11-1598369426784:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41216,DS-5e58a60b-3a75-4776-b3cf-f31b631fcb1f,DISK], DatanodeInfoWithStorage[127.0.0.1:42351,DS-1b7fffce-5468-476d-a7c0-de312d43c329,DISK], DatanodeInfoWithStorage[127.0.0.1:43639,DS-1de4af85-dd06-4886-bd15-aec0b0c4c5fb,DISK], DatanodeInfoWithStorage[127.0.0.1:42537,DS-cfb5b8df-49d4-4f71-9b84-05ac045de3b2,DISK], DatanodeInfoWithStorage[127.0.0.1:46624,DS-0773ecfd-51c9-4a14-a006-c72ab26ba7ed,DISK], DatanodeInfoWithStorage[127.0.0.1:34910,DS-6cda0e6b-e4ba-4464-9fd1-35584fe9100a,DISK], DatanodeInfoWithStorage[127.0.0.1:39498,DS-a94e2e05-f83f-4231-8ee6-f83f1918ec20,DISK], DatanodeInfoWithStorage[127.0.0.1:35008,DS-636427ce-09bd-4e36-86f0-0e763e95853d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-438899860-172.17.0.11-1598369754652:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45457,DS-ba812ebb-6a2d-43e6-bd9d-9a52f75f3599,DISK], DatanodeInfoWithStorage[127.0.0.1:37951,DS-5ce73e10-5042-4e89-a132-ace3200d30c8,DISK], DatanodeInfoWithStorage[127.0.0.1:39176,DS-68f5e200-33f7-4562-82d8-11ad2a26a4d8,DISK], DatanodeInfoWithStorage[127.0.0.1:44442,DS-6fc767ff-3f00-4cee-9daa-03f376674f17,DISK], DatanodeInfoWithStorage[127.0.0.1:42048,DS-a67ab7c1-6b90-444f-80b4-b405f51e9c38,DISK], DatanodeInfoWithStorage[127.0.0.1:45367,DS-c3fbdb11-0c19-413e-bd4a-742de0c3438b,DISK], DatanodeInfoWithStorage[127.0.0.1:34995,DS-d2c0facc-c50c-4253-b967-92acf68a398b,DISK], DatanodeInfoWithStorage[127.0.0.1:42993,DS-120ddc50-15a9-4225-9a5c-478a03ca797c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-438899860-172.17.0.11-1598369754652:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45457,DS-ba812ebb-6a2d-43e6-bd9d-9a52f75f3599,DISK], DatanodeInfoWithStorage[127.0.0.1:37951,DS-5ce73e10-5042-4e89-a132-ace3200d30c8,DISK], DatanodeInfoWithStorage[127.0.0.1:39176,DS-68f5e200-33f7-4562-82d8-11ad2a26a4d8,DISK], DatanodeInfoWithStorage[127.0.0.1:44442,DS-6fc767ff-3f00-4cee-9daa-03f376674f17,DISK], DatanodeInfoWithStorage[127.0.0.1:42048,DS-a67ab7c1-6b90-444f-80b4-b405f51e9c38,DISK], DatanodeInfoWithStorage[127.0.0.1:45367,DS-c3fbdb11-0c19-413e-bd4a-742de0c3438b,DISK], DatanodeInfoWithStorage[127.0.0.1:34995,DS-d2c0facc-c50c-4253-b967-92acf68a398b,DISK], DatanodeInfoWithStorage[127.0.0.1:42993,DS-120ddc50-15a9-4225-9a5c-478a03ca797c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1665915912-172.17.0.11-1598370458930:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41543,DS-4ece6e85-f19b-46e9-9dca-c8baefc23b4e,DISK], DatanodeInfoWithStorage[127.0.0.1:44953,DS-c32deff4-c4ed-44bb-ae2d-66ab030bdad8,DISK], DatanodeInfoWithStorage[127.0.0.1:45020,DS-4673d410-ce9d-4729-9bdb-73d15e51f10b,DISK], DatanodeInfoWithStorage[127.0.0.1:35557,DS-2f567de8-ac5a-4e82-84ce-3c2194fa77a3,DISK], DatanodeInfoWithStorage[127.0.0.1:45844,DS-549ea134-f0ff-482f-ab9c-46bdee558029,DISK], DatanodeInfoWithStorage[127.0.0.1:37271,DS-b0e2dd6a-8cfd-47de-b332-6a98b3f50e84,DISK], DatanodeInfoWithStorage[127.0.0.1:37402,DS-8f53101d-b2c0-4a2e-bb78-4d85ffd68f54,DISK], DatanodeInfoWithStorage[127.0.0.1:37559,DS-9d31903a-59fd-4e34-bde8-58ad8ad01a55,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1665915912-172.17.0.11-1598370458930:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41543,DS-4ece6e85-f19b-46e9-9dca-c8baefc23b4e,DISK], DatanodeInfoWithStorage[127.0.0.1:44953,DS-c32deff4-c4ed-44bb-ae2d-66ab030bdad8,DISK], DatanodeInfoWithStorage[127.0.0.1:45020,DS-4673d410-ce9d-4729-9bdb-73d15e51f10b,DISK], DatanodeInfoWithStorage[127.0.0.1:35557,DS-2f567de8-ac5a-4e82-84ce-3c2194fa77a3,DISK], DatanodeInfoWithStorage[127.0.0.1:45844,DS-549ea134-f0ff-482f-ab9c-46bdee558029,DISK], DatanodeInfoWithStorage[127.0.0.1:37271,DS-b0e2dd6a-8cfd-47de-b332-6a98b3f50e84,DISK], DatanodeInfoWithStorage[127.0.0.1:37402,DS-8f53101d-b2c0-4a2e-bb78-4d85ffd68f54,DISK], DatanodeInfoWithStorage[127.0.0.1:37559,DS-9d31903a-59fd-4e34-bde8-58ad8ad01a55,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1141385792-172.17.0.11-1598370496042:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41048,DS-78d1e190-444b-4859-8b29-16b234dea8ad,DISK], DatanodeInfoWithStorage[127.0.0.1:39634,DS-2f4614f7-8a65-41e0-98b4-ab1633264d25,DISK], DatanodeInfoWithStorage[127.0.0.1:41792,DS-1b18f24b-48f8-4cfc-aabf-e816329e9893,DISK], DatanodeInfoWithStorage[127.0.0.1:37702,DS-bac8009c-aeca-43b2-abb5-36fbcc8527f8,DISK], DatanodeInfoWithStorage[127.0.0.1:42320,DS-84b62178-f892-4bc2-9ef0-39457bdabae2,DISK], DatanodeInfoWithStorage[127.0.0.1:35178,DS-0156fdd0-80dd-43e8-af14-5fe27a423ef9,DISK], DatanodeInfoWithStorage[127.0.0.1:42775,DS-2867a045-dd8f-4c41-a801-ed3e70eab196,DISK], DatanodeInfoWithStorage[127.0.0.1:38389,DS-cfa31b4b-2a92-4a6f-827b-d49396bc01cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1141385792-172.17.0.11-1598370496042:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41048,DS-78d1e190-444b-4859-8b29-16b234dea8ad,DISK], DatanodeInfoWithStorage[127.0.0.1:39634,DS-2f4614f7-8a65-41e0-98b4-ab1633264d25,DISK], DatanodeInfoWithStorage[127.0.0.1:41792,DS-1b18f24b-48f8-4cfc-aabf-e816329e9893,DISK], DatanodeInfoWithStorage[127.0.0.1:37702,DS-bac8009c-aeca-43b2-abb5-36fbcc8527f8,DISK], DatanodeInfoWithStorage[127.0.0.1:42320,DS-84b62178-f892-4bc2-9ef0-39457bdabae2,DISK], DatanodeInfoWithStorage[127.0.0.1:35178,DS-0156fdd0-80dd-43e8-af14-5fe27a423ef9,DISK], DatanodeInfoWithStorage[127.0.0.1:42775,DS-2867a045-dd8f-4c41-a801-ed3e70eab196,DISK], DatanodeInfoWithStorage[127.0.0.1:38389,DS-cfa31b4b-2a92-4a6f-827b-d49396bc01cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-348859368-172.17.0.11-1598370742452:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39823,DS-69f1753a-d795-483c-911e-48343cfe4e62,DISK], DatanodeInfoWithStorage[127.0.0.1:40561,DS-63c571a8-3adc-44c4-ac9d-d684d7320a44,DISK], DatanodeInfoWithStorage[127.0.0.1:33316,DS-e9165439-11b3-4724-aa23-418cf014cfe8,DISK], DatanodeInfoWithStorage[127.0.0.1:43236,DS-2187f42f-b456-4fe0-94af-1b76c93bb2c8,DISK], DatanodeInfoWithStorage[127.0.0.1:40004,DS-e1ea8618-5cba-419b-83fc-e1fc417b259d,DISK], DatanodeInfoWithStorage[127.0.0.1:39264,DS-37c8b361-5989-4f16-8569-7354539c9dd8,DISK], DatanodeInfoWithStorage[127.0.0.1:45630,DS-ec1c2096-7b3f-4feb-ab04-91131a2271de,DISK], DatanodeInfoWithStorage[127.0.0.1:46043,DS-77ef38e5-94f9-43bb-b133-df175355bbe9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-348859368-172.17.0.11-1598370742452:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39823,DS-69f1753a-d795-483c-911e-48343cfe4e62,DISK], DatanodeInfoWithStorage[127.0.0.1:40561,DS-63c571a8-3adc-44c4-ac9d-d684d7320a44,DISK], DatanodeInfoWithStorage[127.0.0.1:33316,DS-e9165439-11b3-4724-aa23-418cf014cfe8,DISK], DatanodeInfoWithStorage[127.0.0.1:43236,DS-2187f42f-b456-4fe0-94af-1b76c93bb2c8,DISK], DatanodeInfoWithStorage[127.0.0.1:40004,DS-e1ea8618-5cba-419b-83fc-e1fc417b259d,DISK], DatanodeInfoWithStorage[127.0.0.1:39264,DS-37c8b361-5989-4f16-8569-7354539c9dd8,DISK], DatanodeInfoWithStorage[127.0.0.1:45630,DS-ec1c2096-7b3f-4feb-ab04-91131a2271de,DISK], DatanodeInfoWithStorage[127.0.0.1:46043,DS-77ef38e5-94f9-43bb-b133-df175355bbe9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-616858429-172.17.0.11-1598370911061:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42554,DS-a4a1844e-ab4c-46b7-a41f-b479273d61b5,DISK], DatanodeInfoWithStorage[127.0.0.1:46231,DS-a9cb069b-74e5-4648-b152-9e51f282ab98,DISK], DatanodeInfoWithStorage[127.0.0.1:36483,DS-814bc7df-e58f-436a-9bc0-b3785c6ff1fb,DISK], DatanodeInfoWithStorage[127.0.0.1:40480,DS-15577fff-d8f1-4b94-abb2-6a6cffe7a844,DISK], DatanodeInfoWithStorage[127.0.0.1:40376,DS-a133ff97-282d-4b6e-a528-fdd71d672e6d,DISK], DatanodeInfoWithStorage[127.0.0.1:42942,DS-89433a3a-1e2e-42a2-996c-aa4e2341613a,DISK], DatanodeInfoWithStorage[127.0.0.1:39720,DS-c093e4aa-f1de-4f1c-a8dd-25a49b90ea28,DISK], DatanodeInfoWithStorage[127.0.0.1:33152,DS-6934ec35-0e9b-4fb7-ad15-f33aa8c7a1ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-616858429-172.17.0.11-1598370911061:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42554,DS-a4a1844e-ab4c-46b7-a41f-b479273d61b5,DISK], DatanodeInfoWithStorage[127.0.0.1:46231,DS-a9cb069b-74e5-4648-b152-9e51f282ab98,DISK], DatanodeInfoWithStorage[127.0.0.1:36483,DS-814bc7df-e58f-436a-9bc0-b3785c6ff1fb,DISK], DatanodeInfoWithStorage[127.0.0.1:40480,DS-15577fff-d8f1-4b94-abb2-6a6cffe7a844,DISK], DatanodeInfoWithStorage[127.0.0.1:40376,DS-a133ff97-282d-4b6e-a528-fdd71d672e6d,DISK], DatanodeInfoWithStorage[127.0.0.1:42942,DS-89433a3a-1e2e-42a2-996c-aa4e2341613a,DISK], DatanodeInfoWithStorage[127.0.0.1:39720,DS-c093e4aa-f1de-4f1c-a8dd-25a49b90ea28,DISK], DatanodeInfoWithStorage[127.0.0.1:33152,DS-6934ec35-0e9b-4fb7-ad15-f33aa8c7a1ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1106904331-172.17.0.11-1598371667652:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44672,DS-f6dded07-2a95-41ba-b228-1ff6f4ee1444,DISK], DatanodeInfoWithStorage[127.0.0.1:44267,DS-997c392b-9471-4cb0-b3c9-c1da7811d0dd,DISK], DatanodeInfoWithStorage[127.0.0.1:37077,DS-9d714068-be74-4591-8145-f5153b3fd92c,DISK], DatanodeInfoWithStorage[127.0.0.1:43305,DS-dee2ee59-5542-40bc-9c70-6b51b3ead6c1,DISK], DatanodeInfoWithStorage[127.0.0.1:45031,DS-8327d219-94e4-435f-b6e6-56e6811b71b4,DISK], DatanodeInfoWithStorage[127.0.0.1:42019,DS-b375deb7-4e72-4cc1-8817-b5479674534b,DISK], DatanodeInfoWithStorage[127.0.0.1:36231,DS-8100a7e1-35c8-4b74-a5f2-4495dba1418c,DISK], DatanodeInfoWithStorage[127.0.0.1:46172,DS-005db309-ccbd-4790-bb51-9884bc3ccffe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1106904331-172.17.0.11-1598371667652:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44672,DS-f6dded07-2a95-41ba-b228-1ff6f4ee1444,DISK], DatanodeInfoWithStorage[127.0.0.1:44267,DS-997c392b-9471-4cb0-b3c9-c1da7811d0dd,DISK], DatanodeInfoWithStorage[127.0.0.1:37077,DS-9d714068-be74-4591-8145-f5153b3fd92c,DISK], DatanodeInfoWithStorage[127.0.0.1:43305,DS-dee2ee59-5542-40bc-9c70-6b51b3ead6c1,DISK], DatanodeInfoWithStorage[127.0.0.1:45031,DS-8327d219-94e4-435f-b6e6-56e6811b71b4,DISK], DatanodeInfoWithStorage[127.0.0.1:42019,DS-b375deb7-4e72-4cc1-8817-b5479674534b,DISK], DatanodeInfoWithStorage[127.0.0.1:36231,DS-8100a7e1-35c8-4b74-a5f2-4495dba1418c,DISK], DatanodeInfoWithStorage[127.0.0.1:46172,DS-005db309-ccbd-4790-bb51-9884bc3ccffe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2057524045-172.17.0.11-1598371842455:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41962,DS-4a46203d-1916-4b1e-a960-8f612aa97825,DISK], DatanodeInfoWithStorage[127.0.0.1:39425,DS-ac25c457-ee62-49f9-b751-23693eaf2a9f,DISK], DatanodeInfoWithStorage[127.0.0.1:45095,DS-7ae84da7-c7c6-4227-bd26-24217b7daa94,DISK], DatanodeInfoWithStorage[127.0.0.1:40432,DS-fcd60bee-01a1-42e3-990d-7b4790797b4c,DISK], DatanodeInfoWithStorage[127.0.0.1:45495,DS-4b4390fa-4e36-4b44-9c82-c4924ba36f60,DISK], DatanodeInfoWithStorage[127.0.0.1:34673,DS-96705724-a875-4828-8280-b207dce5d4ad,DISK], DatanodeInfoWithStorage[127.0.0.1:33934,DS-157d4ed1-6daa-4aa5-bebf-e78731e8901c,DISK], DatanodeInfoWithStorage[127.0.0.1:38573,DS-c3f49594-15e5-4a8f-9a0a-55f85c70bd3f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2057524045-172.17.0.11-1598371842455:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41962,DS-4a46203d-1916-4b1e-a960-8f612aa97825,DISK], DatanodeInfoWithStorage[127.0.0.1:39425,DS-ac25c457-ee62-49f9-b751-23693eaf2a9f,DISK], DatanodeInfoWithStorage[127.0.0.1:45095,DS-7ae84da7-c7c6-4227-bd26-24217b7daa94,DISK], DatanodeInfoWithStorage[127.0.0.1:40432,DS-fcd60bee-01a1-42e3-990d-7b4790797b4c,DISK], DatanodeInfoWithStorage[127.0.0.1:45495,DS-4b4390fa-4e36-4b44-9c82-c4924ba36f60,DISK], DatanodeInfoWithStorage[127.0.0.1:34673,DS-96705724-a875-4828-8280-b207dce5d4ad,DISK], DatanodeInfoWithStorage[127.0.0.1:33934,DS-157d4ed1-6daa-4aa5-bebf-e78731e8901c,DISK], DatanodeInfoWithStorage[127.0.0.1:38573,DS-c3f49594-15e5-4a8f-9a0a-55f85c70bd3f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-686331725-172.17.0.11-1598371884762:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45290,DS-7385627e-2b7e-4047-a66c-9c6e9bcd8ccd,DISK], DatanodeInfoWithStorage[127.0.0.1:43854,DS-df1a13b8-3b80-48e2-b41a-75a649998645,DISK], DatanodeInfoWithStorage[127.0.0.1:43458,DS-8c700d4d-c416-49a5-97f9-501734cc9c91,DISK], DatanodeInfoWithStorage[127.0.0.1:36163,DS-ffd440d0-0068-4635-9552-14c2fbb86747,DISK], DatanodeInfoWithStorage[127.0.0.1:35054,DS-1d0186b3-55b2-4c3d-9513-7ca4fe29bd42,DISK], DatanodeInfoWithStorage[127.0.0.1:38369,DS-37d46b37-2d52-455d-a2d2-becb173d6ac8,DISK], DatanodeInfoWithStorage[127.0.0.1:43886,DS-48bc7562-f6aa-41ce-933d-24539b17fdd1,DISK], DatanodeInfoWithStorage[127.0.0.1:37800,DS-c80c4962-813a-422e-8020-47dd3763e60f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-686331725-172.17.0.11-1598371884762:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45290,DS-7385627e-2b7e-4047-a66c-9c6e9bcd8ccd,DISK], DatanodeInfoWithStorage[127.0.0.1:43854,DS-df1a13b8-3b80-48e2-b41a-75a649998645,DISK], DatanodeInfoWithStorage[127.0.0.1:43458,DS-8c700d4d-c416-49a5-97f9-501734cc9c91,DISK], DatanodeInfoWithStorage[127.0.0.1:36163,DS-ffd440d0-0068-4635-9552-14c2fbb86747,DISK], DatanodeInfoWithStorage[127.0.0.1:35054,DS-1d0186b3-55b2-4c3d-9513-7ca4fe29bd42,DISK], DatanodeInfoWithStorage[127.0.0.1:38369,DS-37d46b37-2d52-455d-a2d2-becb173d6ac8,DISK], DatanodeInfoWithStorage[127.0.0.1:43886,DS-48bc7562-f6aa-41ce-933d-24539b17fdd1,DISK], DatanodeInfoWithStorage[127.0.0.1:37800,DS-c80c4962-813a-422e-8020-47dd3763e60f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 5260
