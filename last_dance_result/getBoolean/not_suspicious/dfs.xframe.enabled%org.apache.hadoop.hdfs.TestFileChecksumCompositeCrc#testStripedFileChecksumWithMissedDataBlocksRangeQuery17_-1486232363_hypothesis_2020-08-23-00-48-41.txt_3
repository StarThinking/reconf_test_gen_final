reconf_parameter: dfs.xframe.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1105620567-172.17.0.17-1598143837460:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34338,DS-b9d245ac-f0b8-4147-a180-d062a9c88f1c,DISK], DatanodeInfoWithStorage[127.0.0.1:46237,DS-23b21ab5-ae49-4480-a80c-1cb0864d3865,DISK], DatanodeInfoWithStorage[127.0.0.1:46774,DS-5a679861-02c2-4a5e-b124-5cca9a64ba1b,DISK], DatanodeInfoWithStorage[127.0.0.1:42672,DS-7c1d5063-c6b8-44ca-baea-18c7edc95377,DISK], DatanodeInfoWithStorage[127.0.0.1:33416,DS-5cad02ad-10fb-4e67-89c4-0c15e3fd738f,DISK], DatanodeInfoWithStorage[127.0.0.1:37059,DS-c0e80820-cedb-4463-b3e3-89679ec01d58,DISK], DatanodeInfoWithStorage[127.0.0.1:41419,DS-bb64398c-8ab1-444a-8a03-bfeb77bd18ac,DISK], DatanodeInfoWithStorage[127.0.0.1:37493,DS-0d17904e-fd5f-4643-b8ac-3b5af917373a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1105620567-172.17.0.17-1598143837460:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34338,DS-b9d245ac-f0b8-4147-a180-d062a9c88f1c,DISK], DatanodeInfoWithStorage[127.0.0.1:46237,DS-23b21ab5-ae49-4480-a80c-1cb0864d3865,DISK], DatanodeInfoWithStorage[127.0.0.1:46774,DS-5a679861-02c2-4a5e-b124-5cca9a64ba1b,DISK], DatanodeInfoWithStorage[127.0.0.1:42672,DS-7c1d5063-c6b8-44ca-baea-18c7edc95377,DISK], DatanodeInfoWithStorage[127.0.0.1:33416,DS-5cad02ad-10fb-4e67-89c4-0c15e3fd738f,DISK], DatanodeInfoWithStorage[127.0.0.1:37059,DS-c0e80820-cedb-4463-b3e3-89679ec01d58,DISK], DatanodeInfoWithStorage[127.0.0.1:41419,DS-bb64398c-8ab1-444a-8a03-bfeb77bd18ac,DISK], DatanodeInfoWithStorage[127.0.0.1:37493,DS-0d17904e-fd5f-4643-b8ac-3b5af917373a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1449211319-172.17.0.17-1598144027286:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46674,DS-4a816b42-7bed-4a0e-af42-4edbc038d7ad,DISK], DatanodeInfoWithStorage[127.0.0.1:33261,DS-6142ff7c-4f80-404c-b7d6-6da6b6882af0,DISK], DatanodeInfoWithStorage[127.0.0.1:40270,DS-49077eb7-891a-4b46-aa5a-94151124c363,DISK], DatanodeInfoWithStorage[127.0.0.1:44254,DS-98ede168-4cc7-4599-8e1f-397414071d91,DISK], DatanodeInfoWithStorage[127.0.0.1:46408,DS-9005aab5-bbae-41d4-b3c3-011e3c717cea,DISK], DatanodeInfoWithStorage[127.0.0.1:45064,DS-7ef0567f-faba-4693-a04b-f911699bc146,DISK], DatanodeInfoWithStorage[127.0.0.1:34698,DS-704526e0-6572-49ba-9b4b-0499dfaf33b4,DISK], DatanodeInfoWithStorage[127.0.0.1:34980,DS-ab6e39c3-0cce-4f7e-861f-bfab95fed6c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1449211319-172.17.0.17-1598144027286:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46674,DS-4a816b42-7bed-4a0e-af42-4edbc038d7ad,DISK], DatanodeInfoWithStorage[127.0.0.1:33261,DS-6142ff7c-4f80-404c-b7d6-6da6b6882af0,DISK], DatanodeInfoWithStorage[127.0.0.1:40270,DS-49077eb7-891a-4b46-aa5a-94151124c363,DISK], DatanodeInfoWithStorage[127.0.0.1:44254,DS-98ede168-4cc7-4599-8e1f-397414071d91,DISK], DatanodeInfoWithStorage[127.0.0.1:46408,DS-9005aab5-bbae-41d4-b3c3-011e3c717cea,DISK], DatanodeInfoWithStorage[127.0.0.1:45064,DS-7ef0567f-faba-4693-a04b-f911699bc146,DISK], DatanodeInfoWithStorage[127.0.0.1:34698,DS-704526e0-6572-49ba-9b4b-0499dfaf33b4,DISK], DatanodeInfoWithStorage[127.0.0.1:34980,DS-ab6e39c3-0cce-4f7e-861f-bfab95fed6c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-723493771-172.17.0.17-1598144130667:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46774,DS-aa541928-6317-40f6-a69d-321bb4165a7d,DISK], DatanodeInfoWithStorage[127.0.0.1:36181,DS-d93ddbb5-93e4-4f31-8086-338dae6646c6,DISK], DatanodeInfoWithStorage[127.0.0.1:41147,DS-6e053d30-8128-411d-a3bc-3cf94b5de83d,DISK], DatanodeInfoWithStorage[127.0.0.1:44384,DS-d44a1da1-9190-496d-aa92-18e6d25a426f,DISK], DatanodeInfoWithStorage[127.0.0.1:41189,DS-af36b5ff-9d81-403c-bebd-c2177b1483a7,DISK], DatanodeInfoWithStorage[127.0.0.1:37071,DS-d70b16e1-7605-466b-ac90-bfb3fe02048f,DISK], DatanodeInfoWithStorage[127.0.0.1:46715,DS-888f25f3-e142-448b-aed9-25233c96fb4e,DISK], DatanodeInfoWithStorage[127.0.0.1:45861,DS-4d5676b5-b56e-470f-b082-bf831111ad2a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-723493771-172.17.0.17-1598144130667:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46774,DS-aa541928-6317-40f6-a69d-321bb4165a7d,DISK], DatanodeInfoWithStorage[127.0.0.1:36181,DS-d93ddbb5-93e4-4f31-8086-338dae6646c6,DISK], DatanodeInfoWithStorage[127.0.0.1:41147,DS-6e053d30-8128-411d-a3bc-3cf94b5de83d,DISK], DatanodeInfoWithStorage[127.0.0.1:44384,DS-d44a1da1-9190-496d-aa92-18e6d25a426f,DISK], DatanodeInfoWithStorage[127.0.0.1:41189,DS-af36b5ff-9d81-403c-bebd-c2177b1483a7,DISK], DatanodeInfoWithStorage[127.0.0.1:37071,DS-d70b16e1-7605-466b-ac90-bfb3fe02048f,DISK], DatanodeInfoWithStorage[127.0.0.1:46715,DS-888f25f3-e142-448b-aed9-25233c96fb4e,DISK], DatanodeInfoWithStorage[127.0.0.1:45861,DS-4d5676b5-b56e-470f-b082-bf831111ad2a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-842194959-172.17.0.17-1598144290137:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44759,DS-138faa26-33eb-43af-a177-59059b48453a,DISK], DatanodeInfoWithStorage[127.0.0.1:34430,DS-a3a66439-5592-4bfe-8a2c-e5e952f17ad5,DISK], DatanodeInfoWithStorage[127.0.0.1:39425,DS-1606fe79-2d50-45e9-b262-71bd217aa31f,DISK], DatanodeInfoWithStorage[127.0.0.1:42831,DS-87dff612-2b64-415b-926f-72803e4d8e46,DISK], DatanodeInfoWithStorage[127.0.0.1:45181,DS-1b35e7fd-a0af-4ed5-9008-8f0761f2d1a0,DISK], DatanodeInfoWithStorage[127.0.0.1:35860,DS-5f9846c6-a9b5-461d-aca6-e6fc44c5a192,DISK], DatanodeInfoWithStorage[127.0.0.1:45663,DS-e4ddc708-b6e0-4964-8d13-8623466508e2,DISK], DatanodeInfoWithStorage[127.0.0.1:37256,DS-3ffe18ff-c28e-4e5c-a723-0372002e2526,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-842194959-172.17.0.17-1598144290137:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44759,DS-138faa26-33eb-43af-a177-59059b48453a,DISK], DatanodeInfoWithStorage[127.0.0.1:34430,DS-a3a66439-5592-4bfe-8a2c-e5e952f17ad5,DISK], DatanodeInfoWithStorage[127.0.0.1:39425,DS-1606fe79-2d50-45e9-b262-71bd217aa31f,DISK], DatanodeInfoWithStorage[127.0.0.1:42831,DS-87dff612-2b64-415b-926f-72803e4d8e46,DISK], DatanodeInfoWithStorage[127.0.0.1:45181,DS-1b35e7fd-a0af-4ed5-9008-8f0761f2d1a0,DISK], DatanodeInfoWithStorage[127.0.0.1:35860,DS-5f9846c6-a9b5-461d-aca6-e6fc44c5a192,DISK], DatanodeInfoWithStorage[127.0.0.1:45663,DS-e4ddc708-b6e0-4964-8d13-8623466508e2,DISK], DatanodeInfoWithStorage[127.0.0.1:37256,DS-3ffe18ff-c28e-4e5c-a723-0372002e2526,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-842221972-172.17.0.17-1598144826888:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39005,DS-cc22638b-501d-4e9d-873e-2a17239f229b,DISK], DatanodeInfoWithStorage[127.0.0.1:44012,DS-6acb2181-7d00-4dd6-93f3-4a9be6667711,DISK], DatanodeInfoWithStorage[127.0.0.1:34554,DS-30a14564-b225-4ef5-b040-deebce43d923,DISK], DatanodeInfoWithStorage[127.0.0.1:36533,DS-b9f62e90-cfd5-41b4-b3c7-3e2ebf5e52f4,DISK], DatanodeInfoWithStorage[127.0.0.1:46307,DS-3ee752bf-6f9c-4891-ae9b-5962a732d757,DISK], DatanodeInfoWithStorage[127.0.0.1:37099,DS-a7037cdc-db24-4823-9599-5fb6ac227147,DISK], DatanodeInfoWithStorage[127.0.0.1:46769,DS-037ee390-8f93-485b-8cae-39fd4deb30ef,DISK], DatanodeInfoWithStorage[127.0.0.1:38209,DS-56dd74e2-2f33-434c-9b85-f104f2076445,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-842221972-172.17.0.17-1598144826888:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39005,DS-cc22638b-501d-4e9d-873e-2a17239f229b,DISK], DatanodeInfoWithStorage[127.0.0.1:44012,DS-6acb2181-7d00-4dd6-93f3-4a9be6667711,DISK], DatanodeInfoWithStorage[127.0.0.1:34554,DS-30a14564-b225-4ef5-b040-deebce43d923,DISK], DatanodeInfoWithStorage[127.0.0.1:36533,DS-b9f62e90-cfd5-41b4-b3c7-3e2ebf5e52f4,DISK], DatanodeInfoWithStorage[127.0.0.1:46307,DS-3ee752bf-6f9c-4891-ae9b-5962a732d757,DISK], DatanodeInfoWithStorage[127.0.0.1:37099,DS-a7037cdc-db24-4823-9599-5fb6ac227147,DISK], DatanodeInfoWithStorage[127.0.0.1:46769,DS-037ee390-8f93-485b-8cae-39fd4deb30ef,DISK], DatanodeInfoWithStorage[127.0.0.1:38209,DS-56dd74e2-2f33-434c-9b85-f104f2076445,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-178966258-172.17.0.17-1598145079944:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35621,DS-8efad515-3f3d-452d-9175-7120e4775f3e,DISK], DatanodeInfoWithStorage[127.0.0.1:35717,DS-8e9c6dac-94a3-455e-b8c8-7cd3eb0b0b47,DISK], DatanodeInfoWithStorage[127.0.0.1:38797,DS-36978334-8038-4490-adae-364d9d065d1c,DISK], DatanodeInfoWithStorage[127.0.0.1:37827,DS-bdc9c8fa-daed-461f-be2c-d992a2083d2b,DISK], DatanodeInfoWithStorage[127.0.0.1:44577,DS-1271240a-b897-4c82-95e3-777317c760b4,DISK], DatanodeInfoWithStorage[127.0.0.1:34099,DS-43416491-05ad-4b12-b882-2c9751073abc,DISK], DatanodeInfoWithStorage[127.0.0.1:41695,DS-05fdf935-1d20-4449-967b-2cf81a936482,DISK], DatanodeInfoWithStorage[127.0.0.1:43766,DS-e0825531-bda5-477c-b097-41de200d7973,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-178966258-172.17.0.17-1598145079944:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35621,DS-8efad515-3f3d-452d-9175-7120e4775f3e,DISK], DatanodeInfoWithStorage[127.0.0.1:35717,DS-8e9c6dac-94a3-455e-b8c8-7cd3eb0b0b47,DISK], DatanodeInfoWithStorage[127.0.0.1:38797,DS-36978334-8038-4490-adae-364d9d065d1c,DISK], DatanodeInfoWithStorage[127.0.0.1:37827,DS-bdc9c8fa-daed-461f-be2c-d992a2083d2b,DISK], DatanodeInfoWithStorage[127.0.0.1:44577,DS-1271240a-b897-4c82-95e3-777317c760b4,DISK], DatanodeInfoWithStorage[127.0.0.1:34099,DS-43416491-05ad-4b12-b882-2c9751073abc,DISK], DatanodeInfoWithStorage[127.0.0.1:41695,DS-05fdf935-1d20-4449-967b-2cf81a936482,DISK], DatanodeInfoWithStorage[127.0.0.1:43766,DS-e0825531-bda5-477c-b097-41de200d7973,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1462884841-172.17.0.17-1598145116981:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39232,DS-bd59460a-8d23-4442-92b7-d4493c871dc6,DISK], DatanodeInfoWithStorage[127.0.0.1:33958,DS-58fc70b3-feb2-4f60-91cc-6777eb38b260,DISK], DatanodeInfoWithStorage[127.0.0.1:35534,DS-4ef6222c-3679-4759-8ca5-6083b2097b71,DISK], DatanodeInfoWithStorage[127.0.0.1:42336,DS-425a5f30-6186-47de-b124-c591de2a6ede,DISK], DatanodeInfoWithStorage[127.0.0.1:33123,DS-f0d6d60b-54f2-43f1-819c-0c218f515e9c,DISK], DatanodeInfoWithStorage[127.0.0.1:33916,DS-458026ee-c4ba-45ea-85b2-a55aa5932f51,DISK], DatanodeInfoWithStorage[127.0.0.1:39838,DS-cd8d1f34-5828-493b-82c9-450aa321c5ce,DISK], DatanodeInfoWithStorage[127.0.0.1:41423,DS-f1397386-cd68-45a5-8450-5013d9af1381,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1462884841-172.17.0.17-1598145116981:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39232,DS-bd59460a-8d23-4442-92b7-d4493c871dc6,DISK], DatanodeInfoWithStorage[127.0.0.1:33958,DS-58fc70b3-feb2-4f60-91cc-6777eb38b260,DISK], DatanodeInfoWithStorage[127.0.0.1:35534,DS-4ef6222c-3679-4759-8ca5-6083b2097b71,DISK], DatanodeInfoWithStorage[127.0.0.1:42336,DS-425a5f30-6186-47de-b124-c591de2a6ede,DISK], DatanodeInfoWithStorage[127.0.0.1:33123,DS-f0d6d60b-54f2-43f1-819c-0c218f515e9c,DISK], DatanodeInfoWithStorage[127.0.0.1:33916,DS-458026ee-c4ba-45ea-85b2-a55aa5932f51,DISK], DatanodeInfoWithStorage[127.0.0.1:39838,DS-cd8d1f34-5828-493b-82c9-450aa321c5ce,DISK], DatanodeInfoWithStorage[127.0.0.1:41423,DS-f1397386-cd68-45a5-8450-5013d9af1381,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1721395745-172.17.0.17-1598145940199:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41642,DS-72c3c873-5be0-4ab8-b305-4cf75f57608e,DISK], DatanodeInfoWithStorage[127.0.0.1:40790,DS-8943e330-9afa-4c39-acf5-5ae2f7e05849,DISK], DatanodeInfoWithStorage[127.0.0.1:36528,DS-8cd39228-d061-477c-9170-df439375a78f,DISK], DatanodeInfoWithStorage[127.0.0.1:36471,DS-6fe765ba-602d-4417-a92c-5166020c2824,DISK], DatanodeInfoWithStorage[127.0.0.1:36158,DS-433e366d-7556-4d5f-871d-5adea7221309,DISK], DatanodeInfoWithStorage[127.0.0.1:32837,DS-149a544b-946d-4c3a-b645-5e47b069f486,DISK], DatanodeInfoWithStorage[127.0.0.1:41210,DS-cf6f2d0b-4679-49aa-907d-670e90f5e4f2,DISK], DatanodeInfoWithStorage[127.0.0.1:39098,DS-65ca3df5-54aa-496f-9925-bfb0e0a23a05,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1721395745-172.17.0.17-1598145940199:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41642,DS-72c3c873-5be0-4ab8-b305-4cf75f57608e,DISK], DatanodeInfoWithStorage[127.0.0.1:40790,DS-8943e330-9afa-4c39-acf5-5ae2f7e05849,DISK], DatanodeInfoWithStorage[127.0.0.1:36528,DS-8cd39228-d061-477c-9170-df439375a78f,DISK], DatanodeInfoWithStorage[127.0.0.1:36471,DS-6fe765ba-602d-4417-a92c-5166020c2824,DISK], DatanodeInfoWithStorage[127.0.0.1:36158,DS-433e366d-7556-4d5f-871d-5adea7221309,DISK], DatanodeInfoWithStorage[127.0.0.1:32837,DS-149a544b-946d-4c3a-b645-5e47b069f486,DISK], DatanodeInfoWithStorage[127.0.0.1:41210,DS-cf6f2d0b-4679-49aa-907d-670e90f5e4f2,DISK], DatanodeInfoWithStorage[127.0.0.1:39098,DS-65ca3df5-54aa-496f-9925-bfb0e0a23a05,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.xframe.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2130206487-172.17.0.17-1598145974243:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44333,DS-a15c869f-c030-4e33-9338-cabe7bb8877b,DISK], DatanodeInfoWithStorage[127.0.0.1:40740,DS-945cb40a-26ee-4e46-9e97-e811d8a70ec4,DISK], DatanodeInfoWithStorage[127.0.0.1:38783,DS-d62206b6-766b-4dd2-b753-21df5fcba228,DISK], DatanodeInfoWithStorage[127.0.0.1:46269,DS-57646550-5914-4446-8888-55d2e7f33594,DISK], DatanodeInfoWithStorage[127.0.0.1:42533,DS-5665a2ff-a197-4136-b587-50b78fab5cc5,DISK], DatanodeInfoWithStorage[127.0.0.1:44307,DS-ecacde8d-2310-41a2-b4a0-27fbf69c481b,DISK], DatanodeInfoWithStorage[127.0.0.1:40094,DS-c05f17ac-c13c-4bc9-8e3e-585cdd54ea8f,DISK], DatanodeInfoWithStorage[127.0.0.1:41543,DS-21d94890-1070-4d79-bb74-ba6aba42d1dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2130206487-172.17.0.17-1598145974243:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44333,DS-a15c869f-c030-4e33-9338-cabe7bb8877b,DISK], DatanodeInfoWithStorage[127.0.0.1:40740,DS-945cb40a-26ee-4e46-9e97-e811d8a70ec4,DISK], DatanodeInfoWithStorage[127.0.0.1:38783,DS-d62206b6-766b-4dd2-b753-21df5fcba228,DISK], DatanodeInfoWithStorage[127.0.0.1:46269,DS-57646550-5914-4446-8888-55d2e7f33594,DISK], DatanodeInfoWithStorage[127.0.0.1:42533,DS-5665a2ff-a197-4136-b587-50b78fab5cc5,DISK], DatanodeInfoWithStorage[127.0.0.1:44307,DS-ecacde8d-2310-41a2-b4a0-27fbf69c481b,DISK], DatanodeInfoWithStorage[127.0.0.1:40094,DS-c05f17ac-c13c-4bc9-8e3e-585cdd54ea8f,DISK], DatanodeInfoWithStorage[127.0.0.1:41543,DS-21d94890-1070-4d79-bb74-ba6aba42d1dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1903970041-172.17.0.17-1598146588483:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45192,DS-269c9261-0883-42c9-ae27-38ab3c77b20d,DISK], DatanodeInfoWithStorage[127.0.0.1:43440,DS-fe962e78-17e0-41e6-8b6c-f9f1324b2491,DISK], DatanodeInfoWithStorage[127.0.0.1:42824,DS-dcdf07a9-a965-4c81-81ba-bf2f416122b9,DISK], DatanodeInfoWithStorage[127.0.0.1:40843,DS-66c742ec-45d8-4981-bb0b-3f764f372e10,DISK], DatanodeInfoWithStorage[127.0.0.1:40140,DS-191454a2-246c-444b-8223-dca9bd562113,DISK], DatanodeInfoWithStorage[127.0.0.1:43444,DS-4d202560-75ca-493c-959d-c1d0c80875eb,DISK], DatanodeInfoWithStorage[127.0.0.1:40200,DS-3b6840a6-ad0e-4553-9b44-3ca0a2e29739,DISK], DatanodeInfoWithStorage[127.0.0.1:34327,DS-e732d8a8-9298-4e02-b9c6-91fbe1036596,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1903970041-172.17.0.17-1598146588483:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45192,DS-269c9261-0883-42c9-ae27-38ab3c77b20d,DISK], DatanodeInfoWithStorage[127.0.0.1:43440,DS-fe962e78-17e0-41e6-8b6c-f9f1324b2491,DISK], DatanodeInfoWithStorage[127.0.0.1:42824,DS-dcdf07a9-a965-4c81-81ba-bf2f416122b9,DISK], DatanodeInfoWithStorage[127.0.0.1:40843,DS-66c742ec-45d8-4981-bb0b-3f764f372e10,DISK], DatanodeInfoWithStorage[127.0.0.1:40140,DS-191454a2-246c-444b-8223-dca9bd562113,DISK], DatanodeInfoWithStorage[127.0.0.1:43444,DS-4d202560-75ca-493c-959d-c1d0c80875eb,DISK], DatanodeInfoWithStorage[127.0.0.1:40200,DS-3b6840a6-ad0e-4553-9b44-3ca0a2e29739,DISK], DatanodeInfoWithStorage[127.0.0.1:34327,DS-e732d8a8-9298-4e02-b9c6-91fbe1036596,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1721476972-172.17.0.17-1598146750964:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42185,DS-40ae8437-ea17-4a1b-a4ef-e0af4438b80f,DISK], DatanodeInfoWithStorage[127.0.0.1:33548,DS-51d1772e-fc27-4dbd-8d56-86b35aeda4db,DISK], DatanodeInfoWithStorage[127.0.0.1:39446,DS-c9ffcccf-2e67-412e-b45e-4933f9bb058a,DISK], DatanodeInfoWithStorage[127.0.0.1:36425,DS-9f5be436-25db-4907-9e1f-c39a423e29ff,DISK], DatanodeInfoWithStorage[127.0.0.1:32843,DS-9f88d267-16f7-4859-853e-4c5524e4b428,DISK], DatanodeInfoWithStorage[127.0.0.1:38178,DS-f68b681c-d079-4440-8ea3-7de66720ce02,DISK], DatanodeInfoWithStorage[127.0.0.1:46253,DS-ee8e3f7e-1a96-4a30-b5b9-ce4ae15dd4b6,DISK], DatanodeInfoWithStorage[127.0.0.1:46802,DS-bcc120c5-9915-4344-8b16-afe0d03a9424,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1721476972-172.17.0.17-1598146750964:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42185,DS-40ae8437-ea17-4a1b-a4ef-e0af4438b80f,DISK], DatanodeInfoWithStorage[127.0.0.1:33548,DS-51d1772e-fc27-4dbd-8d56-86b35aeda4db,DISK], DatanodeInfoWithStorage[127.0.0.1:39446,DS-c9ffcccf-2e67-412e-b45e-4933f9bb058a,DISK], DatanodeInfoWithStorage[127.0.0.1:36425,DS-9f5be436-25db-4907-9e1f-c39a423e29ff,DISK], DatanodeInfoWithStorage[127.0.0.1:32843,DS-9f88d267-16f7-4859-853e-4c5524e4b428,DISK], DatanodeInfoWithStorage[127.0.0.1:38178,DS-f68b681c-d079-4440-8ea3-7de66720ce02,DISK], DatanodeInfoWithStorage[127.0.0.1:46253,DS-ee8e3f7e-1a96-4a30-b5b9-ce4ae15dd4b6,DISK], DatanodeInfoWithStorage[127.0.0.1:46802,DS-bcc120c5-9915-4344-8b16-afe0d03a9424,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-167546777-172.17.0.17-1598146780193:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40781,DS-fa01cda3-c462-44fb-a8e0-106dcad9e87f,DISK], DatanodeInfoWithStorage[127.0.0.1:36639,DS-3a5acf68-c7fe-48a0-9d57-b3300da41958,DISK], DatanodeInfoWithStorage[127.0.0.1:44219,DS-82156362-1d23-4a27-b489-f90ba021bf89,DISK], DatanodeInfoWithStorage[127.0.0.1:42554,DS-1b294d91-39d4-411c-8c81-f40f4ff341fa,DISK], DatanodeInfoWithStorage[127.0.0.1:33186,DS-e893cf7d-6bff-4bc1-b748-f61ae312f2e3,DISK], DatanodeInfoWithStorage[127.0.0.1:32849,DS-502df8b0-6f10-47c4-882c-e0d8178dc518,DISK], DatanodeInfoWithStorage[127.0.0.1:42659,DS-267b4fff-79b7-42b7-aa28-71019298bb8b,DISK], DatanodeInfoWithStorage[127.0.0.1:43477,DS-b38dddb6-47d8-41fd-9e83-6552c097a703,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-167546777-172.17.0.17-1598146780193:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40781,DS-fa01cda3-c462-44fb-a8e0-106dcad9e87f,DISK], DatanodeInfoWithStorage[127.0.0.1:36639,DS-3a5acf68-c7fe-48a0-9d57-b3300da41958,DISK], DatanodeInfoWithStorage[127.0.0.1:44219,DS-82156362-1d23-4a27-b489-f90ba021bf89,DISK], DatanodeInfoWithStorage[127.0.0.1:42554,DS-1b294d91-39d4-411c-8c81-f40f4ff341fa,DISK], DatanodeInfoWithStorage[127.0.0.1:33186,DS-e893cf7d-6bff-4bc1-b748-f61ae312f2e3,DISK], DatanodeInfoWithStorage[127.0.0.1:32849,DS-502df8b0-6f10-47c4-882c-e0d8178dc518,DISK], DatanodeInfoWithStorage[127.0.0.1:42659,DS-267b4fff-79b7-42b7-aa28-71019298bb8b,DISK], DatanodeInfoWithStorage[127.0.0.1:43477,DS-b38dddb6-47d8-41fd-9e83-6552c097a703,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1459129880-172.17.0.17-1598147230949:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38850,DS-d43e902c-5bf2-448d-8d4a-aa9fe6ab37f3,DISK], DatanodeInfoWithStorage[127.0.0.1:35314,DS-1168b26e-ab33-4bb6-bf17-e93c78232153,DISK], DatanodeInfoWithStorage[127.0.0.1:36018,DS-d9c4e6a3-bdef-4920-b60a-eb045a5fe4bb,DISK], DatanodeInfoWithStorage[127.0.0.1:37378,DS-df7f3bbd-f0ee-4fd8-b554-a96c588e25bc,DISK], DatanodeInfoWithStorage[127.0.0.1:34317,DS-e421b765-0410-4acc-ae1a-d6bb9c7ce1fe,DISK], DatanodeInfoWithStorage[127.0.0.1:38307,DS-d3050862-d0bf-473d-af97-b531462a87ab,DISK], DatanodeInfoWithStorage[127.0.0.1:42395,DS-6cbe7ad2-5cc2-4d00-b837-a6c1af9114fd,DISK], DatanodeInfoWithStorage[127.0.0.1:44752,DS-718ec8fc-f286-46d4-b774-523e4fa41490,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1459129880-172.17.0.17-1598147230949:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38850,DS-d43e902c-5bf2-448d-8d4a-aa9fe6ab37f3,DISK], DatanodeInfoWithStorage[127.0.0.1:35314,DS-1168b26e-ab33-4bb6-bf17-e93c78232153,DISK], DatanodeInfoWithStorage[127.0.0.1:36018,DS-d9c4e6a3-bdef-4920-b60a-eb045a5fe4bb,DISK], DatanodeInfoWithStorage[127.0.0.1:37378,DS-df7f3bbd-f0ee-4fd8-b554-a96c588e25bc,DISK], DatanodeInfoWithStorage[127.0.0.1:34317,DS-e421b765-0410-4acc-ae1a-d6bb9c7ce1fe,DISK], DatanodeInfoWithStorage[127.0.0.1:38307,DS-d3050862-d0bf-473d-af97-b531462a87ab,DISK], DatanodeInfoWithStorage[127.0.0.1:42395,DS-6cbe7ad2-5cc2-4d00-b837-a6c1af9114fd,DISK], DatanodeInfoWithStorage[127.0.0.1:44752,DS-718ec8fc-f286-46d4-b774-523e4fa41490,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1367308080-172.17.0.17-1598148095565:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37276,DS-f3ad1c21-b0d2-49a2-b5e1-fdb947753d34,DISK], DatanodeInfoWithStorage[127.0.0.1:39740,DS-5fcfcc61-e4d6-44bc-80eb-c2e59769bd19,DISK], DatanodeInfoWithStorage[127.0.0.1:37074,DS-1264eb2b-dd25-4de7-aa79-b517f6d7620e,DISK], DatanodeInfoWithStorage[127.0.0.1:37682,DS-8f452965-497f-45c1-b5a5-a5d794f32ab2,DISK], DatanodeInfoWithStorage[127.0.0.1:32833,DS-b17ec423-7929-44e5-be78-0ece8d761afb,DISK], DatanodeInfoWithStorage[127.0.0.1:35655,DS-5bfeb9fb-ae64-4021-b339-6e3aa66787d7,DISK], DatanodeInfoWithStorage[127.0.0.1:42228,DS-1e0915be-b4f2-4e35-826e-b5c8642488d0,DISK], DatanodeInfoWithStorage[127.0.0.1:45882,DS-2de1da32-fdaf-487d-b503-2a0f09aeac80,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1367308080-172.17.0.17-1598148095565:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37276,DS-f3ad1c21-b0d2-49a2-b5e1-fdb947753d34,DISK], DatanodeInfoWithStorage[127.0.0.1:39740,DS-5fcfcc61-e4d6-44bc-80eb-c2e59769bd19,DISK], DatanodeInfoWithStorage[127.0.0.1:37074,DS-1264eb2b-dd25-4de7-aa79-b517f6d7620e,DISK], DatanodeInfoWithStorage[127.0.0.1:37682,DS-8f452965-497f-45c1-b5a5-a5d794f32ab2,DISK], DatanodeInfoWithStorage[127.0.0.1:32833,DS-b17ec423-7929-44e5-be78-0ece8d761afb,DISK], DatanodeInfoWithStorage[127.0.0.1:35655,DS-5bfeb9fb-ae64-4021-b339-6e3aa66787d7,DISK], DatanodeInfoWithStorage[127.0.0.1:42228,DS-1e0915be-b4f2-4e35-826e-b5c8642488d0,DISK], DatanodeInfoWithStorage[127.0.0.1:45882,DS-2de1da32-fdaf-487d-b503-2a0f09aeac80,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2078067369-172.17.0.17-1598148668297:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45960,DS-f200d254-9bc8-4ae0-8871-4b20cdd8ee1b,DISK], DatanodeInfoWithStorage[127.0.0.1:43844,DS-0b0af814-462a-4116-bf17-2797b855c89f,DISK], DatanodeInfoWithStorage[127.0.0.1:34049,DS-88a57613-334d-44bd-909b-25d3dc3c75ea,DISK], DatanodeInfoWithStorage[127.0.0.1:35064,DS-f4ebc4c8-ca2d-4ef5-8143-ebf808c36106,DISK], DatanodeInfoWithStorage[127.0.0.1:45163,DS-bd388cae-c460-4616-8be0-96d7587c0d79,DISK], DatanodeInfoWithStorage[127.0.0.1:39294,DS-cfff2507-f657-4590-899a-da4b6c9f07a8,DISK], DatanodeInfoWithStorage[127.0.0.1:37543,DS-9f330a5b-a6db-4576-9343-fca571cd373e,DISK], DatanodeInfoWithStorage[127.0.0.1:40164,DS-a1fa932c-dfc8-4b83-9995-903be93e878f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2078067369-172.17.0.17-1598148668297:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45960,DS-f200d254-9bc8-4ae0-8871-4b20cdd8ee1b,DISK], DatanodeInfoWithStorage[127.0.0.1:43844,DS-0b0af814-462a-4116-bf17-2797b855c89f,DISK], DatanodeInfoWithStorage[127.0.0.1:34049,DS-88a57613-334d-44bd-909b-25d3dc3c75ea,DISK], DatanodeInfoWithStorage[127.0.0.1:35064,DS-f4ebc4c8-ca2d-4ef5-8143-ebf808c36106,DISK], DatanodeInfoWithStorage[127.0.0.1:45163,DS-bd388cae-c460-4616-8be0-96d7587c0d79,DISK], DatanodeInfoWithStorage[127.0.0.1:39294,DS-cfff2507-f657-4590-899a-da4b6c9f07a8,DISK], DatanodeInfoWithStorage[127.0.0.1:37543,DS-9f330a5b-a6db-4576-9343-fca571cd373e,DISK], DatanodeInfoWithStorage[127.0.0.1:40164,DS-a1fa932c-dfc8-4b83-9995-903be93e878f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1831855243-172.17.0.17-1598148727373:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33072,DS-f5210d81-b87a-433f-92ca-b88e3dbd9a74,DISK], DatanodeInfoWithStorage[127.0.0.1:44024,DS-9bc24687-2ae8-48d7-82ca-ca9b8f9cda61,DISK], DatanodeInfoWithStorage[127.0.0.1:32971,DS-667b0ec1-7e8b-47e1-8c90-124c0786c05b,DISK], DatanodeInfoWithStorage[127.0.0.1:39396,DS-01b0e08d-212c-4863-bc95-575e66bb5197,DISK], DatanodeInfoWithStorage[127.0.0.1:44848,DS-f3e0b78c-f13d-4406-829c-c6d7a06c5982,DISK], DatanodeInfoWithStorage[127.0.0.1:45728,DS-4708d142-1a6a-48e4-bfe2-174c4e1b9948,DISK], DatanodeInfoWithStorage[127.0.0.1:45976,DS-bc469f32-a7c2-4836-b742-1f14ec3cd3b4,DISK], DatanodeInfoWithStorage[127.0.0.1:40496,DS-5653f2aa-9922-4fb2-aa32-8f3d8b6b2e75,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1831855243-172.17.0.17-1598148727373:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33072,DS-f5210d81-b87a-433f-92ca-b88e3dbd9a74,DISK], DatanodeInfoWithStorage[127.0.0.1:44024,DS-9bc24687-2ae8-48d7-82ca-ca9b8f9cda61,DISK], DatanodeInfoWithStorage[127.0.0.1:32971,DS-667b0ec1-7e8b-47e1-8c90-124c0786c05b,DISK], DatanodeInfoWithStorage[127.0.0.1:39396,DS-01b0e08d-212c-4863-bc95-575e66bb5197,DISK], DatanodeInfoWithStorage[127.0.0.1:44848,DS-f3e0b78c-f13d-4406-829c-c6d7a06c5982,DISK], DatanodeInfoWithStorage[127.0.0.1:45728,DS-4708d142-1a6a-48e4-bfe2-174c4e1b9948,DISK], DatanodeInfoWithStorage[127.0.0.1:45976,DS-bc469f32-a7c2-4836-b742-1f14ec3cd3b4,DISK], DatanodeInfoWithStorage[127.0.0.1:40496,DS-5653f2aa-9922-4fb2-aa32-8f3d8b6b2e75,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1268336195-172.17.0.17-1598148786921:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38251,DS-3a7b4fda-35ce-4dd4-916f-4bb9df430b6a,DISK], DatanodeInfoWithStorage[127.0.0.1:40211,DS-f9a1c52a-a019-4eae-8f80-5116e5e4ab9e,DISK], DatanodeInfoWithStorage[127.0.0.1:34441,DS-bc6e13e8-54dd-479b-92a8-d6a22ab17eba,DISK], DatanodeInfoWithStorage[127.0.0.1:33741,DS-e5929073-8eb2-4444-9184-e62cccb89368,DISK], DatanodeInfoWithStorage[127.0.0.1:45556,DS-4e5fb185-4c4b-4992-8fbc-2e8d199acb81,DISK], DatanodeInfoWithStorage[127.0.0.1:39181,DS-ef260481-a5dc-4f01-bea7-d10e4dfd517d,DISK], DatanodeInfoWithStorage[127.0.0.1:40033,DS-0c6ec5f0-6f45-4abd-ad61-4d7f33faaa8c,DISK], DatanodeInfoWithStorage[127.0.0.1:35401,DS-225bc915-9b12-4de3-959f-e763e8c4aced,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1268336195-172.17.0.17-1598148786921:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38251,DS-3a7b4fda-35ce-4dd4-916f-4bb9df430b6a,DISK], DatanodeInfoWithStorage[127.0.0.1:40211,DS-f9a1c52a-a019-4eae-8f80-5116e5e4ab9e,DISK], DatanodeInfoWithStorage[127.0.0.1:34441,DS-bc6e13e8-54dd-479b-92a8-d6a22ab17eba,DISK], DatanodeInfoWithStorage[127.0.0.1:33741,DS-e5929073-8eb2-4444-9184-e62cccb89368,DISK], DatanodeInfoWithStorage[127.0.0.1:45556,DS-4e5fb185-4c4b-4992-8fbc-2e8d199acb81,DISK], DatanodeInfoWithStorage[127.0.0.1:39181,DS-ef260481-a5dc-4f01-bea7-d10e4dfd517d,DISK], DatanodeInfoWithStorage[127.0.0.1:40033,DS-0c6ec5f0-6f45-4abd-ad61-4d7f33faaa8c,DISK], DatanodeInfoWithStorage[127.0.0.1:35401,DS-225bc915-9b12-4de3-959f-e763e8c4aced,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5084
