reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2119308642-172.17.0.21-1598346895364:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39619,DS-a7d75cbd-71bc-4574-9922-6a891d864809,DISK], DatanodeInfoWithStorage[127.0.0.1:37638,DS-1d684cbe-c3c3-4520-86f3-4afb0f01029c,DISK], DatanodeInfoWithStorage[127.0.0.1:33709,DS-667ff8cb-decc-45a4-82ce-ab143345c119,DISK], DatanodeInfoWithStorage[127.0.0.1:37639,DS-ae4adb85-d7f0-41ee-8c85-dbeffeb0922a,DISK], DatanodeInfoWithStorage[127.0.0.1:37298,DS-6fa0c07b-5a58-441d-abd7-c36b5cd7b9fb,DISK], DatanodeInfoWithStorage[127.0.0.1:44000,DS-2fb59442-e7fe-48a8-9ba4-6b99b73d95b0,DISK], DatanodeInfoWithStorage[127.0.0.1:42875,DS-ebf09a11-9d8e-467b-ae5e-fe93902433aa,DISK], DatanodeInfoWithStorage[127.0.0.1:40412,DS-82e007ab-adff-439b-a6f6-b00c6efbd1ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2119308642-172.17.0.21-1598346895364:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39619,DS-a7d75cbd-71bc-4574-9922-6a891d864809,DISK], DatanodeInfoWithStorage[127.0.0.1:37638,DS-1d684cbe-c3c3-4520-86f3-4afb0f01029c,DISK], DatanodeInfoWithStorage[127.0.0.1:33709,DS-667ff8cb-decc-45a4-82ce-ab143345c119,DISK], DatanodeInfoWithStorage[127.0.0.1:37639,DS-ae4adb85-d7f0-41ee-8c85-dbeffeb0922a,DISK], DatanodeInfoWithStorage[127.0.0.1:37298,DS-6fa0c07b-5a58-441d-abd7-c36b5cd7b9fb,DISK], DatanodeInfoWithStorage[127.0.0.1:44000,DS-2fb59442-e7fe-48a8-9ba4-6b99b73d95b0,DISK], DatanodeInfoWithStorage[127.0.0.1:42875,DS-ebf09a11-9d8e-467b-ae5e-fe93902433aa,DISK], DatanodeInfoWithStorage[127.0.0.1:40412,DS-82e007ab-adff-439b-a6f6-b00c6efbd1ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1409391833-172.17.0.21-1598347675022:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39424,DS-0e88aa3f-2c19-4e15-8b1b-c1203376d6a0,DISK], DatanodeInfoWithStorage[127.0.0.1:35012,DS-2bff9a61-8c7e-41c9-bb41-9a305147fddf,DISK], DatanodeInfoWithStorage[127.0.0.1:44144,DS-abdcb565-0ff5-4c71-aa15-5d9490d4d1bd,DISK], DatanodeInfoWithStorage[127.0.0.1:44518,DS-4cca69a9-33d1-4ce8-bdee-43f225570f86,DISK], DatanodeInfoWithStorage[127.0.0.1:42471,DS-efb71fa8-233a-41a6-91ad-d358f9ed343c,DISK], DatanodeInfoWithStorage[127.0.0.1:42304,DS-194e0f30-9336-4d14-95a2-922445e40969,DISK], DatanodeInfoWithStorage[127.0.0.1:45755,DS-f5944149-dbd7-407c-9d48-e87b24c716b6,DISK], DatanodeInfoWithStorage[127.0.0.1:43587,DS-71c38d39-fdee-4953-a27c-a1a39bcbe280,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1409391833-172.17.0.21-1598347675022:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39424,DS-0e88aa3f-2c19-4e15-8b1b-c1203376d6a0,DISK], DatanodeInfoWithStorage[127.0.0.1:35012,DS-2bff9a61-8c7e-41c9-bb41-9a305147fddf,DISK], DatanodeInfoWithStorage[127.0.0.1:44144,DS-abdcb565-0ff5-4c71-aa15-5d9490d4d1bd,DISK], DatanodeInfoWithStorage[127.0.0.1:44518,DS-4cca69a9-33d1-4ce8-bdee-43f225570f86,DISK], DatanodeInfoWithStorage[127.0.0.1:42471,DS-efb71fa8-233a-41a6-91ad-d358f9ed343c,DISK], DatanodeInfoWithStorage[127.0.0.1:42304,DS-194e0f30-9336-4d14-95a2-922445e40969,DISK], DatanodeInfoWithStorage[127.0.0.1:45755,DS-f5944149-dbd7-407c-9d48-e87b24c716b6,DISK], DatanodeInfoWithStorage[127.0.0.1:43587,DS-71c38d39-fdee-4953-a27c-a1a39bcbe280,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1906225281-172.17.0.21-1598348178957:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35107,DS-04bcf5a9-e304-4ebe-befd-b8cf88b46a5e,DISK], DatanodeInfoWithStorage[127.0.0.1:34835,DS-3691bca3-5639-4432-a4b7-5e445debe368,DISK], DatanodeInfoWithStorage[127.0.0.1:41782,DS-4b62567e-2ff9-4383-8ecc-425071b0f763,DISK], DatanodeInfoWithStorage[127.0.0.1:34017,DS-9f147f31-366b-4f23-ad78-2debc5bebe82,DISK], DatanodeInfoWithStorage[127.0.0.1:33764,DS-90322fa6-abe3-45d3-a6bb-d1dcdc5b09a3,DISK], DatanodeInfoWithStorage[127.0.0.1:34483,DS-45b11508-4b2e-41fd-94db-3e3c4ca47940,DISK], DatanodeInfoWithStorage[127.0.0.1:40493,DS-db6b8270-f274-4b53-b9e2-c0b4233cd02d,DISK], DatanodeInfoWithStorage[127.0.0.1:36978,DS-5b783128-99ab-4adb-90a3-a374f070d66b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1906225281-172.17.0.21-1598348178957:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35107,DS-04bcf5a9-e304-4ebe-befd-b8cf88b46a5e,DISK], DatanodeInfoWithStorage[127.0.0.1:34835,DS-3691bca3-5639-4432-a4b7-5e445debe368,DISK], DatanodeInfoWithStorage[127.0.0.1:41782,DS-4b62567e-2ff9-4383-8ecc-425071b0f763,DISK], DatanodeInfoWithStorage[127.0.0.1:34017,DS-9f147f31-366b-4f23-ad78-2debc5bebe82,DISK], DatanodeInfoWithStorage[127.0.0.1:33764,DS-90322fa6-abe3-45d3-a6bb-d1dcdc5b09a3,DISK], DatanodeInfoWithStorage[127.0.0.1:34483,DS-45b11508-4b2e-41fd-94db-3e3c4ca47940,DISK], DatanodeInfoWithStorage[127.0.0.1:40493,DS-db6b8270-f274-4b53-b9e2-c0b4233cd02d,DISK], DatanodeInfoWithStorage[127.0.0.1:36978,DS-5b783128-99ab-4adb-90a3-a374f070d66b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1177171515-172.17.0.21-1598348281844:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36116,DS-c4cddbad-bf80-4f07-b719-dfbb925e7d02,DISK], DatanodeInfoWithStorage[127.0.0.1:38642,DS-2c84f30d-4a81-4340-a5f7-1066668fb122,DISK], DatanodeInfoWithStorage[127.0.0.1:34970,DS-364e2cfe-ecea-4401-840a-282a78f689e8,DISK], DatanodeInfoWithStorage[127.0.0.1:45621,DS-6bc4b4e2-ad7f-43c0-85ea-563206b286e8,DISK], DatanodeInfoWithStorage[127.0.0.1:36246,DS-cc3fd190-8a4a-4174-af20-b4e1df9503a8,DISK], DatanodeInfoWithStorage[127.0.0.1:46552,DS-bddee4b6-4548-43ef-bfc0-f14345dcfd9b,DISK], DatanodeInfoWithStorage[127.0.0.1:40326,DS-e4657c05-70c5-4622-88f8-852ca3c42136,DISK], DatanodeInfoWithStorage[127.0.0.1:40790,DS-ea13485a-b77a-4998-8e2b-ace07840bcb3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1177171515-172.17.0.21-1598348281844:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36116,DS-c4cddbad-bf80-4f07-b719-dfbb925e7d02,DISK], DatanodeInfoWithStorage[127.0.0.1:38642,DS-2c84f30d-4a81-4340-a5f7-1066668fb122,DISK], DatanodeInfoWithStorage[127.0.0.1:34970,DS-364e2cfe-ecea-4401-840a-282a78f689e8,DISK], DatanodeInfoWithStorage[127.0.0.1:45621,DS-6bc4b4e2-ad7f-43c0-85ea-563206b286e8,DISK], DatanodeInfoWithStorage[127.0.0.1:36246,DS-cc3fd190-8a4a-4174-af20-b4e1df9503a8,DISK], DatanodeInfoWithStorage[127.0.0.1:46552,DS-bddee4b6-4548-43ef-bfc0-f14345dcfd9b,DISK], DatanodeInfoWithStorage[127.0.0.1:40326,DS-e4657c05-70c5-4622-88f8-852ca3c42136,DISK], DatanodeInfoWithStorage[127.0.0.1:40790,DS-ea13485a-b77a-4998-8e2b-ace07840bcb3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-167840681-172.17.0.21-1598348322522:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41759,DS-d8e3b9f5-ce68-4419-a742-587bbac01e30,DISK], DatanodeInfoWithStorage[127.0.0.1:33104,DS-f8801323-29cd-4cfa-8ed1-d6106c69faef,DISK], DatanodeInfoWithStorage[127.0.0.1:38208,DS-177c9558-8238-45e2-8681-d6fd61f05080,DISK], DatanodeInfoWithStorage[127.0.0.1:38852,DS-2820bc4e-3511-4e2e-b4db-7e1f7e736057,DISK], DatanodeInfoWithStorage[127.0.0.1:40700,DS-3a51429f-a315-4274-bd9c-e3cd2827759e,DISK], DatanodeInfoWithStorage[127.0.0.1:39690,DS-4bf3c012-4912-46f1-9131-7b3d19e1c4fd,DISK], DatanodeInfoWithStorage[127.0.0.1:36186,DS-809f58cb-6266-439d-9f6b-26aa744e248f,DISK], DatanodeInfoWithStorage[127.0.0.1:44640,DS-e3792399-0e0f-458e-a204-8334fb1d85bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-167840681-172.17.0.21-1598348322522:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41759,DS-d8e3b9f5-ce68-4419-a742-587bbac01e30,DISK], DatanodeInfoWithStorage[127.0.0.1:33104,DS-f8801323-29cd-4cfa-8ed1-d6106c69faef,DISK], DatanodeInfoWithStorage[127.0.0.1:38208,DS-177c9558-8238-45e2-8681-d6fd61f05080,DISK], DatanodeInfoWithStorage[127.0.0.1:38852,DS-2820bc4e-3511-4e2e-b4db-7e1f7e736057,DISK], DatanodeInfoWithStorage[127.0.0.1:40700,DS-3a51429f-a315-4274-bd9c-e3cd2827759e,DISK], DatanodeInfoWithStorage[127.0.0.1:39690,DS-4bf3c012-4912-46f1-9131-7b3d19e1c4fd,DISK], DatanodeInfoWithStorage[127.0.0.1:36186,DS-809f58cb-6266-439d-9f6b-26aa744e248f,DISK], DatanodeInfoWithStorage[127.0.0.1:44640,DS-e3792399-0e0f-458e-a204-8334fb1d85bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-931912185-172.17.0.21-1598348696842:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43055,DS-818685b9-477b-4723-92ed-8f5315aad564,DISK], DatanodeInfoWithStorage[127.0.0.1:39561,DS-b67fb15a-eb79-4e0d-a8fd-40e91981a8f6,DISK], DatanodeInfoWithStorage[127.0.0.1:46639,DS-75725ba8-1840-4e78-a64f-66adcab05760,DISK], DatanodeInfoWithStorage[127.0.0.1:37692,DS-ae3213e4-b324-4174-9fd3-676c7b67840c,DISK], DatanodeInfoWithStorage[127.0.0.1:41910,DS-d4edb190-8c1c-4cb7-87ea-4f2140a0b839,DISK], DatanodeInfoWithStorage[127.0.0.1:39047,DS-494eb979-3730-4b4a-8672-e6f340707036,DISK], DatanodeInfoWithStorage[127.0.0.1:42654,DS-91df06df-5ee7-4f6a-8485-c8ce2e96798b,DISK], DatanodeInfoWithStorage[127.0.0.1:38233,DS-c3cab1af-1889-42c2-869a-63601e725b44,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-931912185-172.17.0.21-1598348696842:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43055,DS-818685b9-477b-4723-92ed-8f5315aad564,DISK], DatanodeInfoWithStorage[127.0.0.1:39561,DS-b67fb15a-eb79-4e0d-a8fd-40e91981a8f6,DISK], DatanodeInfoWithStorage[127.0.0.1:46639,DS-75725ba8-1840-4e78-a64f-66adcab05760,DISK], DatanodeInfoWithStorage[127.0.0.1:37692,DS-ae3213e4-b324-4174-9fd3-676c7b67840c,DISK], DatanodeInfoWithStorage[127.0.0.1:41910,DS-d4edb190-8c1c-4cb7-87ea-4f2140a0b839,DISK], DatanodeInfoWithStorage[127.0.0.1:39047,DS-494eb979-3730-4b4a-8672-e6f340707036,DISK], DatanodeInfoWithStorage[127.0.0.1:42654,DS-91df06df-5ee7-4f6a-8485-c8ce2e96798b,DISK], DatanodeInfoWithStorage[127.0.0.1:38233,DS-c3cab1af-1889-42c2-869a-63601e725b44,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-899418812-172.17.0.21-1598349674585:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39538,DS-ca65afcd-e8b1-485d-9d41-8ff00ce8628d,DISK], DatanodeInfoWithStorage[127.0.0.1:38565,DS-5967a1d8-c4ab-4a9b-a4f5-9d27cd248794,DISK], DatanodeInfoWithStorage[127.0.0.1:40652,DS-45f4b2d7-9b2c-4498-9cba-8ae19a5ab76f,DISK], DatanodeInfoWithStorage[127.0.0.1:44021,DS-3880396a-52e7-4204-b3f8-a47f12c5244a,DISK], DatanodeInfoWithStorage[127.0.0.1:34574,DS-4d07ee9f-d398-4742-9738-2c8fc0f8f98a,DISK], DatanodeInfoWithStorage[127.0.0.1:43209,DS-814f36b7-7dec-4088-b5db-0da510394ba1,DISK], DatanodeInfoWithStorage[127.0.0.1:36123,DS-056b9a28-0e93-4fba-9047-a74b16096406,DISK], DatanodeInfoWithStorage[127.0.0.1:35855,DS-daf2e8cf-31a1-4f69-b35f-e57d0ef2a9af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-899418812-172.17.0.21-1598349674585:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39538,DS-ca65afcd-e8b1-485d-9d41-8ff00ce8628d,DISK], DatanodeInfoWithStorage[127.0.0.1:38565,DS-5967a1d8-c4ab-4a9b-a4f5-9d27cd248794,DISK], DatanodeInfoWithStorage[127.0.0.1:40652,DS-45f4b2d7-9b2c-4498-9cba-8ae19a5ab76f,DISK], DatanodeInfoWithStorage[127.0.0.1:44021,DS-3880396a-52e7-4204-b3f8-a47f12c5244a,DISK], DatanodeInfoWithStorage[127.0.0.1:34574,DS-4d07ee9f-d398-4742-9738-2c8fc0f8f98a,DISK], DatanodeInfoWithStorage[127.0.0.1:43209,DS-814f36b7-7dec-4088-b5db-0da510394ba1,DISK], DatanodeInfoWithStorage[127.0.0.1:36123,DS-056b9a28-0e93-4fba-9047-a74b16096406,DISK], DatanodeInfoWithStorage[127.0.0.1:35855,DS-daf2e8cf-31a1-4f69-b35f-e57d0ef2a9af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-439076359-172.17.0.21-1598349852778:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41184,DS-8b7fb724-f7bd-4be0-bdd3-6aa359b5afea,DISK], DatanodeInfoWithStorage[127.0.0.1:43023,DS-ba160800-620d-4ead-b766-8b8d787c6d26,DISK], DatanodeInfoWithStorage[127.0.0.1:43149,DS-7be897ec-9780-4c35-aecc-78153eefde00,DISK], DatanodeInfoWithStorage[127.0.0.1:42103,DS-0fac1a82-0505-4d87-9b84-5612324ffc57,DISK], DatanodeInfoWithStorage[127.0.0.1:36560,DS-c755a6aa-582d-4ea0-a1b4-728c6c62a92a,DISK], DatanodeInfoWithStorage[127.0.0.1:35398,DS-653938c6-427a-4b19-ad3e-8562d39751c4,DISK], DatanodeInfoWithStorage[127.0.0.1:35374,DS-5d219469-9c97-45c0-b6fd-f84c14328cb7,DISK], DatanodeInfoWithStorage[127.0.0.1:41339,DS-3d495425-58c5-4bd4-86ce-b4b2e459e89d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-439076359-172.17.0.21-1598349852778:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41184,DS-8b7fb724-f7bd-4be0-bdd3-6aa359b5afea,DISK], DatanodeInfoWithStorage[127.0.0.1:43023,DS-ba160800-620d-4ead-b766-8b8d787c6d26,DISK], DatanodeInfoWithStorage[127.0.0.1:43149,DS-7be897ec-9780-4c35-aecc-78153eefde00,DISK], DatanodeInfoWithStorage[127.0.0.1:42103,DS-0fac1a82-0505-4d87-9b84-5612324ffc57,DISK], DatanodeInfoWithStorage[127.0.0.1:36560,DS-c755a6aa-582d-4ea0-a1b4-728c6c62a92a,DISK], DatanodeInfoWithStorage[127.0.0.1:35398,DS-653938c6-427a-4b19-ad3e-8562d39751c4,DISK], DatanodeInfoWithStorage[127.0.0.1:35374,DS-5d219469-9c97-45c0-b6fd-f84c14328cb7,DISK], DatanodeInfoWithStorage[127.0.0.1:41339,DS-3d495425-58c5-4bd4-86ce-b4b2e459e89d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-648312392-172.17.0.21-1598349957389:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39109,DS-b7790ad7-5824-43df-9ecf-d14c51495a5b,DISK], DatanodeInfoWithStorage[127.0.0.1:34148,DS-1349a2f5-4261-408d-8302-c725b4f837b5,DISK], DatanodeInfoWithStorage[127.0.0.1:34482,DS-816ac0d8-8563-4934-89f2-c701111e29ea,DISK], DatanodeInfoWithStorage[127.0.0.1:33366,DS-114dcf1a-7e5e-4061-8687-3c206571c13b,DISK], DatanodeInfoWithStorage[127.0.0.1:38714,DS-cce1bfe9-4529-4ced-8b47-8a4a28e64dc7,DISK], DatanodeInfoWithStorage[127.0.0.1:33639,DS-0d6070b8-b33d-4985-a7e9-8a342f45959b,DISK], DatanodeInfoWithStorage[127.0.0.1:36339,DS-388f8f21-cfc2-4d97-a855-4e36935f1a0b,DISK], DatanodeInfoWithStorage[127.0.0.1:35241,DS-8e780def-7b37-4efb-8e9b-888075222069,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-648312392-172.17.0.21-1598349957389:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39109,DS-b7790ad7-5824-43df-9ecf-d14c51495a5b,DISK], DatanodeInfoWithStorage[127.0.0.1:34148,DS-1349a2f5-4261-408d-8302-c725b4f837b5,DISK], DatanodeInfoWithStorage[127.0.0.1:34482,DS-816ac0d8-8563-4934-89f2-c701111e29ea,DISK], DatanodeInfoWithStorage[127.0.0.1:33366,DS-114dcf1a-7e5e-4061-8687-3c206571c13b,DISK], DatanodeInfoWithStorage[127.0.0.1:38714,DS-cce1bfe9-4529-4ced-8b47-8a4a28e64dc7,DISK], DatanodeInfoWithStorage[127.0.0.1:33639,DS-0d6070b8-b33d-4985-a7e9-8a342f45959b,DISK], DatanodeInfoWithStorage[127.0.0.1:36339,DS-388f8f21-cfc2-4d97-a855-4e36935f1a0b,DISK], DatanodeInfoWithStorage[127.0.0.1:35241,DS-8e780def-7b37-4efb-8e9b-888075222069,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1475488279-172.17.0.21-1598349992370:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46829,DS-ff7a2ade-5338-47e3-a87c-02e9039d1091,DISK], DatanodeInfoWithStorage[127.0.0.1:39569,DS-0c1da512-b7f7-474b-b0bc-874b9cd6af87,DISK], DatanodeInfoWithStorage[127.0.0.1:37217,DS-e4a00037-5b97-473c-8d2b-8de0ed343754,DISK], DatanodeInfoWithStorage[127.0.0.1:45808,DS-8350dc23-f483-41f6-b5fc-9bbc6a91a2ac,DISK], DatanodeInfoWithStorage[127.0.0.1:36851,DS-7caf7035-86e0-4114-8afc-167c44174cf1,DISK], DatanodeInfoWithStorage[127.0.0.1:34130,DS-480747e6-c476-43d7-8697-a40a57a5a7c1,DISK], DatanodeInfoWithStorage[127.0.0.1:37459,DS-2fa92785-cd81-448b-9ff9-819949d89cfa,DISK], DatanodeInfoWithStorage[127.0.0.1:35975,DS-20afa6b3-2948-4331-9863-c8c212678348,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1475488279-172.17.0.21-1598349992370:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46829,DS-ff7a2ade-5338-47e3-a87c-02e9039d1091,DISK], DatanodeInfoWithStorage[127.0.0.1:39569,DS-0c1da512-b7f7-474b-b0bc-874b9cd6af87,DISK], DatanodeInfoWithStorage[127.0.0.1:37217,DS-e4a00037-5b97-473c-8d2b-8de0ed343754,DISK], DatanodeInfoWithStorage[127.0.0.1:45808,DS-8350dc23-f483-41f6-b5fc-9bbc6a91a2ac,DISK], DatanodeInfoWithStorage[127.0.0.1:36851,DS-7caf7035-86e0-4114-8afc-167c44174cf1,DISK], DatanodeInfoWithStorage[127.0.0.1:34130,DS-480747e6-c476-43d7-8697-a40a57a5a7c1,DISK], DatanodeInfoWithStorage[127.0.0.1:37459,DS-2fa92785-cd81-448b-9ff9-819949d89cfa,DISK], DatanodeInfoWithStorage[127.0.0.1:35975,DS-20afa6b3-2948-4331-9863-c8c212678348,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-638957143-172.17.0.21-1598350027377:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43787,DS-9f00d896-73d5-4143-8c49-f2b4685c332c,DISK], DatanodeInfoWithStorage[127.0.0.1:45377,DS-c4560fc0-8855-42af-9bdf-d78ea41363cd,DISK], DatanodeInfoWithStorage[127.0.0.1:43128,DS-9689ceb4-adf2-4b24-b357-d90f3f668ba1,DISK], DatanodeInfoWithStorage[127.0.0.1:33825,DS-2cba1ea9-1fdd-4fda-a69f-245c22a5bc4d,DISK], DatanodeInfoWithStorage[127.0.0.1:38287,DS-27d94d6a-2657-4d3d-a617-66fd8ea34d65,DISK], DatanodeInfoWithStorage[127.0.0.1:40931,DS-7f89510b-2bc7-43a1-98bc-80f167e629ef,DISK], DatanodeInfoWithStorage[127.0.0.1:37470,DS-39f757c6-6e2b-4e4b-b8c9-9a02934f3110,DISK], DatanodeInfoWithStorage[127.0.0.1:39092,DS-d2747063-83b1-4796-9948-0cd1242a3df1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-638957143-172.17.0.21-1598350027377:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43787,DS-9f00d896-73d5-4143-8c49-f2b4685c332c,DISK], DatanodeInfoWithStorage[127.0.0.1:45377,DS-c4560fc0-8855-42af-9bdf-d78ea41363cd,DISK], DatanodeInfoWithStorage[127.0.0.1:43128,DS-9689ceb4-adf2-4b24-b357-d90f3f668ba1,DISK], DatanodeInfoWithStorage[127.0.0.1:33825,DS-2cba1ea9-1fdd-4fda-a69f-245c22a5bc4d,DISK], DatanodeInfoWithStorage[127.0.0.1:38287,DS-27d94d6a-2657-4d3d-a617-66fd8ea34d65,DISK], DatanodeInfoWithStorage[127.0.0.1:40931,DS-7f89510b-2bc7-43a1-98bc-80f167e629ef,DISK], DatanodeInfoWithStorage[127.0.0.1:37470,DS-39f757c6-6e2b-4e4b-b8c9-9a02934f3110,DISK], DatanodeInfoWithStorage[127.0.0.1:39092,DS-d2747063-83b1-4796-9948-0cd1242a3df1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1485732789-172.17.0.21-1598350227186:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37630,DS-647240b7-e158-4341-b4ea-3f483de677dd,DISK], DatanodeInfoWithStorage[127.0.0.1:41293,DS-3dcbefc7-a9d8-4207-afd1-8386274887d1,DISK], DatanodeInfoWithStorage[127.0.0.1:33770,DS-968beb5a-0eb8-4834-a165-511d930d29c1,DISK], DatanodeInfoWithStorage[127.0.0.1:39329,DS-9865b75a-01f1-48cc-b1a2-e1dae484750c,DISK], DatanodeInfoWithStorage[127.0.0.1:45154,DS-b3a4d8ab-12a8-43d7-89da-bb68f96bc5ad,DISK], DatanodeInfoWithStorage[127.0.0.1:41234,DS-d09de8ac-d0a0-40ac-8c62-9614291fb323,DISK], DatanodeInfoWithStorage[127.0.0.1:43486,DS-238c36cd-9f85-4243-8838-ce647c8bd292,DISK], DatanodeInfoWithStorage[127.0.0.1:35729,DS-a41a8770-ff22-4281-8eab-8cd077fe32f4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1485732789-172.17.0.21-1598350227186:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37630,DS-647240b7-e158-4341-b4ea-3f483de677dd,DISK], DatanodeInfoWithStorage[127.0.0.1:41293,DS-3dcbefc7-a9d8-4207-afd1-8386274887d1,DISK], DatanodeInfoWithStorage[127.0.0.1:33770,DS-968beb5a-0eb8-4834-a165-511d930d29c1,DISK], DatanodeInfoWithStorage[127.0.0.1:39329,DS-9865b75a-01f1-48cc-b1a2-e1dae484750c,DISK], DatanodeInfoWithStorage[127.0.0.1:45154,DS-b3a4d8ab-12a8-43d7-89da-bb68f96bc5ad,DISK], DatanodeInfoWithStorage[127.0.0.1:41234,DS-d09de8ac-d0a0-40ac-8c62-9614291fb323,DISK], DatanodeInfoWithStorage[127.0.0.1:43486,DS-238c36cd-9f85-4243-8838-ce647c8bd292,DISK], DatanodeInfoWithStorage[127.0.0.1:35729,DS-a41a8770-ff22-4281-8eab-8cd077fe32f4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-372598493-172.17.0.21-1598350438314:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42811,DS-dce8e7a9-897b-4991-93ef-c7a2407e4569,DISK], DatanodeInfoWithStorage[127.0.0.1:41720,DS-ae5925fe-1c34-4f69-ac63-8d39ee92d815,DISK], DatanodeInfoWithStorage[127.0.0.1:45060,DS-54ba7bde-1d25-411b-b259-743fc0c9476f,DISK], DatanodeInfoWithStorage[127.0.0.1:44767,DS-1bcca46b-0e13-4177-88a2-39dc8ee97be1,DISK], DatanodeInfoWithStorage[127.0.0.1:45293,DS-f27f7855-6d07-42fe-aba2-349aab984225,DISK], DatanodeInfoWithStorage[127.0.0.1:41447,DS-06e130c1-fe95-46c8-8812-cf71903fc2ff,DISK], DatanodeInfoWithStorage[127.0.0.1:44677,DS-0e0489f4-15fe-4fd5-8bbe-71eeb49ddfe5,DISK], DatanodeInfoWithStorage[127.0.0.1:40472,DS-c6014480-22ec-4385-b049-c2ed771d2d25,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-372598493-172.17.0.21-1598350438314:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42811,DS-dce8e7a9-897b-4991-93ef-c7a2407e4569,DISK], DatanodeInfoWithStorage[127.0.0.1:41720,DS-ae5925fe-1c34-4f69-ac63-8d39ee92d815,DISK], DatanodeInfoWithStorage[127.0.0.1:45060,DS-54ba7bde-1d25-411b-b259-743fc0c9476f,DISK], DatanodeInfoWithStorage[127.0.0.1:44767,DS-1bcca46b-0e13-4177-88a2-39dc8ee97be1,DISK], DatanodeInfoWithStorage[127.0.0.1:45293,DS-f27f7855-6d07-42fe-aba2-349aab984225,DISK], DatanodeInfoWithStorage[127.0.0.1:41447,DS-06e130c1-fe95-46c8-8812-cf71903fc2ff,DISK], DatanodeInfoWithStorage[127.0.0.1:44677,DS-0e0489f4-15fe-4fd5-8bbe-71eeb49ddfe5,DISK], DatanodeInfoWithStorage[127.0.0.1:40472,DS-c6014480-22ec-4385-b049-c2ed771d2d25,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1341863083-172.17.0.21-1598351351705:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35290,DS-f3201874-07a4-4ac1-b466-ec893c28a736,DISK], DatanodeInfoWithStorage[127.0.0.1:45192,DS-17e38f1b-3364-4b80-b3df-7a7e183a2dc7,DISK], DatanodeInfoWithStorage[127.0.0.1:43748,DS-9c7d0a87-54fa-4ed3-9f5c-ee110e663bd5,DISK], DatanodeInfoWithStorage[127.0.0.1:37054,DS-c1bb8d43-d28b-4221-b0b9-65fda49870e8,DISK], DatanodeInfoWithStorage[127.0.0.1:40239,DS-c436f330-7718-450b-961d-8d9d338af672,DISK], DatanodeInfoWithStorage[127.0.0.1:39136,DS-2f6e4936-c7c7-4a31-b5c5-34e90c780ac0,DISK], DatanodeInfoWithStorage[127.0.0.1:46116,DS-4bc29e6d-46c0-4da7-9656-52ed5d35af9a,DISK], DatanodeInfoWithStorage[127.0.0.1:40766,DS-e3a68fa3-a650-4003-a86e-36fa3bf99399,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1341863083-172.17.0.21-1598351351705:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35290,DS-f3201874-07a4-4ac1-b466-ec893c28a736,DISK], DatanodeInfoWithStorage[127.0.0.1:45192,DS-17e38f1b-3364-4b80-b3df-7a7e183a2dc7,DISK], DatanodeInfoWithStorage[127.0.0.1:43748,DS-9c7d0a87-54fa-4ed3-9f5c-ee110e663bd5,DISK], DatanodeInfoWithStorage[127.0.0.1:37054,DS-c1bb8d43-d28b-4221-b0b9-65fda49870e8,DISK], DatanodeInfoWithStorage[127.0.0.1:40239,DS-c436f330-7718-450b-961d-8d9d338af672,DISK], DatanodeInfoWithStorage[127.0.0.1:39136,DS-2f6e4936-c7c7-4a31-b5c5-34e90c780ac0,DISK], DatanodeInfoWithStorage[127.0.0.1:46116,DS-4bc29e6d-46c0-4da7-9656-52ed5d35af9a,DISK], DatanodeInfoWithStorage[127.0.0.1:40766,DS-e3a68fa3-a650-4003-a86e-36fa3bf99399,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 2 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 4996
