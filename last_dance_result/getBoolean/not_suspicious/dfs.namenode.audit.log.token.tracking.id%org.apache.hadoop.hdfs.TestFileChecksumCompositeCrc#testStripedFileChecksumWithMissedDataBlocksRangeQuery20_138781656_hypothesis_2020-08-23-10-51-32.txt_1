reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-145681433-172.17.0.3-1598179973682:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38296,DS-06d493a3-8bf3-4ea8-a3cb-c3cabd2e0018,DISK], DatanodeInfoWithStorage[127.0.0.1:39442,DS-a3ff19af-0943-4ad3-a83b-d34805efa797,DISK], DatanodeInfoWithStorage[127.0.0.1:35496,DS-ba8b3e22-65d1-43dd-8075-7aec5a89452c,DISK], DatanodeInfoWithStorage[127.0.0.1:42102,DS-3615b915-b543-4d7a-b492-fdb672de4f09,DISK], DatanodeInfoWithStorage[127.0.0.1:35567,DS-0c07f73a-7a57-49ac-8d22-77f6317673c2,DISK], DatanodeInfoWithStorage[127.0.0.1:44583,DS-487bf029-ff09-4ae4-850c-ce9174688aae,DISK], DatanodeInfoWithStorage[127.0.0.1:41566,DS-894d9fcb-a25e-4e11-a2d1-9ae92c4a1bb0,DISK], DatanodeInfoWithStorage[127.0.0.1:40994,DS-b0934ece-3a2b-4635-894c-6ebad735d8f4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-145681433-172.17.0.3-1598179973682:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38296,DS-06d493a3-8bf3-4ea8-a3cb-c3cabd2e0018,DISK], DatanodeInfoWithStorage[127.0.0.1:39442,DS-a3ff19af-0943-4ad3-a83b-d34805efa797,DISK], DatanodeInfoWithStorage[127.0.0.1:35496,DS-ba8b3e22-65d1-43dd-8075-7aec5a89452c,DISK], DatanodeInfoWithStorage[127.0.0.1:42102,DS-3615b915-b543-4d7a-b492-fdb672de4f09,DISK], DatanodeInfoWithStorage[127.0.0.1:35567,DS-0c07f73a-7a57-49ac-8d22-77f6317673c2,DISK], DatanodeInfoWithStorage[127.0.0.1:44583,DS-487bf029-ff09-4ae4-850c-ce9174688aae,DISK], DatanodeInfoWithStorage[127.0.0.1:41566,DS-894d9fcb-a25e-4e11-a2d1-9ae92c4a1bb0,DISK], DatanodeInfoWithStorage[127.0.0.1:40994,DS-b0934ece-3a2b-4635-894c-6ebad735d8f4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-878033420-172.17.0.3-1598180081340:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40033,DS-7c1900f8-83f4-4817-b045-d20fde375883,DISK], DatanodeInfoWithStorage[127.0.0.1:46551,DS-84983d61-d9ff-4e83-aaf1-dd902a99fc56,DISK], DatanodeInfoWithStorage[127.0.0.1:35029,DS-d9308678-320e-47c9-9031-4c3d786a2beb,DISK], DatanodeInfoWithStorage[127.0.0.1:37744,DS-2ff69802-7cac-4322-8933-bad9119a4d6c,DISK], DatanodeInfoWithStorage[127.0.0.1:32995,DS-ae6f1eba-9be2-4dfb-bb03-63991383859b,DISK], DatanodeInfoWithStorage[127.0.0.1:37408,DS-c4a5b840-b085-45e4-b657-65bead0a48e2,DISK], DatanodeInfoWithStorage[127.0.0.1:43905,DS-85ebaa30-233a-4351-ba40-8e4efc73f9ad,DISK], DatanodeInfoWithStorage[127.0.0.1:40934,DS-2514dc8d-9170-42e2-a018-db53af19864a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-878033420-172.17.0.3-1598180081340:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40033,DS-7c1900f8-83f4-4817-b045-d20fde375883,DISK], DatanodeInfoWithStorage[127.0.0.1:46551,DS-84983d61-d9ff-4e83-aaf1-dd902a99fc56,DISK], DatanodeInfoWithStorage[127.0.0.1:35029,DS-d9308678-320e-47c9-9031-4c3d786a2beb,DISK], DatanodeInfoWithStorage[127.0.0.1:37744,DS-2ff69802-7cac-4322-8933-bad9119a4d6c,DISK], DatanodeInfoWithStorage[127.0.0.1:32995,DS-ae6f1eba-9be2-4dfb-bb03-63991383859b,DISK], DatanodeInfoWithStorage[127.0.0.1:37408,DS-c4a5b840-b085-45e4-b657-65bead0a48e2,DISK], DatanodeInfoWithStorage[127.0.0.1:43905,DS-85ebaa30-233a-4351-ba40-8e4efc73f9ad,DISK], DatanodeInfoWithStorage[127.0.0.1:40934,DS-2514dc8d-9170-42e2-a018-db53af19864a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-284822027-172.17.0.3-1598180304699:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38357,DS-6cb05554-af24-41d3-953b-804ae96e8f74,DISK], DatanodeInfoWithStorage[127.0.0.1:38043,DS-870f5356-0b5b-44b0-b73a-78baae95d819,DISK], DatanodeInfoWithStorage[127.0.0.1:46790,DS-0f7a303e-1410-4043-9ff3-ad95f54a0e5a,DISK], DatanodeInfoWithStorage[127.0.0.1:34845,DS-c77697f0-8bdf-4010-8117-d6285eb14892,DISK], DatanodeInfoWithStorage[127.0.0.1:43339,DS-c9e1452f-a895-415b-bb71-d7e85f4f438b,DISK], DatanodeInfoWithStorage[127.0.0.1:43323,DS-2505b289-d85c-4378-bae4-c45ec7ec22b2,DISK], DatanodeInfoWithStorage[127.0.0.1:45109,DS-ccdde1f3-4b7c-4d65-8f20-9cfa10c05dd1,DISK], DatanodeInfoWithStorage[127.0.0.1:46015,DS-24d8605e-809b-4721-b60d-0ec049270064,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-284822027-172.17.0.3-1598180304699:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38357,DS-6cb05554-af24-41d3-953b-804ae96e8f74,DISK], DatanodeInfoWithStorage[127.0.0.1:38043,DS-870f5356-0b5b-44b0-b73a-78baae95d819,DISK], DatanodeInfoWithStorage[127.0.0.1:46790,DS-0f7a303e-1410-4043-9ff3-ad95f54a0e5a,DISK], DatanodeInfoWithStorage[127.0.0.1:34845,DS-c77697f0-8bdf-4010-8117-d6285eb14892,DISK], DatanodeInfoWithStorage[127.0.0.1:43339,DS-c9e1452f-a895-415b-bb71-d7e85f4f438b,DISK], DatanodeInfoWithStorage[127.0.0.1:43323,DS-2505b289-d85c-4378-bae4-c45ec7ec22b2,DISK], DatanodeInfoWithStorage[127.0.0.1:45109,DS-ccdde1f3-4b7c-4d65-8f20-9cfa10c05dd1,DISK], DatanodeInfoWithStorage[127.0.0.1:46015,DS-24d8605e-809b-4721-b60d-0ec049270064,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-12802625-172.17.0.3-1598180770158:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44733,DS-2dc81e43-ec63-44dc-9e0a-3f3ba3237ecb,DISK], DatanodeInfoWithStorage[127.0.0.1:45528,DS-d202f847-f0d2-4b6e-9c47-6980430086dc,DISK], DatanodeInfoWithStorage[127.0.0.1:39430,DS-7371337b-f6ee-4af4-9a7b-68f3c2f5a495,DISK], DatanodeInfoWithStorage[127.0.0.1:36471,DS-4b11ca75-1c06-43de-aec9-0824f63c4e6d,DISK], DatanodeInfoWithStorage[127.0.0.1:41028,DS-e5970b90-9671-449b-bdbc-88873b8c006e,DISK], DatanodeInfoWithStorage[127.0.0.1:41460,DS-ecdd8e03-9bf8-4626-aaf2-55f959ed3a0e,DISK], DatanodeInfoWithStorage[127.0.0.1:42568,DS-5e3e1e11-f817-415c-86c3-e2bb2c4476aa,DISK], DatanodeInfoWithStorage[127.0.0.1:42684,DS-896d6b85-9672-4ac5-9bc2-b33b5118f582,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-12802625-172.17.0.3-1598180770158:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44733,DS-2dc81e43-ec63-44dc-9e0a-3f3ba3237ecb,DISK], DatanodeInfoWithStorage[127.0.0.1:45528,DS-d202f847-f0d2-4b6e-9c47-6980430086dc,DISK], DatanodeInfoWithStorage[127.0.0.1:39430,DS-7371337b-f6ee-4af4-9a7b-68f3c2f5a495,DISK], DatanodeInfoWithStorage[127.0.0.1:36471,DS-4b11ca75-1c06-43de-aec9-0824f63c4e6d,DISK], DatanodeInfoWithStorage[127.0.0.1:41028,DS-e5970b90-9671-449b-bdbc-88873b8c006e,DISK], DatanodeInfoWithStorage[127.0.0.1:41460,DS-ecdd8e03-9bf8-4626-aaf2-55f959ed3a0e,DISK], DatanodeInfoWithStorage[127.0.0.1:42568,DS-5e3e1e11-f817-415c-86c3-e2bb2c4476aa,DISK], DatanodeInfoWithStorage[127.0.0.1:42684,DS-896d6b85-9672-4ac5-9bc2-b33b5118f582,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1940842630-172.17.0.3-1598180874886:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45434,DS-b243081e-65c0-40c7-9bef-9b00faf131ce,DISK], DatanodeInfoWithStorage[127.0.0.1:42965,DS-e4a676c4-6b26-4bc8-98f4-f9f2aac258c2,DISK], DatanodeInfoWithStorage[127.0.0.1:35531,DS-946e2c65-31f2-4640-bd0b-29c7fcd57615,DISK], DatanodeInfoWithStorage[127.0.0.1:41138,DS-966056ac-33cc-49dc-a20a-9b3524330f41,DISK], DatanodeInfoWithStorage[127.0.0.1:42876,DS-08fe40d5-f185-400a-979a-9acb6477181a,DISK], DatanodeInfoWithStorage[127.0.0.1:33672,DS-55b5169f-70c9-4127-a696-ab148e1969f5,DISK], DatanodeInfoWithStorage[127.0.0.1:43427,DS-0ecc06b0-1562-43e9-8b67-368650cd38d2,DISK], DatanodeInfoWithStorage[127.0.0.1:41599,DS-2fa30951-a3e2-4607-80cc-da974b7a057d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1940842630-172.17.0.3-1598180874886:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45434,DS-b243081e-65c0-40c7-9bef-9b00faf131ce,DISK], DatanodeInfoWithStorage[127.0.0.1:42965,DS-e4a676c4-6b26-4bc8-98f4-f9f2aac258c2,DISK], DatanodeInfoWithStorage[127.0.0.1:35531,DS-946e2c65-31f2-4640-bd0b-29c7fcd57615,DISK], DatanodeInfoWithStorage[127.0.0.1:41138,DS-966056ac-33cc-49dc-a20a-9b3524330f41,DISK], DatanodeInfoWithStorage[127.0.0.1:42876,DS-08fe40d5-f185-400a-979a-9acb6477181a,DISK], DatanodeInfoWithStorage[127.0.0.1:33672,DS-55b5169f-70c9-4127-a696-ab148e1969f5,DISK], DatanodeInfoWithStorage[127.0.0.1:43427,DS-0ecc06b0-1562-43e9-8b67-368650cd38d2,DISK], DatanodeInfoWithStorage[127.0.0.1:41599,DS-2fa30951-a3e2-4607-80cc-da974b7a057d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-383865261-172.17.0.3-1598180909563:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44865,DS-3f9314c0-d9be-421d-97a0-c5b38a40bbf6,DISK], DatanodeInfoWithStorage[127.0.0.1:44709,DS-3f812e4f-ddc6-475c-a5e8-3cce3812580a,DISK], DatanodeInfoWithStorage[127.0.0.1:44193,DS-de311e5b-1aed-4d9b-a257-b5d2c7afcf02,DISK], DatanodeInfoWithStorage[127.0.0.1:45283,DS-47c4970b-5496-492d-a7d8-bc8881325b2b,DISK], DatanodeInfoWithStorage[127.0.0.1:37345,DS-56cd87aa-fa49-4cab-8d8b-106c9559ea47,DISK], DatanodeInfoWithStorage[127.0.0.1:38204,DS-e43aee62-5c16-482c-833c-78081a5d5fb9,DISK], DatanodeInfoWithStorage[127.0.0.1:40178,DS-3d7427f2-8728-4998-86fa-35b14adecb19,DISK], DatanodeInfoWithStorage[127.0.0.1:37459,DS-f631f28a-aa3d-4014-a90b-79d9e6f56507,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-383865261-172.17.0.3-1598180909563:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44865,DS-3f9314c0-d9be-421d-97a0-c5b38a40bbf6,DISK], DatanodeInfoWithStorage[127.0.0.1:44709,DS-3f812e4f-ddc6-475c-a5e8-3cce3812580a,DISK], DatanodeInfoWithStorage[127.0.0.1:44193,DS-de311e5b-1aed-4d9b-a257-b5d2c7afcf02,DISK], DatanodeInfoWithStorage[127.0.0.1:45283,DS-47c4970b-5496-492d-a7d8-bc8881325b2b,DISK], DatanodeInfoWithStorage[127.0.0.1:37345,DS-56cd87aa-fa49-4cab-8d8b-106c9559ea47,DISK], DatanodeInfoWithStorage[127.0.0.1:38204,DS-e43aee62-5c16-482c-833c-78081a5d5fb9,DISK], DatanodeInfoWithStorage[127.0.0.1:40178,DS-3d7427f2-8728-4998-86fa-35b14adecb19,DISK], DatanodeInfoWithStorage[127.0.0.1:37459,DS-f631f28a-aa3d-4014-a90b-79d9e6f56507,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-235774973-172.17.0.3-1598181170787:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37668,DS-ba25e36d-f333-46df-915c-8f67ee76ba1f,DISK], DatanodeInfoWithStorage[127.0.0.1:40397,DS-cddb3d47-948b-478a-9e8a-54cc163fa4cd,DISK], DatanodeInfoWithStorage[127.0.0.1:37674,DS-7b1e7a81-5016-4b22-a010-189597bad766,DISK], DatanodeInfoWithStorage[127.0.0.1:41460,DS-a8b51753-1188-4772-8c3d-8ce14c2083a7,DISK], DatanodeInfoWithStorage[127.0.0.1:38187,DS-47e3d6c6-5bc5-4c23-9d59-ca25b734c066,DISK], DatanodeInfoWithStorage[127.0.0.1:43369,DS-1a449dc8-86be-4474-bec2-ffdb34a1a0e5,DISK], DatanodeInfoWithStorage[127.0.0.1:42200,DS-d1bb8781-9266-4ea9-90fe-2149150be2b8,DISK], DatanodeInfoWithStorage[127.0.0.1:45246,DS-c7dc3136-1889-4409-9f92-a40e268ce0ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-235774973-172.17.0.3-1598181170787:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37668,DS-ba25e36d-f333-46df-915c-8f67ee76ba1f,DISK], DatanodeInfoWithStorage[127.0.0.1:40397,DS-cddb3d47-948b-478a-9e8a-54cc163fa4cd,DISK], DatanodeInfoWithStorage[127.0.0.1:37674,DS-7b1e7a81-5016-4b22-a010-189597bad766,DISK], DatanodeInfoWithStorage[127.0.0.1:41460,DS-a8b51753-1188-4772-8c3d-8ce14c2083a7,DISK], DatanodeInfoWithStorage[127.0.0.1:38187,DS-47e3d6c6-5bc5-4c23-9d59-ca25b734c066,DISK], DatanodeInfoWithStorage[127.0.0.1:43369,DS-1a449dc8-86be-4474-bec2-ffdb34a1a0e5,DISK], DatanodeInfoWithStorage[127.0.0.1:42200,DS-d1bb8781-9266-4ea9-90fe-2149150be2b8,DISK], DatanodeInfoWithStorage[127.0.0.1:45246,DS-c7dc3136-1889-4409-9f92-a40e268ce0ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-774056560-172.17.0.3-1598181209295:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44046,DS-c6a43f9c-6db8-4c7e-91f7-1c7d9ca8ef94,DISK], DatanodeInfoWithStorage[127.0.0.1:36986,DS-bd796331-8892-4056-886e-61ee205d57f8,DISK], DatanodeInfoWithStorage[127.0.0.1:36029,DS-c3e4453e-e5cf-4979-921d-087171702e20,DISK], DatanodeInfoWithStorage[127.0.0.1:35827,DS-a0db2663-f9c9-4727-90c5-da98b4b8f3ed,DISK], DatanodeInfoWithStorage[127.0.0.1:34135,DS-93d11e06-f702-4c9d-a373-f975c77391de,DISK], DatanodeInfoWithStorage[127.0.0.1:40980,DS-b3b70b16-97e4-4c89-a91f-63eb48a3b4c2,DISK], DatanodeInfoWithStorage[127.0.0.1:44277,DS-33399e81-ca70-4296-bd15-42f6f28ca42b,DISK], DatanodeInfoWithStorage[127.0.0.1:35003,DS-9f1e94e6-dd5c-4245-9a9a-f48c54871600,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-774056560-172.17.0.3-1598181209295:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44046,DS-c6a43f9c-6db8-4c7e-91f7-1c7d9ca8ef94,DISK], DatanodeInfoWithStorage[127.0.0.1:36986,DS-bd796331-8892-4056-886e-61ee205d57f8,DISK], DatanodeInfoWithStorage[127.0.0.1:36029,DS-c3e4453e-e5cf-4979-921d-087171702e20,DISK], DatanodeInfoWithStorage[127.0.0.1:35827,DS-a0db2663-f9c9-4727-90c5-da98b4b8f3ed,DISK], DatanodeInfoWithStorage[127.0.0.1:34135,DS-93d11e06-f702-4c9d-a373-f975c77391de,DISK], DatanodeInfoWithStorage[127.0.0.1:40980,DS-b3b70b16-97e4-4c89-a91f-63eb48a3b4c2,DISK], DatanodeInfoWithStorage[127.0.0.1:44277,DS-33399e81-ca70-4296-bd15-42f6f28ca42b,DISK], DatanodeInfoWithStorage[127.0.0.1:35003,DS-9f1e94e6-dd5c-4245-9a9a-f48c54871600,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-36769672-172.17.0.3-1598181240165:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34408,DS-2877d5d8-4c48-4642-bbdb-80ad52ea2871,DISK], DatanodeInfoWithStorage[127.0.0.1:43958,DS-feeea564-28cd-44f0-97ab-a0b1aa41ed7c,DISK], DatanodeInfoWithStorage[127.0.0.1:45298,DS-fcbf87de-d2f3-4a4d-8a7b-f02512b37fa3,DISK], DatanodeInfoWithStorage[127.0.0.1:35434,DS-9c427029-eb5d-4568-9c9a-e9ee7f0a38bd,DISK], DatanodeInfoWithStorage[127.0.0.1:44062,DS-ad0b1b9b-ab4f-4fc9-a958-e1425eaa186c,DISK], DatanodeInfoWithStorage[127.0.0.1:36626,DS-6396203b-89b8-44a4-a60a-c965305586ef,DISK], DatanodeInfoWithStorage[127.0.0.1:45689,DS-1001f440-72d6-4606-8566-934f45f6c2cf,DISK], DatanodeInfoWithStorage[127.0.0.1:44457,DS-50b27967-0913-4766-bd29-00f9db47acaf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-36769672-172.17.0.3-1598181240165:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34408,DS-2877d5d8-4c48-4642-bbdb-80ad52ea2871,DISK], DatanodeInfoWithStorage[127.0.0.1:43958,DS-feeea564-28cd-44f0-97ab-a0b1aa41ed7c,DISK], DatanodeInfoWithStorage[127.0.0.1:45298,DS-fcbf87de-d2f3-4a4d-8a7b-f02512b37fa3,DISK], DatanodeInfoWithStorage[127.0.0.1:35434,DS-9c427029-eb5d-4568-9c9a-e9ee7f0a38bd,DISK], DatanodeInfoWithStorage[127.0.0.1:44062,DS-ad0b1b9b-ab4f-4fc9-a958-e1425eaa186c,DISK], DatanodeInfoWithStorage[127.0.0.1:36626,DS-6396203b-89b8-44a4-a60a-c965305586ef,DISK], DatanodeInfoWithStorage[127.0.0.1:45689,DS-1001f440-72d6-4606-8566-934f45f6c2cf,DISK], DatanodeInfoWithStorage[127.0.0.1:44457,DS-50b27967-0913-4766-bd29-00f9db47acaf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-541035730-172.17.0.3-1598181342743:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46235,DS-801e5a53-c526-42f5-8495-844ba011e837,DISK], DatanodeInfoWithStorage[127.0.0.1:45667,DS-14fdce76-99ad-49b7-ad42-189456962ddb,DISK], DatanodeInfoWithStorage[127.0.0.1:33689,DS-db896037-58ef-451d-907b-6094e613c94f,DISK], DatanodeInfoWithStorage[127.0.0.1:41706,DS-9f287cb1-8874-4697-883d-4ade8e628bce,DISK], DatanodeInfoWithStorage[127.0.0.1:39878,DS-8e8cce70-b099-4250-9a68-09e74e16544d,DISK], DatanodeInfoWithStorage[127.0.0.1:40502,DS-a1ed1b6c-f41b-43e2-85fc-6286f9710dac,DISK], DatanodeInfoWithStorage[127.0.0.1:40725,DS-5cb09d68-c375-4bbf-8c37-bfc7211c6aff,DISK], DatanodeInfoWithStorage[127.0.0.1:46778,DS-2d490b54-bf7e-4fc5-a965-213c3d45d25e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-541035730-172.17.0.3-1598181342743:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46235,DS-801e5a53-c526-42f5-8495-844ba011e837,DISK], DatanodeInfoWithStorage[127.0.0.1:45667,DS-14fdce76-99ad-49b7-ad42-189456962ddb,DISK], DatanodeInfoWithStorage[127.0.0.1:33689,DS-db896037-58ef-451d-907b-6094e613c94f,DISK], DatanodeInfoWithStorage[127.0.0.1:41706,DS-9f287cb1-8874-4697-883d-4ade8e628bce,DISK], DatanodeInfoWithStorage[127.0.0.1:39878,DS-8e8cce70-b099-4250-9a68-09e74e16544d,DISK], DatanodeInfoWithStorage[127.0.0.1:40502,DS-a1ed1b6c-f41b-43e2-85fc-6286f9710dac,DISK], DatanodeInfoWithStorage[127.0.0.1:40725,DS-5cb09d68-c375-4bbf-8c37-bfc7211c6aff,DISK], DatanodeInfoWithStorage[127.0.0.1:46778,DS-2d490b54-bf7e-4fc5-a965-213c3d45d25e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1876261419-172.17.0.3-1598181999505:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42087,DS-e5ee23e3-5d97-4e86-9e56-e393edfaec79,DISK], DatanodeInfoWithStorage[127.0.0.1:40053,DS-ff6dc545-f767-4333-9969-1a4f6406c9d3,DISK], DatanodeInfoWithStorage[127.0.0.1:45177,DS-f8279a0f-d45a-49e0-aa0d-5658f1debcd9,DISK], DatanodeInfoWithStorage[127.0.0.1:43148,DS-d46390a4-b112-48ff-a4cc-8a07909cbc03,DISK], DatanodeInfoWithStorage[127.0.0.1:44816,DS-80f2f84f-ef6b-461a-b8cb-2002cb408cb6,DISK], DatanodeInfoWithStorage[127.0.0.1:36321,DS-93db1352-668b-4769-9a13-3628a2da9d12,DISK], DatanodeInfoWithStorage[127.0.0.1:46151,DS-c7084483-bca1-4c48-b9ea-87d657010518,DISK], DatanodeInfoWithStorage[127.0.0.1:38065,DS-f9067c62-c6e1-4e2a-a163-ce63c0e56f3b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1876261419-172.17.0.3-1598181999505:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42087,DS-e5ee23e3-5d97-4e86-9e56-e393edfaec79,DISK], DatanodeInfoWithStorage[127.0.0.1:40053,DS-ff6dc545-f767-4333-9969-1a4f6406c9d3,DISK], DatanodeInfoWithStorage[127.0.0.1:45177,DS-f8279a0f-d45a-49e0-aa0d-5658f1debcd9,DISK], DatanodeInfoWithStorage[127.0.0.1:43148,DS-d46390a4-b112-48ff-a4cc-8a07909cbc03,DISK], DatanodeInfoWithStorage[127.0.0.1:44816,DS-80f2f84f-ef6b-461a-b8cb-2002cb408cb6,DISK], DatanodeInfoWithStorage[127.0.0.1:36321,DS-93db1352-668b-4769-9a13-3628a2da9d12,DISK], DatanodeInfoWithStorage[127.0.0.1:46151,DS-c7084483-bca1-4c48-b9ea-87d657010518,DISK], DatanodeInfoWithStorage[127.0.0.1:38065,DS-f9067c62-c6e1-4e2a-a163-ce63c0e56f3b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1690436279-172.17.0.3-1598182301035:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39693,DS-3d60bccc-c86c-4420-8261-abed5d9cd04e,DISK], DatanodeInfoWithStorage[127.0.0.1:36533,DS-746d4c63-b80e-47e6-bb88-1a37051650a0,DISK], DatanodeInfoWithStorage[127.0.0.1:42912,DS-85f9b842-3f73-4c87-ade7-882168e906d4,DISK], DatanodeInfoWithStorage[127.0.0.1:43171,DS-ad957b07-0124-4b84-ba2f-d46c83727b0f,DISK], DatanodeInfoWithStorage[127.0.0.1:42040,DS-2490d05a-a696-447d-8e22-a18a19307079,DISK], DatanodeInfoWithStorage[127.0.0.1:41711,DS-741a9563-1783-4bf4-b200-9901b3ad1358,DISK], DatanodeInfoWithStorage[127.0.0.1:34827,DS-ed552d27-62a0-414e-b853-74348bc18781,DISK], DatanodeInfoWithStorage[127.0.0.1:39939,DS-2d8e63b3-c679-413f-bfc6-7c306dd14f44,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1690436279-172.17.0.3-1598182301035:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39693,DS-3d60bccc-c86c-4420-8261-abed5d9cd04e,DISK], DatanodeInfoWithStorage[127.0.0.1:36533,DS-746d4c63-b80e-47e6-bb88-1a37051650a0,DISK], DatanodeInfoWithStorage[127.0.0.1:42912,DS-85f9b842-3f73-4c87-ade7-882168e906d4,DISK], DatanodeInfoWithStorage[127.0.0.1:43171,DS-ad957b07-0124-4b84-ba2f-d46c83727b0f,DISK], DatanodeInfoWithStorage[127.0.0.1:42040,DS-2490d05a-a696-447d-8e22-a18a19307079,DISK], DatanodeInfoWithStorage[127.0.0.1:41711,DS-741a9563-1783-4bf4-b200-9901b3ad1358,DISK], DatanodeInfoWithStorage[127.0.0.1:34827,DS-ed552d27-62a0-414e-b853-74348bc18781,DISK], DatanodeInfoWithStorage[127.0.0.1:39939,DS-2d8e63b3-c679-413f-bfc6-7c306dd14f44,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1556848454-172.17.0.3-1598182364651:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35796,DS-25dcb1df-d6bb-4180-a33c-3e18d1857f79,DISK], DatanodeInfoWithStorage[127.0.0.1:41857,DS-8fd71086-42b4-4288-abea-fd4f52528eb6,DISK], DatanodeInfoWithStorage[127.0.0.1:41191,DS-e0491ed1-16d3-4a32-b1eb-2dbabc02d368,DISK], DatanodeInfoWithStorage[127.0.0.1:38006,DS-65d1641b-3fea-4f06-a477-94f9ff5344be,DISK], DatanodeInfoWithStorage[127.0.0.1:45943,DS-d4c6f346-aa27-4fdd-918a-e91814f7aaf2,DISK], DatanodeInfoWithStorage[127.0.0.1:43627,DS-6c34c95d-f864-4b53-9390-970cae7fff54,DISK], DatanodeInfoWithStorage[127.0.0.1:42419,DS-94f44763-76ec-40f9-ac3c-6e40d9de1ffc,DISK], DatanodeInfoWithStorage[127.0.0.1:35555,DS-4898d8db-d64b-4814-b428-b390d010d06b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1556848454-172.17.0.3-1598182364651:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35796,DS-25dcb1df-d6bb-4180-a33c-3e18d1857f79,DISK], DatanodeInfoWithStorage[127.0.0.1:41857,DS-8fd71086-42b4-4288-abea-fd4f52528eb6,DISK], DatanodeInfoWithStorage[127.0.0.1:41191,DS-e0491ed1-16d3-4a32-b1eb-2dbabc02d368,DISK], DatanodeInfoWithStorage[127.0.0.1:38006,DS-65d1641b-3fea-4f06-a477-94f9ff5344be,DISK], DatanodeInfoWithStorage[127.0.0.1:45943,DS-d4c6f346-aa27-4fdd-918a-e91814f7aaf2,DISK], DatanodeInfoWithStorage[127.0.0.1:43627,DS-6c34c95d-f864-4b53-9390-970cae7fff54,DISK], DatanodeInfoWithStorage[127.0.0.1:42419,DS-94f44763-76ec-40f9-ac3c-6e40d9de1ffc,DISK], DatanodeInfoWithStorage[127.0.0.1:35555,DS-4898d8db-d64b-4814-b428-b390d010d06b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1270136684-172.17.0.3-1598182532089:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35067,DS-41457b6b-f9a6-4389-8d80-260c1cb27047,DISK], DatanodeInfoWithStorage[127.0.0.1:39889,DS-bd84659d-ae60-441a-9570-a262f6b42634,DISK], DatanodeInfoWithStorage[127.0.0.1:40831,DS-703a0706-479d-41ce-ba9e-dff7af34555a,DISK], DatanodeInfoWithStorage[127.0.0.1:34648,DS-fc01b16d-5d12-4294-88b7-712f91ee6682,DISK], DatanodeInfoWithStorage[127.0.0.1:33521,DS-0f448e82-ecdb-4cde-bb91-6696708ce8e3,DISK], DatanodeInfoWithStorage[127.0.0.1:42055,DS-c853f7ae-3744-47fa-b8ab-01c19b54dfa3,DISK], DatanodeInfoWithStorage[127.0.0.1:44637,DS-af3e9745-bce5-4fbf-9dd4-b8e9186c49d5,DISK], DatanodeInfoWithStorage[127.0.0.1:46324,DS-628a9cfc-c7b8-4d23-b81d-04b894b60ad1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1270136684-172.17.0.3-1598182532089:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35067,DS-41457b6b-f9a6-4389-8d80-260c1cb27047,DISK], DatanodeInfoWithStorage[127.0.0.1:39889,DS-bd84659d-ae60-441a-9570-a262f6b42634,DISK], DatanodeInfoWithStorage[127.0.0.1:40831,DS-703a0706-479d-41ce-ba9e-dff7af34555a,DISK], DatanodeInfoWithStorage[127.0.0.1:34648,DS-fc01b16d-5d12-4294-88b7-712f91ee6682,DISK], DatanodeInfoWithStorage[127.0.0.1:33521,DS-0f448e82-ecdb-4cde-bb91-6696708ce8e3,DISK], DatanodeInfoWithStorage[127.0.0.1:42055,DS-c853f7ae-3744-47fa-b8ab-01c19b54dfa3,DISK], DatanodeInfoWithStorage[127.0.0.1:44637,DS-af3e9745-bce5-4fbf-9dd4-b8e9186c49d5,DISK], DatanodeInfoWithStorage[127.0.0.1:46324,DS-628a9cfc-c7b8-4d23-b81d-04b894b60ad1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1732780240-172.17.0.3-1598182734070:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42513,DS-b615c9f8-4754-429c-a90a-438bdb628a14,DISK], DatanodeInfoWithStorage[127.0.0.1:38787,DS-53eb3f5f-091b-47b8-a577-496b5968cd81,DISK], DatanodeInfoWithStorage[127.0.0.1:38669,DS-c6d794fd-f44d-4a9a-ab97-5697b3ed9b2f,DISK], DatanodeInfoWithStorage[127.0.0.1:38321,DS-40152ce0-20c9-41bd-94c1-a30a4a2aaf5e,DISK], DatanodeInfoWithStorage[127.0.0.1:36204,DS-39972c99-43aa-445d-9a84-8f5a13b1ba82,DISK], DatanodeInfoWithStorage[127.0.0.1:45757,DS-4d477908-53ec-462e-835b-728e38f8905f,DISK], DatanodeInfoWithStorage[127.0.0.1:42516,DS-266158fe-8454-494e-b13c-2e921ca26b4b,DISK], DatanodeInfoWithStorage[127.0.0.1:40260,DS-db4a5f0f-b77c-4cc5-8348-d7c8971eaef6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1732780240-172.17.0.3-1598182734070:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42513,DS-b615c9f8-4754-429c-a90a-438bdb628a14,DISK], DatanodeInfoWithStorage[127.0.0.1:38787,DS-53eb3f5f-091b-47b8-a577-496b5968cd81,DISK], DatanodeInfoWithStorage[127.0.0.1:38669,DS-c6d794fd-f44d-4a9a-ab97-5697b3ed9b2f,DISK], DatanodeInfoWithStorage[127.0.0.1:38321,DS-40152ce0-20c9-41bd-94c1-a30a4a2aaf5e,DISK], DatanodeInfoWithStorage[127.0.0.1:36204,DS-39972c99-43aa-445d-9a84-8f5a13b1ba82,DISK], DatanodeInfoWithStorage[127.0.0.1:45757,DS-4d477908-53ec-462e-835b-728e38f8905f,DISK], DatanodeInfoWithStorage[127.0.0.1:42516,DS-266158fe-8454-494e-b13c-2e921ca26b4b,DISK], DatanodeInfoWithStorage[127.0.0.1:40260,DS-db4a5f0f-b77c-4cc5-8348-d7c8971eaef6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-244263259-172.17.0.3-1598182795283:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37380,DS-f4264528-235c-41fc-b0b2-29f2c2c8ae79,DISK], DatanodeInfoWithStorage[127.0.0.1:41317,DS-ca9d21ad-a534-4fc3-9ca1-a448eaa56851,DISK], DatanodeInfoWithStorage[127.0.0.1:33547,DS-a12dddaa-0137-487e-a6f7-f1cef97dec28,DISK], DatanodeInfoWithStorage[127.0.0.1:38942,DS-95ad3481-22cf-4350-b9f2-97be014ab2f6,DISK], DatanodeInfoWithStorage[127.0.0.1:40868,DS-94b89747-b1b4-4c02-a386-1db62454dde3,DISK], DatanodeInfoWithStorage[127.0.0.1:40554,DS-44624583-68aa-43cd-a6f0-06352768c08d,DISK], DatanodeInfoWithStorage[127.0.0.1:34665,DS-c1c7fdfb-2027-42c4-9235-d1b0c321d572,DISK], DatanodeInfoWithStorage[127.0.0.1:41954,DS-c03525fa-c287-483d-8da4-1cfdefb0e5e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-244263259-172.17.0.3-1598182795283:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37380,DS-f4264528-235c-41fc-b0b2-29f2c2c8ae79,DISK], DatanodeInfoWithStorage[127.0.0.1:41317,DS-ca9d21ad-a534-4fc3-9ca1-a448eaa56851,DISK], DatanodeInfoWithStorage[127.0.0.1:33547,DS-a12dddaa-0137-487e-a6f7-f1cef97dec28,DISK], DatanodeInfoWithStorage[127.0.0.1:38942,DS-95ad3481-22cf-4350-b9f2-97be014ab2f6,DISK], DatanodeInfoWithStorage[127.0.0.1:40868,DS-94b89747-b1b4-4c02-a386-1db62454dde3,DISK], DatanodeInfoWithStorage[127.0.0.1:40554,DS-44624583-68aa-43cd-a6f0-06352768c08d,DISK], DatanodeInfoWithStorage[127.0.0.1:34665,DS-c1c7fdfb-2027-42c4-9235-d1b0c321d572,DISK], DatanodeInfoWithStorage[127.0.0.1:41954,DS-c03525fa-c287-483d-8da4-1cfdefb0e5e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1635411462-172.17.0.3-1598183221154:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38382,DS-d7773d3c-9cbf-4ea0-9844-7a4150f9ce8e,DISK], DatanodeInfoWithStorage[127.0.0.1:46198,DS-4814f53f-a61b-40e9-b83b-f6d5a7b05ee8,DISK], DatanodeInfoWithStorage[127.0.0.1:35813,DS-f8f83196-b159-4745-a700-2e6c9cbcb374,DISK], DatanodeInfoWithStorage[127.0.0.1:45235,DS-bd7ee334-01b0-4372-a77f-b8e286b516a7,DISK], DatanodeInfoWithStorage[127.0.0.1:40631,DS-d734d234-9b21-4cb3-9d1f-a15ae361619a,DISK], DatanodeInfoWithStorage[127.0.0.1:40316,DS-8e647f77-75ba-410d-803f-a50665bc40d6,DISK], DatanodeInfoWithStorage[127.0.0.1:35350,DS-17fb3188-f354-468f-8b99-0a3e75891dba,DISK], DatanodeInfoWithStorage[127.0.0.1:37912,DS-9ea165df-19b2-46a8-bf83-8cb471f5ae61,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1635411462-172.17.0.3-1598183221154:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38382,DS-d7773d3c-9cbf-4ea0-9844-7a4150f9ce8e,DISK], DatanodeInfoWithStorage[127.0.0.1:46198,DS-4814f53f-a61b-40e9-b83b-f6d5a7b05ee8,DISK], DatanodeInfoWithStorage[127.0.0.1:35813,DS-f8f83196-b159-4745-a700-2e6c9cbcb374,DISK], DatanodeInfoWithStorage[127.0.0.1:45235,DS-bd7ee334-01b0-4372-a77f-b8e286b516a7,DISK], DatanodeInfoWithStorage[127.0.0.1:40631,DS-d734d234-9b21-4cb3-9d1f-a15ae361619a,DISK], DatanodeInfoWithStorage[127.0.0.1:40316,DS-8e647f77-75ba-410d-803f-a50665bc40d6,DISK], DatanodeInfoWithStorage[127.0.0.1:35350,DS-17fb3188-f354-468f-8b99-0a3e75891dba,DISK], DatanodeInfoWithStorage[127.0.0.1:37912,DS-9ea165df-19b2-46a8-bf83-8cb471f5ae61,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-972397568-172.17.0.3-1598183305350:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34455,DS-26e0b183-cd03-4de7-b0e6-3c429a674d62,DISK], DatanodeInfoWithStorage[127.0.0.1:44471,DS-313d9d60-5e39-4202-a689-dacd780462a2,DISK], DatanodeInfoWithStorage[127.0.0.1:46439,DS-3acb08b1-9d08-4b68-86fc-20e44e5b70e8,DISK], DatanodeInfoWithStorage[127.0.0.1:39887,DS-b0842209-d410-4f27-bdbf-f0f75626478b,DISK], DatanodeInfoWithStorage[127.0.0.1:42958,DS-1ec812f7-75c6-480f-bd11-ec331efaf704,DISK], DatanodeInfoWithStorage[127.0.0.1:41333,DS-bcb24160-1239-4030-84c2-a0c7bfbcce52,DISK], DatanodeInfoWithStorage[127.0.0.1:40956,DS-ce5a95d6-0c26-477b-85c7-bf57673c484b,DISK], DatanodeInfoWithStorage[127.0.0.1:40929,DS-06464c0d-151f-42a4-866e-f33a480fd50d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-972397568-172.17.0.3-1598183305350:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34455,DS-26e0b183-cd03-4de7-b0e6-3c429a674d62,DISK], DatanodeInfoWithStorage[127.0.0.1:44471,DS-313d9d60-5e39-4202-a689-dacd780462a2,DISK], DatanodeInfoWithStorage[127.0.0.1:46439,DS-3acb08b1-9d08-4b68-86fc-20e44e5b70e8,DISK], DatanodeInfoWithStorage[127.0.0.1:39887,DS-b0842209-d410-4f27-bdbf-f0f75626478b,DISK], DatanodeInfoWithStorage[127.0.0.1:42958,DS-1ec812f7-75c6-480f-bd11-ec331efaf704,DISK], DatanodeInfoWithStorage[127.0.0.1:41333,DS-bcb24160-1239-4030-84c2-a0c7bfbcce52,DISK], DatanodeInfoWithStorage[127.0.0.1:40956,DS-ce5a95d6-0c26-477b-85c7-bf57673c484b,DISK], DatanodeInfoWithStorage[127.0.0.1:40929,DS-06464c0d-151f-42a4-866e-f33a480fd50d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-377298077-172.17.0.3-1598183552750:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33470,DS-6f2d2939-9435-4234-8451-d10f6b289a72,DISK], DatanodeInfoWithStorage[127.0.0.1:40256,DS-29af744b-22b9-4f41-83bd-e34f9ca3c5c7,DISK], DatanodeInfoWithStorage[127.0.0.1:36630,DS-6d7d4eba-f9da-412b-8384-ba595596ffec,DISK], DatanodeInfoWithStorage[127.0.0.1:38640,DS-def145bf-d1e2-44f7-a0ec-a903fdec9c61,DISK], DatanodeInfoWithStorage[127.0.0.1:45607,DS-eed89b1b-4962-42cc-b4c9-aa963b20bf3d,DISK], DatanodeInfoWithStorage[127.0.0.1:38862,DS-4c190324-bb14-422c-83d3-d1fd533450d9,DISK], DatanodeInfoWithStorage[127.0.0.1:32995,DS-92771eaa-257c-4268-b7db-40f7e0c22256,DISK], DatanodeInfoWithStorage[127.0.0.1:44490,DS-39d6a8ba-8d22-4d65-8e66-775e1e154651,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-377298077-172.17.0.3-1598183552750:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33470,DS-6f2d2939-9435-4234-8451-d10f6b289a72,DISK], DatanodeInfoWithStorage[127.0.0.1:40256,DS-29af744b-22b9-4f41-83bd-e34f9ca3c5c7,DISK], DatanodeInfoWithStorage[127.0.0.1:36630,DS-6d7d4eba-f9da-412b-8384-ba595596ffec,DISK], DatanodeInfoWithStorage[127.0.0.1:38640,DS-def145bf-d1e2-44f7-a0ec-a903fdec9c61,DISK], DatanodeInfoWithStorage[127.0.0.1:45607,DS-eed89b1b-4962-42cc-b4c9-aa963b20bf3d,DISK], DatanodeInfoWithStorage[127.0.0.1:38862,DS-4c190324-bb14-422c-83d3-d1fd533450d9,DISK], DatanodeInfoWithStorage[127.0.0.1:32995,DS-92771eaa-257c-4268-b7db-40f7e0c22256,DISK], DatanodeInfoWithStorage[127.0.0.1:44490,DS-39d6a8ba-8d22-4d65-8e66-775e1e154651,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-909067565-172.17.0.3-1598183619325:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35742,DS-d8a53b5a-1898-4f48-8839-d6683bc0eeb7,DISK], DatanodeInfoWithStorage[127.0.0.1:39238,DS-41607835-8cef-4dfa-860d-629627478bc6,DISK], DatanodeInfoWithStorage[127.0.0.1:37643,DS-414fabf0-e35c-4e80-9889-893722ff0f09,DISK], DatanodeInfoWithStorage[127.0.0.1:37741,DS-b11b2d3b-9386-4cd8-849b-de05cb3671a5,DISK], DatanodeInfoWithStorage[127.0.0.1:42745,DS-2bb2d759-ad33-4b20-9b09-0cad240d6826,DISK], DatanodeInfoWithStorage[127.0.0.1:41513,DS-89257080-4508-40e8-88c3-9bb3f937790a,DISK], DatanodeInfoWithStorage[127.0.0.1:37005,DS-f44b2d1a-b4a9-4b64-a2eb-8a90ff2749da,DISK], DatanodeInfoWithStorage[127.0.0.1:43198,DS-79ce5d7a-a565-4d04-be5d-a8fecdcbd525,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-909067565-172.17.0.3-1598183619325:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35742,DS-d8a53b5a-1898-4f48-8839-d6683bc0eeb7,DISK], DatanodeInfoWithStorage[127.0.0.1:39238,DS-41607835-8cef-4dfa-860d-629627478bc6,DISK], DatanodeInfoWithStorage[127.0.0.1:37643,DS-414fabf0-e35c-4e80-9889-893722ff0f09,DISK], DatanodeInfoWithStorage[127.0.0.1:37741,DS-b11b2d3b-9386-4cd8-849b-de05cb3671a5,DISK], DatanodeInfoWithStorage[127.0.0.1:42745,DS-2bb2d759-ad33-4b20-9b09-0cad240d6826,DISK], DatanodeInfoWithStorage[127.0.0.1:41513,DS-89257080-4508-40e8-88c3-9bb3f937790a,DISK], DatanodeInfoWithStorage[127.0.0.1:37005,DS-f44b2d1a-b4a9-4b64-a2eb-8a90ff2749da,DISK], DatanodeInfoWithStorage[127.0.0.1:43198,DS-79ce5d7a-a565-4d04-be5d-a8fecdcbd525,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1781277158-172.17.0.3-1598183790280:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42315,DS-09700693-aa13-4354-b8d7-912e50fdd658,DISK], DatanodeInfoWithStorage[127.0.0.1:43945,DS-9eac3c5e-0538-4ac6-b339-63893ad579b3,DISK], DatanodeInfoWithStorage[127.0.0.1:38389,DS-693cba46-d50c-4f1e-8165-dd9df3e8cabb,DISK], DatanodeInfoWithStorage[127.0.0.1:35591,DS-9fd27f0a-49ab-442e-b476-cab76f5ec37e,DISK], DatanodeInfoWithStorage[127.0.0.1:34913,DS-84f980c3-df1b-4f06-ae82-9c643794ca13,DISK], DatanodeInfoWithStorage[127.0.0.1:35368,DS-a33c4b43-e0f5-4bc6-8be7-5613fe1cbb67,DISK], DatanodeInfoWithStorage[127.0.0.1:37509,DS-b7bcc911-e350-44b7-ba89-cc4699b87deb,DISK], DatanodeInfoWithStorage[127.0.0.1:33693,DS-edac9833-a111-4781-b75a-0595c82e13ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1781277158-172.17.0.3-1598183790280:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42315,DS-09700693-aa13-4354-b8d7-912e50fdd658,DISK], DatanodeInfoWithStorage[127.0.0.1:43945,DS-9eac3c5e-0538-4ac6-b339-63893ad579b3,DISK], DatanodeInfoWithStorage[127.0.0.1:38389,DS-693cba46-d50c-4f1e-8165-dd9df3e8cabb,DISK], DatanodeInfoWithStorage[127.0.0.1:35591,DS-9fd27f0a-49ab-442e-b476-cab76f5ec37e,DISK], DatanodeInfoWithStorage[127.0.0.1:34913,DS-84f980c3-df1b-4f06-ae82-9c643794ca13,DISK], DatanodeInfoWithStorage[127.0.0.1:35368,DS-a33c4b43-e0f5-4bc6-8be7-5613fe1cbb67,DISK], DatanodeInfoWithStorage[127.0.0.1:37509,DS-b7bcc911-e350-44b7-ba89-cc4699b87deb,DISK], DatanodeInfoWithStorage[127.0.0.1:33693,DS-edac9833-a111-4781-b75a-0595c82e13ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-789556405-172.17.0.3-1598184067497:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36283,DS-8a18d318-7b53-4bdf-869c-c74267a6bbbf,DISK], DatanodeInfoWithStorage[127.0.0.1:39784,DS-535c1329-8a73-4827-965d-1559336ddc59,DISK], DatanodeInfoWithStorage[127.0.0.1:43403,DS-6c808abb-5e82-425a-92b1-c093acde0503,DISK], DatanodeInfoWithStorage[127.0.0.1:38172,DS-5d03260b-7e83-41f9-aaea-14936c10bf50,DISK], DatanodeInfoWithStorage[127.0.0.1:36254,DS-0864cffb-9f7b-429b-a56b-fdc313abf383,DISK], DatanodeInfoWithStorage[127.0.0.1:44179,DS-b5806f8f-6d16-4571-bee5-30ddb2dc4471,DISK], DatanodeInfoWithStorage[127.0.0.1:41197,DS-8f9aea42-9363-46e4-8534-63e0ced54ecc,DISK], DatanodeInfoWithStorage[127.0.0.1:34181,DS-cf698ce6-1bc3-4a59-99f7-943c9707fb3f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-789556405-172.17.0.3-1598184067497:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36283,DS-8a18d318-7b53-4bdf-869c-c74267a6bbbf,DISK], DatanodeInfoWithStorage[127.0.0.1:39784,DS-535c1329-8a73-4827-965d-1559336ddc59,DISK], DatanodeInfoWithStorage[127.0.0.1:43403,DS-6c808abb-5e82-425a-92b1-c093acde0503,DISK], DatanodeInfoWithStorage[127.0.0.1:38172,DS-5d03260b-7e83-41f9-aaea-14936c10bf50,DISK], DatanodeInfoWithStorage[127.0.0.1:36254,DS-0864cffb-9f7b-429b-a56b-fdc313abf383,DISK], DatanodeInfoWithStorage[127.0.0.1:44179,DS-b5806f8f-6d16-4571-bee5-30ddb2dc4471,DISK], DatanodeInfoWithStorage[127.0.0.1:41197,DS-8f9aea42-9363-46e4-8534-63e0ced54ecc,DISK], DatanodeInfoWithStorage[127.0.0.1:34181,DS-cf698ce6-1bc3-4a59-99f7-943c9707fb3f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1716762580-172.17.0.3-1598184165058:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42586,DS-067d554b-a07e-4390-b57e-951e99b85c72,DISK], DatanodeInfoWithStorage[127.0.0.1:35353,DS-66f78e2f-5b06-4898-86c1-078f73aa8e3d,DISK], DatanodeInfoWithStorage[127.0.0.1:35692,DS-1208be5c-fc05-4c05-9fb6-6ccd2fe3dd8b,DISK], DatanodeInfoWithStorage[127.0.0.1:43093,DS-98aa500e-43d0-4aec-ba09-7bbfdcd31111,DISK], DatanodeInfoWithStorage[127.0.0.1:39021,DS-b3a10194-3817-418f-858e-1e0d6fcadba3,DISK], DatanodeInfoWithStorage[127.0.0.1:33689,DS-b70868a8-2b32-41f3-afc4-fddfb214564b,DISK], DatanodeInfoWithStorage[127.0.0.1:44511,DS-2ff8d49c-1b0f-40bc-8842-86383d96b5ee,DISK], DatanodeInfoWithStorage[127.0.0.1:44427,DS-3b82bd8b-d835-4293-8f6d-d8007f229ebc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1716762580-172.17.0.3-1598184165058:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42586,DS-067d554b-a07e-4390-b57e-951e99b85c72,DISK], DatanodeInfoWithStorage[127.0.0.1:35353,DS-66f78e2f-5b06-4898-86c1-078f73aa8e3d,DISK], DatanodeInfoWithStorage[127.0.0.1:35692,DS-1208be5c-fc05-4c05-9fb6-6ccd2fe3dd8b,DISK], DatanodeInfoWithStorage[127.0.0.1:43093,DS-98aa500e-43d0-4aec-ba09-7bbfdcd31111,DISK], DatanodeInfoWithStorage[127.0.0.1:39021,DS-b3a10194-3817-418f-858e-1e0d6fcadba3,DISK], DatanodeInfoWithStorage[127.0.0.1:33689,DS-b70868a8-2b32-41f3-afc4-fddfb214564b,DISK], DatanodeInfoWithStorage[127.0.0.1:44511,DS-2ff8d49c-1b0f-40bc-8842-86383d96b5ee,DISK], DatanodeInfoWithStorage[127.0.0.1:44427,DS-3b82bd8b-d835-4293-8f6d-d8007f229ebc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-949615863-172.17.0.3-1598184200632:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35482,DS-47f4c2e6-1667-42d6-8338-57382ea3410c,DISK], DatanodeInfoWithStorage[127.0.0.1:36894,DS-88abb251-b064-4819-a7fc-0a808e8e7a23,DISK], DatanodeInfoWithStorage[127.0.0.1:44020,DS-773921f1-e0c1-4a44-89bf-00fc5a50cfe1,DISK], DatanodeInfoWithStorage[127.0.0.1:34455,DS-686791b6-84b6-4907-97a8-2cccb3899b43,DISK], DatanodeInfoWithStorage[127.0.0.1:39679,DS-e8f2be0a-c075-40aa-bb06-e628e8efdc90,DISK], DatanodeInfoWithStorage[127.0.0.1:33944,DS-863f8d28-905b-4a93-b97d-c0e682e11ce0,DISK], DatanodeInfoWithStorage[127.0.0.1:37405,DS-082fc07d-d46b-4d03-a1c5-e3f640df254a,DISK], DatanodeInfoWithStorage[127.0.0.1:43128,DS-02cb6c91-b8f6-46dc-9b37-8c02f3f00f25,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-949615863-172.17.0.3-1598184200632:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35482,DS-47f4c2e6-1667-42d6-8338-57382ea3410c,DISK], DatanodeInfoWithStorage[127.0.0.1:36894,DS-88abb251-b064-4819-a7fc-0a808e8e7a23,DISK], DatanodeInfoWithStorage[127.0.0.1:44020,DS-773921f1-e0c1-4a44-89bf-00fc5a50cfe1,DISK], DatanodeInfoWithStorage[127.0.0.1:34455,DS-686791b6-84b6-4907-97a8-2cccb3899b43,DISK], DatanodeInfoWithStorage[127.0.0.1:39679,DS-e8f2be0a-c075-40aa-bb06-e628e8efdc90,DISK], DatanodeInfoWithStorage[127.0.0.1:33944,DS-863f8d28-905b-4a93-b97d-c0e682e11ce0,DISK], DatanodeInfoWithStorage[127.0.0.1:37405,DS-082fc07d-d46b-4d03-a1c5-e3f640df254a,DISK], DatanodeInfoWithStorage[127.0.0.1:43128,DS-02cb6c91-b8f6-46dc-9b37-8c02f3f00f25,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-351031233-172.17.0.3-1598184404893:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37453,DS-d4e04da5-40e9-4be6-b5af-c74220ad4320,DISK], DatanodeInfoWithStorage[127.0.0.1:45991,DS-fbc3d518-726a-49e3-95c3-178e727d1dae,DISK], DatanodeInfoWithStorage[127.0.0.1:43014,DS-26a41a47-e8e2-49cb-a9e1-e39ff9f29ded,DISK], DatanodeInfoWithStorage[127.0.0.1:37918,DS-459ec630-c899-4123-aac8-350717100311,DISK], DatanodeInfoWithStorage[127.0.0.1:43476,DS-824d896b-c18d-4206-8ec2-70026cd72e36,DISK], DatanodeInfoWithStorage[127.0.0.1:36278,DS-3e7dff94-d98b-450e-a089-077f601cf7c1,DISK], DatanodeInfoWithStorage[127.0.0.1:43196,DS-38bdba1e-e86e-407e-a27f-16619e5209ef,DISK], DatanodeInfoWithStorage[127.0.0.1:44392,DS-36299d72-33de-4b45-9b7a-d5eba30ad427,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-351031233-172.17.0.3-1598184404893:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37453,DS-d4e04da5-40e9-4be6-b5af-c74220ad4320,DISK], DatanodeInfoWithStorage[127.0.0.1:45991,DS-fbc3d518-726a-49e3-95c3-178e727d1dae,DISK], DatanodeInfoWithStorage[127.0.0.1:43014,DS-26a41a47-e8e2-49cb-a9e1-e39ff9f29ded,DISK], DatanodeInfoWithStorage[127.0.0.1:37918,DS-459ec630-c899-4123-aac8-350717100311,DISK], DatanodeInfoWithStorage[127.0.0.1:43476,DS-824d896b-c18d-4206-8ec2-70026cd72e36,DISK], DatanodeInfoWithStorage[127.0.0.1:36278,DS-3e7dff94-d98b-450e-a089-077f601cf7c1,DISK], DatanodeInfoWithStorage[127.0.0.1:43196,DS-38bdba1e-e86e-407e-a27f-16619e5209ef,DISK], DatanodeInfoWithStorage[127.0.0.1:44392,DS-36299d72-33de-4b45-9b7a-d5eba30ad427,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-128382211-172.17.0.3-1598184678130:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42059,DS-d614d2bb-0fe2-43b0-b8da-fa0ec5dce1de,DISK], DatanodeInfoWithStorage[127.0.0.1:46519,DS-0f84e8d8-87e4-496c-8a6f-f58ef21f6b7b,DISK], DatanodeInfoWithStorage[127.0.0.1:42898,DS-0899df9c-acf2-4c76-9db4-6e88271e6eef,DISK], DatanodeInfoWithStorage[127.0.0.1:42793,DS-74747cb7-1104-4831-9fae-b5900dbb42c8,DISK], DatanodeInfoWithStorage[127.0.0.1:44671,DS-d0cce840-8fef-4492-bc7f-3ddd165e3a6e,DISK], DatanodeInfoWithStorage[127.0.0.1:41592,DS-f853ba3e-5b39-49db-b972-5eb917414dbf,DISK], DatanodeInfoWithStorage[127.0.0.1:38978,DS-34181076-6cea-41ae-aa18-52b9f4229144,DISK], DatanodeInfoWithStorage[127.0.0.1:43280,DS-d5c58d1b-aa9a-479e-9c81-df85610bdbae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-128382211-172.17.0.3-1598184678130:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42059,DS-d614d2bb-0fe2-43b0-b8da-fa0ec5dce1de,DISK], DatanodeInfoWithStorage[127.0.0.1:46519,DS-0f84e8d8-87e4-496c-8a6f-f58ef21f6b7b,DISK], DatanodeInfoWithStorage[127.0.0.1:42898,DS-0899df9c-acf2-4c76-9db4-6e88271e6eef,DISK], DatanodeInfoWithStorage[127.0.0.1:42793,DS-74747cb7-1104-4831-9fae-b5900dbb42c8,DISK], DatanodeInfoWithStorage[127.0.0.1:44671,DS-d0cce840-8fef-4492-bc7f-3ddd165e3a6e,DISK], DatanodeInfoWithStorage[127.0.0.1:41592,DS-f853ba3e-5b39-49db-b972-5eb917414dbf,DISK], DatanodeInfoWithStorage[127.0.0.1:38978,DS-34181076-6cea-41ae-aa18-52b9f4229144,DISK], DatanodeInfoWithStorage[127.0.0.1:43280,DS-d5c58d1b-aa9a-479e-9c81-df85610bdbae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-209438401-172.17.0.3-1598184911034:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39441,DS-04d32d8e-739f-40ee-b845-999342aca942,DISK], DatanodeInfoWithStorage[127.0.0.1:33264,DS-b82391b9-4ac8-4677-bdfe-9b144ff5cec6,DISK], DatanodeInfoWithStorage[127.0.0.1:40782,DS-03fd8400-b8e0-4620-9bbf-1de0546d6593,DISK], DatanodeInfoWithStorage[127.0.0.1:42744,DS-eeead223-3fd8-4cca-b1eb-cb4f46b78c09,DISK], DatanodeInfoWithStorage[127.0.0.1:44362,DS-bb7f4e28-21ce-44d9-a4bd-3aee69c84a67,DISK], DatanodeInfoWithStorage[127.0.0.1:45664,DS-657b6cba-c351-4cfe-b8ef-7061452acec8,DISK], DatanodeInfoWithStorage[127.0.0.1:37680,DS-7f82873a-8be5-4b16-9324-a4c812e36a1c,DISK], DatanodeInfoWithStorage[127.0.0.1:39914,DS-d15ec6bb-4048-4a0e-ad82-688803dee209,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-209438401-172.17.0.3-1598184911034:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39441,DS-04d32d8e-739f-40ee-b845-999342aca942,DISK], DatanodeInfoWithStorage[127.0.0.1:33264,DS-b82391b9-4ac8-4677-bdfe-9b144ff5cec6,DISK], DatanodeInfoWithStorage[127.0.0.1:40782,DS-03fd8400-b8e0-4620-9bbf-1de0546d6593,DISK], DatanodeInfoWithStorage[127.0.0.1:42744,DS-eeead223-3fd8-4cca-b1eb-cb4f46b78c09,DISK], DatanodeInfoWithStorage[127.0.0.1:44362,DS-bb7f4e28-21ce-44d9-a4bd-3aee69c84a67,DISK], DatanodeInfoWithStorage[127.0.0.1:45664,DS-657b6cba-c351-4cfe-b8ef-7061452acec8,DISK], DatanodeInfoWithStorage[127.0.0.1:37680,DS-7f82873a-8be5-4b16-9324-a4c812e36a1c,DISK], DatanodeInfoWithStorage[127.0.0.1:39914,DS-d15ec6bb-4048-4a0e-ad82-688803dee209,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 11 out of 50
v1v1v2v2 failed with probability 15 out of 50
result: false positive !!!
Total execution time in seconds : 5095
